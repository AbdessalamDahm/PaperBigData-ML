"{\"abstract\":\"Deep learning has achieved great successes in solving specific artificial intelligence problems recently. Substantial progresses are made on Computer Vision (CV) and Natural Language Processing (NLP). As a connection between the two worlds of vision and language, video captioning is the task of producing a natural-language utterance (usually a sentence) that describes the visual content of a video. The task is naturally decomposed into two sub-tasks. One is to encode a video via a thorough understanding and learn visual representation. The other is caption generation, which decodes the learned representation into a sequential sentence, word by word. In this survey, we first formulate the problem of video captioning, then review stateof-the-art methods categorized by their emphasis on vision or language, and followed by a summary of standard datasets and representative approaches. Finally, we highlight the challenges which are not yet fully understood in this task and present future research directions.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\",\"url\":\"https://www.semanticscholar.org/author/39650418\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\",\"url\":\"https://www.semanticscholar.org/author/2053452\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\",\"url\":\"https://www.semanticscholar.org/author/1717861\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2001.11782\",\"authors\":[{\"authorId\":\"152584142\",\"name\":\"Zhengxiong Jia\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":\"10.1145/3372278.3390697\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"title\":\"iCap: Interactive Image Captioning with Predictive Text\",\"url\":\"https://www.semanticscholar.org/paper/87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123970110\",\"name\":\"T. Cai\"},{\"authorId\":\"2029318199\",\"name\":\"Michael I Mandel\"},{\"authorId\":\"1391126980\",\"name\":\"Di He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"568d98710ecd8402820f56ae08277adf1f9a0382\",\"title\":\"Music autotagging as captioning\",\"url\":\"https://www.semanticscholar.org/paper/568d98710ecd8402820f56ae08277adf1f9a0382\",\"venue\":\"NLP4MUSA\",\"year\":2020},{\"arxivId\":\"2008.05691\",\"authors\":[{\"authorId\":\"40342339\",\"name\":\"Kelly Mack\"},{\"authorId\":\"1666630110\",\"name\":\"Danielle Bragg\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"},{\"authorId\":\"24569263\",\"name\":\"M. W. Bos\"},{\"authorId\":\"1876811542\",\"name\":\"Isabelle Albi\"},{\"authorId\":\"1403171029\",\"name\":\"A. Monroy-Hern\\u00e1ndez\"}],\"doi\":\"10.1145/3415196\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df2cc12317c20bfde91351b483aa702cd1f84862\",\"title\":\"Social App Accessibility for Deaf Signers\",\"url\":\"https://www.semanticscholar.org/paper/df2cc12317c20bfde91351b483aa702cd1f84862\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":\"2005.07771\",\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"1703003796\",\"name\":\"Anish Madan\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"152253423\",\"name\":\"Y. Yu\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3949fff9e84261dee6e856faf4b04a27dfa460cd\",\"title\":\"C3VQG: Category Consistent Cyclic Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/3949fff9e84261dee6e856faf4b04a27dfa460cd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49868702\",\"name\":\"Ran Wei\"},{\"authorId\":\"144065286\",\"name\":\"Li Mi\"},{\"authorId\":\"7741774\",\"name\":\"Y. Hu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.jvcir.2020.102751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b43ca6f4615d5e384a9b404964a49ed21a14805\",\"title\":\"Exploiting the local temporal information for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4b43ca6f4615d5e384a9b404964a49ed21a14805\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020}],\"corpusId\":199465866,\"doi\":\"10.24963/ijcai.2019/877\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"references\":[{\"arxivId\":\"1705.02101\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"title\":\"TALL: Temporal Activity Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/e9bd6f0b04a0ddf9fcdf3a5fd1cfe87f8ae9cfff\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":null,\"name\":\"Mohit Bansal. Reinforced video captioning with entailmen rewards\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In EMNLP\",\"url\":\"\",\"venue\":\"pages 979\\u2013985,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Siqi Liu\"},{\"authorId\":null,\"name\":\"Zhenhai Zhu\"},{\"authorId\":null,\"name\":\"Ning Ye\"},{\"authorId\":null,\"name\":\"Sergio Guadarrama\"},{\"authorId\":null,\"name\":\"Kevin Murphy. Improved image captioning via policy gradi spider\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 873\\u2013881,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Chen\"},{\"authorId\":null,\"name\":\"William B. Dolan. Collecting highly parallel data for para evaluation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACL-HLT\",\"url\":\"\",\"venue\":\"pages 190\\u2013200,\",\"year\":2011},{\"arxivId\":\"1708.05271\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10480a42957a8e08e4c543185e135d7c254583a5\",\"title\":\"Incorporating Copying Mechanism in Image Captioning for Learning Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/10480a42957a8e08e4c543185e135d7c254583a5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1804.05448\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/N18-2125\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"title\":\"Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8548d5a93869a5a4c808f5e81742f59f848c718c\",\"title\":\"Semantic Proposal for Activity Localization in Videos via Sentence Query\",\"url\":\"https://www.semanticscholar.org/paper/8548d5a93869a5a4c808f5e81742f59f848c718c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yehao Li\"},{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Hongyang Chao\"},{\"authorId\":null,\"name\":\"Tao Mei. Jointly localizing\"},{\"authorId\":null,\"name\":\"describing events for dense video captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 7492\\u20137500,\",\"year\":2018},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":null,\"name\":\"Wenhao Jiang\"},{\"authorId\":null,\"name\":\"Lin Ma\"},{\"authorId\":null,\"name\":\"Wei Liu\"},{\"authorId\":null,\"name\":\"Yong Xu. Bidirectional attentive fusion with context ga captioning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 7190\\u20137198,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anna Rohrbach\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Wei Qiu\"},{\"authorId\":null,\"name\":\"Annemarie Friedrich\"},{\"authorId\":null,\"name\":\"Manfred Pinkal\"},{\"authorId\":null,\"name\":\"Bernt Schiele. Coherent multi-sentence video description detail\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In GCPR\",\"url\":\"\",\"venue\":\"pages 184\\u2013195,\",\"year\":2014},{\"arxivId\":\"1503.01070\",\"authors\":[{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"title\":\"Using Descriptive Video Services to Create a Large Data Source for Video Annotation Research\",\"url\":\"https://www.semanticscholar.org/paper/b1ddb2994e49a6a4f45e878c1cda7562b03177e6\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jingyuan Chen\"},{\"authorId\":null,\"name\":\"Xinpeng Chen\"},{\"authorId\":null,\"name\":\"Lin Ma\"},{\"authorId\":null,\"name\":\"Zequn Jie\"},{\"authorId\":null,\"name\":\"Tat-Seng Chua. Temporally grounding natural sentence in video\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In EMNLP\",\"url\":\"\",\"venue\":\"pages 162\\u2013171,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2363529\",\"name\":\"Pradipto Das\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"38972663\",\"name\":\"Richard F. Doell\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2013.340\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"title\":\"A Thousand Frames in Just a Few Words: Lingual Description of Videos through Latent Topics and Sparse Object Stitching\",\"url\":\"https://www.semanticscholar.org/paper/a23ab0fb7d9e9961e92d704ed71e3dbc15c0d908\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Quanzeng You\"},{\"authorId\":null,\"name\":\"Hailin Jin\"},{\"authorId\":null,\"name\":\"Zhaowen Wang\"},{\"authorId\":null,\"name\":\"Chen Fang\"},{\"authorId\":null,\"name\":\"Jiebo Luo. Image captioning with semantic attention\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 4651\\u20134659,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Atsuhiro Kojima\"},{\"authorId\":null,\"name\":\"Takeshi Tamura\"},{\"authorId\":null,\"name\":\"Kunio Fukunaga. Natural language description of human ac actions\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"International Journal of Computer Vision\",\"url\":\"\",\"venue\":\"50(2):171\\u2013184,\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Houqiang Li\"},{\"authorId\":null,\"name\":\"Tao Mei. Video captioning with transferred semantic attributes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 984\\u2013992,\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huiyun Wang\"},{\"authorId\":null,\"name\":\"Youjiang Xu\"},{\"authorId\":null,\"name\":\"Yahong Han. Spotting\"},{\"authorId\":null,\"name\":\"aggregating salient regions for video captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 1519\\u20131526,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jingkuan Song\"},{\"authorId\":null,\"name\":\"Lianli Gao\"},{\"authorId\":null,\"name\":\"Zhao Guo\"},{\"authorId\":null,\"name\":\"Wu Liu\"},{\"authorId\":null,\"name\":\"Dongxiang Zhang\"},{\"authorId\":null,\"name\":\"Heng Tao Shen. Hierarchical LSTM with adjusted temporal captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 2737\\u20132743,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xuguang Duan\"},{\"authorId\":null,\"name\":\"Wen-bing Huang\"},{\"authorId\":null,\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Jingdong Wang\"},{\"authorId\":null,\"name\":\"Wenwu Zhu\"},{\"authorId\":null,\"name\":\"Junzhou Huang. Weakly supervised dense event captioning in videos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 3063\\u20133073,\",\"year\":2018},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2263748\",\"name\":\"Chuanqi Shen\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2017.675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"352b190acfe19406baee53a169a8732f9b2764d4\",\"title\":\"SST: Single-Stream Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/352b190acfe19406baee53a169a8732f9b2764d4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Christian Szegedy\"},{\"authorId\":null,\"name\":\"Vincent Vanhoucke\"},{\"authorId\":null,\"name\":\"Sergey Ioffe\"},{\"authorId\":null,\"name\":\"Jonathon Shlens\"},{\"authorId\":null,\"name\":\"Zbigniew Wojna. Rethinking the inception architecture for c vision\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 2818\\u20132826,\",\"year\":2016},{\"arxivId\":\"1812.06587\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"171a027fc6c7f4194569170accc48187c8bb5aaa\",\"title\":\"Grounded Video Description\",\"url\":\"https://www.semanticscholar.org/paper/171a027fc6c7f4194569170accc48187c8bb5aaa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhiqiang Shen\"},{\"authorId\":null,\"name\":\"Jianguo Li\"},{\"authorId\":null,\"name\":\"Zhou Su\"},{\"authorId\":null,\"name\":\"Minjun Li\"},{\"authorId\":null,\"name\":\"Yurong Chen\"},{\"authorId\":null,\"name\":\"Yu-Gang Jiang\"},{\"authorId\":null,\"name\":\"Xiangyang Xue. Weakly supervised dense video captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 5159\\u20135167,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lubomir D. Du Tran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bourdev , Rob Fergus , Lorenzo Torresani , and Manohar Paluri . Learning spatiotemporal features with 3 d convolutional networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shizhe Chen\"},{\"authorId\":null,\"name\":\"Jia Chen\"},{\"authorId\":null,\"name\":\"Qin Jin\"},{\"authorId\":null,\"name\":\"Alexander G. Hauptmann. Video captioning with guidance of mu topics\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 1838\\u2013 1846,\",\"year\":2017},{\"arxivId\":\"1905.01077\",\"authors\":[{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1609/aaai.v33i01.33018167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d40892479541c2d173c836534e6fb2acb597de49\",\"title\":\"Temporal Deformable Convolutional Encoder-Decoder Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d40892479541c2d173c836534e6fb2acb597de49\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Steven J. Rennie\"},{\"authorId\":null,\"name\":\"Etienne Marcheret\"},{\"authorId\":null,\"name\":\"Youssef Mroueh\"},{\"authorId\":null,\"name\":\"Jarret Ross\"},{\"authorId\":null,\"name\":\"Vaibhava Goel. Selfcritical sequence training for image captioning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 1179\\u20131195,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Yehao Li\"},{\"authorId\":null,\"name\":\"Tao Mei. Incorporating copying mechanism in image capt objects\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 5263\\u20135271,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Li Yao\"},{\"authorId\":null,\"name\":\"Atousa Torabi\"},{\"authorId\":null,\"name\":\"Kyunghyun Cho\"},{\"authorId\":null,\"name\":\"Nicolas Ballas\"},{\"authorId\":null,\"name\":\"Christopher J. Pal\"},{\"authorId\":null,\"name\":\"Hugo Larochelle\"},{\"authorId\":null,\"name\":\"Aaron C. Courville. Describing videos by exploiting temp structure\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4507\\u20134515,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anna Rohrbach\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Niket Tandon\"},{\"authorId\":null,\"name\":\"Bernt Schiele. A dataset for movie description\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 3202\\u20133212,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Tao Mei\"},{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Houqiang Li\"},{\"authorId\":null,\"name\":\"Yong Rui. Jointly modeling embedding\"},{\"authorId\":null,\"name\":\"translation to bridge video\"},{\"authorId\":null,\"name\":\"language\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 4594\\u20134602,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stephanie Pancoast\"},{\"authorId\":null,\"name\":\"Murat Akbacak. Softening quantization in bag-of-audiowords\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICASSP\",\"url\":\"\",\"venue\":\"pages 1370\\u20131374,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Vaswani\"},{\"authorId\":null,\"name\":\"Noam Shazeer\"},{\"authorId\":null,\"name\":\"Niki Parmar\"},{\"authorId\":null,\"name\":\"Jakob Uszkoreit\"},{\"authorId\":null,\"name\":\"Llion Jones\"},{\"authorId\":null,\"name\":\"Aidan N. Gomez\"},{\"authorId\":null,\"name\":\"Lukasz Kaiser\"},{\"authorId\":null,\"name\":\"Illia Polosukhin. Attention is all you need\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 6000\\u20136010,\",\"year\":2017},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.24963/ijcai.2017/307\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e33bc5c83f2cea403a5521385ee8e2794b311275\",\"title\":\"MAM-RNN: Multi-level Attention Model Based RNN for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e33bc5c83f2cea403a5521385ee8e2794b311275\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144841441\",\"name\":\"J. Xu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3123266.3123448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff172624dd0a3bd31ca925b73cd7295d596173e2\",\"title\":\"Learning Multimodal Attention LSTM Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ff172624dd0a3bd31ca925b73cd7295d596173e2\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"},{\"authorId\":\"3766304\",\"name\":\"Abhaya Agarwal\"}],\"doi\":\"10.3115/1626355.1626389\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34d7a07c493ca6336c92156806a2947e115caadc\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/34d7a07c493ca6336c92156806a2947e115caadc\",\"venue\":\"WMT@ACL\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Vasili Ramanishka\"},{\"authorId\":null,\"name\":\"Abir Das\"},{\"authorId\":null,\"name\":\"Dong Huk Park\"},{\"authorId\":null,\"name\":\"Subhashini Venugopalan\"},{\"authorId\":null,\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Kate Saenko. Multimodal video description\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 1092\\u20131096,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ranjay Krishna\"},{\"authorId\":null,\"name\":\"Kenji Hata\"},{\"authorId\":null,\"name\":\"Frederic Ren\"},{\"authorId\":null,\"name\":\"Li Fei-Fei\"},{\"authorId\":null,\"name\":\"Juan Carlos Niebles. Densecaptioning events in videos\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 706\\u2013715,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haonan Yu\"},{\"authorId\":null,\"name\":\"Jiang Wang\"},{\"authorId\":null,\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":null,\"name\":\"Wei Xu. Video paragraph captioning using hierarchical networks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 4584\\u20134593,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In CVPR\",\"url\":\"\",\"venue\":\"pages 770\\u2013778,\",\"year\":2016},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67093239\",\"name\":\"\\uae40\\uac74\\uc911\"}],\"doi\":\"10.1021/acsguide.40106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cb07b6ddbf161c0a199f6941243cbd733bdae0f\",\"title\":\"\\ucc28\\uc138\\ub300 Multimedia \\uc11c\\ube44\\uc2a4\",\"url\":\"https://www.semanticscholar.org/paper/6cb07b6ddbf161c0a199f6941243cbd733bdae0f\",\"venue\":\"\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Subhashini Venugopalan\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Jeffrey Donahue\"},{\"authorId\":null,\"name\":\"Raymond J. Mooney\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Kate Saenko. Sequence to sequence - video to text\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4534\\u20134542,\",\"year\":2015},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1704.01502\",\"authors\":[{\"authorId\":\"145314568\",\"name\":\"Zhiqiang Shen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"},{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"3700393\",\"name\":\"Minjun Li\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2017.548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"title\":\"Weakly Supervised Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87836796\",\"name\":\"S. Moss\"}],\"doi\":\"10.1080/20519842.2017.1271602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76fc42fa34104156d9d118b49d7e201da917a1f\",\"title\":\"Listen\",\"url\":\"https://www.semanticscholar.org/paper/e76fc42fa34104156d9d118b49d7e201da917a1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"title\":\"Spotting and Aggregating Salient Regions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018191\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"title\":\"Motion Guided Spatial Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2013.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6a7a563640bf53953c4fda0997e4db176488510\",\"title\":\"YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6a7a563640bf53953c4fda0997e4db176488510\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tianwei Lin\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":null,\"name\":\"Zheng Shou. Single shot temporal action detection\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 988\\u2013996,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":null,\"name\":\"Oliver Wang\"},{\"authorId\":null,\"name\":\"Eli Shechtman\"},{\"authorId\":null,\"name\":\"Josef Sivic\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Bryan Russell. Localizing moments in video with natural language\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 5804\\u20135813,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jun Xu\"},{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Tao Mei. Learning multimodal attention LSTM networks f captioning\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ACM MM\",\"url\":\"\",\"venue\":\"pages 537\\u2013545,\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":\"1710.08011\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"35163655\",\"name\":\"K. Hata\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba11083602568bbc2514c0905e0d831a65c2af6e\",\"title\":\"ActivityNet Challenge 2017 Summary\",\"url\":\"https://www.semanticscholar.org/paper/ba11083602568bbc2514c0905e0d831a65c2af6e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nayyer Aafaq\"},{\"authorId\":null,\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":null,\"name\":\"Wei Liu\"},{\"authorId\":null,\"name\":\"Ajmal Mian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Video description: A survey of methods\",\"url\":\"\",\"venue\":\"datasets and evaluation metrics. arXiv preprint arXiv:1806.00186,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chiori Hori\"},{\"authorId\":null,\"name\":\"Takaaki Hori\"},{\"authorId\":null,\"name\":\"Teng-Yok Lee\"},{\"authorId\":null,\"name\":\"Ziming Zhang\"},{\"authorId\":null,\"name\":\"Bret Harsham\"},{\"authorId\":null,\"name\":\"John R. Hershey\"},{\"authorId\":null,\"name\":\"Tim K. Marks\"},{\"authorId\":null,\"name\":\"Kazuhiko Sumi. Attention-based multimodal fusion for video description\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 4203\\u20134212,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonas Gehring\"},{\"authorId\":null,\"name\":\"Michael Auli\"},{\"authorId\":null,\"name\":\"David Grangier\"},{\"authorId\":null,\"name\":\"Denis Yarats\"},{\"authorId\":null,\"name\":\"Yann N. Dauphin. Convolutional sequence to sequence learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 1243\\u20131252,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hershey et al\"},{\"authorId\":null,\"name\":\"2017 Shawn Hershey\"},{\"authorId\":null,\"name\":\"Sourish Chaudhuri\"},{\"authorId\":null,\"name\":\"Daniel P.W. Ellis\"},{\"authorId\":null,\"name\":\"Jort F. Gemmeke\"},{\"authorId\":null,\"name\":\"Aren Jansen\"},{\"authorId\":null,\"name\":\"R. Channing Moore\"},{\"authorId\":null,\"name\":\"Manoj Plakal\"},{\"authorId\":null,\"name\":\"Devin Platt\"},{\"authorId\":null,\"name\":\"Rif A. Saurous\"},{\"authorId\":null,\"name\":\"Bryan Seybold\"},{\"authorId\":null,\"name\":\"Malcolm Slaney\"},{\"authorId\":null,\"name\":\"Ron J. Weiss\"},{\"authorId\":null,\"name\":\"Kevin W. Wilson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CNN architectures for large-scale\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Michaela Regneri\"},{\"authorId\":null,\"name\":\"Marcus Rohrbach\"},{\"authorId\":null,\"name\":\"Dominikus Wetzel\"},{\"authorId\":null,\"name\":\"Stefan Thater\"},{\"authorId\":null,\"name\":\"Bernt Schiele\"},{\"authorId\":null,\"name\":\"Manfred Pinkal. Grounding action descriptions in videos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Transactions of the Association for Computational Linguistics\",\"url\":\"\",\"venue\":\"1:25\\u201336,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Yingwei Pan\"},{\"authorId\":null,\"name\":\"Yehao Li\"},{\"authorId\":null,\"name\":\"Tao Mei. Exploring visual relationship for image captioning\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ECCV\",\"url\":\"\",\"venue\":\"pages 684\\u2013699,\",\"year\":2018},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chen\"},{\"authorId\":null,\"name\":\"Shaoxiang\"},{\"authorId\":null,\"name\":\"Ting Yao\"},{\"authorId\":null,\"name\":\"Yu-Gang Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deep learning for video captioning: a review.\",\"url\":\"\",\"venue\":\"Proceedings of the 28th International Joint Conference on Artificial Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Deep Learning for Video Captioning: A Review\",\"topics\":[{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"}],\"url\":\"https://www.semanticscholar.org/paper/eeca19117a8a733aae6fb4a91c51d1c1dc03eb7f\",\"venue\":\"IJCAI\",\"year\":2019}\n"