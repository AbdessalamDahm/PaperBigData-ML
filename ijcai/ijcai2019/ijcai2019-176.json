"{\"abstract\":\"Artificial Intelligence has seen several breakthroughs in two-player perfect information game. Nevertheless, Doudizhu, a three-player imperfect information game, is still quite challenging. In this paper, we present a Doudizhu AI by applying deep reinforcement learning from games of self-play. The algorithm combines an asymmetric MCTS on nodes representing each player\\u2019s information set, a policy-value network that approximates the policy and value on each decision node, and inference on unobserved hands of other players by given policy. Our results show that self-play can significantly improve the performance of our agent in this multiagent imperfect information game. Even starting with a weak AI, our agent can achieve human expert level after days of self-play and training.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"7212083\",\"name\":\"Qiqi Jiang\",\"url\":\"https://www.semanticscholar.org/author/7212083\"},{\"authorId\":\"151484554\",\"name\":\"K. Li\",\"url\":\"https://www.semanticscholar.org/author/151484554\"},{\"authorId\":\"151487369\",\"name\":\"B. Du\",\"url\":\"https://www.semanticscholar.org/author/151487369\"},{\"authorId\":null,\"name\":\"Hao Chen\",\"url\":null},{\"authorId\":\"50417738\",\"name\":\"Hai Fang\",\"url\":\"https://www.semanticscholar.org/author/50417738\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"46636541\",\"name\":\"Y. Gao\"}],\"doi\":\"10.3233/icg-190138\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1928d975f3eaea3a436c257e4f8e3ff4bfd7e113\",\"title\":\"The DouDiZhu tournament of the 2019 Computer Olympiad\",\"url\":\"https://www.semanticscholar.org/paper/1928d975f3eaea3a436c257e4f8e3ff4bfd7e113\",\"venue\":\"J. Int. Comput. Games Assoc.\",\"year\":2020},{\"arxivId\":\"1910.04376\",\"authors\":[{\"authorId\":\"1759658\",\"name\":\"Daochen Zha\"},{\"authorId\":\"51238382\",\"name\":\"Kwei-Herng Lai\"},{\"authorId\":\"153842970\",\"name\":\"Y. Cao\"},{\"authorId\":\"50822341\",\"name\":\"Song-Yi Huang\"},{\"authorId\":\"1381629357\",\"name\":\"Ruzhe Wei\"},{\"authorId\":null,\"name\":\"Junyu Guo\"},{\"authorId\":\"48539647\",\"name\":\"Xia Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"891a964ba4c5b36d87066a2c38b841bd6cd18978\",\"title\":\"RLCard: A Toolkit for Reinforcement Learning in Card Games\",\"url\":\"https://www.semanticscholar.org/paper/891a964ba4c5b36d87066a2c38b841bd6cd18978\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46372384\",\"name\":\"Jiayu Xu\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"48571613\",\"name\":\"Like Zhang\"},{\"authorId\":\"2040216379\",\"name\":\"Junle Wang\"},{\"authorId\":\"18183222\",\"name\":\"Chong Zhang\"},{\"authorId\":\"2000862732\",\"name\":\"Yanqing Jing\"},{\"authorId\":\"2900841\",\"name\":\"Z. Wang\"},{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"}],\"doi\":\"10.1145/3434581.3434611\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"733d1dd0dc502ac0d4261d83680cd616e2b82c90\",\"title\":\"Lineup Mining and Balance Analysis of Auto Battler\",\"url\":\"https://www.semanticscholar.org/paper/733d1dd0dc502ac0d4261d83680cd616e2b82c90\",\"venue\":\"\",\"year\":2020}],\"corpusId\":199465788,\"doi\":\"10.24963/ijcai.2019/176\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"fce784e6ce4e9eceb45ebd03cd130d733a9f33bc\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824021\",\"name\":\"J. Long\"},{\"authorId\":\"15914175\",\"name\":\"Nathan R Sturtevant\"},{\"authorId\":\"1799228\",\"name\":\"M. Buro\"},{\"authorId\":\"1785387\",\"name\":\"T. Furtak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"011e2c79575721764c127e210c9d8105a6305e70\",\"title\":\"Understanding the Success of Perfect Information Monte Carlo Sampling in Game Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/011e2c79575721764c127e210c9d8105a6305e70\",\"venue\":\"AAAI\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145528658\",\"name\":\"G. Kendall\"}],\"doi\":\"10.1109/TCIAIG.2015.2409514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9046f46d088eee7be4af8be5ffea602394a937c0\",\"title\":\"Editorial: IEEE Transactions on Computational Intelligence and AI in Games\",\"url\":\"https://www.semanticscholar.org/paper/9046f46d088eee7be4af8be5ffea602394a937c0\",\"venue\":\"IEEE Trans. Comput. Intell. AI Games\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Michael Buro\"},{\"authorId\":null,\"name\":\"Jeffrey Richard Long\"},{\"authorId\":null,\"name\":\"Timothy Furtak\"},{\"authorId\":null,\"name\":\"Nathan R Sturtevant. Improving state evaluation\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"inference\",\"url\":\"\",\"venue\":\"and search in trick-based card games. In IJCAI, pages 1407\\u20131413,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37183181\",\"name\":\"J. Heinrich\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8db6005fda5ed2d5d0e011a1ac14d26386e630b9\",\"title\":\"Smooth UCT Search in Computer Poker\",\"url\":\"https://www.semanticscholar.org/paper/8db6005fda5ed2d5d0e011a1ac14d26386e630b9\",\"venue\":\"IJCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Johannes Heinrich\"},{\"authorId\":null,\"name\":\"David Silver. Smooth uct search in computer poker\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 554\\u2013560,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Timothy Furtak\"},{\"authorId\":null,\"name\":\"Michael Buro. Recursive monte carlo search for imperfect i games\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Computational Intelligence in Games (CIG)\",\"url\":\"\",\"venue\":\"2013 IEEE Conference on, pages 1\\u20138. IEEE,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799228\",\"name\":\"M. Buro\"},{\"authorId\":\"47824021\",\"name\":\"J. Long\"},{\"authorId\":\"1785387\",\"name\":\"T. Furtak\"},{\"authorId\":\"15914175\",\"name\":\"Nathan R Sturtevant\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92ba50551dbe9b304e75260eb3070e0cf40ec2b2\",\"title\":\"Improving State Evaluation, Inference, and Search in Trick-Based Card Games\",\"url\":\"https://www.semanticscholar.org/paper/92ba50551dbe9b304e75260eb3070e0cf40ec2b2\",\"venue\":\"IJCAI\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gerald Tesauro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Td-gammon: A selfteaching backgammon program\",\"url\":\"\",\"venue\":\"Applications of Neural Networks, pages 267\\u2013285. Springer,\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37183181\",\"name\":\"J. Heinrich\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b20f103c1f20074fa35bd8fc41983964283acac\",\"title\":\"Fictitious Self-Play in Extensive-Form Games\",\"url\":\"https://www.semanticscholar.org/paper/8b20f103c1f20074fa35bd8fc41983964283acac\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2685623\",\"name\":\"Noam Brown\"},{\"authorId\":\"145714168\",\"name\":\"T. Sandholm\"}],\"doi\":\"10.1126/science.aao1733\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaabb78d0bc44ed132e4d077e9486c86a9e4cda9\",\"title\":\"Superhuman AI for heads-up no-limit poker: Libratus beats top professionals\",\"url\":\"https://www.semanticscholar.org/paper/eaabb78d0bc44ed132e4d077e9486c86a9e4cda9\",\"venue\":\"Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1785387\",\"name\":\"T. Furtak\"},{\"authorId\":\"1799228\",\"name\":\"M. Buro\"}],\"doi\":\"10.1109/CIG.2013.6633646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43b9b9a0bf666cb0363881d65f5db4cf004d3e61\",\"title\":\"Recursive Monte Carlo search for imperfect information games\",\"url\":\"https://www.semanticscholar.org/paper/43b9b9a0bf666cb0363881d65f5db4cf004d3e61\",\"venue\":\"2013 IEEE Conference on Computational Inteligence in Games (CIG)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100858232\",\"name\":\"O. Brownlee\"},{\"authorId\":\"2697616\",\"name\":\"T. Koopmans\"}],\"doi\":\"10.2307/1907816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a973eb892f233acb3093589393181ae633d3a244\",\"title\":\"ACTIVITY ANALYSIS OF PRODUCTION AND ALLOCATION\",\"url\":\"https://www.semanticscholar.org/paper/a973eb892f233acb3093589393181ae633d3a244\",\"venue\":\"\",\"year\":1952},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706174\",\"name\":\"M. Ginsberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0b8530ded7444ca40cca23b59d014f2f9c78340\",\"title\":\"GIB: Steps Toward an Expert-Level Bridge-Playing Program\",\"url\":\"https://www.semanticscholar.org/paper/e0b8530ded7444ca40cca23b59d014f2f9c78340\",\"venue\":\"IJCAI\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32767016\",\"name\":\"M. Ponsen\"},{\"authorId\":\"38881572\",\"name\":\"Geert Gerritsen\"},{\"authorId\":\"145599543\",\"name\":\"Guillaume Chaslot\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"895395ec1a146aea68a7d86eab3388990b22accd\",\"title\":\"Integrating Opponent Models with Monte-Carlo Tree Search in Poker\",\"url\":\"https://www.semanticscholar.org/paper/895395ec1a146aea68a7d86eab3388990b22accd\",\"venue\":\"Interactive Decision Theory and Game Theory\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Edward J Powley\"},{\"authorId\":null,\"name\":\"Daniel Whitehouse\"},{\"authorId\":null,\"name\":\"Peter I Cowling. Determinization in monte-carlo tree sea Simul\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Behav\",\"url\":\"\",\"venue\":\"pages 17\\u201324,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144497046\",\"name\":\"N. Nilsson\"}],\"doi\":\"10.7551/mitpress/11723.003.0006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b886f2c097b635ee9550ca29fff7dcbbb7727ff7\",\"title\":\"Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/b886f2c097b635ee9550ca29fff7dcbbb7727ff7\",\"venue\":\"IFIP Congress\",\"year\":1974},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Johannes Heinrich\"},{\"authorId\":null,\"name\":\"Marc Lanctot\"},{\"authorId\":null,\"name\":\"David Silver. Fictitious self-play in extensive-form games\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 805\\u2013813,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5952316\",\"name\":\"L. Christophorou\"}],\"doi\":\"10.1007/978-3-319-90713-0_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bccfe3fc62312408a4b27cb46b15a19e0176f995\",\"title\":\"Science\",\"url\":\"https://www.semanticscholar.org/paper/bccfe3fc62312408a4b27cb46b15a19e0176f995\",\"venue\":\"Emerging Dynamics: Science, Energy, Society and Values\",\"year\":2018},{\"arxivId\":\"1701.01724\",\"authors\":[{\"authorId\":\"8801705\",\"name\":\"Matej Moravc\\u00edk\"},{\"authorId\":\"46828293\",\"name\":\"Martina Schmid\"},{\"authorId\":\"2625574\",\"name\":\"Neil Burch\"},{\"authorId\":\"1759154\",\"name\":\"V. Lis\\u00fd\"},{\"authorId\":\"2551974\",\"name\":\"Dustin Morrill\"},{\"authorId\":\"2294262\",\"name\":\"N. Bard\"},{\"authorId\":\"48112534\",\"name\":\"Trevor Davis\"},{\"authorId\":\"144514513\",\"name\":\"K. Waugh\"},{\"authorId\":\"1681530\",\"name\":\"Michael Bradley Johanson\"},{\"authorId\":\"143913104\",\"name\":\"Michael H. Bowling\"}],\"doi\":\"10.1126/science.aam6960\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2155552ca5afb784a3c1d67a5bcbd4e688b6e05\",\"title\":\"DeepStack: Expert-level artificial intelligence in heads-up no-limit poker\",\"url\":\"https://www.semanticscholar.org/paper/a2155552ca5afb784a3c1d67a5bcbd4e688b6e05\",\"venue\":\"Science\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2449382\",\"name\":\"T. Hubert\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"40227832\",\"name\":\"Matthew Lai\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1126/science.aar6404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9717d29840f4d8f1cc19d1b1e80c5d12ec40608\",\"title\":\"A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play\",\"url\":\"https://www.semanticscholar.org/paper/f9717d29840f4d8f1cc19d1b1e80c5d12ec40608\",\"venue\":\"Science\",\"year\":2018},{\"arxivId\":\"1603.01121\",\"authors\":[{\"authorId\":\"37183181\",\"name\":\"J. Heinrich\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1d2a7ef81960846b9cec00bce8eefa06ccc8796\",\"title\":\"Deep Reinforcement Learning from Self-Play in Imperfect-Information Games\",\"url\":\"https://www.semanticscholar.org/paper/a1d2a7ef81960846b9cec00bce8eefa06ccc8796\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ponsen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Thore Graepel, et al. A general reinforcement learning algorithm that masters chess, shogi, and go through selfplay\",\"url\":\"\",\"venue\":\"Workshops at the Twenty-Fourth AAAI Conference on Artificial Intelligence\",\"year\":1995}],\"title\":\"DeltaDou: Expert-level Doudizhu AI through Self-play\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Value network\",\"topicId\":\"70279\",\"url\":\"https://www.semanticscholar.org/topic/70279\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Influence diagram\",\"topicId\":\"38454\",\"url\":\"https://www.semanticscholar.org/topic/38454\"},{\"topic\":\"Weak AI\",\"topicId\":\"1251676\",\"url\":\"https://www.semanticscholar.org/topic/1251676\"},{\"topic\":\"Information Card\",\"topicId\":\"537935\",\"url\":\"https://www.semanticscholar.org/topic/537935\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Agent-based model\",\"topicId\":\"4774\",\"url\":\"https://www.semanticscholar.org/topic/4774\"},{\"topic\":\"Monte Carlo tree search\",\"topicId\":\"18928\",\"url\":\"https://www.semanticscholar.org/topic/18928\"}],\"url\":\"https://www.semanticscholar.org/paper/fce784e6ce4e9eceb45ebd03cd130d733a9f33bc\",\"venue\":\"IJCAI\",\"year\":2019}\n"