"{\"abstract\":\"Imitation learning targets deriving a mapping from states to actions, a.k.a. policy, from expert demonstrations. Existing methods for imitation learning typically require any actions in the demonstrations to be fully available, which is hard to ensure in real applications. Though algorithms for learning with unobservable actions have been proposed, they focus solely on state information and overlook the fact that the action sequence could still be partially available and provide useful information for policy deriving. In this paper, we propose a novel algorithm called Action-Guided Adversarial Imitation Learning (AGAIL) that learns a policy from demonstrations with incomplete action sequences, i.e., incomplete demonstrations. The core idea of AGAIL is to separate demonstrations into state and action trajectories, and train a policy with state trajectories while using actions as auxiliary information to guide the training whenever applicable. Built upon the Generative Adversarial Imitation Learning, AGAIL has three components: a generator, a discriminator, and a guide. The generator learns a policy with rewards provided by the discriminator, which tries to distinguish state distributions between demonstrations and samples generated by the policy. The guide provides additional rewards to the generator when demonstrated actions for specific states are available. We compare AGAIL to other methods on benchmark tasks and show that AGAIL consistently delivers comparable performance to the state-of-the-art methods even when the action sequence in demonstrations is only partially available.\",\"arxivId\":\"1905.12310\",\"authors\":[{\"authorId\":\"9492808\",\"name\":\"M. Sun\",\"url\":\"https://www.semanticscholar.org/author/9492808\"},{\"authorId\":\"3230330\",\"name\":\"Xiaojuan Ma\",\"url\":\"https://www.semanticscholar.org/author/3230330\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2005.01020\",\"authors\":[{\"authorId\":\"9492808\",\"name\":\"M. Sun\"},{\"authorId\":\"15476901\",\"name\":\"Z. Peng\"},{\"authorId\":\"35722495\",\"name\":\"M. Xia\"},{\"authorId\":\"3230330\",\"name\":\"Xiaojuan Ma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f1881a111d252e938582f5ad267f42f89adcab7\",\"title\":\"Investigating the Effects of Robot Engagement Communication on Learning from Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/9f1881a111d252e938582f5ad267f42f89adcab7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08353\",\"authors\":[{\"authorId\":\"6592040\",\"name\":\"Zhihao Cheng\"},{\"authorId\":\"144117135\",\"name\":\"L. Liu\"},{\"authorId\":\"153152072\",\"name\":\"Aishan Liu\"},{\"authorId\":\"144990601\",\"name\":\"Hao Sun\"},{\"authorId\":\"39829184\",\"name\":\"Meng Fang\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aaecb73259a939ea1f2e088f5a937a1a4791349\",\"title\":\"On the Guaranteed Almost Equivalence between Imitation Learning from Observation and Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/4aaecb73259a939ea1f2e088f5a937a1a4791349\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.07284\",\"authors\":[{\"authorId\":\"48026827\",\"name\":\"Eiji Uchibe\"},{\"authorId\":\"1714997\",\"name\":\"K. Doya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"543ab481de60cb2e3a9b67128996d93c8dfac361\",\"title\":\"Imitation learning based on entropy-regularized forward and inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/543ab481de60cb2e3a9b67128996d93c8dfac361\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":168169989,\"doi\":\"10.24963/ijcai.2019/487\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e402ae3e5db859e45960b32419bd511c56d06152\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Andrew Bagnell Shreyansh Daftry\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"gan : Interpretable representation learning by information maximizing generative adversarial nets\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1802.06070\",\"authors\":[{\"authorId\":\"8140754\",\"name\":\"Benjamin Eysenbach\"},{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"46920727\",\"name\":\"J. Ibarz\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b01eaef54a653ba03ddd5a978690380fbc19bfc\",\"title\":\"Diversity is All You Need: Learning Skills without a Reward Function\",\"url\":\"https://www.semanticscholar.org/paper/5b01eaef54a653ba03ddd5a978690380fbc19bfc\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100947077\",\"name\":\"\\u6052\\u592b \\u5409\\u5ddd\"}],\"doi\":\"10.7210/JRSJ.7.400\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"19b7cbf244e7b6aed8dd2782c8ad4f65c211514f\",\"title\":\"First International Symposium on Experimental Robotics\",\"url\":\"https://www.semanticscholar.org/paper/19b7cbf244e7b6aed8dd2782c8ad4f65c211514f\",\"venue\":\"\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Brian D. Ziebart\"},{\"authorId\":null,\"name\":\"J. Andrew Bagnell\"},{\"authorId\":null,\"name\":\"Anind K. Dey. Modeling interaction via the principle of entropy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 1255\\u20131262,\",\"year\":2010},{\"arxivId\":\"1603.00448\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04162cb8cfaa0f7e37586823ff4ad0bff09ed21d\",\"title\":\"Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/04162cb8cfaa0f7e37586823ff4ad0bff09ed21d\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2837869\",\"name\":\"T. Brys\"},{\"authorId\":\"3134710\",\"name\":\"A. Harutyunyan\"},{\"authorId\":\"2811287\",\"name\":\"Halit Bener Suay\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"},{\"authorId\":\"144336828\",\"name\":\"A. Now\\u00e9\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f926d3bf410875857effe1b5000a4fbc25397b74\",\"title\":\"Reinforcement Learning from Demonstration through Shaping\",\"url\":\"https://www.semanticscholar.org/paper/f926d3bf410875857effe1b5000a4fbc25397b74\",\"venue\":\"IJCAI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Ho\"},{\"authorId\":null,\"name\":\"Stefano Ermon. Generative adversarial imitation learning\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 4565\\u20134573,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Brian D Ziebart\"},{\"authorId\":null,\"name\":\"Andrew L Maas\"},{\"authorId\":null,\"name\":\"J Andrew Bagnell\"},{\"authorId\":null,\"name\":\"Anind K Dey\"},{\"authorId\":null,\"name\":\"J. Andrew Bagnell Brian D. Ziebart\"},{\"authorId\":null,\"name\":\"Anind K. Dey\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Trust region policy optimization Apprenticeship learning using linear programming\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37814588\",\"name\":\"M. Puterman\"}],\"doi\":\"10.1002/9780470316887\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8090121ad488b4af27bc59bf91b62e9c6a6f49c6\",\"title\":\"Markov Decision Processes: Discrete Stochastic Dynamic Programming\",\"url\":\"https://www.semanticscholar.org/paper/8090121ad488b4af27bc59bf91b62e9c6a6f49c6\",\"venue\":\"Wiley Series in Probability and Statistics\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735414\",\"name\":\"T. Knasel\"}],\"doi\":\"10.1016/0921-8890(88)90002-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd77f310393f521669b209cbb6828fb45a8485d\",\"title\":\"Robotics and autonomous systems\",\"url\":\"https://www.semanticscholar.org/paper/edd77f310393f521669b209cbb6828fb45a8485d\",\"venue\":\"Robotics Auton. Syst.\",\"year\":1988},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1011.0686\",\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"21889436\",\"name\":\"G. Gordon\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"79ab3c49903ec8cb339437ccf5cf998607fc313e\",\"title\":\"A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning\",\"url\":\"https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e\",\"venue\":\"AISTATS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Ho\"},{\"authorId\":null,\"name\":\"Stefano Ermon. Generative adversarial imitation learning\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 4565\\u20134573,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Michael I Jordan\"},{\"authorId\":null,\"name\":\"Philipp Moritz. Trust region policy optimization. In ICML\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"volume 37\",\"url\":\"\",\"venue\":\"pages 1889\\u20131897,\",\"year\":2015},{\"arxivId\":\"1608.00627\",\"authors\":[{\"authorId\":\"2739544\",\"name\":\"Shreyansh Daftry\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-50115-4_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e0540ea3c3cc8cd009b2006d96c4b3ac2a84e52\",\"title\":\"Learning Transferable Policies for Monocular Reactive MAV Control\",\"url\":\"https://www.semanticscholar.org/paper/8e0540ea3c3cc8cd009b2006d96c4b3ac2a84e52\",\"venue\":\"ISER\",\"year\":2016},{\"arxivId\":\"1805.01954\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2018/687\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc2fb12eaa4dae74c5de0799b29624b5c585c43b\",\"title\":\"Behavioral Cloning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/cc2fb12eaa4dae74c5de0799b29624b5c585c43b\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"70e10a5459c6f1aaf346ee4f2dcc837151fbe75c\",\"title\":\"Efficient Reductions for Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/70e10a5459c6f1aaf346ee4f2dcc837151fbe75c\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145847467\",\"name\":\"D. Pomerleau\"}],\"doi\":\"10.1162/neco.1991.3.1.88\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d652a1980e743c7c85ff6066409ea1e3be4d685\",\"title\":\"Efficient Training of Artificial Neural Networks for Autonomous Navigation\",\"url\":\"https://www.semanticscholar.org/paper/8d652a1980e743c7c85ff6066409ea1e3be4d685\",\"venue\":\"Neural Computation\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Andrew Y Ng. Apprenticeship learning via inverse reinforc ICML\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"page 1\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Geoffrey Gordon\"},{\"authorId\":null,\"name\":\"Drew Bagnell. A reduction of imitation learning\"},{\"authorId\":null,\"name\":\"structured prediction to no-regret online learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the fourteenth international conference on artificial intelligence and statistics\",\"url\":\"\",\"venue\":\"pages 627\\u2013635,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35712547\",\"name\":\"N. Baram\"},{\"authorId\":\"8412923\",\"name\":\"Oron Anschel\"},{\"authorId\":\"39954258\",\"name\":\"I. Caspi\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"814b36fedfe7f7ce10eaa72bddb3c7ea7a663f37\",\"title\":\"End-to-End Differentiable Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/814b36fedfe7f7ce10eaa72bddb3c7ea7a663f37\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"51453887\",\"name\":\"Jiaming Song\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4135004c75a361c91311314fc588d229a7107526\",\"title\":\"InfoGAIL: Interpretable Imitation Learning from Visual Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/4135004c75a361c91311314fc588d229a7107526\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1836885\",\"name\":\"Brenna Argall\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"},{\"authorId\":\"1699032\",\"name\":\"B. Browning\"}],\"doi\":\"10.1016/j.robot.2008.10.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e5dfb0b1e54412e799eb0e86d552956cc3a5f54\",\"title\":\"A survey of robot learning from demonstration\",\"url\":\"https://www.semanticscholar.org/paper/4e5dfb0b1e54412e799eb0e86d552956cc3a5f54\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152300037\",\"name\":\"J. Young\"}],\"doi\":\"10.1038/230260b0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6cea23b4a07b66e3122252f47f9cc715b469cf9\",\"title\":\"Machine Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/b6cea23b4a07b66e3122252f47f9cc715b469cf9\",\"venue\":\"Nature\",\"year\":1971},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Brian D. Ziebart\"},{\"authorId\":null,\"name\":\"J. Andrew Bagnell\"},{\"authorId\":null,\"name\":\"Anind K. Dey. Modeling interaction via the principle of ICML\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICML\\u201910\",\"url\":\"\",\"venue\":\"pages 1255\\u20131262, USA,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144041292\",\"name\":\"M. Bain\"},{\"authorId\":\"1804253\",\"name\":\"C. Sammut\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f4731d5133cb96ab30e08bf39dffa874aebf487\",\"title\":\"A Framework for Behavioural Cloning\",\"url\":\"https://www.semanticscholar.org/paper/1f4731d5133cb96ab30e08bf39dffa874aebf487\",\"venue\":\"Machine Intelligence 15\",\"year\":1995},{\"arxivId\":\"1707.02201\",\"authors\":[{\"authorId\":\"1879232\",\"name\":\"J. Merel\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"22216833\",\"name\":\"TB Dhruva\"},{\"authorId\":\"144999731\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"144083287\",\"name\":\"Jay Lemmon\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e6e01f580c973d91f6445d839389f9f2d5efc78e\",\"title\":\"Learning human behaviors from motion capture by adversarial imitation\",\"url\":\"https://www.semanticscholar.org/paper/e6e01f580c973d91f6445d839389f9f2d5efc78e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1302.4971\",\"authors\":[{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"39971338\",\"name\":\"T. Dean\"},{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ae91735c6e5f4ab44bfa95bd144663f057d1935\",\"title\":\"On the Complexity of Solving Markov Decision Problems\",\"url\":\"https://www.semanticscholar.org/paper/7ae91735c6e5f4ab44bfa95bd144663f057d1935\",\"venue\":\"UAI\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"34961461\",\"name\":\"Andrew L. Maas\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"144021446\",\"name\":\"Anind K. Dey\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11b6bdfe36c48b11367b27187da11d95892f0361\",\"title\":\"Maximum Entropy Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/11b6bdfe36c48b11367b27187da11d95892f0361\",\"venue\":\"AAAI\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nir Baram\"},{\"authorId\":null,\"name\":\"Oron Anschel\"},{\"authorId\":null,\"name\":\"Itai Caspi\"},{\"authorId\":null,\"name\":\"Shie Mannor. End-to-end differentiable adversarial imit learning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 390\\u2013399,\",\"year\":2017},{\"arxivId\":\"1606.03476\",\"authors\":[{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"title\":\"Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Michael L Littman\"},{\"authorId\":null,\"name\":\"Thomas L Dean\"},{\"authorId\":null,\"name\":\"Leslie Pack Kaelbling. On the complexity of solving marko Intelligence\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 394\\u2013402\",\"url\":\"\",\"venue\":\"Morgan Kaufmann Publishers Inc.,\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492009633\",\"name\":\"Patrick J. Roa\"}],\"doi\":\"10.1023/A:1017153816538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"title\":\"Volume 8\",\"url\":\"https://www.semanticscholar.org/paper/8e6d789ee714d29c9b5156ba9d61b2170d7a315f\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1606.01540\",\"authors\":[{\"authorId\":\"49508975\",\"name\":\"G. Brockman\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"152877508\",\"name\":\"Ludwig Pettersson\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143805717\",\"name\":\"Jie Tang\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"title\":\"OpenAI Gym\",\"url\":\"https://www.semanticscholar.org/paper/ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784820\",\"name\":\"A. Taylor\"}],\"doi\":\"10.1145/1518701.1519022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20efcd00528a0b7d3bf28c2da0950c8a0c7bebe6\",\"title\":\"Machine intelligence\",\"url\":\"https://www.semanticscholar.org/paper/20efcd00528a0b7d3bf28c2da0950c8a0c7bebe6\",\"venue\":\"CHI\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38473726\",\"name\":\"U. Syed\"},{\"authorId\":\"1687780\",\"name\":\"Michael Bowling\"},{\"authorId\":\"1716301\",\"name\":\"R. Schapire\"}],\"doi\":\"10.1145/1390156.1390286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45c16943fb8cffd1a23ac45345107cf79ad2bb79\",\"title\":\"Apprenticeship learning using linear programming\",\"url\":\"https://www.semanticscholar.org/paper/45c16943fb8cffd1a23ac45345107cf79ad2bb79\",\"venue\":\"ICML '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Umar Syed\"},{\"authorId\":null,\"name\":\"Michael Bowling\"},{\"authorId\":null,\"name\":\"Robert E Schapire. Apprenticeship learning using linear p ICML\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"pages 1032\\u20131039\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2008},{\"arxivId\":\"1604.07316\",\"authors\":[{\"authorId\":\"3146322\",\"name\":\"M. Bojarski\"},{\"authorId\":\"2824480\",\"name\":\"D. Testa\"},{\"authorId\":\"3393305\",\"name\":\"Daniel Dworakowski\"},{\"authorId\":\"2372758\",\"name\":\"Bernhard Firner\"},{\"authorId\":\"2286388\",\"name\":\"Beat Flepp\"},{\"authorId\":\"38774604\",\"name\":\"Prasoon Goyal\"},{\"authorId\":\"2307573\",\"name\":\"L. Jackel\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145636949\",\"name\":\"U. Muller\"},{\"authorId\":\"3393542\",\"name\":\"Jiakai Zhang\"},{\"authorId\":\"145863017\",\"name\":\"X. Zhang\"},{\"authorId\":\"79678947\",\"name\":\"Jake Zhao\"},{\"authorId\":\"3262926\",\"name\":\"Karol Zieba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3cc46583217ec81e87045a4f9ae3478a008227\",\"title\":\"End to End Learning for Self-Driving Cars\",\"url\":\"https://www.semanticscholar.org/paper/0e3cc46583217ec81e87045a4f9ae3478a008227\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98241663\",\"name\":\"M. V. Rossum\"}],\"doi\":\"10.1142/9789814360784_0003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"title\":\"Neural Computation\",\"url\":\"https://www.semanticscholar.org/paper/2d5af1ab6368f20a4a9bb2afae23663e5b08b9c6\",\"venue\":\"\",\"year\":1989},{\"arxivId\":\"1703.01703\",\"authors\":[{\"authorId\":\"3275284\",\"name\":\"Bradly C. Stadie\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e1a1b9c2e8feeb31c6855292859bf94101e8382\",\"title\":\"Third-Person Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2e1a1b9c2e8feeb31c6855292859bf94101e8382\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995717\",\"name\":\"Bingyi Kang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c979efe1f0a8b0b343ea332368e5b51dc153c522\",\"title\":\"Policy Optimization with Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/c979efe1f0a8b0b343ea332368e5b51dc153c522\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Drew Bagnell. Efficient reductions for imitation learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the thirteenth international conference on artificial intelligence and statistics\",\"url\":\"\",\"venue\":\"pages 661\\u2013668,\",\"year\":2010},{\"arxivId\":\"1802.05313\",\"authors\":[{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c37e0d93d19efbd8bb50d1a4d92979793f4341d2\",\"title\":\"Reinforcement Learning from Imperfect Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/c37e0d93d19efbd8bb50d1a4d92979793f4341d2\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1606.03657\",\"authors\":[{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"35da0a2001eea88486a5de677ab97868c93d0824\",\"title\":\"InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/35da0a2001eea88486a5de677ab97868c93d0824\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"144021446\",\"name\":\"Anind K. Dey\"}],\"doi\":\"10.1184/R1/6555611.V1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d13f848714c21268e0f52472309ff6b6b3140ec6\",\"title\":\"Modeling Interaction via the Principle of Maximum Causal Entropy\",\"url\":\"https://www.semanticscholar.org/paper/d13f848714c21268e0f52472309ff6b6b3140ec6\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1145/1015330.1015430\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"title\":\"Apprenticeship learning via inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"venue\":\"ICML '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"1868677\",\"name\":\"D. Harada\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94066dc12fe31e96af7557838159bde598cb4f10\",\"title\":\"Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping\",\"url\":\"https://www.semanticscholar.org/paper/94066dc12fe31e96af7557838159bde598cb4f10\",\"venue\":\"ICML\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bingyi Kang\"},{\"authorId\":null,\"name\":\"Zequn Jie\"},{\"authorId\":null,\"name\":\"Jiashi Feng. Policy optimization with demonstrations\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 2474\\u20132483,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dean A Pomerleau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Algo - rithms for inverse reinforcement learning\",\"url\":\"\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.2460/AJVR.67.2.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"title\":\"Algorithms for Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"venue\":\"ICML\",\"year\":2000}],\"title\":\"Adversarial Imitation Learning from Incomplete Demonstrations\",\"topics\":[{\"topic\":\"Discriminator\",\"topicId\":\"41710\",\"url\":\"https://www.semanticscholar.org/topic/41710\"},{\"topic\":\"Mutual information\",\"topicId\":\"23425\",\"url\":\"https://www.semanticscholar.org/topic/23425\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Integrated test facility\",\"topicId\":\"2350571\",\"url\":\"https://www.semanticscholar.org/topic/2350571\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/e402ae3e5db859e45960b32419bd511c56d06152\",\"venue\":\"IJCAI\",\"year\":2019}\n"