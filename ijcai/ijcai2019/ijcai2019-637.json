"{\"abstract\":\"With the increase in the amount of data and the expansion of model scale, distributed parallel training becomes an important and successful technique to address the optimization challenges. Nevertheless, although distributed stochastic gradient descent (SGD) algorithms can achieve a linear iteration speedup, they are limited significantly in practice by the communication cost, making it difficult to achieve a linear time speedup. In this paper, we propose a computation and communication decoupled stochastic gradient descent (CoCoD-SGD) algorithm to run computation and communication in parallel to reduce the communication cost. We prove that CoCoD-SGD has a linear iteration speedup with respect to the total computation capability of the hardware resources. In addition, it has a lower communication complexity and better time speedup comparing with traditional distributed SGD algorithms. Experiments on deep neural network training demonstrate the significant improvements of CoCoD-SGD: when training ResNet18 and VGG16 with 16 Geforce GTX 1080Ti GPUs, CoCoD-SGD is up to 2-3$\\\\times$ faster than traditional synchronous SGD.\",\"arxivId\":\"1906.12043\",\"authors\":[{\"authorId\":\"24984914\",\"name\":\"S. Shen\",\"url\":\"https://www.semanticscholar.org/author/24984914\"},{\"authorId\":\"2230211\",\"name\":\"Linli Xu\",\"url\":\"https://www.semanticscholar.org/author/2230211\"},{\"authorId\":\"49722448\",\"name\":\"J. Liu\",\"url\":\"https://www.semanticscholar.org/author/49722448\"},{\"authorId\":\"51175567\",\"name\":\"Xianfeng Liang\",\"url\":\"https://www.semanticscholar.org/author/51175567\"},{\"authorId\":\"49097021\",\"name\":\"Yifei Cheng\",\"url\":\"https://www.semanticscholar.org/author/49097021\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1912.12844\",\"authors\":[{\"authorId\":\"152922681\",\"name\":\"Xian-Feng Liang\"},{\"authorId\":\"1456158490\",\"name\":\"Shuheng Shen\"},{\"authorId\":\"15114609\",\"name\":\"J. Liu\"},{\"authorId\":\"145070813\",\"name\":\"Z. Pan\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"49097021\",\"name\":\"Yifei Cheng\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1db9e4e420f940f821ab5974a3c96614304c5995\",\"title\":\"Variance Reduced Local SGD with Lower Communication Complexity\",\"url\":\"https://www.semanticscholar.org/paper/1db9e4e420f940f821ab5974a3c96614304c5995\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.08277\",\"authors\":[{\"authorId\":\"51175126\",\"name\":\"Haozhao Wang\"},{\"authorId\":\"1999171\",\"name\":\"Z. Qu\"},{\"authorId\":\"144123438\",\"name\":\"Song Guo\"},{\"authorId\":\"1470731190\",\"name\":\"Xin Gao\"},{\"authorId\":\"9358854\",\"name\":\"Ruixuan Li\"},{\"authorId\":\"3243858\",\"name\":\"Baoliu Ye\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a47bd5fdb0abbe5fc2fe093f2cab0d0fa3a0aef3\",\"title\":\"Intermittent Pulling with Local Compensation for Communication-Efficient Federated Learning\",\"url\":\"https://www.semanticscholar.org/paper/a47bd5fdb0abbe5fc2fe093f2cab0d0fa3a0aef3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.09539\",\"authors\":[{\"authorId\":\"30880777\",\"name\":\"Jianyu Wang\"},{\"authorId\":\"143922910\",\"name\":\"Hao Liang\"},{\"authorId\":\"144225970\",\"name\":\"Gauri Joshi\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053834\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74748e65866091bc6bdb2a91b6606b2e17eea1d9\",\"title\":\"Overlap Local-SGD: An Algorithmic Approach to Hide Communication Delays in Distributed SGD\",\"url\":\"https://www.semanticscholar.org/paper/74748e65866091bc6bdb2a91b6606b2e17eea1d9\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50668220\",\"name\":\"Shuo Ouyang\"},{\"authorId\":\"39891717\",\"name\":\"Dezun Dong\"},{\"authorId\":\"3450366\",\"name\":\"Yemao Xu\"},{\"authorId\":\"27695626\",\"name\":\"Li-quan Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"470ac7863e30f804e9cdec673e6570c92737b9de\",\"title\":\"Communication Optimization Strategies for Distributed Deep Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/470ac7863e30f804e9cdec673e6570c92737b9de\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06377\",\"authors\":[{\"authorId\":\"1456158490\",\"name\":\"Shuheng Shen\"},{\"authorId\":\"1443743714\",\"name\":\"Yifei Cheng\"},{\"authorId\":\"15114609\",\"name\":\"J. Liu\"},{\"authorId\":\"2230211\",\"name\":\"Linli Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ac8bc1db6dfb793b0905e966bd8e2fc1fa59650\",\"title\":\"STL-SGD: Speeding Up Local SGD with Stagewise Communication Period\",\"url\":\"https://www.semanticscholar.org/paper/8ac8bc1db6dfb793b0905e966bd8e2fc1fa59650\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00433\",\"authors\":[{\"authorId\":\"13743960\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51261b5d6f6ae1e2fb067e9f2747f2ed2f4c7ee1\",\"title\":\"Shuffle-Exchange Brings Faster: Reduce the Idle Time During Communication for Decentralized Neural Network Training\",\"url\":\"https://www.semanticscholar.org/paper/51261b5d6f6ae1e2fb067e9f2747f2ed2f4c7ee1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03009\",\"authors\":[{\"authorId\":\"50668220\",\"name\":\"Shuo Ouyang\"},{\"authorId\":\"39891717\",\"name\":\"Dezun Dong\"},{\"authorId\":\"3450366\",\"name\":\"Yemao Xu\"},{\"authorId\":\"27695626\",\"name\":\"Li-quan Xiao\"}],\"doi\":\"10.1016/j.jpdc.2020.11.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"444470335d06646c064797dbdbf4e23b662c2a41\",\"title\":\"Communication optimization strategies for distributed deep neural network training: A survey\",\"url\":\"https://www.semanticscholar.org/paper/444470335d06646c064797dbdbf4e23b662c2a41\",\"venue\":\"\",\"year\":2020}],\"corpusId\":195750755,\"doi\":\"10.24963/ijcai.2019/637\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"95eb340785e5f0f30daafb091be40129568c45f4\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"38713459\",\"name\":\"Hao Yu\"},{\"authorId\":null,\"name\":\"Sen Yang\"},{\"authorId\":\"1682028\",\"name\":\"Shenghuo Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1fd42ad509ad98ae2a7a09dbbc559a694155992\",\"title\":\"Parallel Restarted SGD for Non-Convex Optimization with Faster Convergence and Less Communication\",\"url\":\"https://www.semanticscholar.org/paper/e1fd42ad509ad98ae2a7a09dbbc559a694155992\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N Luehr\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Fast multi-gpu collectives with nccl, 2016\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2407825\",\"name\":\"S. Potluri\"},{\"authorId\":\"1780048\",\"name\":\"Khaled Hamidouche\"},{\"authorId\":\"143806133\",\"name\":\"Akshay Venkatesh\"},{\"authorId\":\"3070999\",\"name\":\"Devendar Bureddy\"},{\"authorId\":\"1731654\",\"name\":\"D. Panda\"}],\"doi\":\"10.1109/ICPP.2013.17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"497fc8616563777046ecc89c85771b2ab446a518\",\"title\":\"Efficient Inter-node MPI Communication Using GPUDirect RDMA for InfiniBand Clusters with NVIDIA GPUs\",\"url\":\"https://www.semanticscholar.org/paper/497fc8616563777046ecc89c85771b2ab446a518\",\"venue\":\"2013 42nd International Conference on Parallel Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mu Li\"},{\"authorId\":\"34752743\",\"name\":\"D. Andersen\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"144887704\",\"name\":\"K. Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ca5de59edbdd49a9c0502c58331524d220bc8c\",\"title\":\"Communication Efficient Distributed Machine Learning with the Parameter Server\",\"url\":\"https://www.semanticscholar.org/paper/04ca5de59edbdd49a9c0502c58331524d220bc8c\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1708.01012\",\"authors\":[{\"authorId\":\"144315735\",\"name\":\"Fan Zhou\"},{\"authorId\":\"3136303\",\"name\":\"G. Cong\"}],\"doi\":\"10.24963/ijcai.2018/447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b07018924334ddc6ec0e8cb07ba0093d5e8c7997\",\"title\":\"On the convergence properties of a K-step averaging stochastic gradient descent algorithm for nonconvex optimization\",\"url\":\"https://www.semanticscholar.org/paper/b07018924334ddc6ec0e8cb07ba0093d5e8c7997\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1104.5525\",\"authors\":[{\"authorId\":\"40333747\",\"name\":\"A. Agarwal\"},{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"}],\"doi\":\"10.1109/CDC.2012.6426626\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15b252f6a6439479462f74a4f41484a461a93ca5\",\"title\":\"Distributed delayed stochastic optimization\",\"url\":\"https://www.semanticscholar.org/paper/15b252f6a6439479462f74a4f41484a461a93ca5\",\"venue\":\"2012 IEEE 51st IEEE Conference on Decision and Control (CDC)\",\"year\":2012},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1706.02677\",\"authors\":[{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34837514\",\"name\":\"P. Noordhuis\"},{\"authorId\":\"39033676\",\"name\":\"L. Wesolowski\"},{\"authorId\":\"1717990\",\"name\":\"Aapo Kyrola\"},{\"authorId\":\"3609856\",\"name\":\"Andrew Tulloch\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"title\":\"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\",\"url\":\"https://www.semanticscholar.org/paper/0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1809.07599\",\"authors\":[{\"authorId\":\"2127057\",\"name\":\"S. Stich\"},{\"authorId\":\"51440515\",\"name\":\"Jean-Baptiste Cordonnier\"},{\"authorId\":\"2456863\",\"name\":\"M. Jaggi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38f1ef8ab96e5e0195abcd197bf6df47eb308e8a\",\"title\":\"Sparsified SGD with Memory\",\"url\":\"https://www.semanticscholar.org/paper/38f1ef8ab96e5e0195abcd197bf6df47eb308e8a\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1012.1367\",\"authors\":[{\"authorId\":\"1716876\",\"name\":\"O. Dekel\"},{\"authorId\":\"1388775848\",\"name\":\"Ran Gilad-Bachrach\"},{\"authorId\":\"1768909\",\"name\":\"O. Shamir\"},{\"authorId\":\"145942104\",\"name\":\"L. Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b197d60de05e14781d67a318b29a4d4600a7460\",\"title\":\"Optimal Distributed Online Prediction Using Mini-Batches\",\"url\":\"https://www.semanticscholar.org/paper/4b197d60de05e14781d67a318b29a4d4600a7460\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":\"1506.08272\",\"authors\":[{\"authorId\":\"2922996\",\"name\":\"Xiangru Lian\"},{\"authorId\":\"48356204\",\"name\":\"Yijun Huang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"37427994\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0d4ca87ff248812de726e668120534b37783104\",\"title\":\"Asynchronous Parallel Stochastic Gradient for Nonconvex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/c0d4ca87ff248812de726e668120534b37783104\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3311387\",\"name\":\"Dan Alistarh\"},{\"authorId\":\"29916095\",\"name\":\"Demjan Grubic\"},{\"authorId\":\"2800851\",\"name\":\"Jerry Li\"},{\"authorId\":\"2870603\",\"name\":\"Ryota Tomioka\"},{\"authorId\":\"1782150\",\"name\":\"M. Vojnovic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69b52a20c6f909f36447b09741a73e1993643448\",\"title\":\"QSGD: Communication-Efficient SGD via Gradient Quantization and Encoding\",\"url\":\"https://www.semanticscholar.org/paper/69b52a20c6f909f36447b09741a73e1993643448\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1805.09767\",\"authors\":[{\"authorId\":\"2127057\",\"name\":\"S. Stich\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cfa76a82be96c74b2eff514265b7fd271a179cd\",\"title\":\"Local SGD Converges Fast and Communicates Little\",\"url\":\"https://www.semanticscholar.org/paper/7cfa76a82be96c74b2eff514265b7fd271a179cd\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1809.10505\",\"authors\":[{\"authorId\":\"3311387\",\"name\":\"Dan Alistarh\"},{\"authorId\":\"1713648\",\"name\":\"Torsten Hoefler\"},{\"authorId\":\"153374846\",\"name\":\"M. Johansson\"},{\"authorId\":\"35342555\",\"name\":\"Sarit Khirirat\"},{\"authorId\":\"145292827\",\"name\":\"Nikola Konstantinov\"},{\"authorId\":\"37833666\",\"name\":\"C\\u00e9dric Renggli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8c43aa050203e2b49cd8021d0f65c7d2cca00e\",\"title\":\"The Convergence of Sparsified Gradient Methods\",\"url\":\"https://www.semanticscholar.org/paper/2d8c43aa050203e2b49cd8021d0f65c7d2cca00e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Wen\"},{\"authorId\":null,\"name\":\"Cong Xu\"},{\"authorId\":null,\"name\":\"Feng Yan\"},{\"authorId\":null,\"name\":\"Chunpeng Wu\"},{\"authorId\":null,\"name\":\"Yandan Wang\"},{\"authorId\":null,\"name\":\"Yiran Chen\"},{\"authorId\":null,\"name\":\"Hai Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Jean - Baptiste Cordon - nier , and Martin Jaggi . Sparsified sgd with memory\",\"url\":\"\",\"venue\":\"Parallel Processing ( ICPP )\",\"year\":null},{\"arxivId\":\"1811.03619\",\"authors\":[{\"authorId\":\"50024633\",\"name\":\"Youjie Li\"},{\"authorId\":\"2036193\",\"name\":\"Mingchao Yu\"},{\"authorId\":\"50341280\",\"name\":\"Songze Li\"},{\"authorId\":\"5877233\",\"name\":\"A. S. Avestimehr\"},{\"authorId\":\"1686484\",\"name\":\"Nam Sung Kim\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7aeae28124c322ded336e753c016488cd7305562\",\"title\":\"Pipe-SGD: A Decentralized Pipelined SGD Framework for Distributed Deep Net Training\",\"url\":\"https://www.semanticscholar.org/paper/7aeae28124c322ded336e753c016488cd7305562\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1705.07878\",\"authors\":[{\"authorId\":\"145225262\",\"name\":\"Wei Wen\"},{\"authorId\":\"145656507\",\"name\":\"C. Xu\"},{\"authorId\":\"145552742\",\"name\":\"Feng Yan\"},{\"authorId\":\"3207491\",\"name\":\"Chunpeng Wu\"},{\"authorId\":\"2416228\",\"name\":\"Yandan Wang\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"40348219\",\"name\":\"Hai Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bdb91a6e47385292ab7a18e8901a6a25f50cc6b\",\"title\":\"TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4bdb91a6e47385292ab7a18e8901a6a25f50cc6b\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1702.05800\",\"authors\":[{\"authorId\":\"47740021\",\"name\":\"J. Chen\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1944541\",\"name\":\"R. J\\u00f3zefowicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"25fb5a6abcd88ee52bdb3165b844c941e90eb9bf\",\"title\":\"Revisiting Distributed Synchronous SGD\",\"url\":\"https://www.semanticscholar.org/paper/25fb5a6abcd88ee52bdb3165b844c941e90eb9bf\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1802.05799\",\"authors\":[{\"authorId\":\"145099650\",\"name\":\"A. Sergeev\"},{\"authorId\":\"35816153\",\"name\":\"Mike Del Balso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2c8726d092aea573e69f5b0a2654225883cfacf\",\"title\":\"Horovod: fast and easy distributed deep learning in TensorFlow\",\"url\":\"https://www.semanticscholar.org/paper/e2c8726d092aea573e69f5b0a2654225883cfacf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1605.08695\",\"authors\":[{\"authorId\":\"51284110\",\"name\":\"M. Abadi\"},{\"authorId\":\"144758007\",\"name\":\"P. Barham\"},{\"authorId\":\"47740021\",\"name\":\"J. Chen\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"36347083\",\"name\":\"Andy Davis\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"1780892\",\"name\":\"Sanjay Ghemawat\"},{\"authorId\":\"145659929\",\"name\":\"Geoffrey Irving\"},{\"authorId\":\"73195837\",\"name\":\"M. Isard\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"},{\"authorId\":\"3369421\",\"name\":\"Josh Levenberg\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"144375552\",\"name\":\"Sherry Moore\"},{\"authorId\":\"20154699\",\"name\":\"D. Murray\"},{\"authorId\":\"32163737\",\"name\":\"B. Steiner\"},{\"authorId\":\"2080690\",\"name\":\"P. Tucker\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"47941411\",\"name\":\"Pete Warden\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"145167058\",\"name\":\"Y. Yu\"},{\"authorId\":\"47957022\",\"name\":\"Xiaoqiang Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46200b99c40e8586c8a0f588488ab6414119fb28\",\"title\":\"TensorFlow: A system for large-scale machine learning\",\"url\":\"https://www.semanticscholar.org/paper/46200b99c40e8586c8a0f588488ab6414119fb28\",\"venue\":\"OSDI\",\"year\":2016},{\"arxivId\":\"1512.01274\",\"authors\":[{\"authorId\":\"1913774\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Mu Li\"},{\"authorId\":\"3047972\",\"name\":\"Y. Li\"},{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"48246959\",\"name\":\"Naiyan Wang\"},{\"authorId\":\"5366829\",\"name\":\"Minjie Wang\"},{\"authorId\":\"39102205\",\"name\":\"Tianjun Xiao\"},{\"authorId\":\"48310008\",\"name\":\"B. Xu\"},{\"authorId\":\"40313479\",\"name\":\"C. Zhang\"},{\"authorId\":null,\"name\":\"Zheng Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62df84d6a4d26f95e4714796c2337c9848cc13b5\",\"title\":\"MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\",\"url\":\"https://www.semanticscholar.org/paper/62df84d6a4d26f95e4714796c2337c9848cc13b5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1309.5549\",\"authors\":[{\"authorId\":\"2291057\",\"name\":\"S. Ghadimi\"},{\"authorId\":\"2070945\",\"name\":\"G. Lan\"}],\"doi\":\"10.1137/120880811\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8424a9e5a4456a2c45a42e392b9c01cd0c5c9467\",\"title\":\"Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic Programming\",\"url\":\"https://www.semanticscholar.org/paper/8424a9e5a4456a2c45a42e392b9c01cd0c5c9467\",\"venue\":\"SIAM J. Optim.\",\"year\":2013},{\"arxivId\":\"1712.01887\",\"authors\":[{\"authorId\":\"49417466\",\"name\":\"Yujun Lin\"},{\"authorId\":\"153114506\",\"name\":\"S. Han\"},{\"authorId\":\"3123774\",\"name\":\"Huizi Mao\"},{\"authorId\":null,\"name\":\"Yu Wang\"},{\"authorId\":\"80724002\",\"name\":\"W. Dally\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"92495abbac86394cb759bec15a763dbf49a8e590\",\"title\":\"Deep Gradient Compression: Reducing the Communication Bandwidth for Distributed Training\",\"url\":\"https://www.semanticscholar.org/paper/92495abbac86394cb759bec15a763dbf49a8e590\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1704.05021\",\"authors\":[{\"authorId\":\"8129718\",\"name\":\"A. F. Aji\"},{\"authorId\":\"1702066\",\"name\":\"Kenneth Heafield\"}],\"doi\":\"10.18653/v1/D17-1045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8437e3b32f091f62f3796556435e139db130f90\",\"title\":\"Sparse Communication for Distributed Gradient Descent\",\"url\":\"https://www.semanticscholar.org/paper/e8437e3b32f091f62f3796556435e139db130f90\",\"venue\":\"EMNLP\",\"year\":2017}],\"title\":\"Faster Distributed Deep Net Training: Computation and Communication Decoupled Stochastic Gradient Descent\",\"topics\":[{\"topic\":\"Stochastic gradient descent\",\"topicId\":\"202796\",\"url\":\"https://www.semanticscholar.org/topic/202796\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Speedup\",\"topicId\":\"4162\",\"url\":\"https://www.semanticscholar.org/topic/4162\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Iteration\",\"topicId\":\"11823\",\"url\":\"https://www.semanticscholar.org/topic/11823\"},{\"topic\":\"Communication complexity\",\"topicId\":\"17505\",\"url\":\"https://www.semanticscholar.org/topic/17505\"},{\"topic\":\"Time complexity\",\"topicId\":\"3448\",\"url\":\"https://www.semanticscholar.org/topic/3448\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Deep Web\",\"topicId\":\"79183\",\"url\":\"https://www.semanticscholar.org/topic/79183\"},{\"topic\":\"GeForce 200 series\",\"topicId\":\"305355\",\"url\":\"https://www.semanticscholar.org/topic/305355\"}],\"url\":\"https://www.semanticscholar.org/paper/95eb340785e5f0f30daafb091be40129568c45f4\",\"venue\":\"IJCAI\",\"year\":2019}\n"