"{\"abstract\":\"Recently, research on variance reduced incremental gradient descent methods (e.g., SAGA) has made exciting progress (e.g., linear convergence for strongly convex (SC) problems). However, existing accelerated methods (e.g., point-SAGA) suffer from drawbacks such as inflexibility. In this paper, we design a novel and simple momentum to accelerate the classical SAGA algorithm, and propose a direct accelerated incremental gradient descent algorithm. In particular, our theoretical result shows that our algorithm attains a best-known oracle complexity for SC minimization problems and an improved convergence rate for the case of n\\u2265 L/\\u03bc. We also give experimental results justifying our theoretical results and showing the effectiveness of our algorithm.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"49420369\",\"name\":\"Y. Liu\",\"url\":\"https://www.semanticscholar.org/author/49420369\"},{\"authorId\":\"3062185\",\"name\":\"F. Shang\",\"url\":\"https://www.semanticscholar.org/author/3062185\"},{\"authorId\":\"144125121\",\"name\":\"L. Jiao\",\"url\":\"https://www.semanticscholar.org/author/144125121\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"35588611\",\"name\":\"Yuan-yuan Liu\"},{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"48447409\",\"name\":\"H. Liu\"},{\"authorId\":\"153125712\",\"name\":\"Lin Kong\"},{\"authorId\":\"9277609\",\"name\":\"Jiao Li-cheng\"},{\"authorId\":\"144859190\",\"name\":\"Z. Lin\"}],\"doi\":\"10.1109/tpami.2020.3000512\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a8e47054f06b52f5633a47644117f13cb1432574\",\"title\":\"Accelerated Variance Reduction Stochastic ADMM for Large-Scale Machine Learning.\",\"url\":\"https://www.semanticscholar.org/paper/a8e47054f06b52f5633a47644117f13cb1432574\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1912.00858\",\"authors\":[{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"152395542\",\"name\":\"Bingkun Wei\"},{\"authorId\":\"8424393\",\"name\":\"Hongying Liu\"},{\"authorId\":\"40270988\",\"name\":\"Y. Liu\"},{\"authorId\":\"9924411\",\"name\":\"Jiacheng Zhuo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9590577b159abd2a6fd8222cb76022473559e320\",\"title\":\"Efficient Relaxed Gradient Support Pursuit for Sparsity Constrained Non-convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/9590577b159abd2a6fd8222cb76022473559e320\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":199466024,\"doi\":\"10.24963/ijcai.2019/422\",\"fieldsOfStudy\":[\"Physics\",\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"4f9692725b69ee24933bb775c54c6cdc85265505\",\"references\":[{\"arxivId\":\"1603.05953\",\"authors\":[{\"authorId\":\"1388725932\",\"name\":\"Zeyuan Allen-Zhu\"}],\"doi\":\"10.1145/3055399.3055448\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06fc893d0a70249e6350df1495755b79f0870ad0\",\"title\":\"Katyusha: the first direct acceleration of stochastic gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/06fc893d0a70249e6350df1495755b79f0870ad0\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70053935\",\"name\":\"H. McLaughlin\"},{\"authorId\":\"117057253\",\"name\":\"Anna Liljestrom\"},{\"authorId\":\"145752919\",\"name\":\"J. Lim\"},{\"authorId\":\"48181154\",\"name\":\"D. Meyers\"}],\"doi\":\"10.1177/0013124502342006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f96cb4cfc30edaeada36d18336b0e04f9119114\",\"title\":\"Learn\",\"url\":\"https://www.semanticscholar.org/paper/8f96cb4cfc30edaeada36d18336b0e04f9119114\",\"venue\":\"\",\"year\":2002},{\"arxivId\":\"1802.09932\",\"authors\":[{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"12477386\",\"name\":\"Kaiwen Zhou\"},{\"authorId\":\"8424393\",\"name\":\"Hongying Liu\"},{\"authorId\":\"1717691\",\"name\":\"James Cheng\"},{\"authorId\":\"1807998\",\"name\":\"I. Tsang\"},{\"authorId\":\"48571674\",\"name\":\"L. Zhang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"1734497\",\"name\":\"Licheng Jiao\"}],\"doi\":\"10.1109/TKDE.2018.2878765\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6ff0c6ddb503b836aaa4f25a77615ac1fd87935\",\"title\":\"VR-SGD: A Simple Stochastic Variance Reduction Method for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/c6ff0c6ddb503b836aaa4f25a77615ac1fd87935\",\"venue\":\"IEEE Transactions on Knowledge and Data Engineering\",\"year\":2020},{\"arxivId\":\"1506.07512\",\"authors\":[{\"authorId\":\"34765463\",\"name\":\"Roy Frostig\"},{\"authorId\":\"144804200\",\"name\":\"R. Ge\"},{\"authorId\":\"144695232\",\"name\":\"Sham M. Kakade\"},{\"authorId\":\"2357926\",\"name\":\"Aaron Sidford\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be681f95d2a3636532068f165d7fbf8fa0a301d5\",\"title\":\"Un-regularizing: approximate proximal point and faster stochastic algorithms for empirical risk minimization\",\"url\":\"https://www.semanticscholar.org/paper/be681f95d2a3636532068f165d7fbf8fa0a301d5\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fanhua Shang\"},{\"authorId\":null,\"name\":\"Yuanyuan Liu\"},{\"authorId\":null,\"name\":\"James Cheng\"},{\"authorId\":null,\"name\":\"K. W. Ng\"},{\"authorId\":null,\"name\":\"Yuichi Yoshida. Guaranteed sufficient decrease for stocha optimization\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In AISTATS\",\"url\":\"\",\"venue\":\"pages 1027\\u20131036,\",\"year\":2018},{\"arxivId\":\"1506.01972\",\"authors\":[{\"authorId\":\"13319052\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145155439\",\"name\":\"Y. Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d0b96767d7285b7ce8ecca9715aef9b020fafd9\",\"title\":\"Improved SVRG for Non-Strongly-Convex or Sum-of-Non-Convex Objectives\",\"url\":\"https://www.semanticscholar.org/paper/3d0b96767d7285b7ce8ecca9715aef9b020fafd9\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1802.09933\",\"authors\":[{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"1723917\",\"name\":\"Y. Liu\"},{\"authorId\":\"12477386\",\"name\":\"Kaiwen Zhou\"},{\"authorId\":\"1717691\",\"name\":\"James Cheng\"},{\"authorId\":\"35572780\",\"name\":\"Kelvin Kai Wing Ng\"},{\"authorId\":\"51462146\",\"name\":\"Y. Yoshida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45e6723ec935e9c30ccb12da38a1c7ad041332bd\",\"title\":\"Guaranteed Sufficient Decrease for Stochastic Variance Reduced Gradient Optimization\",\"url\":\"https://www.semanticscholar.org/paper/45e6723ec935e9c30ccb12da38a1c7ad041332bd\",\"venue\":\"AISTATS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiwen Zhou\"},{\"authorId\":null,\"name\":\"Fanhua Shang\"},{\"authorId\":null,\"name\":\"James Cheng. A simple stochastic variance reduced algori rates\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 5975\\u20135984,\",\"year\":2018},{\"arxivId\":\"1202.6258\",\"authors\":[{\"authorId\":\"7245737\",\"name\":\"N. Roux\"},{\"authorId\":\"145610994\",\"name\":\"M. Schmidt\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"49ab3776d88ff76612a7738358912db834639177\",\"title\":\"A Stochastic Gradient Method with an Exponential Convergence Rate for Finite Training Sets\",\"url\":\"https://www.semanticscholar.org/paper/49ab3776d88ff76612a7738358912db834639177\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":\"0811.2026\",\"authors\":[{\"authorId\":\"1692950\",\"name\":\"Seyoung Kim\"},{\"authorId\":\"2892216\",\"name\":\"Kyung-Ah Sohn\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1093/bioinformatics/btp218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"094cc86f46aa2520decf59a5d4b0e8755a5e59a7\",\"title\":\"A multivariate regression approach to association analysis of a quantitative trait network\",\"url\":\"https://www.semanticscholar.org/paper/094cc86f46aa2520decf59a5d4b0e8755a5e59a7\",\"venue\":\"Bioinform.\",\"year\":2009},{\"arxivId\":\"1810.03105\",\"authors\":[{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"144125122\",\"name\":\"L. Jiao\"},{\"authorId\":\"12477386\",\"name\":\"Kaiwen Zhou\"},{\"authorId\":\"1717691\",\"name\":\"James Cheng\"},{\"authorId\":\"143756447\",\"name\":\"Yan Ren\"},{\"authorId\":\"48932637\",\"name\":\"Yufei Jin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b7b8010e7220ddcccd5f796b6d1fab4aef0add7\",\"title\":\"ASVRG: Accelerated Proximal SVRG\",\"url\":\"https://www.semanticscholar.org/paper/6b7b8010e7220ddcccd5f796b6d1fab4aef0add7\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":\"1602.02442\",\"authors\":[{\"authorId\":\"34597877\",\"name\":\"Aaron Defazio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"998c3387d98808c9b4f82609c8851e6d57bcfebf\",\"title\":\"A Simple Practical Accelerated Method for Finite Sums\",\"url\":\"https://www.semanticscholar.org/paper/998c3387d98808c9b4f82609c8851e6d57bcfebf\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69999923\",\"name\":\"\\uc7a5\\ubcd1\\ud0c1\"},{\"authorId\":\"65891736\",\"name\":\"\\uae40\\uc0bc\\ubb18\"},{\"authorId\":\"71329699\",\"name\":\"\\ud5c8\\ucca0\\uad6c\"}],\"doi\":\"10.4135/9781412952644.n56\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c17b89bb49201fc3460477e59fc1d1db99b3a08\",\"title\":\"\\u201cBioinformatics\\u201d \\ud2b9\\uc9d1\\uc744 \\ub0b4\\uba74\\uc11c\",\"url\":\"https://www.semanticscholar.org/paper/8c17b89bb49201fc3460477e59fc1d1db99b3a08\",\"venue\":\"\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomoya Murata\"},{\"authorId\":null,\"name\":\"Taiji Suzuki. Doubly accelerated stochastic variance red minimization\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 608\\u2013617,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Atsushi Nitanda. Stochastic proximal gradient descent with techniques\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 1574\\u2013 1582,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rie Johnson\"},{\"authorId\":null,\"name\":\"Tong Zhang. Accelerating stochastic gradient descent us reduction\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 315\\u2013323,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nicolas Le Roux\"},{\"authorId\":null,\"name\":\"Mark Schmidt\"},{\"authorId\":null,\"name\":\"Francis Bach. A stochastic gradient method with an exponen sets\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 2672\\u20132680,\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yuanyuan Liu\"},{\"authorId\":null,\"name\":\"Fanhua Shang\"},{\"authorId\":null,\"name\":\"James Cheng. Accelerated variance reduced stochastic ADMM\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AAAI\",\"url\":\"\",\"venue\":\"pages 2287\\u20132293,\",\"year\":2017},{\"arxivId\":\"1605.08003\",\"authors\":[{\"authorId\":\"32373165\",\"name\":\"Blake E. Woodworth\"},{\"authorId\":\"1706280\",\"name\":\"Nathan Srebro\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"03282fc4d206fde34237bcf85f1765442abbd4c9\",\"title\":\"Tight Complexity Bounds for Optimizing Composite Objectives\",\"url\":\"https://www.semanticscholar.org/paper/03282fc4d206fde34237bcf85f1765442abbd4c9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Le Thi Khanh Hien\"},{\"authorId\":null,\"name\":\"Cuong V. Nguyen\"},{\"authorId\":null,\"name\":\"Huan Xu\"},{\"authorId\":null,\"name\":\"Canyi Lu\"},{\"authorId\":null,\"name\":\"J JiashiFeng.Acceleratedstochasticmirrordescentalgor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Optimiz\",\"url\":\"\",\"venue\":\"Theory App.,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lin Xiao\"},{\"authorId\":null,\"name\":\"Tong Zhang. A proximal stochastic gradient method with reduction\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SIAM J\",\"url\":\"\",\"venue\":\"Optim., 24(4):2057\\u20132075,\",\"year\":2014},{\"arxivId\":\"1806.11048\",\"authors\":[{\"authorId\":\"12477386\",\"name\":\"Kaiwen Zhou\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"db42241da264f67046f9ff1b0c245fbfcc556237\",\"title\":\"Direct Acceleration of SAGA using Sampled Negative Momentum\",\"url\":\"https://www.semanticscholar.org/paper/db42241da264f67046f9ff1b0c245fbfcc556237\",\"venue\":\"AISTATS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aaron Defazio\"},{\"authorId\":null,\"name\":\"Tiberio S. Caetano\"},{\"authorId\":null,\"name\":\"Justin Domke\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Finito: A faster\",\"url\":\"\",\"venue\":\"permutable incremental gradient method for big data problems. In ICML, pages 1125\\u20131133,\",\"year\":2014},{\"arxivId\":\"1806.11027\",\"authors\":[{\"authorId\":\"12477386\",\"name\":\"Kaiwen Zhou\"},{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"1717691\",\"name\":\"James Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f25f9513a86546a22626d6e1ea3b446c8fc994\",\"title\":\"A Simple Stochastic Variance Reduced Algorithm with Fast Convergence Rates\",\"url\":\"https://www.semanticscholar.org/paper/42f25f9513a86546a22626d6e1ea3b446c8fc994\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1703.07948\",\"authors\":[{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"1723917\",\"name\":\"Y. Liu\"},{\"authorId\":\"1717691\",\"name\":\"James Cheng\"},{\"authorId\":\"9924411\",\"name\":\"Jiacheng Zhuo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea130447495efda0b171a9b7ca1dc0baca5bab15\",\"title\":\"Fast Stochastic Variance Reduced Gradient Method with Momentum Acceleration for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/ea130447495efda0b171a9b7ca1dc0baca5bab15\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1403.4699\",\"authors\":[{\"authorId\":\"145942106\",\"name\":\"Lin Xiao\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"}],\"doi\":\"10.1137/140961791\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c92372db9eec502bfe53c3aed0537a9b4147a6e5\",\"title\":\"A Proximal Stochastic Gradient Method with Progressive Variance Reduction\",\"url\":\"https://www.semanticscholar.org/paper/c92372db9eec502bfe53c3aed0537a9b4147a6e5\",\"venue\":\"SIAM J. Optim.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lijun Zhang\"},{\"authorId\":null,\"name\":\"Mehrdad Mahdavi\"},{\"authorId\":null,\"name\":\"Rong Jin. Linear convergence with condition number inde gradients\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 980\\u2013988,\",\"year\":2013},{\"arxivId\":\"1209.1873\",\"authors\":[{\"authorId\":\"1389955537\",\"name\":\"S. Shalev-Shwartz\"},{\"authorId\":\"47593026\",\"name\":\"T. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cdc492d91e5264bdf9b7d87051042c32a19d86e\",\"title\":\"Stochastic dual coordinate ascent methods for regularized loss\",\"url\":\"https://www.semanticscholar.org/paper/1cdc492d91e5264bdf9b7d87051042c32a19d86e\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2013},{\"arxivId\":\"1506.02186\",\"authors\":[{\"authorId\":\"3376305\",\"name\":\"Hongzhou Lin\"},{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"de5064b36b1ba71ac7424cdaf280af5bbdf780c1\",\"title\":\"A Universal Catalyst for First-Order Optimization\",\"url\":\"https://www.semanticscholar.org/paper/de5064b36b1ba71ac7424cdaf280af5bbdf780c1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1707.03190\",\"authors\":[{\"authorId\":\"1723917\",\"name\":\"Y. Liu\"},{\"authorId\":\"3062185\",\"name\":\"F. Shang\"},{\"authorId\":\"1717691\",\"name\":\"James Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3d1cad48c70a3c969c5332a8ae819aa9cd88dc7\",\"title\":\"Accelerated Variance Reduced Stochastic ADMM\",\"url\":\"https://www.semanticscholar.org/paper/e3d1cad48c70a3c969c5332a8ae819aa9cd88dc7\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40204991\",\"name\":\"A. Beck\"},{\"authorId\":\"1727609\",\"name\":\"M. Teboulle\"}],\"doi\":\"10.1137/080716542\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c718363c22221fd16771672da3bfd5f67d2c34c\",\"title\":\"A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems\",\"url\":\"https://www.semanticscholar.org/paper/3c718363c22221fd16771672da3bfd5f67d2c34c\",\"venue\":\"SIAM J. Imaging Sci.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zeyuan Allen-Zhu\"},{\"authorId\":null,\"name\":\"Yang Yuan. Improved SVRG for non-strongly-convex or sum objectives\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 1080\\u20131089,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amir Beck\"},{\"authorId\":null,\"name\":\"Marc Teboulle. A fast iterative shrinkage-thresholding problems\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SIAM J\",\"url\":\"\",\"venue\":\"Imaging Sci., 2(1):183\\u2013202,\",\"year\":2009},{\"arxivId\":\"1407.2710\",\"authors\":[{\"authorId\":\"34597877\",\"name\":\"Aaron Defazio\"},{\"authorId\":\"1722101\",\"name\":\"Justin Domke\"},{\"authorId\":\"70910418\",\"name\":\"T. S. Caetano\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"076ac26625e3fda9aaaf27f0f03426a0423bb188\",\"title\":\"Finito: A faster, permutable incremental gradient method for big data problems\",\"url\":\"https://www.semanticscholar.org/paper/076ac26625e3fda9aaaf27f0f03426a0423bb188\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1407.0202\",\"authors\":[{\"authorId\":\"34597877\",\"name\":\"Aaron Defazio\"},{\"authorId\":\"144570279\",\"name\":\"Francis R. Bach\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4daec165c1f4aa1206b0d91c0b26f0287d1ef52d\",\"title\":\"SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives\",\"url\":\"https://www.semanticscholar.org/paper/4daec165c1f4aa1206b0d91c0b26f0287d1ef52d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hongzhou Lin\"},{\"authorId\":null,\"name\":\"Julien Mairal\"},{\"authorId\":null,\"name\":\"Zaid Harchaoui. A universal catalyst for first-order optimization\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 3366\\u20133374,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1933529\",\"name\":\"Le Thi Khanh Hien\"},{\"authorId\":\"15514007\",\"name\":\"Cuong V Nguyen\"},{\"authorId\":\"46485339\",\"name\":\"Huan Xu\"},{\"authorId\":\"33224509\",\"name\":\"Canyi Lu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c01363a766bb7499ba12302623d564781339081\",\"title\":\"Accelerated Stochastic Mirror Descent Algorithms For Composite Non-strongly Convex Optimization\",\"url\":\"https://www.semanticscholar.org/paper/0c01363a766bb7499ba12302623d564781339081\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1603.05642\",\"authors\":[{\"authorId\":\"13319052\",\"name\":\"Z. Zhu\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bbf543c5b2bab13bb1808c23d2227f0a6416240\",\"title\":\"Optimal Black-Box Reductions Between Optimization Objectives\",\"url\":\"https://www.semanticscholar.org/paper/6bbf543c5b2bab13bb1808c23d2227f0a6416240\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97752732\",\"name\":\"D. Hinkley\"}],\"doi\":\"10.1002/0471667196.ess0046.pub2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c01b5b50d6d082a88bccbf11f539955072a2e2c\",\"title\":\"Annals of Statistics\",\"url\":\"https://www.semanticscholar.org/paper/2c01b5b50d6d082a88bccbf11f539955072a2e2c\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mehrdad Mahdavi\"},{\"authorId\":null,\"name\":\"Lijun Zhang\"},{\"authorId\":null,\"name\":\"Rong Jin. Mixed optimization for smooth functions\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 674\\u2013682,\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2968184\",\"name\":\"R. Johnson\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c05444fbc239321f6676f3cd539cac34fde7b8\",\"title\":\"Accelerating Stochastic Gradient Descent using Predictive Variance Reduction\",\"url\":\"https://www.semanticscholar.org/paper/43c05444fbc239321f6676f3cd539cac34fde7b8\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1703.00439\",\"authors\":[{\"authorId\":\"3047922\",\"name\":\"T. Murata\"},{\"authorId\":\"40617873\",\"name\":\"T. Suzuki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e5ed4d49357089f2b8c51a4ba83c0c81de9eda1\",\"title\":\"Doubly Accelerated Stochastic Variance Reduced Dual Averaging Method for Regularized Empirical Risk Minimization\",\"url\":\"https://www.semanticscholar.org/paper/2e5ed4d49357089f2b8c51a4ba83c0c81de9eda1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39738194\",\"name\":\"L. Zhang\"},{\"authorId\":\"1694826\",\"name\":\"M. Mahdavi\"},{\"authorId\":\"144723884\",\"name\":\"Rong Jin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4794596da548a2e62c28911c0d0224fbdf330622\",\"title\":\"Linear Convergence with Condition Number Independent Access of Full Gradients\",\"url\":\"https://www.semanticscholar.org/paper/4794596da548a2e62c28911c0d0224fbdf330622\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aaron Defazio. A simple practical accelerated method for sums\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 676\\u2013684,\",\"year\":2016}],\"title\":\"Accelerated Incremental Gradient Descent using Momentum Acceleration with Scaling Factor\",\"topics\":[{\"topic\":\"Stochastic gradient descent\",\"topicId\":\"202796\",\"url\":\"https://www.semanticscholar.org/topic/202796\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"}],\"url\":\"https://www.semanticscholar.org/paper/4f9692725b69ee24933bb775c54c6cdc85265505\",\"venue\":\"IJCAI\",\"year\":2019}\n"