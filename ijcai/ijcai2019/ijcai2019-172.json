"{\"abstract\":\"Recently, Evolution Strategies (ES) have been successfully applied to solve problems commonly addressed by reinforcement learning (RL). Due to the simplicity of ES approaches, their runtime is often dominated by the RL-task at hand (e.g., playing a game). In this work, we introduce Progressive Episode Lengths (PEL) as a new technique and incorporate it with ES. The main objective is to allow the agent to play short and easy tasks with limited lengths, and then use the gained knowledge to further solve long and hard tasks with progressive lengths. Hence allowing the agent to perform many function evaluations and find a good solution for short time horizons before adapting the strategy to tackle larger time horizons. We evaluated PEL on a subset of Atari games from OpenAI Gym, showing that it can substantially improve the optimization speed, stability and final score of canonical ES. Specifically, we show average improvements of 80% (32%) after 2 hours (10 hours) compared to canonical ES.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"151494070\",\"name\":\"Lior Fuks\",\"url\":\"https://www.semanticscholar.org/author/151494070\"},{\"authorId\":\"3461721\",\"name\":\"Noor Awad\",\"url\":\"https://www.semanticscholar.org/author/3461721\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\",\"url\":\"https://www.semanticscholar.org/author/144661829\"},{\"authorId\":\"145963266\",\"name\":\"M. Lindauer\",\"url\":\"https://www.semanticscholar.org/author/145963266\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"35793119\",\"name\":\"Gresa Shala\"},{\"authorId\":\"146024084\",\"name\":\"Andr\\u00e9 Biedenkapp\"},{\"authorId\":\"3461721\",\"name\":\"Noor Awad\"},{\"authorId\":\"2278843\",\"name\":\"S. Adriaensen\"},{\"authorId\":\"145963266\",\"name\":\"M. Lindauer\"},{\"authorId\":\"1702307574\",\"name\":\"Frank Hutter\"}],\"doi\":\"10.1007/978-3-030-58112-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7353e4bcfef04d1c103a4559f569b3a964b48bc5\",\"title\":\"Learning Step-Size Adaptation in CMA-ES\",\"url\":\"https://www.semanticscholar.org/paper/7353e4bcfef04d1c103a4559f569b3a964b48bc5\",\"venue\":\"PPSN\",\"year\":2020}],\"corpusId\":199466462,\"doi\":\"10.24963/ijcai.2019/172\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"0dbf2d2c05e1955fbcf3461def336224cc68ce1f\",\"references\":[{\"arxivId\":\"1603.06560\",\"authors\":[{\"authorId\":\"8446798\",\"name\":\"L. Li\"},{\"authorId\":\"40566417\",\"name\":\"K. Jamieson\"},{\"authorId\":\"3186812\",\"name\":\"G. DeSalvo\"},{\"authorId\":\"2435268\",\"name\":\"Afshin Rostamizadeh\"},{\"authorId\":\"145532827\",\"name\":\"Ameet Talwalkar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"892f9a2f69241feec647856cd26bed37e04fd747\",\"title\":\"Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization\",\"url\":\"https://www.semanticscholar.org/paper/892f9a2f69241feec647856cd26bed37e04fd747\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"144108062\",\"name\":\"Jasper Snoek\"},{\"authorId\":\"1722180\",\"name\":\"R. Adams\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d08d5f5aa142d6c44336cbed286d6c40ca6f5bf0\",\"title\":\"Multi-Task Bayesian Optimization\",\"url\":\"https://www.semanticscholar.org/paper/d08d5f5aa142d6c44336cbed286d6c40ca6f5bf0\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1802.08842\",\"authors\":[{\"authorId\":\"22259392\",\"name\":\"P. Chrabaszcz\"},{\"authorId\":\"1678656\",\"name\":\"I. Loshchilov\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":\"10.24963/ijcai.2018/197\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19af387c0ee32929b54ff45656129a721a84c192\",\"title\":\"Back to Basics: Benchmarking Canonical Evolution Strategies for Playing Atari\",\"url\":\"https://www.semanticscholar.org/paper/19af387c0ee32929b54ff45656129a721a84c192\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386660\",\"name\":\"Zohar S. Karnin\"},{\"authorId\":\"1711492\",\"name\":\"T. Koren\"},{\"authorId\":\"1765862\",\"name\":\"O. Somekh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43e0414b3cb52369c0ffece6eb043d0717776e92\",\"title\":\"Almost Optimal Exploration in Multi-Armed Bandits\",\"url\":\"https://www.semanticscholar.org/paper/43e0414b3cb52369c0ffece6eb043d0717776e92\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144678068\",\"name\":\"G. J. LaPorte\"},{\"authorId\":\"51977809\",\"name\":\"J. Branke\"},{\"authorId\":\"48240034\",\"name\":\"C. Chen\"}],\"doi\":\"10.1162/EVCO_a_00136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee40a2431e70b7d39d0d07f4e25afb648ccb5229\",\"title\":\"Adaptive Parent Population Sizing in Evolution Strategies\",\"url\":\"https://www.semanticscholar.org/paper/ee40a2431e70b7d39d0d07f4e25afb648ccb5229\",\"venue\":\"Evolutionary Computation\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48890329\",\"name\":\"G. Miller\"},{\"authorId\":\"14024873\",\"name\":\"P. Todd\"},{\"authorId\":\"1983880\",\"name\":\"S. Hegde\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e89cb97bc83badf8c6cc0e2439ee4a035cba72d9\",\"title\":\"Designing Neural Networks using Genetic Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/e89cb97bc83badf8c6cc0e2439ee4a035cba72d9\",\"venue\":\"ICGA\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Salimans\"},{\"authorId\":null,\"name\":\"J. Ho\"},{\"authorId\":null,\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"and S\",\"url\":\"\",\"venue\":\"Sidor amd I. Sutskever. Evolution strategies as a scalable alternative to reinforcement learning. arXiv:1703.03864 [stat.ML]\",\"year\":2017},{\"arxivId\":\"1703.01041\",\"authors\":[{\"authorId\":\"2892780\",\"name\":\"E. Real\"},{\"authorId\":\"144375552\",\"name\":\"Sherry Moore\"},{\"authorId\":\"1714992\",\"name\":\"A. Selle\"},{\"authorId\":\"48218655\",\"name\":\"Saurabh Saxena\"},{\"authorId\":\"1412638497\",\"name\":\"Yutaka Leon Suematsu\"},{\"authorId\":\"21799852\",\"name\":\"J. Tan\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f108b65fe0003e387e1cd7e50f537af0531818e4\",\"title\":\"Large-Scale Evolution of Image Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/f108b65fe0003e387e1cd7e50f537af0531818e4\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1712.06567\",\"authors\":[{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"8309711\",\"name\":\"V. Madhavan\"},{\"authorId\":\"32577240\",\"name\":\"Edoardo Conti\"},{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba3ace39f1f1afb6651ef4c0e4b8317fd9d48fcf\",\"title\":\"Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ba3ace39f1f1afb6651ef4c0e4b8317fd9d48fcf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69040387\",\"name\":\"I. Rechenberg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d04942a086f9cafbb1c6453b64ba188beeb03823\",\"title\":\"Evolutionsstrategie : Optimierung technischer Systeme nach Prinzipien der biologischen Evolution\",\"url\":\"https://www.semanticscholar.org/paper/d04942a086f9cafbb1c6453b64ba188beeb03823\",\"venue\":\"\",\"year\":1973},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20616732\",\"name\":\"Andreas Precht Poulsen\"},{\"authorId\":\"20566917\",\"name\":\"Mark Thorhauge\"},{\"authorId\":\"16294621\",\"name\":\"Mikkel Hvilshj Funch\"},{\"authorId\":\"1745664\",\"name\":\"S. Risi\"}],\"doi\":\"10.1109/CIG.2017.8080444\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71088fd8339437bfa482fd6979e7ba03bdebb660\",\"title\":\"DLNE: A hybridization of deep learning and neuroevolution for visual control\",\"url\":\"https://www.semanticscholar.org/paper/71088fd8339437bfa482fd6979e7ba03bdebb660\",\"venue\":\"2017 IEEE Conference on Computational Intelligence and Games (CIG)\",\"year\":2017},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737999\",\"name\":\"S. Narvekar\"}],\"doi\":\"10.24963/ijcai.2017/757\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8e2c45367820406c65e9ebe26d598054a1996f28\",\"title\":\"Curriculum Learning in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8e2c45367820406c65e9ebe26d598054a1996f28\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1606.03498\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"571b0750085ae3d939525e62af510ee2cee9d5ea\",\"title\":\"Improved Techniques for Training GANs\",\"url\":\"https://www.semanticscholar.org/paper/571b0750085ae3d939525e62af510ee2cee9d5ea\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2449382\",\"name\":\"T. Hubert\"},{\"authorId\":\"144522726\",\"name\":\"L. Baker\"},{\"authorId\":\"40227832\",\"name\":\"Matthew Lai\"},{\"authorId\":\"34848283\",\"name\":\"A. Bolton\"},{\"authorId\":\"1519062204\",\"name\":\"Yutian Chen\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"88791868\",\"name\":\"F. Hui\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature24270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c27db32efa8137cbf654902f8f728f338e55cd1c\",\"title\":\"Mastering the game of Go without human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c27db32efa8137cbf654902f8f728f338e55cd1c\",\"venue\":\"Nature\",\"year\":2017},{\"arxivId\":\"1511.07289\",\"authors\":[{\"authorId\":\"34917892\",\"name\":\"Djork-Arn\\u00e9 Clevert\"},{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f63e917638553414526a0cc8550de4ad2d83fe7a\",\"title\":\"Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)\",\"url\":\"https://www.semanticscholar.org/paper/f63e917638553414526a0cc8550de4ad2d83fe7a\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"},{\"authorId\":\"46317290\",\"name\":\"Qian Zhao\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21d255246cd7ddba24a651fd716950f893ea8eb2\",\"title\":\"Self-Paced Curriculum Learning\",\"url\":\"https://www.semanticscholar.org/paper/21d255246cd7ddba24a651fd716950f893ea8eb2\",\"venue\":\"AAAI\",\"year\":2015},{\"arxivId\":\"1707.03902\",\"authors\":[{\"authorId\":\"22255447\",\"name\":\"Samuel Alvernaz\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":\"10.1109/CIG.2017.8080408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60710f275494da521426a8c1af952b4451e062e2\",\"title\":\"Autoencoder-augmented neuroevolution for visual doom playing\",\"url\":\"https://www.semanticscholar.org/paper/60710f275494da521426a8c1af952b4451e062e2\",\"venue\":\"2017 IEEE Conference on Computational Intelligence and Games (CIG)\",\"year\":2017},{\"arxivId\":\"1712.06560\",\"authors\":[{\"authorId\":\"32577240\",\"name\":\"Edoardo Conti\"},{\"authorId\":\"8309711\",\"name\":\"V. Madhavan\"},{\"authorId\":\"9927844\",\"name\":\"Felipe Petroski Such\"},{\"authorId\":\"39799304\",\"name\":\"Joel Lehman\"},{\"authorId\":\"1846883\",\"name\":\"K. Stanley\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2064020586d5832b55f80a7dffea1fd90a5d94dd\",\"title\":\"Improving Exploration in Evolution Strategies for Deep Reinforcement Learning via a Population of Novelty-Seeking Agents\",\"url\":\"https://www.semanticscholar.org/paper/2064020586d5832b55f80a7dffea1fd90a5d94dd\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553380\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8de174ab5419b9d3127695405efd079808e956e8\",\"title\":\"Curriculum learning\",\"url\":\"https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1410.7326\",\"authors\":[{\"authorId\":\"1745664\",\"name\":\"S. Risi\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":\"10.1109/TCIAIG.2015.2494596\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3f7cfe0129d7b06ea0e5b15894ba3b8bb3f57bed\",\"title\":\"Neuroevolution in Games: State of the Art and Open Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3f7cfe0129d7b06ea0e5b15894ba3b8bb3f57bed\",\"venue\":\"IEEE Transactions on Computational Intelligence and AI in Games\",\"year\":2017},{\"arxivId\":\"1106.4487\",\"authors\":[{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"},{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1109/CEC.2008.4631255\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"dd5cf95a7af93d2733120d177c593989b19b98fe\",\"title\":\"Natural Evolution Strategies\",\"url\":\"https://www.semanticscholar.org/paper/dd5cf95a7af93d2733120d177c593989b19b98fe\",\"venue\":\"2008 IEEE Congress on Evolutionary Computation (IEEE World Congress on Computational Intelligence)\",\"year\":2008},{\"arxivId\":\"1606.01540\",\"authors\":[{\"authorId\":\"49508975\",\"name\":\"G. Brockman\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"152877508\",\"name\":\"Ludwig Pettersson\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143805717\",\"name\":\"Jie Tang\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"title\":\"OpenAI Gym\",\"url\":\"https://www.semanticscholar.org/paper/ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1803.00657\",\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143901532\",\"name\":\"X. Yao\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TEVC.2019.2895748\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbca46c24c800bee41b21ac0258651db54892e80\",\"title\":\"Evolutionary Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/cbca46c24c800bee41b21ac0258651db54892e80\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1807.01774\",\"authors\":[{\"authorId\":\"2154062\",\"name\":\"Stefan Falkner\"},{\"authorId\":\"145227684\",\"name\":\"A. Klein\"},{\"authorId\":\"144661829\",\"name\":\"F. Hutter\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93436a26d744e0417e21df10abdfce2cc74b1e58\",\"title\":\"BOHB: Robust and Efficient Hyperparameter Optimization at Scale\",\"url\":\"https://www.semanticscholar.org/paper/93436a26d744e0417e21df10abdfce2cc74b1e58\",\"venue\":\"ICML\",\"year\":2018}],\"title\":\"An Evolution Strategy with Progressive Episode Lengths for Playing Games\",\"topics\":[{\"topic\":\"Evolution strategy\",\"topicId\":\"64343\",\"url\":\"https://www.semanticscholar.org/topic/64343\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Half-Life 2: Episode Two\",\"topicId\":\"3324159\",\"url\":\"https://www.semanticscholar.org/topic/3324159\"},{\"topic\":\"Atari\",\"topicId\":\"20108\",\"url\":\"https://www.semanticscholar.org/topic/20108\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Progressive scan\",\"topicId\":\"130045\",\"url\":\"https://www.semanticscholar.org/topic/130045\"}],\"url\":\"https://www.semanticscholar.org/paper/0dbf2d2c05e1955fbcf3461def336224cc68ce1f\",\"venue\":\"IJCAI\",\"year\":2019}\n"