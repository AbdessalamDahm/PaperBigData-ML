"{\"abstract\":\"The rapid pace of recent research in AI has been driven in part by the presence of fast and challenging simulation environments. These environments often take the form of games; with tasks ranging from simple board games, to competitive video games. We propose a new benchmark - Obstacle Tower: a high fidelity, 3D, 3rd person, procedurally generated environment. An agent playing Obstacle Tower must learn to solve both low-level control and high-level planning problems in tandem while learning from pixels and a sparse reward signal. Unlike other benchmarks such as the Arcade Learning Environment, evaluation of agent performance in Obstacle Tower is based on an agent's ability to perform well on unseen instances of the environment. In this paper we outline the environment and provide a set of baseline results produced by current state-of-the-art Deep RL methods as well as human players. These algorithms fail to produce agents capable of performing near human level.\",\"arxivId\":\"1902.01378\",\"authors\":[{\"authorId\":\"7174267\",\"name\":\"Arthur Juliani\",\"url\":\"https://www.semanticscholar.org/author/7174267\"},{\"authorId\":\"38865023\",\"name\":\"Ahmed Khalifa\",\"url\":\"https://www.semanticscholar.org/author/38865023\"},{\"authorId\":\"51266557\",\"name\":\"Vincent-Pierre Berges\",\"url\":\"https://www.semanticscholar.org/author/51266557\"},{\"authorId\":\"10984391\",\"name\":\"J. Harper\",\"url\":\"https://www.semanticscholar.org/author/10984391\"},{\"authorId\":\"51450774\",\"name\":\"Hunter Henry\",\"url\":\"https://www.semanticscholar.org/author/51450774\"},{\"authorId\":\"68973547\",\"name\":\"Adam Crespi\",\"url\":\"https://www.semanticscholar.org/author/68973547\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\",\"url\":\"https://www.semanticscholar.org/author/1810053\"},{\"authorId\":\"51438954\",\"name\":\"D. Lange\",\"url\":\"https://www.semanticscholar.org/author/51438954\"}],\"citationVelocity\":20,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381490900\",\"name\":\"Viviane Clay\"},{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"},{\"authorId\":\"113146087\",\"name\":\"Kai-Uwe K\\u00fchnberger\"},{\"authorId\":\"1734512\",\"name\":\"G. Pipa\"}],\"doi\":\"10.1016/j.neunet.2020.11.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4842f6d9ccb0f97c6d3bac1c204aea80bdec5274\",\"title\":\"Learning sparse and meaningful representations through embodiment.\",\"url\":\"https://www.semanticscholar.org/paper/4842f6d9ccb0f97c6d3bac1c204aea80bdec5274\",\"venue\":\"Neural networks : the official journal of the International Neural Network Society\",\"year\":2020},{\"arxivId\":\"2004.00980\",\"authors\":[{\"authorId\":\"3469155\",\"name\":\"Anssi Kanervisto\"},{\"authorId\":\"49315290\",\"name\":\"C. Scheller\"},{\"authorId\":\"1968243\",\"name\":\"Ville Hautam\\u00e4ki\"}],\"doi\":\"10.1109/CoG47356.2020.9231687\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3f37a4a4ca3ff3c9a2cc9bae2138db628dd7ecc4\",\"title\":\"Action Space Shaping in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f37a4a4ca3ff3c9a2cc9bae2138db628dd7ecc4\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114416489\",\"name\":\"Josh Roy\"},{\"authorId\":\"1765407\",\"name\":\"G. Konidaris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d957e3ba44b2b9167a737832b82774fef19a6829\",\"title\":\"Visual Transfer for Reinforcement Learning via Wasserstein Confusion\",\"url\":\"https://www.semanticscholar.org/paper/d957e3ba44b2b9167a737832b82774fef19a6829\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.01387\",\"authors\":[{\"authorId\":\"40470211\",\"name\":\"T. Paine\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"2067577\",\"name\":\"B. Shahriari\"},{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"28552618\",\"name\":\"M. Hoffman\"},{\"authorId\":\"2794457\",\"name\":\"Hubert Soyer\"},{\"authorId\":\"1825728\",\"name\":\"Richard Tanburn\"},{\"authorId\":\"67007190\",\"name\":\"Steven Kapturowski\"},{\"authorId\":\"3422052\",\"name\":\"Neil C. Rabinowitz\"},{\"authorId\":\"32540138\",\"name\":\"D.V.J. Williams\"},{\"authorId\":\"1403998955\",\"name\":\"Gabriel Barth-Maron\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"},{\"authorId\":\"1411404253\",\"name\":\"Worlds Team\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"428e2bf31b1e6ef6b5f2e982d39575158bded349\",\"title\":\"Making Efficient Use of Demonstrations to Solve Hard Exploration Problems\",\"url\":\"https://www.semanticscholar.org/paper/428e2bf31b1e6ef6b5f2e982d39575158bded349\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1911.01547\",\"authors\":[{\"authorId\":\"1400521679\",\"name\":\"F. Chollet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"261c25adc19c2d107403913e464ad5520a56a261\",\"title\":\"On the Measure of Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/261c25adc19c2d107403913e464ad5520a56a261\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.07483\",\"authors\":[{\"authorId\":\"102928633\",\"name\":\"Benjamin Beyret\"},{\"authorId\":\"1398777358\",\"name\":\"J. Hern\\u00e1ndez-Orallo\"},{\"authorId\":\"6643500\",\"name\":\"L. Cheke\"},{\"authorId\":\"4626726\",\"name\":\"Marta Halina\"},{\"authorId\":\"1757629\",\"name\":\"M. Shanahan\"},{\"authorId\":\"143966629\",\"name\":\"M. Crosby\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d919ff2808010e0ef6d33c36fc69173b22761c23\",\"title\":\"The Animal-AI Environment: Training and Testing Animal-Like Artificial Cognition\",\"url\":\"https://www.semanticscholar.org/paper/d919ff2808010e0ef6d33c36fc69173b22761c23\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.03532\",\"authors\":[{\"authorId\":\"1392640592\",\"name\":\"Alessandro Sestini\"},{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e181bd818ed5a0ede02ba97c705392567828e60f\",\"title\":\"Deep Policy Networks for NPC Behaviors that Adapt to Changing Design Parameters in Roguelike Games\",\"url\":\"https://www.semanticscholar.org/paper/e181bd818ed5a0ede02ba97c705392567828e60f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381203300\",\"name\":\"Mads Johansen\"},{\"authorId\":\"3000538\",\"name\":\"M. Pichlmair\"},{\"authorId\":\"1745664\",\"name\":\"S. Risi\"}],\"doi\":\"10.1109/CIG.2019.8848072\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8560a37efd38e109140cb8e8bb17993bcb2b6f2f\",\"title\":\"Video Game Description Language Environment for Unity Machine Learning Agents\",\"url\":\"https://www.semanticscholar.org/paper/8560a37efd38e109140cb8e8bb17993bcb2b6f2f\",\"venue\":\"2019 IEEE Conference on Games (CoG)\",\"year\":2019},{\"arxivId\":\"2004.06784\",\"authors\":[{\"authorId\":\"1749837\",\"name\":\"Eugene Charniak\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"57e03307e6a4f69dbe410957e7661b783d75de47\",\"title\":\"Extrapolation in Gridworld Markov-Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/57e03307e6a4f69dbe410957e7661b783d75de47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11174\",\"authors\":[{\"authorId\":\"144194990\",\"name\":\"Corban G. Rivera\"},{\"authorId\":\"30858741\",\"name\":\"O. Lyons\"},{\"authorId\":\"1507584875\",\"name\":\"Arielle Summitt\"},{\"authorId\":\"1507562048\",\"name\":\"Ayman Fatima\"},{\"authorId\":\"81429190\",\"name\":\"J. Pak\"},{\"authorId\":\"1507105219\",\"name\":\"William Shao\"},{\"authorId\":\"48390727\",\"name\":\"R. Chalmers\"},{\"authorId\":\"1507558094\",\"name\":\"Aryeh Englander\"},{\"authorId\":\"51487859\",\"name\":\"Edward W. Staley\"},{\"authorId\":\"144645861\",\"name\":\"I. Wang\"},{\"authorId\":\"2742856\",\"name\":\"Ashley J. Llorens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6579cd5a7a0dabc738d6845ac94f684626dccc4\",\"title\":\"TanksWorld: A Multi-Agent Environment for AI Safety Research\",\"url\":\"https://www.semanticscholar.org/paper/c6579cd5a7a0dabc738d6845ac94f684626dccc4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51509387\",\"name\":\"Noga H. Rotman\"},{\"authorId\":\"1718880\",\"name\":\"M. Schapira\"},{\"authorId\":\"3025260\",\"name\":\"A. Tamar\"}],\"doi\":\"10.1145/3422604.3425940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8bf8f69b35c240d25748b0b9d774f3479de02b\",\"title\":\"Online Safety Assurance for Learning-Augmented Systems\",\"url\":\"https://www.semanticscholar.org/paper/0d8bf8f69b35c240d25748b0b9d774f3479de02b\",\"venue\":\"HotNets\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144719340\",\"name\":\"J. Peters\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f26a89180b9bf2f58b8647ea30580fed0ee3ff28\",\"title\":\"Proximal Policy Optimization with Explicit Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/f26a89180b9bf2f58b8647ea30580fed0ee3ff28\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.08129\",\"authors\":[{\"authorId\":\"102469604\",\"name\":\"Yuji Kanagawa\"},{\"authorId\":\"48999027\",\"name\":\"Tomoyuki Kaneko\"}],\"doi\":\"10.1109/CIG.2019.8848075\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9cde9bffc786b8150c4bf3c9a8ac47458e4965b0\",\"title\":\"Rogue-Gym: A New Challenge for Generalization in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/9cde9bffc786b8150c4bf3c9a8ac47458e4965b0\",\"venue\":\"2019 IEEE Conference on Games (CoG)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745664\",\"name\":\"S. Risi\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b8a788d3c748bd51283b4fae6d3b9de7976c171\",\"title\":\"Procedural Content Generation: From Automatically Generating Game Levels to Increasing Generality in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/5b8a788d3c748bd51283b4fae6d3b9de7976c171\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381490900\",\"name\":\"Viviane Clay\"},{\"authorId\":\"144027562\",\"name\":\"P. K\\u00f6nig\"},{\"authorId\":\"113146087\",\"name\":\"Kai-Uwe K\\u00fchnberger\"},{\"authorId\":\"1734512\",\"name\":\"G. Pipa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a4f27ad663908e80a305a2bae15945878a49825\",\"title\":\"Learning Semantically Meaningful Representations Through Embodiment\",\"url\":\"https://www.semanticscholar.org/paper/8a4f27ad663908e80a305a2bae15945878a49825\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.11633\",\"authors\":[{\"authorId\":\"36045639\",\"name\":\"Maciek Chociej\"},{\"authorId\":\"2930640\",\"name\":\"P. Welinder\"},{\"authorId\":\"2617057\",\"name\":\"Lilian Weng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e9903120f6e138473fdcb52a977698c08b672be7\",\"title\":\"ORRB - OpenAI Remote Rendering Backend\",\"url\":\"https://www.semanticscholar.org/paper/e9903120f6e138473fdcb52a977698c08b672be7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.01914\",\"authors\":[{\"authorId\":\"1392640592\",\"name\":\"Alessandro Sestini\"},{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3edda9dff4106c4ac16be6f7dedce1a64ad760ea\",\"title\":\"DeepCrawl: Deep Reinforcement Learning for Turn-based Strategy Games\",\"url\":\"https://www.semanticscholar.org/paper/3edda9dff4106c4ac16be6f7dedce1a64ad760ea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05598\",\"authors\":[{\"authorId\":\"1500654996\",\"name\":\"Aske Plaat\"},{\"authorId\":\"1680388\",\"name\":\"W. Kosters\"},{\"authorId\":\"1491612558\",\"name\":\"Mike Preuss\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4d9298ab1af6bb3af8cb4f60a6642fbc2e17f5\",\"title\":\"Deep Model-Based Reinforcement Learning for High-Dimensional Problems, a Survey\",\"url\":\"https://www.semanticscholar.org/paper/6d4d9298ab1af6bb3af8cb4f60a6642fbc2e17f5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ryan Julian\"},{\"authorId\":null,\"name\":\"K. R. Zentner\"},{\"authorId\":null,\"name\":\"Avnish Narayan\"},{\"authorId\":null,\"name\":\"Tsan Kwong Wong\"},{\"authorId\":null,\"name\":\"Yonghyun Cho\"},{\"authorId\":null,\"name\":\"Keren Zhu\"},{\"authorId\":null,\"name\":\"Linda Wong\"},{\"authorId\":null,\"name\":\"Chang Su\"},{\"authorId\":null,\"name\":\"Zhanpeng He\"},{\"authorId\":null,\"name\":\"Karol Hausman\"},{\"authorId\":null,\"name\":\"Gaurav S. Sukhatme\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3e4c634d35eaee493f37a2129e47756b4f9f9aa\",\"title\":\"Demystifying Reproducibility in Meta- and Multi-Task Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a3e4c634d35eaee493f37a2129e47756b4f9f9aa\",\"venue\":\"ICML 2020\",\"year\":2020},{\"arxivId\":\"2003.08165\",\"authors\":[{\"authorId\":\"48066360\",\"name\":\"Yujin Tang\"},{\"authorId\":\"49141627\",\"name\":\"D. Nguyen\"},{\"authorId\":\"1389041357\",\"name\":\"David Ha\"}],\"doi\":\"10.1145/3377930.3389847\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cf62055fa0faab9c325f4b30415f5b0dc285434\",\"title\":\"Neuroevolution of self-interpretable agents\",\"url\":\"https://www.semanticscholar.org/paper/8cf62055fa0faab9c325f4b30415f5b0dc285434\",\"venue\":\"GECCO\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146372255\",\"name\":\"Caglar Gulcehre\"},{\"authorId\":\"145757538\",\"name\":\"T. L. Paine\"},{\"authorId\":\"2067577\",\"name\":\"B. Shahriari\"},{\"authorId\":\"1715051\",\"name\":\"Misha Denil\"},{\"authorId\":\"49491006\",\"name\":\"Matt Hoffman\"},{\"authorId\":\"2794457\",\"name\":\"Hubert Soyer\"},{\"authorId\":\"1825728\",\"name\":\"Richard Tanburn\"},{\"authorId\":\"67007190\",\"name\":\"Steven Kapturowski\"},{\"authorId\":\"3422052\",\"name\":\"Neil C. Rabinowitz\"},{\"authorId\":\"32540138\",\"name\":\"D.V.J. Williams\"},{\"authorId\":\"1403998955\",\"name\":\"Gabriel Barth-Maron\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e3261603c4278d782736bb5b6156fb232a51ec69\",\"title\":\"SOLVE HARD EXPLORATION PROBLEMS\",\"url\":\"https://www.semanticscholar.org/paper/e3261603c4278d782736bb5b6156fb232a51ec69\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482480310\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"103368444\",\"name\":\"K. Tuyls\"},{\"authorId\":\"49281458\",\"name\":\"W. Czarnecki\"},{\"authorId\":\"145955154\",\"name\":\"F. C. Santos\"},{\"authorId\":\"144845452\",\"name\":\"M. Rowland\"},{\"authorId\":\"41208936\",\"name\":\"J. Connor\"},{\"authorId\":\"1897926\",\"name\":\"D. Hennes\"},{\"authorId\":\"31633968\",\"name\":\"P. Muller\"},{\"authorId\":\"3422031\",\"name\":\"Julien P\\u00e9rolat\"},{\"authorId\":\"1419267454\",\"name\":\"Bart De Vylder\"},{\"authorId\":\"2203658\",\"name\":\"A. Gruslys\"},{\"authorId\":\"49274028\",\"name\":\"R. Munos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27cd7f52863cca75518b199a0696bc855753d56d\",\"title\":\"Navigating the Landscape of Multiplayer Games to Probe the Drosophila of AI\",\"url\":\"https://www.semanticscholar.org/paper/27cd7f52863cca75518b199a0696bc855753d56d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.07780\",\"authors\":[{\"authorId\":\"1949747\",\"name\":\"Robert Geirhos\"},{\"authorId\":\"134172524\",\"name\":\"Jorn-Henrik Jacobsen\"},{\"authorId\":\"40899528\",\"name\":\"Claudio Michaelis\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"1924112\",\"name\":\"Felix Wichmann\"}],\"doi\":\"10.1038/s42256-020-00257-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f9826db03c83a069d9d0c939d8b539b2dfd4a94\",\"title\":\"Shortcut Learning in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8f9826db03c83a069d9d0c939d8b539b2dfd4a94\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00567\",\"authors\":[{\"authorId\":\"1392512187\",\"name\":\"Marco Pleines\"},{\"authorId\":\"2191688\",\"name\":\"J. Jitsev\"},{\"authorId\":\"1491612558\",\"name\":\"Mike Preuss\"},{\"authorId\":\"144084779\",\"name\":\"F. Zimmer\"}],\"doi\":\"10.1109/CoG47356.2020.9231802\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a69a3186633f03ff49939dcfdb14aff71fa9f180\",\"title\":\"Obstacle Tower Without Human Demonstrations: How Far a Deep Feed-Forward Network Goes with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a69a3186633f03ff49939dcfdb14aff71fa9f180\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143966629\",\"name\":\"M. Crosby\"}],\"doi\":\"10.1007/s11023-020-09535-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5a17f43fc2d15b1be12bd3120024062b61c1993\",\"title\":\"Building Thinking Machines by Solving Animal Cognition Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a5a17f43fc2d15b1be12bd3120024062b61c1993\",\"venue\":\"Minds and Machines\",\"year\":2020},{\"arxivId\":\"2005.01642\",\"authors\":[{\"authorId\":\"2008186335\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"103368444\",\"name\":\"K. Tuyls\"},{\"authorId\":\"49281458\",\"name\":\"W. Czarnecki\"},{\"authorId\":\"145955156\",\"name\":\"F. Santos\"},{\"authorId\":\"144845447\",\"name\":\"M. Rowland\"},{\"authorId\":\"2007915382\",\"name\":\"Jerome Connor\"},{\"authorId\":\"2008182142\",\"name\":\"Daniel Hennes\"},{\"authorId\":\"2008186474\",\"name\":\"Paul Muller\"},{\"authorId\":\"3422031\",\"name\":\"Julien P\\u00e9rolat\"},{\"authorId\":\"1419267454\",\"name\":\"Bart De Vylder\"},{\"authorId\":\"2008191044\",\"name\":\"Audrunas Gruslys\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"}],\"doi\":\"10.1038/s41467-020-19244-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca1ea3122d216a7a74b440468ad7a510af7376b3\",\"title\":\"Navigating the landscape of multiplayer games\",\"url\":\"https://www.semanticscholar.org/paper/ca1ea3122d216a7a74b440468ad7a510af7376b3\",\"venue\":\"Nature communications\",\"year\":2020},{\"arxivId\":\"1912.01588\",\"authors\":[{\"authorId\":\"6062736\",\"name\":\"K. Cobbe\"},{\"authorId\":\"144239765\",\"name\":\"Christopher Hesse\"},{\"authorId\":\"144890163\",\"name\":\"J. Hilton\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e34e130afc6593882e5b762964f5484cef425c22\",\"title\":\"Leveraging Procedural Generation to Benchmark Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e34e130afc6593882e5b762964f5484cef425c22\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2010.06740\",\"authors\":[{\"authorId\":\"1829303908\",\"name\":\"Jake Grigsby\"},{\"authorId\":\"121817403\",\"name\":\"Yanjun Qi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a21468a3db132fb674eb15406894bf5d9adf3b68\",\"title\":\"Measuring Visual Generalization in Continuous Control from Pixels\",\"url\":\"https://www.semanticscholar.org/paper/a21468a3db132fb674eb15406894bf5d9adf3b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392512187\",\"name\":\"Marco Pleines\"},{\"authorId\":\"48235092\",\"name\":\"F. Zimmer\"},{\"authorId\":\"51266557\",\"name\":\"Vincent-Pierre Berges\"}],\"doi\":\"10.1109/CIG.2019.8848080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b9f19902968e890d65e8bdcc39ba1a3a564cc9a\",\"title\":\"Action Spaces in Deep Reinforcement Learning to Mimic Human Input Devices\",\"url\":\"https://www.semanticscholar.org/paper/3b9f19902968e890d65e8bdcc39ba1a3a564cc9a\",\"venue\":\"2019 IEEE Conference on Games (CoG)\",\"year\":2019},{\"arxivId\":\"1909.07750\",\"authors\":[{\"authorId\":\"72592969\",\"name\":\"R. Rajan\"},{\"authorId\":\"1992922723\",\"name\":\"Jessica D\\u00edaz\"},{\"authorId\":\"1992924482\",\"name\":\"Suresh Guttikonda\"},{\"authorId\":\"1702788\",\"name\":\"F. Ferreira\"},{\"authorId\":\"9572390\",\"name\":\"Andre' Biedenkapp\"},{\"authorId\":\"1702307574\",\"name\":\"Frank Hutter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5e782a1896ec8c005ca94db42a4ffec0327a334\",\"title\":\"MDP Playground: Controlling Dimensions of Hardness in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5e782a1896ec8c005ca94db42a4ffec0327a334\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.03465\",\"authors\":[{\"authorId\":\"114416489\",\"name\":\"Josh Roy\"},{\"authorId\":\"1765407\",\"name\":\"G. Konidaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca96857a584bab75c5bf8225357a6197fb5892b3\",\"title\":\"Visual Transfer for Reinforcement Learning via Wasserstein Domain Confusion\",\"url\":\"https://www.semanticscholar.org/paper/ca96857a584bab75c5bf8225357a6197fb5892b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.12911\",\"authors\":[{\"authorId\":\"27550002\",\"name\":\"M. Igl\"},{\"authorId\":\"2474449\",\"name\":\"K. Ciosek\"},{\"authorId\":\"30962601\",\"name\":\"Yingzhen Li\"},{\"authorId\":\"3302876\",\"name\":\"Sebastian Tschiatschek\"},{\"authorId\":\"19622056\",\"name\":\"C. Zhang\"},{\"authorId\":\"1693696\",\"name\":\"S. Devlin\"},{\"authorId\":\"1380228856\",\"name\":\"Katja Hofmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3a1a088ef51548264197ed8882f42e0ad73a9b\",\"title\":\"Generalization in Reinforcement Learning with Selective Noise Injection and Information Bottleneck\",\"url\":\"https://www.semanticscholar.org/paper/2c3a1a088ef51548264197ed8882f42e0ad73a9b\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2002.10433\",\"authors\":[{\"authorId\":\"1491612677\",\"name\":\"S. Risi\"},{\"authorId\":\"1491612558\",\"name\":\"Mike Preuss\"}],\"doi\":\"10.1007/s13218-020-00647-w\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"58443bad8ef57c0ce7df9513a66cacfaa8fb2f93\",\"title\":\"From Chess and Atari to StarCraft and Beyond: How Game AI is Driving the World of AI\",\"url\":\"https://www.semanticscholar.org/paper/58443bad8ef57c0ce7df9513a66cacfaa8fb2f93\",\"venue\":\"KI - K\\u00fcnstliche Intelligenz\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143966629\",\"name\":\"M. Crosby\"},{\"authorId\":\"102928633\",\"name\":\"Benjamin Beyret\"},{\"authorId\":\"1757629\",\"name\":\"M. Shanahan\"},{\"authorId\":\"1398777358\",\"name\":\"J. Hern\\u00e1ndez-Orallo\"},{\"authorId\":\"6643500\",\"name\":\"L. Cheke\"},{\"authorId\":\"4626726\",\"name\":\"Marta Halina\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee1ddfc213aace6a82d91dcdebf38528375dd6a5\",\"title\":\"The Animal-AI Testbed and Competition\",\"url\":\"https://www.semanticscholar.org/paper/ee1ddfc213aace6a82d91dcdebf38528375dd6a5\",\"venue\":\"Proceedings of Machine Learning Research\",\"year\":2019},{\"arxivId\":\"2006.13760\",\"authors\":[{\"authorId\":\"103131985\",\"name\":\"Heinrich Kuttler\"},{\"authorId\":\"39683441\",\"name\":\"Nantas Nardelli\"},{\"authorId\":\"143622869\",\"name\":\"Alexander H. Miller\"},{\"authorId\":\"48647153\",\"name\":\"Roberta Raileanu\"},{\"authorId\":\"1387119507\",\"name\":\"Marco Selvatici\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3228f6fc7902b23c26378e59f8c8820412de7f42\",\"title\":\"The NetHack Learning Environment\",\"url\":\"https://www.semanticscholar.org/paper/3228f6fc7902b23c26378e59f8c8820412de7f42\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581909818\",\"name\":\"Predrag Njegovanovi\\u0107\"}],\"doi\":\"10.24867/06be06njegovanovic\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"19bfe234d5155d4159bf062de1b493890ac7870a\",\"title\":\"NAVIGACIJA U TRODIMENZIONALNOM OKRU\\u017dENJU Obstacle Tower UPOTREBOM U\\u010cENJA USLOVLJAVANJEM\",\"url\":\"https://www.semanticscholar.org/paper/19bfe234d5155d4159bf062de1b493890ac7870a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.11247\",\"authors\":[{\"authorId\":\"1390024367\",\"name\":\"Martin Balla\"},{\"authorId\":\"145815031\",\"name\":\"S. Lucas\"},{\"authorId\":\"1389741275\",\"name\":\"Diego P\\u00e9rez-Li\\u00e9bana\"}],\"doi\":\"10.1109/CoG47356.2020.9231530\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1236684409af2735dedfb4d191afe8141baa523b\",\"title\":\"Evaluating Generalisation in General Video Game Playing\",\"url\":\"https://www.semanticscholar.org/paper/1236684409af2735dedfb4d191afe8141baa523b\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":\"2001.09908\",\"authors\":[{\"authorId\":\"144701829\",\"name\":\"C. Ye\"},{\"authorId\":\"143840345\",\"name\":\"A. Khalifa\"},{\"authorId\":\"14171685\",\"name\":\"Philip Bontrager\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":\"10.1109/CoG47356.2020.9231907\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0e625fca0efc079bb523baf1ff78c46ff4916e\",\"title\":\"Rotation, Translation, and Cropping for Zero-Shot Generalization\",\"url\":\"https://www.semanticscholar.org/paper/2d0e625fca0efc079bb523baf1ff78c46ff4916e\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":\"2012.03204\",\"authors\":[{\"authorId\":\"50982491\",\"name\":\"Hangtian Jia\"},{\"authorId\":\"1776850\",\"name\":\"Yujing Hu\"},{\"authorId\":\"2519427\",\"name\":\"Yingfeng Chen\"},{\"authorId\":\"81185915\",\"name\":\"Chunxu Ren\"},{\"authorId\":\"80892810\",\"name\":\"Tangjie Lv\"},{\"authorId\":\"3120655\",\"name\":\"Changjie Fan\"},{\"authorId\":\"1797369\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8922d5cd990903e594bcd4de96c6251361919c70\",\"title\":\"Fever Basketball: A Complex, Flexible, and Asynchronized Sports Game Environment for Multi-agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8922d5cd990903e594bcd4de96c6251361919c70\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12292\",\"authors\":[{\"authorId\":\"48647153\",\"name\":\"Roberta Raileanu\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bebe8ffb0c357ac0c7eea2556f817b03ee22b570\",\"title\":\"RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments\",\"url\":\"https://www.semanticscholar.org/paper/bebe8ffb0c357ac0c7eea2556f817b03ee22b570\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2010.03934\",\"authors\":[{\"authorId\":\"1391012691\",\"name\":\"Minqi Jiang\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e150c4226f5cdaabc7c09229f5f6a71cdfe96ac4\",\"title\":\"Prioritized Level Replay\",\"url\":\"https://www.semanticscholar.org/paper/e150c4226f5cdaabc7c09229f5f6a71cdfe96ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.03625\",\"authors\":[{\"authorId\":\"51509387\",\"name\":\"Noga H. Rotman\"},{\"authorId\":\"48019865\",\"name\":\"M. Schapira\"},{\"authorId\":\"3025260\",\"name\":\"A. Tamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"668c6b9dbf67535653a44bad4d4a80fbd4f6fd4c\",\"title\":\"Online Safety Assurance for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/668c6b9dbf67535653a44bad4d4a80fbd4f6fd4c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14842\",\"authors\":[{\"authorId\":null,\"name\":\"Md Ashaduzzaman Rubel Mondol\"},{\"authorId\":null,\"name\":\"Aishwarya Pothula\"},{\"authorId\":\"143885555\",\"name\":\"D. Park\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76de355ba1c8ce25afa54a29a46c5edf27a2139b\",\"title\":\"Modeling Social Interaction for Baby in Simulated Environment for Developmental Robotics\",\"url\":\"https://www.semanticscholar.org/paper/76de355ba1c8ce25afa54a29a46c5edf27a2139b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.06704\",\"authors\":[{\"authorId\":\"37373648\",\"name\":\"J. Booth\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6018cb158b43649971e1d3537e259bf81660418d\",\"title\":\"PPO Dash: Improving Generalization in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6018cb158b43649971e1d3537e259bf81660418d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.10079\",\"authors\":[{\"authorId\":\"39121861\",\"name\":\"William H. Guss\"},{\"authorId\":\"104300088\",\"name\":\"Cayden Codel\"},{\"authorId\":\"145186674\",\"name\":\"Katja Hofmann\"},{\"authorId\":\"103681415\",\"name\":\"Brandon Houghton\"},{\"authorId\":\"67230338\",\"name\":\"Noburu Kuno\"},{\"authorId\":\"144177520\",\"name\":\"S. Milani\"},{\"authorId\":\"24178944\",\"name\":\"S. Mohanty\"},{\"authorId\":\"2717017\",\"name\":\"Diego Perez Liebana\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"34887814\",\"name\":\"Nicholay Topin\"},{\"authorId\":\"145684307\",\"name\":\"M. Veloso\"},{\"authorId\":\"3414391\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e08789b299e252674873fa898da5e7da67bb703\",\"title\":\"The MineRL Competition on Sample Efficient Reinforcement Learning using Human Priors\",\"url\":\"https://www.semanticscholar.org/paper/8e08789b299e252674873fa898da5e7da67bb703\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.03374\",\"authors\":[{\"authorId\":\"3469155\",\"name\":\"Anssi Kanervisto\"},{\"authorId\":\"5709182\",\"name\":\"J. Karttunen\"},{\"authorId\":\"1968243\",\"name\":\"Ville Hautam\\u00e4ki\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"78099bc51b491b88d46929ad025aa780116474f5\",\"title\":\"Playing Minecraft with Behavioural Cloning\",\"url\":\"https://www.semanticscholar.org/paper/78099bc51b491b88d46929ad025aa780116474f5\",\"venue\":\"Proceedings of Machine Learning Research\",\"year\":2019},{\"arxivId\":\"1911.13071\",\"authors\":[{\"authorId\":\"1491612677\",\"name\":\"S. Risi\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":\"10.1038/s42256-020-0208-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9fc5535180d5f5e0fd14c360a5199be9620a47a\",\"title\":\"Increasing generality in machine learning through procedural content generation\",\"url\":\"https://www.semanticscholar.org/paper/f9fc5535180d5f5e0fd14c360a5199be9620a47a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69571730\",\"name\":\"A. R\\u00e9nyi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2155b8406c02ab46eabf039f1af1538607076087\",\"title\":\"Towards Finding Longer Proofs\",\"url\":\"https://www.semanticscholar.org/paper/2155b8406c02ab46eabf039f1af1538607076087\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.02627\",\"authors\":[{\"authorId\":\"7174267\",\"name\":\"Arthur Juliani\"},{\"authorId\":\"51266557\",\"name\":\"Vincent-Pierre Berges\"},{\"authorId\":\"80170837\",\"name\":\"Esh Vckay\"},{\"authorId\":\"143792910\",\"name\":\"Yuan Gao\"},{\"authorId\":\"51450774\",\"name\":\"Hunter Henry\"},{\"authorId\":\"49354909\",\"name\":\"M. Mattar\"},{\"authorId\":\"51438954\",\"name\":\"D. Lange\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"252482d733d67230843fe99bf60427285f0ad8e8\",\"title\":\"Unity: A General Platform for Intelligent Agents\",\"url\":\"https://www.semanticscholar.org/paper/252482d733d67230843fe99bf60427285f0ad8e8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"932ca5b6a80b91e76dcadd68b7ba2937a67b8376\",\"title\":\"RIDE: REWARDING IMPACT-DRIVEN EXPLORATION\",\"url\":\"https://www.semanticscholar.org/paper/932ca5b6a80b91e76dcadd68b7ba2937a67b8376\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.12574\",\"authors\":[{\"authorId\":\"48404846\",\"name\":\"J. Singh\"},{\"authorId\":\"144436089\",\"name\":\"L. Zheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"217fef0db6253f8cba6021c466eb2a4432f86721\",\"title\":\"Enhanced Scene Specificity with Sparse Dynamic Value Estimation\",\"url\":\"https://www.semanticscholar.org/paper/217fef0db6253f8cba6021c466eb2a4432f86721\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500654996\",\"name\":\"Aske Plaat\"},{\"authorId\":\"1680388\",\"name\":\"W. Kosters\"},{\"authorId\":\"1491612558\",\"name\":\"Mike Preuss\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c777ec0e47d6347e536ef1da4c455873109f2c62\",\"title\":\"Model-Based Deep Reinforcement Learning for High-Dimensional Problems, a Survey\",\"url\":\"https://www.semanticscholar.org/paper/c777ec0e47d6347e536ef1da4c455873109f2c62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145897522\",\"name\":\"J. Rodr\\u00edguez\"},{\"authorId\":\"144631735\",\"name\":\"A. G. Garc\\u00eda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b999bcfd01a7d30047ddcae9ca38bf0d56ef38b\",\"title\":\"Artificial Intelligence for Videogames with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8b999bcfd01a7d30047ddcae9ca38bf0d56ef38b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.11887\",\"authors\":[{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2333223\",\"name\":\"Niru Maheswaranathan\"},{\"authorId\":\"2015991\",\"name\":\"R. Sun\"},{\"authorId\":\"2800357\",\"name\":\"C. D. Freeman\"},{\"authorId\":\"16443937\",\"name\":\"Ben Poole\"},{\"authorId\":\"1407546430\",\"name\":\"Jascha Sohl-Dickstein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"29f0ea85bac900cff280092db4b6e59882f09601\",\"title\":\"Using a thousand optimization tasks to learn hyperparameter search strategies\",\"url\":\"https://www.semanticscholar.org/paper/29f0ea85bac900cff280092db4b6e59882f09601\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12399\",\"authors\":[{\"authorId\":\"67313599\",\"name\":\"Jerry Zikun Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e746715577fb33a931eb8f70abb721e5d0e453eb\",\"title\":\"Reinforcement Learning Generalization with Surprise Minimization\",\"url\":\"https://www.semanticscholar.org/paper/e746715577fb33a931eb8f70abb721e5d0e453eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03328\",\"authors\":[{\"authorId\":\"1643897142\",\"name\":\"Gabriele Libardi\"},{\"authorId\":\"144186698\",\"name\":\"G. D. Fabritiis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8eecd0f095a16fada70cd15f95737ad57a4e0fd4\",\"title\":\"Guided Exploration with Proximal Policy Optimization using a Single Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/8eecd0f095a16fada70cd15f95737ad57a4e0fd4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02527\",\"authors\":[{\"authorId\":\"1392640592\",\"name\":\"Alessandro Sestini\"},{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1db68bc11d41e9368cca873e59aaef54b02fdfb9\",\"title\":\"Demonstration-efficient Inverse Reinforcement Learning in Procedurally Generated Environments\",\"url\":\"https://www.semanticscholar.org/paper/1db68bc11d41e9368cca873e59aaef54b02fdfb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13100\",\"authors\":[{\"authorId\":\"3285258\",\"name\":\"Zsolt Zombori\"},{\"authorId\":\"30879690\",\"name\":\"Adri\\u00e1n Csisz\\u00e1rik\"},{\"authorId\":\"47407464\",\"name\":\"H. Michalewski\"},{\"authorId\":\"1784106\",\"name\":\"C. Kaliszyk\"},{\"authorId\":\"2087993\",\"name\":\"J. Urban\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab4c0ab48734548c4c48fa33c3eeccde415db8f8\",\"title\":\"Towards Finding Longer Proofs\",\"url\":\"https://www.semanticscholar.org/paper/ab4c0ab48734548c4c48fa33c3eeccde415db8f8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.02622\",\"authors\":[{\"authorId\":\"4775967\",\"name\":\"A. Bou\"},{\"authorId\":\"144186698\",\"name\":\"G. D. Fabritiis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5dfbf0f9d1050b7ab6242a5e56001ac2a3db5075\",\"title\":\"NAPPO: Modular and scalable reinforcement learning in pytorch\",\"url\":\"https://www.semanticscholar.org/paper/5dfbf0f9d1050b7ab6242a5e56001ac2a3db5075\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05012\",\"authors\":[{\"authorId\":\"144177520\",\"name\":\"S. Milani\"},{\"authorId\":\"34887814\",\"name\":\"Nicholay Topin\"},{\"authorId\":\"103681415\",\"name\":\"Brandon Houghton\"},{\"authorId\":\"39121861\",\"name\":\"William H. Guss\"},{\"authorId\":\"24178944\",\"name\":\"S. Mohanty\"},{\"authorId\":\"12965493\",\"name\":\"K. Nakata\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1596824164\",\"name\":\"Noboru Sean Kuno\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7fa675a5975dc57402513d950e786f2af7a0b45\",\"title\":\"Retrospective Analysis of the 2019 MineRL Competition on Sample Efficient Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e7fa675a5975dc57402513d950e786f2af7a0b45\",\"venue\":\"Proceedings of Machine Learning Research\",\"year\":2019}],\"corpusId\":59599710,\"doi\":\"10.24963/ijcai.2019/373\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":9,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ec2b345267d69e8b4dca550efcd0948e0352acd9\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ecoffet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Montezuma\\u2019s revenge solved by go-explore, a new algorithm for hard-exploration problems (sets records on pitfall too)\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthew Johnson\"},{\"authorId\":null,\"name\":\"Katja Hofmann\"},{\"authorId\":null,\"name\":\"Tim Hutton\"},{\"authorId\":null,\"name\":\"David Bignell. The malmo platform for artificial intelli experimentation\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 4246\\u20134247,\",\"year\":2016},{\"arxivId\":\"1806.10729\",\"authors\":[{\"authorId\":\"2775866\",\"name\":\"Niels Justesen\"},{\"authorId\":\"15099359\",\"name\":\"R. Torrado\"},{\"authorId\":\"14171685\",\"name\":\"Philip Bontrager\"},{\"authorId\":\"143840345\",\"name\":\"A. Khalifa\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"1745664\",\"name\":\"S. Risi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60fc8a885083f74c7a0aea829c81a92f2107e4d1\",\"title\":\"Illuminating Generalization in Deep Reinforcement Learning through Procedural Level Generation\",\"url\":\"https://www.semanticscholar.org/paper/60fc8a885083f74c7a0aea829c81a92f2107e4d1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1606.07419\",\"authors\":[{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"3422774\",\"name\":\"Ashvin Nair\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cf83c619423a1504f26495d5f6a495054c46462\",\"title\":\"Learning to Poke by Poking: Experiential Learning of Intuitive Physics\",\"url\":\"https://www.semanticscholar.org/paper/8cf83c619423a1504f26495d5f6a495054c46462\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1703.01161\",\"authors\":[{\"authorId\":\"9948791\",\"name\":\"A. S. Vezhnevets\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"049c6e5736313374c6e594c34b9be89a3a09dced\",\"title\":\"FeUdal Networks for Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/049c6e5736313374c6e594c34b9be89a3a09dced\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Perez-Liebana\"},{\"authorId\":null,\"name\":\"S. Samothrakis\"},{\"authorId\":null,\"name\":\"J. Togelius\"},{\"authorId\":null,\"name\":\"S. M. Lucas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"eral video game ai : Competition , challenges and opportunities\",\"url\":\"\",\"venue\":\"International Conference on Machine Learning ( ICML )\",\"year\":null},{\"arxivId\":\"1808.04355\",\"authors\":[{\"authorId\":\"3080409\",\"name\":\"Yuri Burda\"},{\"authorId\":\"144632352\",\"name\":\"H. Edwards\"},{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1728216\",\"name\":\"A. Storkey\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca14dce53be20d3d23d4f0db844a8389ab619db3\",\"title\":\"Large-Scale Study of Curiosity-Driven Learning\",\"url\":\"https://www.semanticscholar.org/paper/ca14dce53be20d3d23d4f0db844a8389ab619db3\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1602.01783\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"36045539\",\"name\":\"Adri\\u00e0 Puigdom\\u00e8nech Badia\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"title\":\"Asynchronous Methods for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/69e76e16740ed69f4dc55361a3d319ac2f1293dd\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1809.07124\",\"authors\":[{\"authorId\":\"47267576\",\"name\":\"Cinjon Resnick\"},{\"authorId\":\"82285987\",\"name\":\"Wes Eldridge\"},{\"authorId\":\"39810222\",\"name\":\"David R Ha\"},{\"authorId\":\"3908643\",\"name\":\"D. Britz\"},{\"authorId\":\"145356667\",\"name\":\"Jakob N. Foerster\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3feb79e8be23f0a9ef2beee964bfe4c36907dfc8\",\"title\":\"Pommerman: A Multi-Agent Playground\",\"url\":\"https://www.semanticscholar.org/paper/3feb79e8be23f0a9ef2beee964bfe4c36907dfc8\",\"venue\":\"AIIDE Workshops\",\"year\":2018},{\"arxivId\":\"1606.01868\",\"authors\":[{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"144999731\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"143810408\",\"name\":\"D. Saxton\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e90fd78e8a3b98af3954aae5209703aa966603e\",\"title\":\"Unifying Count-Based Exploration and Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/6e90fd78e8a3b98af3954aae5209703aa966603e\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115901011\",\"name\":\"D. Davies\"}],\"doi\":\"10.1016/S0140-6736(05)61503-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a5985e4e237535df0d1b7fd121e86d25842f0bb\",\"title\":\"T\",\"url\":\"https://www.semanticscholar.org/paper/2a5985e4e237535df0d1b7fd121e86d25842f0bb\",\"venue\":\"The Lancet\",\"year\":1998},{\"arxivId\":\"1709.06009\",\"authors\":[{\"authorId\":\"40066857\",\"name\":\"Marlos C. Machado\"},{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1701322\",\"name\":\"Erik Talvitie\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"143913104\",\"name\":\"Michael H. Bowling\"}],\"doi\":\"10.24963/ijcai.2018/787\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b290ffa1f4f8226e326f00984acecdfbe9e28bf\",\"title\":\"Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents\",\"url\":\"https://www.semanticscholar.org/paper/3b290ffa1f4f8226e326f00984acecdfbe9e28bf\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145528658\",\"name\":\"G. Kendall\"}],\"doi\":\"10.1109/TCIAIG.2015.2409514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9046f46d088eee7be4af8be5ffea602394a937c0\",\"title\":\"Editorial: IEEE Transactions on Computational Intelligence and AI in Games\",\"url\":\"https://www.semanticscholar.org/paper/9046f46d088eee7be4af8be5ffea602394a937c0\",\"venue\":\"IEEE Trans. Comput. Intell. AI Games\",\"year\":2015},{\"arxivId\":\"1709.06560\",\"authors\":[{\"authorId\":\"40068904\",\"name\":\"Peter Henderson\"},{\"authorId\":\"18014232\",\"name\":\"R. Islam\"},{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"},{\"authorId\":\"2462512\",\"name\":\"D. Meger\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"33690ff21ef1efb576410e656f2e60c89d0307d6\",\"title\":\"Deep Reinforcement Learning that Matters\",\"url\":\"https://www.semanticscholar.org/paper/33690ff21ef1efb576410e656f2e60c89d0307d6\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"cs/9605103\",\"authors\":[{\"authorId\":\"1709512\",\"name\":\"L. Kaelbling\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"1760402\",\"name\":\"A. Moore\"}],\"doi\":\"10.1613/jair.301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"title\":\"Reinforcement Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/12d1d070a53d4084d88a77b8b143bad51c40c38f\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":1996},{\"arxivId\":\"1810.12894\",\"authors\":[{\"authorId\":\"3080409\",\"name\":\"Yuri Burda\"},{\"authorId\":\"144632352\",\"name\":\"H. Edwards\"},{\"authorId\":\"1728216\",\"name\":\"A. Storkey\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cb3fd057949624aa4f0bbe7a6dcc8777ff04758\",\"title\":\"Exploration by Random Network Distillation\",\"url\":\"https://www.semanticscholar.org/paper/4cb3fd057949624aa4f0bbe7a6dcc8777ff04758\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1812.06110\",\"authors\":[{\"authorId\":\"39163115\",\"name\":\"P. S. Castro\"},{\"authorId\":\"3316330\",\"name\":\"Subhodeep Moitra\"},{\"authorId\":\"52382152\",\"name\":\"Carles Gelada\"},{\"authorId\":\"39703750\",\"name\":\"S. Kumar\"},{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e372ed2b688de0e4dcffbec1d2abdd0fc7ea27a\",\"title\":\"Dopamine: A Research Framework for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8e372ed2b688de0e4dcffbec1d2abdd0fc7ea27a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657391174\",\"name\":\"G.V.T.V. Weerasooriya\"},{\"authorId\":\"1657391179\",\"name\":\"D. N. Jayatissa\"},{\"authorId\":\"1657391068\",\"name\":\"M. Rambanda\"}],\"doi\":\"10.1515/9783111576855-012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f61efefa2a671529c4e6da4cb976d9437332f52e\",\"title\":\"G\",\"url\":\"https://www.semanticscholar.org/paper/f61efefa2a671529c4e6da4cb976d9437332f52e\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Vilalta\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Drissi\",\"url\":\"\",\"venue\":\"Y.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152784304\",\"name\":\"A. Kumar\"},{\"authorId\":\"151506072\",\"name\":\"A. Sharma\"},{\"authorId\":\"91318330\",\"name\":\"B. Torre\"},{\"authorId\":\"3976878\",\"name\":\"F. Albericio\"}],\"doi\":\"10.5040/9781474284028.0024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f36224042ba7fccb20af534eb8a764f72f3d6d\",\"title\":\"S\",\"url\":\"https://www.semanticscholar.org/paper/02f36224042ba7fccb20af534eb8a764f72f3d6d\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Schulman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1702.02284\",\"authors\":[{\"authorId\":\"2064588\",\"name\":\"Sandy H. Huang\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8c16a56d2a9520197da9a1546f517db5f19b204\",\"title\":\"Adversarial Attacks on Neural Network Policies\",\"url\":\"https://www.semanticscholar.org/paper/c8c16a56d2a9520197da9a1546f517db5f19b204\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1606.01540\",\"authors\":[{\"authorId\":\"49508975\",\"name\":\"G. Brockman\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"152877508\",\"name\":\"Ludwig Pettersson\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143805717\",\"name\":\"Jie Tang\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"title\":\"OpenAI Gym\",\"url\":\"https://www.semanticscholar.org/paper/ff7f3277c6fa759e84e1ab7664efdac1c1cec76b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1809.02627\",\"authors\":[{\"authorId\":\"7174267\",\"name\":\"Arthur Juliani\"},{\"authorId\":\"51266557\",\"name\":\"Vincent-Pierre Berges\"},{\"authorId\":\"80170837\",\"name\":\"Esh Vckay\"},{\"authorId\":\"143792910\",\"name\":\"Yuan Gao\"},{\"authorId\":\"51450774\",\"name\":\"Hunter Henry\"},{\"authorId\":\"49354909\",\"name\":\"M. Mattar\"},{\"authorId\":\"51438954\",\"name\":\"D. Lange\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"252482d733d67230843fe99bf60427285f0ad8e8\",\"title\":\"Unity: A General Platform for Intelligent Agents\",\"url\":\"https://www.semanticscholar.org/paper/252482d733d67230843fe99bf60427285f0ad8e8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/B978-0-12-384931-1.00018-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3b8146c7950597628689d14551e74d46cc3543d\",\"title\":\"R\",\"url\":\"https://www.semanticscholar.org/paper/a3b8146c7950597628689d14551e74d46cc3543d\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35168656\",\"name\":\"J. Dormans\"}],\"doi\":\"10.1145/1814256.1814257\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7113e80618d405bc39d5cb1793fb9e9672b7ad54\",\"title\":\"Adventures in level design: generating missions and spaces for action adventure games\",\"url\":\"https://www.semanticscholar.org/paper/7113e80618d405bc39d5cb1793fb9e9672b7ad54\",\"venue\":\"\",\"year\":2010},{\"arxivId\":\"1509.08731\",\"authors\":[{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab68ddbdd8d0b61d9f9c8fa500a4c13d06158060\",\"title\":\"Variational Information Maximisation for Intrinsically Motivated Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ab68ddbdd8d0b61d9f9c8fa500a4c13d06158060\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620865361\",\"name\":\"Seguin Hen\"}],\"doi\":\"10.1515/9783111576855-015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"title\":\"J\",\"url\":\"https://www.semanticscholar.org/paper/048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717017\",\"name\":\"Diego Perez Liebana\"},{\"authorId\":\"2032434\",\"name\":\"Spyridon Samothrakis\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"145815031\",\"name\":\"S. Lucas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"decb7e746acb87710c2a15585cd22133ffc2cc95\",\"title\":\"General Video Game AI: Competition, Challenges and Opportunities\",\"url\":\"https://www.semanticscholar.org/paper/decb7e746acb87710c2a15585cd22133ffc2cc95\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Schneider\"},{\"authorId\":null,\"name\":\"Y. Burda\"},{\"authorId\":null,\"name\":\"H. Edwards\"},{\"authorId\":null,\"name\":\"D. Pathak\"},{\"authorId\":null,\"name\":\"A. Storkey\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"K. Cobbe\"},{\"authorId\":null,\"name\":\"O. Klimov\"},{\"authorId\":null,\"name\":\"C. Hesse\"},{\"authorId\":null,\"name\":\"T. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"fying count - based exploration and intrinsic motivation\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems\",\"year\":null},{\"arxivId\":\"1207.4708\",\"authors\":[{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"2294249\",\"name\":\"Yavar Naddaf\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1687780\",\"name\":\"Michael Bowling\"}],\"doi\":\"10.1613/jair.3912\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f82e4ff4f003581330338aaae71f60316e58dd26\",\"title\":\"The Arcade Learning Environment: An Evaluation Platform for General Agents (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/f82e4ff4f003581330338aaae71f60316e58dd26\",\"venue\":\"IJCAI\",\"year\":2015},{\"arxivId\":\"1804.03720\",\"authors\":[{\"authorId\":\"38967461\",\"name\":\"Alex Nichol\"},{\"authorId\":\"41019154\",\"name\":\"V. Pfau\"},{\"authorId\":\"144239765\",\"name\":\"Christopher Hesse\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b72e488b48e464c7633418873f1cf9fbf3453ff2\",\"title\":\"Gotta Learn Fast: A New Benchmark for Generalization in RL\",\"url\":\"https://www.semanticscholar.org/paper/b72e488b48e464c7633418873f1cf9fbf3453ff2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3333404\",\"name\":\"G. Stiny\"},{\"authorId\":\"1765512\",\"name\":\"J. Gips\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8f7baf704f7d7713eee196de6cb90cbfb7fc4cd\",\"title\":\"Shape Grammars and the Generative Specification of Painting and Sculpture\",\"url\":\"https://www.semanticscholar.org/paper/c8f7baf704f7d7713eee196de6cb90cbfb7fc4cd\",\"venue\":\"IFIP Congress\",\"year\":1971},{\"arxivId\":\"1605.02097\",\"authors\":[{\"authorId\":\"3407787\",\"name\":\"Michal Kempka\"},{\"authorId\":\"3407043\",\"name\":\"Marek Wydmuch\"},{\"authorId\":\"3407668\",\"name\":\"Grzegorz Runc\"},{\"authorId\":\"3407634\",\"name\":\"Jakub Toczek\"},{\"authorId\":\"2146303\",\"name\":\"Wojciech Ja\\u015bkowski\"}],\"doi\":\"10.1109/CIG.2016.7860433\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a473f545318325ba23b7a6b477485d29777ba873\",\"title\":\"ViZDoom: A Doom-based AI research platform for visual reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/a473f545318325ba23b7a6b477485d29777ba873\",\"venue\":\"2016 IEEE Conference on Computational Intelligence and Games (CIG)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095131\",\"name\":\"Philipp Rohlfshagen\"},{\"authorId\":\"1685638\",\"name\":\"Jialin Liu\"},{\"authorId\":\"9157984\",\"name\":\"Diego P\\u00e9rez-Li\\u00e9bana\"},{\"authorId\":\"145815031\",\"name\":\"S. Lucas\"}],\"doi\":\"10.1109/TG.2017.2737145\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb607a8c627f0909df7af6c9e84e1bd7ab931bb3\",\"title\":\"Pac-Man Conquers Academia: Two Decades of Research Using a Classic Arcade Game\",\"url\":\"https://www.semanticscholar.org/paper/cb607a8c627f0909df7af6c9e84e1bd7ab931bb3\",\"venue\":\"IEEE Transactions on Games\",\"year\":2018},{\"arxivId\":\"1707.06347\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143909660\",\"name\":\"F. Wolski\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"title\":\"Proximal Policy Optimization Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Togelius Schaul\"},{\"authorId\":null,\"name\":\"T. Schmidhuber 2011 Schaul\"},{\"authorId\":null,\"name\":\"J. Togelius\"},{\"authorId\":null,\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Measuring intelligence through games. arXiv preprint arXiv:1109.1314\",\"url\":\"\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1710.02298\",\"authors\":[{\"authorId\":\"39357484\",\"name\":\"Matteo Hessel\"},{\"authorId\":\"3321484\",\"name\":\"Joseph Modayil\"},{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"2605877\",\"name\":\"W. Dabney\"},{\"authorId\":\"48257711\",\"name\":\"Dan Horgan\"},{\"authorId\":\"1808897\",\"name\":\"B. Piot\"},{\"authorId\":\"37666967\",\"name\":\"Mohammad Gheshlaghi Azar\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ab3f7ecbdc5a33565a234215604a6ca9d155a33\",\"title\":\"Rainbow: Combining Improvements in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0ab3f7ecbdc5a33565a234215604a6ca9d155a33\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34706692\",\"name\":\"R. Vilalta\"},{\"authorId\":\"1839053\",\"name\":\"Y. Drissi\"}],\"doi\":\"10.1023/A:1019956318069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98f8a0055bb28133efcff359a92937324d0e6f51\",\"title\":\"A Perspective View and Survey of Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/98f8a0055bb28133efcff359a92937324d0e6f51\",\"venue\":\"Artificial Intelligence Review\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48389837\",\"name\":\"Matthew Johnson\"},{\"authorId\":\"145186674\",\"name\":\"Katja Hofmann\"},{\"authorId\":\"12642347\",\"name\":\"T. Hutton\"},{\"authorId\":\"48928368\",\"name\":\"D. Bignell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd6b6291c3c14551cf9f2aa0e04e2e33c86b800e\",\"title\":\"The Malmo Platform for Artificial Intelligence Experimentation\",\"url\":\"https://www.semanticscholar.org/paper/bd6b6291c3c14551cf9f2aa0e04e2e33c86b800e\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"George Stiny\"},{\"authorId\":null,\"name\":\"James Gips. Shape grammars\"},{\"authorId\":null,\"name\":\"the generative specification of painting\"},{\"authorId\":null,\"name\":\"sculpture\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IFIP Congress (2)\",\"url\":\"\",\"venue\":\"volume 2,\",\"year\":1971},{\"arxivId\":\"1501.05611\",\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"40234261\",\"name\":\"Nolan Wagener\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":\"10.1109/ICRA.2015.7138994\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d388e15a41b98f5fde97bd6a50f73aa57d6e7801\",\"title\":\"Learning contact-rich manipulation skills with guided policy search\",\"url\":\"https://www.semanticscholar.org/paper/d388e15a41b98f5fde97bd6a50f73aa57d6e7801\",\"venue\":\"2015 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1623397502\",\"name\":\"Saskia Bonjour\"},{\"authorId\":\"1623405226\",\"name\":\"Doutje Lettinga\"},{\"authorId\":\"1623397535\",\"name\":\"Christian Joppke\"}],\"doi\":\"10.1515/9783111576855-009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"776f6d45b38cf048ff30cea41f0cd3ceeefed622\",\"title\":\"D\",\"url\":\"https://www.semanticscholar.org/paper/776f6d45b38cf048ff30cea41f0cd3ceeefed622\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Adrien Ecoffet\"},{\"authorId\":null,\"name\":\"Joost Huizinga\"},{\"authorId\":null,\"name\":\"Joel Lehman\"},{\"authorId\":null,\"name\":\"Kenneth Stanley\"},{\"authorId\":null,\"name\":\"Jeff Clune\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Montezuma\\u2019s revenge solved by go-explore\",\"url\":\"\",\"venue\":\"a new algorithm for hardexploration problems (sets records on pitfall too),\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630277553\",\"name\":\"M. Sankar\"}],\"doi\":\"10.1515/9783111548050-024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"title\":\"M\",\"url\":\"https://www.semanticscholar.org/paper/517a45c35f9ad52ac75a27c5a5f190d41cbc5e65\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Stiny\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Gips\",\"url\":\"\",\"venue\":\"J.\",\"year\":1971},{\"arxivId\":\"1804.06893\",\"authors\":[{\"authorId\":\"40313479\",\"name\":\"C. Zhang\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1708654\",\"name\":\"R. Munos\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fee7b836b71125a5f6a3696b9c383dae18c21e8\",\"title\":\"A Study on Overfitting in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3fee7b836b71125a5f6a3696b9c383dae18c21e8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Diego Perez-Liebana\"},{\"authorId\":null,\"name\":\"Spyridon Samothrakis\"},{\"authorId\":null,\"name\":\"Julian Togelius\"},{\"authorId\":null,\"name\":\"Simon M Lucas\"},{\"authorId\":null,\"name\":\"Tom Schaul\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"General video game ai: Competition\",\"url\":\"\",\"venue\":\"challenges and opportunities. In Thirtieth AAAI Conference on Artificial Intelligence, pages 4335\\u20134337,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7991309\",\"name\":\"A. L. Samuel\"}],\"doi\":\"10.1147/rd.441.0206\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"422690748d33dfb15e57fda9b851e7894f368e09\",\"title\":\"Some studies in machine learning using the game of checkers\",\"url\":\"https://www.semanticscholar.org/paper/422690748d33dfb15e57fda9b851e7894f368e09\",\"venue\":\"IBM J. Res. Dev.\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31404290\",\"name\":\"R. J. Joenk\"}],\"doi\":\"10.1147/RD.221.0094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"876d33b1c1102bf775d8f34be82c0ba9dd7d5e90\",\"title\":\"IBM journal of research and development: information for authors\",\"url\":\"https://www.semanticscholar.org/paper/876d33b1c1102bf775d8f34be82c0ba9dd7d5e90\",\"venue\":\"\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Karakovskiy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Togelius\",\"url\":\"\",\"venue\":\"J.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144844989\",\"name\":\"F. Hsu\"},{\"authorId\":\"35442558\",\"name\":\"T. Anantharaman\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"},{\"authorId\":\"1733544\",\"name\":\"A. Nowatzyk\"}],\"doi\":\"10.1038/SCIENTIFICAMERICAN1090-44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1bee491adfc254df330394e4908001686501c43\",\"title\":\"A Grandmaster Chess Machine\",\"url\":\"https://www.semanticscholar.org/paper/e1bee491adfc254df330394e4908001686501c43\",\"venue\":\"\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747011\",\"name\":\"P. Hingston\"}],\"doi\":\"10.1109/TCIAIG.2009.2032534\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61e972ce10138b742825b851c35a04155bbc34ae\",\"title\":\"A Turing Test for Computer Game Bots\",\"url\":\"https://www.semanticscholar.org/paper/61e972ce10138b742825b851c35a04155bbc34ae\",\"venue\":\"IEEE Transactions on Computational Intelligence and AI in Games\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Prafulla Dhariwal\"},{\"authorId\":null,\"name\":\"Christopher Hesse\"},{\"authorId\":null,\"name\":\"Oleg Klimov\"},{\"authorId\":null,\"name\":\"Alex Nichol\"},{\"authorId\":null,\"name\":\"Matthias Plappert\"},{\"authorId\":null,\"name\":\"Alec Radford\"},{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Szymon Sidor\"},{\"authorId\":null,\"name\":\"Yuhuai Wu\"},{\"authorId\":null,\"name\":\"Peter Zhokhov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Openai baselines\",\"url\":\"\",\"venue\":\"https://github.com/openai/baselines,\",\"year\":2017},{\"arxivId\":\"1611.05763\",\"authors\":[{\"authorId\":\"13256987\",\"name\":\"J. X. Wang\"},{\"authorId\":\"1399114225\",\"name\":\"Z. Kurth-Nelson\"},{\"authorId\":\"2794457\",\"name\":\"Hubert Soyer\"},{\"authorId\":\"1700356\",\"name\":\"Joel Z. Leibo\"},{\"authorId\":\"7794353\",\"name\":\"Dhruva Tirumala\"},{\"authorId\":\"118538000\",\"name\":\"R\\u00e9mi Munos\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1409234386\",\"name\":\"Matt M. Botvinick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"282a380fb5ac26d99667224cef8c630f6882704f\",\"title\":\"Learning to reinforcement learn\",\"url\":\"https://www.semanticscholar.org/paper/282a380fb5ac26d99667224cef8c630f6882704f\",\"venue\":\"CogSci\",\"year\":2017},{\"arxivId\":\"1812.02341\",\"authors\":[{\"authorId\":\"6062736\",\"name\":\"K. Cobbe\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"},{\"authorId\":\"144239765\",\"name\":\"Christopher Hesse\"},{\"authorId\":\"1837923\",\"name\":\"Taehoon Kim\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef2bc452812d6005ab0a66af6c3f97b6b0ba837e\",\"title\":\"Quantifying Generalization in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ef2bc452812d6005ab0a66af6c3f97b6b0ba837e\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1694170\",\"name\":\"J. Schaeffer\"},{\"authorId\":\"3038110\",\"name\":\"J. Culberson\"},{\"authorId\":\"2501516\",\"name\":\"N. Treloar\"},{\"authorId\":\"144170840\",\"name\":\"B. Knight\"},{\"authorId\":\"2093016\",\"name\":\"P. Lu\"},{\"authorId\":\"144617374\",\"name\":\"D. Szafron\"}],\"doi\":\"10.1016/0004-3702(92)90074-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d088cdda1948d291d7c7cf4bbfe46c9391242cdc\",\"title\":\"A World Championship Caliber Checkers Program\",\"url\":\"https://www.semanticscholar.org/paper/d088cdda1948d291d7c7cf4bbfe46c9391242cdc\",\"venue\":\"Artif. Intell.\",\"year\":1992},{\"arxivId\":\"1703.03400\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c889d6f98e6d79b89c3a6adf8a921f88fa6ba518\",\"title\":\"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1705.05363\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPRW.2017.70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"225ab689f41cef1dc18237ef5dab059a49950abf\",\"title\":\"Curiosity-Driven Exploration by Self-Supervised Prediction\",\"url\":\"https://www.semanticscholar.org/paper/225ab689f41cef1dc18237ef5dab059a49950abf\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2463017\",\"name\":\"S. Karakovskiy\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"}],\"doi\":\"10.1109/TCIAIG.2012.2188528\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6eaa8e1622f37f4a6cf3deeeee78abd3f86c711e\",\"title\":\"The Mario AI Benchmark and Competitions\",\"url\":\"https://www.semanticscholar.org/paper/6eaa8e1622f37f4a6cf3deeeee78abd3f86c711e\",\"venue\":\"IEEE Transactions on Computational Intelligence and AI in Games\",\"year\":2012},{\"arxivId\":\"1809.01999\",\"authors\":[{\"authorId\":\"39810222\",\"name\":\"David R Ha\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cae23343d2efddca3592b08a521a896af5098248\",\"title\":\"Recurrent World Models Facilitate Policy Evolution\",\"url\":\"https://www.semanticscholar.org/paper/cae23343d2efddca3592b08a521a896af5098248\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00003-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06d5b55bec96f2157276b631e2f21d52a33ea246\",\"title\":\"C\",\"url\":\"https://www.semanticscholar.org/paper/06d5b55bec96f2157276b631e2f21d52a33ea246\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":\"1109.1314\",\"authors\":[{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c648a4b03f2d1d9dda4b8c33007c2c9d681cb975\",\"title\":\"Measuring Intelligence through Games\",\"url\":\"https://www.semanticscholar.org/paper/c648a4b03f2d1d9dda4b8c33007c2c9d681cb975\",\"venue\":\"ArXiv\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cinjon Resnick\"},{\"authorId\":null,\"name\":\"Wes Eldridge\"},{\"authorId\":null,\"name\":\"David Ha\"},{\"authorId\":null,\"name\":\"Denny Britz\"},{\"authorId\":null,\"name\":\"Jakob Foerster\"},{\"authorId\":null,\"name\":\"Julian Togelius\"},{\"authorId\":null,\"name\":\"Kyunghyun Cho\"},{\"authorId\":null,\"name\":\"Joan Bruna\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pommerman: A multiagent playground\",\"url\":\"\",\"venue\":\"arXiv:1809.07124,\",\"year\":2018},{\"arxivId\":\"1805.11592\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2054956\",\"name\":\"T. Pfaff\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"145757542\",\"name\":\"T. Paine\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"705bbc4dcd475f9230863771da6596e1f677a92d\",\"title\":\"Playing hard exploration games by watching YouTube\",\"url\":\"https://www.semanticscholar.org/paper/705bbc4dcd475f9230863771da6596e1f677a92d\",\"venue\":\"NeurIPS\",\"year\":2018}],\"title\":\"Obstacle Tower: A Generalization Challenge in Vision, Control, and Planning\",\"topics\":[{\"topic\":\"Automated planning and scheduling\",\"topicId\":\"3649\",\"url\":\"https://www.semanticscholar.org/topic/3649\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Algorithm design\",\"topicId\":\"146513\",\"url\":\"https://www.semanticscholar.org/topic/146513\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Console game\",\"topicId\":\"1088461\",\"url\":\"https://www.semanticscholar.org/topic/1088461\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Procedural generation\",\"topicId\":\"21963\",\"url\":\"https://www.semanticscholar.org/topic/21963\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"},{\"topic\":\"Over-the-counter (finance)\",\"topicId\":\"320339\",\"url\":\"https://www.semanticscholar.org/topic/320339\"},{\"topic\":\"Arcade game\",\"topicId\":\"33581\",\"url\":\"https://www.semanticscholar.org/topic/33581\"}],\"url\":\"https://www.semanticscholar.org/paper/ec2b345267d69e8b4dca550efcd0948e0352acd9\",\"venue\":\"IJCAI\",\"year\":2019}\n"