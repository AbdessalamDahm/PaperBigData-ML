"{\"abstract\":\"Adversarial examples induce model classification errors on purpose, which has raised concerns on the security aspect of machine learning techniques. Many existing countermeasures are compromised by adaptive adversaries and transferred examples. We propose a model-agnostic approach to resolve the problem by analysing the model responses to an input under random perturbations, and study the robustness of detecting norm-bounded adversarial distortions in a theoretical framework. Extensive evaluations are performed on the MNIST, CIFAR10 and ImageNet datasets. The results demonstrate that our detection method is effective and resilient against various attacks including black-box attacks and the powerful CW attack with four adversarial adaptations.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"48311093\",\"name\":\"B. Huang\",\"url\":\"https://www.semanticscholar.org/author/48311093\"},{\"authorId\":null,\"name\":\"Yi Wang\",\"url\":null},{\"authorId\":\"49697354\",\"name\":\"Wei Wang\",\"url\":\"https://www.semanticscholar.org/author/49697354\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2004.02756\",\"authors\":[{\"authorId\":\"1391547584\",\"name\":\"Qinkai Zheng\"},{\"authorId\":\"49660254\",\"name\":\"Han Qiu\"},{\"authorId\":\"1749624\",\"name\":\"G. Memmi\"},{\"authorId\":\"1695917\",\"name\":\"I. Bloch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0590631d8d5b5bb7eef807dc047776d2160b8eb\",\"title\":\"Investigating Image Applications Based on Spatial-Frequency Transform and Deep Learning Techniques\",\"url\":\"https://www.semanticscholar.org/paper/d0590631d8d5b5bb7eef807dc047776d2160b8eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4155554\",\"name\":\"J. Rounds\"},{\"authorId\":\"16173321\",\"name\":\"Addie Kingsland\"},{\"authorId\":\"11947551\",\"name\":\"M. Henry\"},{\"authorId\":\"102754720\",\"name\":\"Kayla Duskin\"}],\"doi\":\"10.1109/CVPRW50498.2020.00403\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40aa6edeca8232cb30f0beea660ac8c63ad2d04c\",\"title\":\"Probing for Artifacts: Detecting Imagenet Model Evasions\",\"url\":\"https://www.semanticscholar.org/paper/40aa6edeca8232cb30f0beea660ac8c63ad2d04c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326259\",\"name\":\"M. Qiu\"},{\"authorId\":\"2157911\",\"name\":\"Han Qiu\"}],\"doi\":\"10.1109/BigDataSecurity-HPSC-IDS49724.2020.00027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cf5c840fa6006767289db6d351a803d8590ce94\",\"title\":\"Review on Image Processing Based Adversarial Example Defenses in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/7cf5c840fa6006767289db6d351a803d8590ce94\",\"venue\":\"2020 IEEE 6th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)\",\"year\":2020},{\"arxivId\":\"1912.09059\",\"authors\":[{\"authorId\":\"36301492\",\"name\":\"Mahmood Sharif\"},{\"authorId\":\"41224057\",\"name\":\"L. Bauer\"},{\"authorId\":\"1746214\",\"name\":\"M. Reiter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6f9ede44525800875933940c8d62aaf5897fca5\",\"title\":\"n-ML: Mitigating Adversarial Examples via Ensembles of Topologically Manipulated Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/c6f9ede44525800875933940c8d62aaf5897fca5\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":199466056,\"doi\":\"10.24963/ijcai.2019/651\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"76e21e9afe8a5754b17dc3ae09537a1fe85ea2ac\",\"references\":[{\"arxivId\":\"1608.08967\",\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"637c25f7e8f37226f829cd9264d4eeea50f75e7b\",\"title\":\"Robustness of classifiers: from adversarial to random noise\",\"url\":\"https://www.semanticscholar.org/paper/637c25f7e8f37226f829cd9264d4eeea50f75e7b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1611.03814\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"2370629\",\"name\":\"Arunesh Sinha\"},{\"authorId\":\"1796536\",\"name\":\"Michael P. Wellman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebab687cd1be7d25392c11f89fce6a63bef7219d\",\"title\":\"Towards the Science of Security and Privacy in Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/ebab687cd1be7d25392c11f89fce6a63bef7219d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1802.03471\",\"authors\":[{\"authorId\":\"2574478\",\"name\":\"Mathias L\\u00e9cuyer\"},{\"authorId\":\"2501382\",\"name\":\"Vaggelis Atlidakis\"},{\"authorId\":\"1972091\",\"name\":\"Roxana Geambasu\"},{\"authorId\":\"46533534\",\"name\":\"D. Hsu\"},{\"authorId\":\"39400201\",\"name\":\"Suman Jana\"}],\"doi\":\"10.1109/SP.2019.00044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e86a51d1f2051ab8f448b66c6dcc17924d17cfa\",\"title\":\"Certified Robustness to Adversarial Examples with Differential Privacy\",\"url\":\"https://www.semanticscholar.org/paper/3e86a51d1f2051ab8f448b66c6dcc17924d17cfa\",\"venue\":\"2019 IEEE Symposium on Security and Privacy (SP)\",\"year\":2019},{\"arxivId\":\"1704.00103\",\"authors\":[{\"authorId\":\"5291972\",\"name\":\"Jiajun Lu\"},{\"authorId\":\"7276866\",\"name\":\"Theerasit Issaranon\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/ICCV.2017.56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"899005eb65650c91240a6624c8b4dc14f757afad\",\"title\":\"SafetyNet: Detecting and Rejecting Adversarial Examples Robustly\",\"url\":\"https://www.semanticscholar.org/paper/899005eb65650c91240a6624c8b4dc14f757afad\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.06131\",\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"2338858\",\"name\":\"I. Corona\"},{\"authorId\":\"3248803\",\"name\":\"Davide Maiorca\"},{\"authorId\":\"39743720\",\"name\":\"B. Nelson\"},{\"authorId\":\"2118348\",\"name\":\"Nedim Srndic\"},{\"authorId\":\"1754215\",\"name\":\"P. Laskov\"},{\"authorId\":\"1779484\",\"name\":\"G. Giacinto\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1007/978-3-642-40994-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"title\":\"Evasion Attacks against Machine Learning at Test Time\",\"url\":\"https://www.semanticscholar.org/paper/033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"venue\":\"ECML/PKDD\",\"year\":2013},{\"arxivId\":\"1711.05929\",\"authors\":[{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2018.00357\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4413dd4a51ab86d09c165d4b2fe1dc2168fc1ff\",\"title\":\"Defense Against Universal Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/c4413dd4a51ab86d09c165d4b2fe1dc2168fc1ff\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1702.06280\",\"authors\":[{\"authorId\":\"39221858\",\"name\":\"Kathrin Grosse\"},{\"authorId\":\"144278515\",\"name\":\"P. Manoharan\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144588806\",\"name\":\"M. Backes\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a77313fa10a864e14f538c73d417d7b4d6f320e\",\"title\":\"On the (Statistical) Detection of Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/0a77313fa10a864e14f538c73d417d7b4d6f320e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.00117\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"2139712\",\"name\":\"Mayank Rana\"},{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"title\":\"Countering Adversarial Images using Input Transformations\",\"url\":\"https://www.semanticscholar.org/paper/e225dd59ef4954db21479cdcbee497624b2d6d0f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.07528\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"2623167\",\"name\":\"Matt Fredrikson\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1109/EuroSP.2016.36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"819167ace2f0caae7745d2f25a803979be5fbfae\",\"title\":\"The Limitations of Deep Learning in Adversarial Settings\",\"url\":\"https://www.semanticscholar.org/paper/819167ace2f0caae7745d2f25a803979be5fbfae\",\"venue\":\"2016 IEEE European Symposium on Security and Privacy (EuroS&P)\",\"year\":2016},{\"arxivId\":\"1704.01155\",\"authors\":[{\"authorId\":\"50231973\",\"name\":\"Weilin Xu\"},{\"authorId\":\"145685504\",\"name\":\"David Evans\"},{\"authorId\":\"1791105\",\"name\":\"Y. Qi\"}],\"doi\":\"10.14722/ndss.2018.23198\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"title\":\"Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9fec45e1ff97ffb0e0cf9f039e39b46043430301\",\"venue\":\"NDSS\",\"year\":2018},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1801.02613\",\"authors\":[{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":null,\"name\":\"Yisen Wang\"},{\"authorId\":\"144757691\",\"name\":\"S. Erfani\"},{\"authorId\":\"2825361\",\"name\":\"S. Wijewickrema\"},{\"authorId\":\"4480560\",\"name\":\"M. E. Houle\"},{\"authorId\":\"1710013\",\"name\":\"Grant Schoenebeck\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a18ada04d93981178234d9c8907fb99ea92fddcb\",\"title\":\"Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality\",\"url\":\"https://www.semanticscholar.org/paper/a18ada04d93981178234d9c8907fb99ea92fddcb\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1808.01688\",\"authors\":[{\"authorId\":\"144473414\",\"name\":\"D. Su\"},{\"authorId\":\"1768312\",\"name\":\"Huan Zhang\"},{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"}],\"doi\":\"10.1007/978-3-030-01258-8_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"821fd5bed14d6d06c25fbf44123fd7be382f7b4e\",\"title\":\"Is Robustness the Cost of Accuracy? - A Comprehensive Study on the Robustness of 18 Deep Image Classification Models\",\"url\":\"https://www.semanticscholar.org/paper/821fd5bed14d6d06c25fbf44123fd7be382f7b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1704.08847\",\"authors\":[{\"authorId\":\"5723508\",\"name\":\"M. Ciss\\u00e9\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"title\":\"Parseval Networks: Improving Robustness to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/013efe3ff541e518c51f08d1b62a62e0c57c0b14\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018}],\"title\":\"Model-Agnostic Adversarial Detection by Random Perturbations\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"MNIST database\",\"topicId\":\"211771\",\"url\":\"https://www.semanticscholar.org/topic/211771\"},{\"topic\":\"Distortion\",\"topicId\":\"15080\",\"url\":\"https://www.semanticscholar.org/topic/15080\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Sensor\",\"topicId\":\"1117\",\"url\":\"https://www.semanticscholar.org/topic/1117\"},{\"topic\":\"Utility functions on indivisible goods\",\"topicId\":\"3578244\",\"url\":\"https://www.semanticscholar.org/topic/3578244\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Naive Bayes classifier\",\"topicId\":\"35925\",\"url\":\"https://www.semanticscholar.org/topic/35925\"}],\"url\":\"https://www.semanticscholar.org/paper/76e21e9afe8a5754b17dc3ae09537a1fe85ea2ac\",\"venue\":\"IJCAI\",\"year\":2019}\n"