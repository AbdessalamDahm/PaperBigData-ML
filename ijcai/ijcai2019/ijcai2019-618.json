"{\"abstract\":\"Experience reuse is key to sample-efficient reinforcement learning. One of the critical issues is how the experience is represented and stored. Previously, the experience can be stored in the forms of features, individual models, and the average model, each lying at a different granularity. However, new tasks may require experience across multiple granularities. In this paper, we propose the policy residual representation (PRR) network, which can extract and store multiple levels of experience. PRR network is trained on a set of tasks with a multi-level architecture, where a module in each level corresponds to a subset of the tasks. Therefore, the PRR network represents the experience in a spectrum-like way. When training on a new task, PRR can provide different levels of experience for accelerating the learning. We experiment with the PRR network on a set of grid world navigation tasks, locomotion tasks, and fighting tasks in a video game. The results show that the PRR network leads to better reuse of experience and thus outperforms some state-of-the-art approaches.\",\"arxivId\":\"1905.13719\",\"authors\":[{\"authorId\":\"22676240\",\"name\":\"Wen-Ji Zhou\",\"url\":\"https://www.semanticscholar.org/author/22676240\"},{\"authorId\":\"47112122\",\"name\":\"Yang Yu\",\"url\":\"https://www.semanticscholar.org/author/47112122\"},{\"authorId\":\"2519427\",\"name\":\"Yingfeng Chen\",\"url\":\"https://www.semanticscholar.org/author/2519427\"},{\"authorId\":\"144155590\",\"name\":\"Kai Guan\",\"url\":\"https://www.semanticscholar.org/author/144155590\"},{\"authorId\":\"80892810\",\"name\":\"Tangjie Lv\",\"url\":\"https://www.semanticscholar.org/author/80892810\"},{\"authorId\":\"3120655\",\"name\":\"Changjie Fan\",\"url\":\"https://www.semanticscholar.org/author/3120655\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\",\"url\":\"https://www.semanticscholar.org/author/145624000\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2010.09536\",\"authors\":[{\"authorId\":\"31190626\",\"name\":\"Hongyao Tang\"},{\"authorId\":\"2528357\",\"name\":\"Zhao-Peng Meng\"},{\"authorId\":\"40513470\",\"name\":\"Jianye Hao\"},{\"authorId\":\"40590308\",\"name\":\"Chen Chen\"},{\"authorId\":\"1701335\",\"name\":\"D. Graves\"},{\"authorId\":\"48937589\",\"name\":\"Dong Li\"},{\"authorId\":\"2032869\",\"name\":\"W. Liu\"},{\"authorId\":\"49307876\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"55d296154f3d6518e93ccf3fdd4f691077b5ceda\",\"title\":\"What About Taking Policy as Input of Value Function: Policy-extended Value Function Approximator\",\"url\":\"https://www.semanticscholar.org/paper/55d296154f3d6518e93ccf3fdd4f691077b5ceda\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":173188535,\"doi\":\"10.24963/ijcai.2019/618\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"30e7f96c987c0f8a7cc64ce8a0599a7d31870c05\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"14212205\",\"name\":\"D. Liu\"},{\"authorId\":\"1398217037\",\"name\":\"M. Abu-Khalaf\"},{\"authorId\":\"1683616\",\"name\":\"A. M. Alimi\"},{\"authorId\":\"144826602\",\"name\":\"C. Anderson\"},{\"authorId\":\"71018001\",\"name\":\"A. Fausto\"},{\"authorId\":\"3836512\",\"name\":\"A. T. Azar\"},{\"authorId\":\"115675135\",\"name\":\"B. Baesens\"},{\"authorId\":\"1764788\",\"name\":\"G. Battistelli\"},{\"authorId\":\"1398734187\",\"name\":\"E. Bayro-Corrochano\"},{\"authorId\":\"1929254\",\"name\":\"S. Boht\\u00e9\"},{\"authorId\":\"2613481\",\"name\":\"P. Bouboulis\"},{\"authorId\":\"1409071182\",\"name\":\"Padua Braga\"},{\"authorId\":\"2123613\",\"name\":\"C. Cervellera\"},{\"authorId\":\"1703849\",\"name\":\"B. Chen\"},{\"authorId\":\"1781965\",\"name\":\"S. Cruces\"},{\"authorId\":\"39293304\",\"name\":\"Qiong-Hai Dai\"},{\"authorId\":\"7416642\",\"name\":\"S. Damelin\"},{\"authorId\":\"103338302\",\"name\":\"Daoyi Dong\"},{\"authorId\":\"1384339708\",\"name\":\"E. El-Alfy\"},{\"authorId\":\"48225830\",\"name\":\"K. Fahd\"},{\"authorId\":\"145319527\",\"name\":\"S. Arabia\"},{\"authorId\":\"143845181\",\"name\":\"D. Elizondo\"},{\"authorId\":\"3138895\",\"name\":\"M. Filippone\"},{\"authorId\":\"145692771\",\"name\":\"Y. Fu\"},{\"authorId\":\"2264182\",\"name\":\"Giorgio Gnecco\"},{\"authorId\":\"2198278\",\"name\":\"Haibo He\"},{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"1815835\",\"name\":\"P. Kidmose\"},{\"authorId\":\"1779619\",\"name\":\"R. M. Kil\"},{\"authorId\":\"2073142\",\"name\":\"R. Legenstein\"},{\"authorId\":\"47892555\",\"name\":\"Hongyi Li\"},{\"authorId\":\"46946977\",\"name\":\"Zhijun Li\"},{\"authorId\":\"47663266\",\"name\":\"Jinling Liang\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"1723706\",\"name\":\"Wenlian Lu\"},{\"authorId\":\"9074167\",\"name\":\"Jiancheng Lv\"},{\"authorId\":\"144893748\",\"name\":\"A. Madureira\"},{\"authorId\":\"152748915\",\"name\":\"M. Panella\"},{\"authorId\":\"1780024\",\"name\":\"R. Polikar\"},{\"authorId\":\"2353770\",\"name\":\"D. Prokhorov\"},{\"authorId\":\"1744102\",\"name\":\"M. Roveri\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"46581758\",\"name\":\"Madhusudana Shashanka\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"1721547\",\"name\":\"I. \\u0160krjanc\"},{\"authorId\":\"40560020\",\"name\":\"Y. Song\"},{\"authorId\":\"1771979\",\"name\":\"S. Squartini\"},{\"authorId\":\"1776000\",\"name\":\"Changyin Sun\"},{\"authorId\":\"144732378\",\"name\":\"T. Tanaka\"},{\"authorId\":\"3134548\",\"name\":\"H. Tang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"4023505\",\"name\":\"P. Ti\\u00f1o\"},{\"authorId\":\"2706487\",\"name\":\"D. Wang\"},{\"authorId\":\"48325417\",\"name\":\"M. J. Watts\"},{\"authorId\":\"1717781\",\"name\":\"Qinglai Wei\"},{\"authorId\":\"50313481\",\"name\":\"Stefan Wermter\"},{\"authorId\":\"32239759\",\"name\":\"M. Wiering\"},{\"authorId\":\"33455548\",\"name\":\"Jonathan Wu\"},{\"authorId\":\"145382103\",\"name\":\"S. Xie\"},{\"authorId\":\"144016434\",\"name\":\"D. Xu\"}],\"doi\":\"10.1109/tnnls.2013.2286276\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"41eb6f471abaa7d111baefda111e488f8ffb39a4\",\"title\":\"IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS\",\"url\":\"https://www.semanticscholar.org/paper/41eb6f471abaa7d111baefda111e488f8ffb39a4\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Chelsea Finn\"},{\"authorId\":null,\"name\":\"Trevor Darrell\"},{\"authorId\":null,\"name\":\"Pieter Abbeel. End-to-end training of deep visuomotor policies\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Journal of Machine Learning Research\",\"url\":\"\",\"venue\":\"17:1\\u201340,\",\"year\":2016},{\"arxivId\":\"1710.09767\",\"authors\":[{\"authorId\":\"10728123\",\"name\":\"Kevin Frans\"},{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d2c4cbb535801549371d9783a98d1e43bddf4e5\",\"title\":\"Meta Learning Shared Hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/4d2c4cbb535801549371d9783a98d1e43bddf4e5\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.07245\",\"authors\":[{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"35509365\",\"name\":\"R. Mendonca\"},{\"authorId\":\"49421394\",\"name\":\"Yuxuan Liu\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"68c108795deef06fa929d1f6e96b75dbf7ce8531\",\"title\":\"Meta-Reinforcement Learning of Structured Exploration Strategies\",\"url\":\"https://www.semanticscholar.org/paper/68c108795deef06fa929d1f6e96b75dbf7ce8531\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398842047\",\"name\":\"Haitham Bou-Ammar\"},{\"authorId\":\"2274623\",\"name\":\"K. Tuyls\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"},{\"authorId\":\"47262477\",\"name\":\"G. Weiss\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65eaabe5733ced3264c8939867561d133bfd8585\",\"title\":\"Reinforcement learning transfer via sparse coding\",\"url\":\"https://www.semanticscholar.org/paper/65eaabe5733ced3264c8939867561d133bfd8585\",\"venue\":\"AAMAS\",\"year\":2012},{\"arxivId\":\"1504.00702\",\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6b8a1b80891c96c28cc6340267b58186157e536\",\"title\":\"End-to-End Training of Deep Visuomotor Policies\",\"url\":\"https://www.semanticscholar.org/paper/b6b8a1b80891c96c28cc6340267b58186157e536\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chao Zhang\"},{\"authorId\":\"144705629\",\"name\":\"Yang Yu\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.24963/ijcai.2018/425\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ede887518958ecb65bfd7e91e4bdb23d11febda\",\"title\":\"Learning Environmental Calibration Actions for Policy Self-Evolution\",\"url\":\"https://www.semanticscholar.org/paper/7ede887518958ecb65bfd7e91e4bdb23d11febda\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144832491\",\"name\":\"E. Todorov\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"}],\"doi\":\"10.1109/IROS.2012.6386109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"title\":\"MuJoCo: A physics engine for model-based control\",\"url\":\"https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chelsea Finn\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Sergey Levine. Model-agnostic meta-learning for fast adap networks\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In Proceedings of the 34th International Conference on Machine Learning (ICML\\u201917)\",\"url\":\"\",\"venue\":\"pages 1126\\u20131135, Sydney, Australia,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48623509\",\"name\":\"Y. Yu\"},{\"authorId\":\"145891473\",\"name\":\"Shi-Yong Chen\"},{\"authorId\":\"2825549\",\"name\":\"Qing Da\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/TNNLS.2018.2803729\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d45811bec4a01aa86d31c6978e3feea5c35b0d23\",\"title\":\"Reusable Reinforcement Learning via Shallow Trails\",\"url\":\"https://www.semanticscholar.org/paper/d45811bec4a01aa86d31c6978e3feea5c35b0d23\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2941244\",\"name\":\"Robert B. Lackey\"},{\"authorId\":\"145191748\",\"name\":\"D. Meltzer\"}],\"doi\":\"10.1109/T-C.1971.223214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"297308f760e40cf5ec115723e2af91b49be5e79d\",\"title\":\"A Simplified Definition of Walsh Functions\",\"url\":\"https://www.semanticscholar.org/paper/297308f760e40cf5ec115723e2af91b49be5e79d\",\"venue\":\"IEEE Transactions on Computers\",\"year\":1971},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Prafulla Dhariwal Alec Radford Oleg Klimov John Schulman\"},{\"authorId\":null,\"name\":\"Filip Wolski. Proximal policy optimization algorithms\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1707.06347,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1007/s11704-016-6906-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5ae9087733111e23f89b744c3fae5ec1be0ce75\",\"title\":\"Learnware: on the future of machine learning\",\"url\":\"https://www.semanticscholar.org/paper/a5ae9087733111e23f89b744c3fae5ec1be0ce75\",\"venue\":\"Frontiers of Computer Science\",\"year\":2016},{\"arxivId\":\"1606.05312\",\"authors\":[{\"authorId\":\"143999673\",\"name\":\"Andr\\u00e9 Barreto\"},{\"authorId\":\"2605877\",\"name\":\"W. Dabney\"},{\"authorId\":\"118538000\",\"name\":\"R\\u00e9mi Munos\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8686b657b61a37da351af2952aabd8b281de408\",\"title\":\"Successor Features for Transfer in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d8686b657b61a37da351af2952aabd8b281de408\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Timothy P. Lillicrap\"},{\"authorId\":null,\"name\":\"Jonathan J. Hunt\"},{\"authorId\":null,\"name\":\"Alexander Pritzel\"},{\"authorId\":null,\"name\":\"Nicolas Heess\"},{\"authorId\":null,\"name\":\"Tom Erez\"},{\"authorId\":null,\"name\":\"Yuval Tassa\"},{\"authorId\":null,\"name\":\"David Silver\"},{\"authorId\":null,\"name\":\"Daan Wierstra. Continuous control with deep reinforceme learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"arXiv\",\"url\":\"\",\"venue\":\"abs/1509.02971,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chao Zhang\"},{\"authorId\":null,\"name\":\"Yang Yu\"},{\"authorId\":null,\"name\":\"Zhi-Hua Zhou. Learning environmental calibration actions f self-evolution\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI\\u201918)\",\"url\":\"\",\"venue\":\"pages 3061\\u20133067, Stockholm, Sweden,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kevin Frans\"},{\"authorId\":null,\"name\":\"Jonathan Ho\"},{\"authorId\":null,\"name\":\"Xi Chen\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"John Schulman. Meta learning shared hierarchies\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 6th International Conference on Learning Representations (ICLR\\u201918)\",\"url\":\"\",\"venue\":\"pages 1\\u2013 8, Vancouver, Canada,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Michael I. Jordan\"},{\"authorId\":null,\"name\":\"PhilippMoritz. Trust region policy optimization\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 32nd International Conference on Machine Learning (ICML\\u201915)\",\"url\":\"\",\"venue\":\"pages 1889\\u20131897, Lille, France,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3379756\",\"name\":\"Yi-Qi Hu\"},{\"authorId\":\"47111884\",\"name\":\"Yang Yu\"},{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.24963/ijcai.2018/315\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"688a1a5fce6a1e31e2c853acace01a365b48cf48\",\"title\":\"Experienced Optimization with Reusable Directional Model for Hyper-Parameter Search\",\"url\":\"https://www.semanticscholar.org/paper/688a1a5fce6a1e31e2c853acace01a365b48cf48\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"},{\"authorId\":\"2830761\",\"name\":\"X. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6cc21b30912bdaecd9f178d700a4c545b1d0838\",\"title\":\"Deep Learning for Real-Time Atari Game Play Using Offline Monte-Carlo Tree Search Planning\",\"url\":\"https://www.semanticscholar.org/paper/b6cc21b30912bdaecd9f178d700a4c545b1d0838\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1703.03400\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c889d6f98e6d79b89c3a6adf8a921f88fa6ba518\",\"title\":\"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518\",\"venue\":\"ICML\",\"year\":2017}],\"title\":\"Reinforcement Learning Experience Reuse with Policy Residual Representation\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Production Rule Representation\",\"topicId\":\"53522\",\"url\":\"https://www.semanticscholar.org/topic/53522\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"AP Computer Science A\",\"topicId\":\"1293197\",\"url\":\"https://www.semanticscholar.org/topic/1293197\"}],\"url\":\"https://www.semanticscholar.org/paper/30e7f96c987c0f8a7cc64ce8a0599a7d31870c05\",\"venue\":\"IJCAI\",\"year\":2019}\n"