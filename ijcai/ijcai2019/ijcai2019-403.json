"{\"abstract\":\"Recent studies have highlighted that deep neural networks (DNNs) are vulnerable to adversarial examples. In this paper, we improve the robustness of DNNs by utilizing techniques of Distance Metric Learning. Specifically, we incorporate Triplet Loss, one of the most popular Distance Metric Learning methods, into the framework of adversarial training. Our proposed algorithm, Adversarial Training with Triplet Loss (AT$^2$L), substitutes the adversarial example against the current model for the anchor of triplet loss to effectively smooth the classification boundary. Furthermore, we propose an ensemble version of AT$^2$L, which aggregates different attack methods and model structures for better defense effects. Our empirical studies verify that the proposed approach can significantly improve the robustness of DNNs without sacrificing accuracy. Finally, we demonstrate that our specially designed triplet loss can also be used as a regularization term to enhance other defense methods.\",\"arxivId\":\"1905.11713\",\"authors\":[{\"authorId\":\"145243623\",\"name\":\"P. Li\",\"url\":\"https://www.semanticscholar.org/author/145243623\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\",\"url\":\"https://www.semanticscholar.org/author/2882166\"},{\"authorId\":\"145218984\",\"name\":\"Bowen Zhou\",\"url\":\"https://www.semanticscholar.org/author/145218984\"},{\"authorId\":\"48571674\",\"name\":\"L. Zhang\",\"url\":\"https://www.semanticscholar.org/author/48571674\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2011.09563\",\"authors\":[{\"authorId\":\"47539646\",\"name\":\"Jiajin Zhang\"},{\"authorId\":\"24038404\",\"name\":\"Hanqing Chao\"},{\"authorId\":\"1690097\",\"name\":\"P. Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9a86fd95946876d44a355bb2c2e4081a90f158\",\"title\":\"Robustified Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/3e9a86fd95946876d44a355bb2c2e4081a90f158\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14672\",\"authors\":[{\"authorId\":\"40894826\",\"name\":\"Muzammal Naseer\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"},{\"authorId\":\"145684318\",\"name\":\"Munawar Hayat\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"b03ccb671fe3432210b1c948c06e25a3e67878f9\",\"title\":\"Stylized Adversarial Defense\",\"url\":\"https://www.semanticscholar.org/paper/b03ccb671fe3432210b1c948c06e25a3e67878f9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.00467\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"98182791\",\"name\":\"Xian Yang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"1739163379\",\"name\":\"Jun Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"title\":\"Bag of Tricks for Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/67f74fe9d46f88661573003f8f1f12967ae49fa3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2002.08619\",\"authors\":[{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"2591451\",\"name\":\"X. Yang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":null,\"name\":\"Kun Xu\"},{\"authorId\":null,\"name\":\"Hang Su\"},{\"authorId\":\"145254056\",\"name\":\"J. Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5b84236178d7805c2e7b503cc6cf4a24b7da626\",\"title\":\"Boosting Adversarial Training with Hypersphere Embedding\",\"url\":\"https://www.semanticscholar.org/paper/d5b84236178d7805c2e7b503cc6cf4a24b7da626\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2003.13969\",\"authors\":[{\"authorId\":\"1602258491\",\"name\":\"Chendi Rao\"},{\"authorId\":\"32879676\",\"name\":\"Jiezhang Cao\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"1819450790\",\"name\":\"Qi Chen\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"98271873\",\"name\":\"Yanwu Xu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09cf8f36eb3fd0295dcae895205f33391ce09c2b\",\"title\":\"A Thorough Comparison Study on Adversarial Attacks and Defenses for Common Thorax Disease Classification in Chest X-rays\",\"url\":\"https://www.semanticscholar.org/paper/09cf8f36eb3fd0295dcae895205f33391ce09c2b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13867206\",\"name\":\"X. Wang\"},{\"authorId\":\"2099254\",\"name\":\"R. Hou\"},{\"authorId\":\"1561664268\",\"name\":\"Boyan Zhao\"},{\"authorId\":\"1563865309\",\"name\":\"Fengkai Yuan\"},{\"authorId\":\"50560888\",\"name\":\"Jun Zhang\"},{\"authorId\":\"144896516\",\"name\":\"D. Meng\"},{\"authorId\":\"2064331\",\"name\":\"Xuehai Qian\"}],\"doi\":\"10.1145/3373376.3378532\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19c61093e89be16073c68f74c42287177023f486\",\"title\":\"DNNGuard: An Elastic Heterogeneous DNN Accelerator Architecture against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/19c61093e89be16073c68f74c42287177023f486\",\"venue\":\"ASPLOS\",\"year\":2020}],\"corpusId\":167217432,\"doi\":\"10.24963/ijcai.2019/403\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"bc696c8b7b507b9e2c72d48b1ba1abaa62bd705d\",\"references\":[{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1709.04114\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"160a03c2890f3ef5436c25ef9b1758faa13807a0\",\"title\":\"EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/160a03c2890f3ef5436c25ef9b1758faa13807a0\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nicolas Papernot\"},{\"authorId\":null,\"name\":\"Patrick McDaniel\"},{\"authorId\":null,\"name\":\"Somesh Jha\"},{\"authorId\":null,\"name\":\"Matt Fredrikson\"},{\"authorId\":null,\"name\":\"Z Berkay Celik\"},{\"authorId\":null,\"name\":\"Ananthram Swami. The limitations of deep learning in adversa settings\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2016 IEEE European Symposium on Security and Privacy\",\"url\":\"\",\"venue\":\"pages 372\\u2013387. IEEE,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d90f06bb70a0a3dced62413346235c02b1aa086\",\"title\":\"Learning Multiple Layers of Features from Tiny Images\",\"url\":\"https://www.semanticscholar.org/paper/5d90f06bb70a0a3dced62413346235c02b1aa086\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Xiaogang Wang. Joint deep learning for pedestrian detection\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE International Conference on Computer Vision\",\"url\":\"\",\"venue\":\"pages 2056\\u20132063,\",\"year\":2013},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1503.03832\",\"authors\":[{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"}],\"doi\":\"10.1109/CVPR.2015.7298682\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5aa26299435bdf7db874ef1640a6c3b5a4a2c394\",\"title\":\"FaceNet: A unified embedding for face recognition and clustering\",\"url\":\"https://www.semanticscholar.org/paper/5aa26299435bdf7db874ef1640a6c3b5a4a2c394\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2970223\",\"name\":\"Zhenlong Yuan\"},{\"authorId\":\"2014146\",\"name\":\"Yongqiang Lu\"},{\"authorId\":\"8491577\",\"name\":\"Zhaoguo Wang\"},{\"authorId\":\"2564865\",\"name\":\"Yibo Xue\"}],\"doi\":\"10.1145/2740070.2631434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3419197b1275e8faae865ca0abeb98f3f13ca433\",\"title\":\"Droid-Sec: deep learning in android malware detection\",\"url\":\"https://www.semanticscholar.org/paper/3419197b1275e8faae865ca0abeb98f3f13ca433\",\"venue\":\"SIGCOMM 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1761691\",\"name\":\"F. Tasse\"},{\"authorId\":\"2377695\",\"name\":\"J. Kosinka\"},{\"authorId\":\"1743917\",\"name\":\"N. Dodgson\"}],\"doi\":\"10.1109/ICCV.2003.1238306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34d7ae9e74ea1531b8409f695f0e22f98fc68db4\",\"title\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/34d7ae9e74ea1531b8409f695f0e22f98fc68db4\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1707.08945\",\"authors\":[{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"1825256\",\"name\":\"Kevin Eykholt\"},{\"authorId\":\"35064352\",\"name\":\"E. Fernandes\"},{\"authorId\":\"1769675\",\"name\":\"T. Kohno\"},{\"authorId\":\"38620893\",\"name\":\"B. Li\"},{\"authorId\":\"49428285\",\"name\":\"Atul Prakash\"},{\"authorId\":\"145416145\",\"name\":\"A. Rahmati\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d295a620fc10a7a656dc693e1b1bf668d1508a8e\",\"title\":\"Robust Physical-World Attacks on Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/d295a620fc10a7a656dc693e1b1bf668d1508a8e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47619311\",\"name\":\"J. Buckman\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"title\":\"Thermometer Encoding: One Hot Way To Resist Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8b9127bee0f7d109da2672ba06d0f39a5a60335a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22229139\",\"name\":\"Ivan Evtimov\"},{\"authorId\":\"1825256\",\"name\":\"Kevin Eykholt\"},{\"authorId\":\"35064352\",\"name\":\"E. Fernandes\"},{\"authorId\":\"1769675\",\"name\":\"T. Kohno\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"49428285\",\"name\":\"Atul Prakash\"},{\"authorId\":\"145416145\",\"name\":\"A. Rahmati\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36a3eed52ff0a694aa73ce6a0d592cb440ed3d31\",\"title\":\"Robust Physical-World Attacks on Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/36a3eed52ff0a694aa73ce6a0d592cb440ed3d31\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1511.04599\",\"authors\":[{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"48036489\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1109/CVPR.2016.282\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"title\":\"DeepFool: A Simple and Accurate Method to Fool Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/52693bcf4627bdbc31734e7f3dbcf5ea7eef4d35\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1803.01442\",\"authors\":[{\"authorId\":\"16404879\",\"name\":\"Guneet S. Dhillon\"},{\"authorId\":\"3371922\",\"name\":\"Kamyar Azizzadenesheli\"},{\"authorId\":\"32219137\",\"name\":\"Zachary Chase Lipton\"},{\"authorId\":\"38267634\",\"name\":\"J. Bernstein\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"19268451\",\"name\":\"A. Khanna\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"title\":\"Stochastic Activation Pruning for Robust Adversarial Defense\",\"url\":\"https://www.semanticscholar.org/paper/2f201c77e7ccdf1f37115e16accac3486a65c03d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pengcheng Li\"},{\"authorId\":null,\"name\":\"Jinfeng Yi\"},{\"authorId\":null,\"name\":\"Lijun Zhang. Query-efficient black-box attack by active learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the 18th IEEE International Conference on Data Mining\",\"url\":\"\",\"venue\":\"pages 1200\\u20131205,\",\"year\":2018},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1602.02697\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1680133\",\"name\":\"S. Jha\"},{\"authorId\":\"144643812\",\"name\":\"Z. Y. Celik\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.1145/3052973.3053009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53b047e503f4c24602f376a774d653f7ed56c024\",\"title\":\"Practical Black-Box Attacks against Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/53b047e503f4c24602f376a774d653f7ed56c024\",\"venue\":\"AsiaCCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jeremy Elson\"},{\"authorId\":null,\"name\":\"John JD Douceur\"},{\"authorId\":null,\"name\":\"Jon Howell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Jared Saul\",\"url\":\"\",\"venue\":\"Asirra: a captcha that exploits interest-aligned manual image categorization.\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yann LeCun. The mnist database of handwritten digits\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"http://yann\",\"url\":\"\",\"venue\":\"lecun. com/exdb/mnist/,\",\"year\":1998},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaojun Xu\"},{\"authorId\":null,\"name\":\"Xinyun Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":null,\"name\":\"Anna Rohrbach\"},{\"authorId\":null,\"name\":\"Trevor Darell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Dawn Song\",\"url\":\"\",\"venue\":\"Can you fool ai with adversarial examples on a visual turing test? arXiv preprint arXiv:1709.08693,\",\"year\":2017},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1706.04701\",\"authors\":[{\"authorId\":\"145551594\",\"name\":\"Warren He\"},{\"authorId\":\"145604979\",\"name\":\"J. Wei\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"title\":\"Adversarial Example Defense: Ensembles of Weak Defenses are not Strong\",\"url\":\"https://www.semanticscholar.org/paper/6f61d15a31d6d051aeee3bf6d1482d332e68ebfe\",\"venue\":\"WOOT\",\"year\":2017}],\"title\":\"Improving the Robustness of Deep Neural Networks via Adversarial Training with Triplet Loss\",\"topics\":[{\"topic\":\"Triplet state\",\"topicId\":\"60687\",\"url\":\"https://www.semanticscholar.org/topic/60687\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Neural network software\",\"topicId\":\"172426\",\"url\":\"https://www.semanticscholar.org/topic/172426\"}],\"url\":\"https://www.semanticscholar.org/paper/bc696c8b7b507b9e2c72d48b1ba1abaa62bd705d\",\"venue\":\"IJCAI\",\"year\":2019}\n"