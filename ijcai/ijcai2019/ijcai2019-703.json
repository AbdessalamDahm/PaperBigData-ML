"{\"abstract\":\"In intelligent speech interaction, automatic speech emotion recognition (SER) plays an important role in understanding user intention. While sentimental speech has different speaker characteristics but similar acoustic attributes, one vital challenge in SER is how to learn robust and discriminative representations for emotion inferring. In this paper, inspired by human emotion perception, we propose a novel representation learning component (RLC) for SER system, which is constructed with Multihead Self-attention and Global Context-aware Attention Long Short-Term Memory Recurrent Neutral Network (GCA-LSTM). With the ability of Multi-head Self-attention mechanism in modeling the element-wise correlative dependencies, RLC can exploit the common patterns of sentimental speech features to enhance emotion-salient information importing in representation learning. By employing GCA-LSTM, RLC can selectively focus on emotion-salient factors with the consideration of entire utterance context, and gradually produce discriminative representation for emotion inferring. Experiments on public emotional benchmark database IEMOCAP and a tremendous realistic interaction database demonstrate the outperformance of the proposed SER framework, with 6.6% to 26.7% relative improvement on unweighted accuracy compared to state-of-the-art techniques.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"9582233\",\"name\":\"Runnan Li\",\"url\":\"https://www.semanticscholar.org/author/9582233\"},{\"authorId\":\"50061417\",\"name\":\"Zhiyong Wu\",\"url\":\"https://www.semanticscholar.org/author/50061417\"},{\"authorId\":\"144202061\",\"name\":\"Jia Jia\",\"url\":\"https://www.semanticscholar.org/author/144202061\"},{\"authorId\":\"3424070\",\"name\":\"Y. Bu\",\"url\":\"https://www.semanticscholar.org/author/3424070\"},{\"authorId\":\"49112958\",\"name\":\"Sheng Zhao\",\"url\":\"https://www.semanticscholar.org/author/49112958\"},{\"authorId\":\"153726255\",\"name\":\"Helen Meng\",\"url\":\"https://www.semanticscholar.org/author/153726255\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"2012.11174\",\"authors\":[{\"authorId\":\"48810457\",\"name\":\"Xiong Cai\"},{\"authorId\":\"50061551\",\"name\":\"Zhiyong Wu\"},{\"authorId\":\"1742084905\",\"name\":\"Kuo Zhong\"},{\"authorId\":\"1456097029\",\"name\":\"Bin Su\"},{\"authorId\":\"5555725\",\"name\":\"Dongyang Dai\"},{\"authorId\":\"1702243\",\"name\":\"H. Meng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"71d0b4df2730a349a6db1cfc24bc02af3c241414\",\"title\":\"Unsupervised Cross-Lingual Speech Emotion Recognition Using DomainAdversarial Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/71d0b4df2730a349a6db1cfc24bc02af3c241414\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"12077195\",\"name\":\"J. Tao\"},{\"authorId\":\"145117682\",\"name\":\"Bin Liu\"},{\"authorId\":\"49024647\",\"name\":\"J. Huang\"},{\"authorId\":\"2146066\",\"name\":\"Zhanlei Yang\"},{\"authorId\":\"2277594\",\"name\":\"Rongjun Li\"}],\"doi\":\"10.21437/interspeech.2020-1705\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"29b972f985c53d960b96a5bf9916cb132c138923\",\"title\":\"Context-Dependent Domain Adversarial Neural Network for Multimodal Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29b972f985c53d960b96a5bf9916cb132c138923\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"},{\"authorId\":\"2392839\",\"name\":\"H. Xu\"},{\"authorId\":\"37216441\",\"name\":\"K. Gao\"}],\"doi\":\"10.1145/3394171.3413690\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"773d51dbb619a167102f75d93f39582a67c24c82\",\"title\":\"CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/773d51dbb619a167102f75d93f39582a67c24c82\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.02598\",\"authors\":[{\"authorId\":\"1557401586\",\"name\":\"Jingjun Liang\"},{\"authorId\":\"83895120\",\"name\":\"Ruichen Li\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413579\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0e5cc1e564501de32de97845c7405626781a413\",\"title\":\"Semi-supervised Multi-modal Emotion Recognition with Cross-Modal Distribution Matching\",\"url\":\"https://www.semanticscholar.org/paper/d0e5cc1e564501de32de97845c7405626781a413\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1910.13807\",\"authors\":[{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"47060742\",\"name\":\"J. Tao\"},{\"authorId\":\"145117682\",\"name\":\"Bin Liu\"},{\"authorId\":\"117578373\",\"name\":\"J. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0979d6a17eaed78a504dddae1a4ff1d32a85eb3\",\"title\":\"Domain adversarial learning for emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0979d6a17eaed78a504dddae1a4ff1d32a85eb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134909283\",\"name\":\"Zengwei Yao\"},{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"11599313\",\"name\":\"Weihuang Liu\"},{\"authorId\":\"46398270\",\"name\":\"Y. Liu\"},{\"authorId\":\"7588999\",\"name\":\"J. Pan\"}],\"doi\":\"10.1016/j.specom.2020.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6acfa3b9302c59c708233c512b94f4e07accc1ba\",\"title\":\"Speech emotion recognition using fusion of three multi-task learning-based classifiers: HSF-DNN, MS-CNN and LLD-RNN\",\"url\":\"https://www.semanticscholar.org/paper/6acfa3b9302c59c708233c512b94f4e07accc1ba\",\"venue\":\"Speech Commun.\",\"year\":2020}],\"corpusId\":198939922,\"doi\":\"10.24963/ijcai.2019/703\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":false,\"paperId\":\"91fc524fb77ab183e3d3b8e0cfb4caeac6304cf0\",\"references\":[{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"2010.16061\",\"authors\":[{\"authorId\":\"144871539\",\"name\":\"D. Powers\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d03a38c5ddb7c7cd1ceb59b28907dc918c5d83a\",\"title\":\"Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation\",\"url\":\"https://www.semanticscholar.org/paper/6d03a38c5ddb7c7cd1ceb59b28907dc918c5d83a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1732747\",\"name\":\"S. Steidl\"},{\"authorId\":\"1745089\",\"name\":\"A. Batliner\"},{\"authorId\":\"3376540\",\"name\":\"Elika Bergelson\"},{\"authorId\":\"34030213\",\"name\":\"J. Krajewski\"},{\"authorId\":\"3403921\",\"name\":\"C. Janott\"},{\"authorId\":\"34834003\",\"name\":\"Andrei Amatuni\"},{\"authorId\":\"40266238\",\"name\":\"M. Casillas\"},{\"authorId\":\"2360038\",\"name\":\"A. Seidl\"},{\"authorId\":\"48453567\",\"name\":\"M. Soderstrom\"},{\"authorId\":\"2510340\",\"name\":\"A. Warlaumont\"},{\"authorId\":\"144943413\",\"name\":\"G. Hidalgo\"},{\"authorId\":\"1995029\",\"name\":\"S. Schnieder\"},{\"authorId\":\"3403347\",\"name\":\"C. Heiser\"},{\"authorId\":\"12816361\",\"name\":\"W. Hohenhorst\"},{\"authorId\":\"145892389\",\"name\":\"M. Herzog\"},{\"authorId\":\"144465731\",\"name\":\"M. Schmitt\"},{\"authorId\":\"143857308\",\"name\":\"Kun Qian\"},{\"authorId\":\"39509609\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2814229\",\"name\":\"George Trigeorgis\"},{\"authorId\":\"2829366\",\"name\":\"Panagiotis Tzirakis\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.21437/INTERSPEECH.2017-43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58c87d2d678aab8bccd5cb20d04bc867682b07f2\",\"title\":\"The INTERSPEECH 2017 Computational Paralinguistics Challenge: Addressee, Cold & Snoring\",\"url\":\"https://www.semanticscholar.org/paper/58c87d2d678aab8bccd5cb20d04bc867682b07f2\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"38816202\",\"name\":\"M. Bulut\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"},{\"authorId\":\"1764265\",\"name\":\"A. Kazemzadeh\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"},{\"authorId\":\"48388640\",\"name\":\"S. Kim\"},{\"authorId\":\"2522842\",\"name\":\"J. N. Chang\"},{\"authorId\":\"1797399\",\"name\":\"S. Lee\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1007/s10579-008-9076-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cf0d213f3253cd46673d955209f8463db73cc51\",\"title\":\"IEMOCAP: interactive emotional dyadic motion capture database\",\"url\":\"https://www.semanticscholar.org/paper/5cf0d213f3253cd46673d955209f8463db73cc51\",\"venue\":\"Lang. Resour. Evaluation\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1693461\",\"name\":\"Ping Hu\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1109/CVPR.2017.391\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2630bf9c818406ee951d5737f532a27aa21ad9f5\",\"title\":\"Global Context-Aware Attention LSTM Networks for 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2630bf9c818406ee951d5737f532a27aa21ad9f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145288124\",\"name\":\"M. Baillie\"},{\"authorId\":\"1716332\",\"name\":\"L. Azzopardi\"},{\"authorId\":\"145876066\",\"name\":\"F. Crestani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"489454cbb59c768624dd9ddb98ad33cf2f3e946c\",\"title\":\"Proceedings of the 2006 ACM symposium on Applied computing\",\"url\":\"https://www.semanticscholar.org/paper/489454cbb59c768624dd9ddb98ad33cf2f3e946c\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Annett Schirmer\"},{\"authorId\":null,\"name\":\"Ralph Adolphs\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Global context - aware attention lstm networks for 3 d action recognition Convolutional mkl based multimodal emotion recognition and sentiment analysis\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7748129\",\"name\":\"M. Steinschneider\"},{\"authorId\":\"2102501\",\"name\":\"K. Nourski\"},{\"authorId\":\"6683107\",\"name\":\"Y. Fishman\"}],\"doi\":\"10.1016/j.heares.2013.05.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d416a7d3a8d7d25276e65e129e508156f45903d8\",\"title\":\"Representation of speech in human auditory cortex: Is it special?\",\"url\":\"https://www.semanticscholar.org/paper/d416a7d3a8d7d25276e65e129e508156f45903d8\",\"venue\":\"Hearing Research\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2814229\",\"name\":\"George Trigeorgis\"},{\"authorId\":\"2124680\",\"name\":\"Fabien Ringeval\"},{\"authorId\":\"40384275\",\"name\":\"R. Brueckner\"},{\"authorId\":\"1779097\",\"name\":\"E. Marchi\"},{\"authorId\":\"1752913\",\"name\":\"Mihalis A. Nicolaou\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/ICASSP.2016.7472669\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96d27c4e487de191a17476a9775a51678a879d18\",\"title\":\"Adieu features? End-to-end speech emotion recognition using a deep convolutional recurrent network\",\"url\":\"https://www.semanticscholar.org/paper/96d27c4e487de191a17476a9775a51678a879d18\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117879557\",\"name\":\"Tali Arad\"}],\"doi\":\"10.1300/j146v10n01_02\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"977f0eb1b53427b0b39cdac7aa9a315d3ca7169a\",\"title\":\"Voice\",\"url\":\"https://www.semanticscholar.org/paper/977f0eb1b53427b0b39cdac7aa9a315d3ca7169a\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"},{\"authorId\":\"143871289\",\"name\":\"S. Ananthakrishnan\"},{\"authorId\":\"1808737\",\"name\":\"S. Saleem\"},{\"authorId\":\"143815072\",\"name\":\"Rohit Kumar\"},{\"authorId\":\"36073757\",\"name\":\"Rohit Prasad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"038ee4737a02bcb609926f036f922aa414df6b13\",\"title\":\"Ensemble of SVM trees for multimodal emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/038ee4737a02bcb609926f036f922aa414df6b13\",\"venue\":\"Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference\",\"year\":2012},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1081\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"title\":\"Context-Dependent Sentiment Analysis in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Lee\"},{\"authorId\":null,\"name\":\"Tashev\"},{\"authorId\":null,\"name\":\"2015 Jinkyu Lee\"},{\"authorId\":null,\"name\":\"Ivan Tashev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Highlevel feature representation using recurrent neural network for speech emotion recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144304984\",\"name\":\"Rui Xia\"},{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/TAFFC.2015.2512598\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"052e4fe0b28297da3fd1dfb54134c77e7e09aada\",\"title\":\"A Multi-Task Learning Framework for Emotion Recognition Using 2D Continuous Space\",\"url\":\"https://www.semanticscholar.org/paper/052e4fe0b28297da3fd1dfb54134c77e7e09aada\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaiming He\"},{\"authorId\":null,\"name\":\"Xiangyu Zhang\"},{\"authorId\":null,\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun. Deep residual learning for image recognition\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE conference on computer vision and pattern recognition\",\"url\":\"\",\"venue\":\"pages 770\\u2013778,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2111113\",\"name\":\"A. Stuhlsatz\"},{\"authorId\":\"145985961\",\"name\":\"C. Meyer\"},{\"authorId\":\"1751126\",\"name\":\"F. Eyben\"},{\"authorId\":\"145714451\",\"name\":\"Thomas Zielke\"},{\"authorId\":\"39430196\",\"name\":\"H. Meier\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1109/ICASSP.2011.5947651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09777b14e073db61ac6e5ecae45a6c25b1c22cbd\",\"title\":\"Deep neural networks for acoustic emotion recognition: Raising the benchmarks\",\"url\":\"https://www.semanticscholar.org/paper/09777b14e073db61ac6e5ecae45a6c25b1c22cbd\",\"venue\":\"2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Soujanya Poria\"},{\"authorId\":null,\"name\":\"Iti Chaturvedi\"},{\"authorId\":null,\"name\":\"Erik Cambria\"},{\"authorId\":null,\"name\":\"Amir Hussain. Convolutional mkl based multimodal emotio recognition\"},{\"authorId\":null,\"name\":\"sentiment analysis. In Proceedings of the IEEE International Mining\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"pages 439\\u2013448\",\"url\":\"\",\"venue\":\"IEEE,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheng Lian\"},{\"authorId\":null,\"name\":\"Ya Li\"},{\"authorId\":null,\"name\":\"Jianhua Tao\"},{\"authorId\":null,\"name\":\"Jian Huang. Improving speech emotion recognition via tr learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1811.07691,\",\"year\":2018},{\"arxivId\":\"1811.07691\",\"authors\":[{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"145819440\",\"name\":\"Ya Li\"},{\"authorId\":\"37670752\",\"name\":\"J. Tao\"},{\"authorId\":\"50535672\",\"name\":\"Jian Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"204c07b2452c17187887c68f2fb9d2fedd0d19c2\",\"title\":\"Improving speech emotion recognition via Transformer-based Predictive Coding through transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/204c07b2452c17187887c68f2fb9d2fedd0d19c2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759817\",\"name\":\"A. Schirmer\"},{\"authorId\":\"46306086\",\"name\":\"R. Adolphs\"}],\"doi\":\"10.1016/j.tics.2017.01.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9057e20e9806f9b14a1d29d57cf7553f7cd56838\",\"title\":\"Emotion Perception from Face, Voice, and Touch: Comparisons and Convergence\",\"url\":\"https://www.semanticscholar.org/paper/9057e20e9806f9b14a1d29d57cf7553f7cd56838\",\"venue\":\"Trends in Cognitive Sciences\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2536431\",\"name\":\"Seyedmahdad Mirsamadi\"},{\"authorId\":\"47223178\",\"name\":\"E. Barsoum\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/ICASSP.2017.7952552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b44b751db2b6f6ef662f517e9a01e055c6e337a8\",\"title\":\"Automatic speech emotion recognition using recurrent neural networks with local attention\",\"url\":\"https://www.semanticscholar.org/paper/b44b751db2b6f6ef662f517e9a01e055c6e337a8\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1910.14537\",\"authors\":[{\"authorId\":\"9359742\",\"name\":\"Sufeng Duan\"},{\"authorId\":\"97628269\",\"name\":\"Hai Zhao\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.317\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8752d24336f79569a461ad44eb05748a3055f479\",\"title\":\"Attention Is All You Need for Chinese Word Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8752d24336f79569a461ad44eb05748a3055f479\",\"venue\":\"EMNLP\",\"year\":2020}],\"title\":\"Towards Discriminative Representation Learning for Speech Emotion Recognition\",\"topics\":[{\"topic\":\"Emotion recognition\",\"topicId\":\"68560\",\"url\":\"https://www.semanticscholar.org/topic/68560\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"RLC circuit\",\"topicId\":\"269737\",\"url\":\"https://www.semanticscholar.org/topic/269737\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/91fc524fb77ab183e3d3b8e0cfb4caeac6304cf0\",\"venue\":\"IJCAI\",\"year\":2019}\n"