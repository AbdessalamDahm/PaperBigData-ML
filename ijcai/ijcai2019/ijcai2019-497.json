"{\"abstract\":\"Classically, imitation learning algorithms have been developed for idealized situations, e.g., the demonstrations are often required to be collected in the exact same environment and usually include the demonstrator's actions. Recently, however, the research community has begun to address some of these shortcomings by offering algorithmic solutions that enable imitation learning from observation (IfO), e.g., learning to perform a task from visual demonstrations that may be in a different environment and do not include actions. Motivated by the fact that agents often also have access to their own internal states (i.e., proprioception), we propose and study an IfO algorithm that leverages this information in the policy learning process. The proposed architecture learns policies over proprioceptive state representations and compares the resulting trajectories visually to the demonstration data. We experimentally test the proposed technique on several MuJoCo domains and show that it outperforms other imitation from observation algorithms by a large margin.\",\"arxivId\":\"1905.09335\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\",\"url\":\"https://www.semanticscholar.org/author/46221670\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\",\"url\":\"https://www.semanticscholar.org/author/1938253\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\",\"url\":\"https://www.semanticscholar.org/author/144848112\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1906.07374\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"153552310\",\"name\":\"S. Geiger\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d308dd89c1efb1e3b604fe79ce8ebefa564a4a9a\",\"title\":\"Sample-efficient Adversarial Imitation Learning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/d308dd89c1efb1e3b604fe79ce8ebefa564a4a9a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.09906\",\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"144190085\",\"name\":\"L. Guan\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2019/884\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bd453ea1e4655311cb1172f7a188cb9c5ee367d\",\"title\":\"Leveraging Human Guidance for Deep Reinforcement Learning Tasks\",\"url\":\"https://www.semanticscholar.org/paper/9bd453ea1e4655311cb1172f7a188cb9c5ee367d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1906.07372\",\"authors\":[{\"authorId\":\"137071348\",\"name\":\"Brahma S. Pavse\"},{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"34719248\",\"name\":\"Josiah P. Hanna\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1109/LRA.2020.3010750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fff2bcc0348dffdb7661640d51738d4716a6304c\",\"title\":\"RIDM: Reinforced Inverse Dynamics Modeling for Learning from a Single Observed Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/fff2bcc0348dffdb7661640d51738d4716a6304c\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486440762\",\"name\":\"K. Ramachandruni\"},{\"authorId\":\"30779954\",\"name\":\"M. Vankadari\"},{\"authorId\":\"1380965321\",\"name\":\"Anima Majumder\"},{\"authorId\":\"1486144212\",\"name\":\"Samrat Dutta\"},{\"authorId\":\"48084237\",\"name\":\"S. Kumar\"}],\"doi\":\"10.1109/ICRA40945.2020.9197544\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7cca565d47880e83b3dc409501ad8bded27993a\",\"title\":\"Attentive Task-Net: Self Supervised Task-Attention Network for Imitation Learning using Video Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/a7cca565d47880e83b3dc409501ad8bded27993a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2004.13529\",\"authors\":[{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"1660809827\",\"name\":\"Nathan Gavenski\"},{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207672\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cc12fe047e4d54577c11c6bc8acebffa07a26b5\",\"title\":\"Augmented Behavioral Cloning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/1cc12fe047e4d54577c11c6bc8acebffa07a26b5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1905.13566\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2019/882\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbcbdb44d9d4ad7bb6bf4e9104653aa7623a17c5\",\"title\":\"Recent Advances in Imitation Learning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/cbcbdb44d9d4ad7bb6bf4e9104653aa7623a17c5\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2011.06507\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a83e5050f389606091ca1d38532ccfd832ff13\",\"title\":\"Reinforcement Learning with Videos: Combining Offline Observations with Interaction\",\"url\":\"https://www.semanticscholar.org/paper/a9a83e5050f389606091ca1d38532ccfd832ff13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.04417\",\"authors\":[{\"authorId\":\"143702931\",\"name\":\"C. Yang\"},{\"authorId\":\"121875989\",\"name\":\"Xiaojian Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"145433219\",\"name\":\"Huaping Liu\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6a479e39218a381c9911df24583058c4f283890\",\"title\":\"Imitation Learning from Observations by Minimizing Inverse Dynamics Disagreement\",\"url\":\"https://www.semanticscholar.org/paper/b6a479e39218a381c9911df24583058c4f283890\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2006.08051\",\"authors\":[{\"authorId\":\"152241734\",\"name\":\"Yuda Song\"},{\"authorId\":\"38792754\",\"name\":\"Aditi Mavalankar\"},{\"authorId\":\"22578070\",\"name\":\"W. Sun\"},{\"authorId\":\"39219411\",\"name\":\"Sicun Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b98f32429eecab610c0c150c111beb95af092d65\",\"title\":\"Provably Efficient Model-based Policy Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/b98f32429eecab610c0c150c111beb95af092d65\",\"venue\":\"ICML\",\"year\":2020}],\"corpusId\":162184018,\"doi\":\"10.24963/ijcai.2019/497\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"1706cc1c2433275fc326967da8318790378da850\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arjovsky et al\"},{\"authorId\":null,\"name\":\"2017 Martin Arjovsky\"},{\"authorId\":null,\"name\":\"Soumith Chintala\"},{\"authorId\":null,\"name\":\"L\\u00e9on Bottou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Wasserstein generative adversarial\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yusuf Aytar\"},{\"authorId\":null,\"name\":\"Tobias Pfaff\"},{\"authorId\":null,\"name\":\"David Budden\"},{\"authorId\":null,\"name\":\"Thomas Paine\"},{\"authorId\":null,\"name\":\"Ziyu Wang\"},{\"authorId\":null,\"name\":\"Nando de Freitas. Playing hard exploration games by watc youtube\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NeurIPS\",\"url\":\"\",\"venue\":\"pages 2935\\u20132945,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"St\\u00e9phane Ross\"},{\"authorId\":null,\"name\":\"Geoffrey J Gordon\"},{\"authorId\":null,\"name\":\"Drew Bagnell. A reduction of imitation learning\"},{\"authorId\":null,\"name\":\"structured prediction to no-regret online learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Artificial Intelligence and Statistics\",\"url\":\"\",\"venue\":\"pages 627\\u2013635,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735414\",\"name\":\"T. Knasel\"}],\"doi\":\"10.1016/0921-8890(88)90002-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd77f310393f521669b209cbb6828fb45a8485d\",\"title\":\"Robotics and autonomous systems\",\"url\":\"https://www.semanticscholar.org/paper/edd77f310393f521669b209cbb6828fb45a8485d\",\"venue\":\"Robotics Auton. Syst.\",\"year\":1988},{\"arxivId\":\"1011.0686\",\"authors\":[{\"authorId\":\"1700433\",\"name\":\"S. Ross\"},{\"authorId\":\"21889436\",\"name\":\"G. Gordon\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"79ab3c49903ec8cb339437ccf5cf998607fc313e\",\"title\":\"A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning\",\"url\":\"https://www.semanticscholar.org/paper/79ab3c49903ec8cb339437ccf5cf998607fc313e\",\"venue\":\"AISTATS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Faraz Torabi\"},{\"authorId\":null,\"name\":\"Garrett Warnell\"},{\"authorId\":null,\"name\":\"Peter Stone. Generative adversarial imitation from obser Imitation\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Intent\",\"url\":\"\",\"venue\":\"and Interaction (I3),\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"YuXuan Liu\"},{\"authorId\":null,\"name\":\"Abhishek Gupta\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Sergey Levine\",\"url\":\"\",\"venue\":\"Imitation from observation: Learning to imitate behaviors from raw video via context translation.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32326232\",\"name\":\"Mor Vered\"},{\"authorId\":\"1725049\",\"name\":\"G. Kaminka\"},{\"authorId\":\"151370638\",\"name\":\"Sivan Biham\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb23f981014549d795bb8da41eb04e9a4f5ee934\",\"title\":\"Online goal recognition through mirroring: humans and agents\",\"url\":\"https://www.semanticscholar.org/paper/bb23f981014549d795bb8da41eb04e9a4f5ee934\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Andrew Y Ng. Apprenticeship learning via inverse reinforc learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"page 1\",\"url\":\"\",\"venue\":\"ACM,\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70092712\",\"name\":\"J. Shepherdson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef6402824bc7a5cfa8b4709f5e766eb39e2132f5\",\"title\":\"Machine Intelligence 15\",\"url\":\"https://www.semanticscholar.org/paper/ef6402824bc7a5cfa8b4709f5e766eb39e2132f5\",\"venue\":\"\",\"year\":1998},{\"arxivId\":\"1807.06158\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f1f8330cddf1f4bf7bd73478223e5c02b69a1ff\",\"title\":\"Generative Adversarial Imitation from Observation\",\"url\":\"https://www.semanticscholar.org/paper/1f1f8330cddf1f4bf7bd73478223e5c02b69a1ff\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.06711\",\"authors\":[{\"authorId\":\"40229316\",\"name\":\"Takayuki Osa\"},{\"authorId\":\"34906504\",\"name\":\"J. Pajarinen\"},{\"authorId\":\"26599977\",\"name\":\"G. Neumann\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":\"10.1561/2300000053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d6adaa16ed0af9935a1130a305c85e8bdf8780d\",\"title\":\"An Algorithmic Perspective on Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8d6adaa16ed0af9935a1130a305c85e8bdf8780d\",\"venue\":\"Found. Trends Robotics\",\"year\":2018},{\"arxivId\":\"1805.01954\",\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.24963/ijcai.2018/687\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc2fb12eaa4dae74c5de0799b29624b5c585c43b\",\"title\":\"Behavioral Cloning from Observation\",\"url\":\"https://www.semanticscholar.org/paper/cc2fb12eaa4dae74c5de0799b29624b5c585c43b\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Greg Brockman\"},{\"authorId\":null,\"name\":\"Vicki Cheung\"},{\"authorId\":null,\"name\":\"Ludwig Pettersson\"},{\"authorId\":null,\"name\":\"Jonas Schneider\"},{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Jie Tang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Wojciech Zaremba\",\"url\":\"\",\"venue\":\"OpenAI Gym,\",\"year\":2016},{\"arxivId\":\"1809.02925\",\"authors\":[{\"authorId\":\"2000906\",\"name\":\"Ilya Kostrikov\"},{\"authorId\":\"6565766\",\"name\":\"Kumar Krishna Agrawal\"},{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1de1e749668a65cf6b88b8138389581108bb129a\",\"title\":\"Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1de1e749668a65cf6b88b8138389581108bb129a\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1707.06347\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143909660\",\"name\":\"F. Wolski\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"title\":\"Proximal Policy Optimization Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13693897\",\"name\":\"Nathan D. Ratliff\"},{\"authorId\":\"1735293\",\"name\":\"D. Bradley\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"1751288\",\"name\":\"J. Chestnutt\"}],\"doi\":\"10.7551/mitpress/7503.003.0149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9452a000f05bc6c52bf8d2e34e086fc60fa1999\",\"title\":\"Boosting Structured Prediction for Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a9452a000f05bc6c52bf8d2e34e086fc60fa1999\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Michael Bain\"},{\"authorId\":null,\"name\":\"Claude Sammut\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A framework for behavioral cloning\",\"url\":\"\",\"venue\":\"Machine Intelligence 14,\",\"year\":1995},{\"arxivId\":\"1906.07372\",\"authors\":[{\"authorId\":\"137071348\",\"name\":\"Brahma S. Pavse\"},{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"34719248\",\"name\":\"Josiah P. Hanna\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":\"10.1109/LRA.2020.3010750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fff2bcc0348dffdb7661640d51738d4716a6304c\",\"title\":\"RIDM: Reinforced Inverse Dynamics Modeling for Learning from a Single Observed Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/fff2bcc0348dffdb7661640d51738d4716a6304c\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Faraz Torabi\"},{\"authorId\":null,\"name\":\"Garrett Warnell\"},{\"authorId\":null,\"name\":\"Peter Stone. Behavioral cloning from observation\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 4950\\u20134957,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1727849\",\"name\":\"S. Hanson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69d7086300e7f5322c06f2f242a565b3a182efb5\",\"title\":\"In Advances in Neural Information Processing Systems\",\"url\":\"https://www.semanticscholar.org/paper/69d7086300e7f5322c06f2f242a565b3a182efb5\",\"venue\":\"NIPS 1990\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Erwin Coumans\"},{\"authorId\":null,\"name\":\"Yunfei Bai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pybullet, a python module for physics simulation for games, robotics and machine\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46221670\",\"name\":\"F. Torabi\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"92bfa173e091c0340497fb8c1143a1df3c6f1dfd\",\"title\":\"Adversarial Imitation Learning from State-only Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/92bfa173e091c0340497fb8c1143a1df3c6f1dfd\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shreyansh Daftry\"},{\"authorId\":null,\"name\":\"J Andrew Bagnell\"},{\"authorId\":null,\"name\":\"Martial Hebert. Learning transferable policies for monocul Robotics\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"pages 3\\u201311\",\"url\":\"\",\"venue\":\"Springer,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Faraz Torabi\"},{\"authorId\":null,\"name\":\"Garrett Warnell\"},{\"authorId\":null,\"name\":\"Peter Stone. Recent advances in imitation learning from observation\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"AAAI Press,\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1502.05477\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdc28dc084af6507e979767755e99fe0b46b39\",\"title\":\"Trust Region Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/66cdc28dc084af6507e979767755e99fe0b46b39\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mor Vered\"},{\"authorId\":null,\"name\":\"Ramon Fraga Pereira\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Maur\\u0131\\u0301cio C Magnaguagno\",\"url\":\"\",\"venue\":\"Gal A Kaminka, and Felipe Meneguzzi. Towards online goal recognition combining goal mirroring and landmarks. In AAMAS, pages 2112\\u2013 2114,\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32326232\",\"name\":\"Mor Vered\"},{\"authorId\":\"34096735\",\"name\":\"R. Pereira\"},{\"authorId\":\"1978841\",\"name\":\"M. C. Magnaguagno\"},{\"authorId\":\"1725049\",\"name\":\"G. Kaminka\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"522fad17245168bdb51af03bb6c3f88f10e9bb84\",\"title\":\"Towards Online Goal Recognition Combining Goal Mirroring and Landmarks\",\"url\":\"https://www.semanticscholar.org/paper/522fad17245168bdb51af03bb6c3f88f10e9bb84\",\"venue\":\"AAMAS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Faraz Torabi\"},{\"authorId\":null,\"name\":\"Garrett Warnell\"},{\"authorId\":null,\"name\":\"Peter Stone\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Imitation learning from video by leveraging proprioception\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1905.09335,\",\"year\":2019},{\"arxivId\":\"1809.06404\",\"authors\":[{\"authorId\":\"1711521\",\"name\":\"A. H. Qureshi\"},{\"authorId\":\"35860894\",\"name\":\"Michael C. Yip\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bfcfb31bf1079c2a2ec838c42e11733f451f022\",\"title\":\"Adversarial Imitation via Variational Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3bfcfb31bf1079c2a2ec838c42e11733f451f022\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Faraz Torabi\"},{\"authorId\":null,\"name\":\"Garrett Warnell\"},{\"authorId\":null,\"name\":\"Peter Stone. Behavioral cloning from observation. In Pro Intelligence\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"IJCAI-18\",\"url\":\"\",\"venue\":\"pages 4950\\u2013 4957,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144919054\",\"name\":\"M. Brainin\"}],\"doi\":\"10.1016/j.jns.2019.10.016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36db3a800f96f160b1a1b1ff9997af0d773f5006\",\"title\":\"Cognition\",\"url\":\"https://www.semanticscholar.org/paper/36db3a800f96f160b1a1b1ff9997af0d773f5006\",\"venue\":\"Journal of the Neurological Sciences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Schulman\"},{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Pieter Abbeel\"},{\"authorId\":null,\"name\":\"Michael Jordan\"},{\"authorId\":null,\"name\":\"Philipp Moritz. Trust region policy optimization\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 1889\\u20131897,\",\"year\":2015},{\"arxivId\":\"1608.00627\",\"authors\":[{\"authorId\":\"2739544\",\"name\":\"Shreyansh Daftry\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-50115-4_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e0540ea3c3cc8cd009b2006d96c4b3ac2a84e52\",\"title\":\"Learning Transferable Policies for Monocular Reactive MAV Control\",\"url\":\"https://www.semanticscholar.org/paper/8e0540ea3c3cc8cd009b2006d96c4b3ac2a84e52\",\"venue\":\"ISER\",\"year\":2016},{\"arxivId\":\"1707.02201\",\"authors\":[{\"authorId\":\"1879232\",\"name\":\"J. Merel\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"22216833\",\"name\":\"TB Dhruva\"},{\"authorId\":\"144999731\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"144083287\",\"name\":\"Jay Lemmon\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6e01f580c973d91f6445d839389f9f2d5efc78e\",\"title\":\"Learning human behaviors from motion capture by adversarial imitation\",\"url\":\"https://www.semanticscholar.org/paper/e6e01f580c973d91f6445d839389f9f2d5efc78e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69364037\",\"name\":\"F. Sasaki\"},{\"authorId\":\"151239870\",\"name\":\"Tetsuya Yohira\"},{\"authorId\":\"3144141\",\"name\":\"A. Kawaguchi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21946808f15dab6c73a76e89d1fa5869df515a3f\",\"title\":\"Sample Efficient Imitation Learning for Continuous Control\",\"url\":\"https://www.semanticscholar.org/paper/21946808f15dab6c73a76e89d1fa5869df515a3f\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"JA Bagnell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Joel Chestnutt\",\"url\":\"\",\"venue\":\"David M Bradley, and Nathan D Ratliff. Boosting structured prediction for imitation learning. In Advances in Neural Information Processing Systems, pages 1153\\u20131160\",\"year\":2007},{\"arxivId\":\"1505.07818\",\"authors\":[{\"authorId\":\"2825246\",\"name\":\"Yaroslav Ganin\"},{\"authorId\":\"145754674\",\"name\":\"E. Ustinova\"},{\"authorId\":\"2780075\",\"name\":\"Hana Ajakan\"},{\"authorId\":\"31580144\",\"name\":\"P. Germain\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"2482151\",\"name\":\"F. Laviolette\"},{\"authorId\":\"143858557\",\"name\":\"M. Marchand\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":\"10.1007/978-3-319-58347-1_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d5972b32a9b5a455a6eef389de5b7fca25771ad\",\"title\":\"Domain-Adversarial Training of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d5972b32a9b5a455a6eef389de5b7fca25771ad\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":\"1710.11248\",\"authors\":[{\"authorId\":\"2550764\",\"name\":\"Justin Fu\"},{\"authorId\":\"27649809\",\"name\":\"Katie Luo\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e2c4e7b3302549b3718601c44d9af6c7554efef\",\"title\":\"Learning Robust Rewards with Adversarial Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/5e2c4e7b3302549b3718601c44d9af6c7554efef\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.11592\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2054956\",\"name\":\"T. Pfaff\"},{\"authorId\":\"2508525\",\"name\":\"D. Budden\"},{\"authorId\":\"145757542\",\"name\":\"T. Paine\"},{\"authorId\":\"47197117\",\"name\":\"Ziyu Wang\"},{\"authorId\":\"1737568\",\"name\":\"N. D. Freitas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"705bbc4dcd475f9230863771da6596e1f677a92d\",\"title\":\"Playing hard exploration games by watching YouTube\",\"url\":\"https://www.semanticscholar.org/paper/705bbc4dcd475f9230863771da6596e1f677a92d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.11244\",\"authors\":[{\"authorId\":\"3461969\",\"name\":\"Wonjoon Goo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":\"10.1109/ICRA.2019.8793515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7a5bd4faa9ba10e31e0e1b00acc520fb836919c\",\"title\":\"One-Shot Learning of Multi-Step Tasks from Observation via Activity Localization in Auxiliary Video\",\"url\":\"https://www.semanticscholar.org/paper/c7a5bd4faa9ba10e31e0e1b00acc520fb836919c\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144832491\",\"name\":\"E. Todorov\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"}],\"doi\":\"10.1109/IROS.2012.6386109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"title\":\"MuJoCo: A physics engine for model-based control\",\"url\":\"https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"2726592\",\"name\":\"Jasmine Hsu\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/CVPRW.2017.69\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"77712d113a62caa83d6330360ce99d6a5f47bd6a\",\"title\":\"Time-Contrastive Networks: Self-Supervised Learning from Multi-view Observation\",\"url\":\"https://www.semanticscholar.org/paper/77712d113a62caa83d6330360ce99d6a5f47bd6a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1703.01703\",\"authors\":[{\"authorId\":\"3275284\",\"name\":\"Bradly C. Stadie\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e1a1b9c2e8feeb31c6855292859bf94101e8382\",\"title\":\"Third-Person Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2e1a1b9c2e8feeb31c6855292859bf94101e8382\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1703.02949\",\"authors\":[{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"49421394\",\"name\":\"Yuxuan Liu\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9f8a1a9a5aec3dcdd155c4594f25274f6418e11\",\"title\":\"Learning Invariant Feature Spaces to Transfer Skills with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9f8a1a9a5aec3dcdd155c4594f25274f6418e11\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1805.07914\",\"authors\":[{\"authorId\":\"48779623\",\"name\":\"A. Edwards\"},{\"authorId\":\"34594615\",\"name\":\"Himanshu Sahni\"},{\"authorId\":\"3403061\",\"name\":\"Yannick Schroecker\"},{\"authorId\":\"1787816\",\"name\":\"C. Isbell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"395ea8a62d84c8dd85a8dadfc3043cf2228e38c5\",\"title\":\"Imitating Latent Policies from Observation\",\"url\":\"https://www.semanticscholar.org/paper/395ea8a62d84c8dd85a8dadfc3043cf2228e38c5\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Martin Arjovsky\"},{\"authorId\":null,\"name\":\"Soumith Chintala\"},{\"authorId\":null,\"name\":\"L\\u00e9on Bottou. Wasserstein generative adversarial networks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 214\\u2013223,\",\"year\":2017}],\"title\":\"Imitation Learning from Video by Leveraging Proprioception\",\"topics\":[{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"Sample complexity\",\"topicId\":\"112440\",\"url\":\"https://www.semanticscholar.org/topic/112440\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Programming paradigm\",\"topicId\":\"29522\",\"url\":\"https://www.semanticscholar.org/topic/29522\"},{\"topic\":\"Robot\",\"topicId\":\"6657\",\"url\":\"https://www.semanticscholar.org/topic/6657\"}],\"url\":\"https://www.semanticscholar.org/paper/1706cc1c2433275fc326967da8318790378da850\",\"venue\":\"IJCAI\",\"year\":2019}\n"