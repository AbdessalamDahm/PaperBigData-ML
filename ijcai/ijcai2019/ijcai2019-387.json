"{\"abstract\":\"Despite significant progress, deep reinforcement learning (RL) suffers from data-inefficiency and limited generalization. Recent efforts apply meta-learning to learn a meta-learner from a set of RL tasks such that a novel but related task could be solved quickly. Though specific in some ways, different tasks in meta-RL are generally similar at a high level. However, most meta-RL methods do not explicitly and adequately model the specific and shared information among different tasks, which limits their ability to learn training tasks and to generalize to novel tasks. In this paper, we propose to capture the shared information on the one hand and meta-learn how to quickly abstract the specific information about a task on the other hand. Methodologically, we train an SGD meta-learner to quickly optimize a task encoder for each task, which generates a task embedding based on past experience. Meanwhile, we learn a policy which is shared across all tasks and conditioned on task embeddings. Empirical results on four simulated tasks demonstrate that our method has better learning capacity on both training and novel tasks and attains up to 3 to 4 times higher returns compared to baselines.\",\"arxivId\":\"1905.06527\",\"authors\":[{\"authorId\":\"49409772\",\"name\":\"L. Lan\",\"url\":\"https://www.semanticscholar.org/author/49409772\"},{\"authorId\":\"7718952\",\"name\":\"Zhenguo Li\",\"url\":\"https://www.semanticscholar.org/author/7718952\"},{\"authorId\":\"143923928\",\"name\":\"X. Guan\",\"url\":\"https://www.semanticscholar.org/author/143923928\"},{\"authorId\":\"1764969\",\"name\":\"P. Wang\",\"url\":\"https://www.semanticscholar.org/author/1764969\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":\"2002.04238\",\"authors\":[{\"authorId\":\"48541481\",\"name\":\"Yun Hua\"},{\"authorId\":\"47119103\",\"name\":\"Xiangfeng Wang\"},{\"authorId\":\"144732659\",\"name\":\"B. Jin\"},{\"authorId\":\"48624960\",\"name\":\"Wenhao Li\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"143644849\",\"name\":\"Xiaofeng He\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d569777654c81b66eedc31987e62ad2de5d9564b\",\"title\":\"Hyper-Meta Reinforcement Learning with Sparse Reward\",\"url\":\"https://www.semanticscholar.org/paper/d569777654c81b66eedc31987e62ad2de5d9564b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.13852\",\"authors\":[{\"authorId\":\"8458211\",\"name\":\"Giannis Karamanolakis\"},{\"authorId\":\"65743795\",\"name\":\"Jun Ma\"},{\"authorId\":\"48477264\",\"name\":\"X. Dong\"}],\"doi\":\"10.18653/v1/2020.acl-main.751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d15d83ae7e61fded91a9455b4a268273718fd7d\",\"title\":\"TXtract: Taxonomy-Aware Knowledge Extraction for Thousands of Product Categories\",\"url\":\"https://www.semanticscholar.org/paper/4d15d83ae7e61fded91a9455b4a268273718fd7d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1910.08348\",\"authors\":[{\"authorId\":\"3378188\",\"name\":\"Luisa M. Zintgraf\"},{\"authorId\":\"3402736\",\"name\":\"K. Shiarlis\"},{\"authorId\":\"27550002\",\"name\":\"M. Igl\"},{\"authorId\":\"51503667\",\"name\":\"S. Schulze\"},{\"authorId\":\"2681954\",\"name\":\"Yarin Gal\"},{\"authorId\":\"1380228856\",\"name\":\"Katja Hofmann\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e94208d4f56e62cf50bb6b3d112a6caa909099d\",\"title\":\"VariBAD: A Very Good Method for Bayes-Adaptive Deep RL via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/5e94208d4f56e62cf50bb6b3d112a6caa909099d\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102475084\",\"name\":\"A. Arzhanov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4faaee7045f0217bfa78be9df76ea968507519c2\",\"title\":\"protANIL: a Fast and Simple Meta-Learning Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/4faaee7045f0217bfa78be9df76ea968507519c2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.01845\",\"authors\":[{\"authorId\":\"3455364\",\"name\":\"Heinke Hihn\"},{\"authorId\":\"2354563\",\"name\":\"D. A. Braun\"}],\"doi\":\"10.1007/s11063-020-10351-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca36ea999cb2f7383e4498d075c5bd8b081e3aa0\",\"title\":\"Specialization in Hierarchical Learning Systems\",\"url\":\"https://www.semanticscholar.org/paper/ca36ea999cb2f7383e4498d075c5bd8b081e3aa0\",\"venue\":\"Neural Process. Lett.\",\"year\":2020},{\"arxivId\":\"2011.13782\",\"authors\":[{\"authorId\":\"2811292\",\"name\":\"Rachit Dubey\"},{\"authorId\":\"145557445\",\"name\":\"E. Grant\"},{\"authorId\":\"1491203133\",\"name\":\"Michael Luo\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab1e16f7f434a3bdeb87b31cc7e6af1c6562b09a\",\"title\":\"Connecting Context-specific Adaptation in Humans to Meta-learning.\",\"url\":\"https://www.semanticscholar.org/paper/ab1e16f7f434a3bdeb87b31cc7e6af1c6562b09a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.00348\",\"authors\":[{\"authorId\":\"3455364\",\"name\":\"Heinke Hihn\"},{\"authorId\":\"2354563\",\"name\":\"D. A. Braun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac710b851a56114e9742188bcb4fa891cd7f78f5\",\"title\":\"Hierarchical Expert Networks for Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/ac710b851a56114e9742188bcb4fa891cd7f78f5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.02914\",\"authors\":[{\"authorId\":\"1723390049\",\"name\":\"Lin Lan\"},{\"authorId\":\"1764969\",\"name\":\"P. Wang\"},{\"authorId\":\"151480429\",\"name\":\"Xuefeng Du\"},{\"authorId\":\"46440341\",\"name\":\"Kaikai Song\"},{\"authorId\":\"145533675\",\"name\":\"Jing Tao\"},{\"authorId\":\"46654518\",\"name\":\"Xiao-Hong Guan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c656e0b1f89f243171ad1198f4a147a23b086d0c\",\"title\":\"Node Classification on Graphs with Few-Shot Novel Labels via Meta Transformed Network Embedding\",\"url\":\"https://www.semanticscholar.org/paper/c656e0b1f89f243171ad1198f4a147a23b086d0c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.08875\",\"authors\":[{\"authorId\":\"41123614\",\"name\":\"Zichuan Lin\"},{\"authorId\":\"8234443\",\"name\":\"G. Thomas\"},{\"authorId\":\"145789924\",\"name\":\"G. Yang\"},{\"authorId\":\"1901958\",\"name\":\"Tengyu Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"638538253332ebeba83f8de1d66f1eb4d2fe61b5\",\"title\":\"Model-based Adversarial Meta-Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/638538253332ebeba83f8de1d66f1eb4d2fe61b5\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.07178\",\"authors\":[{\"authorId\":\"35509365\",\"name\":\"R. Mendonca\"},{\"authorId\":\"3468192\",\"name\":\"Xinyang Geng\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41a5c7271635f66aa1fa3497e28d6791db27b73b\",\"title\":\"Meta-Reinforcement Learning Robust to Distributional Shift via Model Identification and Experience Relabeling\",\"url\":\"https://www.semanticscholar.org/paper/41a5c7271635f66aa1fa3497e28d6791db27b73b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.09796\",\"authors\":[{\"authorId\":\"145868671\",\"name\":\"M. Crawshaw\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"title\":\"Multi-Task Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.07113\",\"authors\":[{\"authorId\":\"51139888\",\"name\":\"OpenAI\"},{\"authorId\":\"2258629\",\"name\":\"I. Akkaya\"},{\"authorId\":\"2206490\",\"name\":\"Marcin Andrychowicz\"},{\"authorId\":\"36045639\",\"name\":\"Maciek Chociej\"},{\"authorId\":\"1380985420\",\"name\":\"Mateusz Litwin\"},{\"authorId\":\"39593364\",\"name\":\"Bob McGrew\"},{\"authorId\":\"6817951\",\"name\":\"Arthur Petron\"},{\"authorId\":\"34800652\",\"name\":\"Alex Paino\"},{\"authorId\":\"3407285\",\"name\":\"Matthias Plappert\"},{\"authorId\":\"46818887\",\"name\":\"Glenn Powell\"},{\"authorId\":\"1380603785\",\"name\":\"Raphael Ribas\"},{\"authorId\":\"145540310\",\"name\":\"J. Schneider\"},{\"authorId\":\"3534905\",\"name\":\"N. Tezak\"},{\"authorId\":\"98102815\",\"name\":\"Jadwiga Tworek\"},{\"authorId\":\"2930640\",\"name\":\"P. Welinder\"},{\"authorId\":\"2617057\",\"name\":\"Lilian Weng\"},{\"authorId\":\"153930486\",\"name\":\"Q. Yuan\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":null,\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"320b227027030fc291de2896fc3c6da49d7614be\",\"title\":\"Solving Rubik's Cube with a Robot Hand\",\"url\":\"https://www.semanticscholar.org/paper/320b227027030fc291de2896fc3c6da49d7614be\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.11373\",\"authors\":[{\"authorId\":\"47786450\",\"name\":\"Jiachen Li\"},{\"authorId\":\"2330711\",\"name\":\"Q. Vuong\"},{\"authorId\":\"1491626709\",\"name\":\"Shuang Liu\"},{\"authorId\":\"47842126\",\"name\":\"Minghua Liu\"},{\"authorId\":\"2474449\",\"name\":\"K. Ciosek\"},{\"authorId\":\"1723059\",\"name\":\"H. Christensen\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561f85be7f5a63d5870a204ec522c094c407ba3b\",\"title\":\"Multi-task Batch Reinforcement Learning with Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/561f85be7f5a63d5870a204ec522c094c407ba3b\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2811292\",\"name\":\"Rachit Dubey\"},{\"authorId\":\"145557445\",\"name\":\"E. Grant\"},{\"authorId\":\"1491203133\",\"name\":\"Michael Luo\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4bda0e2efec184acd32eafc7a80ccc77fd038837\",\"title\":\"Context-Conditioning as Cognitive Control: Guiding Meta-learning with Task Information\",\"url\":\"https://www.semanticscholar.org/paper/4bda0e2efec184acd32eafc7a80ccc77fd038837\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09380\",\"authors\":[{\"authorId\":\"40897068\",\"name\":\"Xin Chen\"},{\"authorId\":\"104406637\",\"name\":\"Yawen Duan\"},{\"authorId\":\"46842298\",\"name\":\"Zewei Chen\"},{\"authorId\":\"47995165\",\"name\":\"Hang Xu\"},{\"authorId\":\"49865053\",\"name\":\"Zihao Chen\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"50728655\",\"name\":\"Tong Zhang\"},{\"authorId\":\"48458760\",\"name\":\"Zhenguo Li\"}],\"doi\":\"10.1007/978-3-030-58529-7_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c77172171ae31f5c4cd1f19e79e91b939d3d966\",\"title\":\"CATCH: Context-based Meta Reinforcement Learning for Transferrable Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/2c77172171ae31f5c4cd1f19e79e91b939d3d966\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.00722\",\"authors\":[{\"authorId\":\"46188113\",\"name\":\"Andrea Tirinzoni\"},{\"authorId\":\"1785396322\",\"name\":\"Riccardo Poiani\"},{\"authorId\":\"1792167\",\"name\":\"Marcello Restelli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0489c2f1fdc5c54dda0f1d9f5477526b5524327e\",\"title\":\"Sequential Transfer in Reinforcement Learning with a Generative Model\",\"url\":\"https://www.semanticscholar.org/paper/0489c2f1fdc5c54dda0f1d9f5477526b5524327e\",\"venue\":\"ICML\",\"year\":2020}],\"corpusId\":155100234,\"doi\":\"10.24963/ijcai.2019/387\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"7bd95a62fd6320730cbb24a0e4fafac97d840652\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1805.12573\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"48002287\",\"name\":\"Ellis Ratner\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e75864bf912b49e78aa593b4ab3f4c50fe357c3\",\"title\":\"Learning a Prior over Intent via Meta-Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8e75864bf912b49e78aa593b4ab3f4c50fe357c3\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47793019\",\"name\":\"Jiaqi Ma\"},{\"authorId\":\"145737110\",\"name\":\"Zhe Zhao\"},{\"authorId\":\"2838461\",\"name\":\"Xinyang Yi\"},{\"authorId\":\"5401495\",\"name\":\"J. Chen\"},{\"authorId\":\"2217278\",\"name\":\"L. Hong\"},{\"authorId\":\"2226805\",\"name\":\"Ed Huai-hsin Chi\"}],\"doi\":\"10.1145/3219819.3220007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af8a8dcb74561d52d904f7bc4afcc747e079b702\",\"title\":\"Modeling Task Relationships in Multi-task Learning with Multi-gate Mixture-of-Experts\",\"url\":\"https://www.semanticscholar.org/paper/af8a8dcb74561d52d904f7bc4afcc747e079b702\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":\"1611.02779\",\"authors\":[{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"1745169\",\"name\":\"P. Bartlett\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"954b01151ff13aef416d27adc60cd9a076753b1a\",\"title\":\"RL$^2$: Fast Reinforcement Learning via Slow Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/954b01151ff13aef416d27adc60cd9a076753b1a\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1806.04640\",\"authors\":[{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"8140754\",\"name\":\"Benjamin Eysenbach\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b93317f61c6ed99542da9d1d691ded9732c16c1c\",\"title\":\"Unsupervised Meta-Learning for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b93317f61c6ed99542da9d1d691ded9732c16c1c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1703.05175\",\"authors\":[{\"authorId\":\"39770136\",\"name\":\"J. Snell\"},{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c269858a7bb34e8350f2442ccf37797856ae9bca\",\"title\":\"Prototypical Networks for Few-shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/c269858a7bb34e8350f2442ccf37797856ae9bca\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1707.03141\",\"authors\":[{\"authorId\":\"3414570\",\"name\":\"N. Mishra\"},{\"authorId\":\"22222033\",\"name\":\"Mostafa Rohaninejad\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"00357a417ce470a78f7a84d18ae2604330455d2a\",\"title\":\"Meta-Learning with Temporal Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/00357a417ce470a78f7a84d18ae2604330455d2a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.06347\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"143909660\",\"name\":\"F. Wolski\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"144538754\",\"name\":\"O. Klimov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"title\":\"Proximal Policy Optimization Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/dce6f9d4017b1785979e7520fd0834ef8cf02f4b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.09835\",\"authors\":[{\"authorId\":\"7718952\",\"name\":\"Zhenguo Li\"},{\"authorId\":\"22173351\",\"name\":\"Fengwei Zhou\"},{\"authorId\":\"144765273\",\"name\":\"F. Chen\"},{\"authorId\":\"1688858\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d33ad6a25264ba1747d8c93f6621c7f90a7ec601\",\"title\":\"Meta-SGD: Learning to Learn Quickly for Few Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/d33ad6a25264ba1747d8c93f6621c7f90a7ec601\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":\"1710.09767\",\"authors\":[{\"authorId\":\"10728123\",\"name\":\"Kevin Frans\"},{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4d2c4cbb535801549371d9783a98d1e43bddf4e5\",\"title\":\"Meta Learning Shared Hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/4d2c4cbb535801549371d9783a98d1e43bddf4e5\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1710.03641\",\"authors\":[{\"authorId\":\"1401178735\",\"name\":\"Maruan Al-Shedivat\"},{\"authorId\":\"1858169\",\"name\":\"Trapit Bansal\"},{\"authorId\":\"3080409\",\"name\":\"Yuri Burda\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2080746\",\"name\":\"Igor Mordatch\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"876a57186bd367e7a301b16ee8ace721e74de86a\",\"title\":\"Continuous Adaptation via Meta-Learning in Nonstationary and Competitive Environments\",\"url\":\"https://www.semanticscholar.org/paper/876a57186bd367e7a301b16ee8ace721e74de86a\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.04821\",\"authors\":[{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"2896187\",\"name\":\"Richard Y. Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"3275284\",\"name\":\"Bradly C. Stadie\"},{\"authorId\":\"143909660\",\"name\":\"F. Wolski\"},{\"authorId\":\"73735391\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c9660db0c94edfb2b1f3ab4f08eb80acd83a1c07\",\"title\":\"Evolved Policy Gradients\",\"url\":\"https://www.semanticscholar.org/paper/c9660db0c94edfb2b1f3ab4f08eb80acd83a1c07\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1803.01118\",\"authors\":[{\"authorId\":\"3275284\",\"name\":\"Bradly C. Stadie\"},{\"authorId\":\"145703741\",\"name\":\"Ge Yang\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"3374063\",\"name\":\"Yuhuai Wu\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b80991d12b41a5a68dc14dd87b692c0f903ceb9c\",\"title\":\"Some Considerations on Learning to Explore via Meta-Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b80991d12b41a5a68dc14dd87b692c0f903ceb9c\",\"venue\":\"ICLR 2018\",\"year\":2018},{\"arxivId\":\"1509.02971\",\"authors\":[{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"024006d4c2a89f7acacc6e4438d156525b60a98f\",\"title\":\"Continuous control with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1704.03012\",\"authors\":[{\"authorId\":\"10104623\",\"name\":\"Carlos Florensa\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3deecaee4ec1a37de3cb10420eaabff067669e17\",\"title\":\"Stochastic Neural Networks for Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3deecaee4ec1a37de3cb10420eaabff067669e17\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1803.11347\",\"authors\":[{\"authorId\":\"3195183\",\"name\":\"Anusha Nagabandi\"},{\"authorId\":\"15593386\",\"name\":\"I. Clavera\"},{\"authorId\":\"47130332\",\"name\":\"Simin Liu\"},{\"authorId\":\"98107250\",\"name\":\"Ronald S. Fearing\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"944bd3b472c8a30163bbfc1b5cbab8545693c3e0\",\"title\":\"Learning to Adapt in Dynamic, Real-World Environments through Meta-Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/944bd3b472c8a30163bbfc1b5cbab8545693c3e0\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1703.03400\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c889d6f98e6d79b89c3a6adf8a921f88fa6ba518\",\"title\":\"Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/c889d6f98e6d79b89c3a6adf8a921f88fa6ba518\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Abhishek Gupta\"},{\"authorId\":null,\"name\":\"Benjamin Eysenbach\"},{\"authorId\":null,\"name\":\"Chelsea Finn\"},{\"authorId\":null,\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Unsupervised metalearning for reinforcement learning\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1806.04640,\",\"year\":2018},{\"arxivId\":\"1706.05098\",\"authors\":[{\"authorId\":\"2884561\",\"name\":\"Sebastian Ruder\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d431f835c06afdea45dff6b24486bf301ebdef0\",\"title\":\"An Overview of Multi-Task Learning in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d431f835c06afdea45dff6b24486bf301ebdef0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1802.07245\",\"authors\":[{\"authorId\":\"144150283\",\"name\":\"A. Gupta\"},{\"authorId\":\"35509365\",\"name\":\"R. Mendonca\"},{\"authorId\":\"49421394\",\"name\":\"Yuxuan Liu\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"68c108795deef06fa929d1f6e96b75dbf7ce8531\",\"title\":\"Meta-Reinforcement Learning of Structured Exploration Strategies\",\"url\":\"https://www.semanticscholar.org/paper/68c108795deef06fa929d1f6e96b75dbf7ce8531\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46188113\",\"name\":\"Andrea Tirinzoni\"},{\"authorId\":\"1389874481\",\"name\":\"Rafael Rodr\\u00edguez-S\\u00e1nchez\"},{\"authorId\":\"1792167\",\"name\":\"Marcello Restelli\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"cfc4dbbb4b08b95c6e53cb35697357128a44198c\",\"title\":\"Transfer of Value Functions via Variational Methods\",\"url\":\"https://www.semanticscholar.org/paper/cfc4dbbb4b08b95c6e53cb35697357128a44198c\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1803.05044\",\"authors\":[{\"authorId\":\"35533477\",\"name\":\"T. Xu\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"},{\"authorId\":\"145927744\",\"name\":\"Liang Zhao\"},{\"authorId\":\"144439558\",\"name\":\"J. Peng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f567f1e8972ff31a7ced59c329e7d75da645baf\",\"title\":\"Learning to Explore with Meta-Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/7f567f1e8972ff31a7ced59c329e7d75da645baf\",\"venue\":\"ICML 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sebastian Ruder\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"An overview of multitask learning in deep neural networks\",\"url\":\"\",\"venue\":\"arXiv preprint arXiv:1706.05098,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995717\",\"name\":\"Bingyi Kang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"9ed6f03f6822d3761da1a6811bfb54e28c919072\",\"title\":\"Transferable Meta Learning Across Domains\",\"url\":\"https://www.semanticscholar.org/paper/9ed6f03f6822d3761da1a6811bfb54e28c919072\",\"venue\":\"UAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144832491\",\"name\":\"E. Todorov\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"}],\"doi\":\"10.1109/IROS.2012.6386109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"title\":\"MuJoCo: A physics engine for model-based control\",\"url\":\"https://www.semanticscholar.org/paper/b354ee518bfc1ac0d8ac447eece9edb69e92eae1\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ma et al\"},{\"authorId\":null,\"name\":\"2018 Jiaqi Ma\"},{\"authorId\":null,\"name\":\"Zhe Zhao\"},{\"authorId\":null,\"name\":\"Xinyang Yi\"},{\"authorId\":null,\"name\":\"Jilin Chen\"},{\"authorId\":null,\"name\":\"Lichan Hong\"},{\"authorId\":null,\"name\":\"Ed H Chi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Modeling task relationships\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":\"1805.09801\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a49a71c9d40051a03c4445fe49025bc75d9eeb6\",\"title\":\"Meta-Gradient Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2a49a71c9d40051a03c4445fe49025bc75d9eeb6\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1504.00702\",\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6b8a1b80891c96c28cc6340267b58186157e536\",\"title\":\"End-to-End Training of Deep Visuomotor Policies\",\"url\":\"https://www.semanticscholar.org/paper/b6b8a1b80891c96c28cc6340267b58186157e536\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2016},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15593386\",\"name\":\"I. Clavera\"},{\"authorId\":\"3195183\",\"name\":\"Anusha Nagabandi\"},{\"authorId\":\"1773013\",\"name\":\"R. Fearing\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"56d13402da5ff98ffdfff640fb987b9b13e924cf\",\"title\":\"Learning to Adapt: Meta-Learning for Model-Based Control\",\"url\":\"https://www.semanticscholar.org/paper/56d13402da5ff98ffdfff640fb987b9b13e924cf\",\"venue\":\"ArXiv\",\"year\":2018}],\"title\":\"Meta Reinforcement Learning with Task Embedding and Shared Policy\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"High-level programming language\",\"topicId\":\"212045\",\"url\":\"https://www.semanticscholar.org/topic/212045\"}],\"url\":\"https://www.semanticscholar.org/paper/7bd95a62fd6320730cbb24a0e4fafac97d840652\",\"venue\":\"IJCAI\",\"year\":2019}\n"