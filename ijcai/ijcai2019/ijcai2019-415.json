"{\"abstract\":\"Adversarial training has been successfully applied to build robust models at a certain cost. While the robustness of a model increases, the standard classification accuracy declines. This phenomenon is suggested to be an inherent trade-off. We propose a model that employs feature prioritization by a nonlinear attention module and $L_2$ feature regularization to improve the adversarial robustness and the standard accuracy relative to adversarial training. The attention module encourages the model to rely heavily on robust features by assigning larger weights to them while suppressing non-robust features. The regularizer encourages the model to extract similar features for the natural and adversarial images, effectively ignoring the added perturbation. In addition to evaluating the robustness of our model, we provide justification for the attention module and propose a novel experimental strategy that quantitatively demonstrates that our model is almost ideally aligned with salient data characteristics. Additional experimental results illustrate the power of our model relative to the state of the art methods.\",\"arxivId\":\"1810.02424\",\"authors\":[{\"authorId\":\"40813771\",\"name\":\"Chihuang Liu\",\"url\":\"https://www.semanticscholar.org/author/40813771\"},{\"authorId\":\"1714905\",\"name\":\"J. J\\u00e1J\\u00e1\",\"url\":\"https://www.semanticscholar.org/author/1714905\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1911.12562\",\"authors\":[{\"authorId\":\"115497293\",\"name\":\"Yingzhe He\"},{\"authorId\":\"2018895\",\"name\":\"Guozhu Meng\"},{\"authorId\":\"145126969\",\"name\":\"Kai Chen\"},{\"authorId\":\"2720669\",\"name\":\"Xingbo Hu\"},{\"authorId\":\"3259508\",\"name\":\"Jinwen He\"}],\"doi\":\"10.1109/tse.2020.3034721\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a49b9bcf2812ba37e1b581e75941cae8d2a0ff1\",\"title\":\"Towards Security Threats of Deep Learning Systems: A Survey.\",\"url\":\"https://www.semanticscholar.org/paper/0a49b9bcf2812ba37e1b581e75941cae8d2a0ff1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.11904\",\"authors\":[{\"authorId\":\"46238935\",\"name\":\"Shangxi Wu\"},{\"authorId\":\"152958348\",\"name\":\"J. Sang\"},{\"authorId\":\"11237053\",\"name\":\"Kaiyuan Xu\"},{\"authorId\":\"30077686\",\"name\":\"Guanhua Zheng\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"927fdb4a129fde6c4d59c2bbdb866411f5405d69\",\"title\":\"Adaptive Adversarial Logits Pairing\",\"url\":\"https://www.semanticscholar.org/paper/927fdb4a129fde6c4d59c2bbdb866411f5405d69\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":52931862,\"doi\":\"10.24963/ijcai.2019/415\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"c7b379b098ecb68b75a35d51eb88cf3ccb12195f\",\"references\":[{\"arxivId\":\"1806.07409\",\"authors\":[{\"authorId\":\"3451382\",\"name\":\"T. Tanay\"},{\"authorId\":\"50819534\",\"name\":\"Jerone T. A. Andrews\"},{\"authorId\":\"1682458\",\"name\":\"Lewis D. Griffin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfb2426a81cd3409089cfc14e1ea813b3afab06d\",\"title\":\"Built-in Vulnerabilities to Imperceptible Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/dfb2426a81cd3409089cfc14e1ea813b3afab06d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41523cfd9773df271cf66002cc36afbe1e06d4ea\",\"title\":\"Progressive Attention Networks for Visual Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/41523cfd9773df271cf66002cc36afbe1e06d4ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eddfcb3462603c076565bf7091c5599efabdd9d4\",\"title\":\"There Is No Free Lunch In Adversarial Robustness (But There Are Unexpected Benefits)\",\"url\":\"https://www.semanticscholar.org/paper/eddfcb3462603c076565bf7091c5599efabdd9d4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72828832\",\"name\":\"Ieee Staff\"}],\"doi\":\"10.1109/sp36276.2017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5da4e9ffc35700829b3f0700a8432fcab9e8f30\",\"title\":\"2017 IEEE Symposium on Security and Privacy, SP 2017, San Jose, CA, USA, May 22-26, 2017\",\"url\":\"https://www.semanticscholar.org/paper/b5da4e9ffc35700829b3f0700a8432fcab9e8f30\",\"venue\":\"IEEE Symposium on Security and Privacy\",\"year\":2017},{\"arxivId\":\"1810.00740\",\"authors\":[{\"authorId\":\"81510136\",\"name\":\"Chuanbiao Song\"},{\"authorId\":\"1702188\",\"name\":\"Kun He\"},{\"authorId\":\"24952249\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1706504\",\"name\":\"J. Hopcroft\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428c2e5992d6ed3186c087cba0fdba2ab6a468b2\",\"title\":\"Improving the Generalization of Adversarial Training with Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/428c2e5992d6ed3186c087cba0fdba2ab6a468b2\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113713833\",\"name\":\"S. J. Crawford\"},{\"authorId\":\"116971860\",\"name\":\"D. F. Kelley\"},{\"authorId\":\"137736247\",\"name\":\"In\\u00e9s Hern\\u00e1ndez \\u00c1vila\"}],\"doi\":\"10.1023/A:1017127612903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a8d3d2b99ab48fef1848fb16506a126a2702bde\",\"title\":\"Volume 1\",\"url\":\"https://www.semanticscholar.org/paper/6a8d3d2b99ab48fef1848fb16506a126a2702bde\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Eric Wong\"},{\"authorId\":null,\"name\":\"Zico Kolter. Provable defenses against adversarial exam polytope\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In International Conference on Machine Learning\",\"url\":\"\",\"venue\":\"pages 5283\\u20135292,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nicholas Carlini\"},{\"authorId\":null,\"name\":\"David Wagner. Towards evaluating the robustness of neura networks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In 2017 IEEE Symposium on Security and Privacy (SP)\",\"url\":\"\",\"venue\":\"pages 39\\u201357. IEEE,\",\"year\":2017},{\"arxivId\":\"1711.00851\",\"authors\":[{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"51026953\",\"name\":\"E. Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b23012689e0f17912fb38d4984775e567cff8d6\",\"title\":\"Provable defenses against adversarial examples via the convex outer adversarial polytope\",\"url\":\"https://www.semanticscholar.org/paper/4b23012689e0f17912fb38d4984775e567cff8d6\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Aaditya Prakash\"},{\"authorId\":null,\"name\":\"Nick Moran\"},{\"authorId\":null,\"name\":\"Solomon Garber\"},{\"authorId\":null,\"name\":\"Antonella DiLillo\"},{\"authorId\":null,\"name\":\"James Storer. Deflecting adversarial attacks with pixel deflection\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"url\":\"\",\"venue\":\"pages 8571\\u20138580,\",\"year\":2018},{\"arxivId\":\"1805.06605\",\"authors\":[{\"authorId\":\"3383048\",\"name\":\"Pouya Samangouei\"},{\"authorId\":\"2747758\",\"name\":\"Maya Kabkab\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"title\":\"Defense-GAN: Protecting Classifiers Against Adversarial Attacks Using Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/f7bb1636ced9036b3d0edafc7d82ad43164d41a3\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1804.03286\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"06b98537324dbf11c7de2040e519b4d110f5d622\",\"title\":\"On the Robustness of the CVPR 2018 White-Box Adversarial Example Defenses\",\"url\":\"https://www.semanticscholar.org/paper/06b98537324dbf11c7de2040e519b4d110f5d622\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1502.02590\",\"authors\":[{\"authorId\":\"33054064\",\"name\":\"Alhussein Fawzi\"},{\"authorId\":\"145602557\",\"name\":\"Omar Fawzi\"},{\"authorId\":\"1703189\",\"name\":\"P. Frossard\"}],\"doi\":\"10.1007/s10994-017-5663-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02441fccec9ed54dd7e21a17736933c84853011\",\"title\":\"Analysis of classifiers\\u2019 robustness to adversarial perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f02441fccec9ed54dd7e21a17736933c84853011\",\"venue\":\"Machine Learning\",\"year\":2017},{\"arxivId\":\"1611.01236\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e2a85a6766b982ff7c8980e57ca6342d22493827\",\"title\":\"Adversarial Machine Learning at Scale\",\"url\":\"https://www.semanticscholar.org/paper/e2a85a6766b982ff7c8980e57ca6342d22493827\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1707.07397\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"34562927\",\"name\":\"Andrew Ilyas\"},{\"authorId\":\"143883029\",\"name\":\"Kevin Kwok\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"title\":\"Synthesizing Robust Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8dce99e33c6fceb3e79023f5894fdbe733c91e92\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1805.10265\",\"authors\":[{\"authorId\":\"1729912\",\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":\"2071666\",\"name\":\"Sven Gowal\"},{\"authorId\":\"49860489\",\"name\":\"Robert Stanforth\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1389654226\",\"name\":\"Brendan O'Donoghue\"},{\"authorId\":\"9960452\",\"name\":\"Jonathan Uesato\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54afe5cde4d4140e728dde299d4d66b2c0eda6da\",\"title\":\"Training verified learners with learned verifiers\",\"url\":\"https://www.semanticscholar.org/paper/54afe5cde4d4140e728dde299d4d66b2c0eda6da\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.12152\",\"authors\":[{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2852106\",\"name\":\"Shibani Santurkar\"},{\"authorId\":\"39468283\",\"name\":\"L. Engstrom\"},{\"authorId\":\"152866449\",\"name\":\"A. Turner\"},{\"authorId\":\"143826246\",\"name\":\"A. Madry\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b9c6022598085dd892f360122c0fa4c630b3f18\",\"title\":\"Robustness May Be at Odds with Accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1b9c6022598085dd892f360122c0fa4c630b3f18\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1710.10766\",\"authors\":[{\"authorId\":\"144404428\",\"name\":\"Yang Song\"},{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"1684887\",\"name\":\"Nate Kushman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"title\":\"PixelDefend: Leveraging Generative Models to Understand and Defend against Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/e83291498a3bc6b0efe8f9571e9c9ca1811707bd\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1712.02976\",\"authors\":[{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"151483845\",\"name\":\"Ming Liang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"48566726\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/CVPR.2018.00191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"title\":\"Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\",\"url\":\"https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.02393\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47e52ec494c9eb7dc8c1bddc482f2ee36c992b08\",\"title\":\"Hierarchical Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/47e52ec494c9eb7dc8c1bddc482f2ee36c992b08\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1804.02391\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"40222538\",\"name\":\"N. Lord\"},{\"authorId\":\"2702448\",\"name\":\"N. Lee\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c70218603f0af1be5d063056cbe629e042141a86\",\"title\":\"Learn To Pay Attention\",\"url\":\"https://www.semanticscholar.org/paper/c70218603f0af1be5d063056cbe629e042141a86\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1801.00553\",\"authors\":[{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/ACCESS.2018.2807385\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b514949ad8344071c0f342f182390d2d88bcc26d\",\"title\":\"Threat of Adversarial Attacks on Deep Learning in Computer Vision: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b514949ad8344071c0f342f182390d2d88bcc26d\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":null,\"name\":\"Sven Gowal\"},{\"authorId\":null,\"name\":\"Robert Stanforth\"},{\"authorId\":null,\"name\":\"Relja Arandjelovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Brendan O\\u2019Donoghue\",\"url\":\"\",\"venue\":\"Jonathan Uesato, and Pushmeet Kohli. Training verified learners with learned verifiers. arXiv preprint arXiv:1805.10265,\",\"year\":2018},{\"arxivId\":\"1803.06373\",\"authors\":[{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"title\":\"Adversarial Logit Pairing\",\"url\":\"https://www.semanticscholar.org/paper/f2c5c3cfe1675dd9239121f1f09069438f047aea\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1708.02582\",\"authors\":[{\"authorId\":\"40191008\",\"name\":\"Taesik Na\"},{\"authorId\":\"2813905\",\"name\":\"J. H. Ko\"},{\"authorId\":\"144192725\",\"name\":\"S. Mukhopadhyay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a710be199c8eb43f465c88fc4b343267c35d38\",\"title\":\"Cascade Adversarial Machine Learning Regularized with a Unified Embedding\",\"url\":\"https://www.semanticscholar.org/paper/45a710be199c8eb43f465c88fc4b343267c35d38\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1801.08926\",\"authors\":[{\"authorId\":\"40014058\",\"name\":\"Aaditya Prakash\"},{\"authorId\":\"33072734\",\"name\":\"N. Moran\"},{\"authorId\":\"50304331\",\"name\":\"Solomon Garber\"},{\"authorId\":\"39432646\",\"name\":\"Antonella DiLillo\"},{\"authorId\":\"1770857\",\"name\":\"J. Storer\"}],\"doi\":\"10.1109/CVPR.2018.00894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5e602bf3d59d2ea1553f06a94e9e94880af065d\",\"title\":\"Deflecting Adversarial Attacks with Pixel Deflection\",\"url\":\"https://www.semanticscholar.org/paper/f5e602bf3d59d2ea1553f06a94e9e94880af065d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Feature prioritization and regularization improve standard accuracy and adversarial robustness\",\"topics\":[{\"topic\":\"Robustness (computer science)\",\"topicId\":\"879\",\"url\":\"https://www.semanticscholar.org/topic/879\"},{\"topic\":\"Adversary (cryptography)\",\"topicId\":\"5369\",\"url\":\"https://www.semanticscholar.org/topic/5369\"},{\"topic\":\"Region of interest\",\"topicId\":\"32373\",\"url\":\"https://www.semanticscholar.org/topic/32373\"},{\"topic\":\"Data structure alignment\",\"topicId\":\"227498\",\"url\":\"https://www.semanticscholar.org/topic/227498\"},{\"topic\":\"Perturbation theory\",\"topicId\":\"5972\",\"url\":\"https://www.semanticscholar.org/topic/5972\"},{\"topic\":\"Noise reduction\",\"topicId\":\"18968\",\"url\":\"https://www.semanticscholar.org/topic/18968\"},{\"topic\":\"Nonlinear system\",\"topicId\":\"5329\",\"url\":\"https://www.semanticscholar.org/topic/5329\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Align (company)\",\"topicId\":\"439709\",\"url\":\"https://www.semanticscholar.org/topic/439709\"},{\"topic\":\"Mind map\",\"topicId\":\"73846\",\"url\":\"https://www.semanticscholar.org/topic/73846\"}],\"url\":\"https://www.semanticscholar.org/paper/c7b379b098ecb68b75a35d51eb88cf3ccb12195f\",\"venue\":\"IJCAI\",\"year\":2019}\n"