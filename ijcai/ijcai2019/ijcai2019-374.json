"{\"abstract\":\"We study the problem of inverse reinforcement learning (IRL) with the added twist that the learner is assisted by a helpful teacher. More formally, we tackle the following algorithmic question: How could a teacher provide an informative sequence of demonstrations to an IRL learner to speed up the learning process? We present an interactive teaching framework where a teacher adaptively chooses the next demonstration based on learner's current policy. In particular, we design teaching algorithms for two concrete settings: an omniscient setting where a teacher has full knowledge about the learner's dynamics and a blackbox setting where the teacher has minimal knowledge. Then, we study a sequential variant of the popular MCE-IRL learner and prove convergence guarantees of our teaching algorithm in the omniscient setting. Extensive experiments with a car driving simulator environment show that the learning progress can be speeded up drastically as compared to an uninformative teacher.\",\"arxivId\":\"1905.11867\",\"authors\":[{\"authorId\":\"2197201\",\"name\":\"P. Kamalaruban\",\"url\":\"https://www.semanticscholar.org/author/2197201\"},{\"authorId\":\"66779461\",\"name\":\"Rati Devidze\",\"url\":\"https://www.semanticscholar.org/author/66779461\"},{\"authorId\":\"1678641\",\"name\":\"V. Cevher\",\"url\":\"https://www.semanticscholar.org/author/1678641\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\",\"url\":\"https://www.semanticscholar.org/author/1703727\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":\"1910.02330\",\"authors\":[{\"authorId\":\"10418812\",\"name\":\"Ahana Ghosh\"},{\"authorId\":\"3302876\",\"name\":\"Sebastian Tschiatschek\"},{\"authorId\":\"12347266\",\"name\":\"Hamed Mahdavi\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ea16eb80669bd963a8302d0bdf52a289df0f3\",\"title\":\"Towards Deployment of Robust AI Agents for Human-Machine Partnerships\",\"url\":\"https://www.semanticscholar.org/paper/c44ea16eb80669bd963a8302d0bdf52a289df0f3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10418812\",\"name\":\"Ahana Ghosh\"},{\"authorId\":\"3302876\",\"name\":\"Sebastian Tschiatschek\"},{\"authorId\":\"12347266\",\"name\":\"Hamed Mahdavi\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":\"10.5555/3398761.3398817\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"293c776401f1c7951eaa6a51ac7904f6a939b655\",\"title\":\"Towards Deployment of Robust Cooperative AI Agents: An Algorithmic Framework for Learning Adaptive Policies\",\"url\":\"https://www.semanticscholar.org/paper/293c776401f1c7951eaa6a51ac7904f6a939b655\",\"venue\":\"AAMAS\",\"year\":2020},{\"arxivId\":\"2007.00425\",\"authors\":[{\"authorId\":\"1782493904\",\"name\":\"Martin Troussard\"},{\"authorId\":\"32854005\",\"name\":\"Emmanuel Pignat\"},{\"authorId\":\"2197201\",\"name\":\"P. Kamalaruban\"},{\"authorId\":\"1381572132\",\"name\":\"Sylvain Calinon\"},{\"authorId\":\"1678641\",\"name\":\"V. Cevher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99a0b02caa8610b06eb1cf618c706e560e74d61c\",\"title\":\"Interaction-limited Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/99a0b02caa8610b06eb1cf618c706e560e74d61c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10012\",\"authors\":[{\"authorId\":\"2343574\",\"name\":\"Farnam Mansouri\"},{\"authorId\":\"50580401\",\"name\":\"Yuxin Chen\"},{\"authorId\":\"3431372\",\"name\":\"Ara Vartanian\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5d3585d9062ea1fb59cb6b74e82e1d0a065d785\",\"title\":\"Preference-Based Batch and Sequential Teaching\",\"url\":\"https://www.semanticscholar.org/paper/e5d3585d9062ea1fb59cb6b74e82e1d0a065d785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.14043\",\"authors\":[{\"authorId\":\"143906108\",\"name\":\"Akash Kumar\"},{\"authorId\":\"46701767\",\"name\":\"Hanqi Zhang\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"1790059\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c786255103f3b322c12cbe5cef7b1bb723fe461\",\"title\":\"The Teaching Dimension of Kernel Perceptron\",\"url\":\"https://www.semanticscholar.org/paper/4c786255103f3b322c12cbe5cef7b1bb723fe461\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.06227\",\"authors\":[{\"authorId\":\"51440946\",\"name\":\"Mustafa Mert \\u00c7elikok\"},{\"authorId\":\"8140697\",\"name\":\"Pierre-Alexandre Murena\"},{\"authorId\":\"73512769\",\"name\":\"Samuel Kaski\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"805689464cb25df0f2a7f420a8bd4ecb9da55812\",\"title\":\"Teaching to Learn: Sequential Teaching of Agents with Inner States\",\"url\":\"https://www.semanticscholar.org/paper/805689464cb25df0f2a7f420a8bd4ecb9da55812\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.08322\",\"authors\":[{\"authorId\":\"46224173\",\"name\":\"Anette Hunziker\"},{\"authorId\":\"49069266\",\"name\":\"Yuxin Chen\"},{\"authorId\":\"2918822\",\"name\":\"Oisin Mac Aodha\"},{\"authorId\":\"143864530\",\"name\":\"M. G. Rodriguez\"},{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"795bde433653156c9ffcf67c9d3c70628ed208f5\",\"title\":\"Teaching Multiple Concepts to a Forgetful Learner\",\"url\":\"https://www.semanticscholar.org/paper/795bde433653156c9ffcf67c9d3c70628ed208f5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1911.13009\",\"authors\":[{\"authorId\":\"49335445\",\"name\":\"M. Lopes\"},{\"authorId\":\"145125979\",\"name\":\"Francisco S. Melo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63783edd4a8df2e045b0a9c7d17d59b61efca9d6\",\"title\":\"Class Teaching for Inverse Reinforcement Learners\",\"url\":\"https://www.semanticscholar.org/paper/63783edd4a8df2e045b0a9c7d17d59b61efca9d6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.03146\",\"authors\":[{\"authorId\":\"1785853\",\"name\":\"Oliver Kroemer\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1765407\",\"name\":\"G. Konidaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f33ae3a6f47ff3897a7ff12c6a0bacec2223d6d6\",\"title\":\"A Review of Robot Learning for Manipulation: Challenges, Representations, and Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/f33ae3a6f47ff3897a7ff12c6a0bacec2223d6d6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.13160\",\"authors\":[{\"authorId\":\"2197201\",\"name\":\"P. Kamalaruban\"},{\"authorId\":\"66779461\",\"name\":\"Rati Devidze\"},{\"authorId\":\"1382076210\",\"name\":\"Volkan Cevher\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3a4a3612376695f2292d9f49fb029cf765232e9\",\"title\":\"Environment Shaping in Reinforcement Learning using State Abstraction\",\"url\":\"https://www.semanticscholar.org/paper/c3a4a3612376695f2292d9f49fb029cf765232e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.10944\",\"authors\":[{\"authorId\":\"2343574\",\"name\":\"Farnam Mansouri\"},{\"authorId\":\"92709397\",\"name\":\"Y. Chen\"},{\"authorId\":\"3431372\",\"name\":\"Ara Vartanian\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b260201571932718383eeb2d19a1957654513f98\",\"title\":\"Preference-Based Batch and Sequential Teaching: Towards a Unified View of Models\",\"url\":\"https://www.semanticscholar.org/paper/b260201571932718383eeb2d19a1957654513f98\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2007.01174\",\"authors\":[{\"authorId\":\"1785336654\",\"name\":\"Luca Viano\"},{\"authorId\":\"1678908\",\"name\":\"Y. Huang\"},{\"authorId\":\"2197201\",\"name\":\"P. Kamalaruban\"},{\"authorId\":\"1678641\",\"name\":\"V. Cevher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f390dd8546e8cc668cd40788739ee8ced1194edb\",\"title\":\"Robust Inverse Reinforcement Learning under Transition Dynamics Mismatch\",\"url\":\"https://www.semanticscholar.org/paper/f390dd8546e8cc668cd40788739ee8ced1194edb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10824\",\"authors\":[{\"authorId\":\"1598433526\",\"name\":\"Amin Rakhsha\"},{\"authorId\":\"2667883\",\"name\":\"G. Radanovic\"},{\"authorId\":\"66779461\",\"name\":\"Rati Devidze\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cbf5c0e2e0c14607128c6512803d0624ab0a359\",\"title\":\"Policy Teaching in Reinforcement Learning via Environment Poisoning Attacks\",\"url\":\"https://www.semanticscholar.org/paper/3cbf5c0e2e0c14607128c6512803d0624ab0a359\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47038451\",\"name\":\"S. Arora\"},{\"authorId\":\"1687438\",\"name\":\"P. Doshi\"},{\"authorId\":\"145902797\",\"name\":\"B. Banerjee\"}],\"doi\":\"10.1007/S10458-020-09485-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b477bd8e05110880ee4e177eb11365a8f26bae96\",\"title\":\"I2RL: online inverse reinforcement learning under occlusion\",\"url\":\"https://www.semanticscholar.org/paper/b477bd8e05110880ee4e177eb11365a8f26bae96\",\"venue\":\"Auton. Agents Multi Agent Syst.\",\"year\":2021},{\"arxivId\":\"2007.01544\",\"authors\":[{\"authorId\":\"36267914\",\"name\":\"Adam Bignold\"},{\"authorId\":\"144465583\",\"name\":\"F. Cruz\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"},{\"authorId\":\"2837869\",\"name\":\"T. Brys\"},{\"authorId\":\"3327913\",\"name\":\"R. Dazeley\"},{\"authorId\":\"1990124\",\"name\":\"P. Vamplew\"},{\"authorId\":\"2763108\",\"name\":\"C. Foale\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b8c5e12a508df6e980bfd59106186aa897a8ee2\",\"title\":\"A Conceptual Framework for Externally-influenced Agents: An Assisted Reinforcement Learning Review\",\"url\":\"https://www.semanticscholar.org/paper/4b8c5e12a508df6e980bfd59106186aa897a8ee2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46224173\",\"name\":\"Anette Hunziker\"},{\"authorId\":\"92709397\",\"name\":\"Y. Chen\"},{\"authorId\":\"2918822\",\"name\":\"Oisin Mac Aodha\"},{\"authorId\":\"1388404108\",\"name\":\"M. Gomez-Rodriguez\"},{\"authorId\":\"153243248\",\"name\":\"A. Krause\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1cda524d7af435c106320eca96f88866f91d434\",\"title\":\"Teaching Multiple Concepts to Forgetful Learners\",\"url\":\"https://www.semanticscholar.org/paper/f1cda524d7af435c106320eca96f88866f91d434\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.00429\",\"authors\":[{\"authorId\":\"3302876\",\"name\":\"Sebastian Tschiatschek\"},{\"authorId\":\"10418812\",\"name\":\"Ahana Ghosh\"},{\"authorId\":\"103170324\",\"name\":\"Luis Haug\"},{\"authorId\":\"66779461\",\"name\":\"Rati Devidze\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6f3b33dc5f4b7fb047295444e88fa9139fb19e4\",\"title\":\"Learner-aware Teaching: Inverse Reinforcement Learning with Preferences and Constraints\",\"url\":\"https://www.semanticscholar.org/paper/a6f3b33dc5f4b7fb047295444e88fa9139fb19e4\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1910.05821\",\"authors\":[{\"authorId\":\"2912952\",\"name\":\"Yuzhe Ma\"},{\"authorId\":\"9117593\",\"name\":\"Xuezhou Zhang\"},{\"authorId\":\"22578070\",\"name\":\"W. Sun\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"20a53578f84be351bd90385fcd674821e1ace17d\",\"title\":\"Policy Poisoning in Batch Reinforcement Learning and Control\",\"url\":\"https://www.semanticscholar.org/paper/20a53578f84be351bd90385fcd674821e1ace17d\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2006.11845\",\"authors\":[{\"authorId\":\"38296971\",\"name\":\"A. De\"},{\"authorId\":\"41022166\",\"name\":\"Nastaran Okati\"},{\"authorId\":\"1944129\",\"name\":\"Ali Zarezade\"},{\"authorId\":\"1452766441\",\"name\":\"M. Gomez-Rodriguez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"917a83e0aeefa37b4fd1a1dbaa125afe28f6ccb1\",\"title\":\"Classification Under Human Assistance\",\"url\":\"https://www.semanticscholar.org/paper/917a83e0aeefa37b4fd1a1dbaa125afe28f6ccb1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.09324\",\"authors\":[{\"authorId\":\"9117593\",\"name\":\"Xuezhou Zhang\"},{\"authorId\":\"1456174103\",\"name\":\"Shubham Kumar Bharti\"},{\"authorId\":\"1485278277\",\"name\":\"Yuzhe Ma\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"585091371951b97a830fd8132ec359d4d1c1248c\",\"title\":\"The Teaching Dimension of Q-learning\",\"url\":\"https://www.semanticscholar.org/paper/585091371951b97a830fd8132ec359d4d1c1248c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.12909\",\"authors\":[{\"authorId\":\"1598433526\",\"name\":\"Amin Rakhsha\"},{\"authorId\":\"2667883\",\"name\":\"G. Radanovic\"},{\"authorId\":\"66779461\",\"name\":\"Rati Devidze\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1764924b9c892ad85c677b95677c344d7ce99143\",\"title\":\"Policy Teaching via Environment Poisoning: Training-time Adversarial Attacks against Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1764924b9c892ad85c677b95677c344d7ce99143\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2002.04258\",\"authors\":[{\"authorId\":\"1491820409\",\"name\":\"Vahid Balazadeh Meresht\"},{\"authorId\":\"152356803\",\"name\":\"A. De\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"1452766441\",\"name\":\"M. Gomez-Rodriguez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b40df849fe7e6527fb8cb8be61b76cee814c96b\",\"title\":\"Learning to Switch Between Machines and Humans\",\"url\":\"https://www.semanticscholar.org/paper/0b40df849fe7e6527fb8cb8be61b76cee814c96b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.02476\",\"authors\":[{\"authorId\":\"7988938\",\"name\":\"Y. Chuang\"},{\"authorId\":\"29592785\",\"name\":\"X. Zhang\"},{\"authorId\":\"1485278277\",\"name\":\"Yuzhe Ma\"},{\"authorId\":\"2543534\",\"name\":\"M. Ho\"},{\"authorId\":\"70117773\",\"name\":\"Joseph L Austerweil\"},{\"authorId\":\"121330545\",\"name\":\"Xiaojin Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"536712c9f8a75e4d6cbbb411b2260a75c6d2f755\",\"title\":\"Using Machine Teaching to Investigate Human Assumptions when Teaching Reinforcement Learners\",\"url\":\"https://www.semanticscholar.org/paper/536712c9f8a75e4d6cbbb411b2260a75c6d2f755\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14677\",\"authors\":[{\"authorId\":\"143906108\",\"name\":\"Akash Kumar\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"},{\"authorId\":\"50580401\",\"name\":\"Yuxin Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1de3e89e8938cd833630fc3c77e31c885491dfa7\",\"title\":\"Average-case Complexity of Teaching Convex Polytopes via Halfspace Queries\",\"url\":\"https://www.semanticscholar.org/paper/1de3e89e8938cd833630fc3c77e31c885491dfa7\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":167217398,\"doi\":\"10.24963/ijcai.2019/374\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ceeb815de098c353b83fa04389b88f7963e052d9\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anette Hunziker\"},{\"authorId\":null,\"name\":\"Yuxin Chen\"},{\"authorId\":null,\"name\":\"Oisin Mac Aodha\"},{\"authorId\":null,\"name\":\"Manuel Gomez-Rodriguez\"},{\"authorId\":null,\"name\":\"Andreas Krause\"},{\"authorId\":null,\"name\":\"Pietro Perona\"},{\"authorId\":null,\"name\":\"Yisong Yue\"},{\"authorId\":null,\"name\":\"Adish Singla. Teaching multiple concepts to a forgetful learner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1805.08322,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Abdeslam Boularias\"},{\"authorId\":null,\"name\":\"Jens Kober\"},{\"authorId\":null,\"name\":\"Jan Peters. Relative entropy inverse reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In AISTATS\",\"url\":\"\",\"venue\":\"pages 182\\u2013189,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhengyuan Zhou\"},{\"authorId\":null,\"name\":\"Michael Bloem\"},{\"authorId\":null,\"name\":\"Nicholas Bambos. Infinite time horizon maximum causal entro Trans\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Automat\",\"url\":\"\",\"venue\":\"Contr., 63(9):2787\\u20132802,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807928\",\"name\":\"A. Billard\"},{\"authorId\":\"1773227\",\"name\":\"S. Calinon\"},{\"authorId\":\"144427136\",\"name\":\"R. Dillmann\"},{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"}],\"doi\":\"10.1007/978-3-540-30301-5_60\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4c940cbe96ce4f181b7c1bb03caacf7efcad5b2\",\"title\":\"Robot Programming by Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/a4c940cbe96ce4f181b7c1bb03caacf7efcad5b2\",\"venue\":\"Springer Handbook of Robotics\",\"year\":2008},{\"arxivId\":\"1802.05190\",\"authors\":[{\"authorId\":\"40211770\",\"name\":\"Y. Chen\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"2918822\",\"name\":\"Oisin Mac Aodha\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1740159\",\"name\":\"Yisong Yue\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6b4178d875f9830130addac37f8dbf2d8698dfd\",\"title\":\"Understanding the Role of Adaptivity in Machine Teaching: The Case of Version Space Learners\",\"url\":\"https://www.semanticscholar.org/paper/e6b4178d875f9830130addac37f8dbf2d8698dfd\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.2200/S00568ED1V01Y201402AIM028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3da1a7501e842d346bbda8c81b229857fc21260\",\"title\":\"Robot Learning from Human Teachers\",\"url\":\"https://www.semanticscholar.org/paper/f3da1a7501e842d346bbda8c81b229857fc21260\",\"venue\":\"Robot Learning from Human Teachers\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29827930\",\"name\":\"K. R. Patil\"},{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"40320634\",\"name\":\"L. Kopec\"},{\"authorId\":\"10129234\",\"name\":\"B. Love\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a32e722191a559dafb0a1aab0f8b7fc44a6e83d9\",\"title\":\"Optimal Teaching for Limited-Capacity Human Learners\",\"url\":\"https://www.semanticscholar.org/paper/a32e722191a559dafb0a1aab0f8b7fc44a6e83d9\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1811.03537\",\"authors\":[{\"authorId\":\"143895090\",\"name\":\"Teresa Yeo\"},{\"authorId\":\"2197201\",\"name\":\"P. Kamalaruban\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"32009009\",\"name\":\"A. Merchant\"},{\"authorId\":\"9040762\",\"name\":\"Thibault Asselborn\"},{\"authorId\":\"3440511\",\"name\":\"Louis Faucon\"},{\"authorId\":\"1799133\",\"name\":\"P. Dillenbourg\"},{\"authorId\":\"1678641\",\"name\":\"V. Cevher\"}],\"doi\":\"10.1609/aaai.v33i01.33015684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa7bde380d3942debf600c300746189f5ca8212f\",\"title\":\"Iterative Classroom Teaching\",\"url\":\"https://www.semanticscholar.org/paper/fa7bde380d3942debf600c300746189f5ca8212f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1810.08926\",\"authors\":[{\"authorId\":\"103170324\",\"name\":\"Luis Haug\"},{\"authorId\":\"3302876\",\"name\":\"Sebastian Tschiatschek\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0c117d65ab42850cf6448fd8e4de9305665b46e\",\"title\":\"Teaching Inverse Reinforcement Learners via Features and Demonstrations\",\"url\":\"https://www.semanticscholar.org/paper/e0c117d65ab42850cf6448fd8e4de9305665b46e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sergey Levine\"},{\"authorId\":null,\"name\":\"Zoran Popovic\"},{\"authorId\":null,\"name\":\"Vladlen Koltun. Feature construction for inverse reinforce learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 1342\\u20131350,\",\"year\":2010},{\"arxivId\":\"1811.06711\",\"authors\":[{\"authorId\":\"40229316\",\"name\":\"Takayuki Osa\"},{\"authorId\":\"34906504\",\"name\":\"J. Pajarinen\"},{\"authorId\":\"26599977\",\"name\":\"G. Neumann\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":\"10.1561/2300000053\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d6adaa16ed0af9935a1130a305c85e8bdf8780d\",\"title\":\"An Algorithmic Perspective on Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8d6adaa16ed0af9935a1130a305c85e8bdf8780d\",\"venue\":\"Found. Trends Robotics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nathan D Ratliff\"},{\"authorId\":null,\"name\":\"J Andrew Bagnell\"},{\"authorId\":null,\"name\":\"Martin A Zinkevich. Maximum margin planning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In ICML\",\"url\":\"\",\"venue\":\"pages 729\\u2013736,\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13693897\",\"name\":\"Nathan D. Ratliff\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"8195063\",\"name\":\"Martin Zinkevich\"}],\"doi\":\"10.1145/1143844.1143936\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117a50fbdfd473e43e550c6103733e6cb4aecb4c\",\"title\":\"Maximum margin planning\",\"url\":\"https://www.semanticscholar.org/paper/117a50fbdfd473e43e550c6103733e6cb4aecb4c\",\"venue\":\"ICML '06\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3348176\",\"name\":\"Daphna Buchsbaum\"},{\"authorId\":\"2222423\",\"name\":\"A. Gopnik\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"},{\"authorId\":\"49949268\",\"name\":\"Patrick Shafto\"}],\"doi\":\"10.1016/j.cognition.2010.12.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ecedd66400ebf7381d6596303bbc2b1e06d9b2\",\"title\":\"Children\\u2019s imitation of causal action sequences is influenced by statistical and pedagogical evidence\",\"url\":\"https://www.semanticscholar.org/paper/66ecedd66400ebf7381d6596303bbc2b1e06d9b2\",\"venue\":\"Cognition\",\"year\":2011},{\"arxivId\":\"1603.00448\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04162cb8cfaa0f7e37586823ff4ad0bff09ed21d\",\"title\":\"Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization\",\"url\":\"https://www.semanticscholar.org/paper/04162cb8cfaa0f7e37586823ff4ad0bff09ed21d\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1606.03476\",\"authors\":[{\"authorId\":\"2126278\",\"name\":\"Jonathan Ho\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"title\":\"Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/4ab53de69372ec2cd2d90c126b6a100165dc8ed1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1875900\",\"name\":\"Anna N. Rafferty\"},{\"authorId\":\"2563117\",\"name\":\"Emma Brunskill\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"},{\"authorId\":\"3210220\",\"name\":\"Patrick Shafto\"}],\"doi\":\"10.1111/cogs.12290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8dd4219745c5f3b840bb09ab882a574823161bb\",\"title\":\"Faster Teaching via POMDP Planning\",\"url\":\"https://www.semanticscholar.org/paper/a8dd4219745c5f3b840bb09ab882a574823161bb\",\"venue\":\"Cogn. Sci.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144123639\",\"name\":\"Jonathan Sorg\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e767ae28510558344f90b0be08344d2b3769cd6\",\"title\":\"Reward Design via Online Gradient Ascent\",\"url\":\"https://www.semanticscholar.org/paper/8e767ae28510558344f90b0be08344d2b3769cd6\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":\"1705.10470\",\"authors\":[{\"authorId\":\"36326884\",\"name\":\"Weiyang Liu\"},{\"authorId\":null,\"name\":\"Bo Dai\"},{\"authorId\":\"3162535\",\"name\":\"Ahmad Humayun\"},{\"authorId\":\"39367354\",\"name\":\"C. Tay\"},{\"authorId\":\"102595883\",\"name\":\"Chen Yu\"},{\"authorId\":\"46600442\",\"name\":\"L. B. Smith\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1779453\",\"name\":\"L. Song\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bc183ee72b40416548937b9155b427a65e5ecbb2\",\"title\":\"Iterative Machine Teaching\",\"url\":\"https://www.semanticscholar.org/paper/bc183ee72b40416548937b9155b427a65e5ecbb2\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"}],\"doi\":\"10.1184/R1/6720692.V1\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2a65434d43ffa6554eaf14b728780919ad4f33eb\",\"title\":\"Modeling purposeful adaptive behavior with the principle of maximum causal entropy\",\"url\":\"https://www.semanticscholar.org/paper/2a65434d43ffa6554eaf14b728780919ad4f33eb\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920543\",\"name\":\"A. Denasi\"},{\"authorId\":\"74215260\",\"name\":\"B. B. Verhaar\"},{\"authorId\":\"144817336\",\"name\":\"D. Kostic\"},{\"authorId\":\"73940928\",\"name\":\"Dennis Bruijnen\"},{\"authorId\":\"144704465\",\"name\":\"H. Nijmeijer\"},{\"authorId\":\"81051707\",\"name\":\"Tph Warmerdam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5edc84dcb6ead31aa858b3ba4f81a58242f761ec\",\"title\":\"Robot programming by demonstration\",\"url\":\"https://www.semanticscholar.org/paper/5edc84dcb6ead31aa858b3ba4f81a58242f761ec\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779671\",\"name\":\"D. Sadigh\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"},{\"authorId\":\"144797536\",\"name\":\"S. Sastry\"},{\"authorId\":\"1775517\",\"name\":\"S. Seshia\"}],\"doi\":\"10.15607/RSS.2017.XIII.053\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e27467ca84c5c1f7239a6e643843c1b97e35671f\",\"title\":\"Active Preference-Based Learning of Reward Functions\",\"url\":\"https://www.semanticscholar.org/paper/e27467ca84c5c1f7239a6e643843c1b97e35671f\",\"venue\":\"Robotics: Science and Systems\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2543534\",\"name\":\"M. Ho\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"},{\"authorId\":\"2700008\",\"name\":\"J. MacGlashan\"},{\"authorId\":\"2053350\",\"name\":\"F. Cushman\"},{\"authorId\":\"2494174\",\"name\":\"Joseph L. Austerweil\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f07062e8a8befecb50022d9f432c52dbfaf4c872\",\"title\":\"Showing versus doing: Teaching by demonstration\",\"url\":\"https://www.semanticscholar.org/paper/f07062e8a8befecb50022d9f432c52dbfaf4c872\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2209847\",\"name\":\"Abdeslam Boularias\"},{\"authorId\":\"145739642\",\"name\":\"J. Kober\"},{\"authorId\":\"145197867\",\"name\":\"Jan Peters\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b16ae0b925eb7277cfe62ecac427e1427636f0\",\"title\":\"Relative Entropy Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d4b16ae0b925eb7277cfe62ecac427e1427636f0\",\"venue\":\"AISTATS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haoqi Zhang\"},{\"authorId\":null,\"name\":\"David C Parkes\"},{\"authorId\":null,\"name\":\"Yiling Chen. Policy teaching through reward function learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In EC\",\"url\":\"\",\"venue\":\"pages 295\\u2013304,\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8611534\",\"name\":\"Sumit Basu\"},{\"authorId\":\"35837717\",\"name\":\"J. Christensen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6069f2448ade3d01d957a3248529a3658796343\",\"title\":\"Teaching Classification Boundaries to Humans\",\"url\":\"https://www.semanticscholar.org/paper/e6069f2448ade3d01d957a3248529a3658796343\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145967801\",\"name\":\"Michael Bloem\"},{\"authorId\":\"1715888\",\"name\":\"N. Bambos\"}],\"doi\":\"10.1109/CDC.2014.7040156\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c81be86261a0e4be2c500dee8641e7fb0499dc6\",\"title\":\"Infinite time horizon maximum causal entropy inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/3c81be86261a0e4be2c500dee8641e7fb0499dc6\",\"venue\":\"53rd IEEE Conference on Decision and Control\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Markus Wulfmeier\"},{\"authorId\":null,\"name\":\"Peter Ondruska\"},{\"authorId\":null,\"name\":\"Ingmar Posner. Maximum entropy deep inverse reinforcement learning\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1507.04888,\",\"year\":2015},{\"arxivId\":\"1210.4918\",\"authors\":[{\"authorId\":\"144926179\",\"name\":\"T. Walsh\"},{\"authorId\":\"2109942\",\"name\":\"S. Goschin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe2ab31de424d89ecd4495fba0d9642d0f19e3ae\",\"title\":\"Dynamic Teaching in Sequential Decision Making Environments\",\"url\":\"https://www.semanticscholar.org/paper/fe2ab31de424d89ecd4495fba0d9642d0f19e3ae\",\"venue\":\"UAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144703353\",\"name\":\"G. Miller\"}],\"doi\":\"10.1111/(issn)1551-6709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d81ed652828fd536d86cc371278efcb502572cd\",\"title\":\"Cognitive science.\",\"url\":\"https://www.semanticscholar.org/paper/9d81ed652828fd536d86cc371278efcb502572cd\",\"venue\":\"Science\",\"year\":1981},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Francisco S Melo\"},{\"authorId\":null,\"name\":\"Carla Guerra\"},{\"authorId\":null,\"name\":\"Manuel Lopes. Interactive optimal teaching with unknown learners\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 2567\\u20132573,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3210220\",\"name\":\"Patrick Shafto\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"}],\"doi\":\"10.1016/j.cogpsych.2013.12.004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd359b45589bf7983ca35965c4873937d13753ef\",\"title\":\"A rational account of pedagogical reasoning: Teaching by, and learning from, examples\",\"url\":\"https://www.semanticscholar.org/paper/bd359b45589bf7983ca35965c4873937d13753ef\",\"venue\":\"Cognitive Psychology\",\"year\":2014},{\"arxivId\":\"1805.07687\",\"authors\":[{\"authorId\":\"47627548\",\"name\":\"Daniel S. Brown\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":\"10.1609/aaai.v33i01.33017749\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2417d4271a47c9235b75b1a5239d704be8198c9c\",\"title\":\"Machine Teaching for Inverse Reinforcement Learning: Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/2417d4271a47c9235b75b1a5239d704be8198c9c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"}],\"doi\":\"10.1111/j.1467-8640.2008.00330.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6301fe8647f06625adec6d4666a816efda8d22c6\",\"title\":\"LEARNING TO SOLVE PROBLEMS FROM EXERCISES\",\"url\":\"https://www.semanticscholar.org/paper/6301fe8647f06625adec6d4666a816efda8d22c6\",\"venue\":\"Comput. Intell.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Parameswaran Kamalaruban\"},{\"authorId\":null,\"name\":\"Rati Devidze\"},{\"authorId\":null,\"name\":\"Volkan Cevher\"},{\"authorId\":null,\"name\":\"Adish Singla. Interactive teaching algorithms for invers learning\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1905.11867,\",\"year\":2019},{\"arxivId\":\"1402.2092\",\"authors\":[{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"1764328\",\"name\":\"Ilija Bogunovic\"},{\"authorId\":\"145144587\",\"name\":\"G\\u00e1bor Bart\\u00f3k\"},{\"authorId\":\"1697131\",\"name\":\"Amin Karbasi\"},{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83adb036d6677b0f5c7cd605616f4793bd7e5ad1\",\"title\":\"Near-Optimally Teaching the Crowd to Classify\",\"url\":\"https://www.semanticscholar.org/paper/83adb036d6677b0f5c7cd605616f4793bd7e5ad1\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1145/1015330.1015430\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"title\":\"Apprenticeship learning via inverse reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/f65020fc3b1692d7989e099d6b6e698be5a50a93\",\"venue\":\"ICML '04\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3162562\",\"name\":\"Haoqi Zhang\"},{\"authorId\":\"30907562\",\"name\":\"D. Parkes\"},{\"authorId\":\"1775608\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1145/1566374.1566417\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3761b43d38e826bd9c841c40ba15256fd3627215\",\"title\":\"Policy teaching through reward function learning\",\"url\":\"https://www.semanticscholar.org/paper/3761b43d38e826bd9c841c40ba15256fd3627215\",\"venue\":\"EC '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36359915\",\"name\":\"M. Panella\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ff15528cbb9c47bb2324d0299c76bf331994882\",\"title\":\"Associate Editor of the Journal of Computer and System Sciences\",\"url\":\"https://www.semanticscholar.org/paper/9ff15528cbb9c47bb2324d0299c76bf331994882\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35096370\",\"name\":\"M. Cakmak\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"}],\"doi\":\"10.1016/j.artint.2014.08.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c23da87627e46ad5db9a71a9a8c4b31ad823d56d\",\"title\":\"Eliciting good teaching from humans for machine learners\",\"url\":\"https://www.semanticscholar.org/paper/c23da87627e46ad5db9a71a9a8c4b31ad823d56d\",\"venue\":\"Artif. Intell.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nicholas Rhinehart\"},{\"authorId\":null,\"name\":\"Kris M Kitani. First-person activity forecasting with o learning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"In ICCV\",\"url\":\"\",\"venue\":\"pages 3696\\u20133705,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kaustubh R Patil\"},{\"authorId\":null,\"name\":\"Xiaojin Zhu\"},{\"authorId\":null,\"name\":\"\\u0141ukasz Kope\\u0107\"},{\"authorId\":null,\"name\":\"Bradley C Love. Optimal teaching for limitedcapacity human learners\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 2465\\u20132473,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kareem Amin\"},{\"authorId\":null,\"name\":\"Nan Jiang\"},{\"authorId\":null,\"name\":\"Satinder P. Singh. Repeated inverse reinforcement learning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 1813\\u20131822,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":\"10.2460/AJVR.67.2.323\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"title\":\"Algorithms for Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b05b67aca720d0bc39bc9afad02a19f522c7a1bc\",\"venue\":\"ICML\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"1764328\",\"name\":\"Ilija Bogunovic\"},{\"authorId\":\"145144587\",\"name\":\"G\\u00e1bor Bart\\u00f3k\"},{\"authorId\":\"1697131\",\"name\":\"Amin Karbasi\"},{\"authorId\":\"49737028\",\"name\":\"A. Krause\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0340ef4a39e79482e6e62efd217037c2a130e6cf\",\"title\":\"On Actively Teaching the Crowd to Classify\",\"url\":\"https://www.semanticscholar.org/paper/0340ef4a39e79482e6e62efd217037c2a130e6cf\",\"venue\":\"NIPS 2013\",\"year\":2013},{\"arxivId\":\"1612.07796\",\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2017.399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"title\":\"First-Person Activity Forecasting with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3f3610711c9000106b56b8d1d5941c49ee3a5f54\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1801.05927\",\"authors\":[{\"authorId\":\"1832364\",\"name\":\"Xiaojin Zhu\"},{\"authorId\":\"1703727\",\"name\":\"A. Singla\"},{\"authorId\":\"2621728\",\"name\":\"Sandra Zilles\"},{\"authorId\":\"1875900\",\"name\":\"Anna N. Rafferty\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfb84f84f6339920d80307f3e1394722f57cfc4d\",\"title\":\"An Overview of Machine Teaching\",\"url\":\"https://www.semanticscholar.org/paper/cfb84f84f6339920d80307f3e1394722f57cfc4d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"1868677\",\"name\":\"D. Harada\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94066dc12fe31e96af7557838159bde598cb4f10\",\"title\":\"Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping\",\"url\":\"https://www.semanticscholar.org/paper/94066dc12fe31e96af7557838159bde598cb4f10\",\"venue\":\"ICML\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70092712\",\"name\":\"J. Shepherdson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef6402824bc7a5cfa8b4709f5e766eb39e2132f5\",\"title\":\"Machine Intelligence 15\",\"url\":\"https://www.semanticscholar.org/paper/ef6402824bc7a5cfa8b4709f5e766eb39e2132f5\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745219\",\"name\":\"S. Schaal\"}],\"doi\":\"10.1007/978-1-4899-7687-1_100247\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9da09d1e63686706d64782e654d69f13fd292ad\",\"title\":\"Learning by Demonstration\",\"url\":\"https://www.semanticscholar.org/paper/a9da09d1e63686706d64782e654d69f13fd292ad\",\"venue\":\"Encyclopedia of Machine Learning and Data Mining\",\"year\":2017},{\"arxivId\":\"1710.07742\",\"authors\":[{\"authorId\":\"36326884\",\"name\":\"Weiyang Liu\"},{\"authorId\":null,\"name\":\"Bo Dai\"},{\"authorId\":\"50078946\",\"name\":\"Xingguo Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1779453\",\"name\":\"L. Song\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"30bb9c78d16329b4910d68cf650c7572f23ebc2a\",\"title\":\"Towards Black-box Iterative Machine Teaching\",\"url\":\"https://www.semanticscholar.org/paper/30bb9c78d16329b4910d68cf650c7572f23ebc2a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1836885\",\"name\":\"Brenna Argall\"},{\"authorId\":\"144753437\",\"name\":\"S. Chernova\"},{\"authorId\":\"1956361\",\"name\":\"M. Veloso\"},{\"authorId\":\"1699032\",\"name\":\"B. Browning\"}],\"doi\":\"10.1016/j.robot.2008.10.024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e5dfb0b1e54412e799eb0e86d552956cc3a5f54\",\"title\":\"A survey of robot learning from demonstration\",\"url\":\"https://www.semanticscholar.org/paper/4e5dfb0b1e54412e799eb0e86d552956cc3a5f54\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2009},{\"arxivId\":\"1606.03137\",\"authors\":[{\"authorId\":\"1397904824\",\"name\":\"Dylan Hadfield-Menell\"},{\"authorId\":\"145107462\",\"name\":\"S. Russell\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"2745001\",\"name\":\"Anca D. Dragan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777\",\"title\":\"Cooperative Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e6abd43fcb157fde4d4ddc3ac8787ae45dbf777\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaojin Zhu\"},{\"authorId\":null,\"name\":\"Adish Singla\"},{\"authorId\":null,\"name\":\"Sandra Zilles\"},{\"authorId\":null,\"name\":\"Anna N. Rafferty. An overview of machine teaching\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CoRR\",\"url\":\"\",\"venue\":\"abs/1801.05927,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ahmad Humayun\"},{\"authorId\":null,\"name\":\"Charlene Tay\"},{\"authorId\":null,\"name\":\"M. James\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg , and Le Song . Iterative machine teaching\",\"url\":\"\",\"venue\":\"In NIPS\",\"year\":2010},{\"arxivId\":\"1805.10755\",\"authors\":[{\"authorId\":\"144426657\",\"name\":\"Wen Sun\"},{\"authorId\":\"21889436\",\"name\":\"G. Gordon\"},{\"authorId\":\"3288815\",\"name\":\"B. Boots\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a523641cab99381db21ff30df4050f7e2f546b3\",\"title\":\"Dual Policy Iteration\",\"url\":\"https://www.semanticscholar.org/paper/3a523641cab99381db21ff30df4050f7e2f546b3\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1507.04888\",\"authors\":[{\"authorId\":\"3331786\",\"name\":\"Markus Wulfmeier\"},{\"authorId\":\"3214791\",\"name\":\"Peter Ondruska\"},{\"authorId\":\"1834086\",\"name\":\"I. Posner\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9ba266a4a4644e877fc37a64be3beddce8904cf7\",\"title\":\"Maximum Entropy Deep Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ba266a4a4644e877fc37a64be3beddce8904cf7\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35096370\",\"name\":\"M. Cakmak\"},{\"authorId\":\"144518313\",\"name\":\"M. Lopes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"739a4c8839311f6cf77ce288d8b31241cfc238a6\",\"title\":\"Algorithmic and Human Teaching of Sequential Decision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/739a4c8839311f6cf77ce288d8b31241cfc238a6\",\"venue\":\"AAAI\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ofra Amir\"},{\"authorId\":null,\"name\":\"Ece Kamar\"},{\"authorId\":null,\"name\":\"Andrey Kolobov\"},{\"authorId\":null,\"name\":\"Barbara J. Grosz. Interactive teaching strategies for agen training\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In IJCAI\",\"url\":\"\",\"venue\":\"pages 804\\u2013811,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jonathan Sorg\"},{\"authorId\":null,\"name\":\"Satinder P. Singh\"},{\"authorId\":null,\"name\":\"Richard L. Lewis. Reward design via online gradient ascent\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 2190\\u20132198,\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"34961461\",\"name\":\"Andrew L. Maas\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"144021446\",\"name\":\"Anind K. Dey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"11b6bdfe36c48b11367b27187da11d95892f0361\",\"title\":\"Maximum Entropy Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/11b6bdfe36c48b11367b27187da11d95892f0361\",\"venue\":\"AAAI\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144497046\",\"name\":\"N. Nilsson\"}],\"doi\":\"10.7551/mitpress/11723.003.0006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b886f2c097b635ee9550ca29fff7dcbbb7727ff7\",\"title\":\"Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/b886f2c097b635ee9550ca29fff7dcbbb7727ff7\",\"venue\":\"IFIP Congress\",\"year\":1974},{\"arxivId\":\"1705.05427\",\"authors\":[{\"authorId\":\"39617345\",\"name\":\"K. Amin\"},{\"authorId\":null,\"name\":\"Nan Jiang\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7251354318a25b0f304bfe756c8749d492106139\",\"title\":\"Repeated Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/7251354318a25b0f304bfe756c8749d492106139\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145125979\",\"name\":\"Francisco S. Melo\"},{\"authorId\":\"144487969\",\"name\":\"Carla Guerra\"},{\"authorId\":\"144518313\",\"name\":\"M. Lopes\"}],\"doi\":\"10.24963/ijcai.2018/356\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"624f05ee6ac46c8d7a5ce451c173234ae0abcddd\",\"title\":\"Interactive Optimal Teaching with Unknown Learners\",\"url\":\"https://www.semanticscholar.org/paper/624f05ee6ac46c8d7a5ce451c173234ae0abcddd\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stefan Schaal. Learning from demonstration\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In NIPS\",\"url\":\"\",\"venue\":\"pages 1040\\u20131046,\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1986848\",\"name\":\"Z. Popovic\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66ac3d7d8e75a64766fc59747d580bfa6d9e4031\",\"title\":\"Feature Construction for Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/66ac3d7d8e75a64766fc59747d580bfa6d9e4031\",\"venue\":\"NIPS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1801209\",\"name\":\"Lisa Torrey\"},{\"authorId\":\"39286677\",\"name\":\"Matthew E. Taylor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"902fccdc900a06246ee0f3f1ee7b58b68ca41916\",\"title\":\"Teaching on a budget: agents advising agents in reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/902fccdc900a06246ee0f3f1ee7b58b68ca41916\",\"venue\":\"AAMAS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32150954\",\"name\":\"S. A. Goldman\"},{\"authorId\":\"81338045\",\"name\":\"M. Kearns\"}],\"doi\":\"10.1006/jcss.1995.1003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d4081bba37b1231bef9296757c05e49423ecfbc\",\"title\":\"On the complexity of teaching\",\"url\":\"https://www.semanticscholar.org/paper/1d4081bba37b1231bef9296757c05e49423ecfbc\",\"venue\":\"COLT '91\",\"year\":1991},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stuart Russell. Learning agents for uncertain environments\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"In COLT\",\"url\":\"\",\"venue\":\"pages 101\\u2013103,\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Stuart Russell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning agents for uncertain environments . In COLT , pages 101 \\u2013 103 , 1998 . [ Schaal , 1997 ] Stefan Schaal . Learning from demonstration\",\"url\":\"\",\"venue\":\"\",\"year\":null}],\"title\":\"Interactive Teaching Algorithms for Inverse Reinforcement Learning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Driving simulator\",\"topicId\":\"247818\",\"url\":\"https://www.semanticscholar.org/topic/247818\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Simulation\",\"topicId\":\"194\",\"url\":\"https://www.semanticscholar.org/topic/194\"},{\"topic\":\"LinuxMCE\",\"topicId\":\"3939342\",\"url\":\"https://www.semanticscholar.org/topic/3939342\"}],\"url\":\"https://www.semanticscholar.org/paper/ceeb815de098c353b83fa04389b88f7963e052d9\",\"venue\":\"IJCAI\",\"year\":2019}\n"