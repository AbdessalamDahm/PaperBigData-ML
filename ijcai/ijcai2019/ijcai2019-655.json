"{\"abstract\":\"Stacked dilated convolutions used in Wavenet have been shown effective for generating high-quality audios. By replacing pooling/striding with dilation in convolution layers, they can preserve high-resolution information and still reach distant locations. Producing high-resolution predictions is also crucial in music source separation, whose goal is to separate different sound sources while maintaining the quality of the separated sounds. Therefore, this paper investigates using stacked dilated convolutions as the backbone for music source separation. However, while stacked dilated convolutions can reach wider context than standard convolutions, their effective receptive fields are still fixed and may not be wide enough for complex music audio signals. To reach information at remote locations, we propose to combine dilated convolution with a modified version of gated recurrent units (GRU) called the `Dilated GRU' to form a block. A Dilated GRU unit receives information from k steps before instead of the previous step for a fixed k. This modification allows a GRU unit to reach a location with fewer recurrent steps and run faster because it can execute partially in parallel. We show that the proposed model with a stack of such blocks performs equally well or better than the state-of-the-art models for separating vocals and accompaniments.\",\"arxivId\":\"1906.01203\",\"authors\":[{\"authorId\":\"1840108\",\"name\":\"J. Liu\",\"url\":\"https://www.semanticscholar.org/author/1840108\"},{\"authorId\":\"119607803\",\"name\":\"Yi-Hsuan Yang\",\"url\":\"https://www.semanticscholar.org/author/119607803\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3078142\",\"name\":\"Woo-Sung Choi\"},{\"authorId\":\"153657983\",\"name\":\"Minseok Kim\"},{\"authorId\":\"1783009\",\"name\":\"Jaehwa Chung\"},{\"authorId\":\"34798433\",\"name\":\"Dae-Won Lee\"},{\"authorId\":\"47165147\",\"name\":\"Soon-Young Jung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9e3ffacbf48767354d11108c339716f35be44a2\",\"title\":\"Investigating Deep Neural Transformations for Spectrogram-based Musical Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/d9e3ffacbf48767354d11108c339716f35be44a2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5866983\",\"name\":\"Yin-Cheng Yeh\"},{\"authorId\":\"1840108\",\"name\":\"J. Liu\"},{\"authorId\":\"37188394\",\"name\":\"Wen-Yi Hsiao\"},{\"authorId\":\"46844441\",\"name\":\"Yu-Siang Huang\"},{\"authorId\":\"145142378\",\"name\":\"Yi-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"176a1482fa527c0e8ec2fa0dfd1cd53c5d43b80b\",\"title\":\"LEARNING TO GENERATE JAZZ AND POP PIANO MUSIC FROM AUDIO VIA MIR TECHNIQUES\",\"url\":\"https://www.semanticscholar.org/paper/176a1482fa527c0e8ec2fa0dfd1cd53c5d43b80b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.00816\",\"authors\":[{\"authorId\":\"31844008\",\"name\":\"Weitao Yuan\"},{\"authorId\":\"123570706\",\"name\":\"B. Dong\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"2196412\",\"name\":\"M. Unoki\"},{\"authorId\":\"144144027\",\"name\":\"Wenwu Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a14fbcf7cc122007e590a0fec50f860f32d11c07\",\"title\":\"Evolving Multi-Resolution Pooling CNN for Monaural Singing Voice Separation\",\"url\":\"https://www.semanticscholar.org/paper/a14fbcf7cc122007e590a0fec50f860f32d11c07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01733\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"53edf8007c2ab11a2dcd1646627d47f9cb41ba51\",\"title\":\"D3Net: Densely connected multidilated DenseNet for music source separation\",\"url\":\"https://www.semanticscholar.org/paper/53edf8007c2ab11a2dcd1646627d47f9cb41ba51\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.06817\",\"authors\":[{\"authorId\":\"46527521\",\"name\":\"Tsung-Han Hsieh\"},{\"authorId\":\"12213855\",\"name\":\"Kai-Hsiang Cheng\"},{\"authorId\":\"1979275\",\"name\":\"Zhe-Cheng Fan\"},{\"authorId\":\"119607879\",\"name\":\"Y. Yang\"},{\"authorId\":\"145142378\",\"name\":\"Yi-Hsuan Yang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"746d7599af91dbec83be38ae2eb5131ae64343d9\",\"title\":\"Addressing The Confounds Of Accompaniments In Singer Identification\",\"url\":\"https://www.semanticscholar.org/paper/746d7599af91dbec83be38ae2eb5131ae64343d9\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2002.06595\",\"authors\":[{\"authorId\":\"7355688\",\"name\":\"Jayneel Parekh\"},{\"authorId\":\"144861416\",\"name\":\"P. Rao\"},{\"authorId\":\"119607803\",\"name\":\"Yi-Hsuan Yang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054473\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2878a23d01806a5c9bee0305e3863abc4ba2968d\",\"title\":\"Speech-To-Singing Conversion in an Encoder-Decoder Framework\",\"url\":\"https://www.semanticscholar.org/paper/2878a23d01806a5c9bee0305e3863abc4ba2968d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2008.00616\",\"authors\":[{\"authorId\":\"27671219\",\"name\":\"Yun-Ning Hung\"},{\"authorId\":\"1882886\",\"name\":\"Alexander Lerch\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a939f5ef5c4a797c1b6af1481c9600ab1c4ab1b0\",\"title\":\"Multitask learning for instrument activation aware music source separation\",\"url\":\"https://www.semanticscholar.org/paper/a939f5ef5c4a797c1b6af1481c9600ab1c4ab1b0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.08526\",\"authors\":[{\"authorId\":\"1840108\",\"name\":\"J. Liu\"},{\"authorId\":\"1596827301\",\"name\":\"Yu-Hua Chen\"},{\"authorId\":\"5866983\",\"name\":\"Yin-Cheng Yeh\"},{\"authorId\":\"119607803\",\"name\":\"Yi-Hsuan Yang\"}],\"doi\":\"10.21437/interspeech.2020-1137\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46a34e4239adfe222bdad453821372904b5d0b40\",\"title\":\"Unconditional Audio Generation with Generative Adversarial Networks and Cycle Regularization\",\"url\":\"https://www.semanticscholar.org/paper/46a34e4239adfe222bdad453821372904b5d0b40\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2011.11844\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3015f8a91bcb75881028a1475b37f4e21aa83496\",\"title\":\"Densely connected multidilated convolutional networks for dense prediction tasks\",\"url\":\"https://www.semanticscholar.org/paper/3015f8a91bcb75881028a1475b37f4e21aa83496\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.02591\",\"authors\":[{\"authorId\":\"1471679454\",\"name\":\"Woo-Sung Choi\"},{\"authorId\":\"123446855\",\"name\":\"Minseok Kim\"},{\"authorId\":\"1783009\",\"name\":\"Jaehwa Chung\"},{\"authorId\":\"34798433\",\"name\":\"Dae-Won Lee\"},{\"authorId\":\"47165147\",\"name\":\"Soon-Young Jung\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"66f79a0e8fcf538e3000210e88749a664b72d119\",\"title\":\"Investigating U-Nets with various Intermediate Blocks for Spectrogram-based Singing Voice Separation.\",\"url\":\"https://www.semanticscholar.org/paper/66f79a0e8fcf538e3000210e88749a664b72d119\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.11408\",\"authors\":[{\"authorId\":\"66560891\",\"name\":\"Junzhe Zhu\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"2769735\",\"name\":\"Leda Sari\"}],\"doi\":\"10.21437/interspeech.2020-2430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"946e7f2dae7bd1ef88f5c34e8a33a77cc14e4a62\",\"title\":\"Identify Speakers in Cocktail Parties with End-to-End Attention\",\"url\":\"https://www.semanticscholar.org/paper/946e7f2dae7bd1ef88f5c34e8a33a77cc14e4a62\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2005.13835\",\"authors\":[{\"authorId\":\"71757074\",\"name\":\"D. Wu\"},{\"authorId\":\"119607803\",\"name\":\"Yi-Hsuan Yang\"}],\"doi\":\"10.21437/interspeech.2020-1984\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78f1d13754b2ad719fa8e0e5f2bfeff18a4a73c5\",\"title\":\"Speech-to-Singing Conversion based on Boundary Equilibrium GAN\",\"url\":\"https://www.semanticscholar.org/paper/78f1d13754b2ad719fa8e0e5f2bfeff18a4a73c5\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2008.02480\",\"authors\":[{\"authorId\":\"9698626\",\"name\":\"Ching-Yu Chiu\"},{\"authorId\":\"37188394\",\"name\":\"Wen-Yi Hsiao\"},{\"authorId\":\"5866983\",\"name\":\"Yin-Cheng Yeh\"},{\"authorId\":\"145142378\",\"name\":\"Yi-Hsuan Yang\"},{\"authorId\":\"2510471\",\"name\":\"A. Su\"}],\"doi\":\"10.1109/MMSP48831.2020.9287146\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e370f882de246b49ab94ab65f3a936d249c52883\",\"title\":\"Mixing-Specific Data Augmentation Techniques for Improved Blind Violin/Piano Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/e370f882de246b49ab94ab65f3a936d249c52883\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"1912.11747\",\"authors\":[{\"authorId\":\"1840108\",\"name\":\"J. Liu\"},{\"authorId\":\"49069469\",\"name\":\"Y. Chen\"},{\"authorId\":\"5866983\",\"name\":\"Yin-Cheng Yeh\"},{\"authorId\":\"119607803\",\"name\":\"Yi-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9e5ad2e37d4bcd68349569fe64e73db563aeeee\",\"title\":\"Score and Lyrics-Free Singing Voice Generation\",\"url\":\"https://www.semanticscholar.org/paper/c9e5ad2e37d4bcd68349569fe64e73db563aeeee\",\"venue\":\"ICCC\",\"year\":2020},{\"arxivId\":\"2010.03164\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"151209080\",\"name\":\"Shota Inoue\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9bf2ffb386fa24d6e6d3c56cc24babbed855949\",\"title\":\"Adversarial attacks on audio source separation\",\"url\":\"https://www.semanticscholar.org/paper/d9bf2ffb386fa24d6e6d3c56cc24babbed855949\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11631\",\"authors\":[{\"authorId\":\"1471679454\",\"name\":\"Woo-Sung Choi\"},{\"authorId\":\"65946876\",\"name\":\"Minseok Kim\"},{\"authorId\":\"1783009\",\"name\":\"Jaehwa Chung\"},{\"authorId\":\"47165147\",\"name\":\"Soon-Young Jung\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ff4296836acc0a92ead3239a313ba43aaa19b013\",\"title\":\"LaSAFT: Latent Source Attentive Frequency Transformation for Conditioned Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/ff4296836acc0a92ead3239a313ba43aaa19b013\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.15772\",\"authors\":[{\"authorId\":\"145456149\",\"name\":\"A. Kolokolova\"},{\"authorId\":\"1736757672\",\"name\":\"M. Billard\"},{\"authorId\":\"1913616\",\"name\":\"R. Bishop\"},{\"authorId\":\"1736830099\",\"name\":\"Moustafa Elsisy\"},{\"authorId\":\"1736801602\",\"name\":\"Zachary Northcott\"},{\"authorId\":\"119684221\",\"name\":\"Laura M. Graves\"},{\"authorId\":\"1502108335\",\"name\":\"Vineel Nagisetty\"},{\"authorId\":\"1736817214\",\"name\":\"Heather Patey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7c179eb3c7a3ce5804dea736ab7d57ece14a11c\",\"title\":\"GANs & Reels: Creating Irish Music using a Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/d7c179eb3c7a3ce5804dea736ab7d57ece14a11c\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":174797938,\"doi\":\"10.24963/ijcai.2019/655\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"77036414bf957f4de90fd9351c50efd6fbc650c9\",\"references\":[{\"arxivId\":\"1710.02224\",\"authors\":[{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"11860412\",\"name\":\"Y. Zhang\"},{\"authorId\":\"12148461\",\"name\":\"W. Han\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"101110803\",\"name\":\"Wei Tan\"},{\"authorId\":\"50471144\",\"name\":\"Xiaodong Cui\"},{\"authorId\":\"2819135\",\"name\":\"M. Witbrock\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2dad7e558a1e2982d0d42042021f4cde4af04abf\",\"title\":\"Dilated Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2dad7e558a1e2982d0d42042021f4cde4af04abf\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1711.01437\",\"authors\":[{\"authorId\":\"2343602\",\"name\":\"S. I. Mimilakis\"},{\"authorId\":\"3193584\",\"name\":\"Konstantinos Drossos\"},{\"authorId\":\"144660120\",\"name\":\"J. F. Santos\"},{\"authorId\":\"1724293\",\"name\":\"G. Schuller\"},{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1109/ICASSP.2018.8461822\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddc3e40664100cead1e18cf7cb21a7a31ace1683\",\"title\":\"Monaural Singing Voice Separation with Skip-Filtering Connections and Recurrent Inference of Time-Frequency Mask\",\"url\":\"https://www.semanticscholar.org/paper/ddc3e40664100cead1e18cf7cb21a7a31ace1683\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1706.09588\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":\"10.1109/WASPAA.2017.8169987\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f14069aaa8b234dfafd3292863c0e610288fbc80\",\"title\":\"Multi-Scale multi-band densenets for audio source separation\",\"url\":\"https://www.semanticscholar.org/paper/f14069aaa8b234dfafd3292863c0e610288fbc80\",\"venue\":\"2017 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)\",\"year\":2017},{\"arxivId\":\"1610.00527\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b01871c114b122340209562972ff515b86b16ccf\",\"title\":\"Video Pixel Networks\",\"url\":\"https://www.semanticscholar.org/paper/b01871c114b122340209562972ff515b86b16ccf\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1409.1259\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/W14-4012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eb09fecd75eb27825dce4f964b97f4f5cc399d7\",\"title\":\"On the Properties of Neural Machine Translation: Encoder-Decoder Approaches\",\"url\":\"https://www.semanticscholar.org/paper/1eb09fecd75eb27825dce4f964b97f4f5cc399d7\",\"venue\":\"SSST@EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2504395\",\"name\":\"S. Uhlich\"},{\"authorId\":\"18155424\",\"name\":\"M. Porcu\"},{\"authorId\":\"40319120\",\"name\":\"F. Giron\"},{\"authorId\":\"18132765\",\"name\":\"Michael Enenkl\"},{\"authorId\":\"143699085\",\"name\":\"T. Kemp\"},{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":\"10.1109/ICASSP.2017.7952158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73e61b31cc673b1bbb21595d50044c860f186fe0\",\"title\":\"Improving music source separation based on deep neural networks through data augmentation and network blending\",\"url\":\"https://www.semanticscholar.org/paper/73e61b31cc673b1bbb21595d50044c860f186fe0\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1703.01161\",\"authors\":[{\"authorId\":\"9948791\",\"name\":\"A. S. Vezhnevets\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"049c6e5736313374c6e594c34b9be89a3a09dced\",\"title\":\"FeUdal Networks for Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/049c6e5736313374c6e594c34b9be89a3a09dced\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82616570\",\"name\":\"Len Vande Veire\"},{\"authorId\":\"51204489\",\"name\":\"T. D. Bie\"}],\"doi\":\"10.1186/S13636-018-0134-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8aa9ddd93cfe2c44bf1d2c9422ad244e6885599e\",\"title\":\"From raw audio to a seamless mix: creating an automated DJ system for Drum and Bass\",\"url\":\"https://www.semanticscholar.org/paper/8aa9ddd93cfe2c44bf1d2c9422ad244e6885599e\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2018},{\"arxivId\":\"1805.02410\",\"authors\":[{\"authorId\":\"47893464\",\"name\":\"Naoya Takahashi\"},{\"authorId\":\"46256604\",\"name\":\"Nabarun Goswami\"},{\"authorId\":\"2744777\",\"name\":\"Yuki Mitsufuji\"}],\"doi\":\"10.1109/IWAENC.2018.8521383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1604967339f9067f787257724022bc1692d07846\",\"title\":\"Mmdenselstm: An Efficient Combination of Convolutional and Recurrent Neural Networks for Audio Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/1604967339f9067f787257724022bc1692d07846\",\"venue\":\"2018 16th International Workshop on Acoustic Signal Enhancement (IWAENC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35581798\",\"name\":\"G. Roma\"},{\"authorId\":\"47972030\",\"name\":\"O. Green\"},{\"authorId\":\"40536642\",\"name\":\"Pierre Alexandre Tremblay\"}],\"doi\":\"10.1007/978-3-319-93764-9_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa859809feff84cb0d572e6497a8f44bd73d2dcf\",\"title\":\"Improving Single-Network Single-Channel Separation of Musical Audio with Convolutional Layers\",\"url\":\"https://www.semanticscholar.org/paper/fa859809feff84cb0d572e6497a8f44bd73d2dcf\",\"venue\":\"LVA/ICA\",\"year\":2018},{\"arxivId\":\"1511.07122\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"title\":\"Multi-Scale Context Aggregation by Dilated Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47515529\",\"name\":\"A. Liutkus\"},{\"authorId\":\"2206907\",\"name\":\"Fabian-Robert St\\u00f6ter\"},{\"authorId\":\"2939947\",\"name\":\"Zafar Rafii\"},{\"authorId\":\"32495809\",\"name\":\"Daichi Kitamura\"},{\"authorId\":\"1744054\",\"name\":\"B. Rivet\"},{\"authorId\":\"1798203\",\"name\":\"N. Ito\"},{\"authorId\":\"144101246\",\"name\":\"Nobutaka Ono\"},{\"authorId\":\"33330734\",\"name\":\"Julie Fontecave Jallon\"}],\"doi\":\"10.1007/978-3-319-53547-0_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92b10ffb51f2a1a55ac1a0eb83cc40a603ecc918\",\"title\":\"The 2016 Signal Separation Evaluation Campaign\",\"url\":\"https://www.semanticscholar.org/paper/92b10ffb51f2a1a55ac1a0eb83cc40a603ecc918\",\"venue\":\"LVA/ICA\",\"year\":2017},{\"arxivId\":\"1804.08300\",\"authors\":[{\"authorId\":\"2939947\",\"name\":\"Zafar Rafii\"},{\"authorId\":\"47515529\",\"name\":\"A. Liutkus\"},{\"authorId\":\"41074845\",\"name\":\"Fabian-Robert St\\u00f6ter\"},{\"authorId\":\"2343602\",\"name\":\"S. I. Mimilakis\"},{\"authorId\":\"48561289\",\"name\":\"D. Fitzgerald\"},{\"authorId\":\"144893701\",\"name\":\"B. Pardo\"}],\"doi\":\"10.1109/TASLP.2018.2825440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac733afa05b194d7ef4859ebd3d62be7ef5c6685\",\"title\":\"An Overview of Lead and Accompaniment Separation in Music\",\"url\":\"https://www.semanticscholar.org/paper/ac733afa05b194d7ef4859ebd3d62be7ef5c6685\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1807.01898\",\"authors\":[{\"authorId\":\"1840108\",\"name\":\"J. Liu\"},{\"authorId\":\"1689230\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICMLA.2018.00123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf4b3ddef37a4f79c89b288793e892fc0aef00ca\",\"title\":\"Denoising Auto-Encoder with Recurrent Skip Connections and Residual Regression for Music Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/bf4b3ddef37a4f79c89b288793e892fc0aef00ca\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39022297\",\"name\":\"A. Jansson\"},{\"authorId\":\"3268101\",\"name\":\"Eric J. Humphrey\"},{\"authorId\":\"1681005\",\"name\":\"N. Montecchio\"},{\"authorId\":\"13709609\",\"name\":\"Rachel M. Bittner\"},{\"authorId\":\"47311278\",\"name\":\"A. Kumar\"},{\"authorId\":\"3205667\",\"name\":\"Tillman Weyde\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"83ea11b45cba0fc7ee5d60f608edae9c1443861d\",\"title\":\"Singing Voice Separation with Deep U-Net Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/83ea11b45cba0fc7ee5d60f608edae9c1443861d\",\"venue\":\"ISMIR\",\"year\":2017},{\"arxivId\":\"1806.03185\",\"authors\":[{\"authorId\":\"39914594\",\"name\":\"D. Stoller\"},{\"authorId\":\"2766157\",\"name\":\"S. Ewert\"},{\"authorId\":\"145039466\",\"name\":\"S. Dixon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6e8386c720d929ba46f1665617645f0291d415\",\"title\":\"Wave-U-Net: A Multi-Scale Neural Network for End-to-End Audio Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/cd6e8386c720d929ba46f1665617645f0291d415\",\"venue\":\"ISMIR\",\"year\":2018},{\"arxivId\":\"1707.01083\",\"authors\":[{\"authorId\":\"50875121\",\"name\":\"X. Zhang\"},{\"authorId\":\"47155568\",\"name\":\"X. Zhou\"},{\"authorId\":\"3287035\",\"name\":\"Mengxiao Lin\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPR.2018.00716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9da734397acd7ff7c557960c62fb1b400b27bd89\",\"title\":\"ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/9da734397acd7ff7c557960c62fb1b400b27bd89\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145183926\",\"name\":\"Aditya Nugraha\"},{\"authorId\":\"47515529\",\"name\":\"A. Liutkus\"},{\"authorId\":\"1692147\",\"name\":\"E. Vincent\"}],\"doi\":\"10.1109/EUSIPCO.2016.7760548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5029c5c086b49bbfb8b842cac936c813bd7d846\",\"title\":\"Multichannel music separation with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e5029c5c086b49bbfb8b842cac936c813bd7d846\",\"venue\":\"2016 24th European Signal Processing Conference (EUSIPCO)\",\"year\":2016},{\"arxivId\":\"1609.03499\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1691713\",\"name\":\"H. Zen\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df0402517a7338ae28bc54acaac400de6b456a46\",\"title\":\"WaveNet: A Generative Model for Raw Audio\",\"url\":\"https://www.semanticscholar.org/paper/df0402517a7338ae28bc54acaac400de6b456a46\",\"venue\":\"SSW\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33802220\",\"name\":\"J. Paulus\"},{\"authorId\":\"1684454\",\"name\":\"T. Virtanen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"005b5d7c05e40f6bedf1ad87762776bfb7121d0b\",\"title\":\"Drum transcription with non-negative spectrogram factorisation\",\"url\":\"https://www.semanticscholar.org/paper/005b5d7c05e40f6bedf1ad87762776bfb7121d0b\",\"venue\":\"2005 13th European Signal Processing Conference\",\"year\":2005},{\"arxivId\":\"1611.09288\",\"authors\":[{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcfdafc2627fafb739b9e22670d9853f889bc9b4\",\"title\":\"Dense Prediction on Sequences with Time-Dilated Convolutions for Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bcfdafc2627fafb739b9e22670d9853f889bc9b4\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1704.04861\",\"authors\":[{\"authorId\":\"144727050\",\"name\":\"A. Howard\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":null,\"name\":\"Bo Chen\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"},{\"authorId\":\"47825047\",\"name\":\"W. Wang\"},{\"authorId\":\"47447630\",\"name\":\"Tobias Weyand\"},{\"authorId\":\"2612392\",\"name\":\"M. Andreetto\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3647d6d0f151dc05626449ee09cc7bce55be497e\",\"title\":\"MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications\",\"url\":\"https://www.semanticscholar.org/paper/3647d6d0f151dc05626449ee09cc7bce55be497e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.06267\",\"authors\":[{\"authorId\":\"2206907\",\"name\":\"Fabian-Robert St\\u00f6ter\"},{\"authorId\":\"47515529\",\"name\":\"A. Liutkus\"},{\"authorId\":\"1798203\",\"name\":\"N. Ito\"}],\"doi\":\"10.1007/978-3-319-93764-9_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48ba025acf306b0b422859a2e523838fe4c0c4bc\",\"title\":\"The 2018 Signal Separation Evaluation Campaign\",\"url\":\"https://www.semanticscholar.org/paper/48ba025acf306b0b422859a2e523838fe4c0c4bc\",\"venue\":\"LVA/ICA\",\"year\":2018},{\"arxivId\":\"1602.07868\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d2c6941a9b4608ba52b328369a3352db2092ae0\",\"title\":\"Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3d2c6941a9b4608ba52b328369a3352db2092ae0\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tom Schaul\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\", Nicolas Heess , Max Jader - berg , David Silver , and Koray Kavukcuoglu . FeUdal networks for hierarchical reinforcement learning\",\"url\":\"\",\"venue\":\"\",\"year\":null}],\"title\":\"Dilated Convolution with Dilated GRU for Music Source Separation\",\"topics\":[{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Source separation\",\"topicId\":\"39125\",\"url\":\"https://www.semanticscholar.org/topic/39125\"},{\"topic\":\"Image resolution\",\"topicId\":\"881\",\"url\":\"https://www.semanticscholar.org/topic/881\"},{\"topic\":\"Dilation (morphology)\",\"topicId\":\"87058\",\"url\":\"https://www.semanticscholar.org/topic/87058\"},{\"topic\":\"anatomical layer\",\"topicId\":\"3245\",\"url\":\"https://www.semanticscholar.org/topic/3245\"},{\"topic\":\"Audio Media\",\"topicId\":\"14912\",\"url\":\"https://www.semanticscholar.org/topic/14912\"},{\"topic\":\"Vertebral column\",\"topicId\":\"3204\",\"url\":\"https://www.semanticscholar.org/topic/3204\"},{\"topic\":\"Internet backbone\",\"topicId\":\"15478\",\"url\":\"https://www.semanticscholar.org/topic/15478\"},{\"topic\":\"Pathological Dilatation\",\"topicId\":\"24136\",\"url\":\"https://www.semanticscholar.org/topic/24136\"}],\"url\":\"https://www.semanticscholar.org/paper/77036414bf957f4de90fd9351c50efd6fbc650c9\",\"venue\":\"IJCAI\",\"year\":2019}\n"