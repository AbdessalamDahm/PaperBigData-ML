"{\"abstract\":\"Carefully crafted, often imperceptible, adversarial perturbations have been shown to cause state-of-the-art models to yield extremely inaccurate outputs, rendering them unsuitable for safety-critical application domains. In addition, recent work has shown that constraining the attack space to a low frequency regime is particularly effective. Yet, it remains unclear whether this is due to generally constraining the attack search space or specifically removing high frequency components from consideration. By systematically controlling the frequency components of the perturbation, evaluating against the top-placing defense submissions in the NeurIPS 2017 competition, we empirically show that performance improvements in both the white-box and black-box transfer settings are yielded only when low frequency components are preserved. In fact, the defended models based on adversarial training are roughly as vulnerable to low frequency perturbations as undefended models, suggesting that the purported robustness of state-of-the-art ImageNet defenses is reliant upon adversarial perturbations being high frequency in nature. We do find that under $\\\\ell_\\\\infty$ $\\\\epsilon=16/255$, the competition distortion bound, low frequency perturbations are indeed perceptible. This questions the use of the $\\\\ell_\\\\infty$-norm, in particular, as a distortion metric, and, in turn, suggests that explicitly considering the frequency space is promising for learning robust models which better align with human perception.\",\"arxivId\":\"1903.00073\",\"authors\":[{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\",\"url\":\"https://www.semanticscholar.org/author/49738125\"},{\"authorId\":\"27623787\",\"name\":\"G. W. Ding\",\"url\":\"https://www.semanticscholar.org/author/27623787\"},{\"authorId\":\"47649984\",\"name\":\"Marcus A. Brubaker\",\"url\":\"https://www.semanticscholar.org/author/47649984\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":\"2002.10349\",\"authors\":[{\"authorId\":\"1502054072\",\"name\":\"Giuseppe Ughi\"},{\"authorId\":\"2019145\",\"name\":\"Vinayak Abrol\"},{\"authorId\":\"144770610\",\"name\":\"J. Tanner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f4e76fa3a6fe3b56465dd04c2574874db2ef843\",\"title\":\"A Model-Based Derivative-Free Approach to Black-Box Adversarial Examples: BOBYQA\",\"url\":\"https://www.semanticscholar.org/paper/0f4e76fa3a6fe3b56465dd04c2574874db2ef843\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.08758\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"21454543\",\"name\":\"Jared S. Frank\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e6c979fb345f673ffc997e377ae724a8c6cd022\",\"title\":\"Low Frequency Adversarial Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/7e6c979fb345f673ffc997e377ae724a8c6cd022\",\"venue\":\"UAI\",\"year\":2019},{\"arxivId\":\"2011.11957\",\"authors\":[{\"authorId\":\"1560221518\",\"name\":\"Yingpeng Deng\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbe9f46fad17f4c06c56c8da7afbdcb6f642c980\",\"title\":\"Towards Imperceptible Universal Attacks on Texture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe9f46fad17f4c06c56c8da7afbdcb6f642c980\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.02637\",\"authors\":[{\"authorId\":\"27623787\",\"name\":\"G. W. Ding\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"50854174\",\"name\":\"Kry Yik Chau Lui\"},{\"authorId\":\"2136577\",\"name\":\"Ruitong Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93314b89c218c02cc1a32cad7071215693599907\",\"title\":\"Max-Margin Adversarial (MMA) Training: Direct Input Space Margin Maximization through Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/93314b89c218c02cc1a32cad7071215693599907\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2005.03141\",\"authors\":[{\"authorId\":\"50219096\",\"name\":\"Zifan Wang\"},{\"authorId\":null,\"name\":\"Yilin Yang\"},{\"authorId\":\"71130557\",\"name\":\"Ankit Shrivastava\"},{\"authorId\":\"40545519\",\"name\":\"Varun Rawal\"},{\"authorId\":\"152385087\",\"name\":\"Zihao Ding\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa95899b59dc20ddd23f724c4cc107ea54f1688e\",\"title\":\"Towards Frequency-Based Explanation for Robust CNN\",\"url\":\"https://www.semanticscholar.org/paper/fa95899b59dc20ddd23f724c4cc107ea54f1688e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.12170\",\"authors\":[{\"authorId\":\"2354483\",\"name\":\"Woohyung Chun\"},{\"authorId\":\"47324550\",\"name\":\"Sung-min Hong\"},{\"authorId\":\"2392545\",\"name\":\"Jun-Ho Huh\"},{\"authorId\":\"1709009\",\"name\":\"I. Kang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b6d0d5e6325fe4fb8ee6df6f528e38054032ea55\",\"title\":\"Mitigating large adversarial perturbations on X-MAS (X minus Moving Averaged Samples)\",\"url\":\"https://www.semanticscholar.org/paper/b6d0d5e6325fe4fb8ee6df6f528e38054032ea55\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.09624\",\"authors\":[{\"authorId\":\"1402924631\",\"name\":\"Guillermo Ortiz-Jim\\u00e9nez\"},{\"authorId\":\"2618576\",\"name\":\"A. Modas\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"1423349315\",\"name\":\"Pascal Frossard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77496dbc5dcd05e928d13af992b7903b36d651dd\",\"title\":\"Optimism in the Face of Adversity: Understanding and Improving Deep Learning through Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/77496dbc5dcd05e928d13af992b7903b36d651dd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.05254\",\"authors\":[{\"authorId\":null,\"name\":\"Yongwei Wang\"},{\"authorId\":\"112912334\",\"name\":\"Mingquan Feng\"},{\"authorId\":\"1484815819\",\"name\":\"R. Ward\"},{\"authorId\":\"38106845\",\"name\":\"Z. Wang\"},{\"authorId\":\"49680751\",\"name\":\"Lanjun Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a17b0280066ae8b632194f7ff44d98028ff60b7d\",\"title\":\"Perception Improvement for Free: Exploring Imperceptible Black-box Adversarial Attacks on Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/a17b0280066ae8b632194f7ff44d98028ff60b7d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.01901\",\"authors\":[{\"authorId\":\"1502054072\",\"name\":\"Giuseppe Ughi\"},{\"authorId\":\"2019145\",\"name\":\"Vinayak Abrol\"},{\"authorId\":\"144770610\",\"name\":\"J. Tanner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8813cd439cd89540585acc6e6bcadb21991e3239\",\"title\":\"An Empirical Study of Derivative-Free-Optimization Algorithms for Targeted Black-Box Attacks in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8813cd439cd89540585acc6e6bcadb21991e3239\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13545\",\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"144234489\",\"name\":\"Xindi Wu\"},{\"authorId\":\"38253388\",\"name\":\"Pengcheng Yin\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/cvpr42600.2020.00871\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bceeb52a9d4a4127d6664eea4870e8a60b378eff\",\"title\":\"High-Frequency Component Helps Explain the Generalization of Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/bceeb52a9d4a4127d6664eea4870e8a60b378eff\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.02256\",\"authors\":[{\"authorId\":\"145931510\",\"name\":\"R. Raju\"},{\"authorId\":\"1704076\",\"name\":\"Mikko H. Lipasti\"}],\"doi\":\"10.1109/DSN-W50199.2020.00016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b10e061aa8b69b22236d479c681d837038e0139e\",\"title\":\"BlurNet: Defense by Filtering the Feature Maps\",\"url\":\"https://www.semanticscholar.org/paper/b10e061aa8b69b22236d479c681d837038e0139e\",\"venue\":\"2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)\",\"year\":2020},{\"arxivId\":\"2004.14861\",\"authors\":[{\"authorId\":\"52121635\",\"name\":\"Nathan Inkawhich\"},{\"authorId\":\"144130492\",\"name\":\"Kevin J Liang\"},{\"authorId\":\"1789625\",\"name\":\"Binghui Wang\"},{\"authorId\":\"52117082\",\"name\":\"Matthew Inkawhich\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a1465abc2714aa214e54452276db8cac8e3ec1e\",\"title\":\"Perturbing Across the Feature Hierarchy to Improve Standard and Strict Blackbox Attack Transferability\",\"url\":\"https://www.semanticscholar.org/paper/6a1465abc2714aa214e54452276db8cac8e3ec1e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1846134\",\"name\":\"J. Lam\"},{\"authorId\":\"2003336037\",\"name\":\"Pengrui Quan\"},{\"authorId\":\"2028894875\",\"name\":\"Jiamin Xu\"},{\"authorId\":\"39733155\",\"name\":\"J. Jeyakumar\"},{\"authorId\":\"1702254\",\"name\":\"M. Srivastava\"}],\"doi\":\"10.1145/3417312.3431827\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b9e4084c395e4a59c95074e7b0e30d07003782e\",\"title\":\"Hard-Label Black-Box Adversarial Attack on Deep Electrocardiogram Classifier\",\"url\":\"https://www.semanticscholar.org/paper/9b9e4084c395e4a59c95074e7b0e30d07003782e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.05549\",\"authors\":[{\"authorId\":\"1560221518\",\"name\":\"Yingpeng Deng\"},{\"authorId\":\"47209857\",\"name\":\"Lina Karam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30e7daa7ccb277e6d44f0e3af0686dc4c70a5ee1\",\"title\":\"Frequency-Tuned Universal Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/30e7daa7ccb277e6d44f0e3af0686dc4c70a5ee1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.03837\",\"authors\":[{\"authorId\":\"1492114961\",\"name\":\"Jie Li\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"33185308\",\"name\":\"Hong-Cheu Liu\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"122246162\",\"name\":\"Bineng Zhong\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16d446f22f86596d7bee3a177e5cc846fc8bc02d\",\"title\":\"Projection & Probability-Driven Black-Box Attack\",\"url\":\"https://www.semanticscholar.org/paper/16d446f22f86596d7bee3a177e5cc846fc8bc02d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.06349\",\"authors\":[{\"authorId\":\"1402924631\",\"name\":\"Guillermo Ortiz-Jim\\u00e9nez\"},{\"authorId\":\"2618576\",\"name\":\"A. Modas\"},{\"authorId\":\"1403182206\",\"name\":\"Seyed-Mohsen Moosavi-Dezfooli\"},{\"authorId\":\"1423349315\",\"name\":\"Pascal Frossard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d90b9c9cad844118a9aadbb5935ee8bf59d4ceb0\",\"title\":\"Hold me tight! Influence of discriminative features on deep network boundaries\",\"url\":\"https://www.semanticscholar.org/paper/d90b9c9cad844118a9aadbb5935ee8bf59d4ceb0\",\"venue\":\"NeurIPS\",\"year\":2020}],\"corpusId\":67855605,\"doi\":\"10.24963/ijcai.2019/470\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"a6d5fdee230d64da596c220f3fee71a29fa14816\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wen Zhou\"},{\"authorId\":null,\"name\":\"Xin Hou\"},{\"authorId\":null,\"name\":\"Yongjun Chen\"},{\"authorId\":null,\"name\":\"Mengyun Tang\"},{\"authorId\":null,\"name\":\"Xiangqi Huang\"},{\"authorId\":null,\"name\":\"Xiang Gan\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Yong Yang\",\"url\":\"\",\"venue\":\"Transferable adversarial perturbations. In ECCV (14), pages 471\\u2013486. Springer,\",\"year\":2018},{\"arxivId\":\"1710.10733\",\"authors\":[{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8451075110e8dde43b3640549cc3de4cfd327c49\",\"title\":\"Attacking the Madry Defense Model with L1-based Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/8451075110e8dde43b3640549cc3de4cfd327c49\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1802.00420\",\"authors\":[{\"authorId\":\"38939786\",\"name\":\"Anish Athalye\"},{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"651adaa058f821a890f2c5d1053d69eb481a8352\",\"title\":\"Obfuscated Gradients Give a False Sense of Security: Circumventing Defenses to Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/651adaa058f821a890f2c5d1053d69eb481a8352\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1708.06131\",\"authors\":[{\"authorId\":\"1684175\",\"name\":\"B. Biggio\"},{\"authorId\":\"2338858\",\"name\":\"I. Corona\"},{\"authorId\":\"3248803\",\"name\":\"Davide Maiorca\"},{\"authorId\":\"39743720\",\"name\":\"B. Nelson\"},{\"authorId\":\"2118348\",\"name\":\"Nedim Srndic\"},{\"authorId\":\"1754215\",\"name\":\"P. Laskov\"},{\"authorId\":\"1779484\",\"name\":\"G. Giacinto\"},{\"authorId\":\"1710171\",\"name\":\"F. Roli\"}],\"doi\":\"10.1007/978-3-642-40994-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"title\":\"Evasion Attacks against Machine Learning at Test Time\",\"url\":\"https://www.semanticscholar.org/paper/033c08ca48aaed2d5ab0a17d668d410538678ed8\",\"venue\":\"ECML/PKDD\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Sharma\"},{\"authorId\":null,\"name\":\"T. Le\"},{\"authorId\":null,\"name\":\"M. Alzantot\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Generating transferable adversarial examples\",\"url\":\"\",\"venue\":\"Caad\",\"year\":2018},{\"arxivId\":\"1707.07012\",\"authors\":[{\"authorId\":\"2368067\",\"name\":\"Barret Zoph\"},{\"authorId\":\"1695525\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1397917613\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.1109/CVPR.2018.00907\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0611891b9e8a7c5731146097b6f201578f47b2f\",\"title\":\"Learning Transferable Architectures for Scalable Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0611891b9e8a7c5731146097b6f201578f47b2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1706.06083\",\"authors\":[{\"authorId\":\"143826246\",\"name\":\"A. Madry\"},{\"authorId\":\"17775913\",\"name\":\"Aleksandar Makelov\"},{\"authorId\":\"33404869\",\"name\":\"L. Schmidt\"},{\"authorId\":\"2754804\",\"name\":\"D. Tsipras\"},{\"authorId\":\"2869958\",\"name\":\"Adrian Vladu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"title\":\"Towards Deep Learning Models Resistant to Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/7aa38b85fa8cba64d6a4010543f6695dbf5f1386\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1804.07998\",\"authors\":[{\"authorId\":\"3030212\",\"name\":\"Moustafa Alzantot\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"143718836\",\"name\":\"Ahmed Elgohary\"},{\"authorId\":\"33386728\",\"name\":\"Bo-Jhang Ho\"},{\"authorId\":\"1702254\",\"name\":\"M. Srivastava\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":\"10.18653/v1/D18-1316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c68fbc1f4aa72d30974f8a3071054e3b227137fd\",\"title\":\"Generating Natural Language Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/c68fbc1f4aa72d30974f8a3071054e3b227137fd\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K Ramamohan Rao\"},{\"authorId\":null,\"name\":\"Ping Yip\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Discrete cosine transform: algorithms\",\"url\":\"\",\"venue\":\"advantages, applications. Academic press,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144438755\",\"name\":\"Qi Lei\"},{\"authorId\":\"3008832\",\"name\":\"Lingfei Wu\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"1718469\",\"name\":\"A. Dimakis\"},{\"authorId\":\"1783667\",\"name\":\"I. Dhillon\"},{\"authorId\":\"2819135\",\"name\":\"M. Witbrock\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"451277e29e8dcd460f4e75131bfe67effa4b5ec5\",\"title\":\"Discrete Attacks and Submodular Optimization with Applications to Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/451277e29e8dcd460f4e75131bfe67effa4b5ec5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1607.02533\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":\"10.1201/9781351251389-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"title\":\"Adversarial examples in the physical world\",\"url\":\"https://www.semanticscholar.org/paper/b544ca32b66b4c9c69bcfa00d63ee4b799d8ab6b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1708.03999\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.1145/3128572.3140448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"title\":\"ZOO: Zeroth Order Optimization Based Black-box Attacks to Deep Neural Networks without Training Substitute Models\",\"url\":\"https://www.semanticscholar.org/paper/9ab7319dbe80549ba80e3320d0546d741a7a5791\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1812.03411\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"title\":\"Feature Denoising for Improving Adversarial Robustness\",\"url\":\"https://www.semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1412.6572\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"title\":\"Explaining and Harnessing Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bee044c8e8903fb67523c1f8c105ab4718600cdb\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Anil Thomas\"},{\"authorId\":null,\"name\":\"Oguz Elibol\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Defense against adversarial attack: 3rd place\",\"url\":\"\",\"venue\":\"https:// github.com/anlthms/nips-2017,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144593422\",\"name\":\"K. Rao\"},{\"authorId\":\"49114976\",\"name\":\"P. Yip\"}],\"doi\":\"10.1016/c2009-0-22279-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29774eec7448f2a869a88376197297b4e8c9215f\",\"title\":\"Discrete Cosine Transform - Algorithms, Advantages, Applications\",\"url\":\"https://www.semanticscholar.org/paper/29774eec7448f2a869a88376197297b4e8c9215f\",\"venue\":\"\",\"year\":1990},{\"arxivId\":\"1810.01268\",\"authors\":[{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"145256853\",\"name\":\"Tien-Dung Le\"},{\"authorId\":\"3030212\",\"name\":\"Moustafa Alzantot\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf79917d4479ce4a79b2186636806d7b86c0616b\",\"title\":\"CAAD 2018: Generating Transferable Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/bf79917d4479ce4a79b2186636806d7b86c0616b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.09868\",\"authors\":[{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f78d7798cb5407bc998870618cc769383ef51eb\",\"title\":\"Bypassing Feature Squeezing by Increasing Adversary Strength\",\"url\":\"https://www.semanticscholar.org/paper/6f78d7798cb5407bc998870618cc769383ef51eb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.00151\",\"authors\":[{\"authorId\":\"144438755\",\"name\":\"Qi Lei\"},{\"authorId\":\"50789977\",\"name\":\"L. Wu\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"1718469\",\"name\":\"A. Dimakis\"},{\"authorId\":\"1783667\",\"name\":\"I. Dhillon\"},{\"authorId\":\"2819135\",\"name\":\"M. Witbrock\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"631440152ea62388bc300be8735eb5c46d9cd0ee\",\"title\":\"Discrete Adversarial Attacks and Submodular Optimization with Applications to Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/631440152ea62388bc300be8735eb5c46d9cd0ee\",\"venue\":\"MLSys\",\"year\":2019},{\"arxivId\":\"1803.04765\",\"authors\":[{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b50026b7b1054ef8e3643fcd7ef89d7b278a068\",\"title\":\"Deep k-Nearest Neighbors: Towards Confident, Interpretable and Robust Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2b50026b7b1054ef8e3643fcd7ef89d7b278a068\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.11090\",\"authors\":[{\"authorId\":\"3030212\",\"name\":\"Moustafa Alzantot\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"144387904\",\"name\":\"S. Chakraborty\"},{\"authorId\":\"1702254\",\"name\":\"M. Srivastava\"}],\"doi\":\"10.1145/3321707.3321749\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df849813aa240c6c56342a32fbf7e13e78c6c2f0\",\"title\":\"GenAttack: practical black-box attacks with gradient-free optimization\",\"url\":\"https://www.semanticscholar.org/paper/df849813aa240c6c56342a32fbf7e13e78c6c2f0\",\"venue\":\"GECCO\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingzhen Li\"},{\"authorId\":null,\"name\":\"John Bradshaw\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and Yash Sharma\",\"url\":\"\",\"venue\":\"Are generative classifiers more robust to adversarial attacks? arXiv preprint arXiv:1802.06552,\",\"year\":2018},{\"arxivId\":\"1803.08533\",\"authors\":[{\"authorId\":\"143877237\",\"name\":\"Lewis Smith\"},{\"authorId\":\"2681954\",\"name\":\"Yarin Gal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63ed798f1847d8a952cbeb75d3b286f16c144914\",\"title\":\"Understanding Measures of Uncertainty for Adversarial Example Detection\",\"url\":\"https://www.semanticscholar.org/paper/63ed798f1847d8a952cbeb75d3b286f16c144914\",\"venue\":\"UAI\",\"year\":2018},{\"arxivId\":\"1312.6199\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"title\":\"Intriguing properties of neural networks\",\"url\":\"https://www.semanticscholar.org/paper/d891dc72cbd40ffaeefdc79f2e7afe1e530a23ad\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145957093\",\"name\":\"Wen Zhou\"},{\"authorId\":\"50135460\",\"name\":\"X. Hou\"},{\"authorId\":\"29515359\",\"name\":\"Y. Chen\"},{\"authorId\":\"3121455\",\"name\":\"Mengyun Tang\"},{\"authorId\":\"2395882\",\"name\":\"Xiangqi Huang\"},{\"authorId\":\"2053487\",\"name\":\"X. Gan\"},{\"authorId\":\"145526690\",\"name\":\"Yong Yang\"}],\"doi\":\"10.1007/978-3-030-01264-9_28\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"ec3da7bb0b1ffce4ce5501e960ce9879c0ae1bd0\",\"title\":\"Transferable Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/ec3da7bb0b1ffce4ce5501e960ce9879c0ae1bd0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1802.06552\",\"authors\":[{\"authorId\":\"2672661\",\"name\":\"Yingzhen Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"51de2f73ad68a0ff2289d4e02957a07ffc4236f4\",\"title\":\"Are Generative Classifiers More Robust to Adversarial Attacks?\",\"url\":\"https://www.semanticscholar.org/paper/51de2f73ad68a0ff2289d4e02957a07ffc4236f4\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1705.07263\",\"authors\":[{\"authorId\":\"39907737\",\"name\":\"N. Carlini\"},{\"authorId\":\"40429990\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1145/3128572.3140444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99cb08c76c120599abd1d1637e32aaf577f38d39\",\"title\":\"Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods\",\"url\":\"https://www.semanticscholar.org/paper/99cb08c76c120599abd1d1637e32aaf577f38d39\",\"venue\":\"AISec@CCS\",\"year\":2017},{\"arxivId\":\"1608.04644\",\"authors\":[{\"authorId\":\"2483738\",\"name\":\"Nicholas Carlini\"},{\"authorId\":\"145394689\",\"name\":\"D. Wagner\"}],\"doi\":\"10.1109/SP.2017.49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"title\":\"Towards Evaluating the Robustness of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df40ce107a71b770c9d0354b78fdd8989da80d2f\",\"venue\":\"2017 IEEE Symposium on Security and Privacy (SP)\",\"year\":2017},{\"arxivId\":\"1804.00097\",\"authors\":[{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"145656562\",\"name\":\"M. Liang\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"39421868\",\"name\":\"Sangxia Huang\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"40119836\",\"name\":\"Y. Zhao\"},{\"authorId\":\"46758154\",\"name\":\"Zhonglin Han\"},{\"authorId\":\"19262286\",\"name\":\"J. Long\"},{\"authorId\":\"41021078\",\"name\":\"Yerkebulan Berdibekov\"},{\"authorId\":\"2859858\",\"name\":\"Takuya Akiba\"},{\"authorId\":\"3117618\",\"name\":\"Seiya Tokui\"},{\"authorId\":\"153225382\",\"name\":\"M. Abe\"}],\"doi\":\"10.1007/978-3-319-94042-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca5642f522cd2cd44948c7e9f337c91e5f26fdcf\",\"title\":\"Adversarial Attacks and Defences Competition\",\"url\":\"https://www.semanticscholar.org/paper/ca5642f522cd2cd44948c7e9f337c91e5f26fdcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1705.07204\",\"authors\":[{\"authorId\":\"2444919\",\"name\":\"Florian Tram\\u00e8r\"},{\"authorId\":\"145714153\",\"name\":\"A. Kurakin\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"},{\"authorId\":\"1752788\",\"name\":\"D. Boneh\"},{\"authorId\":\"144061974\",\"name\":\"P. McDaniel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"title\":\"Ensemble Adversarial Training: Attacks and Defenses\",\"url\":\"https://www.semanticscholar.org/paper/136dee73f203df2f4831994bf4f0c0a4ad2e764e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1801.03924\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c468bbde6a22d961829e1970e6ad5795e05418d1\",\"title\":\"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\",\"url\":\"https://www.semanticscholar.org/paper/c468bbde6a22d961829e1970e6ad5795e05418d1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Thomas\"},{\"authorId\":null,\"name\":\"O. Elibol\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Defense against adversarial attack\",\"url\":\"\",\"venue\":\"3rd place\",\"year\":2017},{\"arxivId\":\"1712.02976\",\"authors\":[{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"151483845\",\"name\":\"Ming Liang\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"48566726\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/CVPR.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"title\":\"Defense Against Adversarial Attacks Using High-Level Representation Guided Denoiser\",\"url\":\"https://www.semanticscholar.org/paper/ca9c1224636b0a7dd37340a4691c34a9914b5af8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.01991\",\"authors\":[{\"authorId\":\"3011497\",\"name\":\"Cihang Xie\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"2852303\",\"name\":\"Zhishuai Zhang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a089c56eec68df722b2a5a52727143aacdc2532\",\"title\":\"Mitigating adversarial effects through randomization\",\"url\":\"https://www.semanticscholar.org/paper/9a089c56eec68df722b2a5a52727143aacdc2532\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1805.09190\",\"authors\":[{\"authorId\":\"36873987\",\"name\":\"Lukas Schott\"},{\"authorId\":\"19237612\",\"name\":\"Jonas Rauber\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"},{\"authorId\":\"40634590\",\"name\":\"W. Brendel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd7789de401811fd8692466b8d49230e7184655f\",\"title\":\"Towards the first adversarially robust neural network model on MNIST\",\"url\":\"https://www.semanticscholar.org/paper/fd7789de401811fd8692466b8d49230e7184655f\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1812.02637\",\"authors\":[{\"authorId\":\"27623787\",\"name\":\"G. W. Ding\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"50854174\",\"name\":\"Kry Yik Chau Lui\"},{\"authorId\":\"2136577\",\"name\":\"Ruitong Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93314b89c218c02cc1a32cad7071215693599907\",\"title\":\"Max-Margin Adversarial (MMA) Training: Direct Input Space Margin Maximization through Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/93314b89c218c02cc1a32cad7071215693599907\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1809.08758\",\"authors\":[{\"authorId\":\"144993411\",\"name\":\"Chuan Guo\"},{\"authorId\":\"21454543\",\"name\":\"Jared S. Frank\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e6c979fb345f673ffc997e377ae724a8c6cd022\",\"title\":\"Low Frequency Adversarial Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/7e6c979fb345f673ffc997e377ae724a8c6cd022\",\"venue\":\"UAI\",\"year\":2019},{\"arxivId\":\"1709.04114\",\"authors\":[{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"49738125\",\"name\":\"Yash Sharma\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"160a03c2890f3ef5436c25ef9b1758faa13807a0\",\"title\":\"EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples\",\"url\":\"https://www.semanticscholar.org/paper/160a03c2890f3ef5436c25ef9b1758faa13807a0\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"37906910\",\"name\":\"Fangzhou Liao\"},{\"authorId\":\"19201674\",\"name\":\"Tianyu Pang\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145296845\",\"name\":\"J. Zhu\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00957\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e37a3b227b68953f8067215828dc8b8714cb21b\",\"title\":\"Boosting Adversarial Attacks with Momentum\",\"url\":\"https://www.semanticscholar.org/paper/8e37a3b227b68953f8067215828dc8b8714cb21b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huichen Lihuichen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4535ecaf37ffc80ef4fe05561c034880388343d0\",\"title\":\"Decision-Based Adversarial Attacks : Reliable Attacks Against Black-box Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/4535ecaf37ffc80ef4fe05561c034880388343d0\",\"venue\":\"\",\"year\":2017}],\"title\":\"On the Effectiveness of Low Frequency Perturbations\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Distortion\",\"topicId\":\"15080\",\"url\":\"https://www.semanticscholar.org/topic/15080\"},{\"topic\":\"Black box\",\"topicId\":\"16977\",\"url\":\"https://www.semanticscholar.org/topic/16977\"},{\"topic\":\"Align (company)\",\"topicId\":\"439709\",\"url\":\"https://www.semanticscholar.org/topic/439709\"}],\"url\":\"https://www.semanticscholar.org/paper/a6d5fdee230d64da596c220f3fee71a29fa14816\",\"venue\":\"IJCAI\",\"year\":2019}\n"