"{\"abstract\":\"Analyzing human multimodal language is an emerging area of research in NLP. Intrinsically this language is multimodal (heterogeneous), sequential and asynchronous; it consists of the language (words), visual (expressions) and acoustic (paralinguistic) modalities all in the form of asynchronous coordinated sequences. From a resource perspective, there is a genuine need for large scale datasets that allow for in-depth studies of this form of language. In this paper we introduce CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI), the largest dataset of sentiment analysis and emotion recognition to date. Using data from CMU-MOSEI and a novel multimodal fusion technique called the Dynamic Fusion Graph (DFG), we conduct experimentation to exploit how modalities interact with each other in human multimodal language. Unlike previously proposed fusion techniques, DFG is highly interpretable and achieves competative performance when compared to the previous state of the art.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\",\"url\":\"https://www.semanticscholar.org/author/144802290\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\",\"url\":\"https://www.semanticscholar.org/author/28130078\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\",\"url\":\"https://www.semanticscholar.org/author/1746416\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\",\"url\":\"https://www.semanticscholar.org/author/49943757\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\",\"url\":\"https://www.semanticscholar.org/author/49933077\"}],\"citationVelocity\":41,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"119837541\",\"name\":\"Jian-Ming Wu\"},{\"authorId\":\"2000011573\",\"name\":\"Jinfa Huang\"},{\"authorId\":\"31229419\",\"name\":\"G. Hattori\"},{\"authorId\":\"2466117\",\"name\":\"Y. Takishima\"},{\"authorId\":\"2000114316\",\"name\":\"Shinya Wada\"},{\"authorId\":\"1809845071\",\"name\":\"Rui Kimura\"},{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"1610841750\",\"name\":\"Satoshi Kurihara\"}],\"doi\":\"10.1145/3382507.3418830\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e1526a7ad07d90f1b53b63299bb1cb9c0ce01925\",\"title\":\"LDNN: Linguistic Knowledge Injectable Deep Neural Network for Group Cohesiveness Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e1526a7ad07d90f1b53b63299bb1cb9c0ce01925\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40219418\",\"name\":\"R. Milner\"},{\"authorId\":\"51257800\",\"name\":\"Md Asif Jalal\"},{\"authorId\":\"2394130\",\"name\":\"Raymond W. M. Ng\"},{\"authorId\":\"2171861\",\"name\":\"Thomas Hain\"}],\"doi\":\"10.1109/ASRU46091.2019.9003838\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cea07906fa0d9a2710ed3b1fb44d43e4a65f2c06\",\"title\":\"A Cross-Corpus Study on Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cea07906fa0d9a2710ed3b1fb44d43e4a65f2c06\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1678917\",\"name\":\"M. Melucci\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"41f9c10ec3bdacda7273fec073a1c5c82d8a2cc7\",\"title\":\"Quantum-inspired Multimodal Representation\",\"url\":\"https://www.semanticscholar.org/paper/41f9c10ec3bdacda7273fec073a1c5c82d8a2cc7\",\"venue\":\"IIR\",\"year\":2019},{\"arxivId\":\"2004.08195\",\"authors\":[{\"authorId\":\"144039832\",\"name\":\"P. Barros\"},{\"authorId\":\"19175266\",\"name\":\"Nikhil Churamani\"},{\"authorId\":\"1923910\",\"name\":\"A. Sciutti\"}],\"doi\":\"10.1109/FG47880.2020.00070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58185ffd760eb04719105725fe1e0d24ac301dc0\",\"title\":\"The FaceChannel: A Light-weight Deep Neural Network for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58185ffd760eb04719105725fe1e0d24ac301dc0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153784747\",\"name\":\"P. Barros\"},{\"authorId\":\"19175266\",\"name\":\"Nikhil Churamani\"},{\"authorId\":\"1961676436\",\"name\":\"Alessandra Sciutti\"}],\"doi\":\"10.1007/s42979-020-00325-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6da5fae8cfc7e5aa559213aa205255c31aca5b11\",\"title\":\"The FaceChannel: A Fast and Furious Deep Neural Network for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6da5fae8cfc7e5aa559213aa205255c31aca5b11\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2010.02295\",\"authors\":[{\"authorId\":\"144286516\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"1456009348\",\"name\":\"Chenguang Zhu\"},{\"authorId\":\"48262024\",\"name\":\"Michael Zeng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02e72083bb4e9c0d4cd43acebbe846ff1d8fb198\",\"title\":\"Semi-Supervised Speech-Language Joint Pre-Training for Spoken Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/02e72083bb4e9c0d4cd43acebbe846ff1d8fb198\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51123172\",\"name\":\"Darshana Priyasad\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48d5edd8d705f5c51f01a1d958de375cca8b06f5\",\"title\":\"Memory Based Attentive Fusion\",\"url\":\"https://www.semanticscholar.org/paper/48d5edd8d705f5c51f01a1d958de375cca8b06f5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.08076\",\"authors\":[{\"authorId\":\"51123172\",\"name\":\"Darshana Priyasad\"},{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1016/j.inffus.2020.10.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08189ce7ec387a47b490113a4040dec6f65a254e\",\"title\":\"Memory based fusion for multi-modal deep learning.\",\"url\":\"https://www.semanticscholar.org/paper/08189ce7ec387a47b490113a4040dec6f65a254e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.01908\",\"authors\":[{\"authorId\":\"12386833\",\"name\":\"Wenxiang Jiao\"},{\"authorId\":\"145609003\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"145310659\",\"name\":\"I. King\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.435\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"925df521337c189bdce4a1b3921c590f14aaa1ff\",\"title\":\"Exploiting Unsupervised Data for Emotion Recognition in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/925df521337c189bdce4a1b3921c590f14aaa1ff\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145390928\",\"name\":\"E. Chen\"},{\"authorId\":\"2095379\",\"name\":\"Zhiyun Lu\"},{\"authorId\":\"49507008\",\"name\":\"Hao Xu\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"49891071\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2104664\",\"name\":\"J. Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea3266caff07d07099b649bf75cc222752140a3e\",\"title\":\"A Large Scale Speech Sentiment Corpus\",\"url\":\"https://www.semanticscholar.org/paper/ea3266caff07d07099b649bf75cc222752140a3e\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.18653/v1/P19-1046\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"title\":\"Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing\",\"url\":\"https://www.semanticscholar.org/paper/9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"50686521\",\"name\":\"A. Stefani\"},{\"authorId\":\"1922081704\",\"name\":\"Giovanni Toto\"},{\"authorId\":\"66396314\",\"name\":\"Emanuele Di Buccio\"},{\"authorId\":\"1678917\",\"name\":\"M. Melucci\"}],\"doi\":\"10.1109/MIPR49039.2020.00044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d33cedd8df6d9b2b1f534d4fd51d90986387d07\",\"title\":\"Towards Multimodal Sentiment Analysis Inspired by the Quantum Theoretical Framework\",\"url\":\"https://www.semanticscholar.org/paper/4d33cedd8df6d9b2b1f534d4fd51d90986387d07\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"}],\"doi\":\"10.1145/3331184.3331419\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"78ca49dc0cccbf941b4497227184f18ed4647d71\",\"title\":\"Multimodal Data Fusion with Quantum Inspiration\",\"url\":\"https://www.semanticscholar.org/paper/78ca49dc0cccbf941b4497227184f18ed4647d71\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1908.06008\",\"authors\":[{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"38655267\",\"name\":\"Gangeshwar Krishnamurthy\"},{\"authorId\":\"2954043\",\"name\":\"Niyati Chhaya\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"1747784\",\"name\":\"Alexander Gelbukh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0ef28a974f2ed1df33ccc6e24aa9aad89223e5f0\",\"title\":\"Variational Fusion for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0ef28a974f2ed1df33ccc6e24aa9aad89223e5f0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.12638\",\"authors\":[{\"authorId\":\"46263614\",\"name\":\"A. Liu\"},{\"authorId\":\"49080680\",\"name\":\"Shuwen Yang\"},{\"authorId\":\"1388262677\",\"name\":\"Po-Han Chi\"},{\"authorId\":\"144162329\",\"name\":\"Po-Chun Hsu\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054458\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cbdf70373d14ea654886cffbce259273dfbb845\",\"title\":\"Mockingjay: Unsupervised Speech Representation Learning with Deep Bidirectional Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/0cbdf70373d14ea654886cffbce259273dfbb845\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104930915\",\"name\":\"Qiyuan Liu\"},{\"authorId\":\"51183249\",\"name\":\"Liangqing Wu\"},{\"authorId\":\"115986457\",\"name\":\"Yang Xu\"},{\"authorId\":\"153165264\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1007/978-3-030-32236-6_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43ca51a90f339589b87d9c370d32dfa5b91dfdd\",\"title\":\"Hierarchical-Gate Multimodal Network for Human Communication Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c43ca51a90f339589b87d9c370d32dfa5b91dfdd\",\"venue\":\"NLPCC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11165439\",\"name\":\"Y. Yao\"},{\"authorId\":\"1396239754\",\"name\":\"Ver\\u00f3nica P\\u00e9rez-Rosas\"},{\"authorId\":\"1898814\",\"name\":\"Mohamed Abouelenien\"},{\"authorId\":\"1803815\",\"name\":\"Mihai Burzo\"}],\"doi\":\"10.1145/3382507.3418821\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fab0028cab9949f7924241b922998811218882a0\",\"title\":\"MORSE: MultimOdal sentiment analysis for Real-life SEttings\",\"url\":\"https://www.semanticscholar.org/paper/fab0028cab9949f7924241b922998811218882a0\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"2011.10916\",\"authors\":[{\"authorId\":\"90683745\",\"name\":\"K. Panchal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"07c9e3c2481a074ed44b7967e49d2a7d75c6f06c\",\"title\":\"Hierachical Delta-Attention Method for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/07c9e3c2481a074ed44b7967e49d2a7d75c6f06c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.05787\",\"authors\":[{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"2811524\",\"name\":\"M. Hasan\"},{\"authorId\":\"1459934320\",\"name\":\"Sangwu Lee\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1429197894\",\"name\":\"Chengfeng Mao\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1491348598\",\"name\":\"Ehsan Hoque\"}],\"doi\":\"10.18653/v1/2020.acl-main.214\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0ecaddd3df8793c1b7050cb4c6b359c041bedc57\",\"title\":\"Integrating Multimodal Information in Large Pretrained Transformers\",\"url\":\"https://www.semanticscholar.org/paper/0ecaddd3df8793c1b7050cb4c6b359c041bedc57\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"102561200\",\"name\":\"Roberto Togneri\"}],\"doi\":\"10.1007/978-3-030-36711-4_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"339786e033965bc2efaccb67a75c0b20a15d35b5\",\"title\":\"Learning-Based Confidence Estimation for Multi-modal Classifier Fusion\",\"url\":\"https://www.semanticscholar.org/paper/339786e033965bc2efaccb67a75c0b20a15d35b5\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1904.06618\",\"authors\":[{\"authorId\":\"2811524\",\"name\":\"M. Hasan\"},{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2693593\",\"name\":\"Jianyuan Zhong\"},{\"authorId\":\"2497319\",\"name\":\"Md. Iftekhar Tanveer\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"144619896\",\"name\":\"M. Hoque\"}],\"doi\":\"10.18653/v1/D19-1211\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"296e8ceeba6550d7ec9b9ee727e0c17420ebb926\",\"title\":\"UR-FUNNY: A Multimodal Language Dataset for Understanding Humor\",\"url\":\"https://www.semanticscholar.org/paper/296e8ceeba6550d7ec9b9ee727e0c17420ebb926\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1909.01067\",\"authors\":[{\"authorId\":\"8213793\",\"name\":\"Habibeh Naderi\"},{\"authorId\":\"2964988\",\"name\":\"Behrouz Haji Soleimani\"},{\"authorId\":\"1386852371\",\"name\":\"Sheri Rempel\"},{\"authorId\":\"1749003\",\"name\":\"S. Matwin\"},{\"authorId\":\"6705660\",\"name\":\"R. Uher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba6980dae0afb0f4f4cf3caaedba5aed8028078a\",\"title\":\"Multimodal Deep Learning for Mental Disorders Prediction from Audio Speech Samples\",\"url\":\"https://www.semanticscholar.org/paper/ba6980dae0afb0f4f4cf3caaedba5aed8028078a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.08218\",\"authors\":[{\"authorId\":\"3455244\",\"name\":\"S. Verma\"},{\"authorId\":\"120465859\",\"name\":\"Jiwei Wang\"},{\"authorId\":\"1998943485\",\"name\":\"Zhefeng Ge\"},{\"authorId\":\"1509070823\",\"name\":\"Rujia Shen\"},{\"authorId\":\"1388648260\",\"name\":\"F. Jin\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"faddf17f65376da3002579fd5fe526041d8ad219\",\"title\":\"Deep-HOSeq: Deep Higher Order Sequence Fusion for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/faddf17f65376da3002579fd5fe526041d8ad219\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754430080\",\"name\":\"Wenmeng Yu\"},{\"authorId\":\"1491194464\",\"name\":\"Hua Xu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"46758765\",\"name\":\"Yilin Zhu\"},{\"authorId\":\"95952564\",\"name\":\"Y. Ma\"},{\"authorId\":\"1754148511\",\"name\":\"Jiele Wu\"},{\"authorId\":\"1657286768\",\"name\":\"Jiyun Zou\"},{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"}],\"doi\":\"10.18653/v1/2020.acl-main.343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fc85469f9ff785f24212a50c58b497de563ae3da\",\"title\":\"CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality\",\"url\":\"https://www.semanticscholar.org/paper/fc85469f9ff785f24212a50c58b497de563ae3da\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1910.03641\",\"authors\":[{\"authorId\":\"2214186\",\"name\":\"Haoqi Li\"},{\"authorId\":\"2533091\",\"name\":\"Brian R W Baucom\"},{\"authorId\":\"33044681\",\"name\":\"P. Georgiou\"}],\"doi\":\"10.7717/peerj-cs.246\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9b4b84835ba1230b2b1a594909116e6ccc5a11bc\",\"title\":\"Linking emotions to behaviors through deep transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/9b4b84835ba1230b2b1a594909116e6ccc5a11bc\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153165264\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"1758474\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1145/3343031.3350987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9031a1e275567d44dd0313137963fe1c1ce61b2\",\"title\":\"Effective Sentiment-relevant Word Selection for Multi-modal Sentiment Analysis in Spoken Language\",\"url\":\"https://www.semanticscholar.org/paper/a9031a1e275567d44dd0313137963fe1c1ce61b2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51516859\",\"name\":\"S. Siriwardhana\"},{\"authorId\":\"1992921690\",\"name\":\"Tharindu Kaluarachchi\"},{\"authorId\":\"1485673104\",\"name\":\"Mark Billinghurst\"},{\"authorId\":\"1486464114\",\"name\":\"Suranga Nanayakkara\"}],\"doi\":\"10.1109/ACCESS.2020.3026823\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3fa0b660d2b26806a8159d58f49acc4bf132b1eb\",\"title\":\"Multimodal Emotion Recognition With Transformer-Based Self Supervised Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/3fa0b660d2b26806a8159d58f49acc4bf132b1eb\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46815454\",\"name\":\"Md. Shad Akhtar\"},{\"authorId\":null,\"name\":\"Abhishek Kumar\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"31565315\",\"name\":\"Chris Biemann\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/W19-0413\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ca8c662823aaccfbe7f15e8670f70d5455b6c17\",\"title\":\"Language-Agnostic Model for Aspect-Based Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/8ca8c662823aaccfbe7f15e8670f70d5455b6c17\",\"venue\":\"IWCS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008352531\",\"name\":\"AmirAli Bagher Zadeh\"},{\"authorId\":\"3436851\",\"name\":\"Yansheng Cao\"},{\"authorId\":\"2008177967\",\"name\":\"Simon Hessner\"},{\"authorId\":\"2008183288\",\"name\":\"Paul Pu Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.141\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"dec43c7511acfc02f5f22fbe4e19ed2aed49b015\",\"title\":\"CMU-MOSEAS: A Multimodal Language Dataset for Spanish, Portuguese, German and French\",\"url\":\"https://www.semanticscholar.org/paper/dec43c7511acfc02f5f22fbe4e19ed2aed49b015\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50262107\",\"name\":\"Yingying Jiang\"},{\"authorId\":\"40400230\",\"name\":\"Wei Li\"},{\"authorId\":\"46357084\",\"name\":\"M. S. Hossain\"},{\"authorId\":\"31277272\",\"name\":\"M. Chen\"},{\"authorId\":\"2682134\",\"name\":\"Abdulhameed Alelaiwi\"},{\"authorId\":\"2773665\",\"name\":\"Muneer H. Al-Hammadi\"}],\"doi\":\"10.1016/J.INFFUS.2019.06.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1d225508f1ca51dc00b11a1f9583b80bccdb557\",\"title\":\"A snapshot research and implementation of multimodal information fusion for data-driven emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1d225508f1ca51dc00b11a1f9583b80bccdb557\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8005713\",\"name\":\"Bhargavi Paranjape\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.18653/v1/W19-5909\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3050735eb35af3527276aa1952f79eb2483df3f0\",\"title\":\"Contextualized Representations for Low-resource Utterance Tagging\",\"url\":\"https://www.semanticscholar.org/paper/3050735eb35af3527276aa1952f79eb2483df3f0\",\"venue\":\"SIGdial\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144529448\",\"name\":\"Yao Chong Lim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b93e73152e400087b13b960e245f673a5990f518\",\"title\":\"Learning Generative Models from Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/b93e73152e400087b13b960e245f673a5990f518\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.14198\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"1384374825\",\"name\":\"Martin Q. Ma\"},{\"authorId\":\"72966973\",\"name\":\"Muqiao Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c0685bec77430b7024ce1fdf5f1e00ef9c355fb\",\"title\":\"Interpretable Multimodal Routing for Human Multimodal Language\",\"url\":\"https://www.semanticscholar.org/paper/5c0685bec77430b7024ce1fdf5f1e00ef9c355fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.08138\",\"authors\":[{\"authorId\":\"47591140\",\"name\":\"Feiyang Chen\"},{\"authorId\":\"144705497\",\"name\":\"Ziqian Luo\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"77e7ad0da898d4ad8ec98b0002bb07c5eed90653\",\"title\":\"Complementary Fusion of Multi-Features and Multi-Modalities in Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/77e7ad0da898d4ad8ec98b0002bb07c5eed90653\",\"venue\":\"AffCon@AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"},{\"authorId\":\"2392839\",\"name\":\"H. Xu\"},{\"authorId\":\"37216441\",\"name\":\"K. Gao\"}],\"doi\":\"10.1145/3394171.3413690\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"773d51dbb619a167102f75d93f39582a67c24c82\",\"title\":\"CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/773d51dbb619a167102f75d93f39582a67c24c82\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1807.03915\",\"authors\":[{\"authorId\":\"144008479\",\"name\":\"H. Pham\"},{\"authorId\":\"2632776\",\"name\":\"Thomas Manzini\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":\"10.18653/v1/W18-3308\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9d55bd57e64c8e48c61e4f1746a2c280d608a8d2\",\"title\":\"Seq2Seq2Sentiment: Multimodal Sequence to Sequence Models for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9d55bd57e64c8e48c61e4f1746a2c280d608a8d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49937103\",\"name\":\"Prasanna Biswas\"},{\"authorId\":\"49167330\",\"name\":\"A. Ray\"},{\"authorId\":\"8031616\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8342193c29fad886d43fad97a8c9884ad6f6f25\",\"title\":\"Computational Model for Understanding Emotions in Sarcasm: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/b8342193c29fad886d43fad97a8c9884ad6f6f25\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.08690\",\"authors\":[{\"authorId\":\"6325349\",\"name\":\"P. Guhan\"},{\"authorId\":\"2413697\",\"name\":\"Manas Agarwal\"},{\"authorId\":\"123729267\",\"name\":\"Naman Awasthi\"},{\"authorId\":\"38432194\",\"name\":\"G. Reeves\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4264c62a2979393703b6237da9293840895e119\",\"title\":\"ABC-Net: Semi-Supervised Multimodal GAN-based Engagement Detection using an Affective, Behavioral and Cognitive Model\",\"url\":\"https://www.semanticscholar.org/paper/c4264c62a2979393703b6237da9293840895e119\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02813\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"9408144\",\"name\":\"P. Wu\"},{\"authorId\":\"12907562\",\"name\":\"Liu Ziyin\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d718b1279a31d8a676f974b469dec20f376b2e7d\",\"title\":\"Cross-Modal Generalization: Learning in Low Resource Modalities via Meta-Alignment\",\"url\":\"https://www.semanticscholar.org/paper/d718b1279a31d8a676f974b469dec20f376b2e7d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993712503\",\"name\":\"Xincheng Ju\"},{\"authorId\":\"1771537\",\"name\":\"D. Zhang\"},{\"authorId\":\"47787394\",\"name\":\"J. Li\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.1145/3394171.3413577\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"daf4a3fb8e9e9f153687aaf7e999534eec242d0f\",\"title\":\"Transformer-based Label Set Generation for Multi-modal Multi-label Emotion Detection\",\"url\":\"https://www.semanticscholar.org/paper/daf4a3fb8e9e9f153687aaf7e999534eec242d0f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1911.01533\",\"authors\":[{\"authorId\":\"2214186\",\"name\":\"Haoqi Li\"},{\"authorId\":\"145254340\",\"name\":\"Ming Tu\"},{\"authorId\":\"49025046\",\"name\":\"Jing Huang\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"},{\"authorId\":\"33044681\",\"name\":\"P. Georgiou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054580\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"257c6803060b17e6160bb38f03f97ef4ee467c49\",\"title\":\"Speaker-Invariant Affective Representation Learning via Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/257c6803060b17e6160bb38f03f97ef4ee467c49\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993657377\",\"name\":\"Guangyao Shen\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"47892939\",\"name\":\"Hongzhi Li\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413909\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b141bea44da3e05a7e00241b37f0e28124157039\",\"title\":\"MEmoR: A Dataset for Multimodal Emotion Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b141bea44da3e05a7e00241b37f0e28124157039\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1911.07848\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.1609/AAAI.V34I01.5347\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"title\":\"Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1481712239\",\"name\":\"Suyash Sangwan\"},{\"authorId\":\"145036777\",\"name\":\"D. Chauhan\"},{\"authorId\":\"46815454\",\"name\":\"Md. Shad Akhtar\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.1007/978-3-030-36808-1_72\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f95ed5fc809e24a378f0c72f72d0329a9da43af6\",\"title\":\"Multi-task Gated Contextual Cross-Modal Attention Framework for Sentiment and Emotion Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f95ed5fc809e24a378f0c72f72d0329a9da43af6\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1908.05787\",\"authors\":[{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"145731758\",\"name\":\"M. K. Hasan\"},{\"authorId\":\"122930584\",\"name\":\"A. Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"144619896\",\"name\":\"M. Hoque\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"69f6defd48137f8e01ddac7b2f1c7ac804dfece1\",\"title\":\"M-BERT: Injecting Multimodal Information in the BERT Structure\",\"url\":\"https://www.semanticscholar.org/paper/69f6defd48137f8e01ddac7b2f1c7ac804dfece1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35576573\",\"name\":\"J. Li\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"}],\"doi\":\"10.21437/interspeech.2020-1688\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90eff998afb10d8f41e15b26f2db3b360fa0ebee\",\"title\":\"Using Speaker-Aligned Graph Memory Block in Multimodally Attentive Emotion Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/90eff998afb10d8f41e15b26f2db3b360fa0ebee\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2010.02057\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"88741566\",\"name\":\"No\\u00e9 Tits\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86a7a97c8efd99b862c524eb46a40276a52d3c60\",\"title\":\"Modulated Fusion using Transformer for Linguistic-Acoustic Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/86a7a97c8efd99b862c524eb46a40276a52d3c60\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2009.14445\",\"authors\":[{\"authorId\":\"2227771\",\"name\":\"Weicheng Ma\"},{\"authorId\":\"7247867\",\"name\":\"Ruibo Liu\"},{\"authorId\":\"48170334\",\"name\":\"L. Wang\"},{\"authorId\":\"1918441\",\"name\":\"Soroush Vosoughi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"915e42247f3b77f0c60f911d65229accb6176444\",\"title\":\"Towards Improved Model Design for Authorship Identification: A Survey on Writing Style Understanding\",\"url\":\"https://www.semanticscholar.org/paper/915e42247f3b77f0c60f911d65229accb6176444\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32585792\",\"name\":\"S. Chakravarthula\"},{\"authorId\":\"2533091\",\"name\":\"Brian R W Baucom\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"},{\"authorId\":\"33044681\",\"name\":\"P. Georgiou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4f46091b0720b01e4c5ba8b5e0c3d716fd7d462\",\"title\":\"An analysis of observation length requirements in spoken language for machine understanding of human behaviors\",\"url\":\"https://www.semanticscholar.org/paper/d4f46091b0720b01e4c5ba8b5e0c3d716fd7d462\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.07635\",\"authors\":[{\"authorId\":\"144039832\",\"name\":\"P. Barros\"},{\"authorId\":\"19175266\",\"name\":\"Nikhil Churamani\"},{\"authorId\":\"1923910\",\"name\":\"A. Sciutti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89091f8899aa0d654b453d80b3d2cd780e18f7f3\",\"title\":\"The FaceChannel: A Fast & Furious Deep Neural Network for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89091f8899aa0d654b453d80b3d2cd780e18f7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000297927\",\"name\":\"Jianhua Yuan\"},{\"authorId\":\"48607376\",\"name\":\"Y. Wu\"},{\"authorId\":\"3399505\",\"name\":\"X. Lu\"},{\"authorId\":\"51325589\",\"name\":\"Yanyan Zhao\"},{\"authorId\":\"152277111\",\"name\":\"B. Qin\"},{\"authorId\":\"1570906914\",\"name\":\"Ting Liu\"}],\"doi\":\"10.1007/S11431-020-1634-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fb879ef0fb668f4994f561f2069ad72ca28afea\",\"title\":\"Recent advances in deep learning based sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/0fb879ef0fb668f4994f561f2069ad72ca28afea\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.06711\",\"authors\":[{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1145/3394171.3413570\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9be8effeaa4b6c68cb92003df40617884b5633a5\",\"title\":\"Emotions Don't Lie: An Audio-Visual Deepfake Detection Method using Affective Cues\",\"url\":\"https://www.semanticscholar.org/paper/9be8effeaa4b6c68cb92003df40617884b5633a5\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1807.01466\",\"authors\":[{\"authorId\":\"2988495\",\"name\":\"Leimin Tian\"},{\"authorId\":\"144490056\",\"name\":\"C. Lai\"},{\"authorId\":\"2050835\",\"name\":\"J. Moore\"}],\"doi\":\"10.18653/v1/W18-3306\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2c15a4d41c0cd91913f862309bf16aba112dcf4\",\"title\":\"Polarity and Intensity: the Two Aspects of Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c2c15a4d41c0cd91913f862309bf16aba112dcf4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41173970\",\"name\":\"I. Li\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"37738947ef9d8f1f48a0e81321e813414235a396\",\"title\":\"Hierarchical Seq 2 Seq : Learning Representations of Online Spoken Speech\",\"url\":\"https://www.semanticscholar.org/paper/37738947ef9d8f1f48a0e81321e813414235a396\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.06606\",\"authors\":[{\"authorId\":\"9900742\",\"name\":\"C. Lee\"},{\"authorId\":\"35287507\",\"name\":\"Kyu Ye Song\"},{\"authorId\":\"3269993\",\"name\":\"Jihoon Jeong\"},{\"authorId\":\"9407778\",\"name\":\"W. Y. Choi\"}],\"doi\":\"10.18653/v1/W18-3304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f357cffffca307e290d113ef450db47a31115172\",\"title\":\"Convolutional Attention Networks for Multimodal Emotion Recognition from Speech and Text Data\",\"url\":\"https://www.semanticscholar.org/paper/f357cffffca307e290d113ef450db47a31115172\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.15955\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"88741566\",\"name\":\"No\\u00e9 Tits\"},{\"authorId\":\"71013766\",\"name\":\"Mathilde Brousmiche\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.1\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2ed73d5a7fd431b68ddc1b69144df7f44246a9b\",\"title\":\"A Transformer-based joint-encoding for Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a2ed73d5a7fd431b68ddc1b69144df7f44246a9b\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":\"2009.09629\",\"authors\":[{\"authorId\":\"47653392\",\"name\":\"Wenliang Dai\"},{\"authorId\":\"152613855\",\"name\":\"Zihan Liu\"},{\"authorId\":\"1660855299\",\"name\":\"Tiezheng Yu\"},{\"authorId\":\"40539650\",\"name\":\"Pascale Fung\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"06d420c2c40f3d117634579f12885c0a00780085\",\"title\":\"Modality-Transferable Emotion Embeddings for Low-Resource Multimodal Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/06d420c2c40f3d117634579f12885c0a00780085\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845316\",\"name\":\"D. Zhang\"},{\"authorId\":\"1993712503\",\"name\":\"Xincheng Ju\"},{\"authorId\":\"47787394\",\"name\":\"J. Li\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.291\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8f786d6cdd4e65581a67ace176d0ead1658b5463\",\"title\":\"Multi-modal Multi-label Emotion Detection with Modality and Label Dependence\",\"url\":\"https://www.semanticscholar.org/paper/8f786d6cdd4e65581a67ace176d0ead1658b5463\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.06692\",\"authors\":[{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"6325349\",\"name\":\"P. Guhan\"},{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1109/cvpr42600.2020.01424\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d19bc4735cdb26935dbf50d2ac6d6b82fcc20302\",\"title\":\"EmotiCon: Context-Aware Multimodal Emotion Recognition Using Frege\\u2019s Principle\",\"url\":\"https://www.semanticscholar.org/paper/d19bc4735cdb26935dbf50d2ac6d6b82fcc20302\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"4909159\",\"name\":\"J. Wu\"},{\"authorId\":\"3025397\",\"name\":\"K. Hoashi\"}],\"doi\":\"10.1145/3340555.3355720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f784ca9a654948de60343c667a4ba1b25fb66e3b\",\"title\":\"Multi-Attention Fusion Network for Video-based Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f784ca9a654948de60343c667a4ba1b25fb66e3b\",\"venue\":\"ICMI '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22249984\",\"name\":\"Jonggu Kim\"},{\"authorId\":\"3078656\",\"name\":\"Hyeonmok Ko\"},{\"authorId\":\"1390629077\",\"name\":\"Seoha Song\"},{\"authorId\":\"31714297\",\"name\":\"Sae-Bom Jang\"},{\"authorId\":\"50751269\",\"name\":\"Jiyeon Hong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f6dd2d421e8335c8c33c8739eae7d010bb55af63\",\"title\":\"Contextual Augmentation of Pretrained Language Models for Emotion Recognition in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/f6dd2d421e8335c8c33c8739eae7d010bb55af63\",\"venue\":\"PEOPLES\",\"year\":2020},{\"arxivId\":\"2011.13572\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"49264083\",\"name\":\"Jia-Xuan He\"},{\"authorId\":\"1742521984\",\"name\":\"Ying Zeng\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"title\":\"Analyzing Unaligned Multimodal Sequence via Graph Convolution and Graph Pooling Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14891\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Japsimar Singh Wahi\"},{\"authorId\":\"1557382867\",\"name\":\"Siyao Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32cdd9d0d4d462a2ca781f0c7cdbc053f6a07938\",\"title\":\"Detecting Hate Speech in Multi-modal Memes\",\"url\":\"https://www.semanticscholar.org/paper/32cdd9d0d4d462a2ca781f0c7cdbc053f6a07938\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52219377\",\"name\":\"Tulika Saha\"},{\"authorId\":\"13231743\",\"name\":\"A. Patra\"},{\"authorId\":\"1777669\",\"name\":\"Sriparna Saha\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/2020.acl-main.402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bff9b22a96a49a35edd10f6a1cec04694cfdc79e\",\"title\":\"Towards Emotion-aided Multi-modal Dialogue Act Classification\",\"url\":\"https://www.semanticscholar.org/paper/bff9b22a96a49a35edd10f6a1cec04694cfdc79e\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1906.00295\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"35836381\",\"name\":\"Shaojie Bai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.18653/v1/P19-1656\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"949fef650da4c41afe6049a183b504b3cc91f4bd\",\"title\":\"Multimodal Transformer for Unaligned Multimodal Language Sequences\",\"url\":\"https://www.semanticscholar.org/paper/949fef650da4c41afe6049a183b504b3cc91f4bd\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71107995\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1109/ICME.2019.00131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d28cbea30a4a9bf74f6ac57e805a72504e4ec56f\",\"title\":\"Modeling the Clause-Level Structure to Multimodal Sentiment Analysis via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d28cbea30a4a9bf74f6ac57e805a72504e4ec56f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1911.09826\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1429197894\",\"name\":\"Chengfeng Mao\"},{\"authorId\":\"1429262863\",\"name\":\"Kelly Shi\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd88d0346e679d1388d7e0ef08f7f7e329f2d760\",\"title\":\"Factorized Multimodal Transformer for Multimodal Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/cd88d0346e679d1388d7e0ef08f7f7e329f2d760\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.00711\",\"authors\":[{\"authorId\":\"1994333\",\"name\":\"Marina Danilevsky\"},{\"authorId\":\"143857309\",\"name\":\"Kun Qian\"},{\"authorId\":\"48361424\",\"name\":\"Ranit Aharonov\"},{\"authorId\":\"2208580\",\"name\":\"Yannis Katsis\"},{\"authorId\":\"1814905\",\"name\":\"B. Kawas\"},{\"authorId\":\"40655309\",\"name\":\"P. Sen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"829e36b23f7b42e109f84b5b761052498b291962\",\"title\":\"A Survey of the State of Explainable AI for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/829e36b23f7b42e109f84b5b761052498b291962\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995716303\",\"name\":\"Ruichen Li\"},{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"49268477\",\"name\":\"Jingwen Hu\"},{\"authorId\":\"143781963\",\"name\":\"S. Guo\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3423327.3423671\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a382ccbc31a1d8c6065ea9335d0d8adf121210af\",\"title\":\"Multi-modal Fusion for Video Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a382ccbc31a1d8c6065ea9335d0d8adf121210af\",\"venue\":\"MuSe @ ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.02038\",\"authors\":[{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63788711785b1dcbe400af8c2332b8bc48bc42fc\",\"title\":\"Low Rank Fusion based Transformers for Multimodal Sequences\",\"url\":\"https://www.semanticscholar.org/paper/63788711785b1dcbe400af8c2332b8bc48bc42fc\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91915492\",\"name\":\"Fan Yang\"},{\"authorId\":\"2602530\",\"name\":\"Xiaochang Peng\"},{\"authorId\":\"134007132\",\"name\":\"Gargi Ghosh\"},{\"authorId\":\"3078538\",\"name\":\"Reshef Shilon\"},{\"authorId\":\"46389865\",\"name\":\"Hao Ma\"},{\"authorId\":\"31449330\",\"name\":\"Eider Moore\"},{\"authorId\":\"15153074\",\"name\":\"Goran Predovi\\u0107\"}],\"doi\":\"10.18653/v1/W19-3502\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ee8ea1a02a7cea51ae9191e0c0dad7ab080741d8\",\"title\":\"Exploring Deep Multimodal Fusion of Text and Photo for Hate Speech Classification\",\"url\":\"https://www.semanticscholar.org/paper/ee8ea1a02a7cea51ae9191e0c0dad7ab080741d8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"1831541\",\"name\":\"Kamrul Hasan\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"252879b227f494df00d465602342f6c38effd27b\",\"title\":\"BERT Input Embedder Attention Gating Shifting Word Embedding Acoustic Embedding Visual Embedding Multimodal Shifting Gate\",\"url\":\"https://www.semanticscholar.org/paper/252879b227f494df00d465602342f6c38effd27b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51491781\",\"name\":\"Minping Chen\"},{\"authorId\":\"1502881409\",\"name\":\"Xia Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03fa50a1b62db4bc5d98bea6ca5bcc1a611af51a\",\"title\":\"SWAFN: Sentimental Words Aware Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/03fa50a1b62db4bc5d98bea6ca5bcc1a611af51a\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46304750\",\"name\":\"Y. Ding\"},{\"authorId\":\"51242086\",\"name\":\"R. Kumaran\"},{\"authorId\":\"4968278\",\"name\":\"Tianjiao Yang\"},{\"authorId\":\"15425485\",\"name\":\"Tobias H\\u00f6llerer\"}],\"doi\":\"10.1145/3382507.3418838\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a6cd445e12074ae349a48d6119874078f7a50553\",\"title\":\"Predicting Video Affect via Induced Affection in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/a6cd445e12074ae349a48d6119874078f7a50553\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644481054\",\"name\":\"AkhtarMd Shad\"},{\"authorId\":\"2015118639\",\"name\":\"ChauhanDushyant Singh\"},{\"authorId\":\"1584888409\",\"name\":\"EkbalAsif\"}],\"doi\":\"10.1145/3380744\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d56d7d58370fbb519bdf0c6e52a966fc92c6e27\",\"title\":\"A Deep Multi-task Contextual Attention Framework for Multi-modal Affect Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1d56d7d58370fbb519bdf0c6e52a966fc92c6e27\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.05659\",\"authors\":[{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1609/AAAI.V34I02.5492\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f518ad056874460e9bc620852a584a3563850cfa\",\"title\":\"M3ER: Multiplicative Multimodal Emotion Recognition Using Facial, Textual, and Speech Cues\",\"url\":\"https://www.semanticscholar.org/paper/f518ad056874460e9bc620852a584a3563850cfa\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1502869569\",\"name\":\"Xia Li\"},{\"authorId\":\"51491781\",\"name\":\"Minping Chen\"}],\"doi\":\"10.1007/978-3-030-63031-7_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2bebbc1f4f0718ad10649ea4a84b69430ec36122\",\"title\":\"Multimodal Sentiment Analysis with Multi-perspective Fusion Network Focusing on Sense Attentive Language\",\"url\":\"https://www.semanticscholar.org/paper/2bebbc1f4f0718ad10649ea4a84b69430ec36122\",\"venue\":\"CNCL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52219377\",\"name\":\"Tulika Saha\"},{\"authorId\":\"1490535619\",\"name\":\"Dhawal Gupta\"},{\"authorId\":\"1777669\",\"name\":\"Sriparna Saha\"},{\"authorId\":\"8031616\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.1007/s12559-019-09704-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"944425c9f840006cd7c91de830ab35ab46283e55\",\"title\":\"Emotion Aided Dialogue Act Classification for Task-Independent Conversations in a Multi-modal Framework\",\"url\":\"https://www.semanticscholar.org/paper/944425c9f840006cd7c91de830ab35ab46283e55\",\"venue\":\"Cognitive Computation\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9214106\",\"name\":\"Md Junaid Akhtar\"},{\"authorId\":\"145036777\",\"name\":\"D. Chauhan\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.1145/3380744\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3bff303cffbb9530f7193d7e3a032d42f5d69bc5\",\"title\":\"A Deep Multi-task Contextual Attention Framework for Multi-modal Affect Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3bff303cffbb9530f7193d7e3a032d42f5d69bc5\",\"venue\":\"ACM Trans. Knowl. Discov. Data\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48783040\",\"name\":\"J. Williams\"},{\"authorId\":\"80633848\",\"name\":\"S. Kleinegesse\"},{\"authorId\":\"89066101\",\"name\":\"Ramona Comanescu\"},{\"authorId\":\"7523199\",\"name\":\"Oana G. Radu\"}],\"doi\":\"10.18653/v1/W18-3302\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc7788e75e2a060e4fd96a4e030eaac77ebebc48\",\"title\":\"Recognizing Emotions in Video Using Multimodal DNN Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/fc7788e75e2a060e4fd96a4e030eaac77ebebc48\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94142567\",\"name\":\"A. Vidal\"},{\"authorId\":\"1410597683\",\"name\":\"Ali J. Salman\"},{\"authorId\":\"1678264\",\"name\":\"Wei-Cheng Lin\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"}],\"doi\":\"10.1145/3382507.3418872\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"85dcb674edef911d733cf93f3a4807926e1244cc\",\"title\":\"MSP-Face Corpus: A Natural Audiovisual Emotional Database\",\"url\":\"https://www.semanticscholar.org/paper/85dcb674edef911d733cf93f3a4807926e1244cc\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.14198\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"1384374825\",\"name\":\"Martin Q. Ma\"},{\"authorId\":\"72966973\",\"name\":\"Muqiao Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.143\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e0657c56fb71a9ebd08bde17058a13869c31d936\",\"title\":\"Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e0657c56fb71a9ebd08bde17058a13869c31d936\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050744\",\"name\":\"J. Zhang\"},{\"authorId\":\"49307584\",\"name\":\"Yan Yang\"},{\"authorId\":\"1561163796\",\"name\":\"Chengcai Chen\"},{\"authorId\":\"145836232\",\"name\":\"L. He\"},{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"}],\"doi\":\"10.1007/978-3-030-60457-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dab5ca53778a81ab80ea20fa0dc2882e9536505\",\"title\":\"Generating Emotional Social Chatbot Responses with a Consistent Speaking Style\",\"url\":\"https://www.semanticscholar.org/paper/0dab5ca53778a81ab80ea20fa0dc2882e9536505\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"2002.08267\",\"authors\":[{\"authorId\":\"1498639630\",\"name\":\"Aman Shenoy\"},{\"authorId\":\"50847752\",\"name\":\"Ashish Sardana\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.3\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4e2f33aa6ad5fdc0cb1be4af1fae78b780623d7d\",\"title\":\"Multilogue-Net: A Context Aware RNN for Multi-modal Emotion Detection and Sentiment Analysis in Conversation\",\"url\":\"https://www.semanticscholar.org/paper/4e2f33aa6ad5fdc0cb1be4af1fae78b780623d7d\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"2003432444\",\"name\":\"Dimitrios Gkoumas\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1830455439\",\"name\":\"Massimo Melucci\"}],\"doi\":\"10.1016/j.inffus.2020.08.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"title\":\"Quantum-inspired multimodal fusion for video sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":\"2005.03545\",\"authors\":[{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"}],\"doi\":\"10.1145/3394171.3413678\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c398f1283d0e594fe710d71e9627319291734b1d\",\"title\":\"MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c398f1283d0e594fe710d71e9627319291734b1d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2005.00357\",\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.1109/taffc.2020.3038167\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3215c17848f6b0d9d0e8b15ef70c1fcad29a8b90\",\"title\":\"Beneath the Tip of the Iceberg: Current Challenges and New Directions in Sentiment Analysis Research\",\"url\":\"https://www.semanticscholar.org/paper/3215c17848f6b0d9d0e8b15ef70c1fcad29a8b90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.02508\",\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"37057361\",\"name\":\"G. Naik\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.18653/v1/P19-1050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d257625e8029f6f4998deb6279f97e07e2893c\",\"title\":\"MELD: A Multimodal Multi-Party Dataset for Emotion Recognition in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/f2d257625e8029f6f4998deb6279f97e07e2893c\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1903.00840\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"144529448\",\"name\":\"Yao Chong Lim\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b3ed172c137638f247ea1208a7f6af5c1e668e0\",\"title\":\"Variational Auto-Decoder\",\"url\":\"https://www.semanticscholar.org/paper/2b3ed172c137638f247ea1208a7f6af5c1e668e0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.03520\",\"authors\":[{\"authorId\":\"138731516\",\"name\":\"Raghuveer Peri\"},{\"authorId\":\"2214186\",\"name\":\"Haoqi Li\"},{\"authorId\":\"6079502\",\"name\":\"Krishna Somandepalli\"},{\"authorId\":\"3270255\",\"name\":\"Arindam Jati\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.21437/odyssey.2020-28\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"edf226f2ae816e1ca385955928641c293146ade0\",\"title\":\"An empirical analysis of information encoded in disentangled neural speaker representations\",\"url\":\"https://www.semanticscholar.org/paper/edf226f2ae816e1ca385955928641c293146ade0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13223746\",\"name\":\"Zhongkai Sun\"},{\"authorId\":\"22603977\",\"name\":\"P. Sarma\"},{\"authorId\":\"1755618\",\"name\":\"W. Sethares\"},{\"authorId\":\"48475334\",\"name\":\"Erik P. Bucy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c4089689eb7e2e5d999767f3c3128423129c480a\",\"title\":\"Ju l 2 01 9 Multi-modal Sentiment Analysis using Deep Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c4089689eb7e2e5d999767f3c3128423129c480a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.04302\",\"authors\":[{\"authorId\":\"3156011\",\"name\":\"Shao-Yen Tseng\"},{\"authorId\":\"33044681\",\"name\":\"P. Georgiou\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"62be60059266d37a5b9d81c9b5a1e754bac8732a\",\"title\":\"Multimodal Embeddings from Language Models\",\"url\":\"https://www.semanticscholar.org/paper/62be60059266d37a5b9d81c9b5a1e754bac8732a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"}],\"doi\":\"10.1109/TMM.2019.2925966\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0bb0d021383c8dbc5d9cc804ffd91b2f4f597cca\",\"title\":\"Locally Confined Modality Fusion Network With a Global Perspective for Multimodal Human Affective Computing\",\"url\":\"https://www.semanticscholar.org/paper/0bb0d021383c8dbc5d9cc804ffd91b2f4f597cca\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2003.06711\",\"authors\":[{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2f57ad6aaa333f3d913ebf13ad95fd25a787867\",\"title\":\"Emotions Don't Lie: A Deepfake Detection Method using Audio-Visual Affective Cues\",\"url\":\"https://www.semanticscholar.org/paper/a2f57ad6aaa333f3d913ebf13ad95fd25a787867\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82849187\",\"name\":\"R. Beard\"},{\"authorId\":\"27408524\",\"name\":\"R. Das\"},{\"authorId\":\"2394130\",\"name\":\"Raymond W. M. Ng\"},{\"authorId\":\"144775910\",\"name\":\"P. Gopalakrishnan\"},{\"authorId\":\"51504808\",\"name\":\"Luka Eerens\"},{\"authorId\":\"3127347\",\"name\":\"P. Swietojanski\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"}],\"doi\":\"10.18653/v1/K18-1025\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6240321ad0632b39ba07d3e65ccdbee8c25c8b0a\",\"title\":\"Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6240321ad0632b39ba07d3e65ccdbee8c25c8b0a\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"47111898\",\"name\":\"Yijun Yu\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"}],\"doi\":\"10.1016/J.INFFUS.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"title\":\"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis\",\"url\":\"https://www.semanticscholar.org/paper/b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":\"2008.06682\",\"authors\":[{\"authorId\":\"51516859\",\"name\":\"S. Siriwardhana\"},{\"authorId\":\"1879515139\",\"name\":\"Andrew Reis\"},{\"authorId\":\"52001535\",\"name\":\"Rivindu Weerasekera\"},{\"authorId\":\"1486464114\",\"name\":\"Suranga Nanayakkara\"}],\"doi\":\"10.21437/interspeech.2020-1212\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dc89a8b66630e1af2c9715ec8f94e863fd289a31\",\"title\":\"Jointly Fine-Tuning \\\"BERT-like\\\" Self Supervised Models to Improve Multimodal Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dc89a8b66630e1af2c9715ec8f94e863fd289a31\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486457665\",\"name\":\"Vipula Dissanayake\"},{\"authorId\":\"1871120\",\"name\":\"Haimo Zhang\"},{\"authorId\":\"1485673104\",\"name\":\"Mark Billinghurst\"},{\"authorId\":\"1486464114\",\"name\":\"Suranga Nanayakkara\"}],\"doi\":\"10.21437/interspeech.2020-1356\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"948e47fb86a41dccb338ab10d79aa4b9f7fcd4de\",\"title\":\"Speech Emotion Recognition 'in the Wild' Using an Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/948e47fb86a41dccb338ab10d79aa4b9f7fcd4de\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382828513\",\"name\":\"Olivier Habimana\"},{\"authorId\":\"121704335\",\"name\":\"Y. Li\"},{\"authorId\":\"9358854\",\"name\":\"Ruixuan Li\"},{\"authorId\":\"70387082\",\"name\":\"Xiwu Gu\"},{\"authorId\":\"145024112\",\"name\":\"G. Yu\"}],\"doi\":\"10.1007/s11432-018-9941-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49b487c884b1d71b98145b2051928af5c2a415d2\",\"title\":\"Sentiment analysis using deep learning approaches: an overview\",\"url\":\"https://www.semanticscholar.org/paper/49b487c884b1d71b98145b2051928af5c2a415d2\",\"venue\":\"Science China Information Sciences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47591140\",\"name\":\"Feiyang Chen\"},{\"authorId\":\"144705497\",\"name\":\"Ziqian Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ac46a3c3bca07193ba5221fb3dd1808111d025c\",\"title\":\"Sentiment Analysis using Deep Robust Complementary Fusion of Multi-Features and Multi-Modalities\",\"url\":\"https://www.semanticscholar.org/paper/4ac46a3c3bca07193ba5221fb3dd1808111d025c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.07175\",\"authors\":[{\"authorId\":\"3151024\",\"name\":\"Lang Su\"},{\"authorId\":\"2037365541\",\"name\":\"Chuqing Hu\"},{\"authorId\":\"46439101\",\"name\":\"G. Li\"},{\"authorId\":\"1491099112\",\"name\":\"Dongpu Cao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da72f519272681d685b5fb07e8d2e42b447e680b\",\"title\":\"MSAF: Multimodal Split Attention Fusion\",\"url\":\"https://www.semanticscholar.org/paper/da72f519272681d685b5fb07e8d2e42b447e680b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"144612044\",\"name\":\"H. Chauhan\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"24cf3fc65e5c7cbd562db1ceb089f88331f9d8e2\",\"title\":\"MEISD: A Multimodal Multi-Label Emotion, Intensity and Sentiment Dialogue Dataset for Emotion Recognition and Sentiment Analysis in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/24cf3fc65e5c7cbd562db1ceb089f88331f9d8e2\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32528506\",\"name\":\"Deepanway Ghosal\"},{\"authorId\":\"46815454\",\"name\":\"Md. Shad Akhtar\"},{\"authorId\":\"145036777\",\"name\":\"D. Chauhan\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/D18-1382\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ec99eca7c86601b8c909147f8caa8c35975bc44e\",\"title\":\"Contextual Inter-modal Attention for Multi-modal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/ec99eca7c86601b8c909147f8caa8c35975bc44e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145036776\",\"name\":\"Dushyant Chauhan\"},{\"authorId\":\"46815454\",\"name\":\"Md. Shad Akhtar\"},{\"authorId\":\"152800923\",\"name\":\"A. Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/D19-1566\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"e85589f60af623cd7ee3d1eff7f1d451147e3b32\",\"title\":\"Context-aware Interactive Attention for Multi-modal Sentiment and Emotion Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e85589f60af623cd7ee3d1eff7f1d451147e3b32\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145952554\",\"name\":\"Michael Chan\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2019.00901\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"title\":\"Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485651353\",\"name\":\"E. Chandra\"},{\"authorId\":\"1717095\",\"name\":\"J. Hsu\"}],\"doi\":\"10.1109/TAAI48200.2019.8959913\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b12e296a60b943abc7e77bf7f2d4c8de2e778cfc\",\"title\":\"Deep Learning for Multimodal Emotion Recognition-Attentive Residual Disconnected RNN\",\"url\":\"https://www.semanticscholar.org/paper/b12e296a60b943abc7e77bf7f2d4c8de2e778cfc\",\"venue\":\"2019 International Conference on Technologies and Applications of Arti\\ufb01cial Intelligence (TAAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35144077\",\"name\":\"A. Yadav\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s00530-020-00656-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"764a6412c9ed41a06092bc6a908d25201029f0da\",\"title\":\"A deep learning architecture of RA-DLNet for visual sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/764a6412c9ed41a06092bc6a908d25201029f0da\",\"venue\":\"Multimedia Systems\",\"year\":2020},{\"arxivId\":\"2006.08335\",\"authors\":[{\"authorId\":\"1750913684\",\"name\":\"Bofan Xue\"},{\"authorId\":\"1774825\",\"name\":\"D. Chan\"},{\"authorId\":\"1729041\",\"name\":\"J. Canny\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ca80f5097b6ad4f4537d913c48abc470fb37342\",\"title\":\"A Dataset and Benchmarks for Multimedia Social Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5ca80f5097b6ad4f4537d913c48abc470fb37342\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49356710\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"1758474\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2969205\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0cebf78b820798e8fd5dca2a94cd888b953274b1\",\"title\":\"Multi-Modal Sentiment Classification With Independent and Interactive Knowledge via Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/0cebf78b820798e8fd5dca2a94cd888b953274b1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144490056\",\"name\":\"C. Lai\"},{\"authorId\":\"144224160\",\"name\":\"Beatrice Alex\"},{\"authorId\":\"47147237\",\"name\":\"Johanna D. Moore\"},{\"authorId\":\"2988495\",\"name\":\"Leimin Tian\"},{\"authorId\":\"3345329\",\"name\":\"Tatsuro Hori\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.21437/INTERSPEECH.2019-2632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab76b65badae8872ce191ea6173d0fdf1f1c3536\",\"title\":\"Detecting Topic-Oriented Speaker Stance in Conversational Speech\",\"url\":\"https://www.semanticscholar.org/paper/ab76b65badae8872ce191ea6173d0fdf1f1c3536\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102701933\",\"name\":\"S. Qureshi\"},{\"authorId\":\"143673279\",\"name\":\"G. Dias\"},{\"authorId\":\"144231505\",\"name\":\"Mohammed Hasanuzzaman\"},{\"authorId\":\"1777669\",\"name\":\"Sriparna Saha\"}],\"doi\":\"10.1109/MCI.2020.2998234\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8027359391974074c9a4c00d486733766abcb53\",\"title\":\"Improving Depression Level Estimation by Concurrently Learning Emotion Intensity\",\"url\":\"https://www.semanticscholar.org/paper/f8027359391974074c9a4c00d486733766abcb53\",\"venue\":\"IEEE Computational Intelligence Magazine\",\"year\":2020},{\"arxivId\":\"2005.01400\",\"authors\":[{\"authorId\":\"49218864\",\"name\":\"Abhinav Shukla\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387779\",\"name\":\"M. Pantic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97d6e0d87311db2333613fbc85fcaa1a6c70cfa6\",\"title\":\"Does Visual Self-Supervision Improve Learning of Speech Representations?\",\"url\":\"https://www.semanticscholar.org/paper/97d6e0d87311db2333613fbc85fcaa1a6c70cfa6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.08696\",\"authors\":[{\"authorId\":\"13223746\",\"name\":\"Zhongkai Sun\"},{\"authorId\":\"22603977\",\"name\":\"P. Sarma\"},{\"authorId\":\"1755618\",\"name\":\"W. Sethares\"},{\"authorId\":\"48475334\",\"name\":\"Erik P. Bucy\"}],\"doi\":\"10.21437/interspeech.2019-2482\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"902bd44b3d94603d23f493ca1486361bb56a3e2b\",\"title\":\"Multi-modal Sentiment Analysis using Deep Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/902bd44b3d94603d23f493ca1486361bb56a3e2b\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71107995\",\"name\":\"Dong Zhang\"},{\"authorId\":\"51183249\",\"name\":\"Liangqing Wu\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1109/ICME.2019.00130\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"39688ac1d78baba35a3ecc8bb12df5d59952b998\",\"title\":\"Multi-Modal Language Analysis with Hierarchical Interaction-Level and Selection-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/39688ac1d78baba35a3ecc8bb12df5d59952b998\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1562122009\",\"name\":\"Anne C. Bloem\"},{\"authorId\":\"145741021\",\"name\":\"E. Barakova\"},{\"authorId\":\"1507519878\",\"name\":\"Inge M. Hootsmans\"},{\"authorId\":\"1507507639\",\"name\":\"Lena M. Opheij\"},{\"authorId\":\"1507480041\",\"name\":\"Romain H. A. Toebosch\"},{\"authorId\":\"2991958\",\"name\":\"Matthias Kerzel\"},{\"authorId\":\"144039833\",\"name\":\"Pablo Barros\"}],\"doi\":\"10.1145/3371382.3378359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f86fcd6028a350e9330bbec52855c794af455e33\",\"title\":\"Improving Emotional Expression Recognition of Robots Using Regions of Interest from Human Data\",\"url\":\"https://www.semanticscholar.org/paper/f86fcd6028a350e9330bbec52855c794af455e33\",\"venue\":\"HRI\",\"year\":2020},{\"arxivId\":\"1911.05544\",\"authors\":[{\"authorId\":\"13223746\",\"name\":\"Zhongkai Sun\"},{\"authorId\":\"22603977\",\"name\":\"P. Sarma\"},{\"authorId\":\"1755618\",\"name\":\"W. Sethares\"},{\"authorId\":\"40609253\",\"name\":\"Yingyu Liang\"}],\"doi\":\"10.1609/aaai.v34i05.6431\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f2e7e083a3837573a4c456f468d90c5a54967d1\",\"title\":\"Learning Relationships between Text, Audio, and Video via Deep Canonical Correlation for Multimodal Language Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f2e7e083a3837573a4c456f468d90c5a54967d1\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.06102\",\"authors\":[{\"authorId\":\"30151156\",\"name\":\"A. A. Ismail\"},{\"authorId\":\"49745735\",\"name\":\"M. Hasan\"},{\"authorId\":\"2840277\",\"name\":\"F. Ishtiaq\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"83f57d064dff8e508fdc5ef3aae485f34c1e80a2\",\"title\":\"Improving Multimodal Accuracy Through Modality Pre-training and Attention\",\"url\":\"https://www.semanticscholar.org/paper/83f57d064dff8e508fdc5ef3aae485f34c1e80a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120828339\",\"name\":\"Binghua Li\"},{\"authorId\":\"1971112\",\"name\":\"Chaofeng Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"47359248\",\"name\":\"N. Zheng\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"}],\"doi\":\"10.1007/978-3-030-58586-0_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"title\":\"TPFN: Applying Outer Product Along Time to Multimodal Sentiment Analysis Fusion on Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49352657\",\"name\":\"Long-Fei Xie\"},{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"}],\"doi\":\"10.1007/978-3-030-59830-3_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6fa32942c85a7283abd1c8fbd4bae11f73853cf\",\"title\":\"Gate-Fusion Transformer for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e6fa32942c85a7283abd1c8fbd4bae11f73853cf\",\"venue\":\"ICPRAI\",\"year\":2020},{\"arxivId\":\"1905.05812\",\"authors\":[{\"authorId\":\"152703890\",\"name\":\"Md. Shad Akhtar\"},{\"authorId\":\"145036777\",\"name\":\"D. Chauhan\"},{\"authorId\":\"32528506\",\"name\":\"Deepanway Ghosal\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/N19-1034\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"093e72b8149826da54d224c21a8ac0e1d2f3ffa8\",\"title\":\"Multi-task Learning for Multi-modal Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/093e72b8149826da54d224c21a8ac0e1d2f3ffa8\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1910.08916\",\"authors\":[{\"authorId\":\"12386833\",\"name\":\"Wenxiang Jiao\"},{\"authorId\":\"1785083\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"145310659\",\"name\":\"I. King\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"17caeae2320511e58406859c0cd735e52977890f\",\"title\":\"PT-CoDE: Pre-trained Context-Dependent Encoder for Utterance-level Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17caeae2320511e58406859c0cd735e52977890f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.01043\",\"authors\":[{\"authorId\":\"39215964\",\"name\":\"Ayush Kumar\"},{\"authorId\":\"1787417\",\"name\":\"J. Vepa\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053012\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65f8114c1ccfb2601c55c7a0e3c4492900c5b1e3\",\"title\":\"Gated Mechanism for Attention Based Multi Modal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/65f8114c1ccfb2601c55c7a0e3c4492900c5b1e3\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1806.02923\",\"authors\":[{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"144304984\",\"name\":\"Rui Xia\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.18653/v1/W18-3303\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"662e48df100e85665d8dea288fc6cc7e426f6b72\",\"title\":\"Multimodal Relational Tensor Network for Sentiment and Emotion Classification\",\"url\":\"https://www.semanticscholar.org/paper/662e48df100e85665d8dea288fc6cc7e426f6b72\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1911.09515\",\"authors\":[{\"authorId\":\"32585792\",\"name\":\"S. Chakravarthula\"},{\"authorId\":\"2533091\",\"name\":\"Brian R W Baucom\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"},{\"authorId\":\"33044681\",\"name\":\"P. Georgiou\"}],\"doi\":\"10.1016/j.csl.2020.101162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2489121b032d5ba49b690975d84e5317abdd8335\",\"title\":\"An analysis of observation length requirements for machine understanding of human behaviors from spoken language\",\"url\":\"https://www.semanticscholar.org/paper/2489121b032d5ba49b690975d84e5317abdd8335\",\"venue\":\"Comput. Speech Lang.\",\"year\":2021},{\"arxivId\":\"2010.11226\",\"authors\":[{\"authorId\":\"2000786644\",\"name\":\"Alex Wilf\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75da325df1463c0d1d26b44ce5133c71ca0d75ae\",\"title\":\"Dynamic Layer Customization for Noise Robust Speech Emotion Recognition in Heterogeneous Condition Training\",\"url\":\"https://www.semanticscholar.org/paper/75da325df1463c0d1d26b44ce5133c71ca0d75ae\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":51868869,\"doi\":\"10.18653/v1/P18-1208\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":45,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"006fdeff6e1a81c404317ee4056d6cc72f9c0e50\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Varun Manjunatha\"},{\"authorId\":null,\"name\":\"Jordan L Boyd-Graber\"},{\"authorId\":null,\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Memn : Multimodal emotional memory network for emotion recognition in dyadic conversational videos Long short - term memory\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Erin Kelly\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"namic wordclouds and vennclouds for exploratory data analysis\",\"url\":\"\",\"venue\":\"Proceedings of the Workshop on Interactive Language Learning , Visualization , and Interfaces\",\"year\":2014},{\"arxivId\":\"1503.03832\",\"authors\":[{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2741985\",\"name\":\"D. Kalenichenko\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"}],\"doi\":\"10.1109/CVPR.2015.7298682\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5aa26299435bdf7db874ef1640a6c3b5a4a2c394\",\"title\":\"FaceNet: A unified embedding for face recognition and clustering\",\"url\":\"https://www.semanticscholar.org/paper/5aa26299435bdf7db874ef1640a6c3b5a4a2c394\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396239754\",\"name\":\"Ver\\u00f3nica P\\u00e9rez-Rosas\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b73b8aa885d972a1f5fafc87208d2f8baa9f83c4\",\"title\":\"Utterance-Level Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b73b8aa885d972a1f5fafc87208d2f8baa9f83c4\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3101156\",\"name\":\"Wootaek Lim\"},{\"authorId\":\"3230496\",\"name\":\"Dae-young Jang\"},{\"authorId\":\"66470019\",\"name\":\"T. Lee\"}],\"doi\":\"10.1109/APSIPA.2016.7820699\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c911b052b343ef7f27a064081469261f9f786f0\",\"title\":\"Speech emotion recognition using convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3c911b052b343ef7f27a064081469261f9f786f0\",\"venue\":\"2016 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"1389036863\",\"name\":\"Jordan L. Boyd-Graber\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":\"10.3115/v1/P15-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d86227948b6000e5d7ed63cf2054ad600b7994a0\",\"title\":\"Deep Unordered Composition Rivals Syntactic Methods for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/d86227948b6000e5d7ed63cf2054ad600b7994a0\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33366691\",\"name\":\"Jiahong Yuan\"},{\"authorId\":\"144173823\",\"name\":\"M. Liberman\"}],\"doi\":\"10.1121/1.2935783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"title\":\"Speaker identification on the SCOTUS corpus\",\"url\":\"https://www.semanticscholar.org/paper/5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34961461\",\"name\":\"Andrew L. Maas\"},{\"authorId\":\"31949420\",\"name\":\"Raymond E. Daly\"},{\"authorId\":\"2040956\",\"name\":\"P. T. Pham\"},{\"authorId\":\"145280442\",\"name\":\"D. Huang\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"649d03490ef72c5274e3bccd03d7a299d2f8da91\",\"title\":\"Learning Word Vectors for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/649d03490ef72c5274e3bccd03d7a299d2f8da91\",\"venue\":\"ACL\",\"year\":2011},{\"arxivId\":\"1806.06176\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"title\":\"Learning Factorized Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"},{\"authorId\":\"115865607\",\"name\":\"Wallace V. Freisen\"},{\"authorId\":\"6929961\",\"name\":\"S. Ancoli\"}],\"doi\":\"10.1037/H0077722\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"98b41e682c80232be7a7741f46404a6118e19fc2\",\"title\":\"Facial signs of emotional experience.\",\"url\":\"https://www.semanticscholar.org/paper/98b41e682c80232be7a7741f46404a6118e19fc2\",\"venue\":\"\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145676779\",\"name\":\"John Kane\"},{\"authorId\":\"3127409\",\"name\":\"C. Gobl\"}],\"doi\":\"10.1109/TASL.2013.2245653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5938ac3639472c4c46612546d5ea65798ebfab50\",\"title\":\"Wavelet Maxima Dispersion for Breathy to Tense Voice Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/5938ac3639472c4c46612546d5ea65798ebfab50\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144881634\",\"name\":\"M. Grimm\"},{\"authorId\":\"1787004\",\"name\":\"K. Kroschel\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1109/ICME.2008.4607572\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed2e47a250c7a868e7f46c8f45e8d78d984a1816\",\"title\":\"The Vera am Mittag German audio-visual emotional speech database\",\"url\":\"https://www.semanticscholar.org/paper/ed2e47a250c7a868e7f46c8f45e8d78d984a1816\",\"venue\":\"2008 IEEE International Conference on Multimedia and Expo\",\"year\":2008},{\"arxivId\":\"1802.00923\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"8365766\",\"name\":\"Prateek Vij\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90f3bd3141026e3a15358149e7de42a3c7ed7f31\",\"title\":\"Multi-attention Recurrent Network for Human Communication Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/90f3bd3141026e3a15358149e7de42a3c7ed7f31\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1644691141\",\"name\":\"WollmerMartin\"},{\"authorId\":\"1644094433\",\"name\":\"WeningerFelix\"},{\"authorId\":\"1644678308\",\"name\":\"KnaupTobias\"},{\"authorId\":\"1643858672\",\"name\":\"SchullerBjorn\"},{\"authorId\":\"1644678279\",\"name\":\"SunCongkai\"},{\"authorId\":\"1644025877\",\"name\":\"SagaeKenji\"},{\"authorId\":\"1644022643\",\"name\":\"MorencyLouis-Philippe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e94c98cdf5d880ffa4a0f2948c57fa27a049250\",\"title\":\"YouTube Movie Reviews\",\"url\":\"https://www.semanticscholar.org/paper/4e94c98cdf5d880ffa4a0f2948c57fa27a049250\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"48099761\",\"name\":\"K. Paliwal\"}],\"doi\":\"10.1109/78.650093\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"title\":\"Bidirectional recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"24590005\",\"name\":\"Alex Perelygin\"},{\"authorId\":\"1856239\",\"name\":\"J. Wu\"},{\"authorId\":\"1964541\",\"name\":\"Jason Chuang\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"687bac2d3320083eb4530bf18bb8f8f721477600\",\"title\":\"Recursive Deep Models for Semantic Compositionality Over a Sentiment Treebank\",\"url\":\"https://www.semanticscholar.org/paper/687bac2d3320083eb4530bf18bb8f8f721477600\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2831374\",\"name\":\"Sanjay Bilakhia\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"144483472\",\"name\":\"A. Nijholt\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1016/j.patrec.2015.03.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae2ee60219d63475c56fcb6c3f2b3664b3c4dbd9\",\"title\":\"The MAHNOB Mimicry Database: A database of naturalistic human interactions\",\"url\":\"https://www.semanticscholar.org/paper/ae2ee60219d63475c56fcb6c3f2b3664b3c4dbd9\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50430495\",\"name\":\"F. Mueller\"}],\"doi\":\"10.1037/14263-000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"200a779c9d94cf7523d84d9b8a05df7f5565da14\",\"title\":\"Lectures on the Science of Language: Delivered at the Royal Institution of Great Britain in April, May, & June, 1861\",\"url\":\"https://www.semanticscholar.org/paper/200a779c9d94cf7523d84d9b8a05df7f5565da14\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"cs/0205070\",\"authors\":[{\"authorId\":\"144865353\",\"name\":\"B. Pang\"},{\"authorId\":\"145810617\",\"name\":\"Lillian Lee\"},{\"authorId\":\"2066721\",\"name\":\"Shivakumar Vaithyanathan\"}],\"doi\":\"10.3115/1118693.1118704\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12d0353ce8b41b7e5409e5a4a611110aee33c7bc\",\"title\":\"Thumbs up? Sentiment Classification using Machine Learning Techniques\",\"url\":\"https://www.semanticscholar.org/paper/12d0353ce8b41b7e5409e5a4a611110aee33c7bc\",\"venue\":\"EMNLP\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Roger Zimmerman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Memn : Multimodal emotional memory network for emotion recognition in dyadic conversational videos Long short - term memory\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Varun Manjunatha\"},{\"authorId\":null,\"name\":\"Jordan L Boyd-Graber\"},{\"authorId\":null,\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Memn : Multimodal emotional memory network for emotion recognition in dyadic conversational videos Long short - term memory\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1802.00927\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"37052144\",\"name\":\"N. Mazumder\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"609512f19e06bf393cb79fbf57183f75b8d889d2\",\"title\":\"Memory Fusion Network for Multi-view Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/609512f19e06bf393cb79fbf57183f75b8d889d2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1707.07250\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D17-1115\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"title\":\"Tensor Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4366352\",\"name\":\"Glen Coppersmith\"},{\"authorId\":\"48354136\",\"name\":\"E. Kelly\"}],\"doi\":\"10.3115/v1/W14-3103\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8e8f7311d52871d86baf7571b87107e23ac99f3\",\"title\":\"Dynamic Wordclouds and Vennclouds for Exploratory Data Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d8e8f7311d52871d86baf7571b87107e23ac99f3\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1802.00924\",\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3136755.3136801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"title\":\"Multimodal sentiment analysis with word-level fusion and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":\"1705.02735\",\"authors\":[{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145262833\",\"name\":\"Cara Jones\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc72b2bb34f6a8216767df80ae13e09d1ef0ebda\",\"title\":\"Combating Human Trafficking with Multimodal Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/fc72b2bb34f6a8216767df80ae13e09d1ef0ebda\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2974242\",\"name\":\"Behnaz Nojavanasghari\"},{\"authorId\":\"20781644\",\"name\":\"Deepak Gopinath\"},{\"authorId\":\"3407381\",\"name\":\"J. Koushik\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/2993148.2993176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaa439c0a1094438b97ed251c968e15e37a47e45\",\"title\":\"Deep multimodal fusion for persuasiveness prediction\",\"url\":\"https://www.semanticscholar.org/paper/aaa439c0a1094438b97ed251c968e15e37a47e45\",\"venue\":\"ICMI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"3468264\",\"name\":\"Aaksha Meghawat\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9648656af140d5b412011de8420f39d3dec3c48\",\"title\":\"Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c9648656af140d5b412011de8420f39d3dec3c48\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"144681495\",\"name\":\"P. Robinson\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/WACV.2016.7477553\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d997919c30fa6711bc5c25cf8c8aea34fac27b91\",\"title\":\"OpenFace: An open source facial behavior analysis toolkit\",\"url\":\"https://www.semanticscholar.org/paper/d997919c30fa6711bc5c25cf8c8aea34fac27b91\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2591941\",\"name\":\"Shyam Sundar Rajagopalan\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1007/978-3-319-46478-7_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88e350a82fc6a30a33f231666455d5076f6c3731\",\"title\":\"Extending Long Short-Term Memory for Multi-View Structured Learning\",\"url\":\"https://www.semanticscholar.org/paper/88e350a82fc6a30a33f231666455d5076f6c3731\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"2204726\",\"name\":\"I. Chaturvedi\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"145125161\",\"name\":\"Amir Hussain\"}],\"doi\":\"10.1109/ICDM.2016.0055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d21cc2677e544b46673ff19ad4f378f32129069\",\"title\":\"Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0d21cc2677e544b46673ff19ad4f378f32129069\",\"venue\":\"2016 IEEE 16th International Conference on Data Mining (ICDM)\",\"year\":2016},{\"arxivId\":\"1605.08695\",\"authors\":[{\"authorId\":\"51284110\",\"name\":\"M. Abadi\"},{\"authorId\":\"144758007\",\"name\":\"P. Barham\"},{\"authorId\":\"47740021\",\"name\":\"J. Chen\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"36347083\",\"name\":\"Andy Davis\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"1780892\",\"name\":\"Sanjay Ghemawat\"},{\"authorId\":\"145659929\",\"name\":\"Geoffrey Irving\"},{\"authorId\":\"73195837\",\"name\":\"M. Isard\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"},{\"authorId\":\"3369421\",\"name\":\"Josh Levenberg\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"144375552\",\"name\":\"Sherry Moore\"},{\"authorId\":\"20154699\",\"name\":\"D. Murray\"},{\"authorId\":\"32163737\",\"name\":\"B. Steiner\"},{\"authorId\":\"2080690\",\"name\":\"P. Tucker\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"47941411\",\"name\":\"Pete Warden\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"145167058\",\"name\":\"Y. Yu\"},{\"authorId\":\"47957022\",\"name\":\"Xiaoqiang Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"46200b99c40e8586c8a0f588488ab6414119fb28\",\"title\":\"TensorFlow: A system for large-scale machine learning\",\"url\":\"https://www.semanticscholar.org/paper/46200b99c40e8586c8a0f588488ab6414119fb28\",\"venue\":\"OSDI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721937\",\"name\":\"P. Alku\"},{\"authorId\":\"1714791\",\"name\":\"H. Strik\"},{\"authorId\":\"3120743\",\"name\":\"E. Vilkman\"}],\"doi\":\"10.1016/S0167-6393(97)00020-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d12b4a7540e1150c60899a1a5a399387e5a4cd\",\"title\":\"Parabolic spectral parameter - A new method for quantification of the glottal flow\",\"url\":\"https://www.semanticscholar.org/paper/00d12b4a7540e1150c60899a1a5a399387e5a4cd\",\"venue\":\"Speech Commun.\",\"year\":1997},{\"arxivId\":\"1704.08063\",\"authors\":[{\"authorId\":\"36326884\",\"name\":\"Weiyang Liu\"},{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"1751019\",\"name\":\"Zhiding Yu\"},{\"authorId\":\"49595665\",\"name\":\"Ming Li\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"97242747\",\"name\":\"Le Song\"}],\"doi\":\"10.1109/CVPR.2017.713\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd8f77b7d3b9d272f7a68defc1412f73e5ac3135\",\"title\":\"SphereFace: Deep Hypersphere Embedding for Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bd8f77b7d3b9d272f7a68defc1412f73e5ac3135\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5481020\",\"name\":\"Sunghyun Park\"},{\"authorId\":\"1927440\",\"name\":\"Han Suk Shim\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"1757166\",\"name\":\"Kenji Sagae\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/2663204.2663260\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6eeb620e1487e4bf30ac0117dcc8261102fdc065\",\"title\":\"Computational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/6eeb620e1487e4bf30ac0117dcc8261102fdc065\",\"venue\":\"ICMI\",\"year\":2014},{\"arxivId\":\"1607.03474\",\"authors\":[{\"authorId\":\"2360589\",\"name\":\"Julian G. Zilly\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"2865775\",\"name\":\"J. Koutn\\u00edk\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dba53e72c182e25e98e8f73a99d75ff69dda0c2\",\"title\":\"Recurrent Highway Networks\",\"url\":\"https://www.semanticscholar.org/paper/7dba53e72c182e25e98e8f73a99d75ff69dda0c2\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1605.02688\",\"authors\":[{\"authorId\":\"1388360943\",\"name\":\"Rami Al-Rfou\"},{\"authorId\":\"1815021\",\"name\":\"G. Alain\"},{\"authorId\":\"2634674\",\"name\":\"Amjad Almahairi\"},{\"authorId\":\"48765757\",\"name\":\"Christof Angerm\\u00fcller\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"3227028\",\"name\":\"Fr\\u00e9d\\u00e9ric Bastien\"},{\"authorId\":\"145040409\",\"name\":\"J. Bayer\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"7330729\",\"name\":\"A. Belopolsky\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"47944877\",\"name\":\"Arnaud Bergeron\"},{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"115295647\",\"name\":\"Valentin Bisson\"},{\"authorId\":\"32308836\",\"name\":\"Josh Bleecher Snyder\"},{\"authorId\":\"14362225\",\"name\":\"Nicolas Bouchard\"},{\"authorId\":\"1395619597\",\"name\":\"Nicolas Boulanger-Lewandowski\"},{\"authorId\":\"2900675\",\"name\":\"Xavier Bouthillier\"},{\"authorId\":\"2346028\",\"name\":\"A. D. Br\\u00e9bisson\"},{\"authorId\":\"1967465\",\"name\":\"Olivier Breuleux\"},{\"authorId\":\"153921980\",\"name\":\"Pierre Luc Carrier\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"29848635\",\"name\":\"Paul F. Christiano\"},{\"authorId\":\"2348758\",\"name\":\"Tim Cooijmans\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"39977229\",\"name\":\"Myriam C\\u00f4t\\u00e9\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"2460212\",\"name\":\"Olivier Delalleau\"},{\"authorId\":\"32604218\",\"name\":\"Julien Demouth\"},{\"authorId\":\"2755582\",\"name\":\"G. Desjardins\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"46573521\",\"name\":\"Laurent Dinh\"},{\"authorId\":\"2812151\",\"name\":\"Melanie Ducoffe\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"40557013\",\"name\":\"Ziye Fan\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"},{\"authorId\":\"39844381\",\"name\":\"M. Germain\"},{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"48196087\",\"name\":\"M. Graham\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"48080691\",\"name\":\"P. Hamel\"},{\"authorId\":\"1405640115\",\"name\":\"Iban Harlouchet\"},{\"authorId\":\"114956664\",\"name\":\"J. Heng\"},{\"authorId\":\"2507883\",\"name\":\"Bal\\u00e1zs Hidasi\"},{\"authorId\":\"25056820\",\"name\":\"S. Honari\"},{\"authorId\":\"36399635\",\"name\":\"Arjun Jain\"},{\"authorId\":\"152857609\",\"name\":\"S\\u00e9bastien Jean\"},{\"authorId\":\"49104216\",\"name\":\"Kai Jia\"},{\"authorId\":\"3025583\",\"name\":\"M. Korobov\"},{\"authorId\":\"144592382\",\"name\":\"Vivek Kulkarni\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"3087941\",\"name\":\"Pascal Lamblin\"},{\"authorId\":\"153109766\",\"name\":\"E. Larsen\"},{\"authorId\":\"40201308\",\"name\":\"C\\u00e9sar Laurent\"},{\"authorId\":\"72490641\",\"name\":\"Sueryun Lee\"},{\"authorId\":\"47682610\",\"name\":\"S. Lefran\\u00e7ois\"},{\"authorId\":\"2387233\",\"name\":\"S. Lemieux\"},{\"authorId\":\"144828689\",\"name\":\"N. L\\u00e9onard\"},{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"3245814\",\"name\":\"J. A. Livezey\"},{\"authorId\":\"40532172\",\"name\":\"C. Lorenz\"},{\"authorId\":\"102472217\",\"name\":\"J. Lowin\"},{\"authorId\":null,\"name\":\"Qianli Ma\"},{\"authorId\":\"1798462\",\"name\":\"Pierre-Antoine Manzagol\"},{\"authorId\":\"3422889\",\"name\":\"Olivier Mastropietro\"},{\"authorId\":\"1914552\",\"name\":\"Robert McGibbon\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"40479190\",\"name\":\"Alberto Orlandi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"121252563\",\"name\":\"M. Pezeshki\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"49577546\",\"name\":\"Daniel Renshaw\"},{\"authorId\":\"3146111\",\"name\":\"M. Rocklin\"},{\"authorId\":\"114117487\",\"name\":\"Adriana Romero\"},{\"authorId\":\"48127262\",\"name\":\"M. Roth\"},{\"authorId\":\"47696458\",\"name\":\"Peter Sadowski\"},{\"authorId\":\"3373139\",\"name\":\"J. Salvatier\"},{\"authorId\":\"47918629\",\"name\":\"F. Savard\"},{\"authorId\":\"1382154289\",\"name\":\"Jan Schl\\u00fcter\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"40116153\",\"name\":\"Gabriel Schwartz\"},{\"authorId\":\"48190457\",\"name\":\"I. Serban\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"3197429\",\"name\":\"Samira Shabanian\"},{\"authorId\":\"39442397\",\"name\":\"\\u00c9tienne Simon\"},{\"authorId\":\"11115628\",\"name\":\"Sigurd Spieckermann\"},{\"authorId\":\"120638144\",\"name\":\"S. Subramanyam\"},{\"authorId\":\"3407592\",\"name\":\"Jakub Sygnowski\"},{\"authorId\":\"66454233\",\"name\":\"J\\u00e9r\\u00e9mie Tanguay\"},{\"authorId\":\"3220768\",\"name\":\"G. V. Tulder\"},{\"authorId\":\"153160559\",\"name\":\"Joseph P. Turian\"},{\"authorId\":\"19555508\",\"name\":\"S. Urban\"},{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"2077146\",\"name\":\"Francesco Visin\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"27358391\",\"name\":\"D. J. Webb\"},{\"authorId\":\"39561601\",\"name\":\"M. Willson\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"47936713\",\"name\":\"Lijun Xue\"},{\"authorId\":\"97709924\",\"name\":\"L. Yao\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b570069f14c7588e066f7138e1f21af59d62e61\",\"title\":\"Theano: A Python framework for fast computation of mathematical expressions\",\"url\":\"https://www.semanticscholar.org/paper/6b570069f14c7588e066f7138e1f21af59d62e61\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1507.06228\",\"authors\":[{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"3035541\",\"name\":\"Klaus Greff\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b92aa7024b87f50737b372e5df31ef091ab54e62\",\"title\":\"Training Very Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/b92aa7024b87f50737b372e5df31ef091ab54e62\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"38816202\",\"name\":\"M. Bulut\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"},{\"authorId\":\"1764265\",\"name\":\"A. Kazemzadeh\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"},{\"authorId\":\"48388640\",\"name\":\"S. Kim\"},{\"authorId\":\"2522842\",\"name\":\"J. N. Chang\"},{\"authorId\":\"1797399\",\"name\":\"S. Lee\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1007/s10579-008-9076-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cf0d213f3253cd46673d955209f8463db73cc51\",\"title\":\"IEMOCAP: interactive emotional dyadic motion capture database\",\"url\":\"https://www.semanticscholar.org/paper/5cf0d213f3253cd46673d955209f8463db73cc51\",\"venue\":\"Lang. Resour. Evaluation\",\"year\":2008},{\"arxivId\":\"2001.00473\",\"authors\":[{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"35042802\",\"name\":\"M. P. Thomas\"},{\"authorId\":\"1921472\",\"name\":\"J\\u00f3n Gu\\u00f0nason\"},{\"authorId\":\"145279341\",\"name\":\"P. Naylor\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1109/TASL.2011.2170835\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec55a1835fe496d052c0df691539b6ecda61acbc\",\"title\":\"Detection of Glottal Closure Instants From Speech Signals: A Quantitative Review\",\"url\":\"https://www.semanticscholar.org/paper/ec55a1835fe496d052c0df691539b6ecda61acbc\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2012},{\"arxivId\":\"1303.5778\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1109/ICASSP.2013.6638947\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"4177ec52d1b80ed57f2e72b0f9a42365f1a8598d\",\"title\":\"Speech recognition with deep recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/4177ec52d1b80ed57f2e72b0f9a42365f1a8598d\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"1740602\",\"name\":\"F. Weninger\"},{\"authorId\":\"2024155\",\"name\":\"T. Knaup\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"2854241\",\"name\":\"C. Sun\"},{\"authorId\":\"1757166\",\"name\":\"Kenji Sagae\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2013.34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"title\":\"YouTube Movie Reviews: Sentiment Analysis in an Audio-Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2016.94\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"efe353682061e0f929e8c916b64b84ff88297e47\",\"title\":\"Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages\",\"url\":\"https://www.semanticscholar.org/paper/efe353682061e0f929e8c916b64b84ff88297e47\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Itseez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Open source computer vision library\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1807.03915\",\"authors\":[{\"authorId\":\"144008479\",\"name\":\"H. Pham\"},{\"authorId\":\"2632776\",\"name\":\"Thomas Manzini\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":\"10.18653/v1/W18-3308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d55bd57e64c8e48c61e4f1746a2c280d608a8d2\",\"title\":\"Seq2Seq2Sentiment: Multimodal Sequence to Sequence Models for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9d55bd57e64c8e48c61e4f1746a2c280d608a8d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1511.08630\",\"authors\":[{\"authorId\":\"2384711\",\"name\":\"Chunting Zhou\"},{\"authorId\":\"152873559\",\"name\":\"Chonglin Sun\"},{\"authorId\":\"49293587\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"1697834\",\"name\":\"F. C. M. Lau\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10f62af29c3fc5e2572baddca559ffbfd6be8787\",\"title\":\"A C-LSTM Neural Network for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/10f62af29c3fc5e2572baddca559ffbfd6be8787\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"2001.00459\",\"authors\":[{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"145890221\",\"name\":\"A. Alwan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8b2c70a7af59ed7f35c6b855fc2db0453eb895e\",\"title\":\"Joint Robust Voicing Detection and Pitch Estimation Based on Residual Harmonics\",\"url\":\"https://www.semanticscholar.org/paper/e8b2c70a7af59ed7f35c6b855fc2db0453eb895e\",\"venue\":\"INTERSPEECH\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2814229\",\"name\":\"George Trigeorgis\"},{\"authorId\":\"2124680\",\"name\":\"Fabien Ringeval\"},{\"authorId\":\"40384275\",\"name\":\"R. Brueckner\"},{\"authorId\":\"1779097\",\"name\":\"E. Marchi\"},{\"authorId\":\"1752913\",\"name\":\"Mihalis A. Nicolaou\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1109/ICASSP.2016.7472669\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96d27c4e487de191a17476a9775a51678a879d18\",\"title\":\"Adieu features? End-to-end speech emotion recognition using a deep convolutional recurrent network\",\"url\":\"https://www.semanticscholar.org/paper/96d27c4e487de191a17476a9775a51678a879d18\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"145143348\",\"name\":\"O. V. R. Murthy\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"2942991\",\"name\":\"J. Joshi\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1145/2818346.2829994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad0863aa16301d7c6617f8b965a64cf58f38594f\",\"title\":\"Video and Image based Emotion Recognition Challenges in the Wild: EmotiW 2015\",\"url\":\"https://www.semanticscholar.org/paper/ad0863aa16301d7c6617f8b965a64cf58f38594f\",\"venue\":\"ICMI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721937\",\"name\":\"P. Alku\"},{\"authorId\":\"104474512\",\"name\":\"Tom B\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"3120743\",\"name\":\"E. Vilkman\"}],\"doi\":\"10.1121/1.1490365\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76d84972a03d69a4760756133b20b0b0243cbe0e\",\"title\":\"Normalized amplitude quotient for parametrization of the glottal flow.\",\"url\":\"https://www.semanticscholar.org/paper/76d84972a03d69a4760756133b20b0b0243cbe0e\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2124680\",\"name\":\"Fabien Ringeval\"},{\"authorId\":\"2956333\",\"name\":\"A. Sonderegger\"},{\"authorId\":\"3674218\",\"name\":\"J\\u00fcrgen S. Sauer\"},{\"authorId\":\"1707657\",\"name\":\"D. Lalanne\"}],\"doi\":\"10.1109/FG.2013.6553805\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5b4b31c4d799a28ce3f7b5a8f770318eff044886\",\"title\":\"Introducing the RECOLA multimodal corpus of remote collaborative and affective interactions\",\"url\":\"https://www.semanticscholar.org/paper/5b4b31c4d799a28ce3f7b5a8f770318eff044886\",\"venue\":\"2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG)\",\"year\":2013},{\"arxivId\":\"1404.2188\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"}],\"doi\":\"10.3115/v1/P14-1062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27725a2d2a8cee9bf9fffc6c2167017103aba0fa\",\"title\":\"A Convolutional Neural Network for Modelling Sentences\",\"url\":\"https://www.semanticscholar.org/paper/27725a2d2a8cee9bf9fffc6c2167017103aba0fa\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2423230\",\"name\":\"L. Breiman\"}],\"doi\":\"10.1023/A:1010933404324\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986\",\"title\":\"Random Forests\",\"url\":\"https://www.semanticscholar.org/paper/13d4c2f76a7c1a4d0a71204e1d5d263a3f5a7986\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Corinna Cortes\"},{\"authorId\":null,\"name\":\"Vladimir Vapnik.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Supportvector networks\",\"url\":\"\",\"venue\":\"Mach. Learn. 20(3):273\\u2013297. https://doi.org/10.1023/A:1022627411411.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Devamanyu Hazarika\"},{\"authorId\":null,\"name\":\"Soujanya Poria\"},{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Erik Cambria\"},{\"authorId\":null,\"name\":\"Louis-Philippe Morency\"},{\"authorId\":null,\"name\":\"Roger Zimmerman.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Memn: Multimodal emotional memory network for emotion recognition in dyadic conversational videos\",\"url\":\"\",\"venue\":\"NAACL.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1606.06259\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"title\":\"MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis in Online Opinion Videos\",\"url\":\"https://www.semanticscholar.org/paper/1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"},{\"authorId\":\"1820249\",\"name\":\"S. Lucey\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1109/MMUL.2012.26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1336839e7bd3d072a2c699e613312a852a6586ae\",\"title\":\"Collecting Large, Richly Annotated Facial-Expression Databases from Movies\",\"url\":\"https://www.semanticscholar.org/paper/1336839e7bd3d072a2c699e613312a852a6586ae\",\"venue\":\"IEEE MultiMedia\",\"year\":2012},{\"arxivId\":\"1604.02878\",\"authors\":[{\"authorId\":\"3393556\",\"name\":\"Kaipeng Zhang\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/LSP.2016.2603342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e60942aa15670ed9ee03af3c0ae011fa4966b7c\",\"title\":\"Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/9e60942aa15670ed9ee03af3c0ae011fa4966b7c\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145115014\",\"name\":\"Corinna Cortes\"},{\"authorId\":\"145803549\",\"name\":\"V. Vapnik\"}],\"doi\":\"10.1023/A:1022627411411\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52b7bf3ba59b31f362aa07f957f1543a29a4279e\",\"title\":\"Support-Vector Networks\",\"url\":\"https://www.semanticscholar.org/paper/52b7bf3ba59b31f362aa07f957f1543a29a4279e\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1960326\",\"name\":\"G. Degottex\"},{\"authorId\":\"145676779\",\"name\":\"John Kane\"},{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"1749273\",\"name\":\"T. Raitio\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"}],\"doi\":\"10.1109/ICASSP.2014.6853739\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"title\":\"COVAREP \\u2014 A collaborative voice analysis repository for speech technologies\",\"url\":\"https://www.semanticscholar.org/paper/511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1081\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"title\":\"Context-Dependent Sentiment Analysis in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"19131845\",\"name\":\"Payal Doshi\"}],\"doi\":\"10.1145/2070481.2070509\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"title\":\"Towards multimodal sentiment analysis: harvesting opinions from the web\",\"url\":\"https://www.semanticscholar.org/paper/0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"venue\":\"ICMI '11\",\"year\":2011}],\"title\":\"Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph\",\"topics\":[{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Sentiment analysis\",\"topicId\":\"6011\",\"url\":\"https://www.semanticscholar.org/topic/6011\"},{\"topic\":\"Emotion recognition\",\"topicId\":\"68560\",\"url\":\"https://www.semanticscholar.org/topic/68560\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"}],\"url\":\"https://www.semanticscholar.org/paper/006fdeff6e1a81c404317ee4056d6cc72f9c0e50\",\"venue\":\"ACL\",\"year\":2018}\n"