"{\"abstract\":\"Multimodal research is an emerging field of artificial intelligence, and one of the main research problems in this field is multimodal fusion. The fusion of multimodal data is the process of integrating multiple unimodal representations into one compact multimodal representation. Previous research in this field has exploited the expressiveness of tensors for multimodal representation. However, these methods often suffer from exponential increase in dimensions and in computational complexity introduced by transformation of input into tensor. In this paper, we propose the Low-rank Multimodal Fusion method, which performs multimodal fusion using low-rank tensors to improve efficiency. We evaluate our model on three different tasks: multimodal sentiment analysis, speaker trait analysis, and emotion recognition. Our model achieves competitive results on all these tasks while drastically reducing computational complexity. Additional experiments also show that our model can perform robustly for a wide range of low-rank settings, and is indeed much more efficient in both training and inference compared to other methods that utilize tensor representations.\",\"arxivId\":\"1806.00064\",\"authors\":[{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\",\"url\":\"https://www.semanticscholar.org/author/49293070\"},{\"authorId\":null,\"name\":\"Ying Shen\",\"url\":null},{\"authorId\":\"50975207\",\"name\":\"Varun Bharadhwaj Lakshminarasimhan\",\"url\":\"https://www.semanticscholar.org/author/50975207\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\",\"url\":\"https://www.semanticscholar.org/author/28130078\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\",\"url\":\"https://www.semanticscholar.org/author/144802290\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\",\"url\":\"https://www.semanticscholar.org/author/49933077\"}],\"citationVelocity\":25,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5084b98071062389323cc19f2a8f17fb69c16df\",\"title\":\"MFM Neural Architecture MFM Generative Network ( b ) MFM Inference Network Inference Network Generative Network\",\"url\":\"https://www.semanticscholar.org/paper/e5084b98071062389323cc19f2a8f17fb69c16df\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.08218\",\"authors\":[{\"authorId\":\"3455244\",\"name\":\"S. Verma\"},{\"authorId\":\"120465859\",\"name\":\"Jiwei Wang\"},{\"authorId\":\"1998943485\",\"name\":\"Zhefeng Ge\"},{\"authorId\":\"1509070823\",\"name\":\"Rujia Shen\"},{\"authorId\":\"1388648260\",\"name\":\"F. Jin\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"faddf17f65376da3002579fd5fe526041d8ad219\",\"title\":\"Deep-HOSeq: Deep Higher Order Sequence Fusion for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/faddf17f65376da3002579fd5fe526041d8ad219\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152285970\",\"name\":\"Pengwei Hu\"},{\"authorId\":\"1733076657\",\"name\":\"Chenhao Lin\"},{\"authorId\":\"1563539653\",\"name\":\"Hui Su\"},{\"authorId\":\"1708276569\",\"name\":\"Shaochun Li\"},{\"authorId\":\"1739342783\",\"name\":\"Xue Han\"},{\"authorId\":\"104755339\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1596817963\",\"name\":\"Jing Mei\"}],\"doi\":\"10.24963/ijcai.2020/760\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a21a4f64f584428c7bc442602b5e11d5e36d585e\",\"title\":\"BlueMemo: Depression Analysis through Twitter Posts\",\"url\":\"https://www.semanticscholar.org/paper/a21a4f64f584428c7bc442602b5e11d5e36d585e\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1911.00212\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.18653/v1/D19-1207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55f546209c01530a7717d4170aa24947c6b92775\",\"title\":\"Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/55f546209c01530a7717d4170aa24947c6b92775\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413404\",\"name\":\"H. Zhu\"},{\"authorId\":\"152764048\",\"name\":\"Zidong Wang\"},{\"authorId\":\"32060935\",\"name\":\"Y. Shi\"},{\"authorId\":\"51300273\",\"name\":\"Yingying Hua\"},{\"authorId\":\"120330496\",\"name\":\"Guoxia Xu\"},{\"authorId\":\"144718787\",\"name\":\"L. Deng\"}],\"doi\":\"10.1155/2020/8843186\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"e7dd2de584fa21ec83d06cacc649d889c7bfdf90\",\"title\":\"Multimodal Fusion Method Based on Self-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e7dd2de584fa21ec83d06cacc649d889c7bfdf90\",\"venue\":\"Wirel. Commun. Mob. Comput.\",\"year\":2020},{\"arxivId\":\"2001.10853\",\"authors\":[{\"authorId\":\"153857960\",\"name\":\"Z. Huang\"},{\"authorId\":\"1414569274\",\"name\":\"Chao Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"1410448986\",\"name\":\"Qibin Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b106718fbddc804773b6135b1915039945096be2\",\"title\":\"H-OWAN: Multi-distorted Image Restoration with Tensor 1x1 Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b106718fbddc804773b6135b1915039945096be2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651954\",\"name\":\"C. Li\"},{\"authorId\":\"3458345\",\"name\":\"Zhun Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2971da6c178e44ee9ce2024897fa4c46d639e8fa\",\"title\":\"Evolutionary Topology Search for Tensor Network Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/2971da6c178e44ee9ce2024897fa4c46d639e8fa\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986672\",\"name\":\"Yue Gu\"},{\"authorId\":\"10328689\",\"name\":\"Xinyu Lyu\"},{\"authorId\":\"46912587\",\"name\":\"W. Sun\"},{\"authorId\":\"8874345\",\"name\":\"W. Li\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"48569799\",\"name\":\"Xin-Yu Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1145/3343031.3351039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c60d8c4c8464bc41d894353f5c09e885df366fe\",\"title\":\"Mutual Correlation Attentive Factors in Dyadic Fusion Networks for Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c60d8c4c8464bc41d894353f5c09e885df366fe\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144008480\",\"name\":\"H. Pham\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":null,\"name\":\"Thomas Manzini\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdea10d1780c80eef301fdb3e3ddb107bff73bd7\",\"title\":\"Target Seq 2 Seq Forward Translation Forward Translation Backward Translation Backward Translation Sentiment Sentiment Prediction 1 23 4 5 Encoder RNN Decoder RNN Embedded Representation Prediction RNN\",\"url\":\"https://www.semanticscholar.org/paper/cdea10d1780c80eef301fdb3e3ddb107bff73bd7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144536644\",\"name\":\"Rui Sun\"},{\"authorId\":\"2562591\",\"name\":\"Xuezhi Cao\"},{\"authorId\":\"97541254\",\"name\":\"Y. Zhao\"},{\"authorId\":\"144143097\",\"name\":\"Jun-chen Wan\"},{\"authorId\":\"144078054\",\"name\":\"Kun Zhou\"},{\"authorId\":\"2642200\",\"name\":\"Fuzheng Zhang\"},{\"authorId\":\"38655501\",\"name\":\"Zhongyuan Wang\"},{\"authorId\":\"144297772\",\"name\":\"Kai Zheng\"}],\"doi\":\"10.1145/3340531.3411947\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b4c7e77006ef6dc65fc8caf90742b73c1972222\",\"title\":\"Multi-modal Knowledge Graphs for Recommender Systems\",\"url\":\"https://www.semanticscholar.org/paper/0b4c7e77006ef6dc65fc8caf90742b73c1972222\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710183\",\"name\":\"Ruohong Huan\"},{\"authorId\":\"1939561\",\"name\":\"J. Shu\"},{\"authorId\":\"51205403\",\"name\":\"Shenglin Bao\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"92007809\",\"name\":\"Peng Chen\"},{\"authorId\":\"151071476\",\"name\":\"Kaikai Chi\"}],\"doi\":\"10.1007/s11042-020-10030-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd1c74f932d0d34a3e5cf2c1a5fc0d8f95a7d600\",\"title\":\"Video multimodal emotion recognition based on Bi-GRU and attention fusion\",\"url\":\"https://www.semanticscholar.org/paper/bd1c74f932d0d34a3e5cf2c1a5fc0d8f95a7d600\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":null,\"name\":\"Ziyin Liu\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d42ce9562a28079bac5b78db584bbdb9eaceba32\",\"title\":\"Modeling Spatiotemporal Multimodal Language with Recurrent Multistage Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d42ce9562a28079bac5b78db584bbdb9eaceba32\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.04931\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3242969.3243019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"079673e3482cb00cdbc38c74ea77dd9c069fe320\",\"title\":\"Multimodal Local-Global Ranking Fusion for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/079673e3482cb00cdbc38c74ea77dd9c069fe320\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":\"2004.12081\",\"authors\":[{\"authorId\":\"49576759\",\"name\":\"Zhe Sun\"},{\"authorId\":\"153857960\",\"name\":\"Z. Huang\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2994226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8ae71ed6bab317e2d04af77b14c4a8e6cc806df\",\"title\":\"A Novel Multimodal Approach for Hybrid Brain\\u2013Computer Interface\",\"url\":\"https://www.semanticscholar.org/paper/d8ae71ed6bab317e2d04af77b14c4a8e6cc806df\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"47111898\",\"name\":\"Yijun Yu\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"}],\"doi\":\"10.1016/J.INFFUS.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"title\":\"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis\",\"url\":\"https://www.semanticscholar.org/paper/b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":\"1908.05787\",\"authors\":[{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"145731758\",\"name\":\"M. K. Hasan\"},{\"authorId\":\"122930584\",\"name\":\"A. Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"144619896\",\"name\":\"M. Hoque\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69f6defd48137f8e01ddac7b2f1c7ac804dfece1\",\"title\":\"M-BERT: Injecting Multimodal Information in the BERT Structure\",\"url\":\"https://www.semanticscholar.org/paper/69f6defd48137f8e01ddac7b2f1c7ac804dfece1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"119837541\",\"name\":\"Jian-Ming Wu\"},{\"authorId\":\"2000011573\",\"name\":\"Jinfa Huang\"},{\"authorId\":\"31229419\",\"name\":\"G. Hattori\"},{\"authorId\":\"2466117\",\"name\":\"Y. Takishima\"},{\"authorId\":\"2000114316\",\"name\":\"Shinya Wada\"},{\"authorId\":\"1809845071\",\"name\":\"Rui Kimura\"},{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"1610841750\",\"name\":\"Satoshi Kurihara\"}],\"doi\":\"10.1145/3382507.3418830\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1526a7ad07d90f1b53b63299bb1cb9c0ce01925\",\"title\":\"LDNN: Linguistic Knowledge Injectable Deep Neural Network for Group Cohesiveness Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e1526a7ad07d90f1b53b63299bb1cb9c0ce01925\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72464437\",\"name\":\"Wu Liang-qing\"},{\"authorId\":\"1409612775\",\"name\":\"Liu\"},{\"authorId\":\"94866450\",\"name\":\"Qiyuan\"},{\"authorId\":\"144322097\",\"name\":\"Z. Dong\"},{\"authorId\":\"1515133875\",\"name\":\"Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8d3430942a2d90bc2035acfb7e7ac8351e4e2303\",\"title\":\"Multimodal Emotion Recognition with Auxiliary Sentiment Information\",\"url\":\"https://www.semanticscholar.org/paper/8d3430942a2d90bc2035acfb7e7ac8351e4e2303\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"},{\"authorId\":\"2392839\",\"name\":\"H. Xu\"},{\"authorId\":\"37216441\",\"name\":\"K. Gao\"}],\"doi\":\"10.1145/3394171.3413690\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"773d51dbb619a167102f75d93f39582a67c24c82\",\"title\":\"CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/773d51dbb619a167102f75d93f39582a67c24c82\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.06022\",\"authors\":[{\"authorId\":\"51446139\",\"name\":\"Gaurav Sahu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80fa460e911a3b96ee568bee06074fe020da1940\",\"title\":\"Multimodal Speech Emotion Recognition and Ambiguity Resolution\",\"url\":\"https://www.semanticscholar.org/paper/80fa460e911a3b96ee568bee06074fe020da1940\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1016/j.inffus.2020.06.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"757782a0524d6d23f430d6d8f924c6212d6afeac\",\"title\":\"Foundations of Multimodal Co-learning\",\"url\":\"https://www.semanticscholar.org/paper/757782a0524d6d23f430d6d8f924c6212d6afeac\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":\"2009.04107\",\"authors\":[{\"authorId\":\"1932103679\",\"name\":\"Zexu Pan\"},{\"authorId\":\"2834542\",\"name\":\"Zhaojie Luo\"},{\"authorId\":\"2100162\",\"name\":\"J. Yang\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.21437/interspeech.2020-1653\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e762956621d3a3906b5891afa0f755e01ffcbde\",\"title\":\"Multi-modal Attention for Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e762956621d3a3906b5891afa0f755e01ffcbde\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993657377\",\"name\":\"Guangyao Shen\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"47892939\",\"name\":\"Hongzhi Li\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413909\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b141bea44da3e05a7e00241b37f0e28124157039\",\"title\":\"MEmoR: A Dataset for Multimodal Emotion Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b141bea44da3e05a7e00241b37f0e28124157039\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1502869569\",\"name\":\"Xia Li\"},{\"authorId\":\"51491781\",\"name\":\"Minping Chen\"}],\"doi\":\"10.1007/978-3-030-63031-7_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2bebbc1f4f0718ad10649ea4a84b69430ec36122\",\"title\":\"Multimodal Sentiment Analysis with Multi-perspective Fusion Network Focusing on Sense Attentive Language\",\"url\":\"https://www.semanticscholar.org/paper/2bebbc1f4f0718ad10649ea4a84b69430ec36122\",\"venue\":\"CNCL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91915492\",\"name\":\"Fan Yang\"},{\"authorId\":\"2602530\",\"name\":\"Xiaochang Peng\"},{\"authorId\":\"134007132\",\"name\":\"Gargi Ghosh\"},{\"authorId\":\"3078538\",\"name\":\"Reshef Shilon\"},{\"authorId\":\"46389865\",\"name\":\"Hao Ma\"},{\"authorId\":\"31449330\",\"name\":\"Eider Moore\"},{\"authorId\":\"15153074\",\"name\":\"Goran Predovi\\u0107\"}],\"doi\":\"10.18653/v1/W19-3502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee8ea1a02a7cea51ae9191e0c0dad7ab080741d8\",\"title\":\"Exploring Deep Multimodal Fusion of Text and Photo for Hate Speech Classification\",\"url\":\"https://www.semanticscholar.org/paper/ee8ea1a02a7cea51ae9191e0c0dad7ab080741d8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.09826\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1429197894\",\"name\":\"Chengfeng Mao\"},{\"authorId\":\"1429262863\",\"name\":\"Kelly Shi\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd88d0346e679d1388d7e0ef08f7f7e329f2d760\",\"title\":\"Factorized Multimodal Transformer for Multimodal Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/cd88d0346e679d1388d7e0ef08f7f7e329f2d760\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.13572\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"49264083\",\"name\":\"Jia-Xuan He\"},{\"authorId\":\"1742521984\",\"name\":\"Ying Zeng\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"title\":\"Analyzing Unaligned Multimodal Sequence via Graph Convolution and Graph Pooling Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145952554\",\"name\":\"Michael Chan\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2019.00901\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"title\":\"Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1678917\",\"name\":\"M. Melucci\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41f9c10ec3bdacda7273fec073a1c5c82d8a2cc7\",\"title\":\"Quantum-inspired Multimodal Representation\",\"url\":\"https://www.semanticscholar.org/paper/41f9c10ec3bdacda7273fec073a1c5c82d8a2cc7\",\"venue\":\"IIR\",\"year\":2019},{\"arxivId\":\"2008.10858\",\"authors\":[{\"authorId\":\"28958635\",\"name\":\"Saadullah Amin\"},{\"authorId\":\"3383477\",\"name\":\"Stalin Varanasi\"},{\"authorId\":\"151072380\",\"name\":\"K. Dunfield\"},{\"authorId\":\"71531491\",\"name\":\"G. Neumann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0126fce30b412d583f8e33714908dd09b86293d1\",\"title\":\"LowFER: Low-rank Bilinear Pooling for Link Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0126fce30b412d583f8e33714908dd09b86293d1\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733076657\",\"name\":\"Chenhao Lin\"},{\"authorId\":\"39765371\",\"name\":\"Pengwei Hu\"},{\"authorId\":\"145984785\",\"name\":\"H. Su\"},{\"authorId\":\"2980517\",\"name\":\"Shaochun Li\"},{\"authorId\":\"144562855\",\"name\":\"Jing Mei\"},{\"authorId\":\"145760827\",\"name\":\"J. Zhou\"},{\"authorId\":\"144801502\",\"name\":\"H. Leung\"}],\"doi\":\"10.1145/3372278.3391932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"78a0a3494c6b223263ca56551501be9fb1b69556\",\"title\":\"SenseMood: Depression Detection on Social Media\",\"url\":\"https://www.semanticscholar.org/paper/78a0a3494c6b223263ca56551501be9fb1b69556\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"50686521\",\"name\":\"A. Stefani\"},{\"authorId\":\"1922081704\",\"name\":\"Giovanni Toto\"},{\"authorId\":\"66396314\",\"name\":\"Emanuele Di Buccio\"},{\"authorId\":\"1678917\",\"name\":\"M. Melucci\"}],\"doi\":\"10.1109/MIPR49039.2020.00044\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d33cedd8df6d9b2b1f534d4fd51d90986387d07\",\"title\":\"Towards Multimodal Sentiment Analysis Inspired by the Quantum Theoretical Framework\",\"url\":\"https://www.semanticscholar.org/paper/4d33cedd8df6d9b2b1f534d4fd51d90986387d07\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"}],\"doi\":\"10.1109/TMM.2019.2925966\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0bb0d021383c8dbc5d9cc804ffd91b2f4f597cca\",\"title\":\"Locally Confined Modality Fusion Network With a Global Perspective for Multimodal Human Affective Computing\",\"url\":\"https://www.semanticscholar.org/paper/0bb0d021383c8dbc5d9cc804ffd91b2f4f597cca\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1811.12624\",\"authors\":[{\"authorId\":\"26418289\",\"name\":\"Elham J. Barezi\"},{\"authorId\":\"1389750954\",\"name\":\"Peyman Momeni\"},{\"authorId\":\"123653449\",\"name\":\"I. Wood\"},{\"authorId\":\"40539650\",\"name\":\"Pascale Fung\"}],\"doi\":\"10.18653/v1/W19-4331\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8337c7876194bf4cccdc670e10ff2a32d2452253\",\"title\":\"Modality-based Factorization for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/8337c7876194bf4cccdc670e10ff2a32d2452253\",\"venue\":\"RepL4NLP@ACL\",\"year\":2019},{\"arxivId\":\"2012.13449\",\"authors\":[{\"authorId\":\"1380229105\",\"name\":\"Abdul Rafey Aftab\"},{\"authorId\":\"2003418085\",\"name\":\"Michael von der Beeck\"},{\"authorId\":\"145506659\",\"name\":\"M. Feld\"}],\"doi\":\"10.1145/3382507.3418836\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"823297b6e769d13eec3fa508ea9daea210868629\",\"title\":\"You Have a Point There: Object Selection Inside an Automobile Using Gaze, Head Pose and Finger Pointing\",\"url\":\"https://www.semanticscholar.org/paper/823297b6e769d13eec3fa508ea9daea210868629\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31707321\",\"name\":\"Sushant Kafle\"},{\"authorId\":\"1695716\",\"name\":\"C. O. Alm\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"}],\"doi\":\"10.21437/interspeech.2019-1898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"587621e39b609ff75820faf832b0a11bd5e4c1ea\",\"title\":\"Fusion Strategy for Prosodic and Lexical Representations of Word Importance\",\"url\":\"https://www.semanticscholar.org/paper/587621e39b609ff75820faf832b0a11bd5e4c1ea\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2811183\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144792800\",\"name\":\"Qin Lv\"},{\"authorId\":\"25712008\",\"name\":\"Duanfeng Gao\"},{\"authorId\":\"51431472\",\"name\":\"S. Shen\"},{\"authorId\":\"1792688\",\"name\":\"Robert P. Dick\"},{\"authorId\":\"2200556\",\"name\":\"M. Hannigan\"},{\"authorId\":\"48873940\",\"name\":\"Q. Liu\"}],\"doi\":\"10.24963/ijcai.2019/603\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5795831fb5e6e368fa3a93e326ae9a5a1eab9a09\",\"title\":\"Multi-Group Encoder-Decoder Networks to Fuse Heterogeneous Data for Next-Day Air Quality Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5795831fb5e6e368fa3a93e326ae9a5a1eab9a09\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1904.06618\",\"authors\":[{\"authorId\":\"2811524\",\"name\":\"M. Hasan\"},{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2693593\",\"name\":\"Jianyuan Zhong\"},{\"authorId\":\"2497319\",\"name\":\"Md. Iftekhar Tanveer\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"144619896\",\"name\":\"M. Hoque\"}],\"doi\":\"10.18653/v1/D19-1211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"296e8ceeba6550d7ec9b9ee727e0c17420ebb926\",\"title\":\"UR-FUNNY: A Multimodal Language Dataset for Understanding Humor\",\"url\":\"https://www.semanticscholar.org/paper/296e8ceeba6550d7ec9b9ee727e0c17420ebb926\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51491781\",\"name\":\"Minping Chen\"},{\"authorId\":\"1502881409\",\"name\":\"Xia Li\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03fa50a1b62db4bc5d98bea6ca5bcc1a611af51a\",\"title\":\"SWAFN: Sentimental Words Aware Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/03fa50a1b62db4bc5d98bea6ca5bcc1a611af51a\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"1831541\",\"name\":\"Kamrul Hasan\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"252879b227f494df00d465602342f6c38effd27b\",\"title\":\"BERT Input Embedder Attention Gating Shifting Word Embedding Acoustic Embedding Visual Embedding Multimodal Shifting Gate\",\"url\":\"https://www.semanticscholar.org/paper/252879b227f494df00d465602342f6c38effd27b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.03821\",\"authors\":[{\"authorId\":\"51446139\",\"name\":\"Gaurav Sahu\"},{\"authorId\":\"1712417\",\"name\":\"Olga Vechtomova\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c2797c04f45f991fe518d78d59146f17d5789b4b\",\"title\":\"Dynamic Fusion for Multimodal Data\",\"url\":\"https://www.semanticscholar.org/paper/c2797c04f45f991fe518d78d59146f17d5789b4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12633486\",\"name\":\"G. Shen\"},{\"authorId\":\"2006853842\",\"name\":\"Riwei Lai\"},{\"authorId\":\"50986454\",\"name\":\"Rui Chen\"},{\"authorId\":\"2005954559\",\"name\":\"Yu Zhang\"},{\"authorId\":\"1988859364\",\"name\":\"Kejia Zhang\"},{\"authorId\":\"40344286\",\"name\":\"Q. Han\"},{\"authorId\":\"104006202\",\"name\":\"Hongtao Song\"}],\"doi\":\"10.21437/interspeech.2020-3131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1353331d71fec03fd11d8fdaee2435ca23f247\",\"title\":\"WISE: Word-Level Interaction-Based Multimodal Fusion for Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d1353331d71fec03fd11d8fdaee2435ca23f247\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2010.09290\",\"authors\":[{\"authorId\":\"46494316\",\"name\":\"Fangtao Li\"},{\"authorId\":\"47825136\",\"name\":\"Wenzhe Wang\"},{\"authorId\":\"1879512436\",\"name\":\"Zihe Liu\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"9745425\",\"name\":\"Chenghao Yan\"},{\"authorId\":\"121084731\",\"name\":\"B. Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbff734406b8bad624828bed8b41a5910c9d3137\",\"title\":\"Frame Aggregation and Multi-Modal Fusion Framework for Video-Based Person Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cbff734406b8bad624828bed8b41a5910c9d3137\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31707321\",\"name\":\"Sushant Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b571a9c1b1aa5323b2c90bde156ce9539674e7c4\",\"title\":\"Word Importance Modeling to Enhance Captions Generated by Automatic Speech Recognition for Deaf and Hard of Hearing Users\",\"url\":\"https://www.semanticscholar.org/paper/b571a9c1b1aa5323b2c90bde156ce9539674e7c4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.07848\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.1609/AAAI.V34I01.5347\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"title\":\"Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.06793\",\"authors\":[{\"authorId\":\"8283163\",\"name\":\"Xinwei Sun\"},{\"authorId\":\"152252625\",\"name\":\"Yilun Xu\"},{\"authorId\":\"152550893\",\"name\":\"Peng Cao\"},{\"authorId\":\"3374192\",\"name\":\"Yuqing Kong\"},{\"authorId\":\"1612968966\",\"name\":\"Lingjing Hu\"},{\"authorId\":\"2437353\",\"name\":\"Shanghang Zhang\"},{\"authorId\":null,\"name\":\"Yizhou Wang\"}],\"doi\":\"10.1007/978-3-030-58580-8_11\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3611f04c1861b6e956597d56afafdefc71c6af6a\",\"title\":\"TCGM: An Information-Theoretic Framework for Semi-Supervised Multi-Modality Learning\",\"url\":\"https://www.semanticscholar.org/paper/3611f04c1861b6e956597d56afafdefc71c6af6a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.03545\",\"authors\":[{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"}],\"doi\":\"10.1145/3394171.3413678\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c398f1283d0e594fe710d71e9627319291734b1d\",\"title\":\"MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c398f1283d0e594fe710d71e9627319291734b1d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144952644\",\"name\":\"D. Y. Choi\"},{\"authorId\":\"1687433\",\"name\":\"Deok-Hwan Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.1109/ACCESS.2020.3036877\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"29af086d2a9e80b5528c55e6e99c63364a7281e1\",\"title\":\"Multimodal Attention Network for Continuous-Time Emotion Recognition Using Video and EEG Signals\",\"url\":\"https://www.semanticscholar.org/paper/29af086d2a9e80b5528c55e6e99c63364a7281e1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000297927\",\"name\":\"Jianhua Yuan\"},{\"authorId\":\"48607376\",\"name\":\"Y. Wu\"},{\"authorId\":\"3399505\",\"name\":\"X. Lu\"},{\"authorId\":\"51325589\",\"name\":\"Yanyan Zhao\"},{\"authorId\":\"152277111\",\"name\":\"B. Qin\"},{\"authorId\":\"1570906914\",\"name\":\"Ting Liu\"}],\"doi\":\"10.1007/S11431-020-1634-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fb879ef0fb668f4994f561f2069ad72ca28afea\",\"title\":\"Recent advances in deep learning based sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/0fb879ef0fb668f4994f561f2069ad72ca28afea\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.09629\",\"authors\":[{\"authorId\":\"47653392\",\"name\":\"Wenliang Dai\"},{\"authorId\":\"152613855\",\"name\":\"Zihan Liu\"},{\"authorId\":\"1660855299\",\"name\":\"Tiezheng Yu\"},{\"authorId\":\"40539650\",\"name\":\"Pascale Fung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06d420c2c40f3d117634579f12885c0a00780085\",\"title\":\"Modality-Transferable Emotion Embeddings for Low-Resource Multimodal Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/06d420c2c40f3d117634579f12885c0a00780085\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3708935\",\"name\":\"M. Hou\"},{\"authorId\":\"48252119\",\"name\":\"Jia-jia Tang\"},{\"authorId\":\"1906161\",\"name\":\"Jianhai Zhang\"},{\"authorId\":\"50340424\",\"name\":\"Wanzeng Kong\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b939a2b7413020d24e991102c76b5e3d9b91798d\",\"title\":\"Deep Multimodal Multilinear Fusion with High-order Polynomial Pooling\",\"url\":\"https://www.semanticscholar.org/paper/b939a2b7413020d24e991102c76b5e3d9b91798d\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.35\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e18858ec06a487d119a73a8217be99ee37d10e5a\",\"title\":\"Dual Low-Rank Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/e18858ec06a487d119a73a8217be99ee37d10e5a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1812.07809\",\"authors\":[{\"authorId\":\"144008479\",\"name\":\"H. Pham\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2632776\",\"name\":\"Thomas Manzini\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":\"10.1609/aaai.v33i01.33016892\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d581e8fd6bb0c1eccb88084bf281beb4f94358c7\",\"title\":\"Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities\",\"url\":\"https://www.semanticscholar.org/paper/d581e8fd6bb0c1eccb88084bf281beb4f94358c7\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3455244\",\"name\":\"S. Verma\"},{\"authorId\":\"50096147\",\"name\":\"C. Wang\"},{\"authorId\":\"48324793\",\"name\":\"Liming Zhu\"},{\"authorId\":\"40474876\",\"name\":\"Wei Liu\"}],\"doi\":\"10.24963/ijcai.2019/503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c602aabadfc00440f74dad7a8ae36ffca4ac2fe2\",\"title\":\"DeepCU: Integrating both Common and Unique Latent Information for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c602aabadfc00440f74dad7a8ae36ffca4ac2fe2\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1811.09362\",\"authors\":[{\"authorId\":null,\"name\":\"Yansen Wang\"},{\"authorId\":null,\"name\":\"Ying Shen\"},{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1609/aaai.v33i01.33017216\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d9273f34a6418c0291dd63f89810896962289e2\",\"title\":\"Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/5d9273f34a6418c0291dd63f89810896962289e2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46294028\",\"name\":\"M. Lee\"},{\"authorId\":\"72657988\",\"name\":\"Dae Yu Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.3390/s20185184\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"99e5cbf00e3bf5e31b0d08980a059ed6310e4b21\",\"title\":\"Visual Scene-Aware Hybrid and Multi-Modal Feature Aggregation for Facial Expression Recognition \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/99e5cbf00e3bf5e31b0d08980a059ed6310e4b21\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.18653/v1/P19-1046\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"title\":\"Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing\",\"url\":\"https://www.semanticscholar.org/paper/9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2007.02038\",\"authors\":[{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"63788711785b1dcbe400af8c2332b8bc48bc42fc\",\"title\":\"Low Rank Fusion based Transformers for Multimodal Sequences\",\"url\":\"https://www.semanticscholar.org/paper/63788711785b1dcbe400af8c2332b8bc48bc42fc\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754430080\",\"name\":\"Wenmeng Yu\"},{\"authorId\":\"1491194464\",\"name\":\"Hua Xu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"46758765\",\"name\":\"Yilin Zhu\"},{\"authorId\":\"95952564\",\"name\":\"Y. Ma\"},{\"authorId\":\"1754148511\",\"name\":\"Jiele Wu\"},{\"authorId\":\"1657286768\",\"name\":\"Jiyun Zou\"},{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"}],\"doi\":\"10.18653/v1/2020.acl-main.343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fc85469f9ff785f24212a50c58b497de563ae3da\",\"title\":\"CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality\",\"url\":\"https://www.semanticscholar.org/paper/fc85469f9ff785f24212a50c58b497de563ae3da\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1808.03920\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"12907562\",\"name\":\"Liu Ziyin\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D18-1014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"title\":\"Multimodal Language Analysis with Recurrent Multistage Fusion\",\"url\":\"https://www.semanticscholar.org/paper/a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2004.14198\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"1384374825\",\"name\":\"Martin Q. Ma\"},{\"authorId\":\"72966973\",\"name\":\"Muqiao Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0657c56fb71a9ebd08bde17058a13869c31d936\",\"title\":\"Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e0657c56fb71a9ebd08bde17058a13869c31d936\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120828339\",\"name\":\"Binghua Li\"},{\"authorId\":\"1971112\",\"name\":\"Chaofeng Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"47359248\",\"name\":\"N. Zheng\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"}],\"doi\":\"10.1007/978-3-030-58586-0_26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"title\":\"TPFN: Applying Outer Product Along Time to Multimodal Sentiment Analysis Fusion on Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.02902\",\"authors\":[{\"authorId\":\"48707832\",\"name\":\"Zilong Wang\"},{\"authorId\":\"92582490\",\"name\":\"Zhaohong Wan\"},{\"authorId\":\"117908148\",\"name\":\"Xiao-jun Wan\"}],\"doi\":\"10.1145/3366423.3380000\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d73e219eaefebd4cc781cd6a12aa791202943365\",\"title\":\"TransModality: An End2End Fusion Method with Transformer for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d73e219eaefebd4cc781cd6a12aa791202943365\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"2007.03876\",\"authors\":[{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a05dd0c22f8b11e01c28d389695721658264fbc\",\"title\":\"Audio-Visual Understanding of Passenger Intents for In-Cabin Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/3a05dd0c22f8b11e01c28d389695721658264fbc\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47739583\",\"name\":\"J. Chen\"},{\"authorId\":\"92994851\",\"name\":\"Aidong Zhang\"}],\"doi\":\"10.1145/3394486.3403182\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d24501a99d05306817171a744878315c31a880b\",\"title\":\"HGMF: Heterogeneous Graph-based Fusion for Multimodal Data with Incompleteness\",\"url\":\"https://www.semanticscholar.org/paper/5d24501a99d05306817171a744878315c31a880b\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":\"1911.05544\",\"authors\":[{\"authorId\":\"13223746\",\"name\":\"Zhongkai Sun\"},{\"authorId\":\"22603977\",\"name\":\"P. Sarma\"},{\"authorId\":\"1755618\",\"name\":\"W. Sethares\"},{\"authorId\":\"40609253\",\"name\":\"Yingyu Liang\"}],\"doi\":\"10.1609/aaai.v34i05.6431\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f2e7e083a3837573a4c456f468d90c5a54967d1\",\"title\":\"Learning Relationships between Text, Audio, and Video via Deep Canonical Correlation for Multimodal Language Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f2e7e083a3837573a4c456f468d90c5a54967d1\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2952472\",\"name\":\"Yansen Wang\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"90251e9c825e4592b4af8c60bd6f7c81b80dd02e\",\"title\":\"Can Shift : Dynamically Adjusting Word Representations Using Nonverbal Behaviours\",\"url\":\"https://www.semanticscholar.org/paper/90251e9c825e4592b4af8c60bd6f7c81b80dd02e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.06176\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"title\":\"Learning Factorized Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1907.01011\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2987266\",\"name\":\"Zhun Liu\"},{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P19-1152\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"93deae7cfaba34066afa05a2b05162891b13e769\",\"title\":\"Learning Representations from Imperfect Time Series Data via Tensor Rank Regularization\",\"url\":\"https://www.semanticscholar.org/paper/93deae7cfaba34066afa05a2b05162891b13e769\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2011.06102\",\"authors\":[{\"authorId\":\"30151156\",\"name\":\"A. A. Ismail\"},{\"authorId\":\"49745735\",\"name\":\"M. Hasan\"},{\"authorId\":\"2840277\",\"name\":\"F. Ishtiaq\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83f57d064dff8e508fdc5ef3aae485f34c1e80a2\",\"title\":\"Improving Multimodal Accuracy Through Modality Pre-training and Attention\",\"url\":\"https://www.semanticscholar.org/paper/83f57d064dff8e508fdc5ef3aae485f34c1e80a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"2003432444\",\"name\":\"Dimitrios Gkoumas\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1830455439\",\"name\":\"Massimo Melucci\"}],\"doi\":\"10.1016/j.inffus.2020.08.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"title\":\"Quantum-inspired multimodal fusion for video sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"venue\":\"Inf. Fusion\",\"year\":2021}],\"corpusId\":44131945,\"doi\":\"10.18653/v1/P18-1209\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":22,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"85653b72209fbf6cb0b9d4f5da2be4d35678ec73\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/s11263-007-0053-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b6803b2b7a16a32616366d54882f59c6f83ddeb\",\"title\":\"A Tensor Approximation Approach to\\u00a0Dimensionality Reduction\",\"url\":\"https://www.semanticscholar.org/paper/4b6803b2b7a16a32616366d54882f59c6f83ddeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2007},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2016.94\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efe353682061e0f929e8c916b64b84ff88297e47\",\"title\":\"Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages\",\"url\":\"https://www.semanticscholar.org/paper/efe353682061e0f929e8c916b64b84ff88297e47\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144238410\",\"name\":\"Qiang Zhu\"},{\"authorId\":\"39369497\",\"name\":\"Mei-Chen Yeh\"},{\"authorId\":\"143766349\",\"name\":\"K. Cheng\"},{\"authorId\":\"1815078\",\"name\":\"S. Avidan\"}],\"doi\":\"10.1109/CVPR.2006.119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05fe01b57b3ba58dc5029c068a48567b55018ea5\",\"title\":\"Fast Human Detection Using a Cascade of Histograms of Oriented Gradients\",\"url\":\"https://www.semanticscholar.org/paper/05fe01b57b3ba58dc5029c068a48567b55018ea5\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"2204726\",\"name\":\"I. Chaturvedi\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"145125161\",\"name\":\"Amir Hussain\"}],\"doi\":\"10.1109/ICDM.2016.0055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d21cc2677e544b46673ff19ad4f378f32129069\",\"title\":\"Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0d21cc2677e544b46673ff19ad4f378f32129069\",\"venue\":\"2016 IEEE 16th International Conference on Data Mining (ICDM)\",\"year\":2016},{\"arxivId\":\"1707.07250\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D17-1115\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"title\":\"Tensor Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33366691\",\"name\":\"Jiahong Yuan\"},{\"authorId\":\"144173823\",\"name\":\"M. Liberman\"}],\"doi\":\"10.1121/1.2935783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"title\":\"Speaker identification on the SCOTUS corpus\",\"url\":\"https://www.semanticscholar.org/paper/5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"1740602\",\"name\":\"F. Weninger\"},{\"authorId\":\"2024155\",\"name\":\"T. Knaup\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"2854241\",\"name\":\"C. Sun\"},{\"authorId\":\"1757166\",\"name\":\"Kenji Sagae\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2013.34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"title\":\"YouTube Movie Reviews: Sentiment Analysis in an Audio-Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"19131845\",\"name\":\"Payal Doshi\"}],\"doi\":\"10.1145/2070481.2070509\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"title\":\"Towards multimodal sentiment analysis: harvesting opinions from the web\",\"url\":\"https://www.semanticscholar.org/paper/0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"venue\":\"ICMI '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38819702\",\"name\":\"Guosheng Hu\"},{\"authorId\":\"145749529\",\"name\":\"Y. Hua\"},{\"authorId\":\"145155439\",\"name\":\"Y. Yuan\"},{\"authorId\":\"47295137\",\"name\":\"Z. Zhang\"},{\"authorId\":\"87669820\",\"name\":\"Zheng Lu\"},{\"authorId\":\"39162236\",\"name\":\"S. Mukherjee\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"143752764\",\"name\":\"N. Robertson\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"}],\"doi\":\"10.1109/ICCV.2017.404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be6d3f0fb0dbef722c5d0af79c371d52659d78cc\",\"title\":\"Attribute-Enhanced Face Recognition with Neural Tensor Fusion Networks\",\"url\":\"https://www.semanticscholar.org/paper/be6d3f0fb0dbef722c5d0af79c371d52659d78cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1802.00923\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"8365766\",\"name\":\"Prateek Vij\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"90f3bd3141026e3a15358149e7de42a3c7ed7f31\",\"title\":\"Multi-attention Recurrent Network for Human Communication Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/90f3bd3141026e3a15358149e7de42a3c7ed7f31\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396239754\",\"name\":\"Ver\\u00f3nica P\\u00e9rez-Rosas\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b73b8aa885d972a1f5fafc87208d2f8baa9f83c4\",\"title\":\"Utterance-Level Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b73b8aa885d972a1f5fafc87208d2f8baa9f83c4\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"3468264\",\"name\":\"Aaksha Meghawat\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c9648656af140d5b412011de8420f39d3dec3c48\",\"title\":\"Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c9648656af140d5b412011de8420f39d3dec3c48\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.06259\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"title\":\"MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis in Online Opinion Videos\",\"url\":\"https://www.semanticscholar.org/paper/1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1802.00927\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"37052144\",\"name\":\"N. Mazumder\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"609512f19e06bf393cb79fbf57183f75b8d889d2\",\"title\":\"Memory Fusion Network for Multi-view Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/609512f19e06bf393cb79fbf57183f75b8d889d2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5481020\",\"name\":\"Sunghyun Park\"},{\"authorId\":\"1927440\",\"name\":\"Han Suk Shim\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"1757166\",\"name\":\"Kenji Sagae\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/2663204.2663260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6eeb620e1487e4bf30ac0117dcc8261102fdc065\",\"title\":\"Computational Analysis of Persuasiveness in Social Multimedia: A Novel Dataset and Multimodal Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/6eeb620e1487e4bf30ac0117dcc8261102fdc065\",\"venue\":\"ICMI\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31669599\",\"name\":\"L. S. Chen\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"},{\"authorId\":\"2407080\",\"name\":\"T. Miyasato\"},{\"authorId\":\"2458123\",\"name\":\"R. Nakatsu\"}],\"doi\":\"10.1109/AFGR.1998.670976\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b388c66af4cf854beffaffbf43abce123a557d4\",\"title\":\"Multimodal human emotion/expression recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b388c66af4cf854beffaffbf43abce123a557d4\",\"venue\":\"Proceedings Third IEEE International Conference on Automatic Face and Gesture Recognition\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2591941\",\"name\":\"Shyam Sundar Rajagopalan\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1007/978-3-319-46478-7_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88e350a82fc6a30a33f231666455d5076f6c3731\",\"title\":\"Extending Long Short-Term Memory for Multi-View Structured Learning\",\"url\":\"https://www.semanticscholar.org/paper/88e350a82fc6a30a33f231666455d5076f6c3731\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2111443\",\"name\":\"Ilya P. Razenshteyn\"},{\"authorId\":\"143825455\",\"name\":\"Z. Song\"},{\"authorId\":\"143982862\",\"name\":\"D. Woodruff\"}],\"doi\":\"10.1145/2897518.2897639\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c568ecbd28e1fe24f58d6566cc37d45e32fb25b9\",\"title\":\"Weighted low rank approximations with provable guarantees\",\"url\":\"https://www.semanticscholar.org/paper/c568ecbd28e1fe24f58d6566cc37d45e32fb25b9\",\"venue\":\"STOC\",\"year\":2016},{\"arxivId\":\"1802.00924\",\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3136755.3136801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"title\":\"Multimodal sentiment analysis with word-level fusion and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50681115\",\"name\":\"L. de Silva\"},{\"authorId\":\"69886001\",\"name\":\"T. Miyasato\"},{\"authorId\":\"2458123\",\"name\":\"R. Nakatsu\"}],\"doi\":\"10.1109/ICICS.1997.647126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbb29e3008cba2266a3a3e017fab60000878ab84\",\"title\":\"Facial emotion recognition using multi-modal information\",\"url\":\"https://www.semanticscholar.org/paper/cbb29e3008cba2266a3a3e017fab60000878ab84\",\"venue\":\"Proceedings of ICICS, 1997 International Conference on Information, Communications and Signal Processing. Theme: Trends in Information Systems Engineering and Wireless Multimedia Communications (Cat.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986267\",\"name\":\"Tao Lei\"},{\"authorId\":\"46272269\",\"name\":\"Yu Xin\"},{\"authorId\":\"1703465\",\"name\":\"Yuan Zhang\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"},{\"authorId\":\"35132120\",\"name\":\"T. Jaakkola\"}],\"doi\":\"10.3115/v1/P14-1130\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"def6e0a5d89de032ef0a3394846e1bb76c12164f\",\"title\":\"Low-Rank Tensors for Scoring Dependency Structures\",\"url\":\"https://www.semanticscholar.org/paper/def6e0a5d89de032ef0a3394846e1bb76c12164f\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119766650\",\"name\":\"B. P. Yuhas\"},{\"authorId\":\"120632614\",\"name\":\"M. Goldstein\"},{\"authorId\":\"123105870\",\"name\":\"T. J. Sejnowski\"}],\"doi\":\"10.1109/35.41402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8bc7b83a70f4e1854c23a950ed168cbc3f98fec\",\"title\":\"Integration of acoustic and visual speech signals using neural networks\",\"url\":\"https://www.semanticscholar.org/paper/f8bc7b83a70f4e1854c23a950ed168cbc3f98fec\",\"venue\":\"IEEE Communications Magazine\",\"year\":1989},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Corinna Cortes\"},{\"authorId\":null,\"name\":\"Vladimir Vapnik.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Supportvector networks\",\"url\":\"\",\"venue\":\"Machine learning 20(3):273\\u2013297.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2974242\",\"name\":\"Behnaz Nojavanasghari\"},{\"authorId\":\"20781644\",\"name\":\"Deepak Gopinath\"},{\"authorId\":\"3407381\",\"name\":\"J. Koushik\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/2993148.2993176\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aaa439c0a1094438b97ed251c968e15e37a47e45\",\"title\":\"Deep multimodal fusion for persuasiveness prediction\",\"url\":\"https://www.semanticscholar.org/paper/aaa439c0a1094438b97ed251c968e15e37a47e45\",\"venue\":\"ICMI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710212\",\"name\":\"O. Koch\"},{\"authorId\":\"2671621\",\"name\":\"C. Lubich\"}],\"doi\":\"10.1137/09076578X\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"082baa999d6a0ec289ac046325c0992396db16d3\",\"title\":\"Dynamical Tensor Approximation\",\"url\":\"https://www.semanticscholar.org/paper/082baa999d6a0ec289ac046325c0992396db16d3\",\"venue\":\"SIAM J. Matrix Anal. Appl.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhao Song\"},{\"authorId\":null,\"name\":\"David P Woodruff\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tending long short - term memory for multiview structured learning\",\"url\":\"\",\"venue\":\"European Conference on Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"38816202\",\"name\":\"M. Bulut\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"},{\"authorId\":\"1764265\",\"name\":\"A. Kazemzadeh\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"},{\"authorId\":\"48388640\",\"name\":\"S. Kim\"},{\"authorId\":\"2522842\",\"name\":\"J. N. Chang\"},{\"authorId\":\"1797399\",\"name\":\"S. Lee\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1007/s10579-008-9076-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5cf0d213f3253cd46673d955209f8463db73cc51\",\"title\":\"IEMOCAP: interactive emotional dyadic motion capture database\",\"url\":\"https://www.semanticscholar.org/paper/5cf0d213f3253cd46673d955209f8463db73cc51\",\"venue\":\"Lang. Resour. Evaluation\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1960326\",\"name\":\"G. Degottex\"},{\"authorId\":\"145676779\",\"name\":\"John Kane\"},{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"1749273\",\"name\":\"T. Raitio\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"}],\"doi\":\"10.1109/ICASSP.2014.6853739\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"title\":\"COVAREP \\u2014 A collaborative voice analysis repository for speech technologies\",\"url\":\"https://www.semanticscholar.org/paper/511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2159324\",\"name\":\"T. W\\u00f6rtwein\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"}],\"doi\":\"10.1109/ACII.2017.8273573\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f022fa9ae43261dcf853379016990cd0ba227684\",\"title\":\"What really matters \\u2014 An information gain analysis of questions and reactions in automated PTSD screenings\",\"url\":\"https://www.semanticscholar.org/paper/f022fa9ae43261dcf853379016990cd0ba227684\",\"venue\":\"2017 Seventh International Conference on Affective Computing and Intelligent Interaction (ACII)\",\"year\":2017},{\"arxivId\":\"1609.05244\",\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"3468264\",\"name\":\"Aaksha Meghawat\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICME.2017.8019301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e9958bb741c23fa4a15089864984e9e74826c4f\",\"title\":\"Select-additive learning: Improving generalization in multimodal sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/8e9958bb741c23fa4a15089864984e9e74826c4f\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017}],\"title\":\"Efficient Low-rank Multimodal Fusion with Modality-Specific Factors\",\"topics\":[{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Computational complexity theory\",\"topicId\":\"1133\",\"url\":\"https://www.semanticscholar.org/topic/1133\"},{\"topic\":\"Sentiment analysis\",\"topicId\":\"6011\",\"url\":\"https://www.semanticscholar.org/topic/6011\"},{\"topic\":\"Time complexity\",\"topicId\":\"3448\",\"url\":\"https://www.semanticscholar.org/topic/3448\"},{\"topic\":\"Lexical Markup Framework\",\"topicId\":\"181411\",\"url\":\"https://www.semanticscholar.org/topic/181411\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Emotion recognition\",\"topicId\":\"68560\",\"url\":\"https://www.semanticscholar.org/topic/68560\"},{\"topic\":\"Oracle Fusion Architecture\",\"topicId\":\"4475853\",\"url\":\"https://www.semanticscholar.org/topic/4475853\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Image fusion\",\"topicId\":\"41451\",\"url\":\"https://www.semanticscholar.org/topic/41451\"},{\"topic\":\"Tribe FloodNet\",\"topicId\":\"3586643\",\"url\":\"https://www.semanticscholar.org/topic/3586643\"}],\"url\":\"https://www.semanticscholar.org/paper/85653b72209fbf6cb0b9d4f5da2be4d35678ec73\",\"venue\":\"ACL\",\"year\":2018}\n"