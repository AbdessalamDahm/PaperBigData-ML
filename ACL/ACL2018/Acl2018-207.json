"{\"abstract\":\"Multimodal affective computing, learning to recognize and interpret human affect and subjective information from multiple data sources, is still challenging because:(i) it is hard to extract informative features to represent human affects from heterogeneous inputs; (ii) current fusion strategies only fuse different modalities at abstract levels, ignoring time-dependent interactions between modalities. Addressing such issues, we introduce a hierarchical multimodal architecture with attention and word-level fusion to classify utterance-level sentiment and emotion from text and audio data. Our introduced model outperforms state-of-the-art approaches on published datasets, and we demonstrate that our model's synchronized attention over modalities offers visual interpretability.\",\"arxivId\":\"1805.08660\",\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\",\"url\":\"https://www.semanticscholar.org/author/49986580\"},{\"authorId\":\"25113310\",\"name\":\"Kangning Yang\",\"url\":\"https://www.semanticscholar.org/author/25113310\"},{\"authorId\":\"4699701\",\"name\":\"S. Fu\",\"url\":\"https://www.semanticscholar.org/author/4699701\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\",\"url\":\"https://www.semanticscholar.org/author/1804228\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\",\"url\":\"https://www.semanticscholar.org/author/2252963\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\",\"url\":\"https://www.semanticscholar.org/author/144555425\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"51127875\",\"name\":\"Y. Cai\"},{\"authorId\":\"3331651\",\"name\":\"H. Cai\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"}],\"doi\":\"10.18653/v1/P19-1239\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4fdd17e212bedd5cb288bf756e44e5af07ebc86c\",\"title\":\"Multi-Modal Sarcasm Detection in Twitter with Hierarchical Fusion Model\",\"url\":\"https://www.semanticscholar.org/paper/4fdd17e212bedd5cb288bf756e44e5af07ebc86c\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"47111898\",\"name\":\"Yijun Yu\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"}],\"doi\":\"10.1016/J.INFFUS.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"title\":\"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis\",\"url\":\"https://www.semanticscholar.org/paper/b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30049047\",\"name\":\"Akshat Choube\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1145/3382507.3418891\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c59bf02668d6c3d6040ffd309279dd3c5f0dd3cf\",\"title\":\"Punchline Detection using Context-Aware Hierarchical Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/c59bf02668d6c3d6040ffd309279dd3c5f0dd3cf\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153165264\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"1758474\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1145/3343031.3350987\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9031a1e275567d44dd0313137963fe1c1ce61b2\",\"title\":\"Effective Sentiment-relevant Word Selection for Multi-modal Sentiment Analysis in Spoken Language\",\"url\":\"https://www.semanticscholar.org/paper/a9031a1e275567d44dd0313137963fe1c1ce61b2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1911.07848\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.1609/AAAI.V34I01.5347\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"title\":\"Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145390928\",\"name\":\"E. Chen\"},{\"authorId\":\"2095379\",\"name\":\"Zhiyun Lu\"},{\"authorId\":\"49507008\",\"name\":\"Hao Xu\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"49891071\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2104664\",\"name\":\"J. Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea3266caff07d07099b649bf75cc222752140a3e\",\"title\":\"A Large Scale Speech Sentiment Corpus\",\"url\":\"https://www.semanticscholar.org/paper/ea3266caff07d07099b649bf75cc222752140a3e\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423692028\",\"name\":\"Yue Gu\"},{\"authorId\":\"1423652462\",\"name\":\"Ruiyu Zhang\"},{\"authorId\":\"153564122\",\"name\":\"Xinwei Zhao\"},{\"authorId\":\"12393038\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"79902107\",\"name\":\"Jalal Abdulbaqi\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"},{\"authorId\":\"51060068\",\"name\":\"Megan Cheng\"},{\"authorId\":\"1945606\",\"name\":\"R. Burd\"}],\"doi\":\"10.1109/ICHI.2019.8904713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df88420f4d7b76db5afca4cb9893a03d3a5e4190\",\"title\":\"Multimodal Attention Network for Trauma Activity Recognition from Spoken Language and Environmental Sound\",\"url\":\"https://www.semanticscholar.org/paper/df88420f4d7b76db5afca4cb9893a03d3a5e4190\",\"venue\":\"2019 IEEE International Conference on Healthcare Informatics (ICHI)\",\"year\":2019},{\"arxivId\":\"1911.09762\",\"authors\":[{\"authorId\":\"2095379\",\"name\":\"Zhiyun Lu\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"49890871\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145039780\",\"name\":\"Chung-Cheng Chiu\"},{\"authorId\":\"2104664\",\"name\":\"J. Fan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9052937\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a021b4e5862d7bf1e93612e1c6740c6d7f9595e1\",\"title\":\"Speech Sentiment Analysis via Pre-Trained Features from End-to-End ASR Models\",\"url\":\"https://www.semanticscholar.org/paper/a021b4e5862d7bf1e93612e1c6740c6d7f9595e1\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1902.11245\",\"authors\":[{\"authorId\":\"3156707\",\"name\":\"Egor Lakomkin\"},{\"authorId\":\"3063709\",\"name\":\"M. Zamani\"},{\"authorId\":\"1798067\",\"name\":\"Cornelius Weber\"},{\"authorId\":\"2632932\",\"name\":\"Sven Magg\"},{\"authorId\":\"1736513\",\"name\":\"S. Wermter\"}],\"doi\":\"10.1109/ICRA.2019.8794468\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d877c95807744d53f5d1570175a501d61528d4d2\",\"title\":\"Incorporating End-to-End Speech Recognition Models for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d877c95807744d53f5d1570175a501d61528d4d2\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"3302978\",\"name\":\"Kaixiang Huang\"},{\"authorId\":\"4699701\",\"name\":\"S. Fu\"},{\"authorId\":\"25113310\",\"name\":\"Kangning Yang\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"3420273\",\"name\":\"Moliang Zhou\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1145/3240508.3240714\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd9a48437e23374d37eab9fe51976f3ef3f46ff1\",\"title\":\"Human Conversation Analysis Using Attentive Multimodal Networks with Hierarchical Encoder-Decoder\",\"url\":\"https://www.semanticscholar.org/paper/cd9a48437e23374d37eab9fe51976f3ef3f46ff1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2010.11985\",\"authors\":[{\"authorId\":\"46477844\",\"name\":\"Jianing Yang\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"1796308073\",\"name\":\"Ruitao Yi\"},{\"authorId\":\"4375156\",\"name\":\"Yuying Zhu\"},{\"authorId\":\"2003216617\",\"name\":\"Azaan Rehman\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"322aec7489a4749f24d8a741766f04046d5ee19c\",\"title\":\"MTGAT: Multimodal Temporal Graph Attention Networks for Unaligned Human Multimodal Language Sequences\",\"url\":\"https://www.semanticscholar.org/paper/322aec7489a4749f24d8a741766f04046d5ee19c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05515\",\"authors\":[{\"authorId\":\"47672355\",\"name\":\"Simin Wang\"},{\"authorId\":\"2633790\",\"name\":\"L. Huang\"},{\"authorId\":\"70668666\",\"name\":\"Jidong Ge\"},{\"authorId\":\"50615665\",\"name\":\"Tengfei Zhang\"},{\"authorId\":\"15295147\",\"name\":\"H. Feng\"},{\"authorId\":\"7755014\",\"name\":\"Ming Li\"},{\"authorId\":\"48212955\",\"name\":\"H. Zhang\"},{\"authorId\":\"145106110\",\"name\":\"Vincent Ng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5b9ed1e6d3cd2e51d155831cdfae39f2e0f4578\",\"title\":\"Synergy between Machine/Deep Learning and Software Engineering: How Far Are We?\",\"url\":\"https://www.semanticscholar.org/paper/b5b9ed1e6d3cd2e51d155831cdfae39f2e0f4578\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09362\",\"authors\":[{\"authorId\":null,\"name\":\"Yansen Wang\"},{\"authorId\":null,\"name\":\"Ying Shen\"},{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1609/aaai.v33i01.33017216\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d9273f34a6418c0291dd63f89810896962289e2\",\"title\":\"Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/5d9273f34a6418c0291dd63f89810896962289e2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153091253\",\"name\":\"Won Ik Cho\"},{\"authorId\":\"117620999\",\"name\":\"Jeong-Hwa Cho\"},{\"authorId\":\"3404042\",\"name\":\"Woo Hyun Kang\"},{\"authorId\":\"1687497\",\"name\":\"N. Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6288485396c1422906f3626c879fa41652c34211\",\"title\":\"Disambiguating Speech Intention via Audio-Text Co-attention Framework: A Case of Prosody-semantics Interface\",\"url\":\"https://www.semanticscholar.org/paper/6288485396c1422906f3626c879fa41652c34211\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.03501\",\"authors\":[{\"authorId\":\"3436466\",\"name\":\"Palash Goyal\"},{\"authorId\":\"144756035\",\"name\":\"Saurabh Sahu\"},{\"authorId\":\"46848045\",\"name\":\"S. Ghosh\"},{\"authorId\":\"117523938\",\"name\":\"C. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0b9fad2013d5ef8f4f64ce3e99f9b355f87a83c\",\"title\":\"Cross-modal Learning for Multi-modal Video Categorization\",\"url\":\"https://www.semanticscholar.org/paper/f0b9fad2013d5ef8f4f64ce3e99f9b355f87a83c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.06102\",\"authors\":[{\"authorId\":\"30151156\",\"name\":\"A. A. Ismail\"},{\"authorId\":\"49745735\",\"name\":\"M. Hasan\"},{\"authorId\":\"2840277\",\"name\":\"F. Ishtiaq\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"83f57d064dff8e508fdc5ef3aae485f34c1e80a2\",\"title\":\"Improving Multimodal Accuracy Through Modality Pre-training and Attention\",\"url\":\"https://www.semanticscholar.org/paper/83f57d064dff8e508fdc5ef3aae485f34c1e80a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.02598\",\"authors\":[{\"authorId\":\"1557401586\",\"name\":\"Jingjun Liang\"},{\"authorId\":\"83895120\",\"name\":\"Ruichen Li\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413579\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0e5cc1e564501de32de97845c7405626781a413\",\"title\":\"Semi-supervised Multi-modal Emotion Recognition with Cross-Modal Distribution Matching\",\"url\":\"https://www.semanticscholar.org/paper/d0e5cc1e564501de32de97845c7405626781a413\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.18653/v1/P19-1046\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"title\":\"Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing\",\"url\":\"https://www.semanticscholar.org/paper/9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115819790\",\"name\":\"Eesung Kim\"},{\"authorId\":\"1782564\",\"name\":\"J. Shin\"}],\"doi\":\"10.1109/ICASSP.2019.8683077\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f1ff248320cce14c4297c366154c80e93fa345b0\",\"title\":\"DNN-based Emotion Recognition Based on Bottleneck Acoustic Features and Lexical Features\",\"url\":\"https://www.semanticscholar.org/paper/f1ff248320cce14c4297c366154c80e93fa345b0\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144893131\",\"name\":\"W. Jiang\"},{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"145137550\",\"name\":\"J. Jin\"},{\"authorId\":\"50017274\",\"name\":\"X. Han\"},{\"authorId\":\"49673331\",\"name\":\"C. Li\"}],\"doi\":\"10.3390/s19122730\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bdbf9c6546ca36ba33e78c162473c263e26e2580\",\"title\":\"Speech Emotion Recognition with Heterogeneous Feature Unification of Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/bdbf9c6546ca36ba33e78c162473c263e26e2580\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\"}],\"doi\":\"10.1109/TMM.2019.2925966\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0bb0d021383c8dbc5d9cc804ffd91b2f4f597cca\",\"title\":\"Locally Confined Modality Fusion Network With a Global Perspective for Multimodal Human Affective Computing\",\"url\":\"https://www.semanticscholar.org/paper/0bb0d021383c8dbc5d9cc804ffd91b2f4f597cca\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49356710\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"1758474\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2969205\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cebf78b820798e8fd5dca2a94cd888b953274b1\",\"title\":\"Multi-Modal Sentiment Classification With Independent and Interactive Knowledge via Semi-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/0cebf78b820798e8fd5dca2a94cd888b953274b1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1907.01011\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2987266\",\"name\":\"Zhun Liu\"},{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P19-1152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93deae7cfaba34066afa05a2b05162891b13e769\",\"title\":\"Learning Representations from Imperfect Time Series Data via Tensor Rank Regularization\",\"url\":\"https://www.semanticscholar.org/paper/93deae7cfaba34066afa05a2b05162891b13e769\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993562639\",\"name\":\"Saurabh Sahu\"},{\"authorId\":\"3436466\",\"name\":\"Palash Goyal\"},{\"authorId\":\"46848045\",\"name\":\"S. Ghosh\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"}],\"doi\":\"10.1145/3394171.3413756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71d117718ebfd5dcde01ed844debc9d33d03e8c9\",\"title\":\"Cross-modal Non-linear Guided Attention and Temporal Coherence in Multi-modal Deep Video Models\",\"url\":\"https://www.semanticscholar.org/paper/71d117718ebfd5dcde01ed844debc9d33d03e8c9\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71107995\",\"name\":\"Dong Zhang\"},{\"authorId\":\"51183249\",\"name\":\"Liangqing Wu\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1109/ICME.2019.00130\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39688ac1d78baba35a3ecc8bb12df5d59952b998\",\"title\":\"Multi-Modal Language Analysis with Hierarchical Interaction-Level and Selection-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/39688ac1d78baba35a3ecc8bb12df5d59952b998\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50152261\",\"name\":\"S. Liu\"},{\"authorId\":\"98742588\",\"name\":\"J. Jiao\"},{\"authorId\":\"152254347\",\"name\":\"Ziping Zhao\"},{\"authorId\":\"87692675\",\"name\":\"Judith Dineley\"},{\"authorId\":\"1709997\",\"name\":\"Nicholas Cummins\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207374\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a45da769c4f3f26898631d3ad28e777ec5eec707\",\"title\":\"Hierarchical Component-attention Based Speaker Turn Embedding for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a45da769c4f3f26898631d3ad28e777ec5eec707\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"1722082\",\"name\":\"Man Lung Yiu\"},{\"authorId\":\"2361778\",\"name\":\"M. Toyoda\"},{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"47824688\",\"name\":\"Wei Wang\"},{\"authorId\":\"144585959\",\"name\":\"B. Cui\"}],\"doi\":\"10.1007/978-3-030-26072-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4b87cbb669dcc1a6e53a6508ce24de7cc34e9f69\",\"title\":\"Web and Big Data: Third International Joint Conference, APWeb-WAIM 2019, Chengdu, China, August 1\\u20133, 2019, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/4b87cbb669dcc1a6e53a6508ce24de7cc34e9f69\",\"venue\":\"APWeb/WAIM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13866918\",\"name\":\"X. Wang\"},{\"authorId\":\"49816509\",\"name\":\"Xiaowen Sun\"},{\"authorId\":\"1518331899\",\"name\":\"Tan Yang\"},{\"authorId\":\"30865675\",\"name\":\"Hongbo Wang\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff77ce37f8be50a7eb7ea7388f47d8e669d67beb\",\"title\":\"Building a Bridge: A Method for Image-Text Sarcasm Detection Without Pretraining on Image-Text Data\",\"url\":\"https://www.semanticscholar.org/paper/ff77ce37f8be50a7eb7ea7388f47d8e669d67beb\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71107995\",\"name\":\"Dong Zhang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.1109/ICME.2019.00131\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d28cbea30a4a9bf74f6ac57e805a72504e4ec56f\",\"title\":\"Modeling the Clause-Level Structure to Multimodal Sentiment Analysis via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d28cbea30a4a9bf74f6ac57e805a72504e4ec56f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2011.13572\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"49264083\",\"name\":\"Jia-Xuan He\"},{\"authorId\":\"1742521984\",\"name\":\"Ying Zeng\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"title\":\"Analyzing Unaligned Multimodal Sequence via Graph Convolution and Graph Pooling Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.00295\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"35836381\",\"name\":\"Shaojie Bai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.18653/v1/P19-1656\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"949fef650da4c41afe6049a183b504b3cc91f4bd\",\"title\":\"Multimodal Transformer for Unaligned Multimodal Language Sequences\",\"url\":\"https://www.semanticscholar.org/paper/949fef650da4c41afe6049a183b504b3cc91f4bd\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145905369\",\"name\":\"Jiaxin Chen\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"756f246b44b53d9d855a0cad4b165086dcb97a0c\",\"title\":\"Natural Language Processing and Attentional-Based Fusion Strategies for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/756f246b44b53d9d855a0cad4b165086dcb97a0c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.08067\",\"authors\":[{\"authorId\":\"8371554\",\"name\":\"Bishal Santra\"},{\"authorId\":\"2025145390\",\"name\":\"P. Anusha\"},{\"authorId\":\"145361874\",\"name\":\"P. Goyal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"868ff5f67089d4e129bd680c8d047d7098a26698\",\"title\":\"Hierarchical Transformer for Task Oriented Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/868ff5f67089d4e129bd680c8d047d7098a26698\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115819790\",\"name\":\"Eesung Kim\"},{\"authorId\":\"1679171695\",\"name\":\"Hyungchan Song\"},{\"authorId\":\"1782564\",\"name\":\"J. Shin\"}],\"doi\":\"10.3390/s20092614\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d0f96f00eb1bf2500d7583eccf4efc7d5a9a860\",\"title\":\"Affective Latent Representation of Acoustic and Lexical Features for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d0f96f00eb1bf2500d7583eccf4efc7d5a9a860\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2952472\",\"name\":\"Yansen Wang\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90251e9c825e4592b4af8c60bd6f7c81b80dd02e\",\"title\":\"Can Shift : Dynamically Adjusting Word Representations Using Nonverbal Behaviours\",\"url\":\"https://www.semanticscholar.org/paper/90251e9c825e4592b4af8c60bd6f7c81b80dd02e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1879113774\",\"name\":\"Sanghyun Seo\"},{\"authorId\":\"1410218214\",\"name\":\"Sanghyuck Na\"},{\"authorId\":\"35031423\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/ACCESS.2020.3006563\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea7d7ac239f2d7575a98439f245ebe3132199227\",\"title\":\"HMTL: Heterogeneous Modality Transfer Learning for Audio-Visual Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/ea7d7ac239f2d7575a98439f245ebe3132199227\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49603949\",\"name\":\"Efthymios Georgiou\"},{\"authorId\":\"1389411330\",\"name\":\"Charilaos Papaioannou\"},{\"authorId\":\"47426012\",\"name\":\"A. Potamianos\"}],\"doi\":\"10.21437/interspeech.2019-3243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9783154a3790a988b50c763af322b5086fc5ae8a\",\"title\":\"Deep Hierarchical Fusion with Application in Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9783154a3790a988b50c763af322b5086fc5ae8a\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986672\",\"name\":\"Yue Gu\"},{\"authorId\":\"10328689\",\"name\":\"Xinyu Lyu\"},{\"authorId\":\"46912587\",\"name\":\"W. Sun\"},{\"authorId\":\"8874345\",\"name\":\"W. Li\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"48569799\",\"name\":\"Xin-Yu Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1145/3343031.3351039\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c60d8c4c8464bc41d894353f5c09e885df366fe\",\"title\":\"Mutual Correlation Attentive Factors in Dyadic Fusion Networks for Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c60d8c4c8464bc41d894353f5c09e885df366fe\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143889734\",\"name\":\"Ziping Zhao\"},{\"authorId\":\"121153870\",\"name\":\"Zhongtian Bao\"},{\"authorId\":\"30512170\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"144206859\",\"name\":\"Jun Deng\"},{\"authorId\":\"49249279\",\"name\":\"Nicholas Cummins\"},{\"authorId\":\"2267401\",\"name\":\"Haishuai Wang\"},{\"authorId\":\"12077195\",\"name\":\"J. Tao\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1109/JSTSP.2019.2955012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01f9ad0c6db54f9bf0a25bc012690e420613a899\",\"title\":\"Automatic Assessment of Depression From Speech via a Hierarchical Attention Transfer Network and Attention Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/01f9ad0c6db54f9bf0a25bc012690e420613a899\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145305154\",\"name\":\"N. Hu\"},{\"authorId\":\"2026046\",\"name\":\"J. Zhou\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"}],\"doi\":\"10.1007/978-3-030-26072-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"688935380107255469f99b06836c2389d9da5fab\",\"title\":\"DeepDial: Passage Completion on Dialogs\",\"url\":\"https://www.semanticscholar.org/paper/688935380107255469f99b06836c2389d9da5fab\",\"venue\":\"APWeb/WAIM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143889734\",\"name\":\"Ziping Zhao\"},{\"authorId\":\"121153870\",\"name\":\"Zhongtian Bao\"},{\"authorId\":\"30512170\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"49249279\",\"name\":\"Nicholas Cummins\"},{\"authorId\":\"2267401\",\"name\":\"Haishuai Wang\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adbe442b83038c303d906753920b116783a02e1c\",\"title\":\"Hierarchical Attention Transfer Networks for Depression Assessment from Speech\",\"url\":\"https://www.semanticscholar.org/paper/adbe442b83038c303d906753920b116783a02e1c\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753517313\",\"name\":\"Kangning Yang\"},{\"authorId\":\"1753672461\",\"name\":\"Chaofan Wang\"},{\"authorId\":\"3455464\",\"name\":\"Zhanna Sarsenbayeva\"},{\"authorId\":\"2575168\",\"name\":\"B. Tag\"},{\"authorId\":\"1726630\",\"name\":\"Tilman Dingler\"},{\"authorId\":\"1753687973\",\"name\":\"Greg Wadley\"},{\"authorId\":\"121738580\",\"name\":\"Jorge Gon\\u00e7alves\"}],\"doi\":\"10.1007/s00371-020-01881-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f753cddfaf14e7d4489ccb9ef4a521d399290a63\",\"title\":\"Benchmarking commercial emotion detection systems using realistic distortions of facial image datasets\",\"url\":\"https://www.semanticscholar.org/paper/f753cddfaf14e7d4489ccb9ef4a521d399290a63\",\"venue\":\"The Visual Computer\",\"year\":2020}],\"corpusId\":46895984,\"doi\":\"10.18653/v1/P18-1207\",\"fieldsOfStudy\":[\"Computer Science\",\"Medicine\"],\"influentialCitationCount\":5,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"7a39763121077c5a67343f822e6617fe3013a124\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"40356508\",\"name\":\"Rajiv Bajpai\"},{\"authorId\":\"145125161\",\"name\":\"Amir Hussain\"}],\"doi\":\"10.1016/j.inffus.2017.02.003\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"778617c5029256eba82b58921e6a70804524fe6d\",\"title\":\"A review of affective computing: From unimodal analysis to multimodal fusion\",\"url\":\"https://www.semanticscholar.org/paper/778617c5029256eba82b58921e6a70804524fe6d\",\"venue\":\"Inf. Fusion\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393667185\",\"name\":\"O. Abdel-Hamid\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"1409704080\",\"name\":\"Hui Jiang\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"},{\"authorId\":\"145047294\",\"name\":\"Gerald Penn\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"}],\"doi\":\"10.1109/TASLP.2014.2339736\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86efe7769f2b8a0e15ca213ab09881e6705caeb0\",\"title\":\"Convolutional Neural Networks for Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/86efe7769f2b8a0e15ca213ab09881e6705caeb0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2014},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1802.08332\",\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1109/ICASSP.2018.8462440\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3394c3d8a84381f1d58970aa904bdb0a76e5fc9\",\"title\":\"Deep Mul Timodal Learning for Emotion Recognition in Spoken Language\",\"url\":\"https://www.semanticscholar.org/paper/a3394c3d8a84381f1d58970aa904bdb0a76e5fc9\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839621\",\"name\":\"A. Savran\"},{\"authorId\":\"2675653\",\"name\":\"Houwei Cao\"},{\"authorId\":\"2796773\",\"name\":\"M. Shah\"},{\"authorId\":\"3115414\",\"name\":\"A. Nenkova\"},{\"authorId\":\"145457626\",\"name\":\"R. Verma\"}],\"doi\":\"10.1145/2388676.2388781\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3aa34121d1182d04c17b460f403c3a7181a4db15\",\"title\":\"Combining video, audio and lexical indicators of affect in spontaneous conversation via particle filtering\",\"url\":\"https://www.semanticscholar.org/paper/3aa34121d1182d04c17b460f403c3a7181a4db15\",\"venue\":\"ICMI '12\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1081\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"title\":\"Context-Dependent Sentiment Analysis in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695589\",\"name\":\"Shiqing Zhang\"},{\"authorId\":\"48691414\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TCSVT.2017.2719043\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aeadade814902ddb9d7fd0e1d2d64a70f0e3ff9\",\"title\":\"Learning Affective Features With a Hybrid Deep Model for Audio\\u2013Visual Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6aeadade814902ddb9d7fd0e1d2d64a70f0e3ff9\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"1740602\",\"name\":\"F. Weninger\"},{\"authorId\":\"2024155\",\"name\":\"T. Knaup\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"2854241\",\"name\":\"C. Sun\"},{\"authorId\":\"1757166\",\"name\":\"Kenji Sagae\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2013.34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"title\":\"YouTube Movie Reviews: Sentiment Analysis in an Audio-Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2013},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"3468264\",\"name\":\"Aaksha Meghawat\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9648656af140d5b412011de8420f39d3dec3c48\",\"title\":\"Select-Additive Learning: Improving Cross-individual Generalization in Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c9648656af140d5b412011de8420f39d3dec3c48\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.06259\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"title\":\"MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis in Online Opinion Videos\",\"url\":\"https://www.semanticscholar.org/paper/1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1707.07250\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D17-1115\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"title\":\"Tensor Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"19131845\",\"name\":\"Payal Doshi\"}],\"doi\":\"10.1145/2070481.2070509\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"title\":\"Towards multimodal sentiment analysis: harvesting opinions from the web\",\"url\":\"https://www.semanticscholar.org/paper/0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"venue\":\"ICMI '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"8214376\",\"name\":\"J. Zhang\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1007/978-3-319-57351-9_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d06e0e139da1fb4b086fb633c72c40b0e7f9b9d\",\"title\":\"Speech Intention Classification with Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2d06e0e139da1fb4b086fb633c72c40b0e7f9b9d\",\"venue\":\"Canadian Conference on AI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"46651686\",\"name\":\"Chengxin Li\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"144792074\",\"name\":\"Huimin Wu\"}],\"doi\":\"10.1109/ICASSP.2015.7178872\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a3e279bd3bc7265ae661242e031bfff384e17b2\",\"title\":\"Speech emotion recognition with acoustic and lexical features\",\"url\":\"https://www.semanticscholar.org/paper/9a3e279bd3bc7265ae661242e031bfff384e17b2\",\"venue\":\"2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1960326\",\"name\":\"G. Degottex\"},{\"authorId\":\"145676779\",\"name\":\"John Kane\"},{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"1749273\",\"name\":\"T. Raitio\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"}],\"doi\":\"10.1109/ICASSP.2014.6853739\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"title\":\"COVAREP \\u2014 A collaborative voice analysis repository for speech technologies\",\"url\":\"https://www.semanticscholar.org/paper/511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"},{\"authorId\":\"143871289\",\"name\":\"S. Ananthakrishnan\"},{\"authorId\":\"1808737\",\"name\":\"S. Saleem\"},{\"authorId\":\"143815072\",\"name\":\"Rohit Kumar\"},{\"authorId\":\"36073757\",\"name\":\"Rohit Prasad\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"038ee4737a02bcb609926f036f922aa414df6b13\",\"title\":\"Ensemble of SVM trees for multimodal emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/038ee4737a02bcb609926f036f922aa414df6b13\",\"venue\":\"Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"1747784\",\"name\":\"Alexander Gelbukh\"}],\"doi\":\"10.18653/v1/D15-1303\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0fe86c7fe3028423fea2183ac1a8d5fa8d4a5948\",\"title\":\"Deep Convolutional Neural Network Textual Features and Multiple Kernel Learning for Utterance-level Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0fe86c7fe3028423fea2183ac1a8d5fa8d4a5948\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1609.05244\",\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"3468264\",\"name\":\"Aaksha Meghawat\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICME.2017.8019301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e9958bb741c23fa4a15089864984e9e74826c4f\",\"title\":\"Select-additive learning: Improving generalization in multimodal sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/8e9958bb741c23fa4a15089864984e9e74826c4f\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"38816202\",\"name\":\"M. Bulut\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"},{\"authorId\":\"1764265\",\"name\":\"A. Kazemzadeh\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"},{\"authorId\":\"48388640\",\"name\":\"S. Kim\"},{\"authorId\":\"2522842\",\"name\":\"J. N. Chang\"},{\"authorId\":\"1797399\",\"name\":\"S. Lee\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1007/s10579-008-9076-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cf0d213f3253cd46673d955209f8463db73cc51\",\"title\":\"IEMOCAP: interactive emotional dyadic motion capture database\",\"url\":\"https://www.semanticscholar.org/paper/5cf0d213f3253cd46673d955209f8463db73cc51\",\"venue\":\"Lang. Resour. Evaluation\",\"year\":2008},{\"arxivId\":\"1802.00924\",\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3136755.3136801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"title\":\"Multimodal sentiment analysis with word-level fusion and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Soujanya Poria\"},{\"authorId\":null,\"name\":\"Erik Cambria\"},{\"authorId\":null,\"name\":\"Devamanyu Hazarika\"},{\"authorId\":null,\"name\":\"Navonil Majumder\"},{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"2017b. Context-dependent sentiment\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751126\",\"name\":\"F. Eyben\"},{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1400943991\",\"name\":\"E. Douglas-Cowie\"},{\"authorId\":\"145635430\",\"name\":\"R. Cowie\"}],\"doi\":\"10.1007/s12193-009-0032-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"006333bd20866b1a1242aa198e78bd5cab35027e\",\"title\":\"On-line emotion recognition in a 3-D activation-valence-time continuum using acoustic and linguistic cues\",\"url\":\"https://www.semanticscholar.org/paper/006333bd20866b1a1242aa198e78bd5cab35027e\",\"venue\":\"Journal on Multimodal User Interfaces\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396239754\",\"name\":\"Ver\\u00f3nica P\\u00e9rez-Rosas\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2013.9\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"81f5aac7c3516928218c892e802d8ef7658c7b9a\",\"title\":\"Multimodal Sentiment Analysis of Spanish Online Videos\",\"url\":\"https://www.semanticscholar.org/paper/81f5aac7c3516928218c892e802d8ef7658c7b9a\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"2022168\",\"name\":\"Diyi Yang\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.18653/v1/N16-1174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"455afd748e8834ef521e4b67c7c056d3c33429e2\",\"title\":\"Hierarchical Attention Networks for Document Classification\",\"url\":\"https://www.semanticscholar.org/paper/455afd748e8834ef521e4b67c7c056d3c33429e2\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"2204726\",\"name\":\"I. Chaturvedi\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"145125161\",\"name\":\"Amir Hussain\"}],\"doi\":\"10.1109/ICDM.2016.0055\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0d21cc2677e544b46673ff19ad4f378f32129069\",\"title\":\"Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0d21cc2677e544b46673ff19ad4f378f32129069\",\"venue\":\"2016 IEEE 16th International Conference on Data Mining (ICDM)\",\"year\":2016},{\"arxivId\":\"1408.5882\",\"authors\":[{\"authorId\":\"38367242\",\"name\":\"Yoon Kim\"}],\"doi\":\"10.3115/v1/D14-1181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba\",\"title\":\"Convolutional Neural Networks for Sentence Classification\",\"url\":\"https://www.semanticscholar.org/paper/1f6ba0782862ec12a5ec6d7fb608523d55b0c6ba\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2779846\",\"name\":\"H. Sakoe\"},{\"authorId\":\"35805230\",\"name\":\"Seibi Chiba\"}],\"doi\":\"10.1109/TASSP.1978.1163055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18f355d7ef4aa9f82bf5c00f84e46714efa5fd77\",\"title\":\"Dynamic programming algorithm optimization for spoken word recognition\",\"url\":\"https://www.semanticscholar.org/paper/18f355d7ef4aa9f82bf5c00f84e46714efa5fd77\",\"venue\":\"\",\"year\":1978},{\"arxivId\":\"1706.00612\",\"authors\":[{\"authorId\":\"145789765\",\"name\":\"M. Neumann\"},{\"authorId\":\"4160376\",\"name\":\"Ngoc Thang Vu\"}],\"doi\":\"10.21437/INTERSPEECH.2017-917\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca7fb00692339f9704b4a5201604889994825a42\",\"title\":\"Attentive Convolutional Neural Network Based Speech Emotion Recognition: A Study on the Impact of Input Features, Signal Length, and Acted Speech\",\"url\":\"https://www.semanticscholar.org/paper/ca7fb00692339f9704b4a5201604889994825a42\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35051208\",\"name\":\"Che-Wei Huang\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.21437/Interspeech.2016-448\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bee98ab1db3635660076e067de24d073b3048d2\",\"title\":\"Attention Assisted Discovery of Sub-Utterance Structure in Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bee98ab1db3635660076e067de24d073b3048d2\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751126\",\"name\":\"F. Eyben\"},{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1145/1873951.1874246\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"438219194cedac00974ad28604b63a66e0b6f436\",\"title\":\"Opensmile: the munich versatile and fast open-source audio feature extractor\",\"url\":\"https://www.semanticscholar.org/paper/438219194cedac00974ad28604b63a66e0b6f436\",\"venue\":\"ACM Multimedia\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717646\",\"name\":\"Dino Seppi\"},{\"authorId\":\"1745089\",\"name\":\"A. Batliner\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1732747\",\"name\":\"S. Steidl\"},{\"authorId\":\"30169286\",\"name\":\"T. Vogt\"},{\"authorId\":\"6164138\",\"name\":\"J. Wagner\"},{\"authorId\":\"1713369\",\"name\":\"L. Devillers\"},{\"authorId\":\"1766081\",\"name\":\"L. Vidrascu\"},{\"authorId\":\"34858847\",\"name\":\"N. Amir\"},{\"authorId\":\"2116706\",\"name\":\"V. Aharonson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4343e2f4c750841ebeb87d2af1ef227617f04fb2\",\"title\":\"Patterns, prototypes, performance: classifying emotional user states\",\"url\":\"https://www.semanticscholar.org/paper/4343e2f4c750841ebeb87d2af1ef227617f04fb2\",\"venue\":\"INTERSPEECH\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2536431\",\"name\":\"Seyedmahdad Mirsamadi\"},{\"authorId\":\"47223178\",\"name\":\"E. Barsoum\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/ICASSP.2017.7952552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b44b751db2b6f6ef662f517e9a01e055c6e337a8\",\"title\":\"Automatic speech emotion recognition using recurrent neural networks with local attention\",\"url\":\"https://www.semanticscholar.org/paper/b44b751db2b6f6ef662f517e9a01e055c6e337a8\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737616\",\"name\":\"D. Litman\"},{\"authorId\":\"1403816980\",\"name\":\"Katherine Forbes-Riley\"}],\"doi\":\"10.3115/1218955.1219000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"059246573111c2cc10a1f59957cf72974e5f0af7\",\"title\":\"Predicting Student Emotions in Computer-Human Tutoring Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/059246573111c2cc10a1f59957cf72974e5f0af7\",\"venue\":\"ACL\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403816980\",\"name\":\"Katherine Forbes-Riley\"},{\"authorId\":\"1737616\",\"name\":\"D. Litman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03e526b7096f68b11453f95eaf35400d5ad625bc\",\"title\":\"Predicting Emotion in Spoken Dialogue from Multiple Knowledge Sources\",\"url\":\"https://www.semanticscholar.org/paper/03e526b7096f68b11453f95eaf35400d5ad625bc\",\"venue\":\"HLT-NAACL\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Rowan Zellers\"},{\"authorId\":null,\"name\":\"Eli Pincus\"},{\"authorId\":null,\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ten - sor fusion network for multimodal sentiment analy\",\"url\":\"\",\"venue\":\"\",\"year\":2017}],\"title\":\"Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment\",\"topics\":[{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Affective computing\",\"topicId\":\"280335\",\"url\":\"https://www.semanticscholar.org/topic/280335\"},{\"topic\":\"Word embedding\",\"topicId\":\"286696\",\"url\":\"https://www.semanticscholar.org/topic/286696\"},{\"topic\":\"Audio Media\",\"topicId\":\"14912\",\"url\":\"https://www.semanticscholar.org/topic/14912\"},{\"topic\":\"Attention deficit hyperactivity disorder\",\"topicId\":\"3786\",\"url\":\"https://www.semanticscholar.org/topic/3786\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"},{\"topic\":\"Genetic Heterogeneity\",\"topicId\":\"128186\",\"url\":\"https://www.semanticscholar.org/topic/128186\"},{\"topic\":\"Alignment\",\"topicId\":\"80376\",\"url\":\"https://www.semanticscholar.org/topic/80376\"},{\"topic\":\"Scientific Publication\",\"topicId\":\"347\",\"url\":\"https://www.semanticscholar.org/topic/347\"},{\"topic\":\"Fuse Device Component\",\"topicId\":\"9864893\",\"url\":\"https://www.semanticscholar.org/topic/9864893\"}],\"url\":\"https://www.semanticscholar.org/paper/7a39763121077c5a67343f822e6617fe3013a124\",\"venue\":\"ACL\",\"year\":2018}\n"