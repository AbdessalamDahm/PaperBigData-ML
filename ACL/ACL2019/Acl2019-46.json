"{\"abstract\":\"We propose a general strategy named \\u2018divide, conquer and combine\\u2019 for multimodal fusion. Instead of directly fusing features at holistic level, we conduct fusion hierarchically so that both local and global interactions are considered for a comprehensive interpretation of multimodal embeddings. In the \\u2018divide\\u2019 and \\u2018conquer\\u2019 stages, we conduct local fusion by exploring the interaction of a portion of the aligned feature vectors across various modalities lying within a sliding window, which ensures that each part of multimodal embeddings are explored sufficiently. On its basis, global fusion is conducted in the \\u2018combine\\u2019 stage to explore the interconnection across local interactions, via an Attentive Bi-directional Skip-connected LSTM that directly connects distant local interactions and integrates two levels of attention mechanism. In this way, local interactions can exchange information sufficiently and thus obtain an overall view of multimodal information. Our method achieves state-of-the-art performance on multimodal affective computing with higher efficiency.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\",\"url\":\"https://www.semanticscholar.org/author/150301735\"},{\"authorId\":\"145442620\",\"name\":\"Haifeng Hu\",\"url\":\"https://www.semanticscholar.org/author/145442620\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\",\"url\":\"https://www.semanticscholar.org/author/150311018\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":\"1911.07848\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.1609/AAAI.V34I01.5347\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"title\":\"Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.10916\",\"authors\":[{\"authorId\":\"90683745\",\"name\":\"K. Panchal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07c9e3c2481a074ed44b7967e49d2a7d75c6f06c\",\"title\":\"Hierachical Delta-Attention Method for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/07c9e3c2481a074ed44b7967e49d2a7d75c6f06c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"47111898\",\"name\":\"Yijun Yu\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"}],\"doi\":\"10.1016/J.INFFUS.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"title\":\"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis\",\"url\":\"https://www.semanticscholar.org/paper/b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51491781\",\"name\":\"Minping Chen\"},{\"authorId\":\"1502881409\",\"name\":\"Xia Li\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03fa50a1b62db4bc5d98bea6ca5bcc1a611af51a\",\"title\":\"SWAFN: Sentimental Words Aware Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/03fa50a1b62db4bc5d98bea6ca5bcc1a611af51a\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"2003432444\",\"name\":\"Dimitrios Gkoumas\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1830455439\",\"name\":\"Massimo Melucci\"}],\"doi\":\"10.1016/j.inffus.2020.08.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"title\":\"Quantum-inspired multimodal fusion for video sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":\"2011.13572\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"49264083\",\"name\":\"Jia-Xuan He\"},{\"authorId\":\"1742521984\",\"name\":\"Ying Zeng\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"title\":\"Analyzing Unaligned Multimodal Sequence via Graph Convolution and Graph Pooling Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120828339\",\"name\":\"Binghua Li\"},{\"authorId\":\"1971112\",\"name\":\"Chaofeng Li\"},{\"authorId\":\"144632157\",\"name\":\"Feng Duan\"},{\"authorId\":\"47359248\",\"name\":\"N. Zheng\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"}],\"doi\":\"10.1007/978-3-030-58586-0_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"title\":\"TPFN: Applying Outer Product Along Time to Multimodal Sentiment Analysis Fusion on Incomplete Data\",\"url\":\"https://www.semanticscholar.org/paper/21cf6ebac135770d97b71702c7eec2d3121cf11c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11226\",\"authors\":[{\"authorId\":\"2000786644\",\"name\":\"Alex Wilf\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75da325df1463c0d1d26b44ce5133c71ca0d75ae\",\"title\":\"Dynamic Layer Customization for Noise Robust Speech Emotion Recognition in Heterogeneous Condition Training\",\"url\":\"https://www.semanticscholar.org/paper/75da325df1463c0d1d26b44ce5133c71ca0d75ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1502869569\",\"name\":\"Xia Li\"},{\"authorId\":\"51491781\",\"name\":\"Minping Chen\"}],\"doi\":\"10.1007/978-3-030-63031-7_26\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2bebbc1f4f0718ad10649ea4a84b69430ec36122\",\"title\":\"Multimodal Sentiment Analysis with Multi-perspective Fusion Network Focusing on Sense Attentive Language\",\"url\":\"https://www.semanticscholar.org/paper/2bebbc1f4f0718ad10649ea4a84b69430ec36122\",\"venue\":\"CNCL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145036777\",\"name\":\"D. Chauhan\"},{\"authorId\":\"1754231407\",\"name\":\"R. DhanushS.\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/2020.acl-main.401\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"571c9d6d3404a59042ee08c85fd07f41eb213913\",\"title\":\"Sentiment and Emotion help Sarcasm? A Multi-task Learning Framework for Multi-Modal Sarcasm, Sentiment and Emotion Analysis\",\"url\":\"https://www.semanticscholar.org/paper/571c9d6d3404a59042ee08c85fd07f41eb213913\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1879113774\",\"name\":\"Sanghyun Seo\"},{\"authorId\":\"1410218214\",\"name\":\"Sanghyuck Na\"},{\"authorId\":\"35031423\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/ACCESS.2020.3006563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea7d7ac239f2d7575a98439f245ebe3132199227\",\"title\":\"HMTL: Heterogeneous Modality Transfer Learning for Audio-Visual Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/ea7d7ac239f2d7575a98439f245ebe3132199227\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2033736328\",\"name\":\"Dushyant Singh Chauhan\"},{\"authorId\":\"2033742567\",\"name\":\"Dhanush S R\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6cd5f380675fb43a0e9ae0935cdb30661cf9c04\",\"title\":\"All-in-One: A Deep Attentive Multi-task Learning Framework for Humour, Sarcasm, Offensive, Motivation, and Sentiment on Memes\",\"url\":\"https://www.semanticscholar.org/paper/b6cd5f380675fb43a0e9ae0935cdb30661cf9c04\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2001.05272\",\"authors\":[{\"authorId\":\"2785065\",\"name\":\"Zhenyu Xuan\"},{\"authorId\":\"1411361508\",\"name\":\"R. Bao\"},{\"authorId\":\"152353165\",\"name\":\"Chuyu Ma\"},{\"authorId\":\"145848676\",\"name\":\"Shengyi Jiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae5eaeedb6e36fed9ceea894d1d1aa79b5c69bd7\",\"title\":\"FGN: Fusion Glyph Network for Chinese Named Entity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae5eaeedb6e36fed9ceea894d1d1aa79b5c69bd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.03545\",\"authors\":[{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"}],\"doi\":\"10.1145/3394171.3413678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c398f1283d0e594fe710d71e9627319291734b1d\",\"title\":\"MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c398f1283d0e594fe710d71e9627319291734b1d\",\"venue\":\"ACM Multimedia\",\"year\":2020}],\"corpusId\":196208194,\"doi\":\"10.18653/v1/P19-1046\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1960326\",\"name\":\"G. Degottex\"},{\"authorId\":\"145676779\",\"name\":\"John Kane\"},{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"1749273\",\"name\":\"T. Raitio\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"}],\"doi\":\"10.1109/ICASSP.2014.6853739\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"title\":\"COVAREP \\u2014 A collaborative voice analysis repository for speech technologies\",\"url\":\"https://www.semanticscholar.org/paper/511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":\"1806.06176\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"title\":\"Learning Factorized Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"144809527\",\"name\":\"Roger Zimmermann\"}],\"doi\":\"10.18653/v1/N18-1193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b76ebad1e4577123db1128ba594dbecf2228b825\",\"title\":\"Conversational Memory Network for Emotion Recognition in Dyadic Dialogue Videos\",\"url\":\"https://www.semanticscholar.org/paper/b76ebad1e4577123db1128ba594dbecf2228b825\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1906.02125\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144529448\",\"name\":\"Yao Chong Lim\"},{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/N19-1267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7812022785cf5f3fa331d011df57a2ddce5ea082\",\"title\":\"Strong and Simple Baselines for Multimodal Utterance Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/7812022785cf5f3fa331d011df57a2ddce5ea082\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"title\":\"End-To-End Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1710.10197\",\"authors\":[{\"authorId\":\"50556355\",\"name\":\"Fei Tao\"},{\"authorId\":null,\"name\":\"Gang Liu\"}],\"doi\":\"10.1109/ICASSP.2018.8461750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba4627a8f2bb21d37e03b56ce96ca7828c1ce4e\",\"title\":\"Advanced LSTM: A Study About Better Time Dependency Modeling in Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ba4627a8f2bb21d37e03b56ce96ca7828c1ce4e\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1709.05769\",\"authors\":[{\"authorId\":\"50884736\",\"name\":\"L. Wu\"},{\"authorId\":\"46396571\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebe8408052d9bf05dc2007d01559dda6129840eb\",\"title\":\"Where to Focus: Deep Attention-based Spatially Recurrent Bilinear Networks for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ebe8408052d9bf05dc2007d01559dda6129840eb\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1806.06228\",\"authors\":[{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1747784\",\"name\":\"Alexander Gelbukh\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"}],\"doi\":\"10.1016/j.knosys.2018.07.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b5aef2894d3248fb5ecc955d50501f0aa276036\",\"title\":\"Multimodal Sentiment Analysis using Hierarchical Fusion with Context Modeling\",\"url\":\"https://www.semanticscholar.org/paper/0b5aef2894d3248fb5ecc955d50501f0aa276036\",\"venue\":\"Knowl. Based Syst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"8214376\",\"name\":\"J. Zhang\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1007/978-3-319-57351-9_30\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2d06e0e139da1fb4b086fb633c72c40b0e7f9b9d\",\"title\":\"Speech Intention Classification with Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2d06e0e139da1fb4b086fb633c72c40b0e7f9b9d\",\"venue\":\"Canadian Conference on AI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751126\",\"name\":\"F. Eyben\"},{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1145/1873951.1874246\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"438219194cedac00974ad28604b63a66e0b6f436\",\"title\":\"Opensmile: the munich versatile and fast open-source audio feature extractor\",\"url\":\"https://www.semanticscholar.org/paper/438219194cedac00974ad28604b63a66e0b6f436\",\"venue\":\"ACM Multimedia\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2812486\",\"name\":\"P. Simard\"},{\"authorId\":\"1688235\",\"name\":\"P. Frasconi\"}],\"doi\":\"10.1109/72.279181\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d0be39ee052d246ae99c082a565aba25b811be2d\",\"title\":\"Learning long-term dependencies with gradient descent is difficult\",\"url\":\"https://www.semanticscholar.org/paper/d0be39ee052d246ae99c082a565aba25b811be2d\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1081\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"title\":\"Context-Dependent Sentiment Analysis in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Minghai Chen\"},{\"authorId\":null,\"name\":\"Soujanya Poria\"},{\"authorId\":null,\"name\":\"Erik Cambria\"},{\"authorId\":null,\"name\":\"Louis Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Ten - sor fusion network for multimodal sentiment analy\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1709.03714\",\"authors\":[{\"authorId\":\"47075013\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3914ec003849befb1d5c4f26e9524400a58f837\",\"title\":\"RRA: Recurrent Residual Attention for Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/b3914ec003849befb1d5c4f26e9524400a58f837\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788202\",\"name\":\"M. Goudreau\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"},{\"authorId\":\"1752242\",\"name\":\"S. Chakradhar\"},{\"authorId\":\"20141813\",\"name\":\"Dong Chen\"}],\"doi\":\"10.1109/72.286928\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"160ad1b01973986944a5f9a17924711ee1861552\",\"title\":\"First-order versus second-order single-layer recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/160ad1b01973986944a5f9a17924711ee1861552\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"3302978\",\"name\":\"Kaixiang Huang\"},{\"authorId\":\"4699701\",\"name\":\"S. Fu\"},{\"authorId\":\"25113310\",\"name\":\"Kangning Yang\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"3420273\",\"name\":\"Moliang Zhou\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.1145/3240508.3240714\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cd9a48437e23374d37eab9fe51976f3ef3f46ff1\",\"title\":\"Human Conversation Analysis Using Attentive Multimodal Networks with Hierarchical Encoder-Decoder\",\"url\":\"https://www.semanticscholar.org/paper/cd9a48437e23374d37eab9fe51976f3ef3f46ff1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"19131845\",\"name\":\"Payal Doshi\"}],\"doi\":\"10.1145/2070481.2070509\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"title\":\"Towards multimodal sentiment analysis: harvesting opinions from the web\",\"url\":\"https://www.semanticscholar.org/paper/0cbeb3cce2947fec2f790b1a28fd182640251b4e\",\"venue\":\"ICMI '11\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502892\",\"name\":\"Viktor Rozgic\"},{\"authorId\":\"143871289\",\"name\":\"S. Ananthakrishnan\"},{\"authorId\":\"1808737\",\"name\":\"S. Saleem\"},{\"authorId\":\"143815072\",\"name\":\"Rohit Kumar\"},{\"authorId\":\"36073757\",\"name\":\"Rohit Prasad\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"038ee4737a02bcb609926f036f922aa414df6b13\",\"title\":\"Ensemble of SVM trees for multimodal emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/038ee4737a02bcb609926f036f922aa414df6b13\",\"venue\":\"Proceedings of The 2012 Asia Pacific Signal and Information Processing Association Annual Summit and Conference\",\"year\":2012},{\"arxivId\":\"1802.00924\",\"authors\":[{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"145745514\",\"name\":\"S. Wang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3136755.3136801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"title\":\"Multimodal sentiment analysis with word-level fusion and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/81980911e5d7c4776962c0f6ae3fe58b5ef07b80\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Paul Pu Liang\"},{\"authorId\":null,\"name\":\"Navonil Mazumder\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Soujanya Poria, Erik Cambria, and Louis Philippe Morency. 2018a. Memory fusion network for multiview sequential learning\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145321667\",\"name\":\"B. Liu\"},{\"authorId\":\"50081327\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/978-1-4614-3223-4_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"527f5f6a533fe9b126d650c000aa328bcf1471e1\",\"title\":\"A Survey of Opinion Mining and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/527f5f6a533fe9b126d650c000aa328bcf1471e1\",\"venue\":\"Mining Text Data\",\"year\":2012},{\"arxivId\":\"1609.05244\",\"authors\":[{\"authorId\":\"3669925\",\"name\":\"Haohan Wang\"},{\"authorId\":\"3468264\",\"name\":\"Aaksha Meghawat\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICME.2017.8019301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e9958bb741c23fa4a15089864984e9e74826c4f\",\"title\":\"Select-additive learning: Improving generalization in multimodal sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/8e9958bb741c23fa4a15089864984e9e74826c4f\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1808.03920\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"12907562\",\"name\":\"Liu Ziyin\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D18-1014\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"title\":\"Multimodal Language Analysis with Recurrent Multistage Fusion\",\"url\":\"https://www.semanticscholar.org/paper/a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1812.07809\",\"authors\":[{\"authorId\":\"144008479\",\"name\":\"H. Pham\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2632776\",\"name\":\"Thomas Manzini\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":\"10.1609/aaai.v33i01.33016892\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d581e8fd6bb0c1eccb88084bf281beb4f94358c7\",\"title\":\"Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities\",\"url\":\"https://www.semanticscholar.org/paper/d581e8fd6bb0c1eccb88084bf281beb4f94358c7\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1802.00927\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"37052144\",\"name\":\"N. Mazumder\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"609512f19e06bf393cb79fbf57183f75b8d889d2\",\"title\":\"Memory Fusion Network for Multi-view Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/609512f19e06bf393cb79fbf57183f75b8d889d2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Minghai Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Soujanya Poria, Erik Cambria, and Louis Philippe Morency\",\"url\":\"\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"2204726\",\"name\":\"I. Chaturvedi\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"145125161\",\"name\":\"Amir Hussain\"}],\"doi\":\"10.1109/ICDM.2016.0055\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0d21cc2677e544b46673ff19ad4f378f32129069\",\"title\":\"Convolutional MKL Based Multimodal Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0d21cc2677e544b46673ff19ad4f378f32129069\",\"venue\":\"2016 IEEE 16th International Conference on Data Mining (ICDM)\",\"year\":2016},{\"arxivId\":\"1805.08660\",\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"25113310\",\"name\":\"Kangning Yang\"},{\"authorId\":\"4699701\",\"name\":\"S. Fu\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.18653/v1/P18-1207\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a39763121077c5a67343f822e6617fe3013a124\",\"title\":\"Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment\",\"url\":\"https://www.semanticscholar.org/paper/7a39763121077c5a67343f822e6617fe3013a124\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2974242\",\"name\":\"Behnaz Nojavanasghari\"},{\"authorId\":\"20781644\",\"name\":\"Deepak Gopinath\"},{\"authorId\":\"3407381\",\"name\":\"J. Koushik\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/2993148.2993176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaa439c0a1094438b97ed251c968e15e37a47e45\",\"title\":\"Deep multimodal fusion for persuasiveness prediction\",\"url\":\"https://www.semanticscholar.org/paper/aaa439c0a1094438b97ed251c968e15e37a47e45\",\"venue\":\"ICMI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P18-1208\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"006fdeff6e1a81c404317ee4056d6cc72f9c0e50\",\"title\":\"Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph\",\"url\":\"https://www.semanticscholar.org/paper/006fdeff6e1a81c404317ee4056d6cc72f9c0e50\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Erik Cambria\"},{\"authorId\":null,\"name\":\"Amir Hussain.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Senticnet\",\"url\":\"\",\"venue\":\"Sentic Computing, pages 23\\u201371.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40622157\",\"name\":\"V. Patel\"},{\"authorId\":\"145670911\",\"name\":\"Gayatri Prabhu\"},{\"authorId\":\"4227000\",\"name\":\"Kiran Bhowmick\"}],\"doi\":\"10.5120/IJCA2015907218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43281079454b7bc47c5ab00f1ebcf00e3a36257c\",\"title\":\"A Survey of Opinion Mining and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/43281079454b7bc47c5ab00f1ebcf00e3a36257c\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"40356508\",\"name\":\"Rajiv Bajpai\"},{\"authorId\":\"145125161\",\"name\":\"Amir Hussain\"}],\"doi\":\"10.1016/j.inffus.2017.02.003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"778617c5029256eba82b58921e6a70804524fe6d\",\"title\":\"A review of affective computing: From unimodal analysis to multimodal fusion\",\"url\":\"https://www.semanticscholar.org/paper/778617c5029256eba82b58921e6a70804524fe6d\",\"venue\":\"Inf. Fusion\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7707551\",\"name\":\"Yiren Wang\"},{\"authorId\":\"144054173\",\"name\":\"Fei Tian\"}],\"doi\":\"10.18653/v1/D16-1093\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1f3198f2b49f8028cd1cdd2d685c144cd18cb9d\",\"title\":\"Recurrent Residual Learning for Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/b1f3198f2b49f8028cd1cdd2d685c144cd18cb9d\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1606.06259\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"title\":\"MOSI: Multimodal Corpus of Sentiment Intensity and Subjectivity Analysis in Online Opinion Videos\",\"url\":\"https://www.semanticscholar.org/paper/1389564ab24d4b63c921a1ed564e5410b5199f7d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681512\",\"name\":\"Chung-Hsien Wu\"},{\"authorId\":\"3332493\",\"name\":\"W. Liang\"}],\"doi\":\"10.1109/ACII.2015.7344613\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f65fb63f745ede5904a41d02335f2d56030bcab\",\"title\":\"Emotion Recognition of Affective Speech Based on Multiple Classifiers Using Acoustic-Prosodic Information and Semantic Labels\",\"url\":\"https://www.semanticscholar.org/paper/2f65fb63f745ede5904a41d02335f2d56030bcab\",\"venue\":\"IEEE Transactions on Affective Computing\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Soujanya Poria\"},{\"authorId\":null,\"name\":\"Iti Chaturvedi\"},{\"authorId\":null,\"name\":\"Erik Cambria\"},{\"authorId\":null,\"name\":\"Amir Hussain\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Convolutional mkl based\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1802.00923\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"8365766\",\"name\":\"Prateek Vij\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90f3bd3141026e3a15358149e7de42a3c7ed7f31\",\"title\":\"Multi-attention Recurrent Network for Human Communication Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/90f3bd3141026e3a15358149e7de42a3c7ed7f31\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33366691\",\"name\":\"Jiahong Yuan\"},{\"authorId\":\"144173823\",\"name\":\"M. Liberman\"}],\"doi\":\"10.1121/1.2935783\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"title\":\"Speaker identification on the SCOTUS corpus\",\"url\":\"https://www.semanticscholar.org/paper/5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"}],\"doi\":\"10.1007/978-0-85729-997-0_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0a21f94de312a0ff31657fd103d6b29db823caa\",\"title\":\"Facial Expression Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d0a21f94de312a0ff31657fd103d6b29db823caa\",\"venue\":\"Visual Analysis of Humans\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"}],\"doi\":\"10.1109/MIS.2016.31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d385f52c9ffbf4bb1d689406cebc5075f5ad4d6a\",\"title\":\"Affective Computing and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d385f52c9ffbf4bb1d689406cebc5075f5ad4d6a\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2016},{\"arxivId\":\"1807.03915\",\"authors\":[{\"authorId\":\"144008479\",\"name\":\"H. Pham\"},{\"authorId\":\"2632776\",\"name\":\"Thomas Manzini\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":\"10.18653/v1/W18-3308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d55bd57e64c8e48c61e4f1746a2c280d608a8d2\",\"title\":\"Seq2Seq2Sentiment: Multimodal Sequence to Sequence Models for Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/9d55bd57e64c8e48c61e4f1746a2c280d608a8d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1811.09362\",\"authors\":[{\"authorId\":null,\"name\":\"Yansen Wang\"},{\"authorId\":null,\"name\":\"Ying Shen\"},{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1609/aaai.v33i01.33017216\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5d9273f34a6418c0291dd63f89810896962289e2\",\"title\":\"Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/5d9273f34a6418c0291dd63f89810896962289e2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1383996606\",\"name\":\"Sidney K. D'Mello\"},{\"authorId\":\"2716110\",\"name\":\"J. K. Westlund\"}],\"doi\":\"10.1145/2682899\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00734497ceb0889f2f52cb9bb721f62a15799ebc\",\"title\":\"A Review and Meta-Analysis of Multimodal Affect Detection Systems\",\"url\":\"https://www.semanticscholar.org/paper/00734497ceb0889f2f52cb9bb721f62a15799ebc\",\"venue\":\"ACM Comput. Surv.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"38816202\",\"name\":\"M. Bulut\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"},{\"authorId\":\"1764265\",\"name\":\"A. Kazemzadeh\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"},{\"authorId\":\"48388640\",\"name\":\"S. Kim\"},{\"authorId\":\"2522842\",\"name\":\"J. N. Chang\"},{\"authorId\":\"1797399\",\"name\":\"S. Lee\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1007/s10579-008-9076-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cf0d213f3253cd46673d955209f8463db73cc51\",\"title\":\"IEMOCAP: interactive emotional dyadic motion capture database\",\"url\":\"https://www.semanticscholar.org/paper/5cf0d213f3253cd46673d955209f8463db73cc51\",\"venue\":\"Lang. Resour. Evaluation\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2591941\",\"name\":\"Shyam Sundar Rajagopalan\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1756344\",\"name\":\"T. Baltrusaitis\"},{\"authorId\":\"1717204\",\"name\":\"R. Goecke\"}],\"doi\":\"10.1007/978-3-319-46478-7_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88e350a82fc6a30a33f231666455d5076f6c3731\",\"title\":\"Extending Long Short-Term Memory for Multi-View Structured Learning\",\"url\":\"https://www.semanticscholar.org/paper/88e350a82fc6a30a33f231666455d5076f6c3731\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1806.00064\",\"authors\":[{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":null,\"name\":\"Ying Shen\"},{\"authorId\":\"50975207\",\"name\":\"Varun Bharadhwaj Lakshminarasimhan\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P18-1209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"85653b72209fbf6cb0b9d4f5da2be4d35678ec73\",\"title\":\"Efficient Low-rank Multimodal Fusion with Modality-Specific Factors\",\"url\":\"https://www.semanticscholar.org/paper/85653b72209fbf6cb0b9d4f5da2be4d35678ec73\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1707.07250\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D17-1115\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"title\":\"Tensor Fusion Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5a96f2bfa2deae2bc35b250251d5fbe82ef4932b\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2016.94\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"efe353682061e0f929e8c916b64b84ff88297e47\",\"title\":\"Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages\",\"url\":\"https://www.semanticscholar.org/paper/efe353682061e0f929e8c916b64b84ff88297e47\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/ICDM.2017.134\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86405b78521d6b27290d5bae069a952137035ad7\",\"title\":\"Multi-level Multiple Attentions for Contextual Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/86405b78521d6b27290d5bae069a952137035ad7\",\"venue\":\"2017 IEEE International Conference on Data Mining (ICDM)\",\"year\":2017},{\"arxivId\":\"1705.09406\",\"authors\":[{\"authorId\":\"11138090\",\"name\":\"Tadas Baltru\\u0161aitis\"},{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/TPAMI.2018.2798607\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"title\":\"Multimodal Machine Learning: A Survey and Taxonomy\",\"url\":\"https://www.semanticscholar.org/paper/6bc4b1376ec2812b6d752c4f6bc8d8fd0512db91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1811.11431\",\"authors\":[{\"authorId\":\"144839857\",\"name\":\"Sachin Mehta\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.1109/CVPR.2019.00941\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a0262328b74b6f59d3d85c0ad2606977af1a22a\",\"title\":\"ESPNetv2: A Light-Weight, Power Efficient, and General Purpose Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0a0262328b74b6f59d3d85c0ad2606977af1a22a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sachin Mehta\"},{\"authorId\":null,\"name\":\"Mohammad Rastegari\"},{\"authorId\":null,\"name\":\"Linda Shapiro\"},{\"authorId\":null,\"name\":\"Hannaneh Hajishirzi.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Espnetv2: A lightweight, power efficient, and general purpose convolutional neural network\",\"url\":\"\",\"venue\":\"IEEE Conference on Computer Vision and Pattern Recognition(CVPR).\",\"year\":2019},{\"arxivId\":\"1811.12624\",\"authors\":[{\"authorId\":\"26418289\",\"name\":\"Elham J. Barezi\"},{\"authorId\":\"1389750954\",\"name\":\"Peyman Momeni\"},{\"authorId\":\"123653449\",\"name\":\"I. Wood\"},{\"authorId\":\"40539650\",\"name\":\"Pascale Fung\"}],\"doi\":\"10.18653/v1/W19-4331\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8337c7876194bf4cccdc670e10ff2a32d2452253\",\"title\":\"Modality-based Factorization for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/8337c7876194bf4cccdc670e10ff2a32d2452253\",\"venue\":\"RepL4NLP@ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2103575\",\"name\":\"M. W\\u00f6llmer\"},{\"authorId\":\"1740602\",\"name\":\"F. Weninger\"},{\"authorId\":\"2024155\",\"name\":\"T. Knaup\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"2854241\",\"name\":\"C. Sun\"},{\"authorId\":\"1757166\",\"name\":\"Kenji Sagae\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2013.34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"title\":\"YouTube Movie Reviews: Sentiment Analysis in an Audio-Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/be32d87c03d8c49a2b48f88b9f3f17340e7c8e6f\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2013},{\"arxivId\":\"1809.04931\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1145/3242969.3243019\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"079673e3482cb00cdbc38c74ea77dd9c069fe320\",\"title\":\"Multimodal Local-Global Ranking Fusion for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/079673e3482cb00cdbc38c74ea77dd9c069fe320\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":\"1212.5701\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8729441d734782c3ed532a7d2d9611b438c0a09a\",\"title\":\"ADADELTA: An Adaptive Learning Rate Method\",\"url\":\"https://www.semanticscholar.org/paper/8729441d734782c3ed532a7d2d9611b438c0a09a\",\"venue\":\"ArXiv\",\"year\":2012}],\"title\":\"Divide, Conquer and Combine: Hierarchical Feature Fusion Network with Local and Global Perspectives for Multimodal Affective Computing\",\"topics\":[{\"topic\":\"Affective computing\",\"topicId\":\"280335\",\"url\":\"https://www.semanticscholar.org/topic/280335\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"}],\"url\":\"https://www.semanticscholar.org/paper/9e43330f452a3ce3a946464214f2c3865eb7c7e4\",\"venue\":\"ACL\",\"year\":2019}\n"