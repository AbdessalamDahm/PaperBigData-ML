"{\"abstract\":\"We present a novel conversational-context aware end-to-end speech recognizer based on a gated neural network that incorporates conversational-context/word/speech embeddings. Unlike conventional speech recognition models, our model learns longer conversational-context information that spans across sentences and is consequently better at recognizing long conversations. Specifically, we propose to use the text-based external word and/or sentence embeddings (i.e., fastText, BERT) within an end-to-end framework, yielding a significant improvement in word error rate with better conversational-context representation. We evaluated the models on the Switchboard conversational speech corpus and show that our model outperforms standard end-to-end speech recognition models.\",\"arxivId\":\"1906.11604\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\",\"url\":\"https://www.semanticscholar.org/author/2678842\"},{\"authorId\":\"35186886\",\"name\":\"Siddharth Dalmia\",\"url\":\"https://www.semanticscholar.org/author/35186886\"},{\"authorId\":\"48352267\",\"name\":\"Florian Metze\",\"url\":\"https://www.semanticscholar.org/author/48352267\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1907.10726\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"35186886\",\"name\":\"Siddharth Dalmia\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.21437/interspeech.2019-3173\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddf68a01ea4aec3c939ff4a027dc48c59a7b8f64\",\"title\":\"Cross-Attention End-to-End ASR for Two-Party Conversations\",\"url\":\"https://www.semanticscholar.org/paper/ddf68a01ea4aec3c939ff4a027dc48c59a7b8f64\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"2009.01008\",\"authors\":[{\"authorId\":\"122658356\",\"name\":\"G. Sun\"},{\"authorId\":\"94109318\",\"name\":\"C. Zhang\"},{\"authorId\":\"1716393\",\"name\":\"P. Woodland\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce5d694ef90232a377da911e14594065ee31f660\",\"title\":\"Cross-Utterance Language Models with Acoustic Error Sampling\",\"url\":\"https://www.semanticscholar.org/paper/ce5d694ef90232a377da911e14594065ee31f660\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11349\",\"authors\":[{\"authorId\":\"4523604\",\"name\":\"X. Chen\"},{\"authorId\":\"40266067\",\"name\":\"S. Parthasarathy\"},{\"authorId\":\"5249664\",\"name\":\"W. Gale\"},{\"authorId\":\"39513746\",\"name\":\"S. Chang\"},{\"authorId\":\"48262024\",\"name\":\"Michael Zeng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"286fe9492eb7cb12ff6c7118a8fd48b7e4840b22\",\"title\":\"LSTM-LM with Long-Term History for First-Pass Decoding in Conversational Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/286fe9492eb7cb12ff6c7118a8fd48b7e4840b22\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03822\",\"authors\":[{\"authorId\":\"1866674954\",\"name\":\"Hayato Futami\"},{\"authorId\":\"49276525\",\"name\":\"Hirofumi Inaguma\"},{\"authorId\":\"70472914\",\"name\":\"Sei Ueno\"},{\"authorId\":\"2226344\",\"name\":\"M. Mimura\"},{\"authorId\":\"144066631\",\"name\":\"S. Sakai\"},{\"authorId\":\"1717105\",\"name\":\"Tatsuya Kawahara\"}],\"doi\":\"10.21437/interspeech.2020-1179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a680b32d65ee1139f584391f050aa3246be6ebdf\",\"title\":\"Distilling the Knowledge of BERT for Sequence-to-Sequence ASR\",\"url\":\"https://www.semanticscholar.org/paper/a680b32d65ee1139f584391f050aa3246be6ebdf\",\"venue\":\"INTERSPEECH\",\"year\":2020}],\"corpusId\":195699400,\"doi\":\"10.18653/v1/P19-1107\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"efe4cae24065785c6727e815b941613b5d9ac0a0\",\"references\":[{\"arxivId\":\"1807.09597\",\"authors\":[{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/SLT.2018.8639664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92bfc33bd14d245b0ce5edfb58dd19dd8335d1ba\",\"title\":\"Acoustic-to-Word Recognition with Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/92bfc33bd14d245b0ce5edfb58dd19dd8335d1ba\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144974724\",\"name\":\"Tian Wang\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c5325c2b67bf88f2b846cf5a6df6c2e6362d75b\",\"title\":\"Larger-Context Language Modelling\",\"url\":\"https://www.semanticscholar.org/paper/6c5325c2b67bf88f2b846cf5a6df6c2e6362d75b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Armand Joulin\"},{\"authorId\":null,\"name\":\"Edouard Grave\"},{\"authorId\":null,\"name\":\"Piotr Bojanowski\"},{\"authorId\":null,\"name\":\"Matthijs Douze\"},{\"authorId\":null,\"name\":\"H\\u00e9rve J\\u00e9gou\"},{\"authorId\":null,\"name\":\"Tomas Mikolov.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fasttext\",\"url\":\"\",\"venue\":\"zip: Compressing text classification models. arXiv preprint arXiv:1612.03651.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"143913738\",\"name\":\"S. Fern\\u00e1ndez\"},{\"authorId\":\"145842938\",\"name\":\"F. Gomez\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1145/1143844.1143891\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96494e722f58705fa20302fe6179d483f52705b4\",\"title\":\"Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/96494e722f58705fa20302fe6179d483f52705b4\",\"venue\":\"ICML '06\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"119837982\",\"name\":\"Jeffrey Wu\"},{\"authorId\":\"48422824\",\"name\":\"R. Child\"},{\"authorId\":\"150970919\",\"name\":\"David Luan\"},{\"authorId\":\"2698777\",\"name\":\"Dario Amodei\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9405cc0d6169988371b2755e573cc28650d14dfe\",\"title\":\"Language Models are Unsupervised Multitask Learners\",\"url\":\"https://www.semanticscholar.org/paper/9405cc0d6169988371b2755e573cc28650d14dfe\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1506.07503\",\"authors\":[{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b624504240fa52ab76167acfe3156150ca01cf3b\",\"title\":\"Attention-Based Models for Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b624504240fa52ab76167acfe3156150ca01cf3b\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1703.07754\",\"authors\":[{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1720857\",\"name\":\"B. Ramabhadran\"},{\"authorId\":\"1698208\",\"name\":\"G. Saon\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"}],\"doi\":\"10.1109/ICASSP.2018.8461935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf0e9724e51b420bc51a1d0625410c86d36641db\",\"title\":\"Building Competitive Direct Acoustics-to-Word Models for English Conversational Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cf0e9724e51b420bc51a1d0625410c86d36641db\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34972608\",\"name\":\"J. J. Godfrey\"},{\"authorId\":\"2921734\",\"name\":\"E. Holliman\"},{\"authorId\":\"144344811\",\"name\":\"J. McDaniel\"}],\"doi\":\"10.1109/ICASSP.1992.225858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d80000d84223e177d070a01a734dba56d5f5c069\",\"title\":\"SWITCHBOARD: telephone speech corpus for research and development\",\"url\":\"https://www.semanticscholar.org/paper/d80000d84223e177d070a01a734dba56d5f5c069\",\"venue\":\"[Proceedings] ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech, and Signal Processing\",\"year\":1992},{\"arxivId\":\"1810.12170\",\"authors\":[{\"authorId\":\"47051926\",\"name\":\"Uri Alon\"},{\"authorId\":\"2779415\",\"name\":\"G. Pundak\"},{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"}],\"doi\":\"10.1109/ICASSP.2019.8682738\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efbc641eea0a1918cb102ebcab59a46f061b66dd\",\"title\":\"Contextual Speech Recognition with Difficult Negative Training Examples\",\"url\":\"https://www.semanticscholar.org/paper/efbc641eea0a1918cb102ebcab59a46f061b66dd\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1609.05935\",\"authors\":[{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"2395936\",\"name\":\"Chengzhu Yu\"},{\"authorId\":\"1755472\",\"name\":\"J. Droppo\"},{\"authorId\":\"1762744\",\"name\":\"A. Stolcke\"}],\"doi\":\"10.1109/ICASSP.2017.7953069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba950c7e734110c5284682fbd522eb6c71a561d7\",\"title\":\"Advances in all-neural speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba950c7e734110c5284682fbd522eb6c71a561d7\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.18653/v1/P18-1085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"title\":\"Illustrative Language Understanding: Large-Scale Visual Grounding with Image Search\",\"url\":\"https://www.semanticscholar.org/paper/35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suyoun Kim\"},{\"authorId\":null,\"name\":\"Florian Metze.\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Dialogcontext aware end-to-end speech recognition\",\"url\":\"\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT), pages 434\\u2013440. IEEE.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":null,\"name\":\"Jan Chorowski\"},{\"authorId\":null,\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":null,\"name\":\"Philemon Brakel\"},{\"authorId\":null,\"name\":\"Yoshua Bengio.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Endto-end attention-based large vocabulary speech recognition\",\"url\":\"\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2016},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1720857\",\"name\":\"B. Ramabhadran\"},{\"authorId\":\"1698208\",\"name\":\"G. Saon\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"1713978\",\"name\":\"D. Nahamoo\"}],\"doi\":\"10.21437/INTERSPEECH.2017-546\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f2c92c53cc5ad80bc929ff3b0ad746da0bb5f30\",\"title\":\"Direct Acoustics-to-Word Models for English Conversational Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1f2c92c53cc5ad80bc929ff3b0ad746da0bb5f30\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"1939851\",\"name\":\"Mohammad Gowayyed\"},{\"authorId\":\"2519438\",\"name\":\"X. Na\"},{\"authorId\":\"3023507\",\"name\":\"T. Ko\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.1109/ICASSP.2016.7472152\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d155d64bdd86edf33f4395c5aec0388ffed69f99\",\"title\":\"An empirical exploration of CTC acoustic models\",\"url\":\"https://www.semanticscholar.org/paper/d155d64bdd86edf33f4395c5aec0388ffed69f99\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1610.03022\",\"authors\":[{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":\"10.1109/ICASSP.2017.7953077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d838994020a794b857a4cd356bfbbf7b52da7473\",\"title\":\"Very deep convolutional networks for end-to-end speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/d838994020a794b857a4cd356bfbbf7b52da7473\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/SLT.2012.6424228\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d1275b2a2ab53013310e759e5c6878b96df643d4\",\"title\":\"Context dependent recurrent neural network language model\",\"url\":\"https://www.semanticscholar.org/paper/d1275b2a2ab53013310e759e5c6878b96df643d4\",\"venue\":\"2012 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2012},{\"arxivId\":\"1507.08240\",\"authors\":[{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"1939851\",\"name\":\"Mohammad Gowayyed\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/ASRU.2015.7404790\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97acdfb3d247f8250d865ef8a9169f06e40f138b\",\"title\":\"EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding\",\"url\":\"https://www.semanticscholar.org/paper/97acdfb3d247f8250d865ef8a9169f06e40f138b\",\"venue\":\"2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"2946873\",\"name\":\"Vijayaditya Peddinti\"},{\"authorId\":\"143943881\",\"name\":\"D. Galvez\"},{\"authorId\":\"2835722\",\"name\":\"Pegah Ghahremani\"},{\"authorId\":\"3316615\",\"name\":\"Vimal Manohar\"},{\"authorId\":\"2519438\",\"name\":\"X. Na\"},{\"authorId\":\"21595671\",\"name\":\"Y. Wang\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.21437/Interspeech.2016-595\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ce6a9a30cd69bd2842a4b581cf48c6815bdfdd8\",\"title\":\"Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI\",\"url\":\"https://www.semanticscholar.org/paper/6ce6a9a30cd69bd2842a4b581cf48c6815bdfdd8\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":\"1711.02207\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"1727524\",\"name\":\"Michael L. Seltzer\"}],\"doi\":\"10.1109/ICASSP.2018.8462201\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25542bf27df82bd75205f9df7960c6132e4293c8\",\"title\":\"Towards Language-Universal End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/25542bf27df82bd75205f9df7960c6132e4293c8\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"2245567\",\"name\":\"M. Karafi\\u00e1t\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"1899242\",\"name\":\"J. \\u010cernock\\u00fd\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9819b600a828a57e1cde047bbe710d3446b30da5\",\"title\":\"Recurrent neural network based language model\",\"url\":\"https://www.semanticscholar.org/paper/9819b600a828a57e1cde047bbe710d3446b30da5\",\"venue\":\"INTERSPEECH\",\"year\":2010},{\"arxivId\":\"1412.5567\",\"authors\":[{\"authorId\":\"2893056\",\"name\":\"Awni Y. Hannun\"},{\"authorId\":\"145353944\",\"name\":\"C. Case\"},{\"authorId\":\"48991386\",\"name\":\"J. Casper\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"2322582\",\"name\":\"Greg Diamos\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"3168041\",\"name\":\"Ryan Prenger\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"2264597\",\"name\":\"S. Sengupta\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24741d280869ad9c60321f5ab6e5f01b7852507d\",\"title\":\"Deep Speech: Scaling up end-to-end speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/24741d280869ad9c60321f5ab6e5f01b7852507d\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1611.01603\",\"authors\":[{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a7b63b50c64f4ec3358477790e84cbd6be2a0b4\",\"title\":\"Bidirectional Attention Flow for Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3a7b63b50c64f4ec3358477790e84cbd6be2a0b4\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407277\",\"name\":\"Adam Paszke\"},{\"authorId\":\"39793298\",\"name\":\"S. Gross\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"114250963\",\"name\":\"G. Chanan\"},{\"authorId\":\"50064334\",\"name\":\"E. Yang\"},{\"authorId\":\"81505016\",\"name\":\"Zachary Devito\"},{\"authorId\":\"3370429\",\"name\":\"Zeming Lin\"},{\"authorId\":\"3050846\",\"name\":\"Alban Desmaison\"},{\"authorId\":\"3029482\",\"name\":\"L. Antiga\"},{\"authorId\":\"1977806\",\"name\":\"A. Lerer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b36a5bb1707bb9c70025294b3a310138aae8327a\",\"title\":\"Automatic differentiation in PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/b36a5bb1707bb9c70025294b3a310138aae8327a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145814376\",\"name\":\"Wayne Xiong\"},{\"authorId\":\"49279472\",\"name\":\"Lingfeng Wu\"},{\"authorId\":\"47593117\",\"name\":\"J. Zhang\"},{\"authorId\":\"1762744\",\"name\":\"A. Stolcke\"}],\"doi\":\"10.18653/v1/D18-1296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7407b6fd730b498450257b4113ca698b17e5d0b5\",\"title\":\"Session-level Language Modeling for Conversational Speech\",\"url\":\"https://www.semanticscholar.org/paper/7407b6fd730b498450257b4113ca698b17e5d0b5\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1609.06773\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ICASSP.2017.7953075\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9af2264799bdc3490e4650e2f5d126762caf420f\",\"title\":\"Joint CTC-attention based end-to-end speech recognition using multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/9af2264799bdc3490e4650e2f5d126762caf420f\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1804.00015\",\"authors\":[{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"39678391\",\"name\":\"Shigeki Karita\"},{\"authorId\":\"3326124\",\"name\":\"T. Hayashi\"},{\"authorId\":\"40845491\",\"name\":\"Jiro Nishitoba\"},{\"authorId\":\"40939427\",\"name\":\"Y. Unno\"},{\"authorId\":\"41018203\",\"name\":\"Nelson Enrique Yalta Soplin\"},{\"authorId\":\"25006055\",\"name\":\"J. Heymann\"},{\"authorId\":\"9699077\",\"name\":\"Matthew Wiesner\"},{\"authorId\":\"34507928\",\"name\":\"Nanxin Chen\"},{\"authorId\":\"3286437\",\"name\":\"Adithya Renduchintala\"},{\"authorId\":\"3038673\",\"name\":\"Tsubasa Ochiai\"}],\"doi\":\"10.21437/Interspeech.2018-1456\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30f86d38f0660af5ea2e16d996434c72eee8c5ee\",\"title\":\"ESPnet: End-to-End Speech Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/30f86d38f0660af5ea2e16d996434c72eee8c5ee\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1610.09975\",\"authors\":[{\"authorId\":\"38940652\",\"name\":\"H. Soltau\"},{\"authorId\":\"39977619\",\"name\":\"H. Liao\"},{\"authorId\":\"2670103\",\"name\":\"H. Sak\"}],\"doi\":\"10.21437/INTERSPEECH.2017-1566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1cb867270f87f96397cb5f0d76cbb58cdf2c2f2\",\"title\":\"Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1cb867270f87f96397cb5f0d76cbb58cdf2c2f2\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1802.05365\",\"authors\":[{\"authorId\":\"39139825\",\"name\":\"Matthew E. Peters\"},{\"authorId\":\"50043859\",\"name\":\"Mark Neumann\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/N18-1202\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3febb2bed8865945e7fddc99efd791887bb7e14f\",\"title\":\"Deep contextualized word representations\",\"url\":\"https://www.semanticscholar.org/paper/3febb2bed8865945e7fddc99efd791887bb7e14f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1803.05566\",\"authors\":[{\"authorId\":\"145364697\",\"name\":\"J. Li\"},{\"authorId\":\"2150041\",\"name\":\"Guoli Ye\"},{\"authorId\":\"144216166\",\"name\":\"A. Das\"},{\"authorId\":\"143624101\",\"name\":\"R. Zhao\"},{\"authorId\":\"1777280\",\"name\":\"Y. Gong\"}],\"doi\":\"10.1109/ICASSP.2018.8462017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"608811ac14dcec1b8f860b30e4dbd5b60628598c\",\"title\":\"Advancing Acoustic-to-Word CTC Model\",\"url\":\"https://www.semanticscholar.org/paper/608811ac14dcec1b8f860b30e4dbd5b60628598c\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/SLT.2018.8639530\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"fe9fae85d21aba4c12d8aec83fbb074f1cdf7f80\",\"title\":\"Hierarchical Multitask Learning With CTC\",\"url\":\"https://www.semanticscholar.org/paper/fe9fae85d21aba4c12d8aec83fbb074f1cdf7f80\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alex Graves\"},{\"authorId\":null,\"name\":\"Navdeep Jaitly.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Towards endto-end speech recognition with recurrent neural networks\",\"url\":\"\",\"venue\":\"Proceedings of the 31st International Conference on Machine Learning (ICML-14), pages 1764\\u20131772.\",\"year\":2014},{\"arxivId\":\"1612.03651\",\"authors\":[{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5feb32a73dd1bd9e13f84a7b3344497a5545106b\",\"title\":\"FastText.zip: Compressing text classification models\",\"url\":\"https://www.semanticscholar.org/paper/5feb32a73dd1bd9e13f84a7b3344497a5545106b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"3326124\",\"name\":\"T. Hayashi\"}],\"doi\":\"10.1109/JSTSP.2017.2763455\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fcd012e8ed2ea8190163369c9f222178e70a19d\",\"title\":\"Hybrid CTC/Attention Architecture for End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8fcd012e8ed2ea8190163369c9f222178e70a19d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2017},{\"arxivId\":\"1808.02480\",\"authors\":[{\"authorId\":\"2779415\",\"name\":\"G. Pundak\"},{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"2557391\",\"name\":\"Rohit Prabhavalkar\"},{\"authorId\":\"31801501\",\"name\":\"A. Kannan\"},{\"authorId\":\"47783376\",\"name\":\"Ding Zhao\"}],\"doi\":\"10.1109/SLT.2018.8639034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8829ed626a278c2eba686ff973496f7c0825a2e8\",\"title\":\"Deep Context: End-to-end Contextual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8829ed626a278c2eba686ff973496f7c0825a2e8\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":\"1511.03962\",\"authors\":[{\"authorId\":\"40608686\",\"name\":\"Yangfeng Ji\"},{\"authorId\":\"143620680\",\"name\":\"Trevor Cohn\"},{\"authorId\":\"47648549\",\"name\":\"Lingpeng Kong\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"144154709\",\"name\":\"Jacob Eisenstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8e76b1062918624e9904e0073e11794d7594593\",\"title\":\"Document Context Language Models\",\"url\":\"https://www.semanticscholar.org/paper/e8e76b1062918624e9904e0073e11794d7594593\",\"venue\":\"ICLR 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shinji Watanabe\"},{\"authorId\":null,\"name\":\"Takaaki Hori\"},{\"authorId\":null,\"name\":\"Shigeki Karita\"},{\"authorId\":null,\"name\":\"Tomoki Hayashi\"},{\"authorId\":null,\"name\":\"Jiro Nishitoba\"},{\"authorId\":null,\"name\":\"Yuya Unno\"},{\"authorId\":null,\"name\":\"Nelson Enrique Yalta Soplin\"},{\"authorId\":null,\"name\":\"Jahn Heymann\"},{\"authorId\":null,\"name\":\"Matthew Wiesner\"},{\"authorId\":null,\"name\":\"Nanxin Chen\"},{\"authorId\":null,\"name\":\"Adithya Renduchintala\"},{\"authorId\":null,\"name\":\"Tsubasa Ochiai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Espnet: End-to-end speech\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"35186886\",\"name\":\"Siddharth Dalmia\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab92a0feaeabc67207647edfaf855a9a171ef10f\",\"title\":\"Situation Informed End-to-End ASR for CHiME-5 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/ab92a0feaeabc67207647edfaf855a9a171ef10f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1607.04606\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.1162/tacl_a_00051\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2dba792360873aef125572812f3673b1a85d850\",\"title\":\"Enriching Word Vectors with Subword Information\",\"url\":\"https://www.semanticscholar.org/paper/e2dba792360873aef125572812f3673b1a85d850\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2017},{\"arxivId\":\"1805.03294\",\"authors\":[{\"authorId\":\"3423021\",\"name\":\"Albert Zeyer\"},{\"authorId\":\"2350348\",\"name\":\"K. Irie\"},{\"authorId\":\"144490010\",\"name\":\"R. Schl\\u00fcter\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"}],\"doi\":\"10.21437/Interspeech.2018-1616\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0ead45e8c1e4cc390ff6603bc0738b8c57f99ec\",\"title\":\"Improved training of end-to-end attention models for speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0ead45e8c1e4cc390ff6603bc0738b8c57f99ec\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1706.02737\",\"authors\":[{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"}],\"doi\":\"10.21437/INTERSPEECH.2017-1296\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c102ac8c779ee0a53dc8e4ee20b4088ac2c7e186\",\"title\":\"Advances in Joint CTC-Attention Based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM\",\"url\":\"https://www.semanticscholar.org/paper/c102ac8c779ee0a53dc8e4ee20b4088ac2c7e186\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1211.5063\",\"authors\":[{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84069287da0a6b488b8c933f3cb5be759cb6237e\",\"title\":\"On the difficulty of training recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/84069287da0a6b488b8c933f3cb5be759cb6237e\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1701.04056\",\"authors\":[{\"authorId\":\"143830417\",\"name\":\"Bing Liu\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.1109/ICASSP.2017.7953251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adb909b83a4ccf3740b9948de2078c7b2bef6909\",\"title\":\"Dialog context language modeling with recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/adb909b83a4ccf3740b9948de2078c7b2bef6909\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"}],\"doi\":\"10.1109/ICASSP.2016.7472621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3056add22b20e3361c38c0472d294a79d4031cb4\",\"title\":\"Listen, attend and spell: A neural network for large vocabulary conversational speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/3056add22b20e3361c38c0472d294a79d4031cb4\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1607.01759\",\"authors\":[{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.18653/V1/E17-2068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"892e53fe5cd39f037cb2a961499f42f3002595dd\",\"title\":\"Bag of Tricks for Efficient Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/892e53fe5cd39f037cb2a961499f42f3002595dd\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Godfrey\"},{\"authorId\":null,\"name\":\"Edward Holliman.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Switchboard-1 release 2 ldc97s62\",\"url\":\"\",\"venue\":\"Linguistic Data Consortium, Philadelphia, LDC97S62.\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Oriol Vinyals\"},{\"authorId\":null,\"name\":\"Quoc VV Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ral speech recognizer : Acoustic - to - word lstm model for large vocabulary speech recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1905.08796\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.18653/v1/N19-1283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae83db6e6b0d6f68434c6d555d16f69c39697beb\",\"title\":\"Acoustic-to-Word Models with Conversational Context Information\",\"url\":\"https://www.semanticscholar.org/paper/ae83db6e6b0d6f68434c6d555d16f69c39697beb\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1212.5701\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8729441d734782c3ed532a7d2d9611b438c0a09a\",\"title\":\"ADADELTA: An Adaptive Learning Rate Method\",\"url\":\"https://www.semanticscholar.org/paper/8729441d734782c3ed532a7d2d9611b438c0a09a\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1508.04395\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"2616163\",\"name\":\"Philemon Brakel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1109/ICASSP.2016.7472618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"878ba5458e9e51f0b341fd9117fa0b43ef4096d3\",\"title\":\"End-to-end attention-based large vocabulary speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/878ba5458e9e51f0b341fd9117fa0b43ef4096d3\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1702.01992\",\"authors\":[{\"authorId\":\"3258998\",\"name\":\"John Arevalo\"},{\"authorId\":\"1794626\",\"name\":\"T. Solorio\"},{\"authorId\":\"1400883928\",\"name\":\"M. Montes-y-G\\u00f3mez\"},{\"authorId\":\"145580599\",\"name\":\"Fabio A. Gonz\\u00e1lez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37e3721940352df07faebd87620732c05b458985\",\"title\":\"Gated Multimodal Units for Information Fusion\",\"url\":\"https://www.semanticscholar.org/paper/37e3721940352df07faebd87620732c05b458985\",\"venue\":\"ICLR\",\"year\":2017}],\"title\":\"Gated Embeddings in End-to-End Speech Recognition for Conversational-Context Fusion\",\"topics\":[{\"topic\":\"Speech recognition\",\"topicId\":\"2869\",\"url\":\"https://www.semanticscholar.org/topic/2869\"},{\"topic\":\"Speech corpus\",\"topicId\":\"68755\",\"url\":\"https://www.semanticscholar.org/topic/68755\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Word error rate\",\"topicId\":\"65795\",\"url\":\"https://www.semanticscholar.org/topic/65795\"},{\"topic\":\"Telephone switchboard\",\"topicId\":\"840541\",\"url\":\"https://www.semanticscholar.org/topic/840541\"},{\"topic\":\"Dialog system\",\"topicId\":\"83260\",\"url\":\"https://www.semanticscholar.org/topic/83260\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Spoken dialog systems\",\"topicId\":\"399292\",\"url\":\"https://www.semanticscholar.org/topic/399292\"},{\"topic\":\"Finite-state machine\",\"topicId\":\"4280\",\"url\":\"https://www.semanticscholar.org/topic/4280\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"}],\"url\":\"https://www.semanticscholar.org/paper/efe4cae24065785c6727e815b941613b5d9ac0a0\",\"venue\":\"ACL\",\"year\":2019}\n"