"{\"abstract\":\"An image caption should fluently present the essential information in a given image, including informative, fine-grained entity mentions and the manner in which these entities interact. However, current captioning models are usually trained to generate captions that only contain common object names, thus falling short on an important \\u201cinformativeness\\u201d dimension. We present a mechanism for integrating image information together with fine-grained labels (assumed to be generated by some upstream models) into a caption that describes the image in a fluent and informative manner. We introduce a multimodal, multi-encoder model based on Transformer that ingests both image features and multiple sources of entity labels. We demonstrate that we can learn to control the appearance of these entity labels in the output, resulting in captions that are both fluent and informative.\",\"arxivId\":\"1906.08876\",\"authors\":[{\"authorId\":\"3038511\",\"name\":\"Sanqiang Zhao\",\"url\":\"https://www.semanticscholar.org/author/3038511\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\",\"url\":\"https://www.semanticscholar.org/author/48267618\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\",\"url\":\"https://www.semanticscholar.org/author/2900341\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\",\"url\":\"https://www.semanticscholar.org/author/1737285\"}],\"citationVelocity\":6,\"citations\":[{\"arxivId\":\"1911.09753\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.1609/AAAI.V34I03.5655\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b49c4285c6f744eaa5a653e7f7f0bc741ddbb8f5\",\"title\":\"Reinforcing an Image Caption Generator Using Off-Line Human Feedback\",\"url\":\"https://www.semanticscholar.org/paper/b49c4285c6f744eaa5a653e7f7f0bc741ddbb8f5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1909.03396\",\"authors\":[{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"2904055\",\"name\":\"Ashish V. Thapliyal\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd153dbee4f4b86962ddacbc47010785f9cdec3c\",\"title\":\"Quality Estimation for Image Captions Based on Large-scale Human Evaluations\",\"url\":\"https://www.semanticscholar.org/paper/bd153dbee4f4b86962ddacbc47010785f9cdec3c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"title\":\"VisualNews : A Large Multi-source News Image Dataset\",\"url\":\"https://www.semanticscholar.org/paper/7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.08686\",\"authors\":[{\"authorId\":\"49967124\",\"name\":\"N. Trieu\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"},{\"authorId\":\"113477341\",\"name\":\"Kazoo Sone\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf315d3defed0ba7e12a1fc00ebb6444c86e117c\",\"title\":\"Multi-Image Summarization: Textual Summary from a Set of Cohesive Images\",\"url\":\"https://www.semanticscholar.org/paper/bf315d3defed0ba7e12a1fc00ebb6444c86e117c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14308\",\"authors\":[{\"authorId\":\"145534763\",\"name\":\"N. Ding\"},{\"authorId\":\"8010189\",\"name\":\"Xinjie Fan\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"50319359\",\"name\":\"D. Schuurmans\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a4bf4ea600f32ceb4b2d005b1b039320cd698f37\",\"title\":\"Attention that does not Explain Away\",\"url\":\"https://www.semanticscholar.org/paper/a4bf4ea600f32ceb4b2d005b1b039320cd698f37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08070\",\"authors\":[{\"authorId\":\"51163002\",\"name\":\"Alasdair Tran\"},{\"authorId\":\"46953477\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"}],\"doi\":\"10.1109/CVPR42600.2020.01305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"title\":\"Transform and Tell: Entity-Aware News Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"title\":\"VisualNews : Benchmark and Challenges in Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00246\",\"authors\":[{\"authorId\":\"2904055\",\"name\":\"Ashish V. Thapliyal\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/2020.acl-main.16\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b88c52150995965a66dc774603444ad570c3941d\",\"title\":\"Cross-modal Language Generation using Pivot Stabilization for Web-scale Language Coverage\",\"url\":\"https://www.semanticscholar.org/paper/b88c52150995965a66dc774603444ad570c3941d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"2008241757\",\"name\":\"Arunav Pratap Shandeelya\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.1371/journal.pone.0241271\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f76b2bf0de083c77f8730809b2c01c28c388c41\",\"title\":\"More to diverse: Generating diversified responses in a task oriented multimodal dialog system\",\"url\":\"https://www.semanticscholar.org/paper/9f76b2bf0de083c77f8730809b2c01c28c388c41\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120897486\",\"name\":\"Anwen Hu\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"title\":\"ICECAP: Information Concentrated Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2839437\",\"name\":\"T. Arnold\"},{\"authorId\":\"51033450\",\"name\":\"L. Tilton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f83f8097d24c8df4570cc04aceeb9015331b6839\",\"title\":\"Enriching Historic Photography with Structured Data using Image Region Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f83f8097d24c8df4570cc04aceeb9015331b6839\",\"venue\":\"AI4HI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":195317077,\"doi\":\"10.18653/v1/P19-1650\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734693\",\"name\":\"John C. Duchi\"},{\"authorId\":\"34840427\",\"name\":\"Elad Hazan\"},{\"authorId\":\"1740765\",\"name\":\"Y. Singer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"413c1142de9d91804d6d11c67ff3fed59c9fc279\",\"title\":\"Adaptive Subgradient Methods for Online Learning and Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/413c1142de9d91804d6d11c67ff3fed59c9fc279\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2011},{\"arxivId\":\"1508.07909\",\"authors\":[{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"2259100\",\"name\":\"B. Haddow\"},{\"authorId\":\"2539211\",\"name\":\"Alexandra Birch\"}],\"doi\":\"10.18653/v1/P16-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1af68821518f03568f913ab03fc02080247a27ff\",\"title\":\"Neural Machine Translation of Rare Words with Subword Units\",\"url\":\"https://www.semanticscholar.org/paper/1af68821518f03568f913ab03fc02080247a27ff\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1804.07889\",\"authors\":[{\"authorId\":\"144690460\",\"name\":\"Di Lu\"},{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"34170717\",\"name\":\"Lifu Huang\"},{\"authorId\":\"144016781\",\"name\":\"Heng Ji\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.18653/v1/D18-1435\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e8feffa2280e41ceb864b940869c5408db89285\",\"title\":\"Entity-aware Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/1e8feffa2280e41ceb864b940869c5408db89285\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1805.03162\",\"authors\":[{\"authorId\":\"144412704\",\"name\":\"Tong Niu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1162/tacl_a_00027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1cba8a5a73c8151c2f5cb6edd5bc6a7c03e80fa\",\"title\":\"Polite Dialogue Generation Without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/f1cba8a5a73c8151c2f5cb6edd5bc6a7c03e80fa\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/P18-1238\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"title\":\"Conceptual Captions: A Cleaned, Hypernymed, Image Alt-text Dataset For Automatic Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4df354db88a70183a64dbc9e56cf14e7669a6c0\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1503.02531\",\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c908739fbff75f03469d13d4a1a07de3414ee19\",\"title\":\"Distilling the Knowledge in a Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0c908739fbff75f03469d13d4a1a07de3414ee19\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1612.00370\",\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a311c538fc021c27acd3953f171924cc5905c\",\"title\":\"Optimization of image description metrics using policy gradient methods\",\"url\":\"https://www.semanticscholar.org/paper/665a311c538fc021c27acd3953f171924cc5905c\",\"venue\":\"ArXiv\",\"year\":2016}],\"title\":\"Informative Image Captioning with External Sources of Information\",\"topics\":[{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Transformer\",\"topicId\":\"6977\",\"url\":\"https://www.semanticscholar.org/topic/6977\"},{\"topic\":\"Entity\",\"topicId\":\"6664\",\"url\":\"https://www.semanticscholar.org/topic/6664\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Upstream (software development)\",\"topicId\":\"15962\",\"url\":\"https://www.semanticscholar.org/topic/15962\"},{\"topic\":\"Precomputation\",\"topicId\":\"147641\",\"url\":\"https://www.semanticscholar.org/topic/147641\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"}],\"url\":\"https://www.semanticscholar.org/paper/68490e9e0bca2f0b1ae2ca636effcd8fc63d2008\",\"venue\":\"ACL\",\"year\":2019}\n"