"{\"abstract\":\"Human language is often multimodal, which comprehends a mixture of natural language, facial gestures, and acoustic behaviors. However, two major challenges in modeling such multimodal human language time-series data exist: 1) inherent data non-alignment due to variable sampling rates for the sequences from each modality; and 2) long-range dependencies between elements across modalities. In this paper, we introduce the Multimodal Transformer (MulT) to generically address the above issues in an end-to-end manner without explicitly aligning the data. At the heart of our model is the directional pairwise cross-modal attention, which attends to interactions between multimodal sequences across distinct time steps and latently adapt streams from one modality to another. Comprehensive experiments on both aligned and non-aligned multimodal time-series show that our model outperforms state-of-the-art methods by a large margin. In addition, empirical analysis suggests that correlated crossmodal signals are able to be captured by the proposed crossmodal attention mechanism in MulT.\",\"arxivId\":\"1906.00295\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\",\"url\":\"https://www.semanticscholar.org/author/145639633\"},{\"authorId\":\"35836381\",\"name\":\"Shaojie Bai\",\"url\":\"https://www.semanticscholar.org/author/35836381\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\",\"url\":\"https://www.semanticscholar.org/author/28130078\"},{\"authorId\":\"145116464\",\"name\":\"J. Z. Kolter\",\"url\":\"https://www.semanticscholar.org/author/145116464\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\",\"url\":\"https://www.semanticscholar.org/author/49933077\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\",\"url\":\"https://www.semanticscholar.org/author/145124475\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":\"2005.09382\",\"authors\":[{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"1573674357\",\"name\":\"Sona Mokra\"},{\"authorId\":\"1571809179\",\"name\":\"N. Wong\"},{\"authorId\":\"3367786\",\"name\":\"T. Harley\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ccd73d95b5e23279929866bc15ec2983f9fa700\",\"title\":\"Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learning from Text\",\"url\":\"https://www.semanticscholar.org/paper/1ccd73d95b5e23279929866bc15ec2983f9fa700\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.09826\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1429197894\",\"name\":\"Chengfeng Mao\"},{\"authorId\":\"1429262863\",\"name\":\"Kelly Shi\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cd88d0346e679d1388d7e0ef08f7f7e329f2d760\",\"title\":\"Factorized Multimodal Transformer for Multimodal Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/cd88d0346e679d1388d7e0ef08f7f7e329f2d760\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.10652\",\"authors\":[{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"38d705a83a5677ef69adeebae7aa9446f4c2cc74\",\"title\":\"Self-Supervised learning with cross-modal transformers for emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/38d705a83a5677ef69adeebae7aa9446f4c2cc74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13830\",\"authors\":[{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"},{\"authorId\":\"2417546\",\"name\":\"S. Hadfield\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/CVPR42600.2020.01004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05dcdfece56d1869895f53ed581d8ad64118c05f\",\"title\":\"Sign Language Transformers: Joint End-to-End Sign Language Recognition and Translation\",\"url\":\"https://www.semanticscholar.org/paper/05dcdfece56d1869895f53ed581d8ad64118c05f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.14840\",\"authors\":[{\"authorId\":\"3397911\",\"name\":\"Georgios Paraskevopoulos\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612582490c445b1859f7feea0c04daf17598014\",\"title\":\"Multiresolution and Multimodal Speech Recognition with Transformers\",\"url\":\"https://www.semanticscholar.org/paper/0612582490c445b1859f7feea0c04daf17598014\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.06682\",\"authors\":[{\"authorId\":\"51516859\",\"name\":\"S. Siriwardhana\"},{\"authorId\":\"1879515139\",\"name\":\"Andrew Reis\"},{\"authorId\":\"52001535\",\"name\":\"Rivindu Weerasekera\"},{\"authorId\":\"1486464114\",\"name\":\"Suranga Nanayakkara\"}],\"doi\":\"10.21437/interspeech.2020-1212\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dc89a8b66630e1af2c9715ec8f94e863fd289a31\",\"title\":\"Jointly Fine-Tuning \\\"BERT-like\\\" Self Supervised Models to Improve Multimodal Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dc89a8b66630e1af2c9715ec8f94e863fd289a31\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.13928\",\"authors\":[{\"authorId\":\"73438475\",\"name\":\"H. M. Hung\"},{\"authorId\":\"97598888\",\"name\":\"Hyung-Jeong Yang\"},{\"authorId\":\"2355626\",\"name\":\"Soohyung Kim\"},{\"authorId\":\"102801601\",\"name\":\"Guee-Sang Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84443aaeccdee9f7145ffd7713acc08e9c7a1b22\",\"title\":\"Variants of BERT, Random Forests and SVM approach for Multimodal Emotion-Target Sub-challenge\",\"url\":\"https://www.semanticscholar.org/paper/84443aaeccdee9f7145ffd7713acc08e9c7a1b22\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03876\",\"authors\":[{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a05dd0c22f8b11e01c28d389695721658264fbc\",\"title\":\"Audio-Visual Understanding of Passenger Intents for In-Cabin Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/3a05dd0c22f8b11e01c28d389695721658264fbc\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993712503\",\"name\":\"Xincheng Ju\"},{\"authorId\":\"1771537\",\"name\":\"D. Zhang\"},{\"authorId\":\"47787394\",\"name\":\"J. Li\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.1145/3394171.3413577\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"daf4a3fb8e9e9f153687aaf7e999534eec242d0f\",\"title\":\"Transformer-based Label Set Generation for Multi-modal Multi-label Emotion Detection\",\"url\":\"https://www.semanticscholar.org/paper/daf4a3fb8e9e9f153687aaf7e999534eec242d0f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51516859\",\"name\":\"S. Siriwardhana\"},{\"authorId\":\"1992921690\",\"name\":\"Tharindu Kaluarachchi\"},{\"authorId\":\"1485673104\",\"name\":\"Mark Billinghurst\"},{\"authorId\":\"1486464114\",\"name\":\"Suranga Nanayakkara\"}],\"doi\":\"10.1109/ACCESS.2020.3026823\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3fa0b660d2b26806a8159d58f49acc4bf132b1eb\",\"title\":\"Multimodal Emotion Recognition With Transformer-Based Self Supervised Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/3fa0b660d2b26806a8159d58f49acc4bf132b1eb\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.11405\",\"authors\":[{\"authorId\":\"9148956\",\"name\":\"Chongyang Bai\"},{\"authorId\":\"2028262\",\"name\":\"H. Chen\"},{\"authorId\":\"39703734\",\"name\":\"Srijan Kumar\"},{\"authorId\":\"1702139\",\"name\":\"J. Leskovec\"},{\"authorId\":\"1728462\",\"name\":\"V. Subrahmanian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51819e6b428676c373d97f267d18b8d4a25020fd\",\"title\":\"M2P2: Multimodal Persuasion Prediction using Adaptive Fusion\",\"url\":\"https://www.semanticscholar.org/paper/51819e6b428676c373d97f267d18b8d4a25020fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118242121\",\"name\":\"Chaitanya Ahuja\"},{\"authorId\":\"152496368\",\"name\":\"Dong Won Lee\"},{\"authorId\":\"1500659510\",\"name\":\"Ryo Ishii\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.170\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d5924c8cdef6270a955ba82c2b07a8282d869744\",\"title\":\"No Gestures Left Behind: Learning Relationships between Spoken Language and Freeform Gestures\",\"url\":\"https://www.semanticscholar.org/paper/d5924c8cdef6270a955ba82c2b07a8282d869744\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.14701\",\"authors\":[{\"authorId\":\"103143311\",\"name\":\"T. Henighan\"},{\"authorId\":\"39515141\",\"name\":\"J. Kaplan\"},{\"authorId\":\"102493084\",\"name\":\"Mor Katz\"},{\"authorId\":\"145624068\",\"name\":\"Mark Chen\"},{\"authorId\":\"144239765\",\"name\":\"Christopher Hesse\"},{\"authorId\":\"31617184\",\"name\":\"J. Jackson\"},{\"authorId\":\"35450887\",\"name\":\"Heewoo Jun\"},{\"authorId\":\"31035595\",\"name\":\"T. Brown\"},{\"authorId\":\"6515819\",\"name\":\"Prafulla Dhariwal\"},{\"authorId\":\"145565184\",\"name\":\"Scott Gray\"},{\"authorId\":\"2004021329\",\"name\":\"Chris Hallacy\"},{\"authorId\":\"46804309\",\"name\":\"B. Mann\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2938206\",\"name\":\"Aditya Ramesh\"},{\"authorId\":\"39849748\",\"name\":\"Nick Ryder\"},{\"authorId\":\"40179323\",\"name\":\"D. Ziegler\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"48447830\",\"name\":\"Dario Amodei\"},{\"authorId\":\"52238703\",\"name\":\"Sam McCandlish\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3efbcfeeb0ea1051a71101d3318da4411081f0b8\",\"title\":\"Scaling Laws for Autoregressive Generative Modeling\",\"url\":\"https://www.semanticscholar.org/paper/3efbcfeeb0ea1051a71101d3318da4411081f0b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3397911\",\"name\":\"Georgios Paraskevopoulos\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":\"10.18653/v1/2020.acl-main.216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9399c7d21a579001a4951bf462843633483af367\",\"title\":\"Multimodal and Multiresolution Speech Recognition with Transformers\",\"url\":\"https://www.semanticscholar.org/paper/9399c7d21a579001a4951bf462843633483af367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2010.02057\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"88741566\",\"name\":\"No\\u00e9 Tits\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.1\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"86a7a97c8efd99b862c524eb46a40276a52d3c60\",\"title\":\"Modulated Fusion using Transformer for Linguistic-Acoustic Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/86a7a97c8efd99b862c524eb46a40276a52d3c60\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49352657\",\"name\":\"Long-Fei Xie\"},{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"}],\"doi\":\"10.1007/978-3-030-59830-3_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6fa32942c85a7283abd1c8fbd4bae11f73853cf\",\"title\":\"Gate-Fusion Transformer for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e6fa32942c85a7283abd1c8fbd4bae11f73853cf\",\"venue\":\"ICPRAI\",\"year\":2020},{\"arxivId\":\"1911.05544\",\"authors\":[{\"authorId\":\"13223746\",\"name\":\"Zhongkai Sun\"},{\"authorId\":\"22603977\",\"name\":\"P. Sarma\"},{\"authorId\":\"1755618\",\"name\":\"W. Sethares\"},{\"authorId\":\"40609253\",\"name\":\"Yingyu Liang\"}],\"doi\":\"10.1609/aaai.v34i05.6431\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f2e7e083a3837573a4c456f468d90c5a54967d1\",\"title\":\"Learning Relationships between Text, Audio, and Video via Deep Canonical Correlation for Multimodal Language Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f2e7e083a3837573a4c456f468d90c5a54967d1\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27743961\",\"name\":\"Dimitris Gkoumas\"},{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"47111898\",\"name\":\"Yijun Yu\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"},{\"authorId\":\"51002652\",\"name\":\"Da-wei Song\"}],\"doi\":\"10.1016/J.INFFUS.2020.09.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"title\":\"What makes the difference? An empirical comparison of fusion strategies for multimodal language analysis\",\"url\":\"https://www.semanticscholar.org/paper/b3b960ceed80dc0b5bf749ae6e152abefef52f52\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":\"2004.14198\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"1384374825\",\"name\":\"Martin Q. Ma\"},{\"authorId\":\"72966973\",\"name\":\"Muqiao Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.143\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e0657c56fb71a9ebd08bde17058a13869c31d936\",\"title\":\"Multimodal Routing: Improving Local and Global Interpretability of Multimodal Language Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e0657c56fb71a9ebd08bde17058a13869c31d936\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845316\",\"name\":\"D. Zhang\"},{\"authorId\":\"1993712503\",\"name\":\"Xincheng Ju\"},{\"authorId\":\"47787394\",\"name\":\"J. Li\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.291\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8f786d6cdd4e65581a67ace176d0ead1658b5463\",\"title\":\"Multi-modal Multi-label Emotion Detection with Modality and Label Dependence\",\"url\":\"https://www.semanticscholar.org/paper/8f786d6cdd4e65581a67ace176d0ead1658b5463\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2009.09629\",\"authors\":[{\"authorId\":\"47653392\",\"name\":\"Wenliang Dai\"},{\"authorId\":\"152613855\",\"name\":\"Zihan Liu\"},{\"authorId\":\"1660855299\",\"name\":\"Tiezheng Yu\"},{\"authorId\":\"40539650\",\"name\":\"Pascale Fung\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"06d420c2c40f3d117634579f12885c0a00780085\",\"title\":\"Modality-Transferable Emotion Embeddings for Low-Resource Multimodal Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/06d420c2c40f3d117634579f12885c0a00780085\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2005.06035\",\"authors\":[{\"authorId\":\"46882405\",\"name\":\"Chen Zheng\"},{\"authorId\":\"144919537\",\"name\":\"Quan Guo\"},{\"authorId\":\"2190934\",\"name\":\"Parisa Kordjamshidi\"}],\"doi\":\"10.18653/v1/2020.acl-main.683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b293e4fd06e8a0f3ea7e46c4dafb575b288515e2\",\"title\":\"Cross-Modality Relevance for Reasoning on Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/b293e4fd06e8a0f3ea7e46c4dafb575b288515e2\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1995716303\",\"name\":\"Ruichen Li\"},{\"authorId\":\"46508997\",\"name\":\"Jinming Zhao\"},{\"authorId\":\"49268477\",\"name\":\"Jingwen Hu\"},{\"authorId\":\"143781963\",\"name\":\"S. Guo\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3423327.3423671\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a382ccbc31a1d8c6065ea9335d0d8adf121210af\",\"title\":\"Multi-modal Fusion for Video Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a382ccbc31a1d8c6065ea9335d0d8adf121210af\",\"venue\":\"MuSe @ ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.09290\",\"authors\":[{\"authorId\":\"46494316\",\"name\":\"Fangtao Li\"},{\"authorId\":\"47825136\",\"name\":\"Wenzhe Wang\"},{\"authorId\":\"1879512436\",\"name\":\"Zihe Liu\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"9745425\",\"name\":\"Chenghao Yan\"},{\"authorId\":\"121084731\",\"name\":\"B. Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbff734406b8bad624828bed8b41a5910c9d3137\",\"title\":\"Frame Aggregation and Multi-Modal Fusion Framework for Video-Based Person Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cbff734406b8bad624828bed8b41a5910c9d3137\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143621743\",\"name\":\"Jianfei Yu\"},{\"authorId\":\"50707231\",\"name\":\"J. Jiang\"},{\"authorId\":\"1624030637\",\"name\":\"L. Yang\"},{\"authorId\":\"1491639587\",\"name\":\"Rui Xia\"}],\"doi\":\"10.18653/v1/2020.acl-main.306\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b4a45b3d2f7573451048d695fbf81cfcee9253e\",\"title\":\"Improving Multimodal Named Entity Recognition via Entity Span Detection with Unified Multimodal Transformer\",\"url\":\"https://www.semanticscholar.org/paper/1b4a45b3d2f7573451048d695fbf81cfcee9253e\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.10916\",\"authors\":[{\"authorId\":\"90683745\",\"name\":\"K. Panchal\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07c9e3c2481a074ed44b7967e49d2a7d75c6f06c\",\"title\":\"Hierachical Delta-Attention Method for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/07c9e3c2481a074ed44b7967e49d2a7d75c6f06c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08670\",\"authors\":[{\"authorId\":\"31469067\",\"name\":\"Jia-Ming Wang\"},{\"authorId\":\"153140559\",\"name\":\"Jun Du\"},{\"authorId\":\"47539230\",\"name\":\"Jian-Shu Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"533b40bdeed5539703163ef77faddc1a96639d91\",\"title\":\"Stroke Constrained Attention Network for Online Handwritten Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/533b40bdeed5539703163ef77faddc1a96639d91\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.05787\",\"authors\":[{\"authorId\":\"153515321\",\"name\":\"Wasifur Rahman\"},{\"authorId\":\"2811524\",\"name\":\"M. Hasan\"},{\"authorId\":\"1459934320\",\"name\":\"Sangwu Lee\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1429197894\",\"name\":\"Chengfeng Mao\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1491348598\",\"name\":\"Ehsan Hoque\"}],\"doi\":\"10.18653/v1/2020.acl-main.214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ecaddd3df8793c1b7050cb4c6b359c041bedc57\",\"title\":\"Integrating Multimodal Information in Large Pretrained Transformers\",\"url\":\"https://www.semanticscholar.org/paper/0ecaddd3df8793c1b7050cb4c6b359c041bedc57\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1909.02950\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"47686397\",\"name\":\"Suvrat Bhooshan\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"1389630028\",\"name\":\"Davide Testuggine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f3003f95798c70675bcea8dc523f89895522e66\",\"title\":\"Supervised Multimodal Bitransformers for Classifying Images and Text\",\"url\":\"https://www.semanticscholar.org/paper/0f3003f95798c70675bcea8dc523f89895522e66\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"2010.11985\",\"authors\":[{\"authorId\":\"46477844\",\"name\":\"Jianing Yang\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"1796308073\",\"name\":\"Ruitao Yi\"},{\"authorId\":\"4375156\",\"name\":\"Yuying Zhu\"},{\"authorId\":\"2003216617\",\"name\":\"Azaan Rehman\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"322aec7489a4749f24d8a741766f04046d5ee19c\",\"title\":\"MTGAT: Multimodal Temporal Graph Attention Networks for Unaligned Human Multimodal Language Sequences\",\"url\":\"https://www.semanticscholar.org/paper/322aec7489a4749f24d8a741766f04046d5ee19c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14198\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"1384374825\",\"name\":\"Martin Q. Ma\"},{\"authorId\":\"72966973\",\"name\":\"Muqiao Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c0685bec77430b7024ce1fdf5f1e00ef9c355fb\",\"title\":\"Interpretable Multimodal Routing for Human Multimodal Language\",\"url\":\"https://www.semanticscholar.org/paper/5c0685bec77430b7024ce1fdf5f1e00ef9c355fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.07848\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"}],\"doi\":\"10.1609/AAAI.V34I01.5347\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"title\":\"Modality to Modality Translation: An Adversarial Representation Learning and Graph Fusion Network for Multimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a1d36d6421fb36403bdc1ad1b33736fd617837e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152250601\",\"name\":\"Weidong He\"},{\"authorId\":\"7719306\",\"name\":\"Zhi-xiao Li\"},{\"authorId\":\"2187496\",\"name\":\"Dongcai Lu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"41157498\",\"name\":\"T. Xu\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"1390958297\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1145/3394171.3413679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"311a3619d7e5409ccedfd646b1a2e3d82eb85502\",\"title\":\"Multimodal Dialogue Systems via Capturing Context-aware Dependencies of Semantic Elements\",\"url\":\"https://www.semanticscholar.org/paper/311a3619d7e5409ccedfd646b1a2e3d82eb85502\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.13572\",\"authors\":[{\"authorId\":\"150301735\",\"name\":\"Sijie Mai\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"49264083\",\"name\":\"Jia-Xuan He\"},{\"authorId\":\"1742521984\",\"name\":\"Ying Zeng\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"title\":\"Analyzing Unaligned Multimodal Sequence via Graph Convolution and Graph Pooling Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f2a6b0d8211751cdb433482955f2ee5df36436fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"},{\"authorId\":\"2392839\",\"name\":\"H. Xu\"},{\"authorId\":\"37216441\",\"name\":\"K. Gao\"}],\"doi\":\"10.1145/3394171.3413690\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"773d51dbb619a167102f75d93f39582a67c24c82\",\"title\":\"CM-BERT: Cross-Modal BERT for Text-Audio Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/773d51dbb619a167102f75d93f39582a67c24c82\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46304750\",\"name\":\"Y. Ding\"},{\"authorId\":\"51242086\",\"name\":\"R. Kumaran\"},{\"authorId\":\"4968278\",\"name\":\"Tianjiao Yang\"},{\"authorId\":\"15425485\",\"name\":\"Tobias H\\u00f6llerer\"}],\"doi\":\"10.1145/3382507.3418838\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cd445e12074ae349a48d6119874078f7a50553\",\"title\":\"Predicting Video Affect via Induced Affection in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/a6cd445e12074ae349a48d6119874078f7a50553\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"2009.08128\",\"authors\":[{\"authorId\":\"1659142288\",\"name\":\"Youngbin Ro\"},{\"authorId\":\"87002967\",\"name\":\"Y. Lee\"},{\"authorId\":\"1439658274\",\"name\":\"Pilsung Kang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.99\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07c18bede4ea8b26843d773ddee55e0b770139f7\",\"title\":\"Multi^2OIE: Multilingual Open Information Extraction based on Multi-Head Attention with BERT\",\"url\":\"https://www.semanticscholar.org/paper/07c18bede4ea8b26843d773ddee55e0b770139f7\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90475778\",\"name\":\"Qing Li\"},{\"authorId\":\"1657274125\",\"name\":\"Guanyuan Yu\"},{\"authorId\":\"2661535\",\"name\":\"Jun-ying Wang\"},{\"authorId\":\"1768818227\",\"name\":\"Yuehao Liu\"}],\"doi\":\"10.1007/s11042-020-09227-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"120920cd832814c6e5cdff0ec0681f2fd227387a\",\"title\":\"A deep multimodal generative and fusion framework for class-imbalanced multimodal data\",\"url\":\"https://www.semanticscholar.org/paper/120920cd832814c6e5cdff0ec0681f2fd227387a\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2009.04107\",\"authors\":[{\"authorId\":\"1932103679\",\"name\":\"Zexu Pan\"},{\"authorId\":\"2834542\",\"name\":\"Zhaojie Luo\"},{\"authorId\":\"2100162\",\"name\":\"J. Yang\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.21437/interspeech.2020-1653\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2e762956621d3a3906b5891afa0f755e01ffcbde\",\"title\":\"Multi-modal Attention for Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2e762956621d3a3906b5891afa0f755e01ffcbde\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411197478\",\"name\":\"N. KrishnaD.\"},{\"authorId\":\"46493993\",\"name\":\"A. Patil\"}],\"doi\":\"10.21437/interspeech.2020-1190\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58794938495d6fae68bb47cf886fcd21342df3ed\",\"title\":\"Multimodal Emotion Recognition Using Cross-Modal Attention and 1D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/58794938495d6fae68bb47cf886fcd21342df3ed\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2010.07637\",\"authors\":[{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"152742748\",\"name\":\"G. Liu\"},{\"authorId\":\"38542466\",\"name\":\"X. Wang\"},{\"authorId\":\"98055366\",\"name\":\"W. Gao\"},{\"authorId\":\"3167960\",\"name\":\"X. Li\"},{\"authorId\":\"49927294\",\"name\":\"J. Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6265b3642be2f0b04e6901e3ba5378d7d37f91d\",\"title\":\"DialogueTRM: Exploring the Intra- and Inter-Modal Emotional Behaviors in the Conversation\",\"url\":\"https://www.semanticscholar.org/paper/e6265b3642be2f0b04e6901e3ba5378d7d37f91d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10839\",\"authors\":[{\"authorId\":\"7878341\",\"name\":\"Wubo Li\"},{\"authorId\":\"46197764\",\"name\":\"D. Jiang\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"}],\"doi\":\"10.21437/interspeech.2020-2359\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"title\":\"TMT: A Transformer-based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"2003432444\",\"name\":\"Dimitrios Gkoumas\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"},{\"authorId\":\"1830455439\",\"name\":\"Massimo Melucci\"}],\"doi\":\"10.1016/j.inffus.2020.08.006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"title\":\"Quantum-inspired multimodal fusion for video sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/c15a3ea20c6bc853448c79fa42c9e92e8e928de3\",\"venue\":\"Inf. Fusion\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95409396\",\"name\":\"L. Sun\"},{\"authorId\":\"49608347\",\"name\":\"Zheng Lian\"},{\"authorId\":\"12077195\",\"name\":\"J. Tao\"},{\"authorId\":\"103294513\",\"name\":\"Bin Liu\"},{\"authorId\":\"41032423\",\"name\":\"Ming-Yue Niu\"}],\"doi\":\"10.1145/3423327.3423672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10a00e85642ec07cfb8eebc09de83445ea8a2833\",\"title\":\"Multi-modal Continuous Dimensional Emotion Recognition Using Recurrent Neural Network and Self-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/10a00e85642ec07cfb8eebc09de83445ea8a2833\",\"venue\":\"MuSe @ ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41219390\",\"name\":\"Qiuchi Li\"},{\"authorId\":\"50686521\",\"name\":\"A. Stefani\"},{\"authorId\":\"1922081704\",\"name\":\"Giovanni Toto\"},{\"authorId\":\"66396314\",\"name\":\"Emanuele Di Buccio\"},{\"authorId\":\"1678917\",\"name\":\"M. Melucci\"}],\"doi\":\"10.1109/MIPR49039.2020.00044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d33cedd8df6d9b2b1f534d4fd51d90986387d07\",\"title\":\"Towards Multimodal Sentiment Analysis Inspired by the Quantum Theoretical Framework\",\"url\":\"https://www.semanticscholar.org/paper/4d33cedd8df6d9b2b1f534d4fd51d90986387d07\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47513413\",\"name\":\"J. Huang\"},{\"authorId\":\"47060742\",\"name\":\"J. Tao\"},{\"authorId\":\"48265485\",\"name\":\"B. Liu\"},{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"33019350\",\"name\":\"Mingyue Niu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053762\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ae1242bf3258f14c05283dc32e906922951749b5\",\"title\":\"Multimodal Transformer Fusion for Continuous Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae1242bf3258f14c05283dc32e906922951749b5\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144898072\",\"name\":\"Xiao Jin\"},{\"authorId\":\"143621743\",\"name\":\"Jianfei Yu\"},{\"authorId\":\"3465740\",\"name\":\"Zixiang Ding\"},{\"authorId\":\"1491639587\",\"name\":\"Rui Xia\"},{\"authorId\":\"50177303\",\"name\":\"X. Zhou\"},{\"authorId\":\"153012625\",\"name\":\"Yaofeng Tu\"}],\"doi\":\"10.1007/978-3-030-60457-8_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87ae3d9b0bf88a6e52a798b5feba84e1fb3d54bb\",\"title\":\"Hierarchical Multimodal Transformer with Localness and Speaker Aware Attention for Emotion Recognition in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/87ae3d9b0bf88a6e52a798b5feba84e1fb3d54bb\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1908.11775\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"35836381\",\"name\":\"Shaojie Bai\"},{\"authorId\":\"143979662\",\"name\":\"M. Yamada\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.18653/v1/D19-1443\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f9080cc8474881e602c28dec8c2d910db83851aa\",\"title\":\"Transformer Dissection: An Unified Understanding for Transformer's Attention via the Lens of Kernel\",\"url\":\"https://www.semanticscholar.org/paper/f9080cc8474881e602c28dec8c2d910db83851aa\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1754430080\",\"name\":\"Wenmeng Yu\"},{\"authorId\":\"1491194464\",\"name\":\"Hua Xu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"46758765\",\"name\":\"Yilin Zhu\"},{\"authorId\":\"95952564\",\"name\":\"Y. Ma\"},{\"authorId\":\"1754148511\",\"name\":\"Jiele Wu\"},{\"authorId\":\"1657286768\",\"name\":\"Jiyun Zou\"},{\"authorId\":\"48783102\",\"name\":\"Kaicheng Yang\"}],\"doi\":\"10.18653/v1/2020.acl-main.343\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc85469f9ff785f24212a50c58b497de563ae3da\",\"title\":\"CH-SIMS: A Chinese Multimodal Sentiment Analysis Dataset with Fine-grained Annotation of Modality\",\"url\":\"https://www.semanticscholar.org/paper/fc85469f9ff785f24212a50c58b497de563ae3da\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008352531\",\"name\":\"AmirAli Bagher Zadeh\"},{\"authorId\":\"3436851\",\"name\":\"Yansheng Cao\"},{\"authorId\":\"2008177967\",\"name\":\"Simon Hessner\"},{\"authorId\":\"2008183288\",\"name\":\"Paul Pu Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.141\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dec43c7511acfc02f5f22fbe4e19ed2aed49b015\",\"title\":\"CMU-MOSEAS: A Multimodal Language Dataset for Spanish, Portuguese, German and French\",\"url\":\"https://www.semanticscholar.org/paper/dec43c7511acfc02f5f22fbe4e19ed2aed49b015\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146434295\",\"name\":\"Chenguang Song\"},{\"authorId\":\"51221884\",\"name\":\"N. Ning\"},{\"authorId\":\"1796249559\",\"name\":\"Yunlei Zhang\"},{\"authorId\":\"1699037\",\"name\":\"Bin Wu\"}],\"doi\":\"10.1016/j.ipm.2020.102437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e28aebd85c2f0d1cda5c1afd39737e06af2e736\",\"title\":\"A multimodal fake news detection model based on crossmodal attention residual and multichannel convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/6e28aebd85c2f0d1cda5c1afd39737e06af2e736\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2004.14858\",\"authors\":[{\"authorId\":\"113705775\",\"name\":\"Lukas Stappen\"},{\"authorId\":\"40399407\",\"name\":\"Alice Baird\"},{\"authorId\":\"40185455\",\"name\":\"Georgios Rizos\"},{\"authorId\":\"2829366\",\"name\":\"Panagiotis Tzirakis\"},{\"authorId\":\"103941082\",\"name\":\"Xinchen Du\"},{\"authorId\":\"123479279\",\"name\":\"F. Hafner\"},{\"authorId\":\"116366891\",\"name\":\"L. Schumann\"},{\"authorId\":\"1404341452\",\"name\":\"Adria Mallol-Ragolta\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"2238874\",\"name\":\"I. Lefter\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9b7a70e98dee7c9da1a685a2c02a42335dc19c5c\",\"title\":\"MuSe 2020 - The First International Multimodal Sentiment Analysis in Real-life Media Challenge and Workshop\",\"url\":\"https://www.semanticscholar.org/paper/9b7a70e98dee7c9da1a685a2c02a42335dc19c5c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.02038\",\"authors\":[{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"63788711785b1dcbe400af8c2332b8bc48bc42fc\",\"title\":\"Low Rank Fusion based Transformers for Multimodal Sequences\",\"url\":\"https://www.semanticscholar.org/paper/63788711785b1dcbe400af8c2332b8bc48bc42fc\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":\"2005.03545\",\"authors\":[{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"1382302885\",\"name\":\"Soujanya Poria\"}],\"doi\":\"10.1145/3394171.3413678\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c398f1283d0e594fe710d71e9627319291734b1d\",\"title\":\"MISA: Modality-Invariant and -Specific Representations for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c398f1283d0e594fe710d71e9627319291734b1d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.10151\",\"authors\":[{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"14487640\",\"name\":\"Ari Holtzman\"},{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"50730674\",\"name\":\"Joyce Chai\"},{\"authorId\":\"1412841514\",\"name\":\"M. Lapata\"},{\"authorId\":\"2672644\",\"name\":\"A. Lazaridou\"},{\"authorId\":\"143823227\",\"name\":\"Jonathan May\"},{\"authorId\":\"17109242\",\"name\":\"Aleksandr Nisnevich\"},{\"authorId\":\"30017846\",\"name\":\"Nicolas Pinto\"},{\"authorId\":\"153160559\",\"name\":\"Joseph P. Turian\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.703\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d\",\"title\":\"Experience Grounds Language\",\"url\":\"https://www.semanticscholar.org/paper/bb6c2a64ecb6e4c9f3f5720d53cca76a2c37505d\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.10390\",\"authors\":[{\"authorId\":null,\"name\":\"Rufin VanRullen\"},{\"authorId\":null,\"name\":\"Ryota Kanai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"69135a269b8d2536bc4f3caa03b465ceb9356192\",\"title\":\"Deep Learning and the Global Workspace Theory\",\"url\":\"https://www.semanticscholar.org/paper/69135a269b8d2536bc4f3caa03b465ceb9356192\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.02598\",\"authors\":[{\"authorId\":\"1557401586\",\"name\":\"Jingjun Liang\"},{\"authorId\":\"83895120\",\"name\":\"Ruichen Li\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413579\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0e5cc1e564501de32de97845c7405626781a413\",\"title\":\"Semi-supervised Multi-modal Emotion Recognition with Cross-Modal Distribution Matching\",\"url\":\"https://www.semanticscholar.org/paper/d0e5cc1e564501de32de97845c7405626781a413\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.05019\",\"authors\":[{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":\"10.21437/Interspeech.2020-1827\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1904958461d165d1cfddcecb5358f413cba1f639\",\"title\":\"Multi-modal embeddings using multi-task learning for emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/1904958461d165d1cfddcecb5358f413cba1f639\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2005.09297\",\"authors\":[{\"authorId\":\"30606918\",\"name\":\"George Sterpu\"},{\"authorId\":\"1814175\",\"name\":\"Christian Saam\"},{\"authorId\":\"34530970\",\"name\":\"N. Harte\"}],\"doi\":\"10.21437/interspeech.2020-2480\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28c9ae026ab49dc63ad108800615da77e38e4089\",\"title\":\"Should we hard-code the recurrence concept or learn it instead ? Exploring the Transformer architecture for Audio-Visual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/28c9ae026ab49dc63ad108800615da77e38e4089\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993736913\",\"name\":\"Lukas Stappen\"},{\"authorId\":\"40399407\",\"name\":\"Alice Baird\"},{\"authorId\":\"1996042232\",\"name\":\"Georgios Rizos\"},{\"authorId\":\"1996058404\",\"name\":\"Panagiotis Tzirakis\"},{\"authorId\":\"1996105164\",\"name\":\"Xinchen Du\"},{\"authorId\":\"123479279\",\"name\":\"F. Hafner\"},{\"authorId\":\"116366891\",\"name\":\"L. Schumann\"},{\"authorId\":\"1404341452\",\"name\":\"Adria Mallol-Ragolta\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"2238874\",\"name\":\"I. Lefter\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1145/3423327.3423673\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d0ebaafe32963bd352e65910a4209f777420f081\",\"title\":\"MuSe 2020 Challenge and Workshop: Multimodal Sentiment Analysis, Emotion-target Engagement and Trustworthiness Detection in Real-life Media: Emotional Car Reviews in-the-wild\",\"url\":\"https://www.semanticscholar.org/paper/d0ebaafe32963bd352e65910a4209f777420f081\",\"venue\":\"MuSe @ ACM Multimedia\",\"year\":2020}],\"corpusId\":173990158,\"doi\":\"10.18653/v1/P19-1656\",\"fieldsOfStudy\":[\"Computer Science\",\"Medicine\"],\"influentialCitationCount\":16,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"949fef650da4c41afe6049a183b504b3cc91f4bd\",\"references\":[{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87863037\",\"name\":\"Michael Tomasello\"}],\"doi\":\"10.1525/jlin.1994.4.1.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709a46a2ec72079012d579917f057ecbabdccbf4\",\"title\":\"Tools, Language and Cognition in Human Evolution\",\"url\":\"https://www.semanticscholar.org/paper/709a46a2ec72079012d579917f057ecbabdccbf4\",\"venue\":\"\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6250262\",\"name\":\"K. Gibson\"},{\"authorId\":\"4081036\",\"name\":\"T. Ingold\"}],\"doi\":\"10.2307/2804508\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09aacefaf98b1c62c09affad3554c897c8791e35\",\"title\":\"Tools, Language and Cognition in Human Evolution\",\"url\":\"https://www.semanticscholar.org/paper/09aacefaf98b1c62c09affad3554c897c8791e35\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"35122767\",\"name\":\"Navonil Majumder\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P17-1081\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"title\":\"Context-Dependent Sentiment Analysis in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/75d17e8fa5165a849ebe5f0475bdf77bf0b6be74\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P18-1208\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"006fdeff6e1a81c404317ee4056d6cc72f9c0e50\",\"title\":\"Multimodal Language Analysis in the Wild: CMU-MOSEI Dataset and Interpretable Dynamic Fusion Graph\",\"url\":\"https://www.semanticscholar.org/paper/006fdeff6e1a81c404317ee4056d6cc72f9c0e50\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"}],\"doi\":\"10.1080/02699939208411068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfdbfe3bf703594b884ae69f505f94ce7e98141e\",\"title\":\"An argument for basic emotions\",\"url\":\"https://www.semanticscholar.org/paper/bfdbfe3bf703594b884ae69f505f94ce7e98141e\",\"venue\":\"\",\"year\":1992},{\"arxivId\":\"1609.08194\",\"authors\":[{\"authorId\":\"11699366\",\"name\":\"L. Yu\"},{\"authorId\":\"144685020\",\"name\":\"Jan Buys\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"}],\"doi\":\"10.18653/v1/D16-1138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f61da0efbb38bd3e6b9a9855809f5288b829f1f0\",\"title\":\"Online Segment to Segment Neural Transduction\",\"url\":\"https://www.semanticscholar.org/paper/f61da0efbb38bd3e6b9a9855809f5288b829f1f0\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"}],\"doi\":\"10.1007/978-0-85729-997-0_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0a21f94de312a0ff31657fd103d6b29db823caa\",\"title\":\"Facial Expression Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d0a21f94de312a0ff31657fd103d6b29db823caa\",\"venue\":\"Visual Analysis of Humans\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47260649\",\"name\":\"Imran Sheikh\"},{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"title\":\"Audio-Visual Fusion for Sentiment Classification using Cross-Modal Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3422920\",\"name\":\"Eli Pincus\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/MIS.2016.94\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"efe353682061e0f929e8c916b64b84ff88297e47\",\"title\":\"Multimodal Sentiment Intensity Analysis in Videos: Facial Gestures and Verbal Messages\",\"url\":\"https://www.semanticscholar.org/paper/efe353682061e0f929e8c916b64b84ff88297e47\",\"venue\":\"IEEE Intelligent Systems\",\"year\":2016},{\"arxivId\":\"1607.06450\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97fb4e3d45bb098e27e0071448b6152217bd35a5\",\"title\":\"Layer Normalization\",\"url\":\"https://www.semanticscholar.org/paper/97fb4e3d45bb098e27e0071448b6152217bd35a5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1960326\",\"name\":\"G. Degottex\"},{\"authorId\":\"145676779\",\"name\":\"John Kane\"},{\"authorId\":\"2242058\",\"name\":\"Thomas Drugman\"},{\"authorId\":\"1749273\",\"name\":\"T. Raitio\"},{\"authorId\":\"1770312\",\"name\":\"Stefan Scherer\"}],\"doi\":\"10.1109/ICASSP.2014.6853739\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"title\":\"COVAREP \\u2014 A collaborative voice analysis repository for speech technologies\",\"url\":\"https://www.semanticscholar.org/paper/511cbe73e535d9afb6c2c4f37c93a7f0e7d54f28\",\"venue\":\"2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2014},{\"arxivId\":\"1805.08660\",\"authors\":[{\"authorId\":\"49986580\",\"name\":\"Yue Gu\"},{\"authorId\":\"25113310\",\"name\":\"Kangning Yang\"},{\"authorId\":\"4699701\",\"name\":\"S. Fu\"},{\"authorId\":\"1804228\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"2252963\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":\"10.18653/v1/P18-1207\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7a39763121077c5a67343f822e6617fe3013a124\",\"title\":\"Multimodal Affective Analysis Using Hierarchical Attention Strategy with Word-Level Alignment\",\"url\":\"https://www.semanticscholar.org/paper/7a39763121077c5a67343f822e6617fe3013a124\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1806.06176\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"title\":\"Learning Factorized Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/034f1c5589644a6b42f50bf61b1628a1c5607fd9\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1811.09362\",\"authors\":[{\"authorId\":null,\"name\":\"Yansen Wang\"},{\"authorId\":null,\"name\":\"Ying Shen\"},{\"authorId\":\"49293070\",\"name\":\"Zhun Liu\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1609/aaai.v33i01.33017216\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5d9273f34a6418c0291dd63f89810896962289e2\",\"title\":\"Words Can Shift: Dynamically Adjusting Word Representations Using Nonverbal Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/5d9273f34a6418c0291dd63f89810896962289e2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1812.07809\",\"authors\":[{\"authorId\":\"144008479\",\"name\":\"H. Pham\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2632776\",\"name\":\"Thomas Manzini\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"}],\"doi\":\"10.1609/aaai.v33i01.33016892\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d581e8fd6bb0c1eccb88084bf281beb4f94358c7\",\"title\":\"Found in Translation: Learning Robust Joint Representations by Cyclic Translations Between Modalities\",\"url\":\"https://www.semanticscholar.org/paper/d581e8fd6bb0c1eccb88084bf281beb4f94358c7\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"143913738\",\"name\":\"S. Fern\\u00e1ndez\"},{\"authorId\":\"145842938\",\"name\":\"F. Gomez\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1145/1143844.1143891\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96494e722f58705fa20302fe6179d483f52705b4\",\"title\":\"Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/96494e722f58705fa20302fe6179d483f52705b4\",\"venue\":\"ICML '06\",\"year\":2006},{\"arxivId\":\"1808.08946\",\"authors\":[{\"authorId\":\"2786820\",\"name\":\"Gongbo Tang\"},{\"authorId\":\"144529826\",\"name\":\"M. M\\u00fcller\"},{\"authorId\":\"40659617\",\"name\":\"Annette Rios Gonzales\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"}],\"doi\":\"10.18653/v1/D18-1458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3ee61f49cd2639c15c8662a45f1d0c2b83a60c1\",\"title\":\"Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e3ee61f49cd2639c15c8662a45f1d0c2b83a60c1\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1809.10853\",\"authors\":[{\"authorId\":\"51428394\",\"name\":\"Alexei Baevski\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d170bd486e4c0fe82601e322b0e9e0dde63ab299\",\"title\":\"Adaptive Input Representations for Neural Language Modeling\",\"url\":\"https://www.semanticscholar.org/paper/d170bd486e4c0fe82601e322b0e9e0dde63ab299\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1703.03130\",\"authors\":[{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"2521552\",\"name\":\"Minwei Feng\"},{\"authorId\":\"1790831\",\"name\":\"C. D. Santos\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144028698\",\"name\":\"B. Xiang\"},{\"authorId\":\"145218984\",\"name\":\"Bowen Zhou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204a4a70428f3938d2c538a4d74c7ae0416306d8\",\"title\":\"A Structured Self-attentive Sentence Embedding\",\"url\":\"https://www.semanticscholar.org/paper/204a4a70428f3938d2c538a4d74c7ae0416306d8\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaolong Wang\"},{\"authorId\":null,\"name\":\"Ross Girshick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Abhinav Gupta, and Kaiming He\",\"url\":\"\",\"venue\":\"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21451088\",\"name\":\"P. Ekman\"},{\"authorId\":\"115865607\",\"name\":\"Wallace V. Freisen\"},{\"authorId\":\"6929961\",\"name\":\"S. Ancoli\"}],\"doi\":\"10.1037/H0077722\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98b41e682c80232be7a7741f46404a6118e19fc2\",\"title\":\"Facial signs of emotional experience.\",\"url\":\"https://www.semanticscholar.org/paper/98b41e682c80232be7a7741f46404a6118e19fc2\",\"venue\":\"\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1501.02598\",\"authors\":[{\"authorId\":\"2672644\",\"name\":\"A. Lazaridou\"},{\"authorId\":\"2702980\",\"name\":\"N. Pham\"},{\"authorId\":\"145283199\",\"name\":\"M. Baroni\"}],\"doi\":\"10.3115/v1/N15-1016\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfa8790b6463cbd8e50d746e03e4c161e1920cf1\",\"title\":\"Combining Language and Vision with a Multimodal Skip-gram Model\",\"url\":\"https://www.semanticscholar.org/paper/dfa8790b6463cbd8e50d746e03e4c161e1920cf1\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145169923\",\"name\":\"I. Sheikh\"},{\"authorId\":\"2824588\",\"name\":\"Sri Harsha Dumpala\"},{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":\"10.18653/v1/W18-3305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a42e66bc97e21d6a0f050f7d8899b509b00bd0b1\",\"title\":\"Sentiment Analysis using Imperfect Views from Spoken Language and Acoustic Modalities\",\"url\":\"https://www.semanticscholar.org/paper/a42e66bc97e21d6a0f050f7d8899b509b00bd0b1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1606.01933\",\"authors\":[{\"authorId\":\"144729897\",\"name\":\"Ankur P. Parikh\"},{\"authorId\":\"2556289\",\"name\":\"Oscar T\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"143790066\",\"name\":\"Dipanjan Das\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"}],\"doi\":\"10.18653/v1/D16-1244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cd8e8f510c89c7c18268e8ad51c061e459ad321\",\"title\":\"A Decomposable Attention Model for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/2cd8e8f510c89c7c18268e8ad51c061e459ad321\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33366691\",\"name\":\"Jiahong Yuan\"},{\"authorId\":\"144173823\",\"name\":\"M. Liberman\"}],\"doi\":\"10.1121/1.2935783\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"title\":\"Speaker identification on the SCOTUS corpus\",\"url\":\"https://www.semanticscholar.org/paper/5e5ed888bd2f603ada808a571a3f0d1d91dae7be\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1804.09849\",\"authors\":[{\"authorId\":\"41019659\",\"name\":\"M. Chen\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"},{\"authorId\":\"12295226\",\"name\":\"Ankur Bapna\"},{\"authorId\":\"153535452\",\"name\":\"Melvin Johnson\"},{\"authorId\":\"3153147\",\"name\":\"Wolfgang Macherey\"},{\"authorId\":\"83536236\",\"name\":\"G. Foster\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"46503039\",\"name\":\"M. Schuster\"},{\"authorId\":\"115023819\",\"name\":\"Zhi-Feng Chen\"},{\"authorId\":\"48607963\",\"name\":\"Yonghui Wu\"},{\"authorId\":\"48342565\",\"name\":\"Macduff Hughes\"}],\"doi\":\"10.18653/v1/P18-1008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb669de2fce407df2f5cb2f8c51dedee3f467e04\",\"title\":\"The Best of Both Worlds: Combining Recent Advances in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/bb669de2fce407df2f5cb2f8c51dedee3f467e04\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Amir Zadeh\"},{\"authorId\":null,\"name\":\"Paul Pu Liang\"},{\"authorId\":null,\"name\":\"Navonil Mazumder\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Soujanya Poria, Erik Cambria, and Louis-Philippe Morency. 2018a. Memory fusion network for multiview sequential learning\",\"url\":\"\",\"venue\":\"Thirty-Second AAAI Conference on Artificial Intelligence\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Carlos Busso\"},{\"authorId\":null,\"name\":\"Murtaza Bulut\"},{\"authorId\":null,\"name\":\"Chi-Chun Lee\"},{\"authorId\":null,\"name\":\"Abe Kazemzadeh\"},{\"authorId\":null,\"name\":\"Emily Mower\"},{\"authorId\":null,\"name\":\"Samuel Kim\"},{\"authorId\":null,\"name\":\"Jeannette N Chang\"},{\"authorId\":null,\"name\":\"Sungbok Lee\"},{\"authorId\":null,\"name\":\"Shrikanth S Narayanan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Iemocap: Interactive emotional\",\"url\":\"\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1802.00927\",\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"37052144\",\"name\":\"N. Mazumder\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"49943757\",\"name\":\"E. Cambria\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"609512f19e06bf393cb79fbf57183f75b8d889d2\",\"title\":\"Memory Fusion Network for Multi-view Sequential Learning\",\"url\":\"https://www.semanticscholar.org/paper/609512f19e06bf393cb79fbf57183f75b8d889d2\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1803.02155\",\"authors\":[{\"authorId\":\"38759328\",\"name\":\"Peter Shaw\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"}],\"doi\":\"10.18653/v1/N18-2074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8efcc854d97dfc2a42b83316a2109f9d166e43f\",\"title\":\"Self-Attention with Relative Position Representations\",\"url\":\"https://www.semanticscholar.org/paper/c8efcc854d97dfc2a42b83316a2109f9d166e43f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5726c7b40fcc454b77d989656c085520bf6c15fa\",\"title\":\"Multimodal learning with deep Boltzmann machines\",\"url\":\"https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1808.03920\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"12907562\",\"name\":\"Liu Ziyin\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D18-1014\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"title\":\"Multimodal Language Analysis with Recurrent Multistage Fusion\",\"url\":\"https://www.semanticscholar.org/paper/a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2106794\",\"name\":\"C. Busso\"},{\"authorId\":\"38816202\",\"name\":\"M. Bulut\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"},{\"authorId\":\"1764265\",\"name\":\"A. Kazemzadeh\"},{\"authorId\":\"2523983\",\"name\":\"E. Provost\"},{\"authorId\":\"48388640\",\"name\":\"S. Kim\"},{\"authorId\":\"2522842\",\"name\":\"J. N. Chang\"},{\"authorId\":\"1797399\",\"name\":\"S. Lee\"},{\"authorId\":\"145254843\",\"name\":\"Shrikanth S. Narayanan\"}],\"doi\":\"10.1007/s10579-008-9076-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5cf0d213f3253cd46673d955209f8463db73cc51\",\"title\":\"IEMOCAP: interactive emotional dyadic motion capture database\",\"url\":\"https://www.semanticscholar.org/paper/5cf0d213f3253cd46673d955209f8463db73cc51\",\"venue\":\"Lang. Resour. Evaluation\",\"year\":2008},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1804.08199\",\"authors\":[{\"authorId\":\"2268272\",\"name\":\"Emma Strubell\"},{\"authorId\":\"2986975\",\"name\":\"Pat Verga\"},{\"authorId\":\"3365603\",\"name\":\"Daniel Andor\"},{\"authorId\":\"145045509\",\"name\":\"D. Weiss\"},{\"authorId\":\"143753639\",\"name\":\"A. McCallum\"}],\"doi\":\"10.18653/v1/D18-1548\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"060ff1aad5619a7d6d6cdfaf8be5da29bff3808c\",\"title\":\"Linguistically-Informed Self-Attention for Semantic Role Labeling\",\"url\":\"https://www.semanticscholar.org/paper/060ff1aad5619a7d6d6cdfaf8be5da29bff3808c\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422912\",\"name\":\"Zihang Dai\"},{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"143712374\",\"name\":\"J. Carbonell\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7822238f5db7d62731eaeabf9725a65f4edf893\",\"title\":\"Transformer-XL: Language Modeling with Longer-Term Dependency\",\"url\":\"https://www.semanticscholar.org/paper/a7822238f5db7d62731eaeabf9725a65f4edf893\",\"venue\":\"\",\"year\":2018}],\"title\":\"Multimodal Transformer for Unaligned Multimodal Language Sequences\",\"topics\":[{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Time series\",\"topicId\":\"1293\",\"url\":\"https://www.semanticscholar.org/topic/1293\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Sampling (signal processing)\",\"topicId\":\"7839\",\"url\":\"https://www.semanticscholar.org/topic/7839\"},{\"topic\":\"Predicate transformer semantics\",\"topicId\":\"340653\",\"url\":\"https://www.semanticscholar.org/topic/340653\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"}],\"url\":\"https://www.semanticscholar.org/paper/949fef650da4c41afe6049a183b504b3cc91f4bd\",\"venue\":\"ACL\",\"year\":2019}\n"