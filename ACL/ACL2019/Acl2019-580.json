"{\"abstract\":\"Multi-head self-attention is a key component of the Transformer, a state-of-the-art architecture for neural machine translation. In this work we evaluate the contribution made by individual attention heads to the overall performance of the model and analyze the roles played by them in the encoder. We find that the most important and confident heads play consistent and often linguistically-interpretable roles. When pruning heads using a method based on stochastic gates and a differentiable relaxation of the L0 penalty, we observe that specialized heads are last to be pruned. Our novel pruning method removes the vast majority of heads without seriously affecting performance. For example, on the English-Russian WMT dataset, pruning 38 out of 48 encoder heads results in a drop of only 0.15 BLEU.\",\"arxivId\":\"1905.09418\",\"authors\":[{\"authorId\":\"46235299\",\"name\":\"Elena Voita\",\"url\":\"https://www.semanticscholar.org/author/46235299\"},{\"authorId\":\"144251066\",\"name\":\"David Talbot\",\"url\":\"https://www.semanticscholar.org/author/144251066\"},{\"authorId\":\"2157158\",\"name\":\"F. Moiseev\",\"url\":\"https://www.semanticscholar.org/author/2157158\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\",\"url\":\"https://www.semanticscholar.org/author/2082372\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\",\"url\":\"https://www.semanticscholar.org/author/144889265\"}],\"citationVelocity\":88,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"51065291\",\"name\":\"Dagmawi Moges\"},{\"authorId\":\"144956396\",\"name\":\"H. Qu\"},{\"authorId\":\"51066540\",\"name\":\"Mingsheng Fu\"}],\"doi\":\"10.1145/3373419.3373430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"473c1a96516a02cca3738af68c808f7d8ff4bead\",\"title\":\"Multi-Head Bidirectional Attention for MRC\",\"url\":\"https://www.semanticscholar.org/paper/473c1a96516a02cca3738af68c808f7d8ff4bead\",\"venue\":\"ICAIP 2019\",\"year\":2019},{\"arxivId\":\"2004.14788\",\"authors\":[{\"authorId\":\"1663413126\",\"name\":\"Yingqiang Gao\"},{\"authorId\":\"32160741\",\"name\":\"Nikola I. Nikolov\"},{\"authorId\":\"1654100733\",\"name\":\"Yuhuang Hu\"},{\"authorId\":\"2391278\",\"name\":\"R. Hahnloser\"}],\"doi\":\"10.18653/v1/2020.acl-main.145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d92905edc1a5d027b0827d1309bc6ac03dd94a0\",\"title\":\"Character-Level Translation with Self-attention\",\"url\":\"https://www.semanticscholar.org/paper/9d92905edc1a5d027b0827d1309bc6ac03dd94a0\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"ON LIANCE\"},{\"authorId\":null,\"name\":\"SPURIOUS HEURISTICS\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1150ac706d66dfdf3cdbb77212ee6f68cef44066\",\"title\":\"INFORMATION-THEORETIC PROBING EXPLAINS RE-\",\"url\":\"https://www.semanticscholar.org/paper/1150ac706d66dfdf3cdbb77212ee6f68cef44066\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1872287\",\"name\":\"P. Bahar\"},{\"authorId\":\"50103291\",\"name\":\"N. Makarov\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7a3ce4cb265f20b45df832276ae14845ef0b90f2\",\"title\":\"Investigation of Transformer-based Latent Attention Models for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/7a3ce4cb265f20b45df832276ae14845ef0b90f2\",\"venue\":\"AMTA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22388629\",\"name\":\"Johannes Gontrum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22fa2c4817ca2b7a5cecdaeb6c563af4a4f9e607\",\"title\":\"Attention Mechanisms for Transition-based Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/22fa2c4817ca2b7a5cecdaeb6c563af4a4f9e607\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.12812\",\"authors\":[{\"authorId\":\"123247172\",\"name\":\"W. Zhang\"},{\"authorId\":\"48557122\",\"name\":\"L. Hou\"},{\"authorId\":\"1384668226\",\"name\":\"Y. Yin\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"93552134\",\"name\":\"X. Chen\"},{\"authorId\":\"48324350\",\"name\":\"X. Jiang\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"097210dc65924f8ce59523faf444e635523dc714\",\"title\":\"TernaryBERT: Distillation-aware Ultra-low Bit BERT\",\"url\":\"https://www.semanticscholar.org/paper/097210dc65924f8ce59523faf444e635523dc714\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.00943\",\"authors\":[{\"authorId\":\"1572108401\",\"name\":\"Yue Guan\"},{\"authorId\":\"1831521\",\"name\":\"Jingwen Leng\"},{\"authorId\":\"1471427600\",\"name\":\"Chao Li\"},{\"authorId\":\"1596812259\",\"name\":\"Quan Chen\"},{\"authorId\":\"1697293\",\"name\":\"M. Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab8ec9583db0f1bb28b59c992cd035bc7928f04\",\"title\":\"How Far Does BERT Look At: Distance-based Clustering and Analysis of BERT's Attention\",\"url\":\"https://www.semanticscholar.org/paper/1ab8ec9583db0f1bb28b59c992cd035bc7928f04\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387975397\",\"name\":\"Matan Ben Noach\"},{\"authorId\":\"2024602005\",\"name\":\"Yoav Goldberg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b60a16d2978b10ead102a6a6cd03dc940b1194cc\",\"title\":\"Compressing Pre-trained Language Models by Matrix Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/b60a16d2978b10ead102a6a6cd03dc940b1194cc\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2005.00561\",\"authors\":[{\"authorId\":\"145816991\",\"name\":\"Sai Prasanna\"},{\"authorId\":\"145046059\",\"name\":\"Anna Rogers\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.259\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"91ac65431b2dc46919e1673fde67671c29446812\",\"title\":\"When BERT Plays the Lottery, All Tickets Are Winning\",\"url\":\"https://www.semanticscholar.org/paper/91ac65431b2dc46919e1673fde67671c29446812\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145646923\",\"name\":\"Harsh V. P. Singh\"},{\"authorId\":\"1718287\",\"name\":\"Q. Mahmoud\"}],\"doi\":\"10.1109/SMC42975.2020.9283392\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2148d2bd13dc45f7047ad3fa4622b73a5f562649\",\"title\":\"Human-in-the-Loop Error Precursor Detection using Language Translation Modeling of HMI States\",\"url\":\"https://www.semanticscholar.org/paper/2148d2bd13dc45f7047ad3fa4622b73a5f562649\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1910.04732\",\"authors\":[{\"authorId\":\"2860279\",\"name\":\"Ziheng Wang\"},{\"authorId\":\"39749986\",\"name\":\"Jeremy Wohlwend\"},{\"authorId\":\"151480189\",\"name\":\"Tao Lei\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.496\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83b8108014e3db4f46354a28ae68193f143c4e7e\",\"title\":\"Structured Pruning of Large Language Models\",\"url\":\"https://www.semanticscholar.org/paper/83b8108014e3db4f46354a28ae68193f143c4e7e\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41129651\",\"name\":\"Maximiliana Behnke\"},{\"authorId\":\"1702066\",\"name\":\"Kenneth Heafield\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.211\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"6346222f4d308dad8e716e0fd33be470f6e94cbb\",\"title\":\"Losing Heads in the Lottery: Pruning Transformer Attention in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/6346222f4d308dad8e716e0fd33be470f6e94cbb\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.01063\",\"authors\":[{\"authorId\":\"1666636295\",\"name\":\"Tomasz Limisiewicz\"},{\"authorId\":\"2536245\",\"name\":\"D. Marecek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e25c85054084b33091d40aedb5dc063195dc33ee\",\"title\":\"Syntax Representation in Word Embeddings and Neural Networks - A Survey\",\"url\":\"https://www.semanticscholar.org/paper/e25c85054084b33091d40aedb5dc063195dc33ee\",\"venue\":\"ITAT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144861196\",\"name\":\"Zhao Meng\"},{\"authorId\":\"1753528574\",\"name\":\"Shengwei Tian\"},{\"authorId\":\"1628955351\",\"name\":\"L. Yu\"}],\"doi\":\"10.3103/S0146411620040082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74f93295bea5962fb54eec5317381f2487e8cfc8\",\"title\":\"Regional Bullying Text Recognition Based on Two-Branch Parallel Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/74f93295bea5962fb54eec5317381f2487e8cfc8\",\"venue\":\"Autom. Control. Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2004.13805\",\"authors\":[{\"authorId\":\"5041757\",\"name\":\"Taeuk Kim\"},{\"authorId\":\"49730060\",\"name\":\"B. Li\"},{\"authorId\":\"3013044\",\"name\":\"Sanggoo Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1e292f83fb88eafa618f61b155ce089a5515d2e\",\"title\":\"Chart-based Zero-shot Constituency Parsing on Multiple Languages\",\"url\":\"https://www.semanticscholar.org/paper/a1e292f83fb88eafa618f61b155ce089a5515d2e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145646923\",\"name\":\"Harsh V. P. Singh\"},{\"authorId\":\"1718287\",\"name\":\"Q. Mahmoud\"}],\"doi\":\"10.3390/s20113228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a35a1fdc3c8f43b4c97f2902a9b8801eded9f87c\",\"title\":\"NLP-Based Approach for Predicting HMI State Sequences Towards Monitoring Operator Situational Awareness\",\"url\":\"https://www.semanticscholar.org/paper/a35a1fdc3c8f43b4c97f2902a9b8801eded9f87c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40454494\",\"name\":\"Hongyi Cui\"},{\"authorId\":\"101333187\",\"name\":\"S. Iida\"},{\"authorId\":\"150260485\",\"name\":\"Po-Hsuan Hung\"},{\"authorId\":\"1732417\",\"name\":\"T. Utsuro\"},{\"authorId\":\"2364073\",\"name\":\"M. Nagata\"}],\"doi\":\"10.18653/v1/D19-5622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59e3f0fcd07a44fd1293681528209d0b0d78e75e\",\"title\":\"Mixed Multi-Head Self-Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/59e3f0fcd07a44fd1293681528209d0b0d78e75e\",\"venue\":\"NGT@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"2011.03803\",\"authors\":[{\"authorId\":\"7635473\",\"name\":\"Wenxuan Wang\"},{\"authorId\":\"2909321\",\"name\":\"Zhaopeng Tu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ca957919dded903bcddda96a9e3590edbdb230f4\",\"title\":\"Rethinking the Value of Transformer Components\",\"url\":\"https://www.semanticscholar.org/paper/ca957919dded903bcddda96a9e3590edbdb230f4\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2004.13342\",\"authors\":[{\"authorId\":\"150341221\",\"name\":\"Wangchunshu Zhou\"},{\"authorId\":\"50251691\",\"name\":\"Tao Ge\"},{\"authorId\":\"71084877\",\"name\":\"Ke Xu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"899b6014b549cc3703543394ed06fc04bac3e57a\",\"title\":\"Scheduled DropHead: A Regularization Method for Transformer Models\",\"url\":\"https://www.semanticscholar.org/paper/899b6014b549cc3703543394ed06fc04bac3e57a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.05221\",\"authors\":[{\"authorId\":\"46722320\",\"name\":\"Manish Gupta\"},{\"authorId\":\"40039923\",\"name\":\"P. Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0b213367c4d7fe9c1d20eda3f5310266eed0398\",\"title\":\"Compression of Deep Learning Models for Text: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/f0b213367c4d7fe9c1d20eda3f5310266eed0398\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15222\",\"authors\":[{\"authorId\":\"2056908\",\"name\":\"J. Vig\"},{\"authorId\":\"145822841\",\"name\":\"Ali Madani\"},{\"authorId\":\"1697944\",\"name\":\"L. R. Varshney\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"8937909\",\"name\":\"Nazneen Rajani\"}],\"doi\":\"10.1101/2020.06.26.174417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b364917b0c51e91fcf2ab9c1d66a14ed4b44c03\",\"title\":\"BERTology Meets Biology: Interpreting Attention in Protein Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2b364917b0c51e91fcf2ab9c1d66a14ed4b44c03\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.04211\",\"authors\":[{\"authorId\":\"38094934\",\"name\":\"Gino Brunner\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"150973452\",\"name\":\"Dami\\u00e1n Pascual\"},{\"authorId\":\"143944934\",\"name\":\"Oliver Richter\"},{\"authorId\":\"2754495\",\"name\":\"Massimiliano Ciaramita\"},{\"authorId\":\"1716440\",\"name\":\"Roger Wattenhofer\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"9ece2c9e721149714206da48eebd955fb1278976\",\"title\":\"On Identifiability in Transformers\",\"url\":\"https://www.semanticscholar.org/paper/9ece2c9e721149714206da48eebd955fb1278976\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2012.09852\",\"authors\":[{\"authorId\":\"48017300\",\"name\":\"Hanrui Wang\"},{\"authorId\":\"1391204926\",\"name\":\"Zhekai Zhang\"},{\"authorId\":\"2026636432\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0e2743bd7acaed2a519be2c8fd16bcc88269dc22\",\"title\":\"SpAtten: Efficient Sparse Attention Architecture with Cascade Token and Head Pruning\",\"url\":\"https://www.semanticscholar.org/paper/0e2743bd7acaed2a519be2c8fd16bcc88269dc22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.08593\",\"authors\":[{\"authorId\":\"4009206\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"145020546\",\"name\":\"Alexey Romanov\"},{\"authorId\":\"145046059\",\"name\":\"Anna Rogers\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"}],\"doi\":\"10.18653/v1/D19-1445\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d78aed1dac6656affa4a04cbf225ced11a83d103\",\"title\":\"Revealing the Dark Secrets of BERT\",\"url\":\"https://www.semanticscholar.org/paper/d78aed1dac6656affa4a04cbf225ced11a83d103\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944716241\",\"name\":\"Lifang Ding\"},{\"authorId\":\"3001727\",\"name\":\"Yujiu Yang\"}],\"doi\":\"10.1109/ICBK50248.2020.00066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91e10d89fe5a9c8c43e9a7262bf4756838fa4dd4\",\"title\":\"SDSK2BERT: Explore the Specific Depth with Specific Knowledge to Compress BERT\",\"url\":\"https://www.semanticscholar.org/paper/91e10d89fe5a9c8c43e9a7262bf4756838fa4dd4\",\"venue\":\"2020 IEEE International Conference on Knowledge Graph (ICKG)\",\"year\":2020},{\"arxivId\":\"2006.16362\",\"authors\":[{\"authorId\":\"51440515\",\"name\":\"Jean-Baptiste Cordonnier\"},{\"authorId\":\"1966031\",\"name\":\"Andreas Loukas\"},{\"authorId\":\"2456863\",\"name\":\"M. Jaggi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59f36efc69a1e8077bdc7c5ff61ca7a756bb58e4\",\"title\":\"Multi-Head Attention: Collaborate Instead of Concatenate\",\"url\":\"https://www.semanticscholar.org/paper/59f36efc69a1e8077bdc7c5ff61ca7a756bb58e4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.03557\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"title\":\"VisualBERT: A Simple and Performant Baseline for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/5aec474c31a2f4b74703c6f786c0a8ff85c450da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.07134\",\"authors\":[{\"authorId\":\"38730896\",\"name\":\"Kenton Murray\"},{\"authorId\":\"1380282424\",\"name\":\"Brian DuSell\"},{\"authorId\":\"145287425\",\"name\":\"David Chiang\"}],\"doi\":\"10.18653/v1/D19-5634\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff062507cbaaa267bf5a9991ecc98d2fd7b7a7b3\",\"title\":\"Efficiency through Auto-Sizing: Notre Dame NLP's Submission to the WNGT 2019 Efficiency Task\",\"url\":\"https://www.semanticscholar.org/paper/ff062507cbaaa267bf5a9991ecc98d2fd7b7a7b3\",\"venue\":\"NGT@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"1909.11556\",\"authors\":[{\"authorId\":\"144270981\",\"name\":\"Angela Fan\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1\",\"title\":\"Reducing Transformer Depth on Demand with Structured Dropout\",\"url\":\"https://www.semanticscholar.org/paper/f4a8480cffa491020bdbb8c4c4e7a7e923b1c2c1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1909.09595\",\"authors\":[{\"authorId\":\"10136905\",\"name\":\"Cheonbok Park\"},{\"authorId\":\"1388303435\",\"name\":\"Inyoup Na\"},{\"authorId\":\"1384588855\",\"name\":\"Yongjang Jo\"},{\"authorId\":\"51039306\",\"name\":\"Sungbok Shin\"},{\"authorId\":\"1390446734\",\"name\":\"Jaehyo Yoo\"},{\"authorId\":\"145276140\",\"name\":\"B. Kwon\"},{\"authorId\":\"7818567\",\"name\":\"J. Zhao\"},{\"authorId\":\"2806472\",\"name\":\"H. Noh\"},{\"authorId\":\"2222810\",\"name\":\"Y. Lee\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":\"10.1109/VISUAL.2019.8933677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4e2534eb6473db9712420b43092f4e84d980412\",\"title\":\"SANVis: Visual Analytics for Understanding Self-Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/d4e2534eb6473db9712420b43092f4e84d980412\",\"venue\":\"2019 IEEE Visualization Conference (VIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3384503\",\"name\":\"Jiachen Mao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"4a54a4c8075264f8fc3dd6500499298e328ed3c4\",\"title\":\"Efficient Neural Network Based Systems on Mobile and Cloud Platforms\",\"url\":\"https://www.semanticscholar.org/paper/4a54a4c8075264f8fc3dd6500499298e328ed3c4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48809473\",\"name\":\"Joanna Moubarak\"},{\"authorId\":\"47332949\",\"name\":\"Carole Bassil\"}],\"doi\":\"10.1109/CSNet50428.2020.9265528\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4230f58577a0c84c841c3583fefd57957495981\",\"title\":\"On Darknet HoneyBots\",\"url\":\"https://www.semanticscholar.org/paper/c4230f58577a0c84c841c3583fefd57957495981\",\"venue\":\"2020 4th Cyber Security in Networking Conference (CSNet)\",\"year\":2020},{\"arxivId\":\"2009.09364\",\"authors\":[{\"authorId\":\"49640821\",\"name\":\"Bang An\"},{\"authorId\":\"33777546\",\"name\":\"Jie Lyu\"},{\"authorId\":\"2920297\",\"name\":\"Zhenyi Wang\"},{\"authorId\":\"102514765\",\"name\":\"Chengkun Li\"},{\"authorId\":\"46622514\",\"name\":\"C. Hu\"},{\"authorId\":\"1491233580\",\"name\":\"Fei Tan\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"50819900\",\"name\":\"Yifan Hu\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.17\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ec2e96830c6f41063c47bd0979691d6901938b52\",\"title\":\"Repulsive Attention: Rethinking Multi-head Attention as Bayesian Inference\",\"url\":\"https://www.semanticscholar.org/paper/ec2e96830c6f41063c47bd0979691d6901938b52\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.13313\",\"authors\":[{\"authorId\":\"49715441\",\"name\":\"Luyu Gao\"},{\"authorId\":\"2475437\",\"name\":\"Zhuyun Dai\"},{\"authorId\":\"144987107\",\"name\":\"J. Callan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.342\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76c2b0fe20e1692e0c06b792d5353e0cc0dd33aa\",\"title\":\"Modularized Transfomer-based Ranking Framework\",\"url\":\"https://www.semanticscholar.org/paper/76c2b0fe20e1692e0c06b792d5353e0cc0dd33aa\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2007.00072\",\"authors\":[{\"authorId\":\"152500865\",\"name\":\"A. Ivanov\"},{\"authorId\":\"2134146\",\"name\":\"Nikoli Dryden\"},{\"authorId\":\"1402921119\",\"name\":\"Tal Ben-Nun\"},{\"authorId\":\"1484986152\",\"name\":\"Shigang Li\"},{\"authorId\":\"1713648\",\"name\":\"Torsten Hoefler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb897a4bdc4c1d60a0333a0d0b4c957e480cc3f3\",\"title\":\"Data Movement Is All You Need: A Case Study on Optimizing Transformers\",\"url\":\"https://www.semanticscholar.org/paper/cb897a4bdc4c1d60a0333a0d0b4c957e480cc3f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.11771\",\"authors\":[{\"authorId\":\"2786820\",\"name\":\"Gongbo Tang\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"1720988\",\"name\":\"Joakim Nivre\"}],\"doi\":\"10.18653/v1/d19-1149\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91f0b74abafcb16da6cef417484cbd6405b5c388\",\"title\":\"Encoders Help You Disambiguate Word Senses in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/91f0b74abafcb16da6cef417484cbd6405b5c388\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1909.10351\",\"authors\":[{\"authorId\":\"39706649\",\"name\":\"Xiaoqi Jiao\"},{\"authorId\":\"1384668226\",\"name\":\"Y. Yin\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"145820291\",\"name\":\"Xin Jiang\"},{\"authorId\":\"80112928\",\"name\":\"X. Chen\"},{\"authorId\":\"38690159\",\"name\":\"Linlin Li\"},{\"authorId\":\"49451193\",\"name\":\"F. Wang\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.372\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba116771ec874f6ed8bdb82e263d47d958de0765\",\"title\":\"TinyBERT: Distilling BERT for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/ba116771ec874f6ed8bdb82e263d47d958de0765\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.08271\",\"authors\":[{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"153345698\",\"name\":\"Tianxiang Sun\"},{\"authorId\":\"26339093\",\"name\":\"Yige Xu\"},{\"authorId\":\"95329799\",\"name\":\"Yunfan Shao\"},{\"authorId\":\"145493218\",\"name\":\"Ning Dai\"},{\"authorId\":\"152638818\",\"name\":\"Xuanjing Huang\"}],\"doi\":\"10.1007/s11431-020-1647-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e06b36f1076b3497992b558d7707f053161dc840\",\"title\":\"Pre-trained Models for Natural Language Processing: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/e06b36f1076b3497992b558d7707f053161dc840\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14992\",\"authors\":[{\"authorId\":\"41019080\",\"name\":\"Nicola De Cao\"},{\"authorId\":\"8804828\",\"name\":\"M. Schlichtkrull\"},{\"authorId\":\"2782694\",\"name\":\"W. Aziz\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.262\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ca8d228cc20829fa95a95bfd5f7e92b2d13f9f5a\",\"title\":\"How do Decisions Emerge across Layers in Neural Models? Interpretation with Differentiable Masking\",\"url\":\"https://www.semanticscholar.org/paper/ca8d228cc20829fa95a95bfd5f7e92b2d13f9f5a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1906.06755\",\"authors\":[{\"authorId\":\"46686009\",\"name\":\"Michael Hahn\"}],\"doi\":\"10.1162/tacl_a_00306\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b3564be8b79f25585acb035f3deaf4ae93c26d8f\",\"title\":\"Theoretical Limitations of Self-Attention in Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/b3564be8b79f25585acb035f3deaf4ae93c26d8f\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101333187\",\"name\":\"S. Iida\"},{\"authorId\":\"47810875\",\"name\":\"R. Kimura\"},{\"authorId\":\"40454494\",\"name\":\"Hongyi Cui\"},{\"authorId\":\"150260485\",\"name\":\"Po-Hsuan Hung\"},{\"authorId\":\"1732417\",\"name\":\"T. Utsuro\"},{\"authorId\":\"2364073\",\"name\":\"M. Nagata\"}],\"doi\":\"10.18653/v1/P19-2030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dffed23fd7f2de433073f2453ab65ebc2954863a\",\"title\":\"Attention over Heads: A Multi-Hop Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/dffed23fd7f2de433073f2453ab65ebc2954863a\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2009.14409\",\"authors\":[{\"authorId\":\"49010615\",\"name\":\"Hyun Dong Lee\"},{\"authorId\":\"47090128\",\"name\":\"Seongmin Lee\"},{\"authorId\":\"144252611\",\"name\":\"U. Kang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8628b43972c85127c03bb1623dd3e044277ef5\",\"title\":\"AUBER: Automated BERT Regularization\",\"url\":\"https://www.semanticscholar.org/paper/0d8628b43972c85127c03bb1623dd3e044277ef5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49715441\",\"name\":\"Luyu Gao\"},{\"authorId\":\"2475437\",\"name\":\"Zhuyun Dai\"},{\"authorId\":\"144987107\",\"name\":\"J. Callan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c056f341a1acec0a79beeae75ac2460a55f4249\",\"title\":\"EARL: Speedup Transformer-based Rankers with Pre-computed Representation\",\"url\":\"https://www.semanticscholar.org/paper/8c056f341a1acec0a79beeae75ac2460a55f4249\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11922\",\"authors\":[{\"authorId\":\"2175972\",\"name\":\"T. Ishkhanov\"},{\"authorId\":\"144685269\",\"name\":\"M. Naumov\"},{\"authorId\":\"48283662\",\"name\":\"Xianjie Chen\"},{\"authorId\":\"1818240682\",\"name\":\"Yan Zhu\"},{\"authorId\":\"1491112836\",\"name\":\"Y. Zhong\"},{\"authorId\":\"27754615\",\"name\":\"A. Azzolini\"},{\"authorId\":\"152873559\",\"name\":\"Chonglin Sun\"},{\"authorId\":\"144797862\",\"name\":\"Frank Jiang\"},{\"authorId\":\"143682293\",\"name\":\"A. Malevich\"},{\"authorId\":\"1896557533\",\"name\":\"Liang Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"763197fe1db175ccf5711b241aaf5266aca05de8\",\"title\":\"Time-based Sequence Model for Personalization and Recommendation Systems\",\"url\":\"https://www.semanticscholar.org/paper/763197fe1db175ccf5711b241aaf5266aca05de8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.13270\",\"authors\":[{\"authorId\":\"1405369173\",\"name\":\"Rajiv Movva\"},{\"authorId\":\"1972123165\",\"name\":\"Jason Y. Zhao\"}],\"doi\":\"10.18653/v1/2020.blackboxnlp-1.19\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"8b2067065e67a0952a32894ba5693d2b07ee5516\",\"title\":\"Dissecting Lottery Ticket Transformers: Structural and Behavioral Study of Sparse Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/8b2067065e67a0952a32894ba5693d2b07ee5516\",\"venue\":\"BLACKBOXNLP\",\"year\":2020},{\"arxivId\":\"2002.00737\",\"authors\":[{\"authorId\":\"5041757\",\"name\":\"Taeuk Kim\"},{\"authorId\":\"8889792\",\"name\":\"Jihun Choi\"},{\"authorId\":\"51260853\",\"name\":\"Daniel Edmiston\"},{\"authorId\":\"73124469\",\"name\":\"Sang-goo Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cf8510d5905bd8a63f1e098e05ab591d689e0fd\",\"title\":\"Are Pre-trained Language Models Aware of Phrases? Simple but Strong Baselines for Grammar Induction\",\"url\":\"https://www.semanticscholar.org/paper/7cf8510d5905bd8a63f1e098e05ab591d689e0fd\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2010.02399\",\"authors\":[{\"authorId\":\"33341943\",\"name\":\"Ameet Deshpande\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.419\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d2660faebfcc1b7c7777f48b32a2eebec346bab\",\"title\":\"Guiding Attention for Self-Supervised Learning with Transformers\",\"url\":\"https://www.semanticscholar.org/paper/3d2660faebfcc1b7c7777f48b32a2eebec346bab\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2002.11794\",\"authors\":[{\"authorId\":\"2276422\",\"name\":\"Zhuohan Li\"},{\"authorId\":\"145217343\",\"name\":\"Eric Wallace\"},{\"authorId\":\"2191455\",\"name\":\"Sheng Shen\"},{\"authorId\":\"48085802\",\"name\":\"Kevin Lin\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"144307989\",\"name\":\"J. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2356781b8a98bf94e6fc73798c6cb65ac35e5f97\",\"title\":\"Train Large, Then Compress: Rethinking Model Size for Efficient Training and Inference of Transformers\",\"url\":\"https://www.semanticscholar.org/paper/2356781b8a98bf94e6fc73798c6cb65ac35e5f97\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2010.12821\",\"authors\":[{\"authorId\":\"3351938\",\"name\":\"Hyung Won Chung\"},{\"authorId\":\"79215748\",\"name\":\"Thibault F\\u00e9vry\"},{\"authorId\":\"47890394\",\"name\":\"H. Tsai\"},{\"authorId\":\"49900605\",\"name\":\"M. Johnson\"},{\"authorId\":\"2884561\",\"name\":\"Sebastian Ruder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc87279d4b32a425377ff18ab63f7ecf95ff228c\",\"title\":\"Rethinking embedding coupling in pre-trained language models\",\"url\":\"https://www.semanticscholar.org/paper/bc87279d4b32a425377ff18ab63f7ecf95ff228c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.12246\",\"authors\":[{\"authorId\":\"41022736\",\"name\":\"Phu Mon Htut\"},{\"authorId\":\"80842917\",\"name\":\"Jason Phang\"},{\"authorId\":\"88739501\",\"name\":\"Shikha Bordia\"},{\"authorId\":\"3644767\",\"name\":\"Samuel R. Bowman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ba8215e77f35b0d947c7cec39c45df4516e93421\",\"title\":\"Do Attention Heads in BERT Track Syntactic Dependencies?\",\"url\":\"https://www.semanticscholar.org/paper/ba8215e77f35b0d947c7cec39c45df4516e93421\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.10608\",\"authors\":[{\"authorId\":\"2006017\",\"name\":\"M. Fomicheva\"},{\"authorId\":\"47392899\",\"name\":\"Shuo Sun\"},{\"authorId\":\"78447404\",\"name\":\"L. Yankovskaya\"},{\"authorId\":\"1948646\",\"name\":\"F. Blain\"},{\"authorId\":\"144204682\",\"name\":\"Francisco Guzm\\u00e1n\"},{\"authorId\":\"2032659\",\"name\":\"M. Fishel\"},{\"authorId\":\"3238627\",\"name\":\"Nikolaos Aletras\"},{\"authorId\":\"113810201\",\"name\":\"Vishrav Chaudhary\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1162/tacl_a_00330\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"de22a52eb09c64fb3b80044c2e56659bcc1aa264\",\"title\":\"Unsupervised Quality Estimation for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/de22a52eb09c64fb3b80044c2e56659bcc1aa264\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2020},{\"arxivId\":\"2012.14768\",\"authors\":[{\"authorId\":null,\"name\":\"Xuebo Liu\"},{\"authorId\":\"1800190\",\"name\":\"Longyue Wang\"},{\"authorId\":\"1758353\",\"name\":\"Derek F. Wong\"},{\"authorId\":\"46573238\",\"name\":\"Liang Ding\"},{\"authorId\":\"1774304\",\"name\":\"Lidia S. Chao\"},{\"authorId\":\"2909321\",\"name\":\"Zhaopeng Tu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ee27d4df0a0e7032c520cb5f26567fb06769ad1\",\"title\":\"Understanding and Improving Encoder Layer Fusion in Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ee27d4df0a0e7032c520cb5f26567fb06769ad1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51888120\",\"name\":\"Gr\\u00e9goire Mialon\"},{\"authorId\":\"81299639\",\"name\":\"Dexiong Chen\"},{\"authorId\":\"1387902104\",\"name\":\"A. d'Aspremont\"},{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b553e7bda1b25fa9f1d4c24bd541d1389b129eb0\",\"title\":\"An Optimal Transport Kernel for Feature Aggregation and its Relationship to Attention\",\"url\":\"https://www.semanticscholar.org/paper/b553e7bda1b25fa9f1d4c24bd541d1389b129eb0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122281127\",\"name\":\"Timothee Mickus\"},{\"authorId\":\"2129425\",\"name\":\"D. Paperno\"},{\"authorId\":\"46180911\",\"name\":\"M. Constant\"},{\"authorId\":\"47753345\",\"name\":\"Kees van Deemter\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"a05a614dc4c39a15f708149aa653fa1b696e928d\",\"title\":\"What do you mean, BERT?\",\"url\":\"https://www.semanticscholar.org/paper/a05a614dc4c39a15f708149aa653fa1b696e928d\",\"venue\":\"SCIL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491241715\",\"name\":\"Swapnil Bhosale\"},{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054621\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e49d70d05590093c019aeb83a153e06379607958\",\"title\":\"Deep Encoded Linguistic and Acoustic Cues for Attention Based End to End Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e49d70d05590093c019aeb83a153e06379607958\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb1a989e98b79fdeb8ff9175710b0d9699ceff9c\",\"title\":\"Exploring Human-like Learning Capabilities of Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/fb1a989e98b79fdeb8ff9175710b0d9699ceff9c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144508458\",\"name\":\"Da Yin\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":\"10.18653/v1/2020.acl-main.469\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"title\":\"What Does BERT with Vision Look At?\",\"url\":\"https://www.semanticscholar.org/paper/cdcdc7ab1f5b6e86146b5c0224cba7d8cd35142c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1911.05758\",\"authors\":[{\"authorId\":\"122281127\",\"name\":\"Timothee Mickus\"},{\"authorId\":\"2129425\",\"name\":\"D. Paperno\"},{\"authorId\":\"46180911\",\"name\":\"M. Constant\"},{\"authorId\":\"1789347\",\"name\":\"Kees van Deemter\"}],\"doi\":\"10.7275/t778-ja71\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"563e2fdcae3f3b6d7f20fac343276737bebc9633\",\"title\":\"What do you mean, BERT? Assessing BERT as a Distributional Semantics Model\",\"url\":\"https://www.semanticscholar.org/paper/563e2fdcae3f3b6d7f20fac343276737bebc9633\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.05315\",\"authors\":[{\"authorId\":\"1432234296\",\"name\":\"Giannis Daras\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"1718469\",\"name\":\"A. Dimakis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0f709acf38eb27702b0fbce1215db0ebaa2de2b\",\"title\":\"SMYRF: Efficient Attention using Asymmetric Clustering\",\"url\":\"https://www.semanticscholar.org/paper/c0f709acf38eb27702b0fbce1215db0ebaa2de2b\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.02648\",\"authors\":[{\"authorId\":\"46285635\",\"name\":\"Yilin Yang\"},{\"authorId\":\"1800190\",\"name\":\"Longyue Wang\"},{\"authorId\":\"34720053\",\"name\":\"Shuming Shi\"},{\"authorId\":\"1729906\",\"name\":\"P. Tadepalli\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2909321\",\"name\":\"Zhaopeng Tu\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.432\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f257e1c1d10a4d8388cc132a51351e1b5e594576\",\"title\":\"On the Sub-Layer Functionalities of Transformer Decoder\",\"url\":\"https://www.semanticscholar.org/paper/f257e1c1d10a4d8388cc132a51351e1b5e594576\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.04004\",\"authors\":[{\"authorId\":\"15660960\",\"name\":\"S. Zhang\"},{\"authorId\":\"2791396\",\"name\":\"Erfan Loweimi\"},{\"authorId\":\"2124937\",\"name\":\"P. Bell\"},{\"authorId\":\"153725670\",\"name\":\"Steve Renals\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"155b80a886583b957e2f05331ed86f2652edcac4\",\"title\":\"Stochastic Attention Head Removal: A Simple and Effective Method for Improving Automatic Speech Recognition with Transformers\",\"url\":\"https://www.semanticscholar.org/paper/155b80a886583b957e2f05331ed86f2652edcac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10907\",\"authors\":[{\"authorId\":\"46235299\",\"name\":\"Elena Voita\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"e5a04572370baad44fc9c312f44029b47e3143fd\",\"title\":\"Analyzing the Source and Target Contributions to Predictions in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/e5a04572370baad44fc9c312f44029b47e3143fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.04341\",\"authors\":[{\"authorId\":\"144358401\",\"name\":\"Kevin Clark\"},{\"authorId\":\"3030219\",\"name\":\"Urvashi Khandelwal\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/W19-4828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95a251513853c6032bdecebd4b74e15795662986\",\"title\":\"What Does BERT Look At? An Analysis of BERT's Attention\",\"url\":\"https://www.semanticscholar.org/paper/95a251513853c6032bdecebd4b74e15795662986\",\"venue\":\"ACL 2019\",\"year\":2019},{\"arxivId\":\"2003.12298\",\"authors\":[{\"authorId\":\"46235299\",\"name\":\"Elena Voita\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.14\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f4b585c9a79dfce0807b445a09036ea0f9cbcdce\",\"title\":\"Information-Theoretic Probing with Minimum Description Length\",\"url\":\"https://www.semanticscholar.org/paper/f4b585c9a79dfce0807b445a09036ea0f9cbcdce\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.07310\",\"authors\":[{\"authorId\":\"1701219797\",\"name\":\"Jize Cao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"46700583\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1007/978-3-030-58539-6_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26cfb57a9722599b361858d454ec816420723e36\",\"title\":\"Behind the Scene: Revealing the Secrets of Pre-trained Vision-and-Language Models\",\"url\":\"https://www.semanticscholar.org/paper/26cfb57a9722599b361858d454ec816420723e36\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.04152\",\"authors\":[{\"authorId\":\"150341221\",\"name\":\"Wangchunshu Zhou\"},{\"authorId\":\"66247317\",\"name\":\"Canwen Xu\"},{\"authorId\":\"50251691\",\"name\":\"Tao Ge\"},{\"authorId\":\"35660011\",\"name\":\"Julian McAuley\"},{\"authorId\":\"71084877\",\"name\":\"Ke Xu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4abdbcf983f78cf3f5bf6e2032503f0e534f6ca8\",\"title\":\"BERT Loses Patience: Fast and Robust Inference with Early Exit\",\"url\":\"https://www.semanticscholar.org/paper/4abdbcf983f78cf3f5bf6e2032503f0e534f6ca8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3444222\",\"name\":\"Nikolay Bogoychev\"},{\"authorId\":\"3272639\",\"name\":\"Roman Grundkiewicz\"},{\"authorId\":\"1805992699\",\"name\":\"Alham Fikri Aji\"},{\"authorId\":\"41129651\",\"name\":\"Maximiliana Behnke\"},{\"authorId\":\"1702066\",\"name\":\"Kenneth Heafield\"},{\"authorId\":\"31922245\",\"name\":\"Sidharth N. Kashyap\"},{\"authorId\":\"1805992488\",\"name\":\"Emmanouil-Ioannis Farsarakis\"},{\"authorId\":\"103104646\",\"name\":\"M. Chudyk\"}],\"doi\":\"10.18653/v1/2020.ngt-1.26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e80e3904acad72dceeafa46f105466dbd67a00c7\",\"title\":\"Edinburgh's Submissions to the 2020 Machine Translation Efficiency Task\",\"url\":\"https://www.semanticscholar.org/paper/e80e3904acad72dceeafa46f105466dbd67a00c7\",\"venue\":\"NGT@ACL\",\"year\":2020},{\"arxivId\":\"1912.06638\",\"authors\":[{\"authorId\":\"153307102\",\"name\":\"J. Tian\"},{\"authorId\":\"1724568\",\"name\":\"A. Kreuzer\"},{\"authorId\":\"1466483565\",\"name\":\"Pai-Hung Chen\"},{\"authorId\":\"1468639651\",\"name\":\"Hans-Martin Will\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e447e3e3584dbcccf7904bf17c7c0e6b1d2f976\",\"title\":\"WaLDORf: Wasteless Language-model Distillation On Reading-comprehension\",\"url\":\"https://www.semanticscholar.org/paper/1e447e3e3584dbcccf7904bf17c7c0e6b1d2f976\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.00740\",\"authors\":[{\"authorId\":\"51153248\",\"name\":\"Kaiji Lu\"},{\"authorId\":\"47197501\",\"name\":\"Z. Wang\"},{\"authorId\":\"3251561\",\"name\":\"Piotr Mardziel\"},{\"authorId\":\"7207306\",\"name\":\"Anupam Datta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"052ea761dfc1ea0e5891e92d9b18401e77d5f48e\",\"title\":\"Abstracting Influence Paths for Explaining (Contextualization of) BERT Models\",\"url\":\"https://www.semanticscholar.org/paper/052ea761dfc1ea0e5891e92d9b18401e77d5f48e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06993\",\"authors\":[{\"authorId\":\"145268909\",\"name\":\"A. Chumachenko\"},{\"authorId\":\"48418468\",\"name\":\"Daniil Gavrilov\"},{\"authorId\":\"9416016\",\"name\":\"Pavel Kalaidin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8b97e063d66fbf8a49b33a7b43efdd4fe677ae3\",\"title\":\"Weight Squeezing: Reparameterization for Compression and Fast Inference\",\"url\":\"https://www.semanticscholar.org/paper/f8b97e063d66fbf8a49b33a7b43efdd4fe677ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05828\",\"authors\":[{\"authorId\":\"1876624327\",\"name\":\"Madhura Pande\"},{\"authorId\":\"1877157182\",\"name\":\"Aakriti Budhraja\"},{\"authorId\":\"9192775\",\"name\":\"Preksha Nema\"},{\"authorId\":\"1629793734\",\"name\":\"P. Kumar\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"3688c76d7e538094db2db92a637b1ac73c686c9a\",\"title\":\"On the Importance of Local Information in Transformer Based Models\",\"url\":\"https://www.semanticscholar.org/paper/3688c76d7e538094db2db92a637b1ac73c686c9a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.11793\",\"authors\":[{\"authorId\":\"26954782\",\"name\":\"Guangxiao Song\"},{\"authorId\":\"35760122\",\"name\":\"Yu Sun\"},{\"authorId\":\"48211420\",\"name\":\"Jiaming Liu\"},{\"authorId\":\"51198133\",\"name\":\"Zhijie Wang\"},{\"authorId\":\"2802415\",\"name\":\"Ulugbek S. Kamilov\"}],\"doi\":\"10.1109/LSP.2020.2977214\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4476b4e5fe98a591eb6799434c67aec2e8453b3\",\"title\":\"A New Recurrent Plug-and-Play Prior Based on the Multiple Self-Similarity Network\",\"url\":\"https://www.semanticscholar.org/paper/c4476b4e5fe98a591eb6799434c67aec2e8453b3\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2008.10021\",\"authors\":[{\"authorId\":\"1500521876\",\"name\":\"Jinsong Li\"},{\"authorId\":\"47918251\",\"name\":\"Jianhua Peng\"},{\"authorId\":\"47130566\",\"name\":\"Shuxin Liu\"},{\"authorId\":\"1899537601\",\"name\":\"Lintianran Weng\"},{\"authorId\":\"46651452\",\"name\":\"Cong Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dad3dc0df0ccebd29c1355570b08787daba2ce9f\",\"title\":\"TSAM: Temporal Link Prediction in Directed Networks based on Self-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/dad3dc0df0ccebd29c1355570b08787daba2ce9f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.06360\",\"authors\":[{\"authorId\":\"40454673\",\"name\":\"J. Scott McCarley\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffc01ec3d950a54b165b0d6b773ef49e4e354d0c\",\"title\":\"Pruning a BERT-based Question Answering Model\",\"url\":\"https://www.semanticscholar.org/paper/ffc01ec3d950a54b165b0d6b773ef49e4e354d0c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8129718\",\"name\":\"A. F. Aji\"}],\"doi\":\"10.7488/ERA/533\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"195738e88bc86c8115c3d04dcccf854f6c0dffba\",\"title\":\"Approximating neural machine translation for efficiency\",\"url\":\"https://www.semanticscholar.org/paper/195738e88bc86c8115c3d04dcccf854f6c0dffba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.05607\",\"authors\":[{\"authorId\":\"1994065972\",\"name\":\"Jasmijn Bastings\"},{\"authorId\":\"3017324\",\"name\":\"Katja Filippova\"}],\"doi\":\"10.18653/V1/2020.BLACKBOXNLP-1.14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"508884a136a461869be128027950d2aa1778518c\",\"title\":\"The elephant in the interpretability room: Why use attention as explanation when we have saliency methods?\",\"url\":\"https://www.semanticscholar.org/paper/508884a136a461869be128027950d2aa1778518c\",\"venue\":\"BLACKBOXNLP\",\"year\":2020},{\"arxivId\":\"2007.12146\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"},{\"authorId\":\"5153264\",\"name\":\"A. Schwing\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":\"10.1007/978-3-030-58545-7_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"title\":\"Spatially Aware Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/f92dc7d9a61f7b8b5b7cb58f3895541e266ce057\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.14913\",\"authors\":[{\"authorId\":null,\"name\":\"Mor Geva\"},{\"authorId\":null,\"name\":\"Roei Schuster\"},{\"authorId\":null,\"name\":\"Jonathan Berant\"},{\"authorId\":null,\"name\":\"Omer Levy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5faf435630b647959f23feccd8bf5082e888c16\",\"title\":\"Transformer Feed-Forward Layers Are Key-Value Memories\",\"url\":\"https://www.semanticscholar.org/paper/c5faf435630b647959f23feccd8bf5082e888c16\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.03844\",\"authors\":[{\"authorId\":\"50433033\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"1683562\",\"name\":\"Preslav Nakov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2b9955bc08fc5f4ddba73082ddabcfaabdbb4416\",\"title\":\"Poor Man's BERT: Smaller and Faster Transformer Models\",\"url\":\"https://www.semanticscholar.org/paper/2b9955bc08fc5f4ddba73082ddabcfaabdbb4416\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12327\",\"authors\":[{\"authorId\":\"145046059\",\"name\":\"Anna Rogers\"},{\"authorId\":\"152176221\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"e9264e8f5bd00cd1609e9a0946d691f635c25cdd\",\"title\":\"A Primer in BERTology: What we know about how BERT works\",\"url\":\"https://www.semanticscholar.org/paper/e9264e8f5bd00cd1609e9a0946d691f635c25cdd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.04284\",\"authors\":[{\"authorId\":\"2056908\",\"name\":\"J. Vig\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":\"10.18653/v1/W19-4808\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a039ea239e37f53a2cb60c68e0a1967994353166\",\"title\":\"Analyzing the Structure of Attention in a Transformer Language Model\",\"url\":\"https://www.semanticscholar.org/paper/a039ea239e37f53a2cb60c68e0a1967994353166\",\"venue\":\"ACL 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35318567\",\"name\":\"Rohan Jha\"},{\"authorId\":\"10727711\",\"name\":\"Charles Lovering\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"237992be146743e9858f8035dbbe92421ff9a889\",\"title\":\"When does data augmentation help generalization in NLP?\",\"url\":\"https://www.semanticscholar.org/paper/237992be146743e9858f8035dbbe92421ff9a889\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02222\",\"authors\":[{\"authorId\":\"145485960\",\"name\":\"Jie Hao\"},{\"authorId\":\"48631170\",\"name\":\"Xing Wang\"},{\"authorId\":\"34720053\",\"name\":\"Shuming Shi\"},{\"authorId\":\"145087095\",\"name\":\"J. Zhang\"},{\"authorId\":\"2909321\",\"name\":\"Zhaopeng Tu\"}],\"doi\":\"10.18653/v1/D19-1082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91066eed5b158e58b004038fcb6cf1186b20791b\",\"title\":\"Multi-Granularity Self-Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/91066eed5b158e58b004038fcb6cf1186b20791b\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2005.06420\",\"authors\":[{\"authorId\":\"46712043\",\"name\":\"J. Henderson\"}],\"doi\":\"10.18653/v1/2020.acl-main.561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c30b8ca9f9f4e03da667314c13cf21a9fad58ebe\",\"title\":\"The Unstoppable Rise of Computational Linguistics in Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/c30b8ca9f9f4e03da667314c13cf21a9fad58ebe\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2001.04686\",\"authors\":[{\"authorId\":\"79846966\",\"name\":\"Amir Hadifar\"},{\"authorId\":\"2630759\",\"name\":\"J. Deleu\"},{\"authorId\":\"2489892\",\"name\":\"Chris Develder\"},{\"authorId\":\"1388296896\",\"name\":\"Thomas Demeester\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"444efc5553f70ae39822a8f0117030f1107fd022\",\"title\":\"Block-wise Dynamic Sparseness\",\"url\":\"https://www.semanticscholar.org/paper/444efc5553f70ae39822a8f0117030f1107fd022\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38094934\",\"name\":\"Gino Brunner\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"150973452\",\"name\":\"Dami\\u00e1n Pascual\"},{\"authorId\":\"143944934\",\"name\":\"Oliver Richter\"},{\"authorId\":\"1716440\",\"name\":\"Roger Wattenhofer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d88b671af49e477e3a0e85014fb853b6d3bd363\",\"title\":\"On the Validity of Self-Attention as Explanation in Transformer Models\",\"url\":\"https://www.semanticscholar.org/paper/2d88b671af49e477e3a0e85014fb853b6d3bd363\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773435\",\"name\":\"Xiaobing Sun\"},{\"authorId\":\"1750913147\",\"name\":\"Wei Lu\"}],\"doi\":\"10.18653/v1/2020.acl-main.312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94e586cd3342940422c0bd01ad7f252db9327394\",\"title\":\"Understanding Attention for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/94e586cd3342940422c0bd01ad7f252db9327394\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145286681\",\"name\":\"Valeriia Bolotova-Baranova\"},{\"authorId\":\"2000577984\",\"name\":\"Vladislav Blinov\"},{\"authorId\":\"1998287201\",\"name\":\"Yukun Zheng\"},{\"authorId\":\"144456145\",\"name\":\"W. Croft\"},{\"authorId\":\"1732541\",\"name\":\"F. Scholer\"},{\"authorId\":\"144721996\",\"name\":\"M. Sanderson\"}],\"doi\":\"10.1145/3340531.3412043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"183d4793bc2237bd7e91457fd2df51e2f94e194c\",\"title\":\"Do People and Neural Nets Pay Attention to the Same Words: Studying Eye-tracking Data for Non-factoid QA Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/183d4793bc2237bd7e91457fd2df51e2f94e194c\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":\"2004.04010\",\"authors\":[{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"50433033\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac416ef1ed5bf6d408c681f603f479e6cb330168\",\"title\":\"Analyzing Redundancy in Pretrained Transformer Models\",\"url\":\"https://www.semanticscholar.org/paper/ac416ef1ed5bf6d408c681f603f479e6cb330168\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.12366\",\"authors\":[{\"authorId\":\"46348958\",\"name\":\"Dongsheng Wang\"},{\"authorId\":\"144613166\",\"name\":\"Casper Hansen\"},{\"authorId\":\"145980035\",\"name\":\"Lucas Chaves Lima\"},{\"authorId\":\"144613163\",\"name\":\"Christian Hansen\"},{\"authorId\":\"1954475\",\"name\":\"Maria Maistro\"},{\"authorId\":\"1707651\",\"name\":\"J. Simonsen\"},{\"authorId\":\"1784800\",\"name\":\"C. Lioma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"859f49079cad7d4804ed8cbf04e26cbc8a3fd638\",\"title\":\"Multi-Head Self-Attention with Role-Guided Masks\",\"url\":\"https://www.semanticscholar.org/paper/859f49079cad7d4804ed8cbf04e26cbc8a3fd638\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.00015\",\"authors\":[{\"authorId\":\"146783606\",\"name\":\"Gon\\u00e7alo M. Correia\"},{\"authorId\":\"2114966\",\"name\":\"Vlad Niculae\"},{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"}],\"doi\":\"10.18653/v1/D19-1223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f6390beca54411b06f3bde424fb983a451789733\",\"title\":\"Adaptively Sparse Transformers\",\"url\":\"https://www.semanticscholar.org/paper/f6390beca54411b06f3bde424fb983a451789733\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1912.00982\",\"authors\":[{\"authorId\":\"50747700\",\"name\":\"Nils Rethmeier\"},{\"authorId\":\"150333998\",\"name\":\"Vageesh Saxena\"},{\"authorId\":\"1736067\",\"name\":\"Isabelle Augenstein\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"2371f6cc3e5a453f406c82f132a4f65b2a5475f7\",\"title\":\"TX-Ray: Quantifying and Explaining Model-Knowledge Transfer in (Un-)Supervised NLP\",\"url\":\"https://www.semanticscholar.org/paper/2371f6cc3e5a453f406c82f132a4f65b2a5475f7\",\"venue\":\"UAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10316631\",\"name\":\"Maksim Podkorytov\"},{\"authorId\":\"65987423\",\"name\":\"Daniel Bis\"},{\"authorId\":\"35696962\",\"name\":\"Jinglun Cai\"},{\"authorId\":\"1978797306\",\"name\":\"Kobra Amirizirtol\"},{\"authorId\":\"48032904\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bd04644c076f0a198e1ec16dfc44e675809ac21\",\"title\":\"Effects of Architecture and Training on Embedding Geometry and Feature Discriminability in BERT\",\"url\":\"https://www.semanticscholar.org/paper/2bd04644c076f0a198e1ec16dfc44e675809ac21\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92846566\",\"name\":\"Jae-young Jo\"},{\"authorId\":\"1754166\",\"name\":\"Sung-Hyon Myaeng\"}],\"doi\":\"10.18653/v1/2020.acl-main.311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b6d03ed66473599ee31872b3cd5ad2ce282371f\",\"title\":\"Roles and Utilization of Attention Heads in Transformer-based Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/5b6d03ed66473599ee31872b3cd5ad2ce282371f\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2009.09672\",\"authors\":[{\"authorId\":\"48064977\",\"name\":\"Zewei Sun\"},{\"authorId\":\"1796216609\",\"name\":\"Shujian Huang\"},{\"authorId\":\"3035069\",\"name\":\"Xin-Yu Dai\"},{\"authorId\":\"1838162\",\"name\":\"Jiajun Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a5f0c96f4aaa6019a5e46e784d9fe5f44f46518\",\"title\":\"Alleviating the Inequality of Attention Heads for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/2a5f0c96f4aaa6019a5e46e784d9fe5f44f46518\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100614864\",\"name\":\"Kai Song\"},{\"authorId\":\"47155350\",\"name\":\"Xiaoqing Zhou\"},{\"authorId\":\"46493312\",\"name\":\"Heng Yu\"},{\"authorId\":\"34227637\",\"name\":\"Zhongqiang Huang\"},{\"authorId\":\"1739211150\",\"name\":\"Yue Zhang\"},{\"authorId\":\"48244965\",\"name\":\"Weihua Luo\"},{\"authorId\":\"134879796\",\"name\":\"Xiangyu Duan\"},{\"authorId\":\"50495554\",\"name\":\"Min Zhang\"}],\"doi\":\"10.1109/TASLP.2020.2998278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1e38fc4c75cfd3bc0b6bde97017b43bfa7e36fd\",\"title\":\"Towards Better Word Alignment in Transformer\",\"url\":\"https://www.semanticscholar.org/paper/c1e38fc4c75cfd3bc0b6bde97017b43bfa7e36fd\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144866658\",\"name\":\"Xin Ning\"},{\"authorId\":\"2890746\",\"name\":\"Weijuan Tian\"},{\"authorId\":\"122009119\",\"name\":\"Weijun Li\"},{\"authorId\":\"80477639\",\"name\":\"Yueyue Lu\"},{\"authorId\":\"1622378586\",\"name\":\"Shuai Nie\"},{\"authorId\":\"35317127\",\"name\":\"Linjun Sun\"},{\"authorId\":\"1625145790\",\"name\":\"Ziheng Chen\"}],\"doi\":\"10.1109/ACCESS.2020.2982782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c79e754407d41904979746fbc8090545c0aeec9\",\"title\":\"BDARS_CapsNet: Bi-Directional Attention Routing Sausage Capsule Network\",\"url\":\"https://www.semanticscholar.org/paper/4c79e754407d41904979746fbc8090545c0aeec9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.00609\",\"authors\":[{\"authorId\":\"1734809795\",\"name\":\"Rajaswa Patil\"},{\"authorId\":\"3180819\",\"name\":\"V. Baths\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68e126d651df2f2277171ce7f29cf2d02926db30\",\"title\":\"CNRL at SemEval-2020 Task 5: Modelling Causal Reasoning in Language with Multi-Head Self-Attention Weights based Counterfactual Detection\",\"url\":\"https://www.semanticscholar.org/paper/68e126d651df2f2277171ce7f29cf2d02926db30\",\"venue\":\"SemEval@COLING\",\"year\":2020},{\"arxivId\":\"2011.00678\",\"authors\":[{\"authorId\":\"93951729\",\"name\":\"Shuhao Gu\"},{\"authorId\":\"1685604483\",\"name\":\"Yang Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b0657ca5a5cf2b2a5e0a8cf8803c8c8e52c3a74\",\"title\":\"Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/9b0657ca5a5cf2b2a5e0a8cf8803c8c8e52c3a74\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2004.14448\",\"authors\":[{\"authorId\":\"1411034322\",\"name\":\"Amil Merchant\"},{\"authorId\":\"1928044\",\"name\":\"Elahe Rahimtoroghi\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"},{\"authorId\":\"6117577\",\"name\":\"Ian Tenney\"}],\"doi\":\"10.18653/v1/2020.blackboxnlp-1.4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b2fd96a52ded7a64f60c1e54f5bb488c787629c0\",\"title\":\"What Happens To BERT Embeddings During Fine-tuning?\",\"url\":\"https://www.semanticscholar.org/paper/b2fd96a52ded7a64f60c1e54f5bb488c787629c0\",\"venue\":\"BLACKBOXNLP\",\"year\":2020},{\"arxivId\":\"2001.10379\",\"authors\":[{\"authorId\":\"51037101\",\"name\":\"Qianyu Guo\"},{\"authorId\":\"39899794\",\"name\":\"Jianzhong Qi\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"247e0a4455da68eb4500a36dbb51233fcbab7812\",\"title\":\"SANST: A Self-Attentive Network for Next Point-of-Interest Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/247e0a4455da68eb4500a36dbb51233fcbab7812\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152500865\",\"name\":\"Andrei Ivanov\"},{\"authorId\":\"2134146\",\"name\":\"Nikoli Dryden\"},{\"authorId\":\"1402921119\",\"name\":\"Tal Ben-Nun\"},{\"authorId\":\"1484986152\",\"name\":\"Shigang Li\"},{\"authorId\":\"1713648\",\"name\":\"Torsten Hoefler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"990d042905b8a41f601d3fdd975bc4051a852bcf\",\"title\":\"Data Movement Is All You Need: A Case Study of Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/990d042905b8a41f601d3fdd975bc4051a852bcf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35318567\",\"name\":\"Rohan Jha\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"46dfd46fb41d56bc77055e436dc969de8df0e76b\",\"title\":\"Data augmentation and the role of hardness for feature learning in NLP\",\"url\":\"https://www.semanticscholar.org/paper/46dfd46fb41d56bc77055e436dc969de8df0e76b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.01055\",\"authors\":[{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"3456894\",\"name\":\"J. Ive\"},{\"authorId\":\"2292466\",\"name\":\"S. Velupillai\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W19-5026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b2ae2a1de566788a6c4af2b2fffa9431a4eb91d\",\"title\":\"Is artificial data useful for biomedical Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/3b2ae2a1de566788a6c4af2b2fffa9431a4eb91d\",\"venue\":\"BioNLP@ACL\",\"year\":2019},{\"arxivId\":\"2010.11859\",\"authors\":[{\"authorId\":\"3444222\",\"name\":\"Nikolay Bogoychev\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0502209e488617681486cfa2566317f407b523b\",\"title\":\"Not all parameters are born equal: Attention is mostly what you need\",\"url\":\"https://www.semanticscholar.org/paper/f0502209e488617681486cfa2566317f407b523b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3244157\",\"name\":\"H. \\u00c7elikkanat\"},{\"authorId\":\"119853017\",\"name\":\"Sami Virpioja\"},{\"authorId\":\"143675545\",\"name\":\"J. Tiedemann\"},{\"authorId\":\"2817917\",\"name\":\"Marianna Apidianaki\"}],\"doi\":\"10.18653/v1/2020.blackboxnlp-1.13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42595cb533b03ad44738102fb0c3cef3e4b5c27c\",\"title\":\"Controlling the Imprint of Passivization and Negation in Contextualized Representations\",\"url\":\"https://www.semanticscholar.org/paper/42595cb533b03ad44738102fb0c3cef3e4b5c27c\",\"venue\":\"BLACKBOXNLP\",\"year\":2020},{\"arxivId\":\"2010.02686\",\"authors\":[{\"authorId\":\"152334478\",\"name\":\"Aina Gar'i Soler\"},{\"authorId\":\"2817917\",\"name\":\"Marianna Apidianaki\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.598\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b71bcf769e7efab90ceba56b9e4f898899538fe\",\"title\":\"BERT Knows Punta Cana is not just beautiful, it's gorgeous: Ranking Scalar Adjectives with Contextualised Representations\",\"url\":\"https://www.semanticscholar.org/paper/5b71bcf769e7efab90ceba56b9e4f898899538fe\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.07453\",\"authors\":[{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"1637298763\",\"name\":\"Gabi Stanovsky\"},{\"authorId\":\"2705113\",\"name\":\"Swabha Swayamdipta\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"1685669\",\"name\":\"N. A. Smith\"}],\"doi\":\"10.18653/v1/2020.acl-main.593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5cc2340766d68ece08bb1520d357bcf8c03ad48\",\"title\":\"The Right Tool for the Job: Matching Model and Instance Complexities\",\"url\":\"https://www.semanticscholar.org/paper/c5cc2340766d68ece08bb1520d357bcf8c03ad48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1910.05276\",\"authors\":[{\"authorId\":\"50716992\",\"name\":\"B. Hoover\"},{\"authorId\":\"2879705\",\"name\":\"Hendrik Strobelt\"},{\"authorId\":\"3159346\",\"name\":\"Sebastian Gehrmann\"}],\"doi\":\"10.18653/v1/2020.acl-demos.22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"327d7e55d64cb34d55bd3a3fe58233c238a312cd\",\"title\":\"exBERT: A Visual Analysis Tool to Explore Learned Representations in Transformers Models\",\"url\":\"https://www.semanticscholar.org/paper/327d7e55d64cb34d55bd3a3fe58233c238a312cd\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145680073\",\"name\":\"S. Yao\"},{\"authorId\":\"3266387\",\"name\":\"Yan Hongfei\"},{\"authorId\":\"1867321719\",\"name\":\"Ying Siping\"},{\"authorId\":\"48240541\",\"name\":\"C. Chen\"},{\"authorId\":\"152277031\",\"name\":\"S. Qi\"}],\"doi\":\"10.1007/978-3-030-56725-5_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdfa19ca94f0362bf98a98425e80e678510b936e\",\"title\":\"Empirical Research on Futures Trading Strategy Based on Time Series Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/fdfa19ca94f0362bf98a98425e80e678510b936e\",\"venue\":\"CCIR\",\"year\":2020},{\"arxivId\":\"1907.00570\",\"authors\":[{\"authorId\":\"3709778\",\"name\":\"Joris Baan\"},{\"authorId\":\"41096186\",\"name\":\"Maartje ter Hoeve\"},{\"authorId\":\"3110566\",\"name\":\"M. V. D. Wees\"},{\"authorId\":\"2210188\",\"name\":\"Anne Schuth\"},{\"authorId\":\"1696030\",\"name\":\"M. Rijke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a4e8e6baa0fa0ed11cf4db92d84a7e6d8eac02a\",\"title\":\"Do Transformer Attention Heads Provide Transparency in Abstractive Summarization?\",\"url\":\"https://www.semanticscholar.org/paper/1a4e8e6baa0fa0ed11cf4db92d84a7e6d8eac02a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145485960\",\"name\":\"Jie Hao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"137f8e5c9550ceb9ef35aea0f49ef5d2295b6b24\",\"title\":\"Multi-Granularity Self-Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/137f8e5c9550ceb9ef35aea0f49ef5d2295b6b24\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.08178\",\"authors\":[{\"authorId\":\"1998313259\",\"name\":\"Xuanfu Wu\"},{\"authorId\":\"1685604483\",\"name\":\"Yang Feng\"},{\"authorId\":\"81050636\",\"name\":\"Chenze Shao\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.82\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99959092c6eadcf359ed8f74de2168244bbe402e\",\"title\":\"Generating Diverse Translation from Model Distribution with Dropout\",\"url\":\"https://www.semanticscholar.org/paper/99959092c6eadcf359ed8f74de2168244bbe402e\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.04037\",\"authors\":[{\"authorId\":\"48557122\",\"name\":\"L. Hou\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"48324350\",\"name\":\"X. Jiang\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bcb5afeef6dff173a82e4bfb8d16b54075cb2938\",\"title\":\"DynaBERT: Dynamic BERT with Adaptive Width and Depth\",\"url\":\"https://www.semanticscholar.org/paper/bcb5afeef6dff173a82e4bfb8d16b54075cb2938\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2001.04246\",\"authors\":[{\"authorId\":\"49025612\",\"name\":\"Daoyuan Chen\"},{\"authorId\":\"2694924\",\"name\":\"Y. Li\"},{\"authorId\":\"2642333\",\"name\":\"Minghui Qiu\"},{\"authorId\":null,\"name\":\"Zhen Wang\"},{\"authorId\":\"2175999\",\"name\":\"Bofang Li\"},{\"authorId\":\"1696332\",\"name\":\"B. Ding\"},{\"authorId\":\"2642895\",\"name\":\"H. Deng\"},{\"authorId\":\"101573196\",\"name\":\"Jun Huang\"},{\"authorId\":\"46639745\",\"name\":\"Wei Lin\"},{\"authorId\":\"1709595\",\"name\":\"Jingren Zhou\"}],\"doi\":\"10.24963/ijcai.2020/337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"799150a4463156175b1e903e9b94f1671c1b029f\",\"title\":\"AdaBERT: Task-Adaptive BERT Compression with Differentiable Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/799150a4463156175b1e903e9b94f1671c1b029f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.03898\",\"authors\":[{\"authorId\":\"3709778\",\"name\":\"Joris Baan\"},{\"authorId\":\"41096186\",\"name\":\"Maartje ter Hoeve\"},{\"authorId\":\"2136191\",\"name\":\"M. V. D. Wees\"},{\"authorId\":\"2210188\",\"name\":\"Anne Schuth\"},{\"authorId\":\"1696030\",\"name\":\"M. Rijke\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"317d2ac530e1db49229d6c442f50722db85afbb7\",\"title\":\"Understanding Multi-Head Attention in Abstractive Summarization\",\"url\":\"https://www.semanticscholar.org/paper/317d2ac530e1db49229d6c442f50722db85afbb7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.02181\",\"authors\":[{\"authorId\":\"143978279\",\"name\":\"Andrea Galassi\"},{\"authorId\":\"70246478\",\"name\":\"Marco Lippi\"},{\"authorId\":\"2896208\",\"name\":\"Paolo Torroni\"}],\"doi\":\"10.1109/TNNLS.2020.3019893\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab456c1ed181c5c48a34adb61395d4806a0ba949\",\"title\":\"Attention in Natural Language Processing.\",\"url\":\"https://www.semanticscholar.org/paper/ab456c1ed181c5c48a34adb61395d4806a0ba949\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":\"2010.02812\",\"authors\":[{\"authorId\":\"1753629012\",\"name\":\"Lucas Torroba Hennigen\"},{\"authorId\":\"81840293\",\"name\":\"Adina Williams\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c4d3b7085ad5f02bc732b489ace590a7bbd58c9\",\"title\":\"Intrinsic Probing through Dimension Selection\",\"url\":\"https://www.semanticscholar.org/paper/3c4d3b7085ad5f02bc732b489ace590a7bbd58c9\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2002.10260\",\"authors\":[{\"authorId\":\"3106437\",\"name\":\"Alessandro Raganato\"},{\"authorId\":\"3080637\",\"name\":\"Yves Scherrer\"},{\"authorId\":\"113391779\",\"name\":\"Jorg Tiedemann\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.49\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ca05087fc36e7917c0ff9a88e89bae35960704ab\",\"title\":\"Fixed Encoder Self-Attention Patterns in Transformer-Based Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/ca05087fc36e7917c0ff9a88e89bae35960704ab\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145485960\",\"name\":\"Jie Hao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"066f99a510f31aabb482d75d331a63c77611291d\",\"title\":\"Multi-Granularity Self-Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/066f99a510f31aabb482d75d331a63c77611291d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.01380\",\"authors\":[{\"authorId\":\"46235299\",\"name\":\"Elena Voita\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"}],\"doi\":\"10.18653/v1/D19-1448\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"112fd54ee193237b24f2ce7fce79e399609a29c5\",\"title\":\"The Bottom-up Evolution of Representations in the Transformer: A Study with Machine Translation and Language Modeling Objectives\",\"url\":\"https://www.semanticscholar.org/paper/112fd54ee193237b24f2ce7fce79e399609a29c5\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717641\",\"name\":\"Mohammad Taher Pilehvar\"},{\"authorId\":\"1387447871\",\"name\":\"Jos\\u00e9 Camacho-Collados\"}],\"doi\":\"10.2200/s01057ed1v01y202009hlt047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68ff3f2219ab53461e8353ed58f0efe7d66e28d4\",\"title\":\"Embeddings in Natural Language Processing: Theory and Advances in Vector Representations of Meaning\",\"url\":\"https://www.semanticscholar.org/paper/68ff3f2219ab53461e8353ed58f0efe7d66e28d4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.12065\",\"authors\":[{\"authorId\":\"51888120\",\"name\":\"Gr\\u00e9goire Mialon\"},{\"authorId\":\"81299639\",\"name\":\"Dexiong Chen\"},{\"authorId\":\"1387902104\",\"name\":\"A. d'Aspremont\"},{\"authorId\":\"2599292\",\"name\":\"J. Mairal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c828f0ce11886f7fb1db29c8196b3f92d0e9a8cd\",\"title\":\"A Trainable Optimal Transport Embedding for Feature Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/c828f0ce11886f7fb1db29c8196b3f92d0e9a8cd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.09286\",\"authors\":[{\"authorId\":\"92954142\",\"name\":\"S. Bhattamishra\"},{\"authorId\":\"1443788809\",\"name\":\"Arkil Patel\"},{\"authorId\":\"144260125\",\"name\":\"Navin Goyal\"}],\"doi\":\"10.18653/v1/2020.conll-1.37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfad7c6d4ad03f1f91cc2dcaed2e69912a5a7d2\",\"title\":\"On the Computational Power of Transformers and Its Implications in Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cbfad7c6d4ad03f1f91cc2dcaed2e69912a5a7d2\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":\"2005.01172\",\"authors\":[{\"authorId\":\"33348864\",\"name\":\"J. Wu\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"50433033\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":\"10.18653/v1/2020.acl-main.422\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ca4ecf116a9b97ce525a01f3f51117877688ddf5\",\"title\":\"Similarity Analysis of Contextual Word Representation Models\",\"url\":\"https://www.semanticscholar.org/paper/ca4ecf116a9b97ce525a01f3f51117877688ddf5\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2002.07028\",\"authors\":[{\"authorId\":\"1798880\",\"name\":\"Srinadh Bhojanapalli\"},{\"authorId\":\"2674870\",\"name\":\"Chulhee Yun\"},{\"authorId\":\"2241094\",\"name\":\"A. Rawat\"},{\"authorId\":\"1981186\",\"name\":\"S. Reddi\"},{\"authorId\":\"46574622\",\"name\":\"S. Kumar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1c39d042fdf8f00a407b0df734764beb6c3b062\",\"title\":\"Low-Rank Bottleneck in Multi-head Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/b1c39d042fdf8f00a407b0df734764beb6c3b062\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2002.08307\",\"authors\":[{\"authorId\":\"1452684657\",\"name\":\"Mitchell A. Gordon\"},{\"authorId\":\"1800354\",\"name\":\"Kevin Duh\"},{\"authorId\":\"145580321\",\"name\":\"Nicholas Andrews\"}],\"doi\":\"10.18653/v1/2020.repl4nlp-1.18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e81ce33b7ce77215c1ee7126a7d4881b8fccfa33\",\"title\":\"Compressing BERT: Studying the Effects of Weight Pruning on Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/e81ce33b7ce77215c1ee7126a7d4881b8fccfa33\",\"venue\":\"RepL4NLP@ACL\",\"year\":2020},{\"arxivId\":\"1909.00188\",\"authors\":[{\"authorId\":\"93951729\",\"name\":\"Shuhao Gu\"},{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1007/978-3-030-32233-5_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a99855603e7689a4529a1573f0bc4716adb246c1\",\"title\":\"Improving Multi-Head Attention with Capsule Networks\",\"url\":\"https://www.semanticscholar.org/paper/a99855603e7689a4529a1573f0bc4716adb246c1\",\"venue\":\"NLPCC\",\"year\":2019},{\"arxivId\":\"1911.07470\",\"authors\":[{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144594275\",\"name\":\"Wai Lam\"}],\"doi\":\"10.1609/AAAI.V34I05.6243\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb98bc96e02396d199fc899287d9b84393c86e79\",\"title\":\"Graph Transformer for Graph-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/bb98bc96e02396d199fc899287d9b84393c86e79\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2001.11003\",\"authors\":[{\"authorId\":\"10430740\",\"name\":\"Leonardo F. R. Ribeiro\"},{\"authorId\":\"49890815\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1794075\",\"name\":\"Claire Gardent\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"}],\"doi\":\"10.1162/tacl_a_00332\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6894f2f34ac9e0d681a951621aeb849e11d354d6\",\"title\":\"Modeling Global and Local Node Contexts for Text Generation from Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/6894f2f34ac9e0d681a951621aeb849e11d354d6\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2020},{\"arxivId\":\"2003.09586\",\"authors\":[{\"authorId\":\"49507285\",\"name\":\"Hongfei Xu\"},{\"authorId\":\"69572149\",\"name\":\"Josef van Genabith\"},{\"authorId\":\"48402957\",\"name\":\"Deyi Xiong\"},{\"authorId\":\"14147919\",\"name\":\"Q. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ca5071b8fa8cb0d23ae2a8044988f302d6642e9\",\"title\":\"Analyzing Word Translation of Transformer Layers\",\"url\":\"https://www.semanticscholar.org/paper/2ca5071b8fa8cb0d23ae2a8044988f302d6642e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.04987\",\"authors\":[{\"authorId\":\"9433771\",\"name\":\"Piyawat Lertvittayakumjorn\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"143719014\",\"name\":\"F. Toni\"}],\"doi\":\"10.18653/V1/2020.EMNLP-MAIN.24\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c13318f8d65505bffa13280b9e2d762982fdc0db\",\"title\":\"FIND: Human-in-the-Loop Debugging Deep Text Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/c13318f8d65505bffa13280b9e2d762982fdc0db\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1911.02972\",\"authors\":[{\"authorId\":\"40125294\",\"name\":\"Jiezhong Qiu\"},{\"authorId\":\"46389865\",\"name\":\"Hao Ma\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"3156075\",\"name\":\"S. Yih\"},{\"authorId\":\"2096387\",\"name\":\"Sinong Wang\"},{\"authorId\":\"143805718\",\"name\":\"Jie Tang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3da5dac5f51acab98c7c46e94a8536dd7fef163c\",\"title\":\"Blockwise Self-Attention for Long Document Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3da5dac5f51acab98c7c46e94a8536dd7fef163c\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.13382\",\"authors\":[{\"authorId\":\"46453937\",\"name\":\"Y. Kim\"},{\"authorId\":\"3032929\",\"name\":\"H. H. Awadalla\"}],\"doi\":\"10.18653/v1/2020.sustainlp-1.20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96d654dbd6d77c8b3d4fe13ee4111feee4e4fa85\",\"title\":\"FastFormers: Highly Efficient Transformer Models for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/96d654dbd6d77c8b3d4fe13ee4111feee4e4fa85\",\"venue\":\"SUSTAINLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2b93624725c9e8f090471b884debc3ba8bc879\",\"title\":\"Weight Squeezing: Reparameterization for Model Compression\",\"url\":\"https://www.semanticscholar.org/paper/fa2b93624725c9e8f090471b884debc3ba8bc879\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.00184\",\"authors\":[{\"authorId\":\"2635755\",\"name\":\"Marcely Zanon Boito\"},{\"authorId\":\"145585242\",\"name\":\"Aline Villavicencio\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"}],\"doi\":\"10.21437/interspeech.2019-2029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"715129cbfd4202cb7c60e6415592bc73066ab739\",\"title\":\"Empirical Evaluation of Sequence-to-Sequence Models for Word Discovery in Low-resource Settings\",\"url\":\"https://www.semanticscholar.org/paper/715129cbfd4202cb7c60e6415592bc73066ab739\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2849740\",\"name\":\"Kehai Chen\"},{\"authorId\":\"108085542\",\"name\":\"Rui Wang\"},{\"authorId\":\"1802277\",\"name\":\"M. Utiyama\"},{\"authorId\":\"1698363\",\"name\":\"Eiichiro Sumita\"},{\"authorId\":\"48399095\",\"name\":\"Tiejun Zhao\"},{\"authorId\":\"2105775\",\"name\":\"Muyun Yang\"},{\"authorId\":\"47941144\",\"name\":\"Hai Zhao\"}],\"doi\":\"10.1109/TASLP.2020.2996077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74c84c391930224f7e1e150525132b3ff8aca8a0\",\"title\":\"Towards More Diverse Input Representation for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/74c84c391930224f7e1e150525132b3ff8aca8a0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569393\",\"name\":\"Xintong Li\"},{\"authorId\":\"73938410\",\"name\":\"Guanlin Li\"},{\"authorId\":\"2978364\",\"name\":\"L. Liu\"},{\"authorId\":\"1735045\",\"name\":\"M. Meng\"},{\"authorId\":\"34720053\",\"name\":\"Shuming Shi\"}],\"doi\":\"10.18653/v1/P19-1124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1c7c5ab9ffce84ee3681011f09def462074f1ca\",\"title\":\"On the Word Alignment from Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/b1c7c5ab9ffce84ee3681011f09def462074f1ca\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2008.00623\",\"authors\":[{\"authorId\":\"151493135\",\"name\":\"Sachin Mehta\"},{\"authorId\":\"2320509\",\"name\":\"Marjan Ghazvininejad\"},{\"authorId\":\"1900163\",\"name\":\"Srini Iyer\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0cd93e95fb6885db47d755a4c631158b0198047\",\"title\":\"DeLighT: Very Deep and Light-weight Transformer\",\"url\":\"https://www.semanticscholar.org/paper/b0cd93e95fb6885db47d755a4c631158b0198047\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.14187\",\"authors\":[{\"authorId\":\"35446689\",\"name\":\"Hanrui Wang\"},{\"authorId\":\"1390573666\",\"name\":\"Zhanghao Wu\"},{\"authorId\":\"47781592\",\"name\":\"Zhijian Liu\"},{\"authorId\":\"81623205\",\"name\":\"H. Cai\"},{\"authorId\":\"20515689\",\"name\":\"Ligeng Zhu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":\"10.18653/v1/2020.acl-main.686\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7\",\"title\":\"HAT: Hardware-Aware Transformers for Efficient Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/ef8d788a904ed66bd8e30ffa69bc3ea1fe57dda7\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1905.10650\",\"authors\":[{\"authorId\":\"144397625\",\"name\":\"Paul Michel\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b03c7ff961822183bab66b2e594415e585d3fd09\",\"title\":\"Are Sixteen Heads Really Better than One?\",\"url\":\"https://www.semanticscholar.org/paper/b03c7ff961822183bab66b2e594415e585d3fd09\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2006.00844\",\"authors\":[{\"authorId\":\"23174933\",\"name\":\"M. Anderson\"},{\"authorId\":\"1388759404\",\"name\":\"Carlos G'omez-Rodr'iguez\"}],\"doi\":\"10.18653/v1/2020.iwpt-1.2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30f3e9b6793e9d6c979070f0446f0f1fa113a9d9\",\"title\":\"Distilling Neural Networks for Greener and Faster Dependency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/30f3e9b6793e9d6c979070f0446f0f1fa113a9d9\",\"venue\":\"IWPT 2020\",\"year\":2020},{\"arxivId\":\"2011.03770\",\"authors\":[{\"authorId\":\"2621696\",\"name\":\"Zhengyan Zhang\"},{\"authorId\":\"51466208\",\"name\":\"Fanchao Qi\"},{\"authorId\":null,\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"1688015\",\"name\":\"Qun Liu\"},{\"authorId\":\"120548773\",\"name\":\"Maosong Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02806b916d2c341d5a5ac7dc3c19e3f2363d402f\",\"title\":\"Know What You Don't Need: Single-Shot Meta-Pruning for Attention Heads\",\"url\":\"https://www.semanticscholar.org/paper/02806b916d2c341d5a5ac7dc3c19e3f2363d402f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.09394\",\"authors\":[{\"authorId\":\"49276525\",\"name\":\"Hirofumi Inaguma\"},{\"authorId\":\"2226344\",\"name\":\"M. Mimura\"},{\"authorId\":\"1717105\",\"name\":\"Tatsuya Kawahara\"}],\"doi\":\"10.21437/interspeech.2020-1780\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16a7af4333f7f8d71e036d2671dbde9827efe943\",\"title\":\"Enhancing Monotonic Multihead Attention for Streaming ASR\",\"url\":\"https://www.semanticscholar.org/paper/16a7af4333f7f8d71e036d2671dbde9827efe943\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2005.03454\",\"authors\":[{\"authorId\":\"51518834\",\"name\":\"Christopher Brix\"},{\"authorId\":\"1872287\",\"name\":\"P. Bahar\"},{\"authorId\":\"145322333\",\"name\":\"H. Ney\"}],\"doi\":\"10.18653/v1/2020.acl-main.360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"143b0bd73e7e765945e0b8620f84f52878617560\",\"title\":\"Successfully Applying the Stabilized Lottery Ticket Hypothesis to the Transformer Architecture\",\"url\":\"https://www.semanticscholar.org/paper/143b0bd73e7e765945e0b8620f84f52878617560\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2004.02199\",\"authors\":[{\"authorId\":\"2675365\",\"name\":\"Conghui Zhu\"},{\"authorId\":\"151485795\",\"name\":\"Guanlin Li\"},{\"authorId\":\"2978364\",\"name\":\"L. Liu\"},{\"authorId\":\"1856039\",\"name\":\"T. Zhao\"},{\"authorId\":\"34720053\",\"name\":\"Shuming Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"315c7e20599793718d7d5193470242c43e2fbb96\",\"title\":\"Understanding Learning Dynamics for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/315c7e20599793718d7d5193470242c43e2fbb96\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1877157182\",\"name\":\"Aakriti Budhraja\"},{\"authorId\":\"1876624327\",\"name\":\"Madhura Pande\"},{\"authorId\":\"9192775\",\"name\":\"Preksha Nema\"},{\"authorId\":\"1629793734\",\"name\":\"P. Kumar\"},{\"authorId\":\"2008183902\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"598c03e058de3566d3ab10e0785009a833b67d2a\",\"title\":\"On the weak link between importance and prunability of attention heads\",\"url\":\"https://www.semanticscholar.org/paper/598c03e058de3566d3ab10e0785009a833b67d2a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.11406\",\"authors\":[{\"authorId\":\"79393511\",\"name\":\"Darius Afchar\"},{\"authorId\":\"2877625\",\"name\":\"Romain Hennequin\"}],\"doi\":\"10.1145/3383313.3412253\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8357c65a42a27085fda7a3ebe47daecf84600c0\",\"title\":\"Making Neural Networks Interpretable with Attribution: Application to Implicit Signals Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a8357c65a42a27085fda7a3ebe47daecf84600c0\",\"venue\":\"RecSys\",\"year\":2020},{\"arxivId\":\"2010.01791\",\"authors\":[{\"authorId\":\"9070961\",\"name\":\"Zian Lin\"},{\"authorId\":\"29833921\",\"name\":\"Jeremiah Zhe Liu\"},{\"authorId\":\"144453917\",\"name\":\"Z. Yang\"},{\"authorId\":\"49864394\",\"name\":\"Nan Hua\"},{\"authorId\":\"144590225\",\"name\":\"D. Roth\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.64\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fa19377b9cd6d2e9292522774c3a13108cd2ff5\",\"title\":\"Pruning Redundant Mappings in Transformer Models via Spectral-Normalized Identity Prior\",\"url\":\"https://www.semanticscholar.org/paper/8fa19377b9cd6d2e9292522774c3a13108cd2ff5\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.11854\",\"authors\":[{\"authorId\":\"48335426\",\"name\":\"Biao Zhang\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2f36f14419565a0fed3032b7f1d1811daf6702e\",\"title\":\"On Sparsifying Encoder Outputs in Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/c2f36f14419565a0fed3032b7f1d1811daf6702e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.15012\",\"authors\":[{\"authorId\":\"35318567\",\"name\":\"Rohan Jha\"},{\"authorId\":\"10727711\",\"name\":\"Charles Lovering\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f8cad3cdb1c4b75d145105887a61fca55852d6c\",\"title\":\"Does Data Augmentation Improve Generalization in NLP\",\"url\":\"https://www.semanticscholar.org/paper/2f8cad3cdb1c4b75d145105887a61fca55852d6c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.07106\",\"authors\":[{\"authorId\":\"12295226\",\"name\":\"Ankur Bapna\"},{\"authorId\":\"3365231\",\"name\":\"N. Arivazhagan\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a106707b0ad05db8961e9cd2a14bf85aff738d5d\",\"title\":\"Controlling Computation versus Quality for Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/a106707b0ad05db8961e9cd2a14bf85aff738d5d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.01854\",\"authors\":[{\"authorId\":\"97393346\",\"name\":\"Sebastian Hofst\\u00e4tter\"},{\"authorId\":\"11019215\",\"name\":\"Markus Zlabinger\"},{\"authorId\":\"1699657\",\"name\":\"A. Hanbury\"}],\"doi\":\"10.3233/FAIA200133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbdc34000b034b75b8ff70872fc7c35549e273a\",\"title\":\"Interpretable & Time-Budget-Constrained Contextualization for Re-Ranking\",\"url\":\"https://www.semanticscholar.org/paper/6dbdc34000b034b75b8ff70872fc7c35549e273a\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2005.00742\",\"authors\":[{\"authorId\":\"1667413380\",\"name\":\"Weiqiu You\"},{\"authorId\":\"23134878\",\"name\":\"Simeng Sun\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"}],\"doi\":\"10.18653/v1/2020.acl-main.687\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07a9f47885cae97efb7b4aa109392128532433da\",\"title\":\"Hard-Coded Gaussian Attention for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/07a9f47885cae97efb7b4aa109392128532433da\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1907.04614\",\"authors\":[{\"authorId\":\"97393346\",\"name\":\"Sebastian Hofst\\u00e4tter\"},{\"authorId\":\"1699657\",\"name\":\"A. Hanbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3c97dd0b8cee91537f1f796d24b0a5a260fe63f\",\"title\":\"Let's measure run time! Extending the IR replicability infrastructure to include performance aspects\",\"url\":\"https://www.semanticscholar.org/paper/d3c97dd0b8cee91537f1f796d24b0a5a260fe63f\",\"venue\":\"OSIRRC@SIGIR\",\"year\":2019},{\"arxivId\":\"2004.14620\",\"authors\":[{\"authorId\":\"1666636295\",\"name\":\"Tomasz Limisiewicz\"},{\"authorId\":\"2436967\",\"name\":\"Rudolf Rosa\"},{\"authorId\":\"1666831775\",\"name\":\"David Marevcek\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.245\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"1197a3d963b8016ff5a9c975d361bd28edf2ad16\",\"title\":\"Universal Dependencies according to BERT: both more specific and more general\",\"url\":\"https://www.semanticscholar.org/paper/1197a3d963b8016ff5a9c975d361bd28edf2ad16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.04922\",\"authors\":[{\"authorId\":\"47039337\",\"name\":\"Zhengxuan Wu\"},{\"authorId\":\"40647710\",\"name\":\"T. Nguyen\"},{\"authorId\":\"144799222\",\"name\":\"Desmond C. Ong\"}],\"doi\":\"10.18653/v1/2020.blackboxnlp-1.24\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"c1ce7375f040327ad7c51e852ae778b6cb8168c9\",\"title\":\"Structured Self-Attention Weights Encode Semantics in Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c1ce7375f040327ad7c51e852ae778b6cb8168c9\",\"venue\":\"BLACKBOXNLP\",\"year\":2020},{\"arxivId\":\"2009.11264\",\"authors\":[{\"authorId\":\"92954142\",\"name\":\"S. Bhattamishra\"},{\"authorId\":\"52154863\",\"name\":\"Kabir Ahuja\"},{\"authorId\":\"144260125\",\"name\":\"Navin Goyal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9c12545d2e7a3a04ce8488cfee43360e6ca9e4f\",\"title\":\"On the Ability and Limitations of Transformers to Recognize Formal Languages\",\"url\":\"https://www.semanticscholar.org/paper/a9c12545d2e7a3a04ce8488cfee43360e6ca9e4f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1912.07840\",\"authors\":[{\"authorId\":\"46451258\",\"name\":\"Karthikeyan K\"},{\"authorId\":\"2240689\",\"name\":\"Zihan Wang\"},{\"authorId\":\"2153374\",\"name\":\"Stephen Mayhew\"},{\"authorId\":\"152567881\",\"name\":\"Dan Roth\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"3b2538f84812f434c740115c185be3e5e216c526\",\"title\":\"Cross-Lingual Ability of Multilingual BERT: An Empirical Study\",\"url\":\"https://www.semanticscholar.org/paper/3b2538f84812f434c740115c185be3e5e216c526\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10324691\",\"name\":\"Kawin Ethayarajh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9504e21924dcc28931de568a1594eb9591ae3b05\",\"title\":\"Rotate $\\\\textit{King}$ to get $\\\\textit{Queen}$: Word Relationships as Orthogonal Transformations in Embedding Space\",\"url\":\"https://www.semanticscholar.org/paper/9504e21924dcc28931de568a1594eb9591ae3b05\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.12993\",\"authors\":[{\"authorId\":\"145426396\",\"name\":\"J. Xin\"},{\"authorId\":\"26917433\",\"name\":\"Raphael Tang\"},{\"authorId\":\"82536583\",\"name\":\"J. Lee\"},{\"authorId\":\"40508553\",\"name\":\"Y. Yu\"},{\"authorId\":\"37752900\",\"name\":\"Jimmy Lin\"}],\"doi\":\"10.18653/v1/2020.acl-main.204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90a1491ac32e732c93773354e4e665794ed4d490\",\"title\":\"DeeBERT: Dynamic Early Exiting for Accelerating BERT Inference\",\"url\":\"https://www.semanticscholar.org/paper/90a1491ac32e732c93773354e4e665794ed4d490\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.10036\",\"authors\":[{\"authorId\":\"35434866\",\"name\":\"Haoye Lu\"},{\"authorId\":\"2047889\",\"name\":\"Yongyi Mao\"},{\"authorId\":\"144297190\",\"name\":\"A. Nayak\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d5c9a2a55b64bcf2cd01c5aa954776575c98500\",\"title\":\"On the Dynamics of Training Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/4d5c9a2a55b64bcf2cd01c5aa954776575c98500\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02030\",\"authors\":[{\"authorId\":\"2030982446\",\"name\":\"Ileana Rugina\"},{\"authorId\":\"26916003\",\"name\":\"R. Dangovski\"},{\"authorId\":\"145341956\",\"name\":\"L. Jing\"},{\"authorId\":\"2026545715\",\"name\":\"Preslav Nakov\"},{\"authorId\":\"31165273\",\"name\":\"M. Solja\\u010di\\u0107\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"020799d924ddd473901044a95a60cde4c1db0ce2\",\"title\":\"Data-Informed Global Sparseness in Attention Mechanisms for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/020799d924ddd473901044a95a60cde4c1db0ce2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14682\",\"authors\":[{\"authorId\":\"2005834795\",\"name\":\"Lei Li\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":null,\"name\":\"Shuhuai Ren\"},{\"authorId\":\"31062018\",\"name\":\"Deli Chen\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":null,\"name\":\"Peng Li\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"2023418414\",\"name\":\"Xu Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e64bad304a6b2697d1fb01e9a0e6daa160ecdb17\",\"title\":\"Accelerating Pre-trained Language Models via Calibrated Cascade\",\"url\":\"https://www.semanticscholar.org/paper/e64bad304a6b2697d1fb01e9a0e6daa160ecdb17\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.05714\",\"authors\":[{\"authorId\":\"2056908\",\"name\":\"J. Vig\"}],\"doi\":\"10.18653/v1/P19-3007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0de0a44b859a3719d11834479112314b4caba669\",\"title\":\"A Multiscale Visualization of Attention in the Transformer Model\",\"url\":\"https://www.semanticscholar.org/paper/0de0a44b859a3719d11834479112314b4caba669\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2005.06537\",\"authors\":[{\"authorId\":\"1490937486\",\"name\":\"Hao Peng\"},{\"authorId\":\"4671928\",\"name\":\"Roy Schwartz\"},{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"1685669\",\"name\":\"N. A. Smith\"}],\"doi\":\"10.18653/v1/2020.acl-main.587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d97cd476bef990352ae921e4c7c5ae1222e9b8da\",\"title\":\"A Mixture of h-1 Heads is Better than h Heads\",\"url\":\"https://www.semanticscholar.org/paper/d97cd476bef990352ae921e4c7c5ae1222e9b8da\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2004.13270\",\"authors\":[{\"authorId\":\"3470504\",\"name\":\"Shilin He\"},{\"authorId\":\"47118965\",\"name\":\"X. Wang\"},{\"authorId\":\"47295584\",\"name\":\"Shuming Shi\"},{\"authorId\":\"145609003\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"2909321\",\"name\":\"Zhaopeng Tu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"210e9635d0afdf6d896349afc55c54c38968d884\",\"title\":\"Assessing the Bilingual Knowledge Learned by Neural Machine Translation Models\",\"url\":\"https://www.semanticscholar.org/paper/210e9635d0afdf6d896349afc55c54c38968d884\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05916\",\"authors\":[{\"authorId\":\"150973452\",\"name\":\"Dami\\u00e1n Pascual\"},{\"authorId\":\"38094934\",\"name\":\"Gino Brunner\"},{\"authorId\":\"1716440\",\"name\":\"Roger Wattenhofer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d9605a8b6364d24b58be561ea1ce4233c088cee\",\"title\":\"Telling BERT's full story: from Local Attention to Global Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/3d9605a8b6364d24b58be561ea1ce4233c088cee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.13515\",\"authors\":[{\"authorId\":\"1795634\",\"name\":\"A. Asperti\"},{\"authorId\":\"144492066\",\"name\":\"S. Bianco\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1b38028f08a2f95141262152f0ff3a81ba15053a\",\"title\":\"Syllabification of the Divine Comedy\",\"url\":\"https://www.semanticscholar.org/paper/1b38028f08a2f95141262152f0ff3a81ba15053a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.00504\",\"authors\":[{\"authorId\":\"10324691\",\"name\":\"Kawin Ethayarajh\"}],\"doi\":\"10.18653/v1/D19-1354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef696f2c85ad5844a923dbf0dc40c69059d3e8db\",\"title\":\"Rotate King to get Queen: Word Relationships as Orthogonal Transformations in Embedding Space\",\"url\":\"https://www.semanticscholar.org/paper/ef696f2c85ad5844a923dbf0dc40c69059d3e8db\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2010.05763\",\"authors\":[{\"authorId\":\"1994191609\",\"name\":\"Nikolaos Manginas\"},{\"authorId\":\"10783142\",\"name\":\"Ilias Chalkidis\"},{\"authorId\":\"1950133\",\"name\":\"Prodromos Malakasiotis\"}],\"doi\":\"10.18653/v1/2020.spnlp-1.7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35fd1376626966cac71d45e573fa56f2f8d64544\",\"title\":\"Layer-wise Guided Training for BERT: Learning Incrementally Refined Document Representations\",\"url\":\"https://www.semanticscholar.org/paper/35fd1376626966cac71d45e573fa56f2f8d64544\",\"venue\":\"SPNLP@EMNLP\",\"year\":2020},{\"arxivId\":\"2010.02416\",\"authors\":[{\"authorId\":\"144774290\",\"name\":\"Y. Hsu\"},{\"authorId\":\"31264049\",\"name\":\"Sarthak Garg\"},{\"authorId\":\"1743953\",\"name\":\"Yi-Hsiu Liao\"},{\"authorId\":\"1988185137\",\"name\":\"Ilya Chatsviorkin\"}],\"doi\":\"10.18653/v1/2020.sustainlp-1.7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a41a98d40fab83a2ac9010ca097e3b2cff4b6da\",\"title\":\"Efficient Inference For Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/4a41a98d40fab83a2ac9010ca097e3b2cff4b6da\",\"venue\":\"SUSTAINLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92954142\",\"name\":\"S. Bhattamishra\"},{\"authorId\":\"52154863\",\"name\":\"Kabir Ahuja\"},{\"authorId\":\"144260125\",\"name\":\"Navin Goyal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0def0a8dfccd1e70bf0f0f8b1a2217252fa3f952\",\"title\":\"On the Ability of Self-Attention Networks to Recognize Counter Languages\",\"url\":\"https://www.semanticscholar.org/paper/0def0a8dfccd1e70bf0f0f8b1a2217252fa3f952\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.04393\",\"authors\":[{\"authorId\":\"23523733\",\"name\":\"Ziyang Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25c3673210f1f4cacb2e851b55af1e4c6f323796\",\"title\":\"Catch the \\\"Tails\\\" of BERT\",\"url\":\"https://www.semanticscholar.org/paper/25c3673210f1f4cacb2e851b55af1e4c6f323796\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06467\",\"authors\":[{\"authorId\":\"37752900\",\"name\":\"Jimmy Lin\"},{\"authorId\":\"143744603\",\"name\":\"Rodrigo Nogueira\"},{\"authorId\":\"48399687\",\"name\":\"A. Yates\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7837b65110622bd23a9afaac4316655b4b1f877\",\"title\":\"Pretrained Transformers for Text Ranking: BERT and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/f7837b65110622bd23a9afaac4316655b4b1f877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5041757\",\"name\":\"Taeuk Kim\"},{\"authorId\":\"3013044\",\"name\":\"Sanggoo Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f2b5420849571d301f694ebed7be8170c814b17\",\"title\":\"Multilingual Zero-shot Constituency Parsing\",\"url\":\"https://www.semanticscholar.org/paper/1f2b5420849571d301f694ebed7be8170c814b17\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":162183964,\"doi\":\"10.18653/v1/P19-1580\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":23,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"07a64686ce8e43ac475a8d820a8a9f1d87989583\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"40405884\",\"name\":\"S. Bach\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"},{\"authorId\":\"144535526\",\"name\":\"Gr\\u00e9goire Montavon\"},{\"authorId\":\"3245416\",\"name\":\"F. Klauschen\"},{\"authorId\":\"145034054\",\"name\":\"K. M\\u00fcller\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1371/journal.pone.0130140\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17a273bbd4448083b01b5a9389b3c37f5425aac0\",\"title\":\"On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation\",\"url\":\"https://www.semanticscholar.org/paper/17a273bbd4448083b01b5a9389b3c37f5425aac0\",\"venue\":\"PloS one\",\"year\":2015},{\"arxivId\":\"1704.03471\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"145775792\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.18653/v1/P17-1080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82364428995c29b3dcb60c1835548eeff4adcd20\",\"title\":\"What do Neural Machine Translation Models Learn about Morphology?\",\"url\":\"https://www.semanticscholar.org/paper/82364428995c29b3dcb60c1835548eeff4adcd20\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1710.01878\",\"authors\":[{\"authorId\":\"144298114\",\"name\":\"M. Zhu\"},{\"authorId\":\"2242641\",\"name\":\"S. Gupta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b4d671a8c7018c0b42673ba581e5ff3ae762d6c\",\"title\":\"To prune, or not to prune: exploring the efficacy of pruning for model compression\",\"url\":\"https://www.semanticscholar.org/paper/3b4d671a8c7018c0b42673ba581e5ff3ae762d6c\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"34564969\",\"name\":\"S. Jean\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1007/s10590-017-9194-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032e9974cedb31f5c6e354626760e54e5ebf1e3c\",\"title\":\"The representational geometry of word meanings acquired by neural machine translation models\",\"url\":\"https://www.semanticscholar.org/paper/032e9974cedb31f5c6e354626760e54e5ebf1e3c\",\"venue\":\"Machine Translation\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746165\",\"name\":\"P. Lison\"},{\"authorId\":\"143675545\",\"name\":\"J. Tiedemann\"},{\"authorId\":\"1761386\",\"name\":\"Milen Kouylekov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a9e5377bbf28b86a1dd8cd5802998c949a34ff3\",\"title\":\"OpenSubtitles2018: Statistical Rescoring of Sentence Alignments in Large, Noisy Parallel Corpora\",\"url\":\"https://www.semanticscholar.org/paper/6a9e5377bbf28b86a1dd8cd5802998c949a34ff3\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":\"1804.00247\",\"authors\":[{\"authorId\":\"3209310\",\"name\":\"M. Popel\"},{\"authorId\":\"143832874\",\"name\":\"Ondrej Bojar\"}],\"doi\":\"10.2478/pralin-2018-0002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3707cf521e3596313af1f53acba6413d0d528a6\",\"title\":\"Training Tips for the Transformer Model\",\"url\":\"https://www.semanticscholar.org/paper/d3707cf521e3596313af1f53acba6413d0d528a6\",\"venue\":\"Prague Bull. Math. Linguistics\",\"year\":2018},{\"arxivId\":\"1712.01312\",\"authors\":[{\"authorId\":\"2075783\",\"name\":\"Christos Louizos\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"},{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"572f5d18a3943dce4e14f937ef66977a01891096\",\"title\":\"Learning Sparse Neural Networks through L0 Regularization\",\"url\":\"https://www.semanticscholar.org/paper/572f5d18a3943dce4e14f937ef66977a01891096\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3106437\",\"name\":\"Alessandro Raganato\"},{\"authorId\":\"143675545\",\"name\":\"J. Tiedemann\"}],\"doi\":\"10.18653/v1/W18-5431\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94238dead40b12735d79ed63e29ead70730261a2\",\"title\":\"An Analysis of Encoder Representations in Transformer-Based Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/94238dead40b12735d79ed63e29ead70730261a2\",\"venue\":\"BlackboxNLP@EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1808.08946\",\"authors\":[{\"authorId\":\"2786820\",\"name\":\"Gongbo Tang\"},{\"authorId\":\"144529826\",\"name\":\"M. M\\u00fcller\"},{\"authorId\":\"40659617\",\"name\":\"Annette Rios Gonzales\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"}],\"doi\":\"10.18653/v1/D18-1458\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e3ee61f49cd2639c15c8662a45f1d0c2b83a60c1\",\"title\":\"Why Self-Attention? A Targeted Evaluation of Neural Machine Translation Architectures\",\"url\":\"https://www.semanticscholar.org/paper/e3ee61f49cd2639c15c8662a45f1d0c2b83a60c1\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1803.03585\",\"authors\":[{\"authorId\":\"2748455\",\"name\":\"Ke M. Tran\"},{\"authorId\":\"3242253\",\"name\":\"Arianna Bisazza\"},{\"authorId\":\"1696402\",\"name\":\"Christof Monz\"}],\"doi\":\"10.18653/v1/D18-1503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"997c55547aeca733dfc5dfebd12412612ecba022\",\"title\":\"The Importance of Being Recurrent for Modeling Hierarchical Structure\",\"url\":\"https://www.semanticscholar.org/paper/997c55547aeca733dfc5dfebd12412612ecba022\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"145775792\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"145247319\",\"name\":\"S. Vogel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5da4567918c9d47a85575008edecb78fdf9dd391\",\"title\":\"Understanding and Improving Morphological Learning in the Neural Machine Translation Decoder\",\"url\":\"https://www.semanticscholar.org/paper/5da4567918c9d47a85575008edecb78fdf9dd391\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"484ad17c926292fbe0d5211540832a8c8a8e958b\",\"title\":\"Stochastic Backpropagation and Approximate Inference in Deep Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/484ad17c926292fbe0d5211540832a8c8a8e958b\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1710.03348\",\"authors\":[{\"authorId\":\"2817643\",\"name\":\"Hamidreza Ghader\"},{\"authorId\":\"1696402\",\"name\":\"Christof Monz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5799525379e505234d727b01f8005f69a4d252d\",\"title\":\"What does Attention in Neural Machine Translation Pay Attention to?\",\"url\":\"https://www.semanticscholar.org/paper/b5799525379e505234d727b01f8005f69a4d252d\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143794227\",\"name\":\"Xing Shi\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":null,\"name\":\"Kevin Knight\"}],\"doi\":\"10.18653/v1/D16-1159\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d821ce08da6c0084d5eacbdf65e25556bc1b9bc3\",\"title\":\"Does String-Based Neural MT Learn Source Syntax?\",\"url\":\"https://www.semanticscholar.org/paper/d821ce08da6c0084d5eacbdf65e25556bc1b9bc3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1810.07595\",\"authors\":[{\"authorId\":\"2786820\",\"name\":\"Gongbo Tang\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"1720988\",\"name\":\"Joakim Nivre\"}],\"doi\":\"10.18653/v1/W18-6304\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7b8b182d0fdf4ea465a700ef9943b15eca910e49\",\"title\":\"An Analysis of Attention Mechanisms: The Case of Word Sense Disambiguation in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/7b8b182d0fdf4ea465a700ef9943b15eca910e49\",\"venue\":\"WMT\",\"year\":2018},{\"arxivId\":\"1801.09797\",\"authors\":[{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1723f1bb6fa033d638d0127e056470a9431246c9\",\"title\":\"Discrete Autoencoders for Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/1723f1bb6fa033d638d0127e056470a9431246c9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Diederik P. Kingma\"},{\"authorId\":null,\"name\":\"Max Welling.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Autoencoding variational bayes\",\"url\":\"\",\"venue\":\"International Conference on Learning Representations, Banff, Canada.\",\"year\":2014},{\"arxivId\":\"1606.09274\",\"authors\":[{\"authorId\":\"13070498\",\"name\":\"A. See\"},{\"authorId\":\"1707242\",\"name\":\"Minh-Thang Luong\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/K16-1029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"230579a14d54ae00073d6c3522ffcef313320be9\",\"title\":\"Compression of Neural Machine Translation Models via Pruning\",\"url\":\"https://www.semanticscholar.org/paper/230579a14d54ae00073d6c3522ffcef313320be9\",\"venue\":\"CoNLL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3242253\",\"name\":\"Arianna Bisazza\"},{\"authorId\":\"5870464\",\"name\":\"Clara Tump\"}],\"doi\":\"10.18653/v1/D18-1313\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af96e98684c278b66769b4656af069585ac6df85\",\"title\":\"The Lazy Encoder: A Fine-Grained Analysis of the Role of Morphology in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/af96e98684c278b66769b4656af069585ac6df85\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1611.01368\",\"authors\":[{\"authorId\":\"2467508\",\"name\":\"Tal Linzen\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"},{\"authorId\":\"79775260\",\"name\":\"Y. Goldberg\"}],\"doi\":\"10.1162/tacl_a_00115\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3aa52436575cf6768a0a1a476601825f6a62e58f\",\"title\":\"Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies\",\"url\":\"https://www.semanticscholar.org/paper/3aa52436575cf6768a0a1a476601825f6a62e58f\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2016},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1811.01157\",\"authors\":[{\"authorId\":\"2956769\",\"name\":\"A. Bau\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"145775792\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5489d244bfc1e9b0d8c94bf6dd774ee1aca2def\",\"title\":\"Identifying and Controlling Important Neurons in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/c5489d244bfc1e9b0d8c94bf6dd774ee1aca2def\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1612.04629\",\"authors\":[{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"}],\"doi\":\"10.18653/V1/E17-2060\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63c4114bd373dd0fcfe0d25a605b353c62be2995\",\"title\":\"How Grammatical is Character-level Neural Machine Translation? Assessing MT Quality with Contrastive Translation Pairs\",\"url\":\"https://www.semanticscholar.org/paper/63c4114bd373dd0fcfe0d25a605b353c62be2995\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":\"1611.00712\",\"authors\":[{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"515a21e90117941150923e559729c59f5fdade1c\",\"title\":\"The Concrete Distribution: A Continuous Relaxation of Discrete Random Variables\",\"url\":\"https://www.semanticscholar.org/paper/515a21e90117941150923e559729c59f5fdade1c\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1611.01144\",\"authors\":[{\"authorId\":\"145116380\",\"name\":\"Eric Jang\"},{\"authorId\":\"2046135\",\"name\":\"Shixiang Gu\"},{\"authorId\":\"16443937\",\"name\":\"Ben Poole\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29e944711a354c396fad71936f536e83025b6ce0\",\"title\":\"Categorical Reparameterization with Gumbel-Softmax\",\"url\":\"https://www.semanticscholar.org/paper/29e944711a354c396fad71936f536e83025b6ce0\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1508.07909\",\"authors\":[{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"2259100\",\"name\":\"B. Haddow\"},{\"authorId\":\"2539211\",\"name\":\"Alexandra Birch\"}],\"doi\":\"10.18653/v1/P16-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1af68821518f03568f913ab03fc02080247a27ff\",\"title\":\"Neural Machine Translation of Rare Words with Subword Units\",\"url\":\"https://www.semanticscholar.org/paper/1af68821518f03568f913ab03fc02080247a27ff\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1803.11138\",\"authors\":[{\"authorId\":\"2807281\",\"name\":\"Kristina Gulordava\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2467508\",\"name\":\"Tal Linzen\"},{\"authorId\":\"145283199\",\"name\":\"M. Baroni\"}],\"doi\":\"10.18653/v1/N18-1108\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d42ddf7c5ce59ae04d1d27085be9f736d1be04b\",\"title\":\"Colorless green recurrent networks dream hierarchically\",\"url\":\"https://www.semanticscholar.org/paper/3d42ddf7c5ce59ae04d1d27085be9f736d1be04b\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1801.07772\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"3049328\",\"name\":\"Llu\\u00eds M\\u00e0rquez i Villodre\"},{\"authorId\":\"145775792\",\"name\":\"Hassan Sajjad\"},{\"authorId\":\"145938140\",\"name\":\"Nadir Durrani\"},{\"authorId\":\"6415321\",\"name\":\"F. Dalvi\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcb028149bb3cf934fbd2e4cbb773ffbb9b0e49d\",\"title\":\"Evaluating Layers of Representation in Neural Machine Translation on Part-of-Speech and Semantic Tagging Tasks\",\"url\":\"https://www.semanticscholar.org/paper/dcb028149bb3cf934fbd2e4cbb773ffbb9b0e49d\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":\"1805.10163\",\"authors\":[{\"authorId\":\"46235299\",\"name\":\"Elena Voita\"},{\"authorId\":\"1708801\",\"name\":\"P. Serdyukov\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"}],\"doi\":\"10.18653/v1/P18-1117\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ad796bf779c8617d1e0d8111913ac3f8eaaf6532\",\"title\":\"Context-Aware Neural Machine Translation Learns Anaphora Resolution\",\"url\":\"https://www.semanticscholar.org/paper/ad796bf779c8617d1e0d8111913ac3f8eaaf6532\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151149706\",\"name\":\"Niehues Jan\"},{\"authorId\":\"144216810\",\"name\":\"R. Cattoni\"},{\"authorId\":\"151220649\",\"name\":\"St\\u00fcker Sebastian\"},{\"authorId\":\"3077970\",\"name\":\"M. Cettolo\"},{\"authorId\":\"145862931\",\"name\":\"M. Turchi\"},{\"authorId\":\"102811815\",\"name\":\"Marcello Federico\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"698984154fcc7b6089d1606dde63efd7e8831034\",\"title\":\"The IWSLT 2018 Evaluation Campaign\",\"url\":\"https://www.semanticscholar.org/paper/698984154fcc7b6089d1606dde63efd7e8831034\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"follow Ding\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"2017) and ignore non-linear activation functions\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143832874\",\"name\":\"Ondrej Bojar\"},{\"authorId\":\"3359291\",\"name\":\"C. Federmann\"},{\"authorId\":\"2032659\",\"name\":\"M. Fishel\"},{\"authorId\":\"2000709\",\"name\":\"Y. Graham\"},{\"authorId\":\"2259100\",\"name\":\"B. Haddow\"},{\"authorId\":\"1755162\",\"name\":\"Philipp Koehn\"},{\"authorId\":\"1696402\",\"name\":\"Christof Monz\"}],\"doi\":\"10.18653/v1/W18-6401\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48fbdf1be70221ac8a6b22079245030ab6158760\",\"title\":\"Findings of the 2018 Conference on Machine Translation (WMT18)\",\"url\":\"https://www.semanticscholar.org/paper/48fbdf1be70221ac8a6b22079245030ab6158760\",\"venue\":\"WMT\",\"year\":2018},{\"arxivId\":\"1902.09574\",\"authors\":[{\"authorId\":\"145635550\",\"name\":\"T. Gale\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"50237813\",\"name\":\"Sara Hooker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26384278cf5d575fc32cb92c303fb648fa0d5217\",\"title\":\"The State of Sparsity in Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/26384278cf5d575fc32cb92c303fb648fa0d5217\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19165330\",\"name\":\"Yanzhuo Ding\"},{\"authorId\":\"144090485\",\"name\":\"Yang Liu\"},{\"authorId\":\"3371599\",\"name\":\"Huanbo Luan\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.18653/v1/P17-1106\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"815f535da88e5b6f974527e6ddc72bca8e214fa9\",\"title\":\"Visualizing and Understanding Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/815f535da88e5b6f974527e6ddc72bca8e214fa9\",\"venue\":\"ACL\",\"year\":2017}],\"title\":\"Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned\",\"topics\":[{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Transformer\",\"topicId\":\"6977\",\"url\":\"https://www.semanticscholar.org/topic/6977\"},{\"topic\":\"Neural machine translation\",\"topicId\":\"210523\",\"url\":\"https://www.semanticscholar.org/topic/210523\"},{\"topic\":\"Lifting scheme\",\"topicId\":\"273536\",\"url\":\"https://www.semanticscholar.org/topic/273536\"},{\"topic\":\"BLEU\",\"topicId\":\"250421\",\"url\":\"https://www.semanticscholar.org/topic/250421\"},{\"topic\":\"Linear programming relaxation\",\"topicId\":\"9397\",\"url\":\"https://www.semanticscholar.org/topic/9397\"}],\"url\":\"https://www.semanticscholar.org/paper/07a64686ce8e43ac475a8d820a8a9f1d87989583\",\"venue\":\"ACL\",\"year\":2019}\n"