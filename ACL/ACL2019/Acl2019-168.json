"{\"abstract\":\"Given a small corpus $\\\\mathcal D_T$ pertaining to a limited set of focused topics, our goal is to train embeddings that accurately capture the sense of words in the topic in spite of the limited size of $\\\\mathcal D_T$. These embeddings may be used in various tasks involving $\\\\mathcal D_T$. A popular strategy in limited data settings is to adapt pre-trained embeddings $\\\\mathcal E$ trained on a large corpus. To correct for sense drift, fine-tuning, regularization, projection, and pivoting have been proposed recently. Among these, regularization informed by a word's corpus frequency performed well, but we improve upon it using a new regularizer based on the stability of its cooccurrence with other words. However, a thorough comparison across ten topics, spanning three tasks, with standardized settings of hyper-parameters, reveals that even the best embedding adaptation strategies provide small gains beyond well-tuned baselines, which many earlier comparisons ignored. In a bold departure from adapting pretrained embeddings, we propose using $\\\\mathcal D_T$ to probe, attend to, and borrow fragments from any large, topic-rich source corpus (such as Wikipedia), which need not be the corpus used to pretrain embeddings. This step is made scalable and practical by suitable indexing. We reach the surprising conclusion that even limited corpus augmentation is more useful than adapting embeddings, which suggests that non-dominant sense information may be irrevocably obliterated from pretrained embeddings and cannot be salvaged by adaptation.\",\"arxivId\":\"1906.02688\",\"authors\":[{\"authorId\":\"2748067\",\"name\":\"Vihari Piratla\",\"url\":\"https://www.semanticscholar.org/author/2748067\"},{\"authorId\":\"1770124\",\"name\":\"Sunita Sarawagi\",\"url\":\"https://www.semanticscholar.org/author/1770124\"},{\"authorId\":\"40941894\",\"name\":\"Soumen Chakrabarti\",\"url\":\"https://www.semanticscholar.org/author/40941894\"}],\"citationVelocity\":0,\"citations\":[],\"corpusId\":174803243,\"doi\":\"10.18653/v1/P19-1168\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"09997b1630ef2a63f617a4fec94400c5d3715c6e\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wael Hamza\"},{\"authorId\":null,\"name\":\"Radu Florian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bowman . 2019 . Glue : A multitask benchmark and analysis platform for natural language understanding\",\"url\":\"\",\"venue\":\"ICLR . ArXiv 1804 . 07461\",\"year\":2017},{\"arxivId\":\"1803.11175\",\"authors\":[{\"authorId\":\"46724030\",\"name\":\"Daniel Matthew Cer\"},{\"authorId\":\"2781059\",\"name\":\"Yinfei Yang\"},{\"authorId\":\"1803858\",\"name\":\"Sheng-yi Kong\"},{\"authorId\":\"49864394\",\"name\":\"Nan Hua\"},{\"authorId\":\"40831840\",\"name\":\"Nicole Limtiaco\"},{\"authorId\":\"40827793\",\"name\":\"Rhomni St. John\"},{\"authorId\":\"40832517\",\"name\":\"Noah Constant\"},{\"authorId\":\"1410898480\",\"name\":\"Mario Guajardo-Cespedes\"},{\"authorId\":\"40827370\",\"name\":\"Steve Yuan\"},{\"authorId\":\"7887562\",\"name\":\"C. Tar\"},{\"authorId\":\"2305450\",\"name\":\"Yun-Hsuan Sung\"},{\"authorId\":\"2704071\",\"name\":\"B. Strope\"},{\"authorId\":\"2186634\",\"name\":\"R. Kurzweil\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a76706d350b8c483a3aff73e61b91d15b5687335\",\"title\":\"Universal Sentence Encoder\",\"url\":\"https://www.semanticscholar.org/paper/a76706d350b8c483a3aff73e61b91d15b5687335\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1612.00796\",\"authors\":[{\"authorId\":\"1903300\",\"name\":\"J. Kirkpatrick\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"3422052\",\"name\":\"Neil C. Rabinowitz\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"2755582\",\"name\":\"G. Desjardins\"},{\"authorId\":\"2228824\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"8181864\",\"name\":\"K. Milan\"},{\"authorId\":\"34660073\",\"name\":\"John Quan\"},{\"authorId\":\"34505275\",\"name\":\"Tiago Ramalho\"},{\"authorId\":\"1398898827\",\"name\":\"Agnieszka Grabska-Barwinska\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"},{\"authorId\":\"2388737\",\"name\":\"C. Clopath\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"2315504\",\"name\":\"Raia Hadsell\"}],\"doi\":\"10.1073/pnas.1611835114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5151d6cb3a4eaec14a56944d58338251fca344ab\",\"title\":\"Overcoming catastrophic forgetting in neural networks\",\"url\":\"https://www.semanticscholar.org/paper/5151d6cb3a4eaec14a56944d58338251fca344ab\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2017},{\"arxivId\":\"1702.03814\",\"authors\":[{\"authorId\":\"40296541\",\"name\":\"Z. Wang\"},{\"authorId\":\"1836135\",\"name\":\"W. Hamza\"},{\"authorId\":\"1707117\",\"name\":\"Radu Florian\"}],\"doi\":\"10.24963/ijcai.2017/579\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9df777e4d8100e52e90fa4bd2d783d25a2fd173\",\"title\":\"Bilateral Multi-Perspective Matching for Natural Language Sentences\",\"url\":\"https://www.semanticscholar.org/paper/a9df777e4d8100e52e90fa4bd2d783d25a2fd173\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1805.04576\",\"authors\":[{\"authorId\":\"22603977\",\"name\":\"P. Sarma\"},{\"authorId\":\"40609253\",\"name\":\"Yingyu Liang\"},{\"authorId\":\"1755618\",\"name\":\"W. Sethares\"}],\"doi\":\"10.18653/v1/P18-2007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"756462aff77a451792778a3f6e3ebc09bcee6c1a\",\"title\":\"Domain Adapted Word Embeddings for Improved Sentiment Classification\",\"url\":\"https://www.semanticscholar.org/paper/756462aff77a451792778a3f6e3ebc09bcee6c1a\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1804.07461\",\"authors\":[{\"authorId\":\"144906624\",\"name\":\"Alex Wang\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"38614754\",\"name\":\"Julian Michael\"},{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"39455775\",\"name\":\"Omer Levy\"},{\"authorId\":\"3644767\",\"name\":\"Samuel R. Bowman\"}],\"doi\":\"10.18653/v1/W18-5446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93b8da28d006415866bf48f9a6e06b5242129195\",\"title\":\"GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/93b8da28d006415866bf48f9a6e06b5242129195\",\"venue\":\"BlackboxNLP@EMNLP\",\"year\":2018},{\"arxivId\":\"1804.00079\",\"authors\":[{\"authorId\":\"50324141\",\"name\":\"Sandeep Subramanian\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afc2850945a871e72c245818f9bc141bd659b453\",\"title\":\"Learning General Purpose Distributed Sentence Representations via Large Scale Multi-task Learning\",\"url\":\"https://www.semanticscholar.org/paper/afc2850945a871e72c245818f9bc141bd659b453\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38956216\",\"name\":\"Lili Mou\"},{\"authorId\":\"49349645\",\"name\":\"Hao Peng\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"},{\"authorId\":\"48615144\",\"name\":\"Yan Xu\"},{\"authorId\":\"144281339\",\"name\":\"L. Zhang\"},{\"authorId\":\"1700880\",\"name\":\"Zhi Jin\"}],\"doi\":\"10.18653/v1/D15-1279\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd32ebb9fac53a14202fb1a4f76ef96d1ff68c6c\",\"title\":\"Discriminative Neural Sentence Modeling by Tree-Based Convolution\",\"url\":\"https://www.semanticscholar.org/paper/bd32ebb9fac53a14202fb1a4f76ef96d1ff68c6c\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7264689\",\"name\":\"Yftah Ziser\"},{\"authorId\":\"1762757\",\"name\":\"Roi Reichart\"}],\"doi\":\"10.18653/v1/N18-1112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cef293344cd42145d3a81dbd813e6453c9120d8a\",\"title\":\"Pivot Based Language Modeling for Improved Neural Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/cef293344cd42145d3a81dbd813e6453c9120d8a\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143931536\",\"name\":\"J. Howard\"},{\"authorId\":\"2884561\",\"name\":\"Sebastian Ruder\"}],\"doi\":\"10.18653/v1/P18-1031\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e077413b25c4d34945cc2707e17e46ed4fe784a\",\"title\":\"Universal Language Model Fine-tuning for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e077413b25c4d34945cc2707e17e46ed4fe784a\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2116927\",\"name\":\"John Blitzer\"},{\"authorId\":\"143957226\",\"name\":\"R. McDonald\"},{\"authorId\":\"145366908\",\"name\":\"Fernando C Pereira\"}],\"doi\":\"10.3115/1610075.1610094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa8d73e572c3ca824a04a5f551b602a17831bc5\",\"title\":\"Domain Adaptation with Structural Correspondence Learning\",\"url\":\"https://www.semanticscholar.org/paper/9fa8d73e572c3ca824a04a5f551b602a17831bc5\",\"venue\":\"EMNLP\",\"year\":2006},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1902.00184\",\"authors\":[{\"authorId\":\"144205297\",\"name\":\"Wei Yang\"},{\"authorId\":\"143844110\",\"name\":\"Wei Lu\"},{\"authorId\":\"3113725\",\"name\":\"V. Zheng\"}],\"doi\":\"10.18653/v1/D17-1312\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d70df38462a8effa02fd8c8cfb94da8f82fcbcad\",\"title\":\"A Simple Regularization-based Algorithm for Learning Cross-Domain Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/d70df38462a8effa02fd8c8cfb94da8f82fcbcad\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1806.04381\",\"authors\":[{\"authorId\":\"144435436\",\"name\":\"Jeremy Barnes\"},{\"authorId\":\"66339110\",\"name\":\"Roman Klinger\"},{\"authorId\":\"7965906\",\"name\":\"Sabine Schulte im Walde\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f818447ce70181ca3cdbc129de82cb36acee0cbc\",\"title\":\"Projecting Embeddings for Domain Adaptation: Joint Modeling of Sentiment Analysis in Diverse Domains\",\"url\":\"https://www.semanticscholar.org/paper/f818447ce70181ca3cdbc129de82cb36acee0cbc\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1603.00968\",\"authors\":[{\"authorId\":\"39724818\",\"name\":\"Ye Zhang\"},{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"1912476\",\"name\":\"Byron C. Wallace\"}],\"doi\":\"10.18653/v1/N16-1178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1258db72eec4bbf02e29edf5bb0c300491a01242\",\"title\":\"MGNC-CNN: A Simple Approach to Exploiting Multiple Word Embeddings for Sentence Classification\",\"url\":\"https://www.semanticscholar.org/paper/1258db72eec4bbf02e29edf5bb0c300491a01242\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Daniel Cer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Universal sentence encoder. CoRR\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ricardo A. Baeza-Yates\"},{\"authorId\":null,\"name\":\"Berthier Ribeiro-Neto.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Modern Information Retrieval\",\"url\":\"\",\"venue\":\"AddisonWesley Longman Publishing Co., Inc., Boston, MA, USA.\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1940272\",\"name\":\"Matt J. Kusner\"},{\"authorId\":\"35760122\",\"name\":\"Yu Sun\"},{\"authorId\":\"1971973\",\"name\":\"Nicholas I. Kolkin\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66021a920001bc3e6258bffe7076d647614147b7\",\"title\":\"From Word Embeddings To Document Distances\",\"url\":\"https://www.semanticscholar.org/paper/66021a920001bc3e6258bffe7076d647614147b7\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1505.07184\",\"authors\":[{\"authorId\":\"2720656\",\"name\":\"Danushka Bollegala\"},{\"authorId\":\"2222390\",\"name\":\"T. Maehara\"},{\"authorId\":\"1743527\",\"name\":\"K. Kawarabayashi\"}],\"doi\":\"10.3115/v1/p15-1071\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4e9e0087b4d1e8ab414319057ce1f605356ad18b\",\"title\":\"Unsupervised Cross-Domain Word Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/4e9e0087b4d1e8ab414319057ce1f605356ad18b\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1607.01759\",\"authors\":[{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"3024698\",\"name\":\"E. Grave\"},{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":\"10.18653/V1/E17-2068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"892e53fe5cd39f037cb2a961499f42f3002595dd\",\"title\":\"Bag of Tricks for Efficient Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/892e53fe5cd39f037cb2a961499f42f3002595dd\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":\"1802.05365\",\"authors\":[{\"authorId\":\"39139825\",\"name\":\"Matthew E. Peters\"},{\"authorId\":\"50043859\",\"name\":\"Mark Neumann\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/N18-1202\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3febb2bed8865945e7fddc99efd791887bb7e14f\",\"title\":\"Deep contextualized word representations\",\"url\":\"https://www.semanticscholar.org/paper/3febb2bed8865945e7fddc99efd791887bb7e14f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48872685\",\"name\":\"Sewon Min\"},{\"authorId\":\"4418074\",\"name\":\"Minjoon Seo\"},{\"authorId\":\"2548384\",\"name\":\"Hannaneh Hajishirzi\"}],\"doi\":\"10.18653/v1/P17-2081\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb1087e8dee2039f773c381a3449a1c382482da6\",\"title\":\"Question Answering through Transfer Learning from Large Fine-grained Supervision Data\",\"url\":\"https://www.semanticscholar.org/paper/bb1087e8dee2039f773c381a3449a1c382482da6\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720656\",\"name\":\"Danushka Bollegala\"},{\"authorId\":\"35258592\",\"name\":\"D. J. Weir\"},{\"authorId\":\"144708726\",\"name\":\"J. Carroll\"}],\"doi\":\"10.3115/v1/P14-1058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f14cefed7a67fb92c93ff830b014e01484e16136\",\"title\":\"Learning to Predict Distributions of Words Across Domains\",\"url\":\"https://www.semanticscholar.org/paper/f14cefed7a67fb92c93ff830b014e01484e16136\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40483594\",\"name\":\"Wenpeng Yin\"},{\"authorId\":\"144418438\",\"name\":\"Hinrich Sch\\u00fctze\"}],\"doi\":\"10.18653/v1/P16-1128\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ab02efb13c1af6b1a5ab6f7597c79caf1d5c215\",\"title\":\"Learning Word Meta-Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/0ab02efb13c1af6b1a5ab6f7597c79caf1d5c215\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1804.05262\",\"authors\":[{\"authorId\":\"145462380\",\"name\":\"J. Coates\"},{\"authorId\":\"2720656\",\"name\":\"Danushka Bollegala\"}],\"doi\":\"10.18653/v1/N18-2031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"441cda3556c7e90ffadeaec4b8c96edeb76228b8\",\"title\":\"Frustratingly Easy Meta-Embedding - Computing Meta-Embeddings by Averaging Source Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/441cda3556c7e90ffadeaec4b8c96edeb76228b8\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1810.04805\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"3259253\",\"name\":\"Kristina Toutanova\"}],\"doi\":\"10.18653/v1/N19-1423\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"title\":\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/df2b0e26d0599ce3e70df8a9da02e51594e0e992\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720656\",\"name\":\"Danushka Bollegala\"},{\"authorId\":\"49590184\",\"name\":\"C. Bao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"08059481168f24e5788c617bfae50821f55a2182\",\"title\":\"Learning Word Meta-Embeddings by Autoencoding\",\"url\":\"https://www.semanticscholar.org/paper/08059481168f24e5788c617bfae50821f55a2182\",\"venue\":\"COLING\",\"year\":2018}],\"title\":\"Topic Sensitive Attention on Generic Corpora Corrects Sense Bias in Pretrained Embeddings\",\"topics\":[{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"Knowledge Graph\",\"topicId\":\"159858\",\"url\":\"https://www.semanticscholar.org/topic/159858\"},{\"topic\":\"Wikipedia\",\"topicId\":\"37413\",\"url\":\"https://www.semanticscholar.org/topic/37413\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"},{\"topic\":\"File spanning\",\"topicId\":\"2852713\",\"url\":\"https://www.semanticscholar.org/topic/2852713\"},{\"topic\":\"Matrix regularization\",\"topicId\":\"1280835\",\"url\":\"https://www.semanticscholar.org/topic/1280835\"},{\"topic\":\"Hyper-heuristic\",\"topicId\":\"415914\",\"url\":\"https://www.semanticscholar.org/topic/415914\"}],\"url\":\"https://www.semanticscholar.org/paper/09997b1630ef2a63f617a4fec94400c5d3715c6e\",\"venue\":\"ACL\",\"year\":2019}\n"