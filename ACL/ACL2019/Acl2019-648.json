"{\"abstract\":\"This paper presents a new model for visual dialog, Recurrent Dual Attention Network (ReDAN), using multi-step reasoning to answer a series of questions about an image. In each question-answering turn of a dialog, ReDAN infers the answer progressively through multiple reasoning steps. In each step of the reasoning process, the semantic representation of the question is updated based on the image and the previous dialog history, and the recurrently-refined representation is used for further reasoning in the subsequent step. On the VisDial v1.0 dataset, the proposed ReDAN model achieves a new state-of-the-art of 64.47% NDCG score. Visualization on the reasoning process further demonstrates that ReDAN can locate context-relevant visual and textual clues via iterative refinement, which can lead to the correct answer step-by-step.\",\"arxivId\":\"1902.00579\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\",\"url\":\"https://www.semanticscholar.org/author/144702900\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\",\"url\":\"https://www.semanticscholar.org/author/145215470\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\",\"url\":\"https://www.semanticscholar.org/author/1877430\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\",\"url\":\"https://www.semanticscholar.org/author/50703697\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\",\"url\":\"https://www.semanticscholar.org/author/38079056\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\",\"url\":\"https://www.semanticscholar.org/author/1800422\"}],\"citationVelocity\":18,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1785405226\",\"name\":\"Xiaofan Chen\"},{\"authorId\":\"1716428\",\"name\":\"Songyang Lao\"},{\"authorId\":\"1789237897\",\"name\":\"Ting Duan\"}],\"doi\":\"10.1145/3438872.3439098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0867cec490d447b02c25abaa00363606f205b9c9\",\"title\":\"Multimodal Fusion of Visual Dialog: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/0867cec490d447b02c25abaa00363606f205b9c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TIP.2020.3034494\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"title\":\"Learning Dual Encoding Model for Adaptive Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2008.04858\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"1643931890\",\"name\":\"Siyi Du\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"}],\"doi\":\"10.1145/3394171.3413826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"title\":\"KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.02379\",\"authors\":[{\"authorId\":\"46258988\",\"name\":\"Vishvak S. Murahari\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"}],\"doi\":\"10.1007/978-3-030-58523-5_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"604d7678235f5bb6039794e382d12058cecf8070\",\"title\":\"Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline\",\"url\":\"https://www.semanticscholar.org/paper/604d7678235f5bb6039794e382d12058cecf8070\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ca0a84cec5948526bafd14d06cd022c9a0a8de\",\"title\":\"Two Causal Principles for Improving Visual Dialog: Visual Dialog Challenge 2019 Winner Report\",\"url\":\"https://www.semanticscholar.org/paper/f7ca0a84cec5948526bafd14d06cd022c9a0a8de\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.03848\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03598364626c419d3a2578b5c22403f0dd246e99\",\"title\":\"Spatio-Temporal Scene Graphs for Video Dialog\",\"url\":\"https://www.semanticscholar.org/paper/03598364626c419d3a2578b5c22403f0dd246e99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02194\",\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"46507139\",\"name\":\"Haibo Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.01007\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a0d2ea210c9bd21676605682a76cec1a4004320a\",\"title\":\"Iterative Context-Aware Graph Inference for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/a0d2ea210c9bd21676605682a76cec1a4004320a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.06745\",\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhu\"},{\"authorId\":\"94228656\",\"name\":\"Fengda Zhu\"},{\"authorId\":\"83374215\",\"name\":\"Zhaohuan Zhan\"},{\"authorId\":\"16208574\",\"name\":\"Bingqian Lin\"},{\"authorId\":\"73416694\",\"name\":\"Jianbin Jiao\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"}],\"doi\":\"10.1109/cvpr42600.2020.01074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07de32d212a2d712b43557b4977b2ac76556e1d6\",\"title\":\"Vision-Dialog Navigation by Exploring Cross-Modal Memory\",\"url\":\"https://www.semanticscholar.org/paper/07de32d212a2d712b43557b4977b2ac76556e1d6\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a5c3216f8aad40b17531e78df8cc18e2b5c73ff\",\"title\":\"The Devil is in the Details: A Magnifying Glass for the GuessWhich Visual Dialogue Game\",\"url\":\"https://www.semanticscholar.org/paper/4a5c3216f8aad40b17531e78df8cc18e2b5c73ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40062064\",\"name\":\"Claudio Greco\"},{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fea5b24f57703f596fa01c188c3e445fa14994df\",\"title\":\"Which Turn do Neural Models Exploit the Most to Solve GuessWhat? Diving into the Dialogue History Encoding in Transformers and LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/fea5b24f57703f596fa01c188c3e445fa14994df\",\"venue\":\"NL4AI@AI*IA\",\"year\":2020},{\"arxivId\":\"1911.10496\",\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"title\":\"Two Causal Principles for Improving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.06698\",\"authors\":[{\"authorId\":\"71119060\",\"name\":\"Gi-Cheon Kang\"},{\"authorId\":\"1755502\",\"name\":\"Junseok Park\"},{\"authorId\":\"2294014\",\"name\":\"Hwaran Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"},{\"authorId\":\"153188145\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"36642cb0c60047846ccc9bb670a63f6884e976d1\",\"title\":\"DialGraph: Sparse Graph Learning Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/36642cb0c60047846ccc9bb670a63f6884e976d1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.03127\",\"authors\":[{\"authorId\":\"80927455\",\"name\":\"Takuma Udagawa\"},{\"authorId\":\"48342111\",\"name\":\"T. Yamazaki\"},{\"authorId\":\"1705519\",\"name\":\"A. Aizawa\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ee340c37a60d20dd8ebe19bc6fa614b981c2060\",\"title\":\"A Linguistic Analysis of Visually Grounded Dialogues Based on Spatial Expressions\",\"url\":\"https://www.semanticscholar.org/paper/6ee340c37a60d20dd8ebe19bc6fa614b981c2060\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144612044\",\"name\":\"H. Chauhan\"},{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.18653/v1/P19-1540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"314b6a975373f69f7628f2bc8647084181c84ac9\",\"title\":\"Ordinal and Attribute Aware Response Generation in a Multimodal Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/314b6a975373f69f7628f2bc8647084181c84ac9\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.08360\",\"authors\":[{\"authorId\":\"49102717\",\"name\":\"Feilong Chen\"},{\"authorId\":\"33427918\",\"name\":\"Fandong Meng\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"144326610\",\"name\":\"Peng Li\"},{\"authorId\":\"153260119\",\"name\":\"Bo Xu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I05.6248\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"title\":\"DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2002.02649\",\"authors\":[{\"authorId\":\"9202187\",\"name\":\"Chaoqun Duan\"},{\"authorId\":\"145500846\",\"name\":\"Lei Cui\"},{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2675365\",\"name\":\"Conghui Zhu\"},{\"authorId\":\"1856039\",\"name\":\"T. Zhao\"}],\"doi\":\"10.3233/FAIA200320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bf0bf048b88c2bb5a7d53e34ec912907295be81\",\"title\":\"Multimodal Matching Transformer for Live Commenting\",\"url\":\"https://www.semanticscholar.org/paper/7bf0bf048b88c2bb5a7d53e34ec912907295be81\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2006.06195\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50580345\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1431754650\",\"name\":\"C. Zhu\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"title\":\"Large-Scale Adversarial Training for Vision-and-Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8dc49a2041a8a269fbf64911a4f2c8cef6738a5c\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2002.10340\",\"authors\":[{\"authorId\":\"144052839\",\"name\":\"Wei Pang\"},{\"authorId\":\"50142157\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-58517-4_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7ba12958cb670442236accd5e0579728821ad7d\",\"title\":\"Guessing State Tracking for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/b7ba12958cb670442236accd5e0579728821ad7d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.14025\",\"authors\":[{\"authorId\":\"79778234\",\"name\":\"Sungjin Park\"},{\"authorId\":\"89016637\",\"name\":\"T. Whang\"},{\"authorId\":\"3037023\",\"name\":\"Y. Yoon\"},{\"authorId\":\"1450703435\",\"name\":\"Hueiseok Lim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"title\":\"Multi-View Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.09818\",\"authors\":[{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"},{\"authorId\":\"145109280\",\"name\":\"S. Walsh\"},{\"authorId\":\"49051223\",\"name\":\"Junting Zhang\"},{\"authorId\":\"38791445\",\"name\":\"J. Zhang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"title\":\"Generative Visual Dialogue System via Adaptive Reasoning and Weighted Likelihood Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.06206\",\"authors\":[{\"authorId\":\"9628638\",\"name\":\"Yun-Wei Chu\"},{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e885f1523349be48c884a4663d705487fde05b8a\",\"title\":\"Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/e885f1523349be48c884a4663d705487fde05b8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.00397\",\"authors\":[{\"authorId\":\"51115516\",\"name\":\"L. Yang\"},{\"authorId\":\"49435166\",\"name\":\"Fanqi Meng\"},{\"authorId\":\"31395194\",\"name\":\"Ming-Kuang Daniel Wu\"},{\"authorId\":\"1850625173\",\"name\":\"Vicent Ying\"},{\"authorId\":\"150345115\",\"name\":\"Xianchao Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c711f0b0f9e214d6ee462cffcac733221bf07026\",\"title\":\"SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space\",\"url\":\"https://www.semanticscholar.org/paper/c711f0b0f9e214d6ee462cffcac733221bf07026\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.02709\",\"authors\":[{\"authorId\":\"48806403\",\"name\":\"Zhenxing Zhang\"},{\"authorId\":\"52643489\",\"name\":\"L. Schomaker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fe68c8c970ba707e8767e5010c32b3cb1033063\",\"title\":\"DTGAN: Dual Attention Generative Adversarial Networks for Text-to-Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/6fe68c8c970ba707e8767e5010c32b3cb1033063\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"2008204693\",\"name\":\"Tobias Bianchi\"},{\"authorId\":\"1805994601\",\"name\":\"Mauricio Mazuecos\"},{\"authorId\":\"2008198429\",\"name\":\"Agata Marcante\"},{\"authorId\":\"3131683\",\"name\":\"Luciana Benotti\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.splu-1.4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"title\":\"They are not all alike: answering different spatial questions requires different grounding strategies\",\"url\":\"https://www.semanticscholar.org/paper/a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"venue\":\"SPLU\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"title\":\"Efficient Attention Mechanism for Handling All the Interactions between Many Inputs with Application to Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.13278\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1785083\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"145310663\",\"name\":\"Irwin King\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.269\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"06c7269c10125589d2599f684b751b1640f7a0cc\",\"title\":\"VD-BERT: A Unified Vision and Dialog Transformer with BERT\",\"url\":\"https://www.semanticscholar.org/paper/06c7269c10125589d2599f684b751b1640f7a0cc\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.07493\",\"authors\":[{\"authorId\":\"144992211\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"1681799\",\"name\":\"Verena Rieser\"}],\"doi\":\"10.18653/v1/2020.acl-main.728\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"8c3baa99376fac050160c25a9c6d92d9baa5846c\",\"title\":\"History for Visual Dialog: Do we really need it?\",\"url\":\"https://www.semanticscholar.org/paper/8c3baa99376fac050160c25a9c6d92d9baa5846c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"2008241757\",\"name\":\"Arunav Pratap Shandeelya\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.1371/journal.pone.0241271\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f76b2bf0de083c77f8730809b2c01c28c388c41\",\"title\":\"More to diverse: Generating diversified responses in a task oriented multimodal dialog system\",\"url\":\"https://www.semanticscholar.org/paper/9f76b2bf0de083c77f8730809b2c01c28c388c41\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":\"2010.11655\",\"authors\":[{\"authorId\":\"5015123\",\"name\":\"Y. Xu\"},{\"authorId\":\"39829184\",\"name\":\"Meng Fang\"},{\"authorId\":\"1409961430\",\"name\":\"Ling Chen\"},{\"authorId\":\"1390662136\",\"name\":\"Yali Du\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"48934799\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4d964088a73465dfaba81ecfc79637f421ed62f\",\"title\":\"Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/e4d964088a73465dfaba81ecfc79637f421ed62f\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"6764364\",\"name\":\"Nidhi Thakur\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59ee2e2ed78da75c356ba063c0a88466ffb62391\",\"title\":\"MultiDM-GCN: Aspect-Guided Response Generation in Multi-Domain Multi-Modal Dialogue System using Graph Convolution Network\",\"url\":\"https://www.semanticscholar.org/paper/59ee2e2ed78da75c356ba063c0a88466ffb62391\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2012.15015\",\"authors\":[{\"authorId\":\"65844131\",\"name\":\"Yuxian Meng\"},{\"authorId\":\"1845298604\",\"name\":\"Shuhe Wang\"},{\"authorId\":\"5439717\",\"name\":\"Qinghong Han\"},{\"authorId\":\"48304805\",\"name\":\"Xiaofei Sun\"},{\"authorId\":\"93192602\",\"name\":\"Fei Wu\"},{\"authorId\":null,\"name\":\"Rui Yan\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3470e15ae52baae8b8560dd59c616da9820cf43a\",\"title\":\"OpenViDial: A Large-Scale, Open-Domain Dialogue Dataset with Visual Contexts\",\"url\":\"https://www.semanticscholar.org/paper/3470e15ae52baae8b8560dd59c616da9820cf43a\",\"venue\":\"\",\"year\":2020}],\"corpusId\":59599940,\"doi\":\"10.18653/v1/P19-1648\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"references\":[{\"arxivId\":\"1607.04423\",\"authors\":[{\"authorId\":\"3043830\",\"name\":\"Yiming Cui\"},{\"authorId\":\"46842323\",\"name\":\"Z. Chen\"},{\"authorId\":\"144572674\",\"name\":\"Si Wei\"},{\"authorId\":\"1754280\",\"name\":\"S. Wang\"},{\"authorId\":\"46999402\",\"name\":\"T. Liu\"},{\"authorId\":\"40936264\",\"name\":\"G. Hu\"}],\"doi\":\"10.18653/v1/P17-1055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6e5df6322659276da6133f9b734a389d7a255e8\",\"title\":\"Attention-over-Attention Neural Networks for Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c6e5df6322659276da6133f9b734a389d7a255e8\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1711.07614\",\"authors\":[{\"authorId\":\"39449550\",\"name\":\"J. Zhang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"31361101\",\"name\":\"J. Zhang\"},{\"authorId\":\"145313245\",\"name\":\"Jianfeng Lu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-01228-1_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d1ad43e4bde61534d6ddc5752151f1775c04d08\",\"title\":\"Asking the Difficult Questions: Goal-Oriented Visual Question Generation via Intermediate Rewards\",\"url\":\"https://www.semanticscholar.org/paper/3d1ad43e4bde61534d6ddc5752151f1775c04d08\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.07613\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00639\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9dde6ed569684356c46217fa53224272b668bae8\",\"title\":\"Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dde6ed569684356c46217fa53224272b668bae8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f25e17eb717e5894e0404ea634451332f85d287\",\"title\":\"Learning Structured Output Representation using Deep Conditional Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/3f25e17eb717e5894e0404ea634451332f85d287\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1812.02664\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"48985581\",\"name\":\"Manli Zhang\"},{\"authorId\":\"47538869\",\"name\":\"J. Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"2259699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":\"10.1109/CVPR.2019.00684\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41db31c451cd819d22f9c0b90be110edc4424911\",\"title\":\"Recursive Visual Attention in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/41db31c451cd819d22f9c0b90be110edc4424911\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1902.09818\",\"authors\":[{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"},{\"authorId\":\"145109280\",\"name\":\"S. Walsh\"},{\"authorId\":\"49051223\",\"name\":\"Junting Zhang\"},{\"authorId\":\"38791445\",\"name\":\"J. Zhang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"title\":\"Generative Visual Dialogue System via Adaptive Reasoning and Weighted Likelihood Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1701.08251\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"3130583\",\"name\":\"Georgios P. Spithourakis\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880fca26169023a900c0f7d65d9b85abc5240a0\",\"title\":\"Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/c880fca26169023a900c0f7d65d9b85abc5240a0\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.06288\",\"authors\":[{\"authorId\":\"3111284\",\"name\":\"J. Chen\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1726477\",\"name\":\"J. Liu\"},{\"authorId\":\"1729368\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/CVPR.2018.00909\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d852da3f126ba2faca380064675a7af3805ec7cb\",\"title\":\"Language-Based Image Editing with Recurrent Attentive Models\",\"url\":\"https://www.semanticscholar.org/paper/d852da3f126ba2faca380064675a7af3805ec7cb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1701.06547\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"145768639\",\"name\":\"Will Monroe\"},{\"authorId\":\"10238549\",\"name\":\"Tianlin Shi\"},{\"authorId\":\"152857609\",\"name\":\"S\\u00e9bastien Jean\"},{\"authorId\":\"1863425\",\"name\":\"Alan Ritter\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.18653/v1/D17-1230\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"176f1d608b918eec8dc4b75e7b6e0acaba84a447\",\"title\":\"Adversarial Learning for Neural Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/176f1d608b918eec8dc4b75e7b6e0acaba84a447\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1712.03556\",\"authors\":[{\"authorId\":\"1729368\",\"name\":\"X. Liu\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"1800354\",\"name\":\"Kevin Duh\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P18-1157\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8490431f3a76fbd165d108eba938ead212a2a639\",\"title\":\"Stochastic Answer Networks for Machine Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/8490431f3a76fbd165d108eba938ead212a2a639\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1606.02245\",\"authors\":[{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f314339651cb25e4234e0b96fe8bd87206847993\",\"title\":\"Iterative Alternating Neural Attention for Machine Reading\",\"url\":\"https://www.semanticscholar.org/paper/f314339651cb25e4234e0b96fe8bd87206847993\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Junjie Zhang\"},{\"authorId\":null,\"name\":\"Qi Wu\"},{\"authorId\":null,\"name\":\"Chunhua Shen\"},{\"authorId\":null,\"name\":\"Jian Zhang\"},{\"authorId\":null,\"name\":\"Jianfeng Lu\"},{\"authorId\":null,\"name\":\"Anton Van Den Hengel.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Goaloriented visual question generation via intermediate rewards\",\"url\":\"\",\"venue\":\"ECCV.\",\"year\":2018},{\"arxivId\":\"1704.06877\",\"authors\":[{\"authorId\":\"40625240\",\"name\":\"Adams Wei Yu\"},{\"authorId\":\"8386466\",\"name\":\"Hongrae Lee\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":\"10.18653/v1/P17-1172\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c25a67ad7e8629a9d12b9e2fc356cd73af99a060\",\"title\":\"Learning to Skim Text\",\"url\":\"https://www.semanticscholar.org/paper/c25a67ad7e8629a9d12b9e2fc356cd73af99a060\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1805.06960\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"51190347\",\"name\":\"Tim Baumg\\u00e4rtner\"},{\"authorId\":\"46176433\",\"name\":\"Aashish Venkatesh\"},{\"authorId\":\"2552871\",\"name\":\"Elia Bruni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f59c20298f25bebda3f98eeb41f16ce9abb5f35a\",\"title\":\"Ask No More: Deciding when to guess in referential visual dialogue\",\"url\":\"https://www.semanticscholar.org/paper/f59c20298f25bebda3f98eeb41f16ce9abb5f35a\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Diederik P Kingma\"},{\"authorId\":null,\"name\":\"Max Welling.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Autoencoding variational bayes\",\"url\":\"\",\"venue\":\"ICLR.\",\"year\":2014},{\"arxivId\":\"1708.05122\",\"authors\":[{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60f432331abc0976cf236c738844f9427277b0de\",\"title\":\"Evaluating Visual Conversational Agents via Cooperative Human-AI Games\",\"url\":\"https://www.semanticscholar.org/paper/60f432331abc0976cf236c738844f9427277b0de\",\"venue\":\"HCOMP\",\"year\":2017},{\"arxivId\":\"1611.08481\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/CVPR.2017.475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bed7834ae7d371171977a590872f60d137c2f951\",\"title\":\"GuessWhat?! Visual Object Discovery through Multi-modal Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/bed7834ae7d371171977a590872f60d137c2f951\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1609.05473\",\"authors\":[{\"authorId\":\"3469209\",\"name\":\"Lantao Yu\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"39055225\",\"name\":\"J. Wang\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"title\":\"SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient\",\"url\":\"https://www.semanticscholar.org/paper/2966ecd82505ecd55ead0e6a327a304c8f9868e3\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J.-H. Kim\"},{\"authorId\":null,\"name\":\"K.-W. On\"},{\"authorId\":null,\"name\":\"W. Lim\"},{\"authorId\":null,\"name\":\"J. Kim\"},{\"authorId\":null,\"name\":\"J.-W. Ha\"},{\"authorId\":null,\"name\":\"B.-T. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"In ICLR,\",\"year\":2017},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1703.05423\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1808897\",\"name\":\"B. Piot\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.24963/ijcai.2017/385\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2cf792165eed4c0bfb25548f5dd63f43dca67a4\",\"title\":\"End-to-end optimization of goal-driven and visually grounded dialogue systems\",\"url\":\"https://www.semanticscholar.org/paper/e2cf792165eed4c0bfb25548f5dd63f43dca67a4\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"F. Strub\"},{\"authorId\":null,\"name\":\"M. Seurin\"},{\"authorId\":null,\"name\":\"E. Perez\"},{\"authorId\":null,\"name\":\"H. de Vries\"},{\"authorId\":null,\"name\":\"P. Preux\"},{\"authorId\":null,\"name\":\"A. Courville\"},{\"authorId\":null,\"name\":\"O. Pietquin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visual reasoning with multihop feature modulation\",\"url\":\"\",\"venue\":\"In ECCV,\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.07036\",\"authors\":[{\"authorId\":\"2890423\",\"name\":\"Eunsol Choi\"},{\"authorId\":\"144533687\",\"name\":\"He He\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144105277\",\"name\":\"Wen-tau Yih\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/D18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e734da43eb8c72e9549b42e96760545036f8e5\",\"title\":\"QuAC : Question Answering in Context\",\"url\":\"https://www.semanticscholar.org/paper/39e734da43eb8c72e9549b42e96760545036f8e5\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1902.09368\",\"authors\":[{\"authorId\":\"71119060\",\"name\":\"Gi-Cheon Kang\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.18653/v1/D19-1209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86754c8a22d5df5636aa5603db01835b5d4ee32c\",\"title\":\"Dual Attention Networks for Visual Reference Resolution in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/86754c8a22d5df5636aa5603db01835b5d4ee32c\",\"venue\":\"EMNLP\",\"year\":2019},{\"arxivId\":\"1808.04446\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"34675041\",\"name\":\"Mathieu Seurin\"},{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"34682317\",\"name\":\"P. Preux\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.1007/978-3-030-01228-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0654e75bfea7af13e021a22a21422b36270c08b7\",\"title\":\"Visual Reasoning with Multi-hop Feature Modulation\",\"url\":\"https://www.semanticscholar.org/paper/0654e75bfea7af13e021a22a21422b36270c08b7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.00145\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"47585344\",\"name\":\"Yu Cheng\"},{\"authorId\":\"30126647\",\"name\":\"Steven Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7158bd1635bf7bb87c557c429774d5236703e64\",\"title\":\"Dialog-based Interactive Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f7158bd1635bf7bb87c557c429774d5236703e64\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714708\",\"name\":\"S. Lee\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"975af82c9ce82a1fad760d58ba0a661217689aa9\",\"title\":\"Answerer in Questioner's Mind for Goal-Oriented Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/975af82c9ce82a1fad760d58ba0a661217689aa9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1809.01816\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-030-01267-0_10\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"782bc02684de81f98c92475957501801bf91e023\",\"title\":\"Visual Coreference Resolution in Visual Dialog using Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/782bc02684de81f98c92475957501801bf91e023\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1609.05284\",\"authors\":[{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"7307263\",\"name\":\"W. Chen\"}],\"doi\":\"10.1145/3097983.3098177\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c636a2dd242908fe2e598a1077c0c57bfdea8633\",\"title\":\"ReasoNet: Learning to Stop Reading in Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/c636a2dd242908fe2e598a1077c0c57bfdea8633\",\"venue\":\"CoCo@NIPS\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1802.03803\",\"authors\":[{\"authorId\":\"3469119\",\"name\":\"Daniela Massiceti\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"144679302\",\"name\":\"P. Dokania\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/CVPR.2018.00638\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7aa181fd7cadc7568d4fd87d2a1b12994ea1828\",\"title\":\"FLIPDIAL: A Generative Model for Two-Way Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/a7aa181fd7cadc7568d4fd87d2a1b12994ea1828\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.07042\",\"authors\":[{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"},{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1162/tacl_a_00266\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"990a7b4eceedb6e053e6386269481bdfc42a1094\",\"title\":\"CoQA: A Conversational Question Answering Challenge\",\"url\":\"https://www.semanticscholar.org/paper/990a7b4eceedb6e053e6386269481bdfc42a1094\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48441202\",\"name\":\"J. Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1561/1500000074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"venue\":\"Found. Trends Inf. Retr.\",\"year\":2019},{\"arxivId\":\"1803.03067\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"289fb3709475f5c87df8d97f129af54029d27fee\",\"title\":\"Compositional Attention Networks for Machine Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/289fb3709475f5c87df8d97f129af54029d27fee\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1606.01549\",\"authors\":[{\"authorId\":\"34994191\",\"name\":\"Bhuwan Dhingra\"},{\"authorId\":\"2391802\",\"name\":\"Hanxiao Liu\"},{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.18653/v1/P17-1168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f2ea810c16275dc74e880296e20dbd83b1bae1c\",\"title\":\"Gated-Attention Readers for Text Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/0f2ea810c16275dc74e880296e20dbd83b1bae1c\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.04623\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"title\":\"DRAW: A Recurrent Neural Network For Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1511.02301\",\"authors\":[{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35b91b365ceb016fb3e022577cec96fb9b445dc5\",\"title\":\"The Goldilocks Principle: Reading Children's Books with Explicit Memory Representations\",\"url\":\"https://www.semanticscholar.org/paper/35b91b365ceb016fb3e022577cec96fb9b445dc5\",\"venue\":\"ICLR\",\"year\":2016}],\"title\":\"Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog\",\"topics\":[{\"topic\":\"dialog\",\"topicId\":\"14876\",\"url\":\"https://www.semanticscholar.org/topic/14876\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Iterative method\",\"topicId\":\"304\",\"url\":\"https://www.semanticscholar.org/topic/304\"},{\"topic\":\"Iterative refinement\",\"topicId\":\"313424\",\"url\":\"https://www.semanticscholar.org/topic/313424\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Refinement (computing)\",\"topicId\":\"5410\",\"url\":\"https://www.semanticscholar.org/topic/5410\"},{\"topic\":\"Holographic principle\",\"topicId\":\"125587\",\"url\":\"https://www.semanticscholar.org/topic/125587\"}],\"url\":\"https://www.semanticscholar.org/paper/8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"venue\":\"ACL\",\"year\":2019}\n"