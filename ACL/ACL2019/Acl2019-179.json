"{\"abstract\":\"Previous work on end-to-end translation from speech has primarily used frame-level features as speech representations, which creates longer, sparser sequences than text. We show that a naive method to create compressed phoneme-like speech representations is far more effective and efficient for translation than traditional frame-level speech features. Specifically, we generate phoneme labels for speech frames and average consecutive frames with the same label to create shorter, higher-level source sequences for translation. We see improvements of up to 5 BLEU on both our high and low resource language pairs, with a reduction in training time of 60%. Our improvements hold across multiple data sizes and two language pairs.\",\"arxivId\":\"1906.01199\",\"authors\":[{\"authorId\":\"3448427\",\"name\":\"Elizabeth Salesky\",\"url\":\"https://www.semanticscholar.org/author/3448427\"},{\"authorId\":\"3011998\",\"name\":\"Matthias Sperber\",\"url\":\"https://www.semanticscholar.org/author/3011998\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\",\"url\":\"https://www.semanticscholar.org/author/1690706\"}],\"citationVelocity\":5,\"citations\":[{\"arxivId\":\"2005.10678\",\"authors\":[{\"authorId\":\"7146976\",\"name\":\"Shun-Po Chuang\"},{\"authorId\":\"35066371\",\"name\":\"Tzu-Wei Sung\"},{\"authorId\":\"49285584\",\"name\":\"Alexander H. Liu\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.18653/v1/2020.acl-main.533\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"8a48f9b899b61c2a340c0fdd001031c06c31be96\",\"title\":\"Worse WER, but Better BLEU? Leveraging Word Embedding as Intermediate in Multitask End-to-End Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/8a48f9b899b61c2a340c0fdd001031c06c31be96\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2010.13047\",\"authors\":[{\"authorId\":\"49276525\",\"name\":\"Hirofumi Inaguma\"},{\"authorId\":\"46722767\",\"name\":\"Yosuke Higuchi\"},{\"authorId\":\"1800354\",\"name\":\"Kevin Duh\"},{\"authorId\":\"1717105\",\"name\":\"Tatsuya Kawahara\"},{\"authorId\":\"1826565368\",\"name\":\"Shinji Watanabe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"589e651c69251ee20a89e075d015eb03b35cf17d\",\"title\":\"Orthros: Non-autoregressive End-to-end Speech Translation with Dual-decoder\",\"url\":\"https://www.semanticscholar.org/paper/589e651c69251ee20a89e075d015eb03b35cf17d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06358\",\"authors\":[{\"authorId\":\"3011998\",\"name\":\"Matthias Sperber\"},{\"authorId\":\"1775245\",\"name\":\"M. Paulik\"}],\"doi\":\"10.18653/v1/2020.acl-main.661\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b57a537ae33092b7acf83dbd0470c6c03752fc79\",\"title\":\"Speech Translation and the End-to-End Promise: Taking Stock of Where We Are\",\"url\":\"https://www.semanticscholar.org/paper/b57a537ae33092b7acf83dbd0470c6c03752fc79\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3469333\",\"name\":\"Sameer Bansal\"}],\"doi\":\"10.7488/ERA/86\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1aacddf2619f704416427473a0f26d353cb97a0f\",\"title\":\"Low-resource speech translation\",\"url\":\"https://www.semanticscholar.org/paper/1aacddf2619f704416427473a0f26d353cb97a0f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.09737\",\"authors\":[{\"authorId\":\"48965598\",\"name\":\"Qianqian Dong\"},{\"authorId\":\"50468534\",\"name\":\"Mingxuan Wang\"},{\"authorId\":null,\"name\":\"Hao Zhou\"},{\"authorId\":null,\"name\":\"Shuang Xu\"},{\"authorId\":null,\"name\":\"Bo Xu\"},{\"authorId\":\"143900005\",\"name\":\"Lei Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa02f925d24f14aeab3183590b0edb1932b5790a\",\"title\":\"SDST: Successive Decoding for Speech-to-text Translation\",\"url\":\"https://www.semanticscholar.org/paper/fa02f925d24f14aeab3183590b0edb1932b5790a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.09704\",\"authors\":[{\"authorId\":\"48965598\",\"name\":\"Qianqian Dong\"},{\"authorId\":\"50468534\",\"name\":\"Mingxuan Wang\"},{\"authorId\":null,\"name\":\"Hao Zhou\"},{\"authorId\":null,\"name\":\"Shuang Xu\"},{\"authorId\":null,\"name\":\"Bo Xu\"},{\"authorId\":\"143900005\",\"name\":\"Lei Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4159d49e449f2f9d716e454dc2c89d018f5a0af\",\"title\":\"TED: Triple Supervision Decouples End-to-end Speech-to-text Translation\",\"url\":\"https://www.semanticscholar.org/paper/a4159d49e449f2f9d716e454dc2c89d018f5a0af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47611972\",\"name\":\"P. Pol\\u00e1k\"},{\"authorId\":\"145541202\",\"name\":\"Sangeet Sagar\"},{\"authorId\":\"51013078\",\"name\":\"Dominik Mach\\u00e1cek\"},{\"authorId\":\"143832874\",\"name\":\"Ondrej Bojar\"}],\"doi\":\"10.18653/v1/2020.iwslt-1.24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b339ef04b495c2deab60f9caf8fc03a33aebe73e\",\"title\":\"CUNI Neural ASR with Phoneme-Level Intermediate Step for~Non-Native~SLT at IWSLT 2020\",\"url\":\"https://www.semanticscholar.org/paper/b339ef04b495c2deab60f9caf8fc03a33aebe73e\",\"venue\":\"IWSLT\",\"year\":2020},{\"arxivId\":\"1911.03167\",\"authors\":[{\"authorId\":\"1404337029\",\"name\":\"Javier Iranzo-S\\u00e1nchez\"},{\"authorId\":\"1398321652\",\"name\":\"Joan Albert Silvestre-Cerd\\u00e0\"},{\"authorId\":\"144373282\",\"name\":\"Javier Jorge\"},{\"authorId\":\"1404337037\",\"name\":\"Nahuel Rosell\\u00f3\"},{\"authorId\":\"144067341\",\"name\":\"A. Gim\\u00e9nez\"},{\"authorId\":\"145277890\",\"name\":\"A. Sanch\\u00eds\"},{\"authorId\":\"2641391\",\"name\":\"Jorge Civera Saiz\"},{\"authorId\":\"1398305843\",\"name\":\"Alfons Juan-C\\u00edscar\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054626\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e79ea35af175419706c6d8e1131fb9b2e0b2737\",\"title\":\"Europarl-ST: A Multilingual Corpus for Speech Translation of Parliamentary Debates\",\"url\":\"https://www.semanticscholar.org/paper/1e79ea35af175419706c6d8e1131fb9b2e0b2737\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2010.08518\",\"authors\":[{\"authorId\":\"48335426\",\"name\":\"Biao Zhang\"},{\"authorId\":\"144889265\",\"name\":\"Ivan Titov\"},{\"authorId\":\"2259100\",\"name\":\"B. Haddow\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18cfec1210265f89f803e016cdfa66f80388fcee\",\"title\":\"Adaptive Feature Selection for End-to-End Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/18cfec1210265f89f803e016cdfa66f80388fcee\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7146976\",\"name\":\"Shun-Po Chuang\"},{\"authorId\":\"49285584\",\"name\":\"Alexander H. Liu\"},{\"authorId\":\"35066371\",\"name\":\"Tzu-Wei Sung\"},{\"authorId\":\"8679507\",\"name\":\"H. Lee\"}],\"doi\":\"10.1109/TASLP.2020.3037543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edb8eca8dd359fd8c446ab4efa490424f8fd4e6\",\"title\":\"Improving Automatic Speech Recognition and Speech Translation via Word Embedding Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6edb8eca8dd359fd8c446ab4efa490424f8fd4e6\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2021},{\"arxivId\":\"2005.13681\",\"authors\":[{\"authorId\":\"3448427\",\"name\":\"Elizabeth Salesky\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.18653/v1/2020.acl-main.217\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"15fb586993d1b269a72e61cfcebb69a56de6a3f1\",\"title\":\"Phone Features Improve Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/15fb586993d1b269a72e61cfcebb69a56de6a3f1\",\"venue\":\"ACL\",\"year\":2020}],\"corpusId\":174798018,\"doi\":\"10.18653/v1/P19-1179\",\"fieldsOfStudy\":[\"Computer Science\",\"Engineering\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"fbd47a815c73a83e8a47ee2ed38826c82ffc0c2a\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Matthias Sperber\"},{\"authorId\":null,\"name\":\"Jan Niehues\"},{\"authorId\":null,\"name\":\"Graham Neubig\"},{\"authorId\":null,\"name\":\"Sebastian St\\u00fcker\"},{\"authorId\":null,\"name\":\"Alex Waibel.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Selfattentional acoustic models\",\"url\":\"\",\"venue\":\"Proc. of EMNLP. ArXiv:1803.09519.\",\"year\":2018},{\"arxivId\":\"1807.10984\",\"authors\":[{\"authorId\":\"35186886\",\"name\":\"Siddharth Dalmia\"},{\"authorId\":\"50079262\",\"name\":\"Xinjian Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.1109/SLT.2018.8639569\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12b1e5e5bdfe2429d98fb5218fd0ab0905bff067\",\"title\":\"Domain Robust Feature Extraction for Rapid Low Resource ASR Development\",\"url\":\"https://www.semanticscholar.org/paper/12b1e5e5bdfe2429d98fb5218fd0ab0905bff067\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":\"1802.07420\",\"authors\":[{\"authorId\":\"35186886\",\"name\":\"Siddharth Dalmia\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.1109/ICASSP.2018.8461802\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"632d25ef7914ce962d258920460a9405b8c4553a\",\"title\":\"Sequence-Based Multi-Lingual Low Resource Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/632d25ef7914ce962d258920460a9405b8c4553a\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"To downsample in time we instead use the LSTM/NiN model used in Sperber et al\",\"url\":\"\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1802.06655\",\"authors\":[{\"authorId\":\"49513989\",\"name\":\"Antonios Anastasopoulos\"},{\"authorId\":\"145287425\",\"name\":\"David Chiang\"}],\"doi\":\"10.18653/v1/N18-1008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c27d7e93a41001184a44cd63c132c93dc2c50820\",\"title\":\"Tied Multitask Learning for Neural Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/c27d7e93a41001184a44cd63c132c93dc2c50820\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1803.08976\",\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/Interspeech.2018-2341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083ec74cc10f96fbb64322ba23450666fd4df6cd\",\"title\":\"Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech\",\"url\":\"https://www.semanticscholar.org/paper/083ec74cc10f96fbb64322ba23450666fd4df6cd\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"}],\"doi\":\"10.1109/ICASSP.2016.7472621\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3056add22b20e3361c38c0472d294a79d4031cb4\",\"title\":\"Listen, attend and spell: A neural network for large vocabulary conversational speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/3056add22b20e3361c38c0472d294a79d4031cb4\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1512.05287\",\"authors\":[{\"authorId\":\"2681954\",\"name\":\"Yarin Gal\"},{\"authorId\":\"1744700\",\"name\":\"Zoubin Ghahramani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652\",\"title\":\"A Theoretically Grounded Application of Dropout in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c1f9ca23f4f09ecfc44bcc8ca1c2736624f4652\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693321\",\"name\":\"S. St\\u00fcker\"},{\"authorId\":\"145618636\",\"name\":\"Tanja Schultz\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.1109/ICASSP.2003.1198737\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e78a1b344c1c8da71756494941873716b999410d\",\"title\":\"Multilingual articulatory features\",\"url\":\"https://www.semanticscholar.org/paper/e78a1b344c1c8da71756494941873716b999410d\",\"venue\":\"2003 IEEE International Conference on Acoustics, Speech, and Signal Processing, 2003. Proceedings. (ICASSP '03).\",\"year\":2003},{\"arxivId\":\"1803.09164\",\"authors\":[{\"authorId\":\"3469333\",\"name\":\"Sameer Bansal\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"},{\"authorId\":\"144871732\",\"name\":\"A. Lopez\"},{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"}],\"doi\":\"10.21437/Interspeech.2018-1326\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4f33b7aeec807df6d4c611d00eaa69f9e94d842a\",\"title\":\"Low-Resource Speech-to-Text Translation\",\"url\":\"https://www.semanticscholar.org/paper/4f33b7aeec807df6d4c611d00eaa69f9e94d842a\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"2268620\",\"name\":\"A. Ghoshal\"},{\"authorId\":\"2541218\",\"name\":\"Gilles Boulianne\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"3075141\",\"name\":\"O. Glembek\"},{\"authorId\":\"46356878\",\"name\":\"N. Goel\"},{\"authorId\":\"2592983\",\"name\":\"M. Hannemann\"},{\"authorId\":\"2745667\",\"name\":\"Petr Motl\\u00edcek\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"35455336\",\"name\":\"P. Schwarz\"},{\"authorId\":\"3330139\",\"name\":\"J. Silovsk\\u00fd\"},{\"authorId\":\"1708033\",\"name\":\"G. Stemmer\"},{\"authorId\":\"2459598\",\"name\":\"K. Vesel\\u00fd\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3a1a2cff2b70fb84a7ca7d97f8adcc5855851795\",\"title\":\"The Kaldi Speech Recognition Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/3a1a2cff2b70fb84a7ca7d97f8adcc5855851795\",\"venue\":\"\",\"year\":2011},{\"arxivId\":\"1610.03022\",\"authors\":[{\"authorId\":\"1682848\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":\"10.1109/ICASSP.2017.7953077\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d838994020a794b857a4cd356bfbbf7b52da7473\",\"title\":\"Very deep convolutional networks for end-to-end speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/d838994020a794b857a4cd356bfbbf7b52da7473\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":\"1508.07909\",\"authors\":[{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"2259100\",\"name\":\"B. Haddow\"},{\"authorId\":\"2539211\",\"name\":\"Alexandra Birch\"}],\"doi\":\"10.18653/v1/P16-1162\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1af68821518f03568f913ab03fc02080247a27ff\",\"title\":\"Neural Machine Translation of Rare Words with Subword Units\",\"url\":\"https://www.semanticscholar.org/paper/1af68821518f03568f913ab03fc02080247a27ff\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144192179\",\"name\":\"A. Wilkinson\"},{\"authorId\":\"8200875\",\"name\":\"Tiancheng Zhao\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.21437/Interspeech.2016-1319\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39ecd41c3a8d6f113218007ce30d3d4be55f36e0\",\"title\":\"Deriving Phonetic Transcriptions and Discovering Word Segmentations for Speech-to-Speech Translation in Low-Resource Settings\",\"url\":\"https://www.semanticscholar.org/paper/39ecd41c3a8d6f113218007ce30d3d4be55f36e0\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":\"1810.08641\",\"authors\":[{\"authorId\":\"3448427\",\"name\":\"Elizabeth Salesky\"},{\"authorId\":\"80081214\",\"name\":\"Andrew Runge\"},{\"authorId\":\"80195231\",\"name\":\"A. Coda\"},{\"authorId\":\"2920247\",\"name\":\"J. Niehues\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.1007/s10590-019-09243-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"485b3f77b9913e151e7ca897d99497e70e7f30d1\",\"title\":\"Optimizing segmentation granularity for neural machine translation\",\"url\":\"https://www.semanticscholar.org/paper/485b3f77b9913e151e7ca897d99497e70e7f30d1\",\"venue\":\"Machine Translation\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Black\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deriving phonetic transcriptions\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1802.04200\",\"authors\":[{\"authorId\":\"3449364\",\"name\":\"Alexandre Berard\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"35976744\",\"name\":\"A. Kocabiyikoglu\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.1109/ICASSP.2018.8461690\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c4fe2bfacc6db6b446401f164a406c48b642e86\",\"title\":\"End-to-End Automatic Speech Translation of Audiobooks\",\"url\":\"https://www.semanticscholar.org/paper/4c4fe2bfacc6db6b446401f164a406c48b642e86\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1710.01329\",\"authors\":[{\"authorId\":\"32125163\",\"name\":\"Toan Q. Nguyen\"},{\"authorId\":\"145287425\",\"name\":\"David Chiang\"}],\"doi\":\"10.18653/v1/N18-1031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3acf8313546def523da334cb3324806ac229769f\",\"title\":\"Improving Lexical Choice in Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/3acf8313546def523da334cb3324806ac229769f\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1809.01431\",\"authors\":[{\"authorId\":\"3469333\",\"name\":\"Sameer Bansal\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"},{\"authorId\":\"144871732\",\"name\":\"A. Lopez\"},{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"}],\"doi\":\"10.18653/v1/N19-1006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19f66dd83abef074b04169ed448251b55429e6d9\",\"title\":\"Pre-training on high-resource speech recognition improves low-resource speech-to-text translation\",\"url\":\"https://www.semanticscholar.org/paper/19f66dd83abef074b04169ed448251b55429e6d9\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1803.00188\",\"authors\":[{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"3011998\",\"name\":\"Matthias Sperber\"},{\"authorId\":\"3277494\",\"name\":\"Xinyi Wang\"},{\"authorId\":\"40895015\",\"name\":\"Matthieu Felix\"},{\"authorId\":\"144633696\",\"name\":\"A. Matthews\"},{\"authorId\":\"51177454\",\"name\":\"S. Padmanabhan\"},{\"authorId\":\"145270896\",\"name\":\"Ye Qi\"},{\"authorId\":\"39670454\",\"name\":\"Devendra Singh Sachan\"},{\"authorId\":\"144332819\",\"name\":\"Philip Arthur\"},{\"authorId\":\"47267872\",\"name\":\"P. Godard\"},{\"authorId\":\"145430120\",\"name\":\"John Hewitt\"},{\"authorId\":\"40425637\",\"name\":\"Rachid Riad\"},{\"authorId\":\"46659717\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c82727731955a2332a0cc38ec56b35a971061eb\",\"title\":\"XNMT: The eXtensible Neural Machine Translation Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/6c82727731955a2332a0cc38ec56b35a971061eb\",\"venue\":\"AMTA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"David Graff\"},{\"authorId\":null,\"name\":\"Shudong Huang\"},{\"authorId\":null,\"name\":\"Ingrid Cartagena\"},{\"authorId\":null,\"name\":\"Kevin Walker\"},{\"authorId\":null,\"name\":\"Christopher Cieri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fisher spanish speech (LDC2010S01). Https://catalog.ldc.upenn.edu/ ldc2010s01\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"395a8f9e7dc5a074ede32d6343fafd7fdff62cbe\",\"title\":\"Sequence-to-Sequence Models Can Directly Transcribe Foreign Speech\",\"url\":\"https://www.semanticscholar.org/paper/395a8f9e7dc5a074ede32d6343fafd7fdff62cbe\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1508.04025\",\"authors\":[{\"authorId\":\"1821711\",\"name\":\"Thang Luong\"},{\"authorId\":\"143950636\",\"name\":\"Hieu Pham\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/D15-1166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93499a7c7f699b6630a86fad964536f9423bb6d0\",\"title\":\"Effective Approaches to Attention-based Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/93499a7c7f699b6630a86fad964536f9423bb6d0\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1803.09519\",\"authors\":[{\"authorId\":\"3011998\",\"name\":\"Matthias Sperber\"},{\"authorId\":\"2920247\",\"name\":\"J. Niehues\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"1693321\",\"name\":\"S. St\\u00fcker\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.21437/Interspeech.2018-1910\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c52ac453e154953abdb06fc041023e327ea609a4\",\"title\":\"Self-Attentional Acoustic Models\",\"url\":\"https://www.semanticscholar.org/paper/c52ac453e154953abdb06fc041023e327ea609a4\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"1808.09943\",\"authors\":[{\"authorId\":\"144507724\",\"name\":\"Colin Cherry\"},{\"authorId\":\"144293067\",\"name\":\"G. Foster\"},{\"authorId\":\"12295226\",\"name\":\"Ankur Bapna\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"},{\"authorId\":\"3153147\",\"name\":\"Wolfgang Macherey\"}],\"doi\":\"10.18653/v1/D18-1461\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87639a90e0ab573236efeb79cf24efafc2463dcf\",\"title\":\"Revisiting Character-Based Neural Machine Translation with Capacity and Compression\",\"url\":\"https://www.semanticscholar.org/paper/87639a90e0ab573236efeb79cf24efafc2463dcf\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38842528\",\"name\":\"Matt Post\"},{\"authorId\":\"50211133\",\"name\":\"G. Kumar\"},{\"authorId\":\"144871732\",\"name\":\"A. Lopez\"},{\"authorId\":\"2841922\",\"name\":\"D. Karakos\"},{\"authorId\":\"1763608\",\"name\":\"Chris Callison-Burch\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"506d59d35f51796c8c3809da68e71a21238e8c67\",\"title\":\"Improved Speech-to-Text Translation with the Fisher and Callhome Spanish\\u2013English Speech Translation Corpus\",\"url\":\"https://www.semanticscholar.org/paper/506d59d35f51796c8c3809da68e71a21238e8c67\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1603.02845\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"}],\"doi\":\"10.1109/TASLP.2016.2517567\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b38190bd0224ef98118260971ecdb2bf7f345e2\",\"title\":\"Unsupervised Word Segmentation and Lexicon Discovery Using Acoustic Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/9b38190bd0224ef98118260971ecdb2bf7f345e2\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Minh-Thang Luong\"},{\"authorId\":null,\"name\":\"Hieu Pham\"},{\"authorId\":null,\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Effective approaches to attentionbased neural machine translation\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1710.03501\",\"authors\":[{\"authorId\":\"47267872\",\"name\":\"P. Godard\"},{\"authorId\":\"1405616546\",\"name\":\"G. Adda\"},{\"authorId\":\"1398188506\",\"name\":\"M. Adda-Decker\"},{\"authorId\":\"145903938\",\"name\":\"Juan Benjumea\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"1409054818\",\"name\":\"Jamison Cooper-Leavitt\"},{\"authorId\":\"3400337\",\"name\":\"Guy-No\\u00ebl Kouarata\"},{\"authorId\":\"145204681\",\"name\":\"L. Lamel\"},{\"authorId\":\"1403371171\",\"name\":\"H. Bonneau-Maynard\"},{\"authorId\":\"50098494\",\"name\":\"M. M\\u00fcller\"},{\"authorId\":\"3400352\",\"name\":\"A. Rialland\"},{\"authorId\":\"1693321\",\"name\":\"S. St\\u00fcker\"},{\"authorId\":\"1846431\",\"name\":\"Fran\\u00e7ois Yvon\"},{\"authorId\":\"2635755\",\"name\":\"Marcely Zanon Boito\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8593e8858db297349cffbb2144e2621b5c2f049\",\"title\":\"A Very Low Resource Language Speech Corpus for Computational Language Documentation Experiments\",\"url\":\"https://www.semanticscholar.org/paper/a8593e8858db297349cffbb2144e2621b5c2f049\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":\"1703.08581\",\"authors\":[{\"authorId\":\"39571582\",\"name\":\"Ron J. Weiss\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"}],\"doi\":\"10.21437/INTERSPEECH.2017-503\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dda047fd87610911c82778243f72f60d1c063383\",\"title\":\"Sequence-to-Sequence Models Can Directly Translate Foreign Speech\",\"url\":\"https://www.semanticscholar.org/paper/dda047fd87610911c82778243f72f60d1c063383\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1702.03856\",\"authors\":[{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"},{\"authorId\":\"152134956\",\"name\":\"Adam Lopez\"},{\"authorId\":\"3469333\",\"name\":\"Sameer Bansal\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"}],\"doi\":\"10.18653/V1/E17-2076\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a4a6aed9e303ac6cda71a7022e91254009e0a1c\",\"title\":\"Towards speech-to-text translation without speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/1a4a6aed9e303ac6cda71a7022e91254009e0a1c\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Bansal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"layer for a total of three BiLSTM layers with the same total downsampling of 4 as Weiss et al\",\"url\":\"\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38535429\",\"name\":\"Oliver Adams\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"143620680\",\"name\":\"Trevor Cohn\"},{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"},{\"authorId\":\"2527751\",\"name\":\"Quoc Truong Do\"},{\"authorId\":\"145223960\",\"name\":\"S. Nakamura\"}],\"doi\":\"10.18653/v1/D16-1263\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91e605a125f64207a242693d0dc1c862080f6c27\",\"title\":\"Learning a Lexicon and Translation Model from Phoneme Lattices\",\"url\":\"https://www.semanticscholar.org/paper/91e605a125f64207a242693d0dc1c862080f6c27\",\"venue\":\"EMNLP\",\"year\":2016}],\"title\":\"Exploring Phoneme-Level Speech Representations for End-to-End Speech Translation\",\"topics\":[{\"topic\":\"Phoneme\",\"topicId\":\"12600\",\"url\":\"https://www.semanticscholar.org/topic/12600\"},{\"topic\":\"BLEU\",\"topicId\":\"250421\",\"url\":\"https://www.semanticscholar.org/topic/250421\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Frame (physical object)\",\"topicId\":\"4537\",\"url\":\"https://www.semanticscholar.org/topic/4537\"},{\"topic\":\"Jumbo frame\",\"topicId\":\"1265749\",\"url\":\"https://www.semanticscholar.org/topic/1265749\"},{\"topic\":\"Assembly language\",\"topicId\":\"68122\",\"url\":\"https://www.semanticscholar.org/topic/68122\"},{\"topic\":\"Genetic Translation Process\",\"topicId\":\"15488\",\"url\":\"https://www.semanticscholar.org/topic/15488\"}],\"url\":\"https://www.semanticscholar.org/paper/fbd47a815c73a83e8a47ee2ed38826c82ffc0c2a\",\"venue\":\"ACL\",\"year\":2019}\n"