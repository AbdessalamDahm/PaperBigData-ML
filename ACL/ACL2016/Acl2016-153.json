"{\"abstract\":\"This paper introduces a novel architecture for reinforcement learning with deep neural networks designed to handle state and action spaces characterized by natural language, as found in text-based games. Termed a deep reinforcement relevance network (DRRN), the architecture represents action and state spaces with separate embedding vectors, which are combined with an interaction function to approximate the Q-function in reinforcement learning. We evaluate the DRRN on two popular text games, showing superior performance over other deep Q-learning architectures. Experiments with paraphrased action descriptions show that the model is extracting meaning rather than simply memorizing strings of text.\",\"arxivId\":\"1511.04636\",\"authors\":[{\"authorId\":\"49264189\",\"name\":\"Ji He\",\"url\":\"https://www.semanticscholar.org/author/49264189\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\",\"url\":\"https://www.semanticscholar.org/author/1720246\"},{\"authorId\":\"144137069\",\"name\":\"X. He\",\"url\":\"https://www.semanticscholar.org/author/144137069\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\",\"url\":\"https://www.semanticscholar.org/author/1800422\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\",\"url\":\"https://www.semanticscholar.org/author/28929337\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\",\"url\":\"https://www.semanticscholar.org/author/144718788\"},{\"authorId\":\"144339506\",\"name\":\"Mari Ostendorf\",\"url\":\"https://www.semanticscholar.org/author/144339506\"}],\"citationVelocity\":31,\"citations\":[{\"arxivId\":\"2005.02233\",\"authors\":[{\"authorId\":\"30087809\",\"name\":\"Yinpei Dai\"},{\"authorId\":\"65967419\",\"name\":\"Huihua Yu\"},{\"authorId\":\"7912096\",\"name\":\"Yixuan Jiang\"},{\"authorId\":\"1672552269\",\"name\":\"Chengguang Tang\"},{\"authorId\":\"34727594\",\"name\":\"Yongbin Li\"},{\"authorId\":\"2084926\",\"name\":\"J. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bcf51512bfe0b6785f6b1dca20613b732faea88\",\"title\":\"A Survey on Dialog Management: Recent Advances and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3bcf51512bfe0b6785f6b1dca20613b732faea88\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.10577\",\"authors\":[{\"authorId\":\"2429349\",\"name\":\"T. Tan\"},{\"authorId\":\"71108546\",\"name\":\"Zhihan Xiong\"},{\"authorId\":\"3427981\",\"name\":\"V. Dwaracherla\"}],\"doi\":\"10.1609/AAAI.V34I04.6055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fbe71b8cb16d37e508465af7e9c716215d5d230\",\"title\":\"Parameterized Indexed Value Function for Efficient Exploration in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/3fbe71b8cb16d37e508465af7e9c716215d5d230\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393196\",\"name\":\"Xiaoyuan Yi\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"},{\"authorId\":\"145171951\",\"name\":\"Ruoyu Li\"},{\"authorId\":\"2259009\",\"name\":\"W. Li\"}],\"doi\":\"10.18653/v1/D18-1353\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"383d0ba13705ead9bcf300e566523c52697e83b7\",\"title\":\"Automatic Poetry Generation with Mutual Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/383d0ba13705ead9bcf300e566523c52697e83b7\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2006.07409\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"1388021064\",\"name\":\"Ethan Tien\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3b2ec1d8e56131d2644b1de89733262adc720716\",\"title\":\"How to Avoid Being Eaten by a Grue: Structured Exploration Strategies for Textual Worlds\",\"url\":\"https://www.semanticscholar.org/paper/3b2ec1d8e56131d2644b1de89733262adc720716\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.07274\",\"authors\":[{\"authorId\":\"46180539\",\"name\":\"Ghulam Ahmed Ansari\"},{\"authorId\":\"1414720849\",\"name\":\"P. SagarJ.\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1723632\",\"name\":\"Balaraman Ravindran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42d46d46eb75173fdb3c9891d10b3143cb43b380\",\"title\":\"Language Expansion In Text-Based Games\",\"url\":\"https://www.semanticscholar.org/paper/42d46d46eb75173fdb3c9891d10b3143cb43b380\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.00462\",\"authors\":[{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.18653/v1/P18-1243\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d59bd979793ede0bc87d181736f26b2f2998e57c\",\"title\":\"Interactive Language Acquisition with One-shot Visual Concept Learning through a Conversational Game\",\"url\":\"https://www.semanticscholar.org/paper/d59bd979793ede0bc87d181736f26b2f2998e57c\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23181435\",\"name\":\"Hou Pong Chan\"},{\"authorId\":\"145310663\",\"name\":\"Irwin King\"}],\"doi\":\"10.18653/v1/D18-1376\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"77266cd00979b59f00301e9f61b5f8750f2094b9\",\"title\":\"Thread Popularity Prediction and Tracking with a Permutation-invariant Model\",\"url\":\"https://www.semanticscholar.org/paper/77266cd00979b59f00301e9f61b5f8750f2094b9\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1911.00497\",\"authors\":[{\"authorId\":\"3436871\",\"name\":\"Nicholas R. Waytowich\"},{\"authorId\":\"24203151\",\"name\":\"Sean L. Barton\"},{\"authorId\":\"2194602\",\"name\":\"V. Lawhern\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b1fcf8436adec4ade1e0107be068f0029c65fe4\",\"title\":\"A Narration-based Reward Shaping Approach using Grounded Natural Language Commands\",\"url\":\"https://www.semanticscholar.org/paper/3b1fcf8436adec4ade1e0107be068f0029c65fe4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750745\",\"name\":\"Brian Broll\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"50438830\",\"name\":\"D. Bignell\"},{\"authorId\":\"40261572\",\"name\":\"A. Swaminathan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebb1c62c355e40de7be950f2863a613ea3ba7cee\",\"title\":\"Customizing Scripted Bots: Sample Efficient Imitation Learning for Human-like Behavior in Minecraft\",\"url\":\"https://www.semanticscholar.org/paper/ebb1c62c355e40de7be950f2863a613ea3ba7cee\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000878497\",\"name\":\"Yunqiu Xu\"},{\"authorId\":\"49330136\",\"name\":\"L. Chen\"},{\"authorId\":\"1791707\",\"name\":\"Meng Fang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"32076894\",\"name\":\"C. Zhang\"}],\"doi\":\"10.1109/CoG47356.2020.9231622\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f9189dcb3a79fa5fc264dc74e99243a0ac519a79\",\"title\":\"Deep Reinforcement Learning with Transformers for Text Adventure Games\",\"url\":\"https://www.semanticscholar.org/paper/f9189dcb3a79fa5fc264dc74e99243a0ac519a79\",\"venue\":\"2020 IEEE Conference on Games (CoG)\",\"year\":2020},{\"arxivId\":\"1909.06283\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"1388017611\",\"name\":\"William Broniec\"},{\"authorId\":\"152879670\",\"name\":\"A. M\\u00fcller\"},{\"authorId\":\"144616002\",\"name\":\"J. Paul\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c933596e06620a09c87604f274f9ecb176650aa2\",\"title\":\"Toward Automated Quest Generation in Text-Adventure Games\",\"url\":\"https://www.semanticscholar.org/paper/c933596e06620a09c87604f274f9ecb176650aa2\",\"venue\":\"ICCC\",\"year\":2020},{\"arxivId\":\"2011.02511\",\"authors\":[{\"authorId\":\"3422710\",\"name\":\"Julia Kreutzer\"},{\"authorId\":\"3289329\",\"name\":\"S. Riezler\"},{\"authorId\":\"19752252\",\"name\":\"Carolin (Haas) Lawrence\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a181f2b0214a3debaad098963339f1e4479790ee\",\"title\":\"Learning from Human Feedback: Challenges for Real-World Reinforcement Learning in NLP\",\"url\":\"https://www.semanticscholar.org/paper/a181f2b0214a3debaad098963339f1e4479790ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kirthevasan Kandasamy\"}],\"doi\":\"10.1184/R1/8337638.V1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9ab3a60992618377b2ba5ec959635fb02da8c99\",\"title\":\"Tuning Hyperparameters without Grad Students: Scaling up Bandit Optimisation\",\"url\":\"https://www.semanticscholar.org/paper/c9ab3a60992618377b2ba5ec959635fb02da8c99\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800944\",\"name\":\"M. Kotti\"},{\"authorId\":\"2204516\",\"name\":\"Vassilios Diakoloukas\"},{\"authorId\":\"1710287\",\"name\":\"Alexandros Papangelis\"},{\"authorId\":\"51261772\",\"name\":\"Michail Lagoudakis\"},{\"authorId\":\"3101750\",\"name\":\"Y. Stylianou\"}],\"doi\":\"10.21437/Interspeech.2018-1293\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f35d817325485ba02f35d13ad35441d7d39f895c\",\"title\":\"A Case Study on the Importance of Belief State Representation for Dialogue Policy Management\",\"url\":\"https://www.semanticscholar.org/paper/f35d817325485ba02f35d13ad35441d7d39f895c\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":\"2010.01523\",\"authors\":[{\"authorId\":\"2620321\",\"name\":\"Tonghan Wang\"},{\"authorId\":\"49857577\",\"name\":\"Tarun Gupta\"},{\"authorId\":\"2827015\",\"name\":\"Anuj Mahajan\"},{\"authorId\":\"2323268\",\"name\":\"B. Peng\"},{\"authorId\":\"1766767\",\"name\":\"S. Whiteson\"},{\"authorId\":\"1797369\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5764095b0186a3fc3832c1052aa14996a5927edc\",\"title\":\"RODE: Learning Roles to Decompose Multi-Agent Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5764095b0186a3fc3832c1052aa14996a5927edc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72639731\",\"name\":\"E. Korkmaz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"548ce343a555c790564a5b8e4d651e397c83c89d\",\"title\":\"Nesterov Momentum Adversarial Perturbations in the Deep Reinforcement Learning Domain\",\"url\":\"https://www.semanticscholar.org/paper/548ce343a555c790564a5b8e4d651e397c83c89d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2441459\",\"name\":\"Xiangrong Zeng\"},{\"authorId\":\"1954845\",\"name\":\"Shizhu He\"},{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"77397868\",\"name\":\"K. Liu\"},{\"authorId\":\"47130230\",\"name\":\"Shengping Liu\"},{\"authorId\":\"11447228\",\"name\":\"J. Zhao\"}],\"doi\":\"10.18653/v1/D19-1035\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"945058efb3bbcf071f3b7cce8d5e9dd0b6348098\",\"title\":\"Learning the Extraction Order of Multiple Relational Facts in a Sentence with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/945058efb3bbcf071f3b7cce8d5e9dd0b6348098\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1805.03257\",\"authors\":[{\"authorId\":\"50561583\",\"name\":\"J. Zhang\"},{\"authorId\":\"8200875\",\"name\":\"Tiancheng Zhao\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"}],\"doi\":\"10.18653/v1/W18-5015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"510d2879c03a2a0fa01ac6d6b95eb1067f2d1bf9\",\"title\":\"Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/510d2879c03a2a0fa01ac6d6b95eb1067f2d1bf9\",\"venue\":\"SIGDIAL Conference\",\"year\":2018},{\"arxivId\":\"2001.08868\",\"authors\":[{\"authorId\":\"3064807\",\"name\":\"Andrea Madotto\"},{\"authorId\":\"2171886\",\"name\":\"M. Namazifar\"},{\"authorId\":\"39378983\",\"name\":\"J. Huizinga\"},{\"authorId\":\"34890911\",\"name\":\"Piero Molino\"},{\"authorId\":\"66821245\",\"name\":\"Adrien Ecoffet\"},{\"authorId\":\"3172630\",\"name\":\"Huaixiu Zheng\"},{\"authorId\":\"1710287\",\"name\":\"Alexandros Papangelis\"},{\"authorId\":\"150978762\",\"name\":\"Dian Yu\"},{\"authorId\":\"144011343\",\"name\":\"C. Khatri\"},{\"authorId\":\"5108268\",\"name\":\"G. Tur\"}],\"doi\":\"10.24963/ijcai.2020/207\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fce7dfc76d9ddff672cca59d0340bdffcac53bcc\",\"title\":\"Exploration Based Language Learning for Text-Based Games\",\"url\":\"https://www.semanticscholar.org/paper/fce7dfc76d9ddff672cca59d0340bdffcac53bcc\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1512.07679\",\"authors\":[{\"authorId\":\"1387885286\",\"name\":\"Gabriel Dulac-Arnold\"},{\"authorId\":\"143811482\",\"name\":\"R. Evans\"},{\"authorId\":\"7634925\",\"name\":\"H. V. Hasselt\"},{\"authorId\":\"1814162\",\"name\":\"Peter Sunehag\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"50697911\",\"name\":\"J. Hunt\"},{\"authorId\":\"2554720\",\"name\":\"Timothy A. Mann\"},{\"authorId\":\"144588860\",\"name\":\"T. Weber\"},{\"authorId\":\"49491434\",\"name\":\"Thomas Degris\"},{\"authorId\":\"48303781\",\"name\":\"Ben Coppin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b2aff88ee03e82993c066c3e698d51da62d5496\",\"title\":\"Deep Reinforcement Learning in Large Discrete Action Spaces\",\"url\":\"https://www.semanticscholar.org/paper/3b2aff88ee03e82993c066c3e698d51da62d5496\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1708.07902\",\"authors\":[{\"authorId\":\"2775866\",\"name\":\"Niels Justesen\"},{\"authorId\":\"14171685\",\"name\":\"Philip Bontrager\"},{\"authorId\":\"1810053\",\"name\":\"J. Togelius\"},{\"authorId\":\"1745664\",\"name\":\"S. Risi\"}],\"doi\":\"10.1109/TG.2019.2896986\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1f2bc5d57ccbf5a04e7fea87f1f4db464f533ca8\",\"title\":\"Deep Learning for Video Game Playing\",\"url\":\"https://www.semanticscholar.org/paper/1f2bc5d57ccbf5a04e7fea87f1f4db464f533ca8\",\"venue\":\"IEEE Transactions on Games\",\"year\":2020},{\"arxivId\":\"2011.01928\",\"authors\":[{\"authorId\":null,\"name\":\"Ayush Jain\"},{\"authorId\":\"1580188581\",\"name\":\"Andrew Szot\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"679d00761a6fc895cf01b85bb695b79b1352ebec\",\"title\":\"Generalization to New Actions in Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/679d00761a6fc895cf01b85bb695b79b1352ebec\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49264189\",\"name\":\"Ji He\"},{\"authorId\":\"144339506\",\"name\":\"Mari Ostendorf\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.18653/v1/D16-1189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ebe658f62d02b871df66a0563b9f8f5c82272ca\",\"title\":\"Deep Reinforcement Learning with a Combinatorial Action Space for Predicting Popular Reddit Threads\",\"url\":\"https://www.semanticscholar.org/paper/5ebe658f62d02b871df66a0563b9f8f5c82272ca\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144322545\",\"name\":\"J. Pan\"},{\"authorId\":\"40509105\",\"name\":\"X. Wang\"},{\"authorId\":\"33718755\",\"name\":\"Yuhu Cheng\"},{\"authorId\":\"145576640\",\"name\":\"Q. Yu\"}],\"doi\":\"10.1109/TNNLS.2018.2806087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2deeb877ebe01b1c3ada2087d3644674f021d8ce\",\"title\":\"Multisource Transfer Double DQN Based on Actor Learning\",\"url\":\"https://www.semanticscholar.org/paper/2deeb877ebe01b1c3ada2087d3644674f021d8ce\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921747\",\"name\":\"Xusen Yin\"},{\"authorId\":\"143823227\",\"name\":\"Jonathan May\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7052dbb441afc67dff08495600cead9b48bcdf87\",\"title\":\"Learn How to Cook a New Recipe in a New House : Using Map Familiarization , Curriculum Learning , and Bandit Feedback to Learn Families of Text-Based Adventure Games\",\"url\":\"https://www.semanticscholar.org/paper/7052dbb441afc67dff08495600cead9b48bcdf87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.01770\",\"authors\":[{\"authorId\":\"2232505\",\"name\":\"Yash Chandak\"},{\"authorId\":\"1709005\",\"name\":\"Georgios Theocharous\"},{\"authorId\":\"71309987\",\"name\":\"C. Nota\"},{\"authorId\":\"143640165\",\"name\":\"P. S. Thomas\"}],\"doi\":\"10.1609/AAAI.V34I04.5739\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1a074c546e54155809492a80310d5799013c4d85\",\"title\":\"Lifelong Learning with a Changing Action Set\",\"url\":\"https://www.semanticscholar.org/paper/1a074c546e54155809492a80310d5799013c4d85\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1812.07617\",\"authors\":[{\"authorId\":\"144235909\",\"name\":\"Raymond Li\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"677aadb8171bd0633f465abe86ee3121abf407aa\",\"title\":\"Towards Deep Conversational Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/677aadb8171bd0633f465abe86ee3121abf407aa\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1812.01628\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.18653/v1/N19-1358\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3caa43a7016fbbf309d45112b31b20230eaf8da\",\"title\":\"Playing Text-Adventure Games with Graph-Based Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f3caa43a7016fbbf309d45112b31b20230eaf8da\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"47074522\",\"name\":\"C. Wang\"},{\"authorId\":\"145942106\",\"name\":\"Lin Xiao\"},{\"authorId\":\"49264189\",\"name\":\"Ji He\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c826dc81da0e729d47e78da97f57f5a7d8e3e9c\",\"title\":\"Q-LDA: Uncovering Latent Patterns in Text-based Sequential Decision Processes\",\"url\":\"https://www.semanticscholar.org/paper/6c826dc81da0e729d47e78da97f57f5a7d8e3e9c\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2001.08837\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7\",\"title\":\"Graph Constrained Reinforcement Learning for Natural Language Action Spaces\",\"url\":\"https://www.semanticscholar.org/paper/028c1a07ac62bbdb681d11cacf4c7485f9aa3ef7\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2009.07346\",\"authors\":[{\"authorId\":\"1709005\",\"name\":\"Georgios Theocharous\"},{\"authorId\":\"2232505\",\"name\":\"Yash Chandak\"},{\"authorId\":\"143640165\",\"name\":\"P. S. Thomas\"},{\"authorId\":\"2863060\",\"name\":\"F. D. Nijs\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27b23fb5dcdc0920c9557d9796661b8f1bfe9f63\",\"title\":\"Reinforcement Learning for Strategic Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/27b23fb5dcdc0920c9557d9796661b8f1bfe9f63\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1701.07274\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1e9e56d80146766bc2316efbc54d8b770a23df\",\"title\":\"Deep Reinforcement Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1862066\",\"name\":\"M. Dobre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e0d90978773345f1230d77a20082dcf95b31c16\",\"title\":\"Low-resource learning in complex games\",\"url\":\"https://www.semanticscholar.org/paper/8e0d90978773345f1230d77a20082dcf95b31c16\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.07343\",\"authors\":[{\"authorId\":\"4614137\",\"name\":\"Yiding Jiang\"},{\"authorId\":\"2046135\",\"name\":\"Shixiang Gu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2c8482c713b94073f3d59895b373db4398ddfbb\",\"title\":\"Language as an Abstraction for Hierarchical Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c2c8482c713b94073f3d59895b373db4398ddfbb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2010.00685\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"39219656\",\"name\":\"Jack Urbanek\"},{\"authorId\":\"6649233\",\"name\":\"Margaret Li\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"1389854357\",\"name\":\"Tim Rocktaschel\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c0770dd213b0d2e704f53fb5c69e1fee127bae1\",\"title\":\"How to Motivate Your Dragon: Teaching Goal-Driven Agents to Speak and Act in Fantasy Worlds\",\"url\":\"https://www.semanticscholar.org/paper/2c0770dd213b0d2e704f53fb5c69e1fee127bae1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.05398\",\"authors\":[{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"}],\"doi\":\"10.1609/AAAI.V34I05.6297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a51ae16cd63300c024d57e770c52216a639f8b7e\",\"title\":\"Interactive Fiction Games: A Colossal Adventure\",\"url\":\"https://www.semanticscholar.org/paper/a51ae16cd63300c024d57e770c52216a639f8b7e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39503804\",\"name\":\"Jiyun Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0275726db5badb308842d43582b4519d76946ae\",\"title\":\"Dynamic Search Models and Applications\",\"url\":\"https://www.semanticscholar.org/paper/e0275726db5badb308842d43582b4519d76946ae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152249495\",\"name\":\"Xiyao Ma\"},{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"1802983\",\"name\":\"X. Pan\"},{\"authorId\":\"47942892\",\"name\":\"Y. Zhou\"},{\"authorId\":null,\"name\":\"Xiaolin Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6039d61d0cb3c08b2629f3b2a6ee7cdb22e4c872\",\"title\":\"RetailNet : Enhancing Retails of Perishable Products with Multiple Selling Strategies via PairWise Multi-Q Learning\",\"url\":\"https://www.semanticscholar.org/paper/6039d61d0cb3c08b2629f3b2a6ee7cdb22e4c872\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.12901\",\"authors\":[{\"authorId\":\"1387885286\",\"name\":\"Gabriel Dulac-Arnold\"},{\"authorId\":\"3187297\",\"name\":\"Daniel J. Mankowitz\"},{\"authorId\":\"143772943\",\"name\":\"T. Hester\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"896e5529de1da1e4494033404721b70339bb9557\",\"title\":\"Challenges of Real-World Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/896e5529de1da1e4494033404721b70339bb9557\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"1803054\",\"name\":\"Shujie Liu\"},{\"authorId\":\"70362337\",\"name\":\"Heung-Yeung Shum\"}],\"doi\":\"10.1016/j.eng.2019.12.014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3410e91c55ec78e4ec94b6a56897945e136d7cd8\",\"title\":\"Progress in Neural NLP: Modeling, Learning, and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/3410e91c55ec78e4ec94b6a56897945e136d7cd8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.06556\",\"authors\":[{\"authorId\":\"19179135\",\"name\":\"Prithviraj Ammanabrolu\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.18653/v1/D19-5301\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77668573e9180b9fe9ae932a5ce9de53c81b045e\",\"title\":\"Transfer in Deep Reinforcement Learning using Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/77668573e9180b9fe9ae932a5ce9de53c81b045e\",\"venue\":\"TextGraphs@EMNLP\",\"year\":2019},{\"arxivId\":\"1802.04394\",\"authors\":[{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"49813753\",\"name\":\"Yuqing Guo\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a053f55804eee01f3c8b4138a1d3364d5bc45ac\",\"title\":\"M-Walk: Learning to Walk over Graphs using Monte Carlo Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/0a053f55804eee01f3c8b4138a1d3364d5bc45ac\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1812.00855\",\"authors\":[{\"authorId\":\"117899652\",\"name\":\"Ruo Yu Tao\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf69d946f05b1ecea27b15768701b4edec5da198\",\"title\":\"Towards Solving Text-based Games by Producing Adaptive Action Spaces\",\"url\":\"https://www.semanticscholar.org/paper/cf69d946f05b1ecea27b15768701b4edec5da198\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.06931\",\"authors\":[{\"authorId\":\"7303313\",\"name\":\"Yangchen Pan\"},{\"authorId\":\"5689899\",\"name\":\"Amir-massoud Farahmand\"},{\"authorId\":\"144542337\",\"name\":\"Martha White\"},{\"authorId\":\"1876327\",\"name\":\"S. Nabi\"},{\"authorId\":\"48288901\",\"name\":\"P. Grover\"},{\"authorId\":\"2965906\",\"name\":\"D. Nikovski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f3a3e262beb57c31c0dc6adbd4aaac2fc6dd49a\",\"title\":\"Reinforcement Learning with Function-Valued Action Spaces for Partial Differential Equation Control\",\"url\":\"https://www.semanticscholar.org/paper/0f3a3e262beb57c31c0dc6adbd4aaac2fc6dd49a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72999225\",\"name\":\"Q. Liu\"},{\"authorId\":\"50110110\",\"name\":\"B. Cui\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"1780690\",\"name\":\"Baolin Peng\"},{\"authorId\":\"120738173\",\"name\":\"Haikuan Huang\"},{\"authorId\":\"2642895\",\"name\":\"H. Deng\"},{\"authorId\":\"40513470\",\"name\":\"Jianye Hao\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"}],\"doi\":\"10.24963/ijcai.2019/710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c312ddab4171f859b0b1115cafd879976be3acc6\",\"title\":\"Building Personalized Simulator for Interactive Search\",\"url\":\"https://www.semanticscholar.org/paper/c312ddab4171f859b0b1115cafd879976be3acc6\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1809.08267\",\"authors\":[{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/3209978.3210183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83e567c2822aeda91006096a5d7ac0b34721d2a5\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/83e567c2822aeda91006096a5d7ac0b34721d2a5\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26938828\",\"name\":\"E. Chourdakis\"},{\"authorId\":\"1714451\",\"name\":\"J. Reiss\"}],\"doi\":\"10.18653/v1/W17-3905\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a7b2d4c58d43e64bd414cc74bc3d2fe179eab364\",\"title\":\"Constructing narrative using a generative model and continuous action policies\",\"url\":\"https://www.semanticscholar.org/paper/a7b2d4c58d43e64bd414cc74bc3d2fe179eab364\",\"venue\":\"CC-NLG@INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177398\",\"name\":\"Bo Yin\"},{\"authorId\":\"144680205\",\"name\":\"Shuai Zhang\"},{\"authorId\":\"153655455\",\"name\":\"Yu Cheng\"}],\"doi\":\"10.1109/JIOT.2020.2996562\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8af2f4856d85cd11b657574b56a2ac186ccdc06\",\"title\":\"Application-Oriented Scheduling for Optimizing the Age of Correlated Information: A Deep-Reinforcement-Learning-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/f8af2f4856d85cd11b657574b56a2ac186ccdc06\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2020},{\"arxivId\":\"2010.12001\",\"authors\":[{\"authorId\":\"84315698\",\"name\":\"Arthur Delarue\"},{\"authorId\":\"40171469\",\"name\":\"R. Anderson\"},{\"authorId\":\"144707259\",\"name\":\"Christian Tjandraatmadja\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7f0bac65336214c042920a378b7ecd511a10ce5\",\"title\":\"Reinforcement Learning with Combinatorial Actions: An Application to Vehicle Routing\",\"url\":\"https://www.semanticscholar.org/paper/c7f0bac65336214c042920a378b7ecd511a10ce5\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1911.12511\",\"authors\":[{\"authorId\":\"3070357\",\"name\":\"Vishal Jain\"},{\"authorId\":\"26958176\",\"name\":\"W. Fedus\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"144368601\",\"name\":\"Doina Precup\"},{\"authorId\":\"1792298\",\"name\":\"Marc G. Bellemare\"}],\"doi\":\"10.1609/AAAI.V34I04.5857\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cdbc4892b19cfc2143c548b3c3085789c9a1f0d\",\"title\":\"Algorithmic Improvements for Deep Reinforcement Learning applied to Interactive Fiction\",\"url\":\"https://www.semanticscholar.org/paper/5cdbc4892b19cfc2143c548b3c3085789c9a1f0d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31785410\",\"name\":\"Bao Chau Phan\"},{\"authorId\":\"148398249\",\"name\":\"Ying-Chih Lai\"},{\"authorId\":\"117652855\",\"name\":\"C. Lin\"}],\"doi\":\"10.3390/s20113039\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f30a31c0fc845a1ad02e2a91a1c5efe82fca1962\",\"title\":\"A Deep Reinforcement Learning-Based MPPT Control for PV Systems under Partial Shading Condition\",\"url\":\"https://www.semanticscholar.org/paper/f30a31c0fc845a1ad02e2a91a1c5efe82fca1962\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d002b3572460bbde84460d9aac2e9b6a669356\",\"title\":\"DICTION WITH RNNS\",\"url\":\"https://www.semanticscholar.org/paper/19d002b3572460bbde84460d9aac2e9b6a669356\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.02986\",\"authors\":[{\"authorId\":\"2921747\",\"name\":\"Xusen Yin\"},{\"authorId\":\"143823227\",\"name\":\"Jonathan May\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d6c2107d265bf461ea08e8180b740d2eb745812d\",\"title\":\"Zero-Shot Learning of Text Adventure Games with Sentence-Level Semantics\",\"url\":\"https://www.semanticscholar.org/paper/d6c2107d265bf461ea08e8180b740d2eb745812d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"41207043\",\"name\":\"L. Deng\"},{\"authorId\":\"1398192396\",\"name\":\"D. Hakkani-Tur\"}],\"doi\":\"10.1007/978-981-10-5209-5_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b7f6c07d9ab0a7f15e857649fd96bc7379c6aa5\",\"title\":\"Deep Learning in Spoken and Text-Based Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/9b7f6c07d9ab0a7f15e857649fd96bc7379c6aa5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48441202\",\"name\":\"J. Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1561/1500000074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"venue\":\"Found. Trends Inf. Retr.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029676598\",\"name\":\"Muddasar Naeem\"},{\"authorId\":\"38616786\",\"name\":\"Syed Tahir Hussain Rizvi\"},{\"authorId\":\"3072035\",\"name\":\"A. Coronato\"}],\"doi\":\"10.1109/ACCESS.2020.3038605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"886144bdf52254bca44d3bd38bc971a5220ce288\",\"title\":\"A Gentle Introduction to Reinforcement Learning and its Application in Different Fields\",\"url\":\"https://www.semanticscholar.org/paper/886144bdf52254bca44d3bd38bc971a5220ce288\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1702.08653\",\"authors\":[{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"47074522\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8889ba4901a6dc647fe4a5590742b1fea6784da\",\"title\":\"Scaffolding Networks for Teaching and Learning to Comprehend\",\"url\":\"https://www.semanticscholar.org/paper/e8889ba4901a6dc647fe4a5590742b1fea6784da\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49003435\",\"name\":\"Muhammad Nabeel\"},{\"authorId\":\"153654433\",\"name\":\"A. Riaz\"},{\"authorId\":\"9212793\",\"name\":\"Wang Zhen-yu\"}],\"doi\":\"10.14569/IJACSA.2019.0100766\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69346d476015177721b58c8852414fca8ca4a15a\",\"title\":\"Cas-GANs: An Approach of Dialogue Policy Learning based on GAN and RL Techniques\",\"url\":\"https://www.semanticscholar.org/paper/69346d476015177721b58c8852414fca8ca4a15a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.02386\",\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"50753116\",\"name\":\"M. Yu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143903370\",\"name\":\"Murray Campbell\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.624\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"061d113a7b3f32deab6bc50fea676fa0b1e0f658\",\"title\":\"Interactive Fiction Game Playing as Multi-Paragraph Reading Comprehension with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/061d113a7b3f32deab6bc50fea676fa0b1e0f658\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2001.05864\",\"authors\":[{\"authorId\":\"67105923\",\"name\":\"Yiyan Chen\"},{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3338533.3366583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7771454dceec1cc83d56d3ea996851e293013e36\",\"title\":\"Weakly Supervised Video Summarization by Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/7771454dceec1cc83d56d3ea996851e293013e36\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698306\",\"name\":\"H. Zhang\"},{\"authorId\":\"9196694\",\"name\":\"Yuntian Feng\"},{\"authorId\":\"1766273\",\"name\":\"Wenning Hao\"},{\"authorId\":\"48390827\",\"name\":\"G. Chen\"},{\"authorId\":\"48442717\",\"name\":\"Dawei Jin\"}],\"doi\":\"10.1587/TRANSINF.2016EDP7450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d5e2c7454f9c93087a373a5a6a577efc5a1a2cd\",\"title\":\"Relation Extraction with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6d5e2c7454f9c93087a373a5a6a577efc5a1a2cd\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2017},{\"arxivId\":\"1905.09700\",\"authors\":[{\"authorId\":\"3393407\",\"name\":\"Chen Tessler\"},{\"authorId\":\"3331540\",\"name\":\"T. Zahavy\"},{\"authorId\":\"6097664\",\"name\":\"D. Cohen\"},{\"authorId\":\"3187297\",\"name\":\"Daniel J. Mankowitz\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cedef40a5ddb55fe061523770659a881fce208c5\",\"title\":\"Action Assembly: Sparse Imitation Learning for Text Based Games with Combinatorial Action Spaces\",\"url\":\"https://www.semanticscholar.org/paper/cedef40a5ddb55fe061523770659a881fce208c5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.01119\",\"authors\":[{\"authorId\":\"29978064\",\"name\":\"Guy Tennenholtz\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"766d48ad414065e5e2fa4fef13c8951f28b58bf4\",\"title\":\"The Natural Language of Actions\",\"url\":\"https://www.semanticscholar.org/paper/766d48ad414065e5e2fa4fef13c8951f28b58bf4\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2008.12095\",\"authors\":[{\"authorId\":\"1660812666\",\"name\":\"Katya Kudashkina\"},{\"authorId\":\"1780797\",\"name\":\"P. Pilarski\"},{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"860b1ee24c1b372d89d601d4d1aee28b5735948e\",\"title\":\"Document-editing Assistants and Model-based Reinforcement Learning as a Path to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/860b1ee24c1b372d89d601d4d1aee28b5735948e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09774\",\"authors\":[{\"authorId\":\"1823518201\",\"name\":\"Brielen Madureira\"},{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a4069dd677b205fba61b4dea75e26c148dee99c5\",\"title\":\"An Overview of Natural Language State Representation for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4069dd677b205fba61b4dea75e26c148dee99c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718794\",\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Yang Liu\"}],\"doi\":\"10.1007/978-981-10-5209-5_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59a3e156711d0d82799248e751c26396c7d24d8f\",\"title\":\"Epilogue: Frontiers of NLP in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/59a3e156711d0d82799248e751c26396c7d24d8f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.11532\",\"authors\":[{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"145256547\",\"name\":\"Ben Kybartas\"},{\"authorId\":\"48316034\",\"name\":\"Tavian Barnes\"},{\"authorId\":\"31464095\",\"name\":\"Emery Fine\"},{\"authorId\":\"145503062\",\"name\":\"J. Moore\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"},{\"authorId\":\"51172009\",\"name\":\"Mahmoud Adada\"},{\"authorId\":\"51166384\",\"name\":\"Wendy Tay\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"}],\"doi\":\"10.1007/978-3-030-24337-1_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89daae27e7df4a418b9610d307ce3df0e30fc8a2\",\"title\":\"TextWorld: A Learning Environment for Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/89daae27e7df4a418b9610d307ce3df0e30fc8a2\",\"venue\":\"CGW@IJCAI\",\"year\":2018},{\"arxivId\":\"1906.02671\",\"authors\":[{\"authorId\":\"3436871\",\"name\":\"Nicholas R. Waytowich\"},{\"authorId\":\"24203151\",\"name\":\"Sean L. Barton\"},{\"authorId\":\"2194602\",\"name\":\"V. Lawhern\"},{\"authorId\":\"3293051\",\"name\":\"E. Stump\"},{\"authorId\":\"1938253\",\"name\":\"Garrett Warnell\"}],\"doi\":\"10.1117/12.2519138\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08b88a9a107033297792cd4935e429a3a116bbc0\",\"title\":\"Grounding natural language commands to StarCraft II game states for narration-guided reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/08b88a9a107033297792cd4935e429a3a116bbc0\",\"venue\":\"Defense + Commercial Sensing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118519138\",\"name\":\"Jorge Armando Mendez Mendez\"},{\"authorId\":\"143830417\",\"name\":\"Bing Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e00c99411a7099cadc0fd11eba5c37df66597a9d\",\"title\":\"Reinforcement Learning of Multi-Domain Dialog Policies Via Action Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/e00c99411a7099cadc0fd11eba5c37df66597a9d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3325824\",\"name\":\"Z. Yao\"},{\"authorId\":null,\"name\":\"Ying Wang\"},{\"authorId\":\"40553142\",\"name\":\"Xue-Song Qiu\"}],\"doi\":\"10.1177/1550147720935775\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fad955046e06ee0fb36f73899a217be3192592d5\",\"title\":\"DQN-based energy-efficient routing algorithm in software-defined data centers\",\"url\":\"https://www.semanticscholar.org/paper/fad955046e06ee0fb36f73899a217be3192592d5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1606.01541\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"145768639\",\"name\":\"Will Monroe\"},{\"authorId\":\"1863425\",\"name\":\"Alan Ritter\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/D16-1127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1298dae5751fb06184f6b067d1503bde8037bdb7\",\"title\":\"Deep Reinforcement Learning for Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/1298dae5751fb06184f6b067d1503bde8037bdb7\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1911.05922\",\"authors\":[{\"authorId\":\"29825392\",\"name\":\"Nicholas Kullman\"},{\"authorId\":\"145863232\",\"name\":\"J. Mendoza\"},{\"authorId\":\"1842067\",\"name\":\"Martin Cousineau\"},{\"authorId\":\"39637661\",\"name\":\"Justin C. Goodson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e66a3acb32200cbfcafe748325b79cef1df080c\",\"title\":\"Atari-fying the Vehicle Routing Problem with Stochastic Service Requests\",\"url\":\"https://www.semanticscholar.org/paper/6e66a3acb32200cbfcafe748325b79cef1df080c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.18653/v1/P18-5007\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b525bac2438c296e3b627a61908cd37e66ac7115\",\"title\":\"Deep Reinforcement Learning for NLP\",\"url\":\"https://www.semanticscholar.org/paper/b525bac2438c296e3b627a61908cd37e66ac7115\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1905.02265\",\"authors\":[{\"authorId\":\"2921747\",\"name\":\"Xusen Yin\"},{\"authorId\":\"143823227\",\"name\":\"Jonathan May\"}],\"doi\":\"10.1109/CIG.2019.8847954\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"150a301567c679ef4a7113639032b626d9a7a4ae\",\"title\":\"Comprehensible Context-driven Text Game Playing\",\"url\":\"https://www.semanticscholar.org/paper/150a301567c679ef4a7113639032b626d9a7a4ae\",\"venue\":\"2019 IEEE Conference on Games (CoG)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396844153\",\"name\":\"Vivan Raaj Rajalingam\"},{\"authorId\":\"2032434\",\"name\":\"Spyridon Samothrakis\"}],\"doi\":\"10.1109/CIG.2019.8847952\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2622cb04f7567bd45dec5e9daad8b6bdb22d993f\",\"title\":\"Neuroevolution Strategies for Word Embedding Adaptation in Text Adventure Games\",\"url\":\"https://www.semanticscholar.org/paper/2622cb04f7567bd45dec5e9daad8b6bdb22d993f\",\"venue\":\"2019 IEEE Conference on Games (CoG)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339506\",\"name\":\"Mari Ostendorf\"}],\"doi\":\"10.1007/978-3-319-45925-7_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f671de27822abc46287a60e93a85c4536dc8fde\",\"title\":\"Continuous-Space Language Processing: Beyond Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/8f671de27822abc46287a60e93a85c4536dc8fde\",\"venue\":\"SLSP\",\"year\":2016},{\"arxivId\":\"1602.02261\",\"authors\":[{\"authorId\":\"143744603\",\"name\":\"Rodrigo Nogueira\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b41a7f3e4a70eb5bc4113cbc6237b6120b7efc4\",\"title\":\"End-to-End Goal-Driven Web Navigation\",\"url\":\"https://www.semanticscholar.org/paper/9b41a7f3e4a70eb5bc4113cbc6237b6120b7efc4\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"2009.11896\",\"authors\":[{\"authorId\":\"34597365\",\"name\":\"Subhajit Chaudhury\"},{\"authorId\":\"40433860\",\"name\":\"Daiki Kimura\"},{\"authorId\":\"2940762\",\"name\":\"Kartik Talamadupula\"},{\"authorId\":\"3305985\",\"name\":\"Michiaki Tatsubori\"},{\"authorId\":\"1699672689\",\"name\":\"Asim Munawar\"},{\"authorId\":\"34769239\",\"name\":\"Ryuki Tachibana\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"382fc61652aeca5732f3c814dddbfcc69fb643ae\",\"title\":\"Bootstrapped Q-learning with Context Relevant Observation Pruning to Generalize in Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/382fc61652aeca5732f3c814dddbfcc69fb643ae\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1806.11525\",\"authors\":[{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"144100820\",\"name\":\"R. Laroche\"},{\"authorId\":\"15032777\",\"name\":\"Remi Tachet des Combes\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c52dddfbb4a3af4cc5e72849fe965c62801539e7\",\"title\":\"Counting to Explore and Generalize in Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/c52dddfbb4a3af4cc5e72849fe965c62801539e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.04259\",\"authors\":[{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2815483\",\"name\":\"R. Loynd\"},{\"authorId\":\"35064203\",\"name\":\"Greg Yang\"},{\"authorId\":\"40261572\",\"name\":\"A. Swaminathan\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c99367ba160609209360d044b7ecae565c4a1f6\",\"title\":\"NAIL: A General Interactive Fiction Agent\",\"url\":\"https://www.semanticscholar.org/paper/2c99367ba160609209360d044b7ecae565c4a1f6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31810380\",\"name\":\"A. R. Sharma\"},{\"authorId\":\"40001345\",\"name\":\"P. Kaushik\"}],\"doi\":\"10.1109/CCAA.2017.8229841\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cf17bd519d8b3017ee7e3eba4e2f69de8e3c8c\",\"title\":\"Literature survey of statistical, deep and reinforcement learning in natural language processing\",\"url\":\"https://www.semanticscholar.org/paper/18cf17bd519d8b3017ee7e3eba4e2f69de8e3c8c\",\"venue\":\"2017 International Conference on Computing, Communication and Automation (ICCCA)\",\"year\":2017},{\"arxivId\":\"2004.13657\",\"authors\":[{\"authorId\":\"1660812666\",\"name\":\"Katya Kudashkina\"},{\"authorId\":\"46660962\",\"name\":\"Valliappa Chockalingam\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"143913104\",\"name\":\"Michael H. Bowling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35763a64b605f37b6de74c776c57dc964416eb18\",\"title\":\"Sample-Efficient Model-based Actor-Critic for an Interactive Dialogue Task\",\"url\":\"https://www.semanticscholar.org/paper/35763a64b605f37b6de74c776c57dc964416eb18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.06217\",\"authors\":[{\"authorId\":\"49264189\",\"name\":\"Ji He\"},{\"authorId\":\"144339506\",\"name\":\"Mari Ostendorf\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"70ad57be5a1e572ecc0c79bfb2110eac0239b479\",\"title\":\"Reinforcement Learning with External Knowledge and Two-Stage Q-functions for Predicting Popular Reddit Threads\",\"url\":\"https://www.semanticscholar.org/paper/70ad57be5a1e572ecc0c79bfb2110eac0239b479\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"49813753\",\"name\":\"Yuqing Guo\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd197026cfd80f0c429480d6a601b1bf67a1f655\",\"title\":\"M-Walk: Learning to Walk in Graph with Monte Carlo Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/bd197026cfd80f0c429480d6a601b1bf67a1f655\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145131956\",\"name\":\"Lei Wang\"},{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"153787010\",\"name\":\"L. Guo\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"835c6b524b90b1639aba28742f7161137ddf4397\",\"title\":\"MathDQN: Solving Arithmetic Word Problems via Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/835c6b524b90b1639aba28742f7161137ddf4397\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1704.08795\",\"authors\":[{\"authorId\":\"31498163\",\"name\":\"Dipendra Kumar Misra\"},{\"authorId\":\"144162125\",\"name\":\"J. Langford\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/D17-1106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc9f3c466c6f6b386f4ef1195853d498cf3c182e\",\"title\":\"Mapping Instructions and Visual Observations to Actions with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/bc9f3c466c6f6b386f4ef1195853d498cf3c182e\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"2010.11655\",\"authors\":[{\"authorId\":\"5015123\",\"name\":\"Y. Xu\"},{\"authorId\":\"39829184\",\"name\":\"Meng Fang\"},{\"authorId\":\"1409961430\",\"name\":\"Ling Chen\"},{\"authorId\":\"1390662136\",\"name\":\"Yali Du\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"48934799\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e4d964088a73465dfaba81ecfc79637f421ed62f\",\"title\":\"Deep Reinforcement Learning with Stacked Hierarchical Attention for Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/e4d964088a73465dfaba81ecfc79637f421ed62f\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2003.11881\",\"authors\":[{\"authorId\":\"1387885286\",\"name\":\"Gabriel Dulac-Arnold\"},{\"authorId\":\"153898744\",\"name\":\"N. Levine\"},{\"authorId\":\"3187297\",\"name\":\"Daniel J. Mankowitz\"},{\"authorId\":\"49297759\",\"name\":\"J. Li\"},{\"authorId\":\"3316271\",\"name\":\"Cosmin Paduraru\"},{\"authorId\":\"2071666\",\"name\":\"Sven Gowal\"},{\"authorId\":\"143772943\",\"name\":\"T. Hester\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a8d0299b155d195d633b16b8821788e3b1de964\",\"title\":\"An empirical investigation of the challenges of real-world reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4a8d0299b155d195d633b16b8821788e3b1de964\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1890151\",\"name\":\"M. Kestemont\"},{\"authorId\":\"8231390\",\"name\":\"T. D. Smedt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e7758b174a1202a2b237ef458b14d77f9b9bc0b\",\"title\":\"The INLG 2017 Workshop on Computational Creativity in Natural Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/4e7758b174a1202a2b237ef458b14d77f9b9bc0b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"49813753\",\"name\":\"Yuqing Guo\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e498917a45783c744b4538807b644ac83ad08c4\",\"title\":\"ReinforceWalk: Learning to Walk in Graph with Monte Carlo Tree Search\",\"url\":\"https://www.semanticscholar.org/paper/4e498917a45783c744b4538807b644ac83ad08c4\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1906.09310\",\"authors\":[{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afdfd1b294f67e56281d00f39e63a47e887c7d8\",\"title\":\"A Study of State Aliasing in Structured Prediction with RNNs\",\"url\":\"https://www.semanticscholar.org/paper/3afdfd1b294f67e56281d00f39e63a47e887c7d8\",\"venue\":\"DeepRLStructPred@ICLR\",\"year\":2019},{\"arxivId\":\"1711.08493\",\"authors\":[{\"authorId\":\"143830417\",\"name\":\"Bing Liu\"},{\"authorId\":\"145381969\",\"name\":\"T. Yu\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"},{\"authorId\":\"144486305\",\"name\":\"O. Mengshoel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1462401921f2a155509c85389c3a4f34680efdc\",\"title\":\"Customized Nonlinear Bandits for Online Response Selection in Neural Conversation Models\",\"url\":\"https://www.semanticscholar.org/paper/b1462401921f2a155509c85389c3a4f34680efdc\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1603.07954\",\"authors\":[{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"3383328\",\"name\":\"Adam Yala\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/D16-1261\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac50801574f7c97f1cf8f6718a9ff2b3e18c2dc6\",\"title\":\"Improving Information Extraction by Acquiring External Evidence with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ac50801574f7c97f1cf8f6718a9ff2b3e18c2dc6\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47474362\",\"name\":\"Mengyang Zhang\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"40491375\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2019.2894438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc98efd9032145bcaddd979a5bc715bbc0e43e0a\",\"title\":\"A Home Service-Oriented Question Answering System With High Accuracy and Stability\",\"url\":\"https://www.semanticscholar.org/paper/fc98efd9032145bcaddd979a5bc715bbc0e43e0a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1810.04118\",\"authors\":[{\"authorId\":\"153859824\",\"name\":\"M. Mohammadi\"},{\"authorId\":\"1404786833\",\"name\":\"Ala Al-Fuqaha\"},{\"authorId\":\"145837051\",\"name\":\"M. Guizani\"},{\"authorId\":\"2309623\",\"name\":\"J. Oh\"}],\"doi\":\"10.1109/JIOT.2017.2712560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b72f4d16532f4e8f5ddd7640262019eea641fd6\",\"title\":\"Semisupervised Deep Reinforcement Learning in Support of IoT and Smart City Services\",\"url\":\"https://www.semanticscholar.org/paper/6b72f4d16532f4e8f5ddd7640262019eea641fd6\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2018},{\"arxivId\":\"1810.06339\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":\"10.1201/9781351006620-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"title\":\"Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.04777\",\"authors\":[{\"authorId\":\"2921747\",\"name\":\"Xusen Yin\"},{\"authorId\":\"143823227\",\"name\":\"Jonathan May\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cdce985b512e3e187a69b8ba8894695d9ecffb03\",\"title\":\"Learn How to Cook a New Recipe in a New House: Using Map Familiarization, Curriculum Learning, and Common Sense to Learn Families of Text-Based Adventure Games\",\"url\":\"https://www.semanticscholar.org/paper/cdce985b512e3e187a69b8ba8894695d9ecffb03\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.02903\",\"authors\":[{\"authorId\":\"1423713062\",\"name\":\"Shunyu Yao\"},{\"authorId\":\"50149352\",\"name\":\"Rohan Rao\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.704\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8aed57b61457655e8354f1b68b34ed1cc0a222ef\",\"title\":\"Keep CALM and Explore: Language Models for Action Generation in Text-based Games\",\"url\":\"https://www.semanticscholar.org/paper/8aed57b61457655e8354f1b68b34ed1cc0a222ef\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.13839\",\"authors\":[{\"authorId\":\"2003745905\",\"name\":\"Thomas Carta\"},{\"authorId\":\"34597365\",\"name\":\"Subhajit Chaudhury\"},{\"authorId\":\"2940762\",\"name\":\"Kartik Talamadupula\"},{\"authorId\":\"3305985\",\"name\":\"Michiaki Tatsubori\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e19dd428d90697a61348090d13be9c9098115dd9\",\"title\":\"VisualHints: A Visual-Lingual Environment for Multimodal Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e19dd428d90697a61348090d13be9c9098115dd9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"48091883137b6f7b756a3e57c677f667d1e207fa\",\"title\":\"Grounding natural language with autonomous interaction\",\"url\":\"https://www.semanticscholar.org/paper/48091883137b6f7b756a3e57c677f667d1e207fa\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1887808\",\"name\":\"Kirthevasan Kandasamy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30d7bcecc11cc977604b57a45bafac2a34a62cb4\",\"title\":\"IMPROVING SEQ2SEQ CONVERSATION MODELS\",\"url\":\"https://www.semanticscholar.org/paper/30d7bcecc11cc977604b57a45bafac2a34a62cb4\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1910.04023\",\"authors\":[{\"authorId\":\"1409249154\",\"name\":\"Ignacio Arroyo-Fern\\u00e1ndez\"},{\"authorId\":\"1410429794\",\"name\":\"Mauricio Carrasco-Ruiz\"},{\"authorId\":\"1414000874\",\"name\":\"Jos\\u00e9 Anibal Arias-Aguilar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd5f1e9c68b732909d51cc27ac78bf0f85db4b44\",\"title\":\"On the Possibility of Rewarding Structure Learning Agents: Mutual Information on Linguistic Random Sets\",\"url\":\"https://www.semanticscholar.org/paper/bd5f1e9c68b732909d51cc27ac78bf0f85db4b44\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.02632\",\"authors\":[{\"authorId\":\"46674570\",\"name\":\"Wenfeng Feng\"},{\"authorId\":\"2029651\",\"name\":\"Hankui Zhuo\"},{\"authorId\":\"1740315\",\"name\":\"S. Kambhampati\"}],\"doi\":\"10.24963/ijcai.2018/565\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b74c2676ac43528c133a30602a1cf759c921fc1\",\"title\":\"Extracting Action Sequences from Texts Based on Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6b74c2676ac43528c133a30602a1cf759c921fc1\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"330c5eaca3bcc4a431cbd57c610f2096055782a1\",\"title\":\"Neural Approaches to Conversational AI Question Answering , Task-Oriented Dialogue and Chatbots : A Unified View\",\"url\":\"https://www.semanticscholar.org/paper/330c5eaca3bcc4a431cbd57c610f2096055782a1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"},{\"authorId\":\"35132120\",\"name\":\"T. Jaakkola\"}],\"doi\":\"10.1613/jair.1.11263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbc8a0a428319324b6a1c9158e75b49f27b5ecd5\",\"title\":\"Grounding Language for Transfer in Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/fbc8a0a428319324b6a1c9158e75b49f27b5ecd5\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2018},{\"arxivId\":\"2010.03790\",\"authors\":[{\"authorId\":\"3377711\",\"name\":\"K. Murugesan\"},{\"authorId\":\"32946276\",\"name\":\"Mattia Atzeni\"},{\"authorId\":\"2223082\",\"name\":\"Pavan Kapanipathi\"},{\"authorId\":\"1748835883\",\"name\":\"Pushkar Shukla\"},{\"authorId\":\"47011667\",\"name\":\"S. Kumaravel\"},{\"authorId\":\"1699108\",\"name\":\"G. Tesauro\"},{\"authorId\":\"2940762\",\"name\":\"Kartik Talamadupula\"},{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"153665855\",\"name\":\"M. Campbell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c117a59fdad8ebf857d01082612093e9e6aa676e\",\"title\":\"Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines\",\"url\":\"https://www.semanticscholar.org/paper/c117a59fdad8ebf857d01082612093e9e6aa676e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1702.03334\",\"authors\":[{\"authorId\":\"1887808\",\"name\":\"Kirthevasan Kandasamy\"},{\"authorId\":\"1698412\",\"name\":\"Yoram Bachrach\"},{\"authorId\":\"2870603\",\"name\":\"Ryota Tomioka\"},{\"authorId\":\"1725299\",\"name\":\"Daniel Tarlow\"},{\"authorId\":\"144305563\",\"name\":\"D. Carter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11732140ada8e05c84e9024927c297565ebd6ad8\",\"title\":\"Batch Policy Gradient Methods for Improving Neural Conversation Models\",\"url\":\"https://www.semanticscholar.org/paper/11732140ada8e05c84e9024927c297565ebd6ad8\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780690\",\"name\":\"Baolin Peng\"},{\"authorId\":\"40286474\",\"name\":\"Xiujun Li\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1744734\",\"name\":\"Sungjin Lee\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c730f3d19bb444145620531917389ce9e138832b\",\"title\":\"Composite Task-Completion Dialogue System via Hierarchical Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c730f3d19bb444145620531917389ce9e138832b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1910.02078\",\"authors\":[{\"authorId\":\"34675041\",\"name\":\"Mathieu Seurin\"},{\"authorId\":\"47432313\",\"name\":\"Philippe Preux\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcbeff0dd9d26b92ec81285e5c9c7c9bb61899c4\",\"title\":\"\\\"I\\u2019m Sorry Dave, I\\u2019m Afraid I Can\\u2019t Do That\\\" Deep Q-Learning from Forbidden Actions\",\"url\":\"https://www.semanticscholar.org/paper/dcbeff0dd9d26b92ec81285e5c9c7c9bb61899c4\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2006.04761\",\"authors\":[{\"authorId\":\"49890207\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145582471\",\"name\":\"Q. Cai\"},{\"authorId\":\"3069462\",\"name\":\"Zhuoran Yang\"},{\"authorId\":\"2369515\",\"name\":\"Yongxin Chen\"},{\"authorId\":\"3113442\",\"name\":\"Zhaoran Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"324d3612bed89062bc46dceed560e3fa7d1ac919\",\"title\":\"Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory\",\"url\":\"https://www.semanticscholar.org/paper/324d3612bed89062bc46dceed560e3fa7d1ac919\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2643208\",\"name\":\"Samik Banerjee\"},{\"authorId\":\"1580250968\",\"name\":\"Lucas Magee\"},{\"authorId\":\"49370639\",\"name\":\"D. Wang\"},{\"authorId\":\"39952501\",\"name\":\"X. Li\"},{\"authorId\":\"2664721\",\"name\":\"Bingxing Huo\"},{\"authorId\":\"25655386\",\"name\":\"J. Jayakumar\"},{\"authorId\":\"89697254\",\"name\":\"K. Matho\"},{\"authorId\":\"1601268437\",\"name\":\"Adam Lin\"},{\"authorId\":\"144686138\",\"name\":\"K. Ram\"},{\"authorId\":\"2370826\",\"name\":\"M. Sivaprakasam\"},{\"authorId\":\"4249527\",\"name\":\"Josh Huang\"},{\"authorId\":null,\"name\":\"Yusu Wang\"},{\"authorId\":\"48850725\",\"name\":\"P. Mitra\"}],\"doi\":\"10.1101/2020.02.18.955237\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3924fc2eb1e31430ae58d7d55c781c29da7730\",\"title\":\"Semantic segmentation of microscopic neuroanatomical data by combining topological priors with encoder-decoder deep networks\",\"url\":\"https://www.semanticscholar.org/paper/ea3924fc2eb1e31430ae58d7d55c781c29da7730\",\"venue\":\"\",\"year\":2020}],\"corpusId\":15986631,\"doi\":\"10.18653/v1/P16-1153\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":16,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6118910c4014cc6c061198a2d88c080ab56ea452\",\"references\":[{\"arxivId\":\"1602.02261\",\"authors\":[{\"authorId\":\"143744603\",\"name\":\"Rodrigo Nogueira\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b41a7f3e4a70eb5bc4113cbc6237b6120b7efc4\",\"title\":\"End-to-End Goal-Driven Web Navigation\",\"url\":\"https://www.semanticscholar.org/paper/9b41a7f3e4a70eb5bc4113cbc6237b6120b7efc4\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145259603\",\"name\":\"S. Young\"},{\"authorId\":\"1768624\",\"name\":\"Milica Gasic\"},{\"authorId\":\"145462220\",\"name\":\"B. Thomson\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"}],\"doi\":\"10.1109/JPROC.2012.2225812\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84b520a8d6de79f62bb095b565d077e95bfb6f5b\",\"title\":\"POMDP-Based Statistical Spoken Dialog Systems: A Review\",\"url\":\"https://www.semanticscholar.org/paper/84b520a8d6de79f62bb095b565d077e95bfb6f5b\",\"venue\":\"Proceedings of the IEEE\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Nogueira\"},{\"authorId\":null,\"name\":\"K Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Webnav: A new largescale task for natural language based sequential decision making\",\"url\":\"\",\"venue\":\"Webnav: A new largescale task for natural language based sequential decision making\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R S Sutton\"},{\"authorId\":null,\"name\":\"A Barto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Reinforcement learning: An introduction, volume 1\",\"url\":\"\",\"venue\":\"Reinforcement learning: An introduction, volume 1\",\"year\":1998},{\"arxivId\":\"1509.02971\",\"authors\":[{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"024006d4c2a89f7acacc6e4438d156525b60a98f\",\"title\":\"Continuous control with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"},{\"authorId\":\"5246203\",\"name\":\"S. Balakrishnan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a950d7836e101e7d649791714d8383a804a6f671\",\"title\":\"Reinforcement learning for dialog management using least-squares Policy iteration and fast feature selection\",\"url\":\"https://www.semanticscholar.org/paper/a950d7836e101e7d649791714d8383a804a6f671\",\"venue\":\"INTERSPEECH\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737296\",\"name\":\"K. Scheffler\"},{\"authorId\":\"145259603\",\"name\":\"S. Young\"}],\"doi\":\"10.3115/1289189.1289246\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c471188c103ddb08c2423b5c3d9c0de27d2e9dd8\",\"title\":\"Automatic learning of dialogue strategy using dialogue simulation and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/c471188c103ddb08c2423b5c3d9c0de27d2e9dd8\",\"venue\":\"\",\"year\":2002},{\"arxivId\":\"1405.4053\",\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f527bcfb09f32e6a4a8afc0b37504941c1ba2cee\",\"title\":\"Distributed Representations of Sentences and Documents\",\"url\":\"https://www.semanticscholar.org/paper/f527bcfb09f32e6a4a8afc0b37504941c1ba2cee\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hinton et al.2012 G. Hinton\"},{\"authorId\":null,\"name\":\"L. Deng\"},{\"authorId\":null,\"name\":\"D. Yu\"},{\"authorId\":null,\"name\":\"G. E. Dahl\"},{\"authorId\":null,\"name\":\"A. Mohamed\"},{\"authorId\":null,\"name\":\"N. Jaitly\"},{\"authorId\":null,\"name\":\"A. Senior\"},{\"authorId\":null,\"name\":\"V. Vanhoucke\"},{\"authorId\":null,\"name\":\"P. Nguyen\"},{\"authorId\":null,\"name\":\"T. N. Sainath\"},{\"authorId\":null,\"name\":\"B. Kingsbury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deep neural networks for acoustic modeling in speech recognition: The shared views\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1390156.1390177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57458bc1cffe5caa45a885af986d70f723f406b4\",\"title\":\"A unified architecture for natural language processing: deep neural networks with multitask learning\",\"url\":\"https://www.semanticscholar.org/paper/57458bc1cffe5caa45a885af986d70f723f406b4\",\"venue\":\"ICML '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"41207043\",\"name\":\"L. Deng\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"35188630\",\"name\":\"G. Dahl\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"40133958\",\"name\":\"Patrick Nguyen\"},{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"}],\"doi\":\"10.1109/MSP.2012.2205597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31868290adf1c000c611dfc966b514d5a34e8d23\",\"title\":\"Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups\",\"url\":\"https://www.semanticscholar.org/paper/31868290adf1c000c611dfc966b514d5a34e8d23\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35188630\",\"name\":\"G. Dahl\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"1723644\",\"name\":\"A. Acero\"}],\"doi\":\"10.1109/TASL.2011.2134090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6658bbf68995731b2083195054ff45b4eca38b3a\",\"title\":\"Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6658bbf68995731b2083195054ff45b4eca38b3a\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Luong et al.2015 M-T. Luong\"},{\"authorId\":null,\"name\":\"H. Pham\"},{\"authorId\":null,\"name\":\"C. D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Effective approaches to attentionbased neural machine translation\",\"url\":\"\",\"venue\":\"In Proc. of the 2015 Conference on Empirical Methods in Natural Language Processing,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sutton\"},{\"authorId\":null,\"name\":\"Barto1998 R. S Sutton\"},{\"authorId\":null,\"name\":\"A. G Barto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Reinforcement learning: An introduction, volume 1. MIT press Cambridge\",\"url\":\"\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143744603\",\"name\":\"Rodrigo Nogueira\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05965fa16f60ec378964e5721bbcc7d2848916b1\",\"title\":\"WebNav: A New Large-Scale Task for Natural Language based Sequential Decision Making\",\"url\":\"https://www.semanticscholar.org/paper/05965fa16f60ec378964e5721bbcc7d2848916b1\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143794407\",\"name\":\"X. Hao\"},{\"authorId\":\"8273966\",\"name\":\"Guigang Zhang\"},{\"authorId\":\"144153753\",\"name\":\"Shang Ma\"}],\"doi\":\"10.1142/S1793351X16500045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f8d648c52edf74e41b0996128aa536e13cc7e82\",\"title\":\"Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4f8d648c52edf74e41b0996128aa536e13cc7e82\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2016},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"1723644\",\"name\":\"A. Acero\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"}],\"doi\":\"10.1145/2505515.2505665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdb813d8b927bdd21ae1858cafa6c34b66a36268\",\"title\":\"Learning deep structured semantic models for web search using clickthrough data\",\"url\":\"https://www.semanticscholar.org/paper/fdb813d8b927bdd21ae1858cafa6c34b66a36268\",\"venue\":\"CIKM\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Kiros\"},{\"authorId\":null,\"name\":\"Y Zhu\"},{\"authorId\":null,\"name\":\"R Salakhutdinov\"},{\"authorId\":null,\"name\":\"R Zemel\"},{\"authorId\":null,\"name\":\"R Urtasun\"},{\"authorId\":null,\"name\":\"A Torralba\"},{\"authorId\":null,\"name\":\"S Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Skipthought vectors\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"36037226\",\"name\":\"R. Ducharme\"},{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"1909943744\",\"name\":\"Christian Janvin\"}],\"doi\":\"10.1162/153244303322533223\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6c2b28f9354f667cd5bd07afc0471d8334430da7\",\"title\":\"A Neural Probabilistic Language Model\",\"url\":\"https://www.semanticscholar.org/paper/6c2b28f9354f667cd5bd07afc0471d8334430da7\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2003},{\"arxivId\":\"1506.08941\",\"authors\":[{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/D15-1001\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d00e7779c39dc7b06d7d43cf6de6d734c8edc4b8\",\"title\":\"Language Understanding for Text-based Games using Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d00e7779c39dc7b06d7d43cf6de6d734c8edc4b8\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V Mnih\"},{\"authorId\":null,\"name\":\"K Kavukcuoglu\"},{\"authorId\":null,\"name\":\"D Silver\"},{\"authorId\":null,\"name\":\"A Rusu\"},{\"authorId\":null,\"name\":\"J Veness\"},{\"authorId\":null,\"name\":\"M G Bellemare\"},{\"authorId\":null,\"name\":\"A Graves\"},{\"authorId\":null,\"name\":\"M Riedmiller\"},{\"authorId\":null,\"name\":\"A Fidjeland\"},{\"authorId\":null,\"name\":\"G Ostrovski\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Humanlevel control through deep reinforcement learning\",\"url\":\"\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144299726\",\"name\":\"Thomas G. Dietterich\"}],\"doi\":\"10.1145/242224.242229\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aab43c9c33af00b718cf2ae374b861d49862a563\",\"title\":\"Machine learning\",\"url\":\"https://www.semanticscholar.org/paper/aab43c9c33af00b718cf2ae374b861d49862a563\",\"venue\":\"CSUR\",\"year\":1996},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699108\",\"name\":\"G. Tesauro\"}],\"doi\":\"10.3233/ICG-1995-18207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0507efeaeb8f0c11443de6d3ecf1dcb91d96c4e8\",\"title\":\"Temporal Difference Learning and TD-Gammon\",\"url\":\"https://www.semanticscholar.org/paper/0507efeaeb8f0c11443de6d3ecf1dcb91d96c4e8\",\"venue\":\"J. Int. Comput. Games Assoc.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Adams\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fundamentals of game design. Pearson Education\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1312.5602\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2319a491378867c7049b3da055c5df60e1671158\",\"title\":\"Playing Atari with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/2319a491378867c7049b3da055c5df60e1671158\",\"venue\":\"ArXiv\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144942240\",\"name\":\"E. Adams\"}],\"doi\":\"10.5860/choice.47-4462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebae6fb17c1f3c39209d7a220db8eb7a64575e50\",\"title\":\"Fundamentals of Game Design\",\"url\":\"https://www.semanticscholar.org/paper/ebae6fb17c1f3c39209d7a220db8eb7a64575e50\",\"venue\":\"\",\"year\":2006},{\"arxivId\":\"1401.5390\",\"authors\":[{\"authorId\":\"1741598\",\"name\":\"S. R. K. Branavan\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.1613/jair.3484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99f1921a8ba5ceecb18e5ca7ff19b7f95c4e250d\",\"title\":\"Learning to Win by Reading Manuals in a Monte-Carlo Framework\",\"url\":\"https://www.semanticscholar.org/paper/99f1921a8ba5ceecb18e5ca7ff19b7f95c4e250d\",\"venue\":\"ACL\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1741598\",\"name\":\"S. R. K. Branavan\"},{\"authorId\":\"3152698\",\"name\":\"Harr Chen\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.3115/1687878.1687892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc1648c91ffda21bbe6e5f08f69c683588fc384c\",\"title\":\"Reinforcement Learning for Mapping Instructions to Actions\",\"url\":\"https://www.semanticscholar.org/paper/cc1648c91ffda21bbe6e5f08f69c683588fc384c\",\"venue\":\"ACL/IJCNLP\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4562073\",\"name\":\"Chris Watkins\"},{\"authorId\":\"46902274\",\"name\":\"P. Dayan\"}],\"doi\":\"10.1007/BF00992698\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"03b7e51c52084ac1db5118342a00b5fbcfc587aa\",\"title\":\"Q-learning\",\"url\":\"https://www.semanticscholar.org/paper/03b7e51c52084ac1db5118342a00b5fbcfc587aa\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"},{\"authorId\":\"81338045\",\"name\":\"M. Kearns\"},{\"authorId\":\"1737616\",\"name\":\"D. Litman\"},{\"authorId\":\"1760530\",\"name\":\"M. Walker\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"839f1b61803e65f20f067b361d0ebf6db337172c\",\"title\":\"Reinforcement Learning for Spoken Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/839f1b61803e65f20f067b361d0ebf6db337172c\",\"venue\":\"NIPS\",\"year\":1999},{\"arxivId\":\"1508.04025\",\"authors\":[{\"authorId\":\"1821711\",\"name\":\"Thang Luong\"},{\"authorId\":\"143950636\",\"name\":\"Hieu Pham\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/D15-1166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93499a7c7f699b6630a86fad964536f9423bb6d0\",\"title\":\"Effective Approaches to Attention-based Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/93499a7c7f699b6630a86fad964536f9423bb6d0\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478313\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54c4cf3a8168c1b70f91cf78a3dc98b671935492\",\"title\":\"Reinforcement learning for robots using neural networks\",\"url\":\"https://www.semanticscholar.org/paper/54c4cf3a8168c1b70f91cf78a3dc98b671935492\",\"venue\":\"\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2576957\",\"name\":\"R. Bellman\"}],\"doi\":\"10.2307/1909506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a6b8a2f80436acdcb201144238c7a49735eb1e9\",\"title\":\"Dynamic programming.\",\"url\":\"https://www.semanticscholar.org/paper/7a6b8a2f80436acdcb201144238c7a49735eb1e9\",\"venue\":\"Science\",\"year\":1966}],\"title\":\"Deep Reinforcement Learning with a Natural Language Action Space\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Text-based game\",\"topicId\":\"2137259\",\"url\":\"https://www.semanticscholar.org/topic/2137259\"},{\"topic\":\"Q-learning\",\"topicId\":\"17301\",\"url\":\"https://www.semanticscholar.org/topic/17301\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"String (computer science)\",\"topicId\":\"8459\",\"url\":\"https://www.semanticscholar.org/topic/8459\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Natural language understanding\",\"topicId\":\"18266\",\"url\":\"https://www.semanticscholar.org/topic/18266\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Time complexity\",\"topicId\":\"3448\",\"url\":\"https://www.semanticscholar.org/topic/3448\"},{\"topic\":\"Approximation algorithm\",\"topicId\":\"87\",\"url\":\"https://www.semanticscholar.org/topic/87\"},{\"topic\":\"FITS\",\"topicId\":\"342298\",\"url\":\"https://www.semanticscholar.org/topic/342298\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Action algebra\",\"topicId\":\"87245\",\"url\":\"https://www.semanticscholar.org/topic/87245\"}],\"url\":\"https://www.semanticscholar.org/paper/6118910c4014cc6c061198a2d88c080ab56ea452\",\"venue\":\"ACL\",\"year\":2016}\n"