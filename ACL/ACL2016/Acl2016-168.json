"{\"abstract\":\"Automatically generating a natural language description of an image is a fundamental problem in artificial intelligence. This task involves both computer vision and natural language processing and is called \\u201cimage caption generation.\\u201d Research on image caption generation has typically focused on taking in an image and generating a caption in English as existing image caption corpora are mostly in English. The lack of corpora in languages other than English is an issue, especially for morphologically rich languages such as Japanese. There is thus a need for corpora sufficiently large for image captioning in other languages. We have developed a Japanese version of the MS COCO caption dataset and a generative model based on a deep recurrent architecture that takes in an image and uses this Japanese version of the dataset to generate a caption in Japanese. As the Japanese portion of the corpus is small, our model was designed to transfer the knowledge representation obtained from the English portion into the Japanese portion. Experiments showed that the resulting bilingual comparable corpus has better performance than a monolingual corpus, indicating that image understanding using a resource-rich language benefits a resource-poor language.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145414551\",\"name\":\"Takashi Miyazaki\",\"url\":\"https://www.semanticscholar.org/author/145414551\"},{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\",\"url\":\"https://www.semanticscholar.org/author/3037066\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":\"1805.08661\",\"authors\":[{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"46200183\",\"name\":\"Chaoxi Xu\"},{\"authorId\":\"26832002\",\"name\":\"X. Wang\"},{\"authorId\":\"2896042\",\"name\":\"W. Lan\"},{\"authorId\":\"152584142\",\"name\":\"Zhengxiong Jia\"},{\"authorId\":\"145789911\",\"name\":\"Gang Yang\"},{\"authorId\":\"1706347\",\"name\":\"Jieping Xu\"}],\"doi\":\"10.1109/TMM.2019.2896494\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b795675a6228abb68f8ed1b8abaf8630309fd764\",\"title\":\"COCO-CN for Cross-Lingual Image Tagging, Captioning, and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b795675a6228abb68f8ed1b8abaf8630309fd764\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9455885\",\"name\":\"Ankit Rathi\"}],\"doi\":\"10.1109/ICCECE48148.2020.9223087\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a93629ec132628e86ff7ab6cd21099f5968d58bf\",\"title\":\"Deep learning apporach for image captioning in Hindi language\",\"url\":\"https://www.semanticscholar.org/paper/a93629ec132628e86ff7ab6cd21099f5968d58bf\",\"venue\":\"2020 International Conference on Computer, Electrical & Communication Engineering (ICCECE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1908.07810\",\"authors\":[{\"authorId\":\"50118263\",\"name\":\"Yike Wu\"},{\"authorId\":\"2516425\",\"name\":\"Shiwan Zhao\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"48379958\",\"name\":\"Ying Zhang\"},{\"authorId\":\"1721029\",\"name\":\"Xiaojie Yuan\"},{\"authorId\":\"1703625\",\"name\":\"Zhong Su\"}],\"doi\":\"10.1109/ICME.2019.00070\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4b29b999bc2d907d6d01ad30829058721d29394\",\"title\":\"Improving Captioning for Low-Resource Languages by Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d4b29b999bc2d907d6d01ad30829058721d29394\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41048842\",\"name\":\"Tonmoay Deb\"},{\"authorId\":\"152359104\",\"name\":\"M. Ali\"},{\"authorId\":\"152398205\",\"name\":\"S. Bhowmik\"},{\"authorId\":\"1972671\",\"name\":\"A. Firoze\"},{\"authorId\":\"152242250\",\"name\":\"Syed Shahir Ahmed\"},{\"authorId\":\"1395633906\",\"name\":\"Muhammad Abeer Tahmeed\"},{\"authorId\":\"145057622\",\"name\":\"N. Rahman\"},{\"authorId\":\"1732925\",\"name\":\"Rashedur M. Rahman\"}],\"doi\":\"10.3233/JIFS-179351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40ba4d6ebb66673bea62b1889f6fcde139f4b816\",\"title\":\"Oboyob: A sequential-semantic Bengali image captioning engine\",\"url\":\"https://www.semanticscholar.org/paper/40ba4d6ebb66673bea62b1889f6fcde139f4b816\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1707.08435\",\"authors\":[{\"authorId\":\"48912184\",\"name\":\"W. Havard\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"1791520\",\"name\":\"O. Rosec\"}],\"doi\":\"10.21437/GLU.2017-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"235780312bf7ead98d7a6332e01d846f12090d2a\",\"title\":\"SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO Data Set\",\"url\":\"https://www.semanticscholar.org/paper/235780312bf7ead98d7a6332e01d846f12090d2a\",\"venue\":\"INTERSPEECH 2017\",\"year\":2017},{\"arxivId\":\"1707.01736\",\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1791713\",\"name\":\"Piek T. J. M. Vossen\"}],\"doi\":\"10.18653/v1/W17-3503\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e22336dc29306ccd938c9a2ae06e3919321dcb8d\",\"title\":\"Cross-linguistic differences and similarities in image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e22336dc29306ccd938c9a2ae06e3919321dcb8d\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f5a58e715afad8499d90c4855824c6967dbf39\",\"title\":\"Learning Visually Grounded and Multilingual Representations\",\"url\":\"https://www.semanticscholar.org/paper/58f5a58e715afad8499d90c4855824c6967dbf39\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1707.06436\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"3393640\",\"name\":\"Soma Shirakabe\"},{\"authorId\":null,\"name\":\"Yun He\"},{\"authorId\":\"9935341\",\"name\":\"S. Ueta\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"49897653\",\"name\":\"K. Abe\"},{\"authorId\":\"2554424\",\"name\":\"Asako Kanezaki\"},{\"authorId\":\"49133490\",\"name\":\"Shinichiro Morita\"},{\"authorId\":\"22219521\",\"name\":\"Toshiyuki Yabe\"},{\"authorId\":\"50544018\",\"name\":\"Yoshihiro Kanehara\"},{\"authorId\":\"22174281\",\"name\":\"Hiroya Yatsuyanagi\"},{\"authorId\":\"1692565\",\"name\":\"S. Maruyama\"},{\"authorId\":\"10756539\",\"name\":\"Ryousuke Takasawa\"},{\"authorId\":\"3217653\",\"name\":\"Masataka Fuchida\"},{\"authorId\":\"2642022\",\"name\":\"Y. Miyashita\"},{\"authorId\":\"34935749\",\"name\":\"Kazushige Okayasu\"},{\"authorId\":\"20505300\",\"name\":\"Yuta Matsuzaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"title\":\"cvpaper.challenge in 2016: Futuristic Computer Vision through 1, 600 Papers Survey\",\"url\":\"https://www.semanticscholar.org/paper/8a9ca15aebadad4b7cfa18c5af91c431d6045b86\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1809.07615\",\"authors\":[{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"}],\"doi\":\"10.18653/v1/K18-1039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b73d82be8270db40577b002789a26e4a226df1ef\",\"title\":\"Lessons learned in multilingual grounded language learning\",\"url\":\"https://www.semanticscholar.org/paper/b73d82be8270db40577b002789a26e4a226df1ef\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3212585\",\"name\":\"Huda Almuzaini\"},{\"authorId\":\"1406444047\",\"name\":\"T. N. Al-Yahya\"},{\"authorId\":\"90527313\",\"name\":\"Hafida Benhidour\"}],\"doi\":\"10.14569/IJACSA.2018.090610\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e0a5ce5204f3f7503c39df6d200627cc331efe2\",\"title\":\"Automatic Arabic Image Captioning using RNN-LSTM-Based Language Model and CNN\",\"url\":\"https://www.semanticscholar.org/paper/1e0a5ce5204f3f7503c39df6d200627cc331efe2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2111626\",\"name\":\"Tongtao Zhang\"},{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"},{\"authorId\":\"2136860\",\"name\":\"Joseph G. Ellis\"},{\"authorId\":\"34170717\",\"name\":\"Lifu Huang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144016781\",\"name\":\"Heng Ji\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1145/3123266.3123294\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b97b00b3742a1402154758179f1d0c3b285b9989\",\"title\":\"Improving Event Extraction via Multimodal Integration\",\"url\":\"https://www.semanticscholar.org/paper/b97b00b3742a1402154758179f1d0c3b285b9989\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41035038\",\"name\":\"Mat\\u00fa\\u0161 Pikuliak\"},{\"authorId\":\"1746545\",\"name\":\"Mari\\u00e1n Simko\"},{\"authorId\":\"1726847\",\"name\":\"M. Bielikov\\u00e1\"}],\"doi\":\"10.1016/j.eswa.2020.113765\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0dd67bdb6090f575800126f997b5b1dbcee02f3\",\"title\":\"Cross-lingual learning for text processing: A survey\",\"url\":\"https://www.semanticscholar.org/paper/b0dd67bdb6090f575800126f997b5b1dbcee02f3\",\"venue\":\"Expert Syst. Appl.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52177940\",\"name\":\"Edy Mulyanto\"},{\"authorId\":\"9723334\",\"name\":\"Esther Irawati Setiawan\"},{\"authorId\":\"3408219\",\"name\":\"E. M. Yuniarno\"},{\"authorId\":\"153121000\",\"name\":\"M. H. Purnomo\"}],\"doi\":\"10.1109/CIVEMSA45640.2019.9071632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d009ef2e76203ce6801b7740b97ba6354d9c0e59\",\"title\":\"Automatic Indonesian Image Caption Generation using CNN-LSTM Model and FEEH-ID Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d009ef2e76203ce6801b7740b97ba6354d9c0e59\",\"venue\":\"2019 IEEE International Conference on Computational Intelligence and Virtual Environments for Measurement Systems and Applications (CIVEMSA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1912135\",\"name\":\"V. Jindal\"}],\"doi\":\"10.18653/v1/N18-4020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49ed7d18d67c20c4152ba26cc235b2a8e4aec0d5\",\"title\":\"Generating Image Captions in Arabic Using Root-Word Based Recurrent Neural Networks and Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/49ed7d18d67c20c4152ba26cc235b2a8e4aec0d5\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2002.00175\",\"authors\":[{\"authorId\":\"2318621\",\"name\":\"Q. Lam\"},{\"authorId\":\"104268348\",\"name\":\"Quang Duy \\u2013 Le\"},{\"authorId\":\"10346850\",\"name\":\"Kiet Van Nguyen\"},{\"authorId\":\"2591380\",\"name\":\"N. Nguyen\"}],\"doi\":\"10.1007/978-3-030-63007-2_57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"245bab73b8921a2fdf1b479b20b4168af26681cf\",\"title\":\"UIT-ViIC: A Dataset for the First Evaluation on Vietnamese Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/245bab73b8921a2fdf1b479b20b4168af26681cf\",\"venue\":\"ICCCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"title\":\"Visual context for verb sense disambiguation and multilingual representation learning\",\"url\":\"https://www.semanticscholar.org/paper/49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.04925\",\"authors\":[{\"authorId\":\"30894109\",\"name\":\"A. Chen\"},{\"authorId\":\"49444758\",\"name\":\"Xinyi Huang\"},{\"authorId\":\"15385188\",\"name\":\"Hailan Lin\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4079b8d38e085386609b82b6bf8ab43d1fab13e\",\"title\":\"Towards Annotation-Free Evaluation of Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f4079b8d38e085386609b82b6bf8ab43d1fab13e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.03493\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1609/AAAI.V34I07.6785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77802591c3f5b3f654bb5b68ad62ed056769320f\",\"title\":\"MULE: Multimodal Universal Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/77802591c3f5b3f654bb5b68ad62ed056769320f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24332496\",\"name\":\"Q. Wei\"},{\"authorId\":\"26832002\",\"name\":\"X. Wang\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":\"10.1145/3095713.3095751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6315c26b1424fc035d113018d791faa9c630c82c\",\"title\":\"Harvesting Deep Models for Cross-Lingual Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/6315c26b1424fc035d113018d791faa9c630c82c\",\"venue\":\"CBMI\",\"year\":2017},{\"arxivId\":\"1710.07177\",\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"37922370\",\"name\":\"S. Frank\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W17-4718\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee5b4fc5fafa7e883d751557b5c7863503cd92d2\",\"title\":\"Findings of the Second Shared Task on Multimodal Machine Translation and Multilingual Image Description\",\"url\":\"https://www.semanticscholar.org/paper/ee5b4fc5fafa7e883d751557b5c7863503cd92d2\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":\"1910.03291\",\"authors\":[{\"authorId\":\"1387993874\",\"name\":\"Alireza Mohammadshahi\"},{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"1751802\",\"name\":\"K. Aberer\"}],\"doi\":\"10.18653/v1/D19-6605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d880af464e477421e5cddc794e971c6db193b8c\",\"title\":\"Aligning Multilingual Word Embeddings for Cross-Modal Retrieval Task\",\"url\":\"https://www.semanticscholar.org/paper/2d880af464e477421e5cddc794e971c6db193b8c\",\"venue\":\"IJCNLP 2019\",\"year\":2019},{\"arxivId\":\"1705.00823\",\"authors\":[{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"3087214\",\"name\":\"Yutaro Shigeto\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":\"10.18653/v1/P17-2066\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6128190a8c18cde6b94e0fae934d6fcc406ea0bb\",\"title\":\"STAIR Captions: Constructing a Large-Scale Japanese Image Caption Dataset\",\"url\":\"https://www.semanticscholar.org/paper/6128190a8c18cde6b94e0fae934d6fcc406ea0bb\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145430120\",\"name\":\"John Hewitt\"},{\"authorId\":\"7975935\",\"name\":\"Daphne Ippolito\"},{\"authorId\":\"105040217\",\"name\":\"Brendan Callahan\"},{\"authorId\":\"46218926\",\"name\":\"Reno Kriz\"},{\"authorId\":\"2129412\",\"name\":\"D. Wijaya\"},{\"authorId\":\"1389724108\",\"name\":\"Chris Callison-Burch\"}],\"doi\":\"10.18653/v1/P18-1239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e2c2d17b6319e2bbe1b34b79cc90e3b88d22a68\",\"title\":\"Learning Translations via Images with a Massively Multilingual Image Dataset\",\"url\":\"https://www.semanticscholar.org/paper/2e2c2d17b6319e2bbe1b34b79cc90e3b88d22a68\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1707.07601\",\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":\"10.18653/v1/D17-1303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8eee0c0a566c9d59e264dd4119225840caa307dc\",\"title\":\"Image Pivoting for Learning Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/8eee0c0a566c9d59e264dd4119225840caa307dc\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"}],\"doi\":\"10.18653/V1/E17-4001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ca8ddf79d4cd1dc20cc8160a6d3326933e943f\",\"title\":\"Pragmatic descriptions of perceptual stimuli\",\"url\":\"https://www.semanticscholar.org/paper/29ca8ddf79d4cd1dc20cc8160a6d3326933e943f\",\"venue\":\"EACL\",\"year\":2017},{\"arxivId\":\"2004.04312\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2129412\",\"name\":\"D. Wijaya\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1007/978-3-030-58548-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"title\":\"Learning to Scale Multilingual Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b8e9b6ecb592269836bcdc46d0d0d001e883c9ee\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410681599\",\"name\":\"A. Gomez-Garay\"},{\"authorId\":\"3262395\",\"name\":\"B. Raducanu\"},{\"authorId\":\"143861895\",\"name\":\"Joaquin Salas\"}],\"doi\":\"10.1007/978-3-319-92198-3_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a24cf818e431ad9cb2e9f423514979f851a08eca\",\"title\":\"Dense Captioning of Natural Scenes in Spanish\",\"url\":\"https://www.semanticscholar.org/paper/a24cf818e431ad9cb2e9f423514979f851a08eca\",\"venue\":\"MCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"},{\"authorId\":\"1888638\",\"name\":\"Akihiro Tamura\"},{\"authorId\":\"49584970\",\"name\":\"T. Ninomiya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4174087859fb7e99e6f24cd7ae765e3b3011a4f9\",\"title\":\"A Visually-Grounded Parallel Corpus with Phrase-to-Region Linking\",\"url\":\"https://www.semanticscholar.org/paper/4174087859fb7e99e6f24cd7ae765e3b3011a4f9\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1708.04390\",\"authors\":[{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"}],\"doi\":\"10.1145/3123266.3123366\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"title\":\"Fluency-Guided Cross-Lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39f3f9d22a072d0ccf423aa31bacbb4071ac0644\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1706.06275\",\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"93168a3dc214447cd938c35e635bea8af4400b12\",\"title\":\"Using Artificial Tokens to Control Languages for Multilingual Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/93168a3dc214447cd938c35e635bea8af4400b12\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"48873415\",\"name\":\"Na Rong\"},{\"authorId\":\"145414551\",\"name\":\"Takashi Miyazaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98025d3d44e9379736adb1228919272ded9298ae\",\"title\":\"Visual Question Answering Dataset for Bilingual Image Understanding: A Study of Cross-Lingual Transfer Using Attention Maps\",\"url\":\"https://www.semanticscholar.org/paper/98025d3d44e9379736adb1228919272ded9298ae\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d42142285c46207a16bd4294e437d504e419a9b7\",\"title\":\"Varying image description tasks: spoken versus written descriptions\",\"url\":\"https://www.semanticscholar.org/paper/d42142285c46207a16bd4294e437d504e419a9b7\",\"venue\":\"VarDial@COLING 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"145987795\",\"name\":\"M. A. Lopes\"},{\"authorId\":\"145877010\",\"name\":\"Douglas M. Souza\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/ICCV.2019.00590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84010f883e9a7283666a6628226016ca4f8d28f1\",\"title\":\"Language-Agnostic Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/84010f883e9a7283666a6628226016ca4f8d28f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.02635\",\"authors\":[{\"authorId\":\"15086992\",\"name\":\"H. Huang\"},{\"authorId\":\"143693093\",\"name\":\"L. Su\"},{\"authorId\":\"1380129958\",\"name\":\"Di Qi\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"144530394\",\"name\":\"Edward Cui\"},{\"authorId\":\"1490606819\",\"name\":\"Taroon Bharti\"},{\"authorId\":\"1452981772\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1453953482\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144934143\",\"name\":\"Dongdong Zhang\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dfb93b3072bc7d4fb3a53072fc04e28f057b1d4e\",\"title\":\"M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/dfb93b3072bc7d4fb3a53072fc04e28f057b1d4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46413437\",\"name\":\"Xiangfang Zeng\"},{\"authorId\":\"35661244\",\"name\":\"Xiaodong Wang\"}],\"doi\":\"10.1109/ICCCBDA.2017.7951934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69c36275ddf2ea95ea4ac39b4d41079c13827281\",\"title\":\"Add English to image Chinese captioning\",\"url\":\"https://www.semanticscholar.org/paper/69c36275ddf2ea95ea4ac39b4d41079c13827281\",\"venue\":\"2017 IEEE 2nd International Conference on Cloud Computing and Big Data Analysis (ICCCBDA)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"2082372\",\"name\":\"Rico Sennrich\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbd429d1a5582ef4347abc7cd99eb6d5b740e70a\",\"title\":\"Explorer Image Pivoting for Learning Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/fbd429d1a5582ef4347abc7cd99eb6d5b740e70a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/W17-4752\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"title\":\"Sheffield MultiMT: Using Object Posterior Predictions for Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/08f6b52317b34b60aa65f38b83e3d72deffa0473\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":\"2010.01288\",\"authors\":[{\"authorId\":\"144407296\",\"name\":\"J. Gao\"},{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"2721708\",\"name\":\"P. Yu\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8405576136062ea661febeeedbc5076235d5eb42\",\"title\":\"Unsupervised Cross-lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8405576136062ea661febeeedbc5076235d5eb42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.06244\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"1720246\",\"name\":\"Jianshu Chen\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1740249\",\"name\":\"X. Yan\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/D18-1038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff065acdde4b8b6cb1e0386924d72cdcee058503\",\"title\":\"XL-NBT: A Cross-lingual Neural Belief Tracking Framework\",\"url\":\"https://www.semanticscholar.org/paper/ff065acdde4b8b6cb1e0386924d72cdcee058503\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1911.12798\",\"authors\":[{\"authorId\":\"3461272\",\"name\":\"Umut Sulubacak\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"1438306994\",\"name\":\"Stig-Arne Gronroos\"},{\"authorId\":\"8769200\",\"name\":\"Aku Rouhe\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"113391779\",\"name\":\"Jorg Tiedemann\"}],\"doi\":\"10.1007/s10590-020-09250-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6f62d2365aa63f5d9c90893ab8aaa25551276fe\",\"title\":\"Multimodal machine translation through visuals and speech\",\"url\":\"https://www.semanticscholar.org/paper/a6f62d2365aa63f5d9c90893ab8aaa25551276fe\",\"venue\":\"Machine Translation\",\"year\":2020},{\"arxivId\":\"1707.08435\",\"authors\":[{\"authorId\":\"151459430\",\"name\":\"William N. Havard\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"1791520\",\"name\":\"O. Rosec\"}],\"doi\":\"10.18709/PERSCIDO.2017.06.DS80\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a759570e6ef674cd93068020c2e6bd036961f7c6\",\"title\":\"SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO Data Set\",\"url\":\"https://www.semanticscholar.org/paper/a759570e6ef674cd93068020c2e6bd036961f7c6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37922370\",\"name\":\"S. Frank\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.1017/S1351324918000074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d31b155926c8d81bea21fb3c689ea950bb109cfb\",\"title\":\"Assessing multilingual multimodal image description: Studies of native speaker preferences and translator choices\",\"url\":\"https://www.semanticscholar.org/paper/d31b155926c8d81bea21fb3c689ea950bb109cfb\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1910.11301\",\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"2093485\",\"name\":\"Jiangtao Feng\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a273479d5ede7a27cf144a18cfbf0542b92fa12\",\"title\":\"Cross-Lingual Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/2a273479d5ede7a27cf144a18cfbf0542b92fa12\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":17040292,\"doi\":\"10.18653/v1/P16-1168\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":7,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"558c587373e2ea44898f70de7858da71aa217b8d\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2216860\",\"name\":\"Ayah Zirikly\"}],\"doi\":\"10.3115/v1/P15-2064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31299844001b0322b4262c3f840ecd1d6a98149c\",\"title\":\"Cross-lingual Transfer of Named Entity Recognizers without Parallel Corpora\",\"url\":\"https://www.semanticscholar.org/paper/31299844001b0322b4262c3f840ecd1d6a98149c\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48772327\",\"name\":\"Qiang Chen\"},{\"authorId\":\"50135831\",\"name\":\"W. Li\"},{\"authorId\":\"144470378\",\"name\":\"Y. Lei\"},{\"authorId\":\"2902322\",\"name\":\"X. Liu\"},{\"authorId\":\"144984527\",\"name\":\"Y. He\"}],\"doi\":\"10.3115/v1/P15-1041\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ced1ba75bd617138a193963476ca7f4f0beab8b\",\"title\":\"Learning to Adapt Credible Knowledge in Cross-lingual Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4ced1ba75bd617138a193963476ca7f4f0beab8b\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bleu: A method for automatic\",\"url\":\"\",\"venue\":\"\",\"year\":2002},{\"arxivId\":\"0808.3231\",\"authors\":[{\"authorId\":\"145624000\",\"name\":\"Z. Zhou\"},{\"authorId\":\"3039887\",\"name\":\"M. Zhang\"},{\"authorId\":\"7649626\",\"name\":\"Sheng-Jun Huang\"},{\"authorId\":\"48514307\",\"name\":\"Yu-Feng Li\"}],\"doi\":\"10.1016/j.artint.2011.10.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fae4506bd003b597fab3291e89fd25b6e3f56bad\",\"title\":\"Multi-instance multi-label learning\",\"url\":\"https://www.semanticscholar.org/paper/fae4506bd003b597fab3291e89fd25b6e3f56bad\",\"venue\":\"Artif. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144084849\",\"name\":\"Jiang Guo\"},{\"authorId\":\"2256319\",\"name\":\"W. Che\"},{\"authorId\":\"1693517\",\"name\":\"David Yarowsky\"},{\"authorId\":\"1687419\",\"name\":\"H. Wang\"},{\"authorId\":\"46999402\",\"name\":\"T. Liu\"}],\"doi\":\"10.3115/v1/P15-1119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"666f6bbb513e43c69ecd7c8ea8f38c894e093478\",\"title\":\"Cross-lingual Dependency Parsing Based on Distributed Representations\",\"url\":\"https://www.semanticscholar.org/paper/666f6bbb513e43c69ecd7c8ea8f38c894e093478\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Tieleman\"},{\"authorId\":null,\"name\":\"G. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Lecture 6.5\\u2014 RmsProp: Divide the gradient by a running average of its recent magnitude. COURSERA: Neural Networks for Machine Learning\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1403.6382\",\"authors\":[{\"authorId\":\"2835963\",\"name\":\"A. Razavian\"},{\"authorId\":\"2622491\",\"name\":\"H. Azizpour\"},{\"authorId\":\"50626295\",\"name\":\"J. Sullivan\"},{\"authorId\":\"144719278\",\"name\":\"S. Carlsson\"}],\"doi\":\"10.1109/CVPRW.2014.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6270baedeba28001cd1b563a199335720d6e0fe0\",\"title\":\"CNN Features Off-the-Shelf: An Astounding Baseline for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6270baedeba28001cd1b563a199335720d6e0fe0\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf60322f83714523e2d7c1d39983151fe9db7146\",\"title\":\"Collecting Image Annotations Using Amazon's Mechanical Turk\",\"url\":\"https://www.semanticscholar.org/paper/bf60322f83714523e2d7c1d39983151fe9db7146\",\"venue\":\"Mturk@HLT-NAACL\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"944a1cfd79dbfb6fef460360a0765ba790f4027a\",\"title\":\"Recurrent Continuous Translation Models\",\"url\":\"https://www.semanticscholar.org/paper/944a1cfd79dbfb6fef460360a0765ba790f4027a\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Julia Hockenmaier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Collecting image annota\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48036166\",\"name\":\"Ruka Funaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.18653/v1/D15-1070\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24a36b5153ce9338d06204bca45098997e79295b\",\"title\":\"Image-Mediated Learning for Zero-Shot Cross-Lingual Document Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/24a36b5153ce9338d06204bca45098997e79295b\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T Tieleman\"},{\"authorId\":null,\"name\":\"G Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Lecture 6.5\\u2014 RmsProp: Divide the gradient by a running average of its recent magnitude\",\"url\":\"\",\"venue\":\"COURSERA: Neural Networks for Machine Learning\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.18653/v1/D15-1021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a98a8b3b28250cb77d99748bff15ddbd9351433\",\"title\":\"A Survey of Current Datasets for Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/4a98a8b3b28250cb77d99748bff15ddbd9351433\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.1109/ICCV.2013.211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"title\":\"Learning the Visual Interpretation of Sentences\",\"url\":\"https://www.semanticscholar.org/paper/6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1310.1531\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8de958fead0d8a9619b55c7299df3257c624a96\",\"title\":\"DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8de958fead0d8a9619b55c7299df3257c624a96\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ruka Funaki\"},{\"authorId\":null,\"name\":\"Hideki Nakayama\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Imagemediated learning for zero-shot cross-lingual document retrieval Association for Computational Linguis- tics\",\"url\":\"\",\"venue\":\"Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3117618\",\"name\":\"Seiya Tokui\"},{\"authorId\":\"1812144\",\"name\":\"Kenta Oono\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67156902beca9bc90b728c8d5dd4ac9d8b27d3a3\",\"title\":\"Chainer : a Next-Generation Open Source Framework for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/67156902beca9bc90b728c8d5dd4ac9d8b27d3a3\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Publishing\"},{\"authorId\":null,\"name\":\"Cham. Chin-Yew Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rouge: A package for auto\",\"url\":\"\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015}],\"title\":\"Cross-Lingual Image Caption Generation\",\"topics\":[{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Crowdsourcing\",\"topicId\":\"85\",\"url\":\"https://www.semanticscholar.org/topic/85\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Knowledge representation and reasoning\",\"topicId\":\"7623\",\"url\":\"https://www.semanticscholar.org/topic/7623\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/558c587373e2ea44898f70de7858da71aa217b8d\",\"venue\":\"ACL\",\"year\":2016}\n"