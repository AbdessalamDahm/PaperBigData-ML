"{\"abstract\":\"In this paper, we aim to understand whether current language and vision (LaVi) models truly grasp the interaction between the two modalities. To this end, we propose an extension of the MSCOCO dataset, FOIL-COCO, which associates images with both correct and \\\"foil\\\" captions, that is, descriptions of the image that are highly similar to the original ones, but contain one single mistake (\\\"foil word\\\"). We show that current LaVi models fall into the traps of this data and perform badly on three tasks: a) caption classification (correct vs. foil); b) foil word detection; c) foil word correction. Humans, in contrast, have near-perfect performance on those tasks. We demonstrate that merely utilising language cues is not enough to model FOIL-COCO and that it challenges the state-of-the-art by requiring a fine-grained understanding of the relation between text and image.\",\"arxivId\":\"1705.01359\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\",\"url\":\"https://www.semanticscholar.org/author/145543514\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\",\"url\":\"https://www.semanticscholar.org/author/3422247\"},{\"authorId\":\"13597291\",\"name\":\"Yauhen Klimovich\",\"url\":\"https://www.semanticscholar.org/author/13597291\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\",\"url\":\"https://www.semanticscholar.org/author/3352951\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\",\"url\":\"https://www.semanticscholar.org/author/1848946\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\",\"url\":\"https://www.semanticscholar.org/author/1716310\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\",\"url\":\"https://www.semanticscholar.org/author/145040726\"}],\"citationVelocity\":15,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"3352951\",\"name\":\"Aur\\u00e9lie Herbelot\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8dce6fa7a13cc94954cbc6be9a709a4ce696ead3\",\"title\":\"Vision and Language Integration: Moving beyond Objects\",\"url\":\"https://www.semanticscholar.org/paper/8dce6fa7a13cc94954cbc6be9a709a4ce696ead3\",\"venue\":\"IWCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49840598\",\"name\":\"Gabriele Bani\"},{\"authorId\":\"51447989\",\"name\":\"Davide Belli\"},{\"authorId\":\"67175437\",\"name\":\"Gautier Dagan\"},{\"authorId\":\"67175746\",\"name\":\"Alexander Geenen\"},{\"authorId\":\"66777364\",\"name\":\"Andrii Skliar\"},{\"authorId\":\"46176433\",\"name\":\"Aashish Venkatesh\"},{\"authorId\":\"51190347\",\"name\":\"Tim Baumg\\u00e4rtner\"},{\"authorId\":\"2552871\",\"name\":\"Elia Bruni\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.1007/978-3-030-11018-5_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc1592733de7ef2c342b48d616524ded97291f56\",\"title\":\"Adding Object Detection Skills to Visual Dialogue Agents\",\"url\":\"https://www.semanticscholar.org/paper/bc1592733de7ef2c342b48d616524ded97291f56\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47963068\",\"name\":\"N. Vyas\"},{\"authorId\":\"3167650\",\"name\":\"Sai Krishna Rallabandi\"},{\"authorId\":\"117576986\",\"name\":\"Lalitesh Morishetti\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.1109/ICASSP.2019.8683370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39bb2e79980f70cdbeb3d1d06c6329700ea00c9d\",\"title\":\"Learning Disentangled Representation in Latent Stochastic Models: A Case Study with Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39bb2e79980f70cdbeb3d1d06c6329700ea00c9d\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22312240\",\"name\":\"Ryosuke Kohita\"},{\"authorId\":\"3253887\",\"name\":\"Hiroshi Noji\"},{\"authorId\":\"1681502\",\"name\":\"Y. Matsumoto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"212eceed8b4772b6a885f401572fc04ca4332bb2\",\"title\":\"Dynamic Feature Selection with Attention in Incremental Parsing\",\"url\":\"https://www.semanticscholar.org/paper/212eceed8b4772b6a885f401572fc04ca4332bb2\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1808.09031\",\"authors\":[{\"authorId\":\"152775164\",\"name\":\"Rebecca Marvin\"},{\"authorId\":\"2467508\",\"name\":\"Tal Linzen\"}],\"doi\":\"10.7275/P0CQ-HV95\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d00097433a538002b36cfd7a621daddde3e4c0d\",\"title\":\"Targeted Syntactic Evaluation of Language Models\",\"url\":\"https://www.semanticscholar.org/paper/4d00097433a538002b36cfd7a621daddde3e4c0d\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1706.01322\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":\"10.18653/v1/W18-1003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3884d98977c12a2fbd2f5a8a7e955a55652a8fd\",\"title\":\"Deep learning evaluation using deep linguistic processing\",\"url\":\"https://www.semanticscholar.org/paper/e3884d98977c12a2fbd2f5a8a7e955a55652a8fd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738647655\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"1438547118\",\"name\":\"Wei-Ting Lu\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"48390820\",\"name\":\"Guanyi Chen\"},{\"authorId\":\"51421297\",\"name\":\"L. Li\"},{\"authorId\":\"1399599427\",\"name\":\"Kees van Deemter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"775d54f3cb71b066ab8959bee9a282a58a286483\",\"title\":\"Gradations of Error Severity in Automatic Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/775d54f3cb71b066ab8959bee9a282a58a286483\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":\"1904.04741\",\"authors\":[{\"authorId\":\"2615736\",\"name\":\"Mahdyar Ravanbakhsh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"250fabf66752c8729cbf286eadab271bd04da710\",\"title\":\"Generative Models for Novelty Detection: Applications in abnormal event and situational change detection from data series\",\"url\":\"https://www.semanticscholar.org/paper/250fabf66752c8729cbf286eadab271bd04da710\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2012.12352\",\"authors\":[{\"authorId\":\"1845867134\",\"name\":\"Letitia Parcalabescu\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"143876555\",\"name\":\"A. Frank\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"title\":\"Seeing past words: Testing the cross-modal capabilities of pretrained V&L models\",\"url\":\"https://www.semanticscholar.org/paper/1133be974efcad7e6bbe656911f0a57d369bb9e4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.02174\",\"authors\":[{\"authorId\":\"3444866\",\"name\":\"Alessandro Suglia\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"34742006\",\"name\":\"Andrea Vanzo\"},{\"authorId\":\"2972920\",\"name\":\"E. Bastianelli\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143873430\",\"name\":\"S. Frank\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"}],\"doi\":\"10.18653/V1/2020.ACL-MAIN.682\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"title\":\"CompGuessWhat?!: A Multi-task Evaluation Framework for Grounded Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc78991050e355477f9d0ba51a241947e8bc9b9d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":\"10.1007/978-3-030-11018-5_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ae89d6027c6b45c7b2b95ebc01a1054966da133\",\"title\":\"Knowing When to Look for What and Where: Evaluating Generation of Spatial Descriptions with Adaptive Attention\",\"url\":\"https://www.semanticscholar.org/paper/8ae89d6027c6b45c7b2b95ebc01a1054966da133\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2010.00839\",\"authors\":[{\"authorId\":\"2235554\",\"name\":\"L. A. Ferreira\"},{\"authorId\":\"73149975\",\"name\":\"Douglas De Rizzo Meneghetti\"},{\"authorId\":\"145275454\",\"name\":\"Paulo E. Santos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca16c0ab75ef7c2b28ac19fbe4ca64ae362cdc7d\",\"title\":\"CAPTION: Correction by Analyses, POS-Tagging and Interpretation of Objects using only Nouns\",\"url\":\"https://www.semanticscholar.org/paper/ca16c0ab75ef7c2b28ac19fbe4ca64ae362cdc7d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"32113652\",\"name\":\"G. Gandolfi\"},{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.248\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"title\":\"Be Different to Be Better! A Benchmark to Leverage the Complementarity of Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8265102\",\"name\":\"Irene Sucameli\"},{\"authorId\":\"2038285\",\"name\":\"A. Lenci\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a041967a20dcdae083fda5821816b2cc4a2c73d\",\"title\":\"Representing Verbs with Visual Argument Vectors\",\"url\":\"https://www.semanticscholar.org/paper/9a041967a20dcdae083fda5821816b2cc4a2c73d\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1906.01205\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"}],\"doi\":\"10.18653/v1/P19-2023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd200e1e18794202c3a55a810717e87be7b7dba\",\"title\":\"A Strong and Robust Baseline for Text-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/edd200e1e18794202c3a55a810717e87be7b7dba\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1904.12004\",\"authors\":[{\"authorId\":\"98243944\",\"name\":\"Chenglong Wang\"},{\"authorId\":\"3407947\",\"name\":\"R. Bunel\"},{\"authorId\":\"1729912\",\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":\"10.1109/CVPR.2019.01254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59b439bde73d80dccf367d414e209d08d312c059\",\"title\":\"Knowing When to Stop: Evaluation and Verification of Conformity to Output-Size Specifications\",\"url\":\"https://www.semanticscholar.org/paper/59b439bde73d80dccf367d414e209d08d312c059\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.09788\",\"authors\":[{\"authorId\":\"1387971311\",\"name\":\"Somaye Jafaritazehjani\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"}],\"doi\":\"10.18653/v1/W19-8625\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"6fca889a5d95fa2df47edbfd65f886f8bf4856fe\",\"title\":\"Visuallly Grounded Generation of Entailments from Premises\",\"url\":\"https://www.semanticscholar.org/paper/6fca889a5d95fa2df47edbfd65f886f8bf4856fe\",\"venue\":\"INLG\",\"year\":2019},{\"arxivId\":\"1904.05521\",\"authors\":[{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"98697868\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":null,\"name\":\"Weiwei Sun\"},{\"authorId\":\"1712167\",\"name\":\"W. Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e2f1b71e1003552afd5420c9a0427269a7c7b454\",\"title\":\"UniVSE: Robust Visual Semantic Embeddings via Structured Semantic Representations\",\"url\":\"https://www.semanticscholar.org/paper/e2f1b71e1003552afd5420c9a0427269a7c7b454\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"2008204693\",\"name\":\"Tobias Bianchi\"},{\"authorId\":\"1805994601\",\"name\":\"Mauricio Mazuecos\"},{\"authorId\":\"2008198429\",\"name\":\"Agata Marcante\"},{\"authorId\":\"3131683\",\"name\":\"Luciana Benotti\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.splu-1.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"title\":\"They are not all alike: answering different spatial questions requires different grounding strategies\",\"url\":\"https://www.semanticscholar.org/paper/a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"venue\":\"SPLU\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":\"10.18653/v1/W19-1608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"930f5566ed228a96edde4e03f8b1c4743e5eff69\",\"title\":\"What a neural language model tells us about spatial relations\",\"url\":\"https://www.semanticscholar.org/paper/930f5566ed228a96edde4e03f8b1c4743e5eff69\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152775164\",\"name\":\"Rebecca Marvin\"},{\"authorId\":\"2467508\",\"name\":\"Tal Linzen\"}],\"doi\":\"10.18653/v1/D18-1151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fb06173b51b0e16766217c75aa8c49e0a12bc17\",\"title\":\"Targeted Syntactic Evaluation of Language Models\",\"url\":\"https://www.semanticscholar.org/paper/8fb06173b51b0e16766217c75aa8c49e0a12bc17\",\"venue\":\"EMNLP 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40062064\",\"name\":\"Claudio Greco\"},{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fea5b24f57703f596fa01c188c3e445fa14994df\",\"title\":\"Which Turn do Neural Models Exploit the Most to Solve GuessWhat? Diving into the Dialogue History Encoding in Transformers and LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/fea5b24f57703f596fa01c188c3e445fa14994df\",\"venue\":\"NL4AI@AI*IA\",\"year\":2020},{\"arxivId\":\"1809.03044\",\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"8716902\",\"name\":\"Huiyuan Xie\"},{\"authorId\":\"2812333\",\"name\":\"Ann A. Copestake\"}],\"doi\":\"10.1007/978-3-030-11018-5_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c792eebc581a3acf387aaa13626173032f79b706\",\"title\":\"How clever is the FiLM model, and how clever can it be?\",\"url\":\"https://www.semanticscholar.org/paper/c792eebc581a3acf387aaa13626173032f79b706\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029654239\",\"name\":\"Adam Dahlgren Lindstr\\u00f6m\"},{\"authorId\":\"3998881\",\"name\":\"Johanna Bj\\u00f6rklund\"},{\"authorId\":\"15618794\",\"name\":\"S. Bensch\"},{\"authorId\":\"1741518\",\"name\":\"F. Drewes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fb92f69d7ee5644606e77c86955cd8fd06f8503\",\"title\":\"Probing Multimodal Embeddings for Linguistic Properties: the Visual-Semantic Case\",\"url\":\"https://www.semanticscholar.org/paper/0fb92f69d7ee5644606e77c86955cd8fd06f8503\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.05475\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1007/978-3-030-11018-5_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17ff28401ba9cc24c6b83256150c86dc49308375\",\"title\":\"Quantifying the amount of visual information used by neural caption generators\",\"url\":\"https://www.semanticscholar.org/paper/17ff28401ba9cc24c6b83256150c86dc49308375\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"547253984732d770bcb95627048ba3733df62e47\",\"title\":\"Grounded and Ungrounded Referring Expressions in Human Dialogues: Language Mirrors Different Grounding Conditions\",\"url\":\"https://www.semanticscholar.org/paper/547253984732d770bcb95627048ba3733df62e47\",\"venue\":\"CLiC-it\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927374\",\"name\":\"\\u00d6zge Ala\\u00e7am\"},{\"authorId\":\"7823802\",\"name\":\"Xing-shan Li\"},{\"authorId\":\"153502408\",\"name\":\"W. Menzel\"},{\"authorId\":\"47851561\",\"name\":\"Tobias Staron\"}],\"doi\":\"10.3389/fnbot.2020.00002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b962b9dc017533e979bafeb5c3c6e3c0f224ca0\",\"title\":\"Crossmodal Language Comprehension\\u2014Psycholinguistic Insights and Computational Approaches\",\"url\":\"https://www.semanticscholar.org/paper/4b962b9dc017533e979bafeb5c3c6e3c0f224ca0\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":\"10.18653/v1/D18-1329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32a64831c7a50e9c9b082cc4ee0e5ca4a92630b2\",\"title\":\"Adversarial Evaluation of Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/32a64831c7a50e9c9b082cc4ee0e5ca4a92630b2\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46391221\",\"name\":\"Hendricks\"},{\"authorId\":\"101014571\",\"name\":\"Miles Hebert\"},{\"authorId\":\"1781120\",\"name\":\"Cristian Sminchisescu\"},{\"authorId\":\"145809650\",\"name\":\"Yael Weiss\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e57ca8cfc00de06f4a5baf555c42b80964c5529b\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Grounding Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/e57ca8cfc00de06f4a5baf555c42b80964c5529b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47987162\",\"name\":\"Hao Wu\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"51437593\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"143872729\",\"name\":\"Weiwei Sun\"},{\"authorId\":\"1712167\",\"name\":\"W. Ma\"}],\"doi\":\"10.1109/CVPR.2019.00677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"title\":\"Unified Visual-Semantic Embeddings: Bridging Vision and Language With Structured Meaning Representations\",\"url\":\"https://www.semanticscholar.org/paper/08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152163039\",\"name\":\"June\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"acf13c52c86a3b38642ba0c6cbcd1b771778965c\",\"title\":\"NAACL HLT 2018 Generalization in the Age of Deep Learning Proceedings of the Workshop\",\"url\":\"https://www.semanticscholar.org/paper/acf13c52c86a3b38642ba0c6cbcd1b771778965c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3409740\",\"name\":\"Ziyu Xue\"},{\"authorId\":\"39494411\",\"name\":\"Lei Wang\"},{\"authorId\":\"2834810\",\"name\":\"Peiyu Guo\"}],\"doi\":\"10.1109/icis46139.2019.8940218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7344b254af85b53c5e989579b1d18fbf946c03de\",\"title\":\"Slot based Image Captioning with WGAN\",\"url\":\"https://www.semanticscholar.org/paper/7344b254af85b53c5e989579b1d18fbf946c03de\",\"venue\":\"2019 IEEE/ACIS 18th International Conference on Computer and Information Science (ICIS)\",\"year\":2019},{\"arxivId\":\"1904.06038\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/W19-0418\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fdbb785dd2bc57cb649434be2a7c9a0a71812704\",\"title\":\"Evaluating the Representational Hub of Language and Vision Models\",\"url\":\"https://www.semanticscholar.org/paper/fdbb785dd2bc57cb649434be2a7c9a0a71812704\",\"venue\":\"IWCS\",\"year\":2019},{\"arxivId\":\"1805.06549\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-2069\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8629c779581a0f46452bc4ca45b571bfbd3cd063\",\"title\":\"Defoiling Foiled Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8629c779581a0f46452bc4ca45b571bfbd3cd063\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1911.10097\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"},{\"authorId\":\"39742349\",\"name\":\"X. Wang\"},{\"authorId\":\"50341799\",\"name\":\"Shuaipeng Li\"}],\"doi\":\"10.1609/AAAI.V34I07.6823\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c669e7deed061f3e7f110330ecc28e0ed076f8\",\"title\":\"HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs\",\"url\":\"https://www.semanticscholar.org/paper/51c669e7deed061f3e7f110330ecc28e0ed076f8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1807.09685\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"}],\"doi\":\"10.1007/978-3-030-01216-8_17\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"887027f0aaa2644c29bb9f4c42dcb19ea94c2763\",\"title\":\"Grounding Visual Explanations\",\"url\":\"https://www.semanticscholar.org/paper/887027f0aaa2644c29bb9f4c42dcb19ea94c2763\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"},{\"authorId\":\"90929602\",\"name\":\"Victoria Basmova\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"50757607\",\"name\":\"Ben Bogin\"},{\"authorId\":\"2087205\",\"name\":\"Sihao Chen\"},{\"authorId\":\"2697425\",\"name\":\"Pradeep Dasigi\"},{\"authorId\":\"33546336\",\"name\":\"Dheeru Dua\"},{\"authorId\":\"51131518\",\"name\":\"Yanai Elazar\"},{\"authorId\":\"1471885977\",\"name\":\"Ananth Gottumukkala\"},{\"authorId\":\"2285178\",\"name\":\"Nitish Gupta\"},{\"authorId\":\"1612142798\",\"name\":\"Hanna Hajishirzi\"},{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"1783281\",\"name\":\"Daniel Khashabi\"},{\"authorId\":\"48085802\",\"name\":\"Kevin Lin\"},{\"authorId\":\"153240238\",\"name\":\"Jiangming Liu\"},{\"authorId\":\"22243769\",\"name\":\"Nelson F. Liu\"},{\"authorId\":\"46244238\",\"name\":\"Phoebe Mulcaire\"},{\"authorId\":\"3333257\",\"name\":\"Qiang Ning\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"144365875\",\"name\":\"Noah A. Smith\"},{\"authorId\":\"17097887\",\"name\":\"Sanjay Subramanian\"},{\"authorId\":\"2799181\",\"name\":\"Reut Tsarfaty\"},{\"authorId\":\"145217343\",\"name\":\"Eric Wallace\"},{\"authorId\":\"91966669\",\"name\":\"A. Zhang\"},{\"authorId\":\"145360756\",\"name\":\"Ben Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fec5868542b4d9070306f1418d1d21666226e90\",\"title\":\"Evaluating NLP Models via Contrast Sets\",\"url\":\"https://www.semanticscholar.org/paper/9fec5868542b4d9070306f1418d1d21666226e90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2004.02709\",\"authors\":[{\"authorId\":\"40642935\",\"name\":\"Matt Gardner\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"50757607\",\"name\":\"Ben Bogin\"},{\"authorId\":\"2087205\",\"name\":\"Sihao Chen\"},{\"authorId\":\"33546336\",\"name\":\"Dheeru Dua\"},{\"authorId\":\"51131518\",\"name\":\"Yanai Elazar\"},{\"authorId\":\"1471885977\",\"name\":\"Ananth Gottumukkala\"},{\"authorId\":\"2285178\",\"name\":\"Nitish Gupta\"},{\"authorId\":\"1612142798\",\"name\":\"Hanna Hajishirzi\"},{\"authorId\":\"1387994137\",\"name\":\"Gabriel Ilharco\"},{\"authorId\":\"1783281\",\"name\":\"Daniel Khashabi\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"153240238\",\"name\":\"Jiangming Liu\"},{\"authorId\":\"22243769\",\"name\":\"Nelson F. Liu\"},{\"authorId\":\"46244238\",\"name\":\"Phoebe Mulcaire\"},{\"authorId\":\"3333257\",\"name\":\"Qiang Ning\"},{\"authorId\":\"144171580\",\"name\":\"S. Singh\"},{\"authorId\":\"143867780\",\"name\":\"N. A. Smith\"},{\"authorId\":\"1915893838\",\"name\":\"Sanjay Subramanian\"},{\"authorId\":\"145217343\",\"name\":\"Eric Wallace\"},{\"authorId\":\"91966669\",\"name\":\"A. Zhang\"},{\"authorId\":\"145360756\",\"name\":\"Ben Zhou\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35e6783307f82d1faa39be0653431305abec7271\",\"title\":\"Evaluating Models' Local Decision Boundaries via Contrast Sets\",\"url\":\"https://www.semanticscholar.org/paper/35e6783307f82d1faa39be0653431305abec7271\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":2948298,\"doi\":\"10.18653/v1/P17-1024\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":9,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"references\":[{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1601.03896\",\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.24963/ijcai.2017/704\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6e9aebe54f76d85c6df7e80faa761ef0aec3d54c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1612.07833\",\"authors\":[{\"authorId\":\"145534769\",\"name\":\"N. Ding\"},{\"authorId\":\"7685850\",\"name\":\"Sebastian Goodman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"title\":\"Understanding Image and Text Simultaneously: a Dual Vision-Language Machine Comprehension Task\",\"url\":\"https://www.semanticscholar.org/paper/6edb41364802b0fdd1e3e98d644fe78b1ecbbe45\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d76a09aa363685bc0f04a502ed853dc09a574e2\",\"title\":\"Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization\",\"url\":\"https://www.semanticscholar.org/paper/7d76a09aa363685bc0f04a502ed853dc09a574e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/W16-3203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbaa92c289f4f5ff9a57b19a2725036a92311f5\",\"title\":\"Focused Evaluation for Image Description with Binary Forced-Choice Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ecbaa92c289f4f5ff9a57b19a2725036a92311f5\",\"venue\":\"VL@ACL\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1711.07373\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"title\":\"Attentive Explanations: Justifying Decisions and Pointing to the Evidence\",\"url\":\"https://www.semanticscholar.org/paper/dc07e7bf1cf25aab2c39c85ab03bf085bbca31b5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1608.08974\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"title\":\"Towards Transparent AI Systems: Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":\"10.3115/v1/P14-2074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52f86811b57034ba5c0478b37cab101d9a84024a\",\"title\":\"Comparing Automatic Evaluation Measures for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/52f86811b57034ba5c0478b37cab101d9a84024a\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1604.00790\",\"authors\":[{\"authorId\":\"47075011\",\"name\":\"Cheng Wang\"},{\"authorId\":\"1688587\",\"name\":\"Haojin Yang\"},{\"authorId\":\"28918194\",\"name\":\"C. Bartz\"},{\"authorId\":\"1708312\",\"name\":\"C. Meinel\"}],\"doi\":\"10.1145/2964284.2964299\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"26e425781e4090abfae65b5d68eac72282dd2e31\",\"title\":\"Image Captioning with Deep Bidirectional LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/26e425781e4090abfae65b5d68eac72282dd2e31\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1607.05910\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1016/j.cviu.2017.05.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c307c51594c6d802080a0780d0d654e2e2891f\",\"title\":\"Visual question answering: A survey of methods and datasets\",\"url\":\"https://www.semanticscholar.org/paper/88c307c51594c6d802080a0780d0d654e2e2891f\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014}],\"title\":\"FOIL it! Find One mismatch between Image and Language caption\",\"topics\":[{\"topic\":\"Pipeline (computing)\",\"topicId\":\"3598681\",\"url\":\"https://www.semanticscholar.org/topic/3598681\"},{\"topic\":\"Humans\",\"topicId\":\"732\",\"url\":\"https://www.semanticscholar.org/topic/732\"},{\"topic\":\"Emoticon\",\"topicId\":\"55238\",\"url\":\"https://www.semanticscholar.org/topic/55238\"},{\"topic\":\"Word lists by frequency\",\"topicId\":\"284043\",\"url\":\"https://www.semanticscholar.org/topic/284043\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"}],\"url\":\"https://www.semanticscholar.org/paper/c86ce9fc2bd5aea98869cf1f31d03e05e7ec672c\",\"venue\":\"ACL\",\"year\":2017}\n"