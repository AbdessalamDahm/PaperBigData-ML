"{\"abstract\":\"Given a collection of images and spoken audio captions, we present a method for discovering word-like acoustic units in the continuous speech signal and grounding them to semantically relevant image regions. For example, our model is able to detect spoken instances of the word 'lighthouse' within an utterance and associate them with image regions containing lighthouses. We do not use any form of conventional automatic speech recognition, nor do we use any text transcriptions or conventional linguistic annotations. Our model effectively implements a form of spoken language acquisition, in which the computer learns not only to recognize word categories by sound, but also to enrich the words it learns with semantics by grounding them in images.\",\"arxivId\":\"1701.07481\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\",\"url\":\"https://www.semanticscholar.org/author/30507748\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\",\"url\":\"https://www.semanticscholar.org/author/145898106\"}],\"citationVelocity\":20,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d42142285c46207a16bd4294e437d504e419a9b7\",\"title\":\"Varying image description tasks: spoken versus written descriptions\",\"url\":\"https://www.semanticscholar.org/paper/d42142285c46207a16bd4294e437d504e419a9b7\",\"venue\":\"VarDial@COLING 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121718703\",\"name\":\"Karan Kashyap\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d72185992627e130ae486c2bd0b1865ac6ade48\",\"title\":\"Learning digits via joint audio-visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9d72185992627e130ae486c2bd0b1865ac6ade48\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7086b32013c38fa2f5250dfdc116a5259aca1c63\",\"title\":\"Unsupervised learning of cross-modal mappings between speech and text\",\"url\":\"https://www.semanticscholar.org/paper/7086b32013c38fa2f5250dfdc116a5259aca1c63\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51261844\",\"name\":\"N. Holzenberger\"},{\"authorId\":\"33868757\",\"name\":\"Mingxing Du\"},{\"authorId\":\"31716086\",\"name\":\"Julien Karadayi\"},{\"authorId\":\"40425637\",\"name\":\"Rachid Riad\"},{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"}],\"doi\":\"10.21437/Interspeech.2018-2364\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1feba3d4d421c136839d8c23a62f19b410ea112b\",\"title\":\"Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments\",\"url\":\"https://www.semanticscholar.org/paper/1feba3d4d421c136839d8c23a62f19b410ea112b\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115057636\",\"name\":\"Emmanuel Azuh\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/interspeech.2019-1718\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ab9392167bdbaa272c95178d50fb08bcfba7148\",\"title\":\"Towards Bilingual Lexicon Discovery From Visually Grounded Speech Audio\",\"url\":\"https://www.semanticscholar.org/paper/7ab9392167bdbaa272c95178d50fb08bcfba7148\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"14871837\",\"name\":\"I. Shapira\"},{\"authorId\":\"120159179\",\"name\":\"Tal Hakim\"},{\"authorId\":\"49791471\",\"name\":\"A. Bronstein\"}],\"doi\":\"10.1109/CVPRW50498.2020.00485\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da031a350f80eb23b8cdbce32ec3b0b792cd7557\",\"title\":\"Self-Supervised Object Detection and Retrieval Using Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/da031a350f80eb23b8cdbce32ec3b0b792cd7557\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1904.07078\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"102758063\",\"name\":\"Aristotelis Anastassiou\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/ICASSP.2019.8683275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb10ac5a5d337b8913786f03c3a9b3816bd27bc3\",\"title\":\"Semantic Query-by-example Speech Search Using Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fb10ac5a5d337b8913786f03c3a9b3816bd27bc3\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2019.00213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"title\":\"Learning Words by Drawing Images\",\"url\":\"https://www.semanticscholar.org/paper/bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.05722\",\"authors\":[{\"authorId\":\"31836044\",\"name\":\"Takashi Oya\"},{\"authorId\":\"34279376\",\"name\":\"Shohei Iwase\"},{\"authorId\":\"41015901\",\"name\":\"R. Natsume\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"3117231\",\"name\":\"Shugo Yamaguchi\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"476d71a4cfd1529c4705636041add568853d74b1\",\"title\":\"Do We Need Sound for Sound Source Localization?\",\"url\":\"https://www.semanticscholar.org/paper/476d71a4cfd1529c4705636041add568853d74b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.03094\",\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16d4d7ec673b5697776d1c4f229f5a824b891972\",\"title\":\"Deep Co-Clustering for Unsupervised Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/16d4d7ec673b5697776d1c4f229f5a824b891972\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.01665\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-01219-9_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"title\":\"Learning to Separate Object Sounds by Watching Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/5c9ca16cb2337fd5948c7af28c29c156981250e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1703.08136\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"40059964\",\"name\":\"Shane Settle\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.21437/INTERSPEECH.2017-502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93f46618df0a6cd81d9e42361082e7a80fc9adf7\",\"title\":\"Visually Grounded Learning of Keyword Prediction from Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/93f46618df0a6cd81d9e42361082e7a80fc9adf7\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1607.08723\",\"authors\":[{\"authorId\":\"2202008\",\"name\":\"Emmanuel Dupoux\"}],\"doi\":\"10.1016/j.cognition.2017.11.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c50105953aba395a0beb78ae39346d28487ace95\",\"title\":\"Cognitive science in the era of artificial intelligence: A roadmap for reverse-engineering the infant language-learner\",\"url\":\"https://www.semanticscholar.org/paper/c50105953aba395a0beb78ae39346d28487ace95\",\"venue\":\"Cognition\",\"year\":2018},{\"arxivId\":\"1811.08890\",\"authors\":[{\"authorId\":\"51261844\",\"name\":\"N. Holzenberger\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"}],\"doi\":\"10.1109/ICASSP.2019.8683540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a01ae256dfe7bd10734fec8a66549fb7ea876a05\",\"title\":\"Learning from Multiview Correlations in Open-domain Videos\",\"url\":\"https://www.semanticscholar.org/paper/a01ae256dfe7bd10734fec8a66549fb7ea876a05\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1808.03920\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"12907562\",\"name\":\"Liu Ziyin\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/D18-1014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"title\":\"Multimodal Language Analysis with Recurrent Multistage Fusion\",\"url\":\"https://www.semanticscholar.org/paper/a81a8cf811540be14f7840ef6939a3d7b901a8e3\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144559601\",\"name\":\"Jennifer Drexler\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/GLU.2017-12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a89449e763fea5c9a06c30e4c11072de54f6f49\",\"title\":\"Analysis of Audio-Visual Features for Unsupervised Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6a89449e763fea5c9a06c30e4c11072de54f6f49\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825768830\",\"name\":\"\\u00d6yk\\u00fc Deniz K\\u00f6se\"},{\"authorId\":\"2535627\",\"name\":\"M. Sara\\u00e7lar\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdf5dfa8baa9bed3161240e6f258e838bd4e9180\",\"title\":\"Recurrent Neural Audiovisual Word Embeddings for Synchronized Speech and Real-Time Mri\",\"url\":\"https://www.semanticscholar.org/paper/cdf5dfa8baa9bed3161240e6f258e838bd4e9180\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1709.04482\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f72a8bfcf198471255607b4fcb7e420a73b3400\",\"title\":\"Analyzing Hidden Representations in End-to-End Automatic Speech Recognition Systems\",\"url\":\"https://www.semanticscholar.org/paper/2f72a8bfcf198471255607b4fcb7e420a73b3400\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"020ef0ff20efd4f873ade6ddd718c1624b5963ca\",\"title\":\"Learning spoken language through vision\",\"url\":\"https://www.semanticscholar.org/paper/020ef0ff20efd4f873ade6ddd718c1624b5963ca\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"120159179\",\"name\":\"Tal Hakim\"},{\"authorId\":\"49791556\",\"name\":\"A. Bronstein\"}],\"doi\":\"10.1109/ICCVW.2019.00567\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b68bddfe1da633dc5cad6015de2bf09c1171b3e\",\"title\":\"Learning to Detect and Retrieve Objects From Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/7b68bddfe1da633dc5cad6015de2bf09c1171b3e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47260649\",\"name\":\"Imran Sheikh\"},{\"authorId\":\"1791335\",\"name\":\"Rupayan Chakraborty\"},{\"authorId\":\"1809276\",\"name\":\"Sunil Kumar Kopparapu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"title\":\"Audio-Visual Fusion for Sentiment Classification using Cross-Modal Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/c7f8ccccda67a44503b4c4e0611f38451a334cc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2005.02721\",\"authors\":[{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"}],\"doi\":\"10.18653/v1/2020.acl-main.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c689903f0d82b5e7a71e0d4c78b78e13faee68b\",\"title\":\"Learning to Understand Child-directed and Adult-directed Speech\",\"url\":\"https://www.semanticscholar.org/paper/8c689903f0d82b5e7a71e0d4c78b78e13faee68b\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1803.08869\",\"authors\":[{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"},{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"}],\"doi\":\"10.7275/extq-7546\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca1c55c6c39da237389cc2c95ba97d4fb84f99c0\",\"title\":\"On the difficulty of a distributional semantics of spoken language\",\"url\":\"https://www.semanticscholar.org/paper/ca1c55c6c39da237389cc2c95ba97d4fb84f99c0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.11137\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"120159179\",\"name\":\"Tal Hakim\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad52b2e7b7d66395ee65d282d422d27488dc140e\",\"title\":\"Toward Self-Supervised Object Detection in Unlabeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/ad52b2e7b7d66395ee65d282d422d27488dc140e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1522034508\",\"name\":\"Masood S. Mortazavi\"}],\"doi\":\"10.21437/interspeech.2020-3024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78da3a2775cac327731cb3027ad89511bc2688d2\",\"title\":\"Speech-Image Semantic Alignment Does Not Depend on Any Prior Classification Tasks\",\"url\":\"https://www.semanticscholar.org/paper/78da3a2775cac327731cb3027ad89511bc2688d2\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"48126134\",\"name\":\"Raman Arora\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"144404308\",\"name\":\"Amanda Duarte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"51261844\",\"name\":\"N. Holzenberger\"},{\"authorId\":\"1908331\",\"name\":\"Chiraag Lala\"},{\"authorId\":\"2513954\",\"name\":\"S. Lee\"},{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"78476552\",\"name\":\"K. Mulligan\"},{\"authorId\":\"1752987954\",\"name\":\"Alissa Ostapenka\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"}],\"doi\":\"10.1109/JSTSP.2020.2998415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14aadd24040edaa9ce9978b53b00aeede015f859\",\"title\":\"Grounded Sequence to Sequence Transduction\",\"url\":\"https://www.semanticscholar.org/paper/14aadd24040edaa9ce9978b53b00aeede015f859\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1711.07846\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"29880725\",\"name\":\"Neil Fendley\"},{\"authorId\":\"49961633\",\"name\":\"James Wilson\"},{\"authorId\":\"34847227\",\"name\":\"Ryan Mukherjee\"}],\"doi\":\"10.1109/CVPR.2018.00646\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a588d38ec81c0337b445931eadf6f443aea13380\",\"title\":\"Functional Map of the World\",\"url\":\"https://www.semanticscholar.org/paper/a588d38ec81c0337b445931eadf6f443aea13380\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"36217631\",\"name\":\"J. Glass\"},{\"authorId\":\"2991962\",\"name\":\"Y. Ohishi\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"36217631\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09a183fb3317048f26c60e541fb82abb476d194a\",\"title\":\"Crossmodal Search using Visually Grounded Multilingual Speech Signal\",\"url\":\"https://www.semanticscholar.org/paper/09a183fb3317048f26c60e541fb82abb476d194a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"145720713\",\"name\":\"Shuai Wang\"}],\"doi\":\"10.1109/TGRS.2020.2979273\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e27873bd45b8b3206127fce377c62576068963b2\",\"title\":\"Deep Cross-Modal Image\\u2013Voice Retrieval in Remote Sensing\",\"url\":\"https://www.semanticscholar.org/paper/e27873bd45b8b3206127fce377c62576068963b2\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1707.08435\",\"authors\":[{\"authorId\":\"48912184\",\"name\":\"W. Havard\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"1791520\",\"name\":\"O. Rosec\"}],\"doi\":\"10.21437/GLU.2017-9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"235780312bf7ead98d7a6332e01d846f12090d2a\",\"title\":\"SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO Data Set\",\"url\":\"https://www.semanticscholar.org/paper/235780312bf7ead98d7a6332e01d846f12090d2a\",\"venue\":\"INTERSPEECH 2017\",\"year\":2017},{\"arxivId\":\"2011.10652\",\"authors\":[{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38d705a83a5677ef69adeebae7aa9446f4c2cc74\",\"title\":\"Self-Supervised learning with cross-modal transformers for emotion recognition\",\"url\":\"https://www.semanticscholar.org/paper/38d705a83a5677ef69adeebae7aa9446f4c2cc74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1707.08435\",\"authors\":[{\"authorId\":\"151459430\",\"name\":\"William N. Havard\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"1791520\",\"name\":\"O. Rosec\"}],\"doi\":\"10.18709/PERSCIDO.2017.06.DS80\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a759570e6ef674cd93068020c2e6bd036961f7c6\",\"title\":\"SPEECH-COCO: 600k Visually Grounded Spoken Captions Aligned to MSCOCO Data Set\",\"url\":\"https://www.semanticscholar.org/paper/a759570e6ef674cd93068020c2e6bd036961f7c6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1934412416\",\"name\":\"Liming Wang\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"}],\"doi\":\"10.21437/interspeech.2020-1148\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"98ade41d9814fb150f35ab0bd710b4aecf5f75c2\",\"title\":\"A DNN-HMM-DNN Hybrid Model for Discovering Word-Like Units from Spoken Captions and Image Regions\",\"url\":\"https://www.semanticscholar.org/paper/98ade41d9814fb150f35ab0bd710b4aecf5f75c2\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"1911.09602\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ec4dab7fe0abeed22dd9ecb25695ab4b66f108b\",\"title\":\"Learning Hierarchical Discrete Linguistic Units from Visually-Grounded Speech\",\"url\":\"https://www.semanticscholar.org/paper/9ec4dab7fe0abeed22dd9ecb25695ab4b66f108b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2012.07396\",\"authors\":[{\"authorId\":\"122729444\",\"name\":\"K. Olaleye\"},{\"authorId\":\"2215469\",\"name\":\"B. Niekerk\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a91e0848168b14d02bb6dd3640867ca6e380569c\",\"title\":\"Towards localisation of keywords in speech using weak supervision\",\"url\":\"https://www.semanticscholar.org/paper/a91e0848168b14d02bb6dd3640867ca6e380569c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1704.04222\",\"authors\":[{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"46207379\",\"name\":\"Yu Zhang\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/INTERSPEECH.2017-349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c20dff792bc447fab730e05f5e997694b67a11e\",\"title\":\"Learning Latent Representations for Speech Generation and Transformation\",\"url\":\"https://www.semanticscholar.org/paper/4c20dff792bc447fab730e05f5e997694b67a11e\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"}],\"doi\":\"10.1109/TGRS.2019.2951636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a86714cb7ac711054244aeea51a55715e679ebb\",\"title\":\"Sound Active Attention Framework for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2a86714cb7ac711054244aeea51a55715e679ebb\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1907.04224\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"145306628\",\"name\":\"A. Ali\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/interspeech.2019-2599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"facccce4f8d059d6156cf3ce536786eb43016939\",\"title\":\"Analyzing Phonetic and Graphemic Representations in End-to-End Automatic Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/facccce4f8d059d6156cf3ce536786eb43016939\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47473876\",\"name\":\"Mingxin Zhang\"},{\"authorId\":\"49125925\",\"name\":\"T. Tanaka\"},{\"authorId\":\"32216189\",\"name\":\"Wenxin Hou\"},{\"authorId\":\"1657484873\",\"name\":\"Shengzhou Gao\"},{\"authorId\":\"49018339\",\"name\":\"T. Shinozaki\"}],\"doi\":\"10.21437/interspeech.2020-2027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed02595d039056765af09f13fc117a8d0656d173\",\"title\":\"Sound-Image Grounding Based Focusing Mechanism for Efficient Automatic Spoken Language Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/ed02595d039056765af09f13fc117a8d0656d173\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/TASLP.2018.2872106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e56c99e8a94d3e585166fcd66f2ab6da60932f09\",\"title\":\"Semantic Speech Retrieval With a Visually Grounded Model of Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/e56c99e8a94d3e585166fcd66f2ab6da60932f09\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2991962\",\"name\":\"Y. Ohishi\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/interspeech.2020-3078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68f6d0789f1f904f38c347f945a5c8232a5bb857\",\"title\":\"Pair Expansion for Learning Multilingual Semantic Embeddings Using Disjoint Visually-Grounded Speech Audio Datasets\",\"url\":\"https://www.semanticscholar.org/paper/68f6d0789f1f904f38c347f945a5c8232a5bb857\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/CVPR.2019.00947\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8abc9fc312fc6916725ec94816ab26c582cf1a90\",\"title\":\"Deep Multimodal Clustering for Unsupervised Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/8abc9fc312fc6916725ec94816ab26c582cf1a90\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2991962\",\"name\":\"Y. Ohishi\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053428\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f9acc521e5cf08a048b8473a5319882ef4d1b10\",\"title\":\"Trilingual Semantic Embeddings of Visually Grounded Speech with Self-Attention Mechanisms\",\"url\":\"https://www.semanticscholar.org/paper/8f9acc521e5cf08a048b8473a5319882ef4d1b10\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2807672\",\"name\":\"M. V. D. Laan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9cbded0bc138d7374b5e40be8bf05f43c2cbb4a3\",\"title\":\"Encoding of speaker identity in a Neural Network model of Visually Grounded Speech perception\",\"url\":\"https://www.semanticscholar.org/paper/9cbded0bc138d7374b5e40be8bf05f43c2cbb4a3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.15288\",\"authors\":[{\"authorId\":\"1522034508\",\"name\":\"Masood S. Mortazavi\"}],\"doi\":\"10.21437/Interspeech.2020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa1bf8450847ba5c4b79ca8dbfb362b4c2e766aa\",\"title\":\"Speech-Image Semantic Alignment Does Not Depend on Any Prior Classification Tasks\",\"url\":\"https://www.semanticscholar.org/paper/fa1bf8450847ba5c4b79ca8dbfb362b4c2e766aa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.04355\",\"authors\":[{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"36217631\",\"name\":\"J. Glass\"}],\"doi\":\"10.21437/interspeech.2019-1227\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b1d97b4b914dfc8df314e26e7454464a4dccc29\",\"title\":\"Transfer Learning from Audio-Visual Grounding to Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b1d97b4b914dfc8df314e26e7454464a4dccc29\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1711.01515\",\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"18833f315d7985337abddc2fc52ee24ab592a300\",\"title\":\"Learning Word Embeddings from Speech\",\"url\":\"https://www.semanticscholar.org/paper/18833f315d7985337abddc2fc52ee24ab592a300\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.00493\",\"authors\":[{\"authorId\":\"1411443431\",\"name\":\"Mohamed El-Geish\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e14f6b18d2b7d4e02b3f9d2426153c819f777a9\",\"title\":\"Learning Joint Acoustic-Phonetic Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/9e14f6b18d2b7d4e02b3f9d2426153c819f777a9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143753565\",\"name\":\"M. Mahmoud\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd4ee99109698fc445a240719c9c8d891dff11db\",\"title\":\"Learning Joint Audio-Phonetic Spelling Embeddings from Noisy Labels (Speech Recognition)\",\"url\":\"https://www.semanticscholar.org/paper/dd4ee99109698fc445a240719c9c8d891dff11db\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.09244\",\"authors\":[{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"}],\"doi\":\"10.18653/v1/P19-1647\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19463ba394386ade82e446674e7756b72178e8ae\",\"title\":\"Symbolic inductive bias for visually grounded learning of spoken language\",\"url\":\"https://www.semanticscholar.org/paper/19463ba394386ade82e446674e7756b72178e8ae\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1904.10947\",\"authors\":[{\"authorId\":\"30803019\",\"name\":\"A. Pasad\"},{\"authorId\":\"49340538\",\"name\":\"Bowen Shi\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.21437/interspeech.2019-3051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"441f16f3805f9cdf5cf1c8f3b429df5485a472d9\",\"title\":\"On the Contributions of Visual and Textual Supervision in Low-resource Semantic Speech Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/441f16f3805f9cdf5cf1c8f3b429df5485a472d9\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1710.01949\",\"authors\":[{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/TASLP.2018.2872106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"561f69917d109a20d630408718676b299c7de191\",\"title\":\"Semantic keyword spotting by learning from images and speech\",\"url\":\"https://www.semanticscholar.org/paper/561f69917d109a20d630408718676b299c7de191\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1706.03815\",\"authors\":[{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"},{\"authorId\":\"19178849\",\"name\":\"M. Barking\"},{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"}],\"doi\":\"10.18653/v1/K17-1037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d719664b18578445931e9aa3e70e3672c9898ac\",\"title\":\"Encoding of phonology in a recurrent neural model of grounded speech\",\"url\":\"https://www.semanticscholar.org/paper/0d719664b18578445931e9aa3e70e3672c9898ac\",\"venue\":\"CoNLL\",\"year\":2017},{\"arxivId\":\"1611.04496\",\"authors\":[{\"authorId\":\"7845441\",\"name\":\"Wanjia He\"},{\"authorId\":\"1702290\",\"name\":\"Weiran Wang\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e018afcc15257db6ed2cfd3beebd11d11d0e93f\",\"title\":\"Multi-view Recurrent Neural Acoustic Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/1e018afcc15257db6ed2cfd3beebd11d11d0e93f\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898103\",\"name\":\"J. Glass\"}],\"doi\":\"10.1007/s11263-019-01205-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/45070dd423a47f237d2c0bc7930579ecc4e4ad0a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46659335\",\"name\":\"Lihong Wang\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"}],\"doi\":\"10.1109/TASLP.2020.2996082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"094cae5ee5b84f6c89c1f597e4e8dc2334366597\",\"title\":\"Multimodal Word Discovery and Retrieval With Spoken Descriptions and Visual Concepts\",\"url\":\"https://www.semanticscholar.org/paper/094cae5ee5b84f6c89c1f597e4e8dc2334366597\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c43dfe8a834fce0467ba6a74b2daeebb5bb8b53\",\"title\":\"On internal language representations in deep learning: an analysis of machine translation and speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/0c43dfe8a834fce0467ba6a74b2daeebb5bb8b53\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46659335\",\"name\":\"Lihong Wang\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"}],\"doi\":\"10.21437/interspeech.2019-1487\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dba99c0ffd69a2a438ad4281a661c0133c646f55\",\"title\":\"Multimodal Word Discovery and Retrieval with Phone Sequence and Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/dba99c0ffd69a2a438ad4281a661c0133c646f55\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1902.03052\",\"authors\":[{\"authorId\":\"151459430\",\"name\":\"William N. Havard\"},{\"authorId\":\"5034292\",\"name\":\"Jean-Pierre Chevrot\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"}],\"doi\":\"10.1109/ICASSP.2019.8683069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25f8bfffe2066934f8e51d44c4f822a7647bc473\",\"title\":\"Models of Visually Grounded Speech Signal Pay Attention to Nouns: A Bilingual Experiment on English and Japanese\",\"url\":\"https://www.semanticscholar.org/paper/25f8bfffe2066934f8e51d44c4f822a7647bc473\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659094312\",\"name\":\"Venkat Krishnamohan\"},{\"authorId\":\"114317909\",\"name\":\"Akshara Soman\"},{\"authorId\":\"1483568345\",\"name\":\"A. Gupta\"},{\"authorId\":\"144113422\",\"name\":\"Sriram Ganapathy\"}],\"doi\":\"10.21437/interspeech.2020-2674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b2a2036de2f179dd9342c321865c6bbdcefbc13\",\"title\":\"Audiovisual Correspondence Learning in Humans and Machines\",\"url\":\"https://www.semanticscholar.org/paper/4b2a2036de2f179dd9342c321865c6bbdcefbc13\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"1702.01991\",\"authors\":[{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"},{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"103538973\",\"name\":\"Afra Alishahi\"}],\"doi\":\"10.18653/v1/P17-1057\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4e8117aed23e806fbe7a623a4ff915ef60e6bef\",\"title\":\"Representations of language in a model of visually grounded speech signal\",\"url\":\"https://www.semanticscholar.org/paper/d4e8117aed23e806fbe7a623a4ff915ef60e6bef\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1808.04108\",\"authors\":[{\"authorId\":\"35508795\",\"name\":\"Chia-Hung Wan\"},{\"authorId\":\"7146976\",\"name\":\"Shun-Po Chuang\"},{\"authorId\":\"144300094\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.1109/ICASSP.2019.8682383\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"908c342d66137f5e70544e8204951f28cb02deb0\",\"title\":\"Towards Audio to Scene Image Synthesis Using Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/908c342d66137f5e70544e8204951f28cb02deb0\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1803.08976\",\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.21437/Interspeech.2018-2341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083ec74cc10f96fbb64322ba23450666fd4df6cd\",\"title\":\"Speech2Vec: A Sequence-to-Sequence Framework for Learning Word Embeddings from Speech\",\"url\":\"https://www.semanticscholar.org/paper/083ec74cc10f96fbb64322ba23450666fd4df6cd\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":null,\"name\":\"Ziyin Liu\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d42ce9562a28079bac5b78db584bbdb9eaceba32\",\"title\":\"Modeling Spatiotemporal Multimodal Language with Recurrent Multistage Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d42ce9562a28079bac5b78db584bbdb9eaceba32\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.03413\",\"authors\":[{\"authorId\":\"1865748\",\"name\":\"Jiguo Li\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"3366824\",\"name\":\"Chuanmin Jia\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"48459110\",\"name\":\"Li Zhang\"},{\"authorId\":\"49417698\",\"name\":\"Y. Wang\"},{\"authorId\":\"14104497\",\"name\":\"Siwei Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/JSTSP.2020.2987417\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f127ef1ad0ca9d261bc40137fb7e84e6152410c\",\"title\":\"Direct Speech-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/1f127ef1ad0ca9d261bc40137fb7e84e6152410c\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1804.01452\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1007/978-3-030-01231-1_40\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"title\":\"Jointly Discovering Visual Objects and Spoken Words from Raw Sensory Input\",\"url\":\"https://www.semanticscholar.org/paper/7dcaf1ef07a593a987f3b529c2ad1e977c0c7196\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"3493789\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1007/978-3-030-31726-3_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fd9462b383033ac1e32964d9219a8636d98be18\",\"title\":\"Deep Voice-Visual Cross-Modal Retrieval with Deep Feature Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/6fd9462b383033ac1e32964d9219a8636d98be18\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1902.08213\",\"authors\":[{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2019.8682666\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b13f5e0d05f66aed6e8104b3be5c5ea853a415\",\"title\":\"Towards Visually Grounded Sub-word Speech Unit Discovery\",\"url\":\"https://www.semanticscholar.org/paper/99b13f5e0d05f66aed6e8104b3be5c5ea853a415\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1812.08951\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1162/tacl_a_00254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"668f42a4d4094f0a66d402a16087e14269b31a1f\",\"title\":\"Analysis Methods in Neural Language Processing: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/668f42a4d4094f0a66d402a16087e14269b31a1f\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2019},{\"arxivId\":\"1805.11264\",\"authors\":[{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2275ab31b4ea01ac6ac3a07855747213d1ed7d0f\",\"title\":\"Disentangling by Partitioning: A Representation Learning Framework for Multimodal Sensory Data\",\"url\":\"https://www.semanticscholar.org/paper/2275ab31b4ea01ac6ac3a07855747213d1ed7d0f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.03052\",\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"2213197\",\"name\":\"Galen Chuang\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2018.8462396\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f54d9dbad1f60de83485232707c945f209af867e\",\"title\":\"Vision as an Interlingua: Learning Multilingual Semantic Embeddings of Untranscribed Speech\",\"url\":\"https://www.semanticscholar.org/paper/f54d9dbad1f60de83485232707c945f209af867e\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"2012.15454\",\"authors\":[{\"authorId\":null,\"name\":\"Wei-Ning Hsu\"},{\"authorId\":null,\"name\":\"David Harwath\"},{\"authorId\":null,\"name\":\"Christopher Song\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"title\":\"Text-Free Image-to-Speech Synthesis Using Learned Segmental Units\",\"url\":\"https://www.semanticscholar.org/paper/5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"venue\":\"\",\"year\":2020}],\"corpusId\":10689140,\"doi\":\"10.18653/v1/P17-1047\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9140be329cd4ebbea8113087d65e68569b2f1269\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144366168\",\"name\":\"A. S. Park\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/TASL.2007.909282\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92b09fbf854caefdb465885b2ebd85d76331dcbf\",\"title\":\"Unsupervised Pattern Discovery in Speech\",\"url\":\"https://www.semanticscholar.org/paper/92b09fbf854caefdb465885b2ebd85d76331dcbf\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2727656\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f\",\"title\":\"Under Review as a Conference Paper at Iclr 2017 Delving into Transferable Adversarial Ex- Amples and Black-box Attacks\",\"url\":\"https://www.semanticscholar.org/paper/94e3e7bc3d23276f0ee2d1cb8f9d14aa19668d5f\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1412.6856\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"title\":\"Object Detectors Emerge in Deep Scene CNNs\",\"url\":\"https://www.semanticscholar.org/paper/9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1610.03342\",\"authors\":[{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"2756960\",\"name\":\"Grzegorz Chrupa\\u0142a\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c26deecb073c57f951a5492a3fd11094a79e865\",\"title\":\"From phonemes to images: levels of representation in a recurrent neural model of visually-grounded language learning\",\"url\":\"https://www.semanticscholar.org/paper/4c26deecb073c57f951a5492a3fd11094a79e865\",\"venue\":\"COLING\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurens van der Maaten\"},{\"authorId\":null,\"name\":\"Geoffrey Hinton.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing high-dimensional data using t-sne\",\"url\":\"\",\"venue\":\"Journal of Machine Learning Research.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145177145\",\"name\":\"M. Johnson\"}],\"doi\":\"10.3115/1626324.1626328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e012fd01693e7f7cddffbe132e0b50d04420447\",\"title\":\"Unsupervised Word Segmentation for Sesotho Using Adaptor Grammars\",\"url\":\"https://www.semanticscholar.org/paper/1e012fd01693e7f7cddffbe132e0b50d04420447\",\"venue\":\"SIGMORPHON\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Paul Lewis\"},{\"authorId\":null,\"name\":\"Gary F. Simon\"},{\"authorId\":null,\"name\":\"Charles D. Fennig.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ethnologue: Languages of the World, Nineteenth edition\",\"url\":\"\",\"venue\":\"SIL International. Online version: http://www.ethnologue.com.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Laurens Van Der Maaten\"},{\"authorId\":null,\"name\":\"Geoffrey Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing high-dimensional data using t-sne\",\"url\":\"\",\"venue\":\"In Journal of Machine Learning Research\",\"year\":2008},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1503.00949\",\"authors\":[{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2016.2535231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05e71b05ed2c4766ed4a080cb0411be7291b717b\",\"title\":\"Weakly Supervised Object Localization with Multi-Fold Multiple Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/05e71b05ed2c4766ed4a080cb0411be7291b717b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1991315\",\"name\":\"S. Goldwater\"},{\"authorId\":\"1799860\",\"name\":\"T. Griffiths\"},{\"authorId\":\"113136778\",\"name\":\"Mark I. Johnson\"}],\"doi\":\"10.1016/j.cognition.2009.03.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f31f9069bb934498a288126053bcab01ff34aa\",\"title\":\"A Bayesian framework for word segmentation: Exploring the effects of context\",\"url\":\"https://www.semanticscholar.org/paper/46f31f9069bb934498a288126053bcab01ff34aa\",\"venue\":\"Cognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2467151\",\"name\":\"John S. Garofolo\"},{\"authorId\":\"145204681\",\"name\":\"L. Lamel\"},{\"authorId\":\"144982775\",\"name\":\"W. Fisher\"},{\"authorId\":\"3241934\",\"name\":\"J. Fiscus\"},{\"authorId\":\"1786370\",\"name\":\"D. Pallett\"},{\"authorId\":\"35669756\",\"name\":\"Nancy L. Dahlgren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47128bb3ce4ed00691c0d7d58c02791c3e963ab7\",\"title\":\"Darpa Timit Acoustic-Phonetic Continuous Speech Corpus CD-ROM {TIMIT} | NIST\",\"url\":\"https://www.semanticscholar.org/paper/47128bb3ce4ed00691c0d7d58c02791c3e963ab7\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144615231\",\"name\":\"C. Lopes\"},{\"authorId\":\"145247471\",\"name\":\"F. Perdigao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3911933c247f705b2488fdd067330820e8db07bf\",\"title\":\"TIMIT Acoustic-Phonetic Continuous Speech Corpus\",\"url\":\"https://www.semanticscholar.org/paper/3911933c247f705b2488fdd067330820e8db07bf\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782853\",\"name\":\"Mark Dredze\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"4366352\",\"name\":\"Glen Coppersmith\"},{\"authorId\":\"32695442\",\"name\":\"Ken Ward Church\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54936542e492318db8f0b726090ceace02448df2\",\"title\":\"NLP on Spoken Documents Without ASR\",\"url\":\"https://www.semanticscholar.org/paper/54936542e492318db8f0b726090ceace02448df2\",\"venue\":\"EMNLP\",\"year\":2010},{\"arxivId\":\"1409.3964\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"145041406\",\"name\":\"A. Bergamo\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/WACV.2016.7477688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd2f443fc18947d2c9ecb81192b3f0a9cd2cf3f1\",\"title\":\"Self-taught object localization with deep networks\",\"url\":\"https://www.semanticscholar.org/paper/bd2f443fc18947d2c9ecb81192b3f0a9cd2cf3f1\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890490\",\"name\":\"Yaodong Zhang\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ASRU.2009.5372931\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ba6e777ea70a90ff780e329a603ed14fe5a63a7\",\"title\":\"Unsupervised spoken keyword spotting via segmental DTW on Gaussian posteriorgrams\",\"url\":\"https://www.semanticscholar.org/paper/2ba6e777ea70a90ff780e329a603ed14fe5a63a7\",\"venue\":\"2009 IEEE Workshop on Automatic Speech Recognition & Understanding\",\"year\":2009},{\"arxivId\":\"1501.06170\",\"authors\":[{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"}],\"doi\":\"10.1109/CVPR.2015.7298724\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"988c8578178fa263c2524d85292072c6a13a6121\",\"title\":\"Unsupervised object discovery and localization in the wild: Part-based matching with bottom-up region proposals\",\"url\":\"https://www.semanticscholar.org/paper/988c8578178fa263c2524d85292072c6a13a6121\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"John Garofolo\"},{\"authorId\":null,\"name\":\"Lori Lamel\"},{\"authorId\":null,\"name\":\"William Fisher\"},{\"authorId\":null,\"name\":\"Jonathan Fiscus\"},{\"authorId\":null,\"name\":\"David Pallet\"},{\"authorId\":null,\"name\":\"Nancy Dahlgren\"},{\"authorId\":null,\"name\":\"Victor Zue\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The TIMIT acoustic-phonetic continuous speech\",\"url\":\"\",\"venue\":\"\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2010.5540112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6eb3a15108dfdec25b46522ed94b866aeb156de9\",\"title\":\"Connecting modalities: Semi-supervised segmentation and annotation of images using unaligned text corpora\",\"url\":\"https://www.semanticscholar.org/paper/6eb3a15108dfdec25b46522ed94b866aeb156de9\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33498578\",\"name\":\"Chia-ying Lee\"},{\"authorId\":\"11030219\",\"name\":\"Timothy J. O'Donnell\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1162/tacl_a_00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aca94a780d3994839663ff743d3319d920db9297\",\"title\":\"Unsupervised Lexicon Discovery from Acoustic Input\",\"url\":\"https://www.semanticscholar.org/paper/aca94a780d3994839663ff743d3319d920db9297\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Daniel Povey\"},{\"authorId\":null,\"name\":\"Arnab Ghoshal\"},{\"authorId\":null,\"name\":\"Gilles Boulianne\"},{\"authorId\":null,\"name\":\"Lukas Burget\"},{\"authorId\":null,\"name\":\"Ondrej Glembek\"},{\"authorId\":null,\"name\":\"Nagendra Goel\"},{\"authorId\":null,\"name\":\"Mirko Hannemann\"},{\"authorId\":null,\"name\":\"Petr Motlicek\"},{\"authorId\":null,\"name\":\"Yanmin Qian\"},{\"authorId\":null,\"name\":\"Petr Schwarz\"},{\"authorId\":null,\"name\":\"Jan Silovsky\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Georg Stemmer, and Karel Vesely. The Kaldi speech recognition toolkit\",\"url\":\"\",\"venue\":\"IEEE 2011 Workshop on Automatic Speech Recognition and Understanding\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"2268620\",\"name\":\"A. Ghoshal\"},{\"authorId\":\"2541218\",\"name\":\"Gilles Boulianne\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"3075141\",\"name\":\"O. Glembek\"},{\"authorId\":\"46356878\",\"name\":\"N. Goel\"},{\"authorId\":\"2592983\",\"name\":\"M. Hannemann\"},{\"authorId\":\"2745667\",\"name\":\"Petr Motl\\u00edcek\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"35455336\",\"name\":\"P. Schwarz\"},{\"authorId\":\"3330139\",\"name\":\"J. Silovsk\\u00fd\"},{\"authorId\":\"1708033\",\"name\":\"G. Stemmer\"},{\"authorId\":\"2459598\",\"name\":\"K. Vesel\\u00fd\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a1a2cff2b70fb84a7ca7d97f8adcc5855851795\",\"title\":\"The Kaldi Speech Recognition Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/3a1a2cff2b70fb84a7ca7d97f8adcc5855851795\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Paul Lewis\"},{\"authorId\":null,\"name\":\"Gary F Simon\"},{\"authorId\":null,\"name\":\"Charles D Fennig\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Ethnologue: Languages of the World, Nineteenth edition. SIL International. Online version\",\"url\":\"\",\"venue\":\"Ethnologue: Languages of the World, Nineteenth edition. SIL International. Online version\",\"year\":2016},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721801\",\"name\":\"C. Fellbaum\"}],\"doi\":\"10.2307/417141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d87ceda3042f781c341ac17109d1e94a717f5f60\",\"title\":\"WordNet : an electronic lexical database\",\"url\":\"https://www.semanticscholar.org/paper/d87ceda3042f781c341ac17109d1e94a717f5f60\",\"venue\":\"\",\"year\":2000},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2167829\",\"name\":\"Lucas Ondel\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"1899242\",\"name\":\"J. \\u010cernock\\u00fd\"}],\"doi\":\"10.1016/j.procs.2016.04.033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d22d3e10f833ff75c688061ea2aa8ad0a0ae854\",\"title\":\"Variational Inference for Acoustic Unit Discovery\",\"url\":\"https://www.semanticscholar.org/paper/2d22d3e10f833ff75c688061ea2aa8ad0a0ae854\",\"venue\":\"SLTU\",\"year\":2016},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"1798550\",\"name\":\"Timothy J. Hazen\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2013.6639335\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2873aec019565daaa8fe98e16df0913754c67b1a\",\"title\":\"Zero resource spoken audio corpus analysis\",\"url\":\"https://www.semanticscholar.org/paper/2873aec019565daaa8fe98e16df0913754c67b1a\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"7536576\",\"name\":\"Benjamin Van Durme\"}],\"doi\":\"10.1109/ASRU.2011.6163965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5561d01b9cc08bac589bccdfc2f68019c58f36e7\",\"title\":\"Efficient spoken term discovery using randomized algorithms\",\"url\":\"https://www.semanticscholar.org/paper/5561d01b9cc08bac589bccdfc2f68019c58f36e7\",\"venue\":\"2011 IEEE Workshop on Automatic Speech Recognition & Understanding\",\"year\":2011},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33498578\",\"name\":\"Chia-ying Lee\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"749ecf7147e861c60c2feba6f65a2e2b81f30905\",\"title\":\"A Nonparametric Bayesian Approach to Acoustic Model Discovery\",\"url\":\"https://www.semanticscholar.org/paper/749ecf7147e861c60c2feba6f65a2e2b81f30905\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"title\":\"Unsupervised Learning of Spoken Language with Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/87697847062e7eefec99a8c3aec888e3eef5e5b9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"2244184\",\"name\":\"Kenneth Ward Church\"},{\"authorId\":\"1738798\",\"name\":\"H. Hermansky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a29bbb30bf72cfc7ac52a351a04a1178e29dd7f\",\"title\":\"Towards spoken term discovery at scale with zero resources\",\"url\":\"https://www.semanticscholar.org/paper/7a29bbb30bf72cfc7ac52a351a04a1178e29dd7f\",\"venue\":\"INTERSPEECH\",\"year\":2010},{\"arxivId\":\"1511.03690\",\"authors\":[{\"authorId\":\"1895488\",\"name\":\"David F. Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ASRU.2015.7404800\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a39aae161cc0787ac6dff3a27a6bd5b199f050a\",\"title\":\"Deep multimodal semantic embeddings for speech and images\",\"url\":\"https://www.semanticscholar.org/paper/5a39aae161cc0787ac6dff3a27a6bd5b199f050a\",\"venue\":\"2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145364504\",\"name\":\"D. Roy\"}],\"doi\":\"10.1109/TMM.2003.811618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bf150d806a2b68c22e7f6cf55cc62175c60f850\",\"title\":\"Grounded spoken language acquisition: experiments in word learning\",\"url\":\"https://www.semanticscholar.org/paper/1bf150d806a2b68c22e7f6cf55cc62175c60f850\",\"venue\":\"IEEE Trans. Multim.\",\"year\":2003}],\"title\":\"Learning Word-Like Units from Joint Audio-Visual Analysis\",\"topics\":[{\"topic\":\"Speech recognition\",\"topicId\":\"2869\",\"url\":\"https://www.semanticscholar.org/topic/2869\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Generative model\",\"topicId\":\"37177\",\"url\":\"https://www.semanticscholar.org/topic/37177\"},{\"topic\":\"Skyscraper\",\"topicId\":\"676111\",\"url\":\"https://www.semanticscholar.org/topic/676111\"},{\"topic\":\"Waterfall model\",\"topicId\":\"140294\",\"url\":\"https://www.semanticscholar.org/topic/140294\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"The Wall Street Journal\",\"topicId\":\"100679\",\"url\":\"https://www.semanticscholar.org/topic/100679\"}],\"url\":\"https://www.semanticscholar.org/paper/9140be329cd4ebbea8113087d65e68569b2f1269\",\"venue\":\"ACL\",\"year\":2017}\n"