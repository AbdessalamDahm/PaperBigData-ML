"{\"abstract\":\"End-to-end automatic speech recognition (ASR) has become a popular alternative to conventional DNN/HMM systems because it avoids the need for linguistic resources such as pronunciation dictionary, tokenization, and context-dependency trees, leading to a greatly simplified model-building process. There are two major types of end-to-end architectures for ASR: attention-based methods use an attention mechanism to perform alignment between acoustic frames and recognized symbols, and connectionist temporal classification (CTC), uses Markov assumptions to efficiently solve sequential problems by dynamic programming. This paper proposes joint decoding algorithm for end-to-end ASR with a hybrid CTC/attention architecture, which effectively utilizes both advantages in decoding. We have applied the proposed method to two ASR benchmarks (spontaneous Japanese and Mandarin Chinese), and showing the comparable performance to conventional state-of-the-art DNN/HMM ASR systems without linguistic resources.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145443186\",\"name\":\"T. Hori\",\"url\":\"https://www.semanticscholar.org/author/145443186\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\",\"url\":\"https://www.semanticscholar.org/author/1746678\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\",\"url\":\"https://www.semanticscholar.org/author/2387467\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"48252309\",\"name\":\"Jian Tang\"},{\"authorId\":\"2635200\",\"name\":\"Junfeng Hou\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"153634883\",\"name\":\"Li-Rong Dai\"},{\"authorId\":\"143656282\",\"name\":\"I. Mcloughlin\"}],\"doi\":\"10.1109/ACCESS.2020.3001636\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f446e27ce288b0611f4b5f35dd6fdab0e8fac75\",\"title\":\"Effective Exploitation of Posterior Information for Attention-Based Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f446e27ce288b0611f4b5f35dd6fdab0e8fac75\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787226\",\"name\":\"Gakuto Kurata\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"}],\"doi\":\"10.1109/SLT.2018.8639629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a07e356708ea72a13e0c8cd0a1fe6cd63dd2485\",\"title\":\"Improved Knowledge Distillation from Bi-Directional to Uni-Directional LSTM CTC for End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7a07e356708ea72a13e0c8cd0a1fe6cd63dd2485\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122380771\",\"name\":\"Chu-Xiong Qin\"},{\"authorId\":\"144554014\",\"name\":\"D. Qu\"},{\"authorId\":\"48571079\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1186/S13636-018-0141-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d3c01c6cb7f911de8029e1c42cdd534bf235473\",\"title\":\"Towards end-to-end speech recognition with transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/7d3c01c6cb7f911de8029e1c42cdd534bf235473\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2018},{\"arxivId\":\"2010.13270\",\"authors\":[{\"authorId\":\"46722767\",\"name\":\"Yosuke Higuchi\"},{\"authorId\":\"49276525\",\"name\":\"Hirofumi Inaguma\"},{\"authorId\":\"1826565368\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"3279652\",\"name\":\"T. Ogawa\"},{\"authorId\":\"1709528\",\"name\":\"T. Kobayashi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fbf70de414a0258011cbba8ee1d0c123d944563\",\"title\":\"Improved Mask-CTC for Non-Autoregressive End-to-End ASR\",\"url\":\"https://www.semanticscholar.org/paper/9fbf70de414a0258011cbba8ee1d0c123d944563\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49661716\",\"name\":\"T. Hori\"},{\"authorId\":\"72995245\",\"name\":\"N. Moritz\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":\"10.21437/interspeech.2020-2928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35570b8c9a79ec53540d48ea5a700232d99ed154\",\"title\":\"Transformer-Based Long-Context End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/35570b8c9a79ec53540d48ea5a700232d99ed154\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122380771\",\"name\":\"Chu-Xiong Qin\"},{\"authorId\":\"144554014\",\"name\":\"D. Qu\"}],\"doi\":\"10.1109/ACCESS.2020.2970758\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6c50b1e72a69229a18624bee76c53187f56ff6a\",\"title\":\"Towards Understanding Attention-Based Speech Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/b6c50b1e72a69229a18624bee76c53187f56ff6a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390725481\",\"name\":\"Wangyou Zhang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"}],\"doi\":\"10.21437/interspeech.2020-2015\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e4047639948c4676861585c302431e41998a96e\",\"title\":\"Learning Contextual Language Embeddings for Monaural Multi-Talker Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e4047639948c4676861585c302431e41998a96e\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35685246\",\"name\":\"Haoran Miao\"},{\"authorId\":\"32607116\",\"name\":\"Gaofeng Cheng\"},{\"authorId\":\"48754077\",\"name\":\"P. Zhang\"},{\"authorId\":\"144905986\",\"name\":\"T. Li\"},{\"authorId\":\"145244226\",\"name\":\"Y. Yan\"}],\"doi\":\"10.21437/interspeech.2019-2018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f39f8275ac2dffdfec9c8fb0ea26b5eaeda0bd7\",\"title\":\"Online Hybrid CTC/Attention Architecture for End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f39f8275ac2dffdfec9c8fb0ea26b5eaeda0bd7\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122380771\",\"name\":\"Chu-Xiong Qin\"},{\"authorId\":\"1726544\",\"name\":\"Wenlin Zhang\"},{\"authorId\":\"2964499\",\"name\":\"Dan Qu\"}],\"doi\":\"10.1186/s13636-019-0161-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4013cc18f320f652035187ca1a8860eff3b7fd77\",\"title\":\"A new joint CTC-attention-based speech recognition model with multi-level multi-head attention\",\"url\":\"https://www.semanticscholar.org/paper/4013cc18f320f652035187ca1a8860eff3b7fd77\",\"venue\":\"EURASIP J. Audio Speech Music. Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390725481\",\"name\":\"Wangyou Zhang\"},{\"authorId\":\"8776560\",\"name\":\"Xuankai Chang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"}],\"doi\":\"10.21437/interspeech.2019-3192\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bdfafbfaedb757f0d661b21cb9168ed9f01eeab9\",\"title\":\"Knowledge Distillation for End-to-End Monaural Multi-Talker ASR System\",\"url\":\"https://www.semanticscholar.org/paper/bdfafbfaedb757f0d661b21cb9168ed9f01eeab9\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9083623\",\"name\":\"Y. Zhao\"},{\"authorId\":\"153798668\",\"name\":\"Jianjian Yue\"},{\"authorId\":\"122136032\",\"name\":\"Xiao-na Xu\"},{\"authorId\":\"50789847\",\"name\":\"Licheng Wu\"},{\"authorId\":\"3477441\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2952406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9650d995b5f599abc15ca5627e70d5816e55371d\",\"title\":\"End-to-End-Based Tibetan Multitask Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9650d995b5f599abc15ca5627e70d5816e55371d\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"title\":\"Iterative Alignment Network for Continuous Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1804.09298\",\"authors\":[{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"1686573\",\"name\":\"Jinyu Li\"}],\"doi\":\"10.1109/JAS.2017.7510508\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"921fc3028478f4cd92e26c5b74ceee38dc40a614\",\"title\":\"Recent progresses in deep learning based acoustic models\",\"url\":\"https://www.semanticscholar.org/paper/921fc3028478f4cd92e26c5b74ceee38dc40a614\",\"venue\":\"IEEE/CAA Journal of Automatica Sinica\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390725481\",\"name\":\"Wangyou Zhang\"},{\"authorId\":\"8776560\",\"name\":\"Xuankai Chang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/TASLP.2020.2988423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87eece8d39d1e25ba87550be8b01af32738cbf2c\",\"title\":\"Improving End-to-End Single-Channel Multi-Talker Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/87eece8d39d1e25ba87550be8b01af32738cbf2c\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"2001.08290\",\"authors\":[{\"authorId\":\"35685246\",\"name\":\"Haoran Miao\"},{\"authorId\":\"32607116\",\"name\":\"Gaofeng Cheng\"},{\"authorId\":\"1435773025\",\"name\":\"C. Gao\"},{\"authorId\":\"48754077\",\"name\":\"P. Zhang\"},{\"authorId\":\"144338840\",\"name\":\"Yonghong Yan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053165\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0eebb3426080fe2d68dc198be445d36c6f8b1d72\",\"title\":\"Transformer-Based Online CTC/Attention End-To-End Speech Recognition Architecture\",\"url\":\"https://www.semanticscholar.org/paper/0eebb3426080fe2d68dc198be445d36c6f8b1d72\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1910.00254\",\"authors\":[{\"authorId\":\"49276525\",\"name\":\"Hirofumi Inaguma\"},{\"authorId\":\"1800354\",\"name\":\"Kevin Duh\"},{\"authorId\":\"1717105\",\"name\":\"Tatsuya Kawahara\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ASRU46091.2019.9003832\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b231737e0048a400527d89aa56c712e8b9bc690\",\"title\":\"Multilingual End-to-End Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/8b231737e0048a400527d89aa56c712e8b9bc690\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":\"1711.02212\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"1727524\",\"name\":\"Michael L. Seltzer\"},{\"authorId\":\"145364697\",\"name\":\"J. Li\"},{\"authorId\":\"143624101\",\"name\":\"R. Zhao\"}],\"doi\":\"10.21437/Interspeech.2018-2517\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"906561eb7c0637aa108d447ac973c0ecad01ab23\",\"title\":\"Improved training for online end-to-end speech recognition systems\",\"url\":\"https://www.semanticscholar.org/paper/906561eb7c0637aa108d447ac973c0ecad01ab23\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443186\",\"name\":\"Takaaki Hori\"},{\"authorId\":\"2387467\",\"name\":\"John R. Hershey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47fd5950f64b62655b560ebd051918444b9abb1c\",\"title\":\"Language Independent End-to-End Architecture For Joint Language and Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47fd5950f64b62655b560ebd051918444b9abb1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145183069\",\"name\":\"H. Seki\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"72995245\",\"name\":\"N. Moritz\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":\"10.21437/interspeech.2019-2860\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b20cadef0c59e80f7dfdf825b07442619d920fd5\",\"title\":\"Vectorized Beam Search for CTC-Attention-Based Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b20cadef0c59e80f7dfdf825b07442619d920fd5\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1903.05261\",\"authors\":[{\"authorId\":\"48081355\",\"name\":\"Yangyang Shi\"},{\"authorId\":\"144091892\",\"name\":\"M. Hwang\"},{\"authorId\":\"143722633\",\"name\":\"Xin Lei\"}],\"doi\":\"10.1109/ICASSP.2019.8683297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9cbfdb1040bb5c397ded23e3256a13ce5bae676\",\"title\":\"End-to-end Speech Recognition Using a High Rank LSTM-CTC Based Model\",\"url\":\"https://www.semanticscholar.org/paper/f9cbfdb1040bb5c397ded23e3256a13ce5bae676\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"3326124\",\"name\":\"T. Hayashi\"}],\"doi\":\"10.1109/JSTSP.2017.2763455\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8fcd012e8ed2ea8190163369c9f222178e70a19d\",\"title\":\"Hybrid CTC/Attention Architecture for End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8fcd012e8ed2ea8190163369c9f222178e70a19d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40059964\",\"name\":\"Shane Settle\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.1109/ICASSP.2018.8461893\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2225950d1d3e02bc0d88a0c78325d00e0122b576\",\"title\":\"End-to-End Multi-Speaker Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2225950d1d3e02bc0d88a0c78325d00e0122b576\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1910.06522\",\"authors\":[{\"authorId\":\"8776560\",\"name\":\"Xuankai Chang\"},{\"authorId\":\"1390725481\",\"name\":\"Wangyou Zhang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ASRU46091.2019.9003986\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94f8ef5944ecbdd0350d406bf3a16a7f2dff7349\",\"title\":\"MIMO-Speech: End-to-End Multi-Channel Multi-Speaker Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94f8ef5944ecbdd0350d406bf3a16a7f2dff7349\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468634\",\"name\":\"Michal Zapotoczny\"},{\"authorId\":\"2319572\",\"name\":\"P. Pietrzak\"},{\"authorId\":\"2398498\",\"name\":\"Adrian Lancucki\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"}],\"doi\":\"10.21437/interspeech.2019-2667\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ded3d23b5b5a9264fe5e67d07ce217f0adf9765\",\"title\":\"Lattice Generation in Attention-Based Speech Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/1ded3d23b5b5a9264fe5e67d07ce217f0adf9765\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"2003.04710\",\"authors\":[{\"authorId\":\"1567419135\",\"name\":\"N. AmirgaliyevE.\"},{\"authorId\":\"1567410304\",\"name\":\"N. KuanyshbayD.\"},{\"authorId\":\"68974962\",\"name\":\"O. Baimuratov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a943e08db1ee82cbc8209ba34f472d3c5ff880e\",\"title\":\"Development of Automatic Speech Recognition for Kazakh Language using Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/6a943e08db1ee82cbc8209ba34f472d3c5ff880e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.04988\",\"authors\":[{\"authorId\":\"143885335\",\"name\":\"Kai Xu\"},{\"authorId\":\"49620929\",\"name\":\"Dawei Li\"},{\"authorId\":\"48289425\",\"name\":\"N. Cassimatis\"},{\"authorId\":\"1709719\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1109/FG.2018.00088\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dfa043929dbf123438cbbc1648b0d2252010f34a\",\"title\":\"LCANet: End-to-End Lipreading with Cascaded Attention-CTC\",\"url\":\"https://www.semanticscholar.org/paper/dfa043929dbf123438cbbc1648b0d2252010f34a\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2019.00429\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"714df3e97817ec56b8dbc7217155adadf2a0487f\",\"title\":\"Iterative Alignment Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/714df3e97817ec56b8dbc7217155adadf2a0487f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.02062\",\"authors\":[{\"authorId\":\"8776560\",\"name\":\"Xuankai Chang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"1736727\",\"name\":\"Kai Yu\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ICASSP.2019.8682822\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"649eb9fd9a18f9601270b7fcde8d6548bfc6ec75\",\"title\":\"End-to-end Monaural Multi-speaker ASR System without Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/649eb9fd9a18f9601270b7fcde8d6548bfc6ec75\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.08311\",\"authors\":[{\"authorId\":\"1787226\",\"name\":\"Gakuto Kurata\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"}],\"doi\":\"10.21437/interspeech.2019-1952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfc99c47296ee1f958f5860d07587bf190a9cfb\",\"title\":\"Guiding CTC Posterior Spike Timings for Improved Posterior Fusion and Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/cbfc99c47296ee1f958f5860d07587bf190a9cfb\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"2005.08700\",\"authors\":[{\"authorId\":\"46722767\",\"name\":\"Yosuke Higuchi\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"34507928\",\"name\":\"Nanxin Chen\"},{\"authorId\":\"3279652\",\"name\":\"T. Ogawa\"},{\"authorId\":\"1709528\",\"name\":\"T. Kobayashi\"}],\"doi\":\"10.21437/interspeech.2020-2404\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5378c72f6f0791753681be30258dffcd67c1ec66\",\"title\":\"Mask CTC: Non-Autoregressive End-to-End ASR with CTC and Mask Predict\",\"url\":\"https://www.semanticscholar.org/paper/5378c72f6f0791753681be30258dffcd67c1ec66\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410474143\",\"name\":\"Juan M. Perero-Codosero\"},{\"authorId\":\"1411355579\",\"name\":\"Javier Ant\\u00f3n-Mart\\u00edn\"},{\"authorId\":\"9122205\",\"name\":\"D. Merino\"},{\"authorId\":\"2494375\",\"name\":\"E. Gonzalo\"},{\"authorId\":\"143741766\",\"name\":\"L. G\\u00f3mez\"}],\"doi\":\"10.21437/IBERSPEECH.2018-55\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d23acec5f43aa3648db8c61f72598be0a141e2f8\",\"title\":\"Exploring Open-Source Deep Learning ASR for Speech-to-Text TV program transcription\",\"url\":\"https://www.semanticscholar.org/paper/d23acec5f43aa3648db8c61f72598be0a141e2f8\",\"venue\":\"IberSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153798668\",\"name\":\"Jianjian Yue\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e4280a43b1f4e74c6ffdf1d6a415bc7f26427fb0\",\"title\":\"ATTENTION-BASED WAVENET-CTC FOR TIBETAN MULTI-DIALECT MULTITASK SPEECH RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/e4280a43b1f4e74c6ffdf1d6a415bc7f26427fb0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.08041\",\"authors\":[{\"authorId\":\"2879849\",\"name\":\"Ruizhi Li\"},{\"authorId\":\"50142326\",\"name\":\"X. Wang\"},{\"authorId\":\"144921407\",\"name\":\"Sri Harish Mallidi\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1738798\",\"name\":\"H. Hermansky\"}],\"doi\":\"10.1109/TASLP.2019.2959721\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84f2cfbc142ad3165ea3bcacd189a3d1110660e0\",\"title\":\"Multi-Stream End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/84f2cfbc142ad3165ea3bcacd189a3d1110660e0\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"2011.12461\",\"authors\":[{\"authorId\":\"40343368\",\"name\":\"W. Wang\"},{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"3253648\",\"name\":\"X. Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a28e5985afd80abaa95b2ba1fe08667a6cfb1227\",\"title\":\"SAR-Net: A End-to-End Deep Speech Accent Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/a28e5985afd80abaa95b2ba1fe08667a6cfb1227\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.05826\",\"authors\":[{\"authorId\":\"49166310\",\"name\":\"Hiroshi Seki\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.18653/v1/P18-1244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3400b8bf1ffde3ef3d35dfcea893e6506427aa21\",\"title\":\"A Purely End-to-end System for Multi-speaker Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3400b8bf1ffde3ef3d35dfcea893e6506427aa21\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2011.01210\",\"authors\":[{\"authorId\":\"34507928\",\"name\":\"Nanxin Chen\"},{\"authorId\":\"1826689833\",\"name\":\"Piotr Zelasko\"},{\"authorId\":\"120678702\",\"name\":\"Jes\\u00fas Villalba\"},{\"authorId\":\"3135554\",\"name\":\"Najim Dehak\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f90f383a3f027bfa48fea68790d3cb77f7634b92\",\"title\":\"Focus on the present: a regularization method for the ASR source-target attention layer\",\"url\":\"https://www.semanticscholar.org/paper/f90f383a3f027bfa48fea68790d3cb77f7634b92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720992134\",\"name\":\"Haoran Miao\"},{\"authorId\":\"1724178858\",\"name\":\"G. Cheng\"},{\"authorId\":\"48754077\",\"name\":\"P. Zhang\"},{\"authorId\":\"145244226\",\"name\":\"Y. Yan\"}],\"doi\":\"10.1109/TASLP.2020.2987752\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7707159f86719591a1c3a1489605b3e241b80e6d\",\"title\":\"Online Hybrid CTC/Attention End-to-End Automatic Speech Recognition Architecture\",\"url\":\"https://www.semanticscholar.org/paper/7707159f86719591a1c3a1489605b3e241b80e6d\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49276525\",\"name\":\"Hirofumi Inaguma\"},{\"authorId\":\"1800354\",\"name\":\"Kevin Duh\"},{\"authorId\":\"1717105\",\"name\":\"Tatsuya Kawahara\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ffecb8b8b415149f5351b64a2dbb1a1fa64219f0\",\"title\":\"C L ] 1 O ct 2 01 9 MULTILINGUAL END-TO-END SPEECH TRANSLATION\",\"url\":\"https://www.semanticscholar.org/paper/ffecb8b8b415149f5351b64a2dbb1a1fa64219f0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.1109/ASRU.2017.8268948\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1a20480e4168d58deec743035b7ff02720672d7\",\"title\":\"Multi-level language modeling and decoding for open vocabulary end-to-end speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1a20480e4168d58deec743035b7ff02720672d7\",\"venue\":\"2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2017},{\"arxivId\":\"1808.02608\",\"authors\":[{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"7519814\",\"name\":\"J. Cho\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/SLT.2018.8639693\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"790eb7e93f1d3fce470c0222fd2be83bab55a428\",\"title\":\"End-to-end Speech Recognition With Word-Based Rnn Language Models\",\"url\":\"https://www.semanticscholar.org/paper/790eb7e93f1d3fce470c0222fd2be83bab55a428\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787226\",\"name\":\"Gakuto Kurata\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"}],\"doi\":\"10.21437/interspeech.2019-1710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8e3658a4940df5528bda0d3aaa4ad8650184be9\",\"title\":\"Multi-Task CTC Training with Auxiliary Feature Reconstruction for End-to-End Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8e3658a4940df5528bda0d3aaa4ad8650184be9\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1810.13091\",\"authors\":[{\"authorId\":\"51455843\",\"name\":\"Ne Luo\"},{\"authorId\":\"46197764\",\"name\":\"D. Jiang\"},{\"authorId\":\"46250834\",\"name\":\"Shuaijiang Zhao\"},{\"authorId\":\"1990550\",\"name\":\"C. Gong\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"852310f5135d7978a435a7851d977f382ac45bd4\",\"title\":\"Towards End-to-End Code-Switching Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/852310f5135d7978a435a7851d977f382ac45bd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":\"10.1109/ASRU.2017.8268945\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f256b31d446015d8cd0f9f3996009cdf2034c5e\",\"title\":\"Language independent end-to-end architecture for joint language identification and speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/3f256b31d446015d8cd0f9f3996009cdf2034c5e\",\"venue\":\"2017 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2017},{\"arxivId\":\"2011.13439\",\"authors\":[{\"authorId\":\"40570741\",\"name\":\"Sameer Khurana\"},{\"authorId\":\"72995245\",\"name\":\"N. Moritz\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6543be2428dcdb29027c312bf6301b06f77b03cc\",\"title\":\"Unsupervised Domain Adaptation for Speech Recognition via Uncertainty Driven Self-Training\",\"url\":\"https://www.semanticscholar.org/paper/6543be2428dcdb29027c312bf6301b06f77b03cc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.01690\",\"authors\":[{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"3394760\",\"name\":\"Ram\\u00f3n Fern\\u00e1ndez Astudillo\"},{\"authorId\":\"3326124\",\"name\":\"T. Hayashi\"},{\"authorId\":\"39076047\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"}],\"doi\":\"10.1109/ICASSP.2019.8683307\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c6407554fb4ee599f42501cf5cba8fcefa88783\",\"title\":\"Cycle-consistency Training for End-to-end Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c6407554fb4ee599f42501cf5cba8fcefa88783\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672888\",\"name\":\"Chia-Yu Li\"},{\"authorId\":\"2428703\",\"name\":\"Ngoc Thang Vu\"}],\"doi\":\"10.1109/IALP48816.2019.9037688\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f96cc501fce8d896c09fb5350a695dac46976b4\",\"title\":\"Integrating Knowledge in End-to-End Automatic Speech Recognition for Mandarin-English Code-Switching\",\"url\":\"https://www.semanticscholar.org/paper/4f96cc501fce8d896c09fb5350a695dac46976b4\",\"venue\":\"2019 International Conference on Asian Language Processing (IALP)\",\"year\":2019},{\"arxivId\":\"2011.11671\",\"authors\":[{\"authorId\":\"4413385\",\"name\":\"I. Sklyar\"},{\"authorId\":\"1396766299\",\"name\":\"A. Piunova\"},{\"authorId\":\"2027163265\",\"name\":\"Yulan Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7ea99e376425f4f2a08fed86c54b5b54efff7ad\",\"title\":\"Streaming Multi-speaker ASR with RNN-T\",\"url\":\"https://www.semanticscholar.org/paper/a7ea99e376425f4f2a08fed86c54b5b54efff7ad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452682\",\"name\":\"Peidong Wang\"},{\"authorId\":\"118005076\",\"name\":\"J. Cui\"},{\"authorId\":\"145350701\",\"name\":\"Chao Weng\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"}],\"doi\":\"10.1109/ICASSP.2019.8683302\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd563451e15704bb650067bde25edbe8603dc853\",\"title\":\"Token-wise Training for Attention Based End-to-end Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd563451e15704bb650067bde25edbe8603dc853\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019}],\"corpusId\":2133607,\"doi\":\"10.18653/v1/P17-1048\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"4cd66273298128dfb5be290e891870085ecfc455\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3117618\",\"name\":\"Seiya Tokui\"},{\"authorId\":\"1812144\",\"name\":\"Kenta Oono\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67156902beca9bc90b728c8d5dd4ac9d8b27d3a3\",\"title\":\"Chainer : a Next-Generation Open Source Framework for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/67156902beca9bc90b728c8d5dd4ac9d8b27d3a3\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1610.09975\",\"authors\":[{\"authorId\":\"38940652\",\"name\":\"H. Soltau\"},{\"authorId\":\"39977619\",\"name\":\"H. Liao\"},{\"authorId\":\"2670103\",\"name\":\"H. Sak\"}],\"doi\":\"10.21437/INTERSPEECH.2017-1566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1cb867270f87f96397cb5f0d76cbb58cdf2c2f2\",\"title\":\"Neural Speech Recognizer: Acoustic-to-Word LSTM Model for Large Vocabulary Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1cb867270f87f96397cb5f0d76cbb58cdf2c2f2\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"41207043\",\"name\":\"L. Deng\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"35188630\",\"name\":\"G. Dahl\"},{\"authorId\":\"40360972\",\"name\":\"Abdel-rahman Mohamed\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"40133958\",\"name\":\"Patrick Nguyen\"},{\"authorId\":\"1784851\",\"name\":\"T. Sainath\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"}],\"doi\":\"10.1109/MSP.2012.2205597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31868290adf1c000c611dfc966b514d5a34e8d23\",\"title\":\"Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups\",\"url\":\"https://www.semanticscholar.org/paper/31868290adf1c000c611dfc966b514d5a34e8d23\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2012},{\"arxivId\":\"1211.5063\",\"authors\":[{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84069287da0a6b488b8c933f3cb5be759cb6237e\",\"title\":\"On the difficulty of training recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/84069287da0a6b488b8c933f3cb5be759cb6237e\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":\"1612.02695\",\"authors\":[{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":\"10.21437/INTERSPEECH.2017-343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7dbb2d983ab95da04e5d47c87ddd2cd9a8f20786\",\"title\":\"Towards Better Decoding and Language Model Integration in Sequence to Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/7dbb2d983ab95da04e5d47c87ddd2cd9a8f20786\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1508.04395\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"2616163\",\"name\":\"Philemon Brakel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.1109/ICASSP.2016.7472618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"878ba5458e9e51f0b341fd9117fa0b43ef4096d3\",\"title\":\"End-to-end attention-based large vocabulary speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/878ba5458e9e51f0b341fd9117fa0b43ef4096d3\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"cs/0205028\",\"authors\":[{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"}],\"doi\":\"10.3115/1225403.1225421\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01a660ec8aa995a88a00bfb41cb86c022047a9db\",\"title\":\"NLTK: The Natural Language Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/01a660ec8aa995a88a00bfb41cb86c022047a9db\",\"venue\":\"ACL\",\"year\":2006},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1609.08144\",\"authors\":[{\"authorId\":\"1780996\",\"name\":\"Y. Wu\"},{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144739074\",\"name\":\"Mohammad Norouzi\"},{\"authorId\":\"3153147\",\"name\":\"Wolfgang Macherey\"},{\"authorId\":\"2048712\",\"name\":\"M. Krikun\"},{\"authorId\":\"145144022\",\"name\":\"Yuan Cao\"},{\"authorId\":\"145312182\",\"name\":\"Q. Gao\"},{\"authorId\":\"113439369\",\"name\":\"Klaus Macherey\"},{\"authorId\":\"2367620\",\"name\":\"Jeff Klingner\"},{\"authorId\":\"145825976\",\"name\":\"Apurva Shah\"},{\"authorId\":\"145657834\",\"name\":\"M. Johnson\"},{\"authorId\":\"2600217\",\"name\":\"X. Liu\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"2776283\",\"name\":\"S. Gouws\"},{\"authorId\":\"2739610\",\"name\":\"Y. Kato\"},{\"authorId\":\"1765329\",\"name\":\"Taku Kudo\"},{\"authorId\":\"1754386\",\"name\":\"H. Kazawa\"},{\"authorId\":\"144077726\",\"name\":\"K. Stevens\"},{\"authorId\":\"35066890\",\"name\":\"G. Kurian\"},{\"authorId\":\"35173708\",\"name\":\"Nishant Patil\"},{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"39660914\",\"name\":\"C. Young\"},{\"authorId\":\"27070552\",\"name\":\"J. Smith\"},{\"authorId\":\"2909504\",\"name\":\"Jason Riesa\"},{\"authorId\":\"29951847\",\"name\":\"Alex Rudnick\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"48342565\",\"name\":\"Macduff Hughes\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbde7dfa6cae81df8ac19ef500c42db96c3d1edd\",\"title\":\"Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/dbde7dfa6cae81df8ac19ef500c42db96c3d1edd\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49421935\",\"name\":\"Y. Liu\"},{\"authorId\":\"1683412\",\"name\":\"Pascale Fung\"},{\"authorId\":\"46286114\",\"name\":\"Y. Yang\"},{\"authorId\":\"2147401\",\"name\":\"C. Cieri\"},{\"authorId\":\"2712233\",\"name\":\"S. Huang\"},{\"authorId\":\"113818670\",\"name\":\"David Graff\"}],\"doi\":\"10.1007/11939993_73\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2740ebd37a35ecf6f7d713558308eeb28311961\",\"title\":\"HKUST/MTS: A Very Large Scale Mandarin Telephone Speech Corpus\",\"url\":\"https://www.semanticscholar.org/paper/d2740ebd37a35ecf6f7d713558308eeb28311961\",\"venue\":\"ISCSLP\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"143913738\",\"name\":\"S. Fern\\u00e1ndez\"},{\"authorId\":\"145842938\",\"name\":\"F. Gomez\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1145/1143844.1143891\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96494e722f58705fa20302fe6179d483f52705b4\",\"title\":\"Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/96494e722f58705fa20302fe6179d483f52705b4\",\"venue\":\"ICML '06\",\"year\":2006},{\"arxivId\":\"1609.06773\",\"authors\":[{\"authorId\":\"2678842\",\"name\":\"Suyoun Kim\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1746678\",\"name\":\"Shinji Watanabe\"}],\"doi\":\"10.1109/ICASSP.2017.7953075\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9af2264799bdc3490e4650e2f5d126762caf420f\",\"title\":\"Joint CTC-attention based end-to-end speech recognition using multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/9af2264799bdc3490e4650e2f5d126762caf420f\",\"venue\":\"2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"1939851\",\"name\":\"Mohammad Gowayyed\"},{\"authorId\":\"2519438\",\"name\":\"X. Na\"},{\"authorId\":\"3023507\",\"name\":\"T. Ko\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.1109/ICASSP.2016.7472152\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d155d64bdd86edf33f4395c5aec0388ffed69f99\",\"title\":\"An empirical exploration of CTC acoustic models\",\"url\":\"https://www.semanticscholar.org/paper/d155d64bdd86edf33f4395c5aec0388ffed69f99\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1212.5701\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8729441d734782c3ed532a7d2d9611b438c0a09a\",\"title\":\"ADADELTA: An Adaptive Learning Rate Method\",\"url\":\"https://www.semanticscholar.org/paper/8729441d734782c3ed532a7d2d9611b438c0a09a\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1412.1602\",\"authors\":[{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"47d2dc34e1d02a8109f5c04bb6939725de23716d\",\"title\":\"End-to-end Continuous Speech Recognition using Attention-based Recurrent NN: First Results\",\"url\":\"https://www.semanticscholar.org/paper/47d2dc34e1d02a8109f5c04bb6939725de23716d\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1506.07503\",\"authors\":[{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b624504240fa52ab76167acfe3156150ca01cf3b\",\"title\":\"Attention-Based Models for Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b624504240fa52ab76167acfe3156150ca01cf3b\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765329\",\"name\":\"Taku Kudo\"},{\"authorId\":\"48522505\",\"name\":\"Kaoru Yamamoto\"},{\"authorId\":\"1681502\",\"name\":\"Y. Matsumoto\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f16410d241616553ae6e63fcf4ba8959eda58aea\",\"title\":\"Applying Conditional Random Fields to Japanese Morphological Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f16410d241616553ae6e63fcf4ba8959eda58aea\",\"venue\":\"EMNLP\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1833359\",\"name\":\"N. Kanda\"},{\"authorId\":\"1711321\",\"name\":\"X. Lu\"},{\"authorId\":\"1805595\",\"name\":\"H. Kawai\"}],\"doi\":\"10.21437/Interspeech.2016-71\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"721fa4f0dd8a6d4f9d07bd8167ebd68aa68f8d0e\",\"title\":\"Maximum a posteriori Based Decoding for CTC Acoustic Models\",\"url\":\"https://www.semanticscholar.org/paper/721fa4f0dd8a6d4f9d07bd8167ebd68aa68f8d0e\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912546\",\"name\":\"K. Maekawa\"},{\"authorId\":\"35246876\",\"name\":\"H. Koiso\"},{\"authorId\":\"1699205\",\"name\":\"S. Furui\"},{\"authorId\":\"1714134\",\"name\":\"H. Isahara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac23e62a18186c9a51dfea16d3602f52ff8c3b3a\",\"title\":\"Spontaneous Speech Corpus of Japanese\",\"url\":\"https://www.semanticscholar.org/paper/ac23e62a18186c9a51dfea16d3602f52ff8c3b3a\",\"venue\":\"LREC\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145705748\",\"name\":\"L. Lu\"},{\"authorId\":\"37409910\",\"name\":\"Xingxing Zhang\"},{\"authorId\":\"145086187\",\"name\":\"S. Renals\"}],\"doi\":\"10.1109/ICASSP.2016.7472641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77854e1a86835065b77b7b15ffabb34f3853f4a2\",\"title\":\"On training the recurrent neural network encoder-decoder for large vocabulary end-to-end speech recognition\",\"url\":\"https://www.semanticscholar.org/paper/77854e1a86835065b77b7b15ffabb34f3853f4a2\",\"venue\":\"2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2016},{\"arxivId\":\"1507.08240\",\"authors\":[{\"authorId\":\"37467623\",\"name\":\"Y. Miao\"},{\"authorId\":\"1939851\",\"name\":\"Mohammad Gowayyed\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/ASRU.2015.7404790\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"97acdfb3d247f8250d865ef8a9169f06e40f138b\",\"title\":\"EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding\",\"url\":\"https://www.semanticscholar.org/paper/97acdfb3d247f8250d865ef8a9169f06e40f138b\",\"venue\":\"2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"2946873\",\"name\":\"Vijayaditya Peddinti\"},{\"authorId\":\"143943881\",\"name\":\"D. Galvez\"},{\"authorId\":\"2835722\",\"name\":\"Pegah Ghahremani\"},{\"authorId\":\"3316615\",\"name\":\"Vimal Manohar\"},{\"authorId\":\"2519438\",\"name\":\"X. Na\"},{\"authorId\":\"21595671\",\"name\":\"Y. Wang\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.21437/Interspeech.2016-595\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ce6a9a30cd69bd2842a4b581cf48c6815bdfdd8\",\"title\":\"Purely Sequence-Trained Neural Networks for ASR Based on Lattice-Free MMI\",\"url\":\"https://www.semanticscholar.org/paper/6ce6a9a30cd69bd2842a4b581cf48c6815bdfdd8\",\"venue\":\"INTERSPEECH\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733733\",\"name\":\"H. Bourlard\"},{\"authorId\":\"144798098\",\"name\":\"N. Morgan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d82e058a5c40954b8f5db170a298a889a254c37\",\"title\":\"Connectionist Speech Recognition: A Hybrid Approach\",\"url\":\"https://www.semanticscholar.org/paper/3d82e058a5c40954b8f5db170a298a889a254c37\",\"venue\":\"\",\"year\":1993},{\"arxivId\":\"1512.02595\",\"authors\":[{\"authorId\":\"2698777\",\"name\":\"Dario Amodei\"},{\"authorId\":\"39436202\",\"name\":\"S. Ananthanarayanan\"},{\"authorId\":\"2432216\",\"name\":\"Rishita Anubhai\"},{\"authorId\":\"47236125\",\"name\":\"J. Bai\"},{\"authorId\":\"5697774\",\"name\":\"Eric Battenberg\"},{\"authorId\":\"145353944\",\"name\":\"C. Case\"},{\"authorId\":\"48991386\",\"name\":\"J. Casper\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"47740218\",\"name\":\"Jingdong Chen\"},{\"authorId\":\"35977287\",\"name\":\"M. Chrzanowski\"},{\"authorId\":\"144638694\",\"name\":\"A. Coates\"},{\"authorId\":\"2322582\",\"name\":\"Greg Diamos\"},{\"authorId\":\"152585800\",\"name\":\"E. Elsen\"},{\"authorId\":\"9695761\",\"name\":\"J. Engel\"},{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"2910729\",\"name\":\"Christopher Fougner\"},{\"authorId\":\"2893056\",\"name\":\"Awni Y. Hannun\"},{\"authorId\":\"34601942\",\"name\":\"Billy Jun\"},{\"authorId\":\"3041255\",\"name\":\"Tony Han\"},{\"authorId\":\"3081566\",\"name\":\"P. LeGresley\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"},{\"authorId\":\"113530808\",\"name\":\"Libby Lin\"},{\"authorId\":\"46617804\",\"name\":\"Sharan Narang\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"3168041\",\"name\":\"Ryan Prenger\"},{\"authorId\":\"144416975\",\"name\":\"S. Qian\"},{\"authorId\":\"34042420\",\"name\":\"Jonathan Raiman\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"2100685\",\"name\":\"David Seetapun\"},{\"authorId\":\"2264597\",\"name\":\"S. Sengupta\"},{\"authorId\":\"8401284\",\"name\":\"Anuroop Sriram\"},{\"authorId\":\"47074522\",\"name\":\"C. Wang\"},{\"authorId\":\"46393411\",\"name\":\"Yi Wang\"},{\"authorId\":\"50219267\",\"name\":\"Zhiqian Wang\"},{\"authorId\":\"144912001\",\"name\":\"B. Xiao\"},{\"authorId\":\"143669548\",\"name\":\"Y. Xie\"},{\"authorId\":\"1755465\",\"name\":\"Dani Yogatama\"},{\"authorId\":\"145141776\",\"name\":\"Jun Zhan\"},{\"authorId\":\"2042558\",\"name\":\"Zhenyao Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ff840a40d3f1557c55c19d4d636da77103168ce\",\"title\":\"Deep Speech 2 : End-to-End Speech Recognition in English and Mandarin\",\"url\":\"https://www.semanticscholar.org/paper/8ff840a40d3f1557c55c19d4d636da77103168ce\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f\",\"title\":\"Towards End-To-End Speech Recognition with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0fa553cfa0cf3cbdf7a913aa2ae789a757dfb32f\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702849\",\"name\":\"N. Xue\"}],\"doi\":\"10.30019/IJCLCLP.200302.0002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f6c28b20458f7f7de0989c2f8296d67162610f2\",\"title\":\"Chinese Word Segmentation as Character Tagging\",\"url\":\"https://www.semanticscholar.org/paper/9f6c28b20458f7f7de0989c2f8296d67162610f2\",\"venue\":\"ROCLING/IJCLCLP\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792214\",\"name\":\"D. Povey\"},{\"authorId\":\"2268620\",\"name\":\"A. Ghoshal\"},{\"authorId\":\"2541218\",\"name\":\"Gilles Boulianne\"},{\"authorId\":\"1816892\",\"name\":\"L. Burget\"},{\"authorId\":\"3075141\",\"name\":\"O. Glembek\"},{\"authorId\":\"46356878\",\"name\":\"N. Goel\"},{\"authorId\":\"2592983\",\"name\":\"M. Hannemann\"},{\"authorId\":\"2745667\",\"name\":\"Petr Motl\\u00edcek\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"},{\"authorId\":\"35455336\",\"name\":\"P. Schwarz\"},{\"authorId\":\"3330139\",\"name\":\"J. Silovsk\\u00fd\"},{\"authorId\":\"1708033\",\"name\":\"G. Stemmer\"},{\"authorId\":\"2459598\",\"name\":\"K. Vesel\\u00fd\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a1a2cff2b70fb84a7ca7d97f8adcc5855851795\",\"title\":\"The Kaldi Speech Recognition Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/3a1a2cff2b70fb84a7ca7d97f8adcc5855851795\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2472759\",\"name\":\"F. Jelinek\"}],\"doi\":\"10.1109/PROC.1976.10159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32a175b36ec7f2f08cb3dfac30ce141e144ec9e9\",\"title\":\"Continuous speech recognition by statistical methods\",\"url\":\"https://www.semanticscholar.org/paper/32a175b36ec7f2f08cb3dfac30ce141e144ec9e9\",\"venue\":\"Proceedings of the IEEE\",\"year\":1976},{\"arxivId\":\"1508.01211\",\"authors\":[{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc555e8156c956f823587ebbff018863e6d2a95e\",\"title\":\"Listen, Attend and Spell\",\"url\":\"https://www.semanticscholar.org/paper/dc555e8156c956f823587ebbff018863e6d2a95e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":\"10.1007/978-3-642-24797-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a97b5db17acc731ef67321832dbbaf5766153135\",\"title\":\"Supervised Sequence Labelling with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a97b5db17acc731ef67321832dbbaf5766153135\",\"venue\":\"Studies in Computational Intelligence\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Takafumi Moriya\"},{\"authorId\":null,\"name\":\"Takahiro Shinozaki\"},{\"authorId\":null,\"name\":\"Shinji Watanabe.\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Kaldi recipe for Japanese spontaneous speech recognition and its evaluation\",\"url\":\"\",\"venue\":\"Autumn Meeting of ASJ. 3-Q-7.\",\"year\":2015}],\"title\":\"Joint CTC/attention decoding for end-to-end speech recognition\",\"topics\":[{\"topic\":\"Speech recognition\",\"topicId\":\"2869\",\"url\":\"https://www.semanticscholar.org/topic/2869\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Dynamic programming\",\"topicId\":\"10893\",\"url\":\"https://www.semanticscholar.org/topic/10893\"},{\"topic\":\"Broadway (microprocessor)\",\"topicId\":\"44552\",\"url\":\"https://www.semanticscholar.org/topic/44552\"},{\"topic\":\"Hidden Markov model\",\"topicId\":\"11239\",\"url\":\"https://www.semanticscholar.org/topic/11239\"},{\"topic\":\"Connectionism\",\"topicId\":\"11245\",\"url\":\"https://www.semanticscholar.org/topic/11245\"},{\"topic\":\"Acknowledgment index\",\"topicId\":\"4975706\",\"url\":\"https://www.semanticscholar.org/topic/4975706\"},{\"topic\":\"Tokenization (data security)\",\"topicId\":\"34443\",\"url\":\"https://www.semanticscholar.org/topic/34443\"},{\"topic\":\"Spontaneous order\",\"topicId\":\"1457732\",\"url\":\"https://www.semanticscholar.org/topic/1457732\"},{\"topic\":\"Dictionary\",\"topicId\":\"2618\",\"url\":\"https://www.semanticscholar.org/topic/2618\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Super Robot Monkey Team Hyperforce Go!\",\"topicId\":\"11585\",\"url\":\"https://www.semanticscholar.org/topic/11585\"},{\"topic\":\"Digital Monster (virtual pet)\",\"topicId\":\"768511\",\"url\":\"https://www.semanticscholar.org/topic/768511\"},{\"topic\":\"Computational linguistics\",\"topicId\":\"26807\",\"url\":\"https://www.semanticscholar.org/topic/26807\"},{\"topic\":\"Markov chain\",\"topicId\":\"5418\",\"url\":\"https://www.semanticscholar.org/topic/5418\"},{\"topic\":\"Acoustic cryptanalysis\",\"topicId\":\"1017215\",\"url\":\"https://www.semanticscholar.org/topic/1017215\"},{\"topic\":\"Automated system recovery\",\"topicId\":\"2686392\",\"url\":\"https://www.semanticscholar.org/topic/2686392\"}],\"url\":\"https://www.semanticscholar.org/paper/4cd66273298128dfb5be290e891870085ecfc455\",\"venue\":\"ACL\",\"year\":2017}\n"