"{\"abstract\":\"Despite the remarkable progress in action recognition over the past several years, existing methods remain limited in efficiency and effectiveness. The methods treating appearance and motion as separate streams are usually subject to the cost of optical flow computation, while those relying on 3D convolution on the original video frames often yield inferior performance in practice. In this paper, we propose a new ConvNet architecture for video representation learning, which can derive disentangled components of dynamics purely from raw video frames, without the need of optical flow estimation. Particularly, the learned representation comprises three components for representing static appearance, apparent motion, and appearance changes. We introduce 3D pooling, cost volume processing, and warped feature differences, respectively for extracting the three components above. These modules are incorporated as three branches in our unified network, which share the underlying features and are learned jointly in an end-to-end manner. On two large datasets, UCF101 [22] and Kinetics [16], our method obtained competitive performances with high efficiency, using only the RGB frame sequence as input.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\",\"url\":\"https://www.semanticscholar.org/author/47827957\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\",\"url\":\"https://www.semanticscholar.org/author/3331521\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\",\"url\":\"https://www.semanticscholar.org/author/1807606\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"50589377\",\"name\":\"L. Wei\"},{\"authorId\":\"145441561\",\"name\":\"W. Cui\"},{\"authorId\":\"2992926\",\"name\":\"Ziyu Hu\"},{\"authorId\":\"152162359\",\"name\":\"Hao Sun\"},{\"authorId\":\"73638359\",\"name\":\"Shijie Hou\"}],\"doi\":\"10.1007/s00371-019-01787-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5473e8cb7e4a272f4da7fe913ad25ea866c230dc\",\"title\":\"A single-shot multi-level feature reused neural network for object detection\",\"url\":\"https://www.semanticscholar.org/paper/5473e8cb7e4a272f4da7fe913ad25ea866c230dc\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2010.11594\",\"authors\":[{\"authorId\":\"3191371\",\"name\":\"Yuanhao Zhai\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2914452\",\"name\":\"W. Tang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-58539-6_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"title\":\"Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2018.2882805\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02c293bc06c580305c8b62a8ed90f37a75608493\",\"title\":\"Adversarial Action Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/02c293bc06c580305c8b62a8ed90f37a75608493\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2009.05757\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"152978186\",\"name\":\"Xiao-wei Guo\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfff32dd150ee568384d60708622e2a3917fd6cf\",\"title\":\"Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion\",\"url\":\"https://www.semanticscholar.org/paper/cfff32dd150ee568384d60708622e2a3917fd6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.03442\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/WACV45572.2020.9093368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afafc4077d9ead2260c6ab12293ada21ee889747\",\"title\":\"Spatio-Temporal Pyramid Graph Convolutions for Human Action Recognition and Postural Assessment\",\"url\":\"https://www.semanticscholar.org/paper/afafc4077d9ead2260c6ab12293ada21ee889747\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.04608\",\"authors\":[{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58517-4_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6e3034cd8855616533d091dc1d70e969c20a42b\",\"title\":\"Actions as Moving Points\",\"url\":\"https://www.semanticscholar.org/paper/e6e3034cd8855616533d091dc1d70e969c20a42b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020}],\"corpusId\":49522444,\"doi\":\"10.1109/CVPR.2018.00687\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":2,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144429686\",\"name\":\"J. Davis\"}],\"doi\":\"10.1109/EVENT.2001.938864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c28a379c5fea508b69a154a5bfc0356d7879b139\",\"title\":\"Hierarchical motion history images for recognizing human motion\",\"url\":\"https://www.semanticscholar.org/paper/c28a379c5fea508b69a154a5bfc0356d7879b139\",\"venue\":\"Proceedings IEEE Workshop on Detection and Recognition of Events in Video\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1501.02565\",\"authors\":[{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2015.7298720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"title\":\"EpicFlow: Edge-preserving interpolation of correspondences for optical flow\",\"url\":\"https://www.semanticscholar.org/paper/f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1801.07455\",\"authors\":[{\"authorId\":\"1979911\",\"name\":\"S. Yan\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"title\":\"Spatial Temporal Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efeaa6e3114d6d6ae5c3041b66ac9a9ae9bf52bf\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1704.07325\",\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"2774325\",\"name\":\"Ren\\u00e9 Ranftl\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/CVPR.2017.615\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"143e10cae07f27f2db9de171eb04a332ddbfeab4\",\"title\":\"Accurate Optical Flow via Direct Cost Volume Processing\",\"url\":\"https://www.semanticscholar.org/paper/143e10cae07f27f2db9de171eb04a332ddbfeab4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1604.06182\",\"authors\":[{\"authorId\":\"1803711\",\"name\":\"H. Idrees\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40633675\",\"name\":\"Alex Gorban\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1016/j.cviu.2016.10.018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c57a070724b48962935ff46ab1384d919e1d1089\",\"title\":\"The THUMOS challenge on action recognition for videos \\\"in the wild\\\"\",\"url\":\"https://www.semanticscholar.org/paper/c57a070724b48962935ff46ab1384d919e1d1089\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1703.03329\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.678\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"title\":\"UntrimmedNets for Weakly Supervised Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/61d0125cd9f5aba4aef3e1db911f77be67a4e8c8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2181441\",\"name\":\"M. Zhao\"},{\"authorId\":\"3928052\",\"name\":\"T. Li\"},{\"authorId\":\"34714099\",\"name\":\"Mohammad Abu Alsheikh\"},{\"authorId\":\"2476765\",\"name\":\"Yonglong Tian\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1109/CVPR.2018.00768\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e42b2981f4e8de54213d624d1ef12bad4fe02f0a\",\"title\":\"Through-Wall Human Pose Estimation Using Radio Signals\",\"url\":\"https://www.semanticscholar.org/paper/e42b2981f4e8de54213d624d1ef12bad4fe02f0a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2598904\",\"name\":\"Christian Bailer\"},{\"authorId\":\"2847305\",\"name\":\"Bertram Taetz\"},{\"authorId\":\"143749919\",\"name\":\"D. Stricker\"}],\"doi\":\"10.1109/ICCV.2015.457\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8371a6a7ff5f3bf0dcdda4742bfe8edfc5e9054\",\"title\":\"Flow Fields: Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/e8371a6a7ff5f3bf0dcdda4742bfe8edfc5e9054\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013}],\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"topics\":[{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Performance\",\"topicId\":\"3097\",\"url\":\"https://www.semanticscholar.org/topic/3097\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Uncompressed video\",\"topicId\":\"649403\",\"url\":\"https://www.semanticscholar.org/topic/649403\"},{\"topic\":\"Big data\",\"topicId\":\"20355\",\"url\":\"https://www.semanticscholar.org/topic/20355\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Lambda lifting\",\"topicId\":\"170468\",\"url\":\"https://www.semanticscholar.org/topic/170468\"},{\"topic\":\"Kinesiology\",\"topicId\":\"113188\",\"url\":\"https://www.semanticscholar.org/topic/113188\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"}],\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"