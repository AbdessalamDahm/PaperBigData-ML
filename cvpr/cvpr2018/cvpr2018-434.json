"{\"abstract\":\"We investigate the problem of object referring (OR) i.e. to localize a target object in a visual scene coming with a language description. Humans perceive the world more as continued video snippets than as static images, and describe objects not only by their appearance, but also by their spatio-temporal context and motion features. Humans also gaze at the object when they issue a referring expression. Existing works for OR mostly focus on static images only, which fall short in providing many such cues. This paper addresses OR in videos with language and human gaze. To that end, we present a new video dataset for OR, with 30, 000 objects over 5, 000 stereo video sequences annotated for their descriptions and gaze. We further propose a novel network model for OR in videos, by integrating appearance, motion, gaze, and spatio-temporal context into one network. Experimental results show that our method effectively utilizes motion cues, human gaze, and spatio-temporal context. Our method outperforms previous OR methods. For dataset and code, please refer https://people.ee.ethz.ch/~arunv/ORGaze.html.\",\"arxivId\":\"1801.01582\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\",\"url\":\"https://www.semanticscholar.org/author/2326243\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\",\"url\":\"https://www.semanticscholar.org/author/1778526\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\",\"url\":\"https://www.semanticscholar.org/author/1681236\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba7890a5e9e51bf6181cc3c03144796cb3e5e254\",\"title\":\"Query : \\\" A man in a red sweatshirt performing breakdance \\\"\",\"url\":\"https://www.semanticscholar.org/paper/ba7890a5e9e51bf6181cc3c03144796cb3e5e254\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.13120\",\"authors\":[{\"authorId\":\"20466488\",\"name\":\"Seonwook Park\"},{\"authorId\":\"2773227\",\"name\":\"E. Aksan\"},{\"authorId\":\"2520795\",\"name\":\"Xucong Zhang\"},{\"authorId\":\"1466533438\",\"name\":\"O. Hilliges\"}],\"doi\":\"10.1007/978-3-030-58610-2_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f23e1db2bf2abc69f6790641fab0caf9fa532ad\",\"title\":\"Towards End-to-end Video-based Eye-Tracking\",\"url\":\"https://www.semanticscholar.org/paper/1f23e1db2bf2abc69f6790641fab0caf9fa532ad\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.02549\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/P19-1183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"title\":\"Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1910.02029\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-020-01374-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.08814\",\"authors\":[{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"72347323\",\"name\":\"X. Yang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-030-58539-6_27\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"13ee363f71e07112210ac2ff27d46625f6f8edab\",\"title\":\"Visual Relation Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/13ee363f71e07112210ac2ff27d46625f6f8edab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1803.08006\",\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-20870-7_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da30d00c9490768e7726725482e3ecbd102f18cd\",\"title\":\"Video Object Segmentation with Language Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/da30d00c9490768e7726725482e3ecbd102f18cd\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"152599661\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2019.00589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"949959250e487617faa3035b05b52aa03a8e9895\",\"title\":\"Generating Easy-to-Understand Referring Expressions for Target Identifications\",\"url\":\"https://www.semanticscholar.org/paper/949959250e487617faa3035b05b52aa03a8e9895\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.08792\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"83754395\",\"name\":\"Simon Vandenhende\"},{\"authorId\":\"1388019229\",\"name\":\"Dusan Grujicic\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1758219\",\"name\":\"Matthew B. Blaschko\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a43ed50d4ae027cfd29ab3fdbb731f8439c49c5\",\"title\":\"Commands 4 Autonomous Vehicles (C4AV) Workshop Summary\",\"url\":\"https://www.semanticscholar.org/paper/9a43ed50d4ae027cfd29ab3fdbb731f8439c49c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26879574\",\"name\":\"Hosnieh Sattar\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1016/j.neucom.2020.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38ecd6e9d1806197b7fd7a9250d7e26203681753\",\"title\":\"Deep gaze pooling: Inferring and visually decoding search intents from human gaze fixations\",\"url\":\"https://www.semanticscholar.org/paper/38ecd6e9d1806197b7fd7a9250d7e26203681753\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2459642\",\"name\":\"P. Vaidyanathan\"},{\"authorId\":\"1401154472\",\"name\":\"Emily Tucker Prud'hommeaux\"},{\"authorId\":\"2899726\",\"name\":\"J. Pelz\"},{\"authorId\":\"144648940\",\"name\":\"Cecilia Ovesdotter Alm\"}],\"doi\":\"10.18653/v1/P18-2022\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fdbebb4972ecf12f1b736bd4fb0cf0223e8217e\",\"title\":\"SNAG: Spoken Narratives and Gaze Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8fdbebb4972ecf12f1b736bd4fb0cf0223e8217e\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1811.12104\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"143973868\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"title\":\"Towards Human-Friendly Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1820939478\",\"name\":\"Preethi Vaidyanathan\"},{\"authorId\":\"113057658\",\"name\":\"Emily Prudhommeaux\"},{\"authorId\":\"144648940\",\"name\":\"Cecilia Ovesdotter Alm\"},{\"authorId\":\"2899726\",\"name\":\"J. Pelz\"}],\"doi\":\"10.1167/jov.20.7.13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"36f47de2c0d8c8fa6d18423030d31e426586997c\",\"title\":\"Computational framework for fusing eye movements and spoken narratives for image annotation\",\"url\":\"https://www.semanticscholar.org/paper/36f47de2c0d8c8fa6d18423030d31e426586997c\",\"venue\":\"Journal of vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000438408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53e77b526587b3c3bf7bb359590692a081b53260\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/53e77b526587b3c3bf7bb359590692a081b53260\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339038\",\"name\":\"Nisha Pillai\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2674440\",\"name\":\"Cynthia Matuszek\"}],\"doi\":\"10.13016/M2NNGG-XN9E\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eb80c4d556c604d5d48c52b9eb0fb04e93130e3\",\"title\":\"Deep Learning for Category-Free Grounded Language Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/4eb80c4d556c604d5d48c52b9eb0fb04e93130e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500658106\",\"name\":\"Osamu Segawa\"},{\"authorId\":\"3326124\",\"name\":\"T. Hayashi\"},{\"authorId\":\"1709999\",\"name\":\"K. Takeda\"}],\"doi\":\"10.1109/ASRU46091.2019.9004030\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c326425e263d8ef905b1f6af67c93d7911dd7f5\",\"title\":\"Attention-Based Speech Recognition Using Gaze Information\",\"url\":\"https://www.semanticscholar.org/paper/6c326425e263d8ef905b1f6af67c93d7911dd7f5\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation in Cities\",\"url\":\"https://www.semanticscholar.org/paper/392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.10995\",\"authors\":[{\"authorId\":\"3351638\",\"name\":\"S. Hecker\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc3910b65df6f78fe36ed24604679a399485eff0\",\"title\":\"Learning Accurate, Comfortable and Human-like Driving\",\"url\":\"https://www.semanticscholar.org/paper/bc3910b65df6f78fe36ed24604679a399485eff0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"41175924\",\"name\":\"Srinjoy Majumdar\"},{\"authorId\":\"32775309\",\"name\":\"Elaine Schaertl Short\"},{\"authorId\":\"1682788\",\"name\":\"A. Thomaz\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"}],\"doi\":\"10.1109/IROS.2018.8593580\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"295c3be3e603b3349d23f8733c3c3eb1744b103c\",\"title\":\"Human Gaze Following for Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/295c3be3e603b3349d23f8733c3c3eb1744b103c\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"2011.04592\",\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"2752573\",\"name\":\"Lisa Beinborn\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b\",\"title\":\"Generating Image Descriptions via Sequential Cross-Modal Alignment Guided by Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/306ec4956aa2bb4e29a0b5c8b52d1c0e6007a32b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1909.10838\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"83754395\",\"name\":\"Simon Vandenhende\"},{\"authorId\":\"1388019229\",\"name\":\"Dusan Grujicic\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.18653/v1/D19-1215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ac1603c0ad5268b202506bb2cddbfe10c45d9f\",\"title\":\"Talk2Car: Taking Control of Your Self-Driving Car\",\"url\":\"https://www.semanticscholar.org/paper/61ac1603c0ad5268b202506bb2cddbfe10c45d9f\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1908.01189\",\"authors\":[{\"authorId\":\"1387996941\",\"name\":\"Hazan Anayurt\"},{\"authorId\":\"1387996951\",\"name\":\"Sezai Artun Ozyegin\"},{\"authorId\":\"1387997004\",\"name\":\"Ulfet Cetin\"},{\"authorId\":\"153160880\",\"name\":\"Utku Akta\\u015f\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"669c4c85770f13a2ff5508aef8ef62c9208948f1\",\"title\":\"Searching for Ambiguous Objects in Videos using Relational Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/669c4c85770f13a2ff5508aef8ef62c9208948f1\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019}],\"corpusId\":4576781,\"doi\":\"10.1109/CVPR.2018.00434\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"references\":[{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144943727\",\"name\":\"S. Karthikeyan\"},{\"authorId\":\"1679794\",\"name\":\"V. Jagadeesh\"},{\"authorId\":\"46949012\",\"name\":\"Renuka Shenoy\"},{\"authorId\":\"1895768\",\"name\":\"M. Eckstein\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/ICCV.2013.83\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"879997b4887f3ee24c478f141a47406d1c1047fd\",\"title\":\"From Where and How to What We See\",\"url\":\"https://www.semanticscholar.org/paper/879997b4887f3ee24c478f141a47406d1c1047fd\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1708.01676\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3407447\",\"name\":\"Rama Kovvuri\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.95\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"title\":\"Query-Guided Regression Network with Context Policy for Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Peng\"},{\"authorId\":null,\"name\":\"D. Samaras\"},{\"authorId\":null,\"name\":\"G. J. Zelinsky\"},{\"authorId\":null,\"name\":\"T. L. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"eling context in referring expressions\",\"url\":\"\",\"venue\":\"European Conference on Computer Vision\",\"year\":null},{\"arxivId\":\"1608.05203\",\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"title\":\"Seeing with Humans: Gaze-Assisted Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c70ad19c90491e2de8de686b6a49f9bbe44692c0\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1407.5736\",\"authors\":[{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1007/978-3-319-10584-0_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c0b510ebf995ef172cb64ed7ce24aa7903dced8\",\"title\":\"Learning Rich Features from RGB-D Images for Object Detection and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2c0b510ebf995ef172cb64ed7ce24aa7903dced8\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7294d3ac0001e4b36c67aeb5c31d1db8ba1da23a\",\"title\":\"Where are they looking?\",\"url\":\"https://www.semanticscholar.org/paper/7294d3ac0001e4b36c67aeb5c31d1db8ba1da23a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144018782\",\"name\":\"M. Soliman\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/IPTA.2016.7821028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4788460f09baa3fa256b3b4ed405daa04c4c97c\",\"title\":\"Towards gaze-based video annotation\",\"url\":\"https://www.semanticscholar.org/paper/a4788460f09baa3fa256b3b4ed405daa04c4c97c\",\"venue\":\"2016 Sixth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144943727\",\"name\":\"S. Karthikeyan\"},{\"authorId\":\"40092548\",\"name\":\"Thuyen Ngo\"},{\"authorId\":\"1895768\",\"name\":\"M. Eckstein\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/CVPR.2015.7298944\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5da06a9b5be4fe7d6838c489e6744162911a5267\",\"title\":\"Eye tracking assisted extraction of attentionally important objects from videos\",\"url\":\"https://www.semanticscholar.org/paper/5da06a9b5be4fe7d6838c489e6744162911a5267\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1803.11209\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"143668320\",\"name\":\"W. Hwu\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e81df94c24c08963c7d338d601bb030a8d919720\",\"title\":\"Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/e81df94c24c08963c7d338d601bb030a8d919720\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1608.00525\",\"authors\":[{\"authorId\":\"3081378\",\"name\":\"Varun K. Nagaraja\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46493-0_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"title\":\"Modeling Context Between Objects for Referring Expression Understanding\",\"url\":\"https://www.semanticscholar.org/paper/86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367000\",\"name\":\"H. Kreysa\"},{\"authorId\":\"7267206\",\"name\":\"P. Knoeferle\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"038a95010263dda51e37120c74cb4ab1bb51b4f7\",\"title\":\"Peripheral speaker gaze facilitates spoken language comprehension: syntactic structuring and thematic role asssignment in German\",\"url\":\"https://www.semanticscholar.org/paper/038a95010263dda51e37120c74cb4ab1bb51b4f7\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1007/978-3-319-10602-1_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b183947ee15718b45546eda6b01e179b9a95421f\",\"title\":\"Edge Boxes: Locating Object Proposals from Edges\",\"url\":\"https://www.semanticscholar.org/paper/b183947ee15718b45546eda6b01e179b9a95421f\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"3038150\",\"name\":\"Cherry Che\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2015.7298994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"title\":\"Multi-task deep visual-semantic embedding for video thumbnail selection\",\"url\":\"https://www.semanticscholar.org/paper/562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1608.00272\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"3451188\",\"name\":\"Patrick Poirson\"},{\"authorId\":\"144947353\",\"name\":\"S. Yang\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46475-6_5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"title\":\"Modeling Context in Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731948\",\"name\":\"P. Viola\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"}],\"doi\":\"10.1109/CVPR.2001.990517\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63\",\"title\":\"Rapid object detection using a boosted cascade of simple features\",\"url\":\"https://www.semanticscholar.org/paper/dc6ea0e30e46163b706f2f8bdc9c67ca87f83d63\",\"venue\":\"Proceedings of the 2001 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. CVPR 2001\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Kiros\"},{\"authorId\":null,\"name\":\"K. Cho\"},{\"authorId\":null,\"name\":\"A. C. Courville\"},{\"authorId\":null,\"name\":\"R. S. Zemel\"},{\"authorId\":null,\"name\":\"Y. Bengio\"},{\"authorId\":null,\"name\":\"P. Poirson\"},{\"authorId\":null,\"name\":\"S. Yang\"},{\"authorId\":null,\"name\":\"A. C. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"eling context in referring expressions\",\"url\":\"\",\"venue\":\"European Conference on Computer Vision\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7267206\",\"name\":\"P. Knoeferle\"},{\"authorId\":\"3367000\",\"name\":\"H. Kreysa\"}],\"doi\":\"10.3389/fpsyg.2012.00538\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"523971743988c5d8831376d97af300488415db5e\",\"title\":\"Can Speaker Gaze Modulate Syntactic Structuring and Thematic Role Assignment during Spoken Sentence Comprehension?\",\"url\":\"https://www.semanticscholar.org/paper/523971743988c5d8831376d97af300488415db5e\",\"venue\":\"Front. Psychology\",\"year\":2012},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2433617\",\"name\":\"Mingzhe Wang\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"31686229\",\"name\":\"Noriyuki Kojima\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1007/978-3-319-46484-8_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dd4f855d0c794060a8a2fabe0639f4a4e792b45\",\"title\":\"Structured Matching for Phrase Localization\",\"url\":\"https://www.semanticscholar.org/paper/3dd4f855d0c794060a8a2fabe0639f4a4e792b45\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49728460\",\"name\":\"P. Cole\"},{\"authorId\":\"37561096\",\"name\":\"J. L. Morgan\"}],\"doi\":\"10.2307/324613\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea578635e554f1d5de10803257ea059a1d60422b\",\"title\":\"Syntax and Semantics. Volume 3 : Speech Acts\",\"url\":\"https://www.semanticscholar.org/paper/ea578635e554f1d5de10803257ea059a1d60422b\",\"venue\":\"\",\"year\":1976},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1606.05814\",\"authors\":[{\"authorId\":\"34987921\",\"name\":\"Kyle Krafka\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"1712418\",\"name\":\"Petr Kellnhofer\"},{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"3422895\",\"name\":\"S. Bhandarkar\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.239\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0695751eb18cd138d7d9441378739882a8afc919\",\"title\":\"Eye Tracking for Everyone\",\"url\":\"https://www.semanticscholar.org/paper/0695751eb18cd138d7d9441378739882a8afc919\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":null,\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2013.101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad2c0ae801c9e8adece483e74725e12a8544d440\",\"title\":\"Studying Relationships between Human Gaze, Description, and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/ad2c0ae801c9e8adece483e74725e12a8544d440\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51265975\",\"name\":\"Eva Maria Nunnemann\"},{\"authorId\":\"2025591\",\"name\":\"K. Bergmann\"},{\"authorId\":\"3367000\",\"name\":\"H. Kreysa\"},{\"authorId\":\"7267206\",\"name\":\"P. Knoeferle\"}],\"doi\":\"10.21437/AVSP.2017-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ae17e61c2ef1ddac9054b2ced910622f7a50219\",\"title\":\"Referential Gaze Makes a Difference in Spoken Language Comprehension: Human Speaker vs. Virtual Agent Listener Gaze\",\"url\":\"https://www.semanticscholar.org/paper/7ae17e61c2ef1ddac9054b2ced910622f7a50219\",\"venue\":\"AVSP\",\"year\":2017},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749373\",\"name\":\"Dim P. Papadopoulos\"},{\"authorId\":\"47849651\",\"name\":\"A. Clarke\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1007/978-3-319-10602-1_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e75e7030837b9b83eb085f26b1ca45a7b2587a19\",\"title\":\"Training Object Class Detectors from Eye Tracking Data\",\"url\":\"https://www.semanticscholar.org/paper/e75e7030837b9b83eb085f26b1ca45a7b2587a19\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32639375\",\"name\":\"Teruhisa Misu\"},{\"authorId\":\"1693369\",\"name\":\"A. Raux\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"},{\"authorId\":\"2120120\",\"name\":\"Joan Devassy\"},{\"authorId\":\"3470201\",\"name\":\"Rakesh Gupta\"}],\"doi\":\"10.1145/2535948.2535951\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c592dfa1fb92dda139cee0eca5388485a67c5d5\",\"title\":\"Situated multi-modal dialog system in vehicles\",\"url\":\"https://www.semanticscholar.org/paper/3c592dfa1fb92dda139cee0eca5388485a67c5d5\",\"venue\":\"GazeIn '13\",\"year\":2013},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1711.03800\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/WACV.2018.00206\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6a4a34829b3b55497210ddbe88ad63ff801faae\",\"title\":\"Object Referring in Visual Scene with Spoken Language\",\"url\":\"https://www.semanticscholar.org/paper/d6a4a34829b3b55497210ddbe88ad63ff801faae\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.06036\",\"authors\":[{\"authorId\":\"1881617\",\"name\":\"Jack Valmadre\"},{\"authorId\":\"2271057\",\"name\":\"Luca Bertinetto\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/CVPR.2017.531\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"000178cd12c8a6e5da8215b6365fae03c20fd18d\",\"title\":\"End-to-End Representation Learning for Correlation Filter Based Tracking\",\"url\":\"https://www.semanticscholar.org/paper/000178cd12c8a6e5da8215b6365fae03c20fd18d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1603.03590\",\"authors\":[{\"authorId\":\"2515835\",\"name\":\"Till Kroeger\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46493-0_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"title\":\"Fast Optical Flow Using Dense Inverse Search\",\"url\":\"https://www.semanticscholar.org/paper/9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"6648406\",\"name\":\"Christopher M. Cervantes\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a645bcd029cc5ce21b973146f21a9655047cc96\",\"title\":\"Phrase Localization and Visual Relationship Detection with Comprehensive Linguistic Cues\",\"url\":\"https://www.semanticscholar.org/paper/1a645bcd029cc5ce21b973146f21a9655047cc96\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1706.01789\",\"authors\":[{\"authorId\":\"49268985\",\"name\":\"M. Kowalski\"},{\"authorId\":\"1930272\",\"name\":\"J. Naruniec\"},{\"authorId\":\"144432036\",\"name\":\"T. Trzci\\u0144ski\"}],\"doi\":\"10.1109/CVPRW.2017.254\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98b83d56ebc4714dcb6b72bfdb426d739b7fb86f\",\"title\":\"Deep Alignment Network: A Convolutional Neural Network for Robust Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/98b83d56ebc4714dcb6b72bfdb426d739b7fb86f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1603.06180\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46448-0_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b133e361e2f8af22b823d25060b2e7c47f690985\",\"title\":\"Segmentation from Natural Language Expressions\",\"url\":\"https://www.semanticscholar.org/paper/b133e361e2f8af22b823d25060b2e7c47f690985\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1604.01685\",\"authors\":[{\"authorId\":\"2841796\",\"name\":\"Marius Cordts\"},{\"authorId\":\"144187309\",\"name\":\"Mohamed Omran\"},{\"authorId\":\"39940699\",\"name\":\"Sebastian Ramos\"},{\"authorId\":\"3393153\",\"name\":\"Timo Rehfeld\"},{\"authorId\":\"1765022\",\"name\":\"M. Enzweiler\"},{\"authorId\":\"1798000\",\"name\":\"Rodrigo Benenson\"},{\"authorId\":\"145582788\",\"name\":\"Uwe Franke\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2016.350\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8c494ee5488fe20e0aa01bddf3fc4632086d654\",\"title\":\"The Cityscapes Dataset for Semantic Urban Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c8c494ee5488fe20e0aa01bddf3fc4632086d654\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1703.06870\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/ea99a5535388196d0d44be5b4d7dd02029a43bb2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014}],\"title\":\"Object Referring in Videos with Language and Human Gaze\",\"topics\":[{\"topic\":\"Humans\",\"topicId\":\"732\",\"url\":\"https://www.semanticscholar.org/topic/732\"},{\"topic\":\"Network model\",\"topicId\":\"20353\",\"url\":\"https://www.semanticscholar.org/topic/20353\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Stereoscopy\",\"topicId\":\"8813\",\"url\":\"https://www.semanticscholar.org/topic/8813\"}],\"url\":\"https://www.semanticscholar.org/paper/7a82d83f818cdc4ac714e468446bc2499ff9caa7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"