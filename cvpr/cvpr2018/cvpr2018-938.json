"{\"abstract\":\"Given two consecutive frames, video interpolation aims at generating intermediate frame(s) to form both spatially and temporally coherent video sequences. While most existing methods focus on single-frame interpolation, we propose an end-to-end convolutional neural network for variable-length multi-frame video interpolation, where the motion interpretation and occlusion reasoning are jointly modeled. We start by computing bi-directional optical flow between the input images using a U-Net architecture. These flows are then linearly combined at each time step to approximate the intermediate bi-directional optical flows. These approximate flows, however, only work well in locally smooth regions and produce artifacts around motion boundaries. To address this shortcoming, we employ another U-Net to refine the approximated flow and also predict soft visibility maps. Finally, the two input images are warped and linearly fused to form each intermediate frame. By applying the visibility maps to the warped images before fusion, we exclude the contribution of occluded pixels to the interpolated intermediate frame to avoid artifacts. Since none of our learned network parameters are time-dependent, our approach is able to produce as many intermediate frames as needed. To train our network, we use 1,132 240-fps video clips, containing 300K individual video frames. Experimental results on several datasets, predicting different numbers of interpolated frames, demonstrate that our approach performs consistently better than existing methods.\",\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\",\"url\":\"https://www.semanticscholar.org/author/40175280\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\",\"url\":\"https://www.semanticscholar.org/author/3232265\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\",\"url\":\"https://www.semanticscholar.org/author/2745026\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\",\"url\":\"https://www.semanticscholar.org/author/37144787\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\",\"url\":\"https://www.semanticscholar.org/author/1389846455\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\",\"url\":\"https://www.semanticscholar.org/author/1690538\"}],\"citationVelocity\":69,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"49521471\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2936549\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"title\":\"FI-Net: A Lightweight Video Frame Interpolation Network Using Feature-Level Flow\",\"url\":\"https://www.semanticscholar.org/paper/00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626101034\",\"name\":\"Nguyen Van Thang\"},{\"authorId\":\"1390764531\",\"name\":\"Kyujoong Lee\"},{\"authorId\":\"3090069\",\"name\":\"Hyuk-Jae Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2982039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"title\":\"A Stacked Deep MEMC Network for Frame Rate Up Conversion and its Application to HEVC\",\"url\":\"https://www.semanticscholar.org/paper/1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98080420\",\"name\":\"Hyeongmin Lee\"},{\"authorId\":\"48271129\",\"name\":\"Taeoh Kim\"},{\"authorId\":\"3305074\",\"name\":\"Tae-Young Chung\"},{\"authorId\":\"48322708\",\"name\":\"Daehyun Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"3055035\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"946a9a5d18a423de9c109087ecae818809276b9c\",\"title\":\"Learning Spatial Transform for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/946a9a5d18a423de9c109087ecae818809276b9c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/CVPR42600.2020.00548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.00450\",\"authors\":[{\"authorId\":\"13267204\",\"name\":\"M. Bemana\"},{\"authorId\":\"1790911\",\"name\":\"K. Myszkowski\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"1759347\",\"name\":\"T. Ritschel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"420ce162335b47288d234160b77c9ccb90b50277\",\"title\":\"X-Fields: Implicit Neural View-, Light- and Time-Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/420ce162335b47288d234160b77c9ccb90b50277\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.09349\",\"authors\":[{\"authorId\":\"88677858\",\"name\":\"Juan Luis Gonzalez Bello\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6104cf7304a6ee90eb3b2850ff6c2e06f298710b\",\"title\":\"Deep 3D-Zoom Net: Unsupervised Learning of Photo-Realistic 3D-Zoom\",\"url\":\"https://www.semanticscholar.org/paper/6104cf7304a6ee90eb3b2850ff6c2e06f298710b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.01005\",\"authors\":[{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3394171.3413686\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ed87dfe5ec1b3efa33016adf188d6d772aaef62\",\"title\":\"ALANET: Adaptive Latent Attention Network for Joint Video Deblurring and Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/3ed87dfe5ec1b3efa33016adf188d6d772aaef62\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93576086\",\"name\":\"H. Lin\"},{\"authorId\":\"1749408\",\"name\":\"P. Hsiu\"},{\"authorId\":\"145348862\",\"name\":\"T. Kuo\"},{\"authorId\":\"47905461\",\"name\":\"Yen-Yu Lin\"}],\"doi\":\"10.24963/ijcai.2020/86\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4876853ba05de357601750ac2708821ae146ad4\",\"title\":\"Spatiotemporal Super-Resolution with Cross-Task Consistency and Its Semi-supervised Extension\",\"url\":\"https://www.semanticscholar.org/paper/a4876853ba05de357601750ac2708821ae146ad4\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21310506\",\"name\":\"Aaron J Cunanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"af1ddce003ae0e9db2a4476797b2d20d741b8598\",\"title\":\"Barbell Trajectory and Kinematics during Two International Weightlifting Championships\",\"url\":\"https://www.semanticscholar.org/paper/af1ddce003ae0e9db2a4476797b2d20d741b8598\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51222025\",\"name\":\"A. B\\u00e4uerle\"},{\"authorId\":\"1703058\",\"name\":\"T. Ropinski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6393c97773943fdefcc4094533702be14b66376a\",\"title\":\"Net2Vis: Transforming Deep Convolutional Networks into Publication-Ready Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/6393c97773943fdefcc4094533702be14b66376a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\"}],\"doi\":\"10.1109/CVPR.2019.00250\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.13194\",\"authors\":[{\"authorId\":\"2317713\",\"name\":\"S. Lee\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/ICIP40778.2020.9191286\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aff965a62434c25e3465223179771f8b9f689054\",\"title\":\"Extrapolative-Interpolative Cycle-Consistency Learning For Video Frame Extrapolation\",\"url\":\"https://www.semanticscholar.org/paper/aff965a62434c25e3465223179771f8b9f689054\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1812.00452\",\"authors\":[{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"46193391\",\"name\":\"Qi-Zhi Cai\"},{\"authorId\":\"46886239\",\"name\":\"R. Wang\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2019.00910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce71c5b4c959c34715503a5980e457e700db9e70\",\"title\":\"Disentangling Propagation and Generation for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ce71c5b4c959c34715503a5980e457e700db9e70\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.06264\",\"authors\":[{\"authorId\":\"144847574\",\"name\":\"Zhichao Yin\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"}],\"doi\":\"10.1109/CVPR.2019.00620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b4ac890f9635d839a043adce0c23090aa8a02f9\",\"title\":\"Hierarchical Discrete Distribution Decomposition for Match Density Estimation\",\"url\":\"https://www.semanticscholar.org/paper/7b4ac890f9635d839a043adce0c23090aa8a02f9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"},{\"authorId\":null,\"name\":\"Yang Zhao\"}],\"doi\":\"10.1109/ACCESS.2019.2940510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"title\":\"Multi-Frame Pyramid Refinement Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1402202242\",\"name\":\"A. S\\u00e1nchez-Pay\"},{\"authorId\":\"1404360730\",\"name\":\"J. Courel-Ib\\u00e1\\u00f1ez\"},{\"authorId\":\"1401976400\",\"name\":\"A. Mart\\u00ednez-Cava\"},{\"authorId\":\"1404360701\",\"name\":\"E. Conesa-Ros\"},{\"authorId\":\"1401976420\",\"name\":\"R. Mor\\u00e1n-Navarro\"},{\"authorId\":\"5896849\",\"name\":\"J. Pallar\\u00e9s\"}],\"doi\":\"10.1016/J.MEASUREMENT.2019.01.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e55f3878c37ef9b8332ad7857271b8ff0f70def\",\"title\":\"Is the high-speed camera-based method a plausible option for bar velocity assessment during resistance training?\",\"url\":\"https://www.semanticscholar.org/paper/9e55f3878c37ef9b8332ad7857271b8ff0f70def\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.07759\",\"authors\":[{\"authorId\":\"84509959\",\"name\":\"Mart Kartasev\"},{\"authorId\":\"84650046\",\"name\":\"Carlo Rapisarda\"},{\"authorId\":\"47414172\",\"name\":\"Dominik Fay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1aed5cd540275f86b7019e494be57437c604715\",\"title\":\"Implementing Adaptive Separable Convolution for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f1aed5cd540275f86b7019e494be57437c604715\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134888279\",\"name\":\"Yung-Han Ho\"},{\"authorId\":\"1381649479\",\"name\":\"Chuan-Yuan Cho\"},{\"authorId\":\"51259830\",\"name\":\"Guo-Lun Jin\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICCV.2019.01056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffc7c3ac48bdff347fd48404fc867a877c156b3b\",\"title\":\"SME-Net: Sparse Motion Estimation for Parametric Video Prediction Through Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ffc7c3ac48bdff347fd48404fc867a877c156b3b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1901.02840\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2019.00151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"title\":\"GIF2Video: Color Dequantization and Temporal Interpolation of GIF Images\",\"url\":\"https://www.semanticscholar.org/paper/75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"title\":\"A Fast 4 K Video Frame Interpolation Using a Hybrid Task-Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.09294\",\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.1109/LSP.2020.3008082\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"540e02b0ec5fbc470ebecb58689a16aba49f848e\",\"title\":\"Self-Supervised Light Field Reconstruction Using Shearlet Transform and Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/540e02b0ec5fbc470ebecb58689a16aba49f848e\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2939143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"title\":\"A Multi-Scale Position Feature Transform Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152359151\",\"name\":\"Chenxi Tu\"},{\"authorId\":\"49567362\",\"name\":\"E. Takeuchi\"},{\"authorId\":\"1856242\",\"name\":\"Alexander Carballo\"},{\"authorId\":\"1709999\",\"name\":\"K. Takeda\"}],\"doi\":\"10.1109/ACCESS.2019.2935253\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f1f39bcb64a8483a57c6301bc878fe95628ec78b\",\"title\":\"Real-Time Streaming Point Cloud Compression for 3D LiDAR Sensor Using U-Net\",\"url\":\"https://www.semanticscholar.org/paper/f1f39bcb64a8483a57c6301bc878fe95628ec78b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1911.00627\",\"authors\":[{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"123100665\",\"name\":\"Q. Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6296ec34c6e792729ec47195727d2ab17d27a50e\",\"title\":\"Quadratic video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6296ec34c6e792729ec47195727d2ab17d27a50e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"39876415\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023270\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"title\":\"Deep Learning Approach to Video Frame Rate Up-Conversion Using Bilateral Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.08188\",\"authors\":[{\"authorId\":\"52061414\",\"name\":\"SungHyun Park\"},{\"authorId\":\"1438418837\",\"name\":\"Kangyeol Kim\"},{\"authorId\":\"48174707\",\"name\":\"J. Lee\"},{\"authorId\":\"1934247587\",\"name\":\"Jaegul Choo\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"49899493\",\"name\":\"Sookyung Kim\"},{\"authorId\":\"1387328701\",\"name\":\"Edward Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58db26d7064d16bd45d2fda6b5ded997f47278e5\",\"title\":\"Vid-ODE: Continuous-Time Video Generation with Neural Ordinary Differential Equation\",\"url\":\"https://www.semanticscholar.org/paper/58db26d7064d16bd45d2fda6b5ded997f47278e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993383158\",\"name\":\"Zeyu Xiao\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"3061449\",\"name\":\"Xueyang Fu\"},{\"authorId\":\"153626238\",\"name\":\"D. Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1145/3394171.3413667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b051580cb309ef990b77875d13ac7dd4e5950a\",\"title\":\"Space-Time Video Super-Resolution Using Temporal Profiles\",\"url\":\"https://www.semanticscholar.org/paper/19b051580cb309ef990b77875d13ac7dd4e5950a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454634\",\"name\":\"Zhichao Yin\"},{\"authorId\":\"47518580\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1807197\",\"name\":\"Fisher Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a57deba5db7814f8ce4afbe202c69e420d75401f\",\"title\":\"Match Density L Loss D 2 V Density to Vector \\u03c6 Upsample\",\"url\":\"https://www.semanticscholar.org/paper/a57deba5db7814f8ce4afbe202c69e420d75401f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151093918\",\"name\":\"Linyan Mei\"},{\"authorId\":\"151109841\",\"name\":\"Mohit Dandekar\"},{\"authorId\":\"150974933\",\"name\":\"Dimitrios Rodopoulos\"},{\"authorId\":\"151045389\",\"name\":\"Jeremy Constantin\"},{\"authorId\":\"2449025\",\"name\":\"P. Debacker\"},{\"authorId\":\"1707947\",\"name\":\"R. Lauwereins\"},{\"authorId\":\"9619761\",\"name\":\"Marian Verhelst\"}],\"doi\":\"10.1109/AICAS.2019.8771481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7423cac74786974d9a01bb0a5f91ad6716389576\",\"title\":\"Sub-Word Parallel Precision-Scalable MAC Engines for Efficient Embedded DNN Inference\",\"url\":\"https://www.semanticscholar.org/paper/7423cac74786974d9a01bb0a5f91ad6716389576\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence Circuits and Systems (AICAS)\",\"year\":2019},{\"arxivId\":\"1912.05193\",\"authors\":[{\"authorId\":\"102580872\",\"name\":\"Andr\\u00e9 Nortje\"},{\"authorId\":\"40021784\",\"name\":\"Herman A. Engelbrecht\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1012d2e369d1bc0b49f201fad95fd851bc654467\",\"title\":\"Deep motion estimation for parallel inter-frame prediction in video compression\",\"url\":\"https://www.semanticscholar.org/paper/1012d2e369d1bc0b49f201fad95fd851bc654467\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744579\",\"name\":\"Hui Men\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"33920690\",\"name\":\"D. Maurer\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"46356710\",\"name\":\"D. Saupe\"}],\"doi\":\"10.1109/QoMEX.2019.8743221\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"af3218b2122817eebfc5d271bbed120504f05342\",\"title\":\"Visual Quality Assessment for Motion Compensated Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af3218b2122817eebfc5d271bbed120504f05342\",\"venue\":\"2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"145037825\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1109/ICIP.2019.8803678\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a3078e39137a59af12f49a985c3b1e1765d51eba\",\"title\":\"Frame Interpolation Using Phase and Amplitude Feature Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/a3078e39137a59af12f49a985c3b1e1765d51eba\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152300394\",\"name\":\"Man M. Ho\"},{\"authorId\":\"3237233\",\"name\":\"J. Zhou\"},{\"authorId\":\"144527543\",\"name\":\"Gang He\"},{\"authorId\":\"2692368\",\"name\":\"Muchen Li\"},{\"authorId\":\"143900008\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPRW50498.2020.00070\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f2d22d60b1fcec545cdfcec9ca76868abd0885c\",\"title\":\"SR-CL-DMC: P-frame coding with Super-Resolution, Color Learning, and Deep Motion Compensation\",\"url\":\"https://www.semanticscholar.org/paper/4f2d22d60b1fcec545cdfcec9ca76868abd0885c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2007.12622\",\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"51268282\",\"name\":\"Keunsoo Ko\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1007/978-3-030-58568-6_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"title\":\"BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98485019\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"title\":\"High-speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.12013\",\"authors\":[{\"authorId\":\"2943460\",\"name\":\"Thomas Vandal\"},{\"authorId\":\"48834077\",\"name\":\"R. Nemani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0454d9ef912a08585d14921b94f8eda11a43bb0a\",\"title\":\"Temporal Interpolation of Geostationary Satellite Imagery with Task Specific Optical Flow.\",\"url\":\"https://www.semanticscholar.org/paper/0454d9ef912a08585d14921b94f8eda11a43bb0a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.05928\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/ICCV.2019.00098\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"title\":\"Unsupervised Video Interpolation Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.06409\",\"authors\":[{\"authorId\":\"39744579\",\"name\":\"Hui Men\"},{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"69032233\",\"name\":\"D. Saupe\"}],\"doi\":\"10.1007/s41233-020-00037-y\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b2130669a20586814e90aa9feeeae9b165001b4f\",\"title\":\"Subjective annotation for a frame interpolation benchmark using artefact amplification\",\"url\":\"https://www.semanticscholar.org/paper/b2130669a20586814e90aa9feeeae9b165001b4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38602589\",\"name\":\"N. Burgos\"},{\"authorId\":\"1721826\",\"name\":\"D. Svoboda\"},{\"authorId\":\"1907022\",\"name\":\"J. Wolterink\"},{\"authorId\":\"150068346\",\"name\":\"C. Zhao\"}],\"doi\":\"10.1007/978-3-030-59520-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66d2554c2d976e912f063fd58c31936772949417\",\"title\":\"Simulation and Synthesis in Medical Imaging: 5th International Workshop, SASHIMI 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/66d2554c2d976e912f063fd58c31936772949417\",\"venue\":\"SASHIMI@MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Keita Ukihashi\"},{\"authorId\":\"47482153\",\"name\":\"Takashi Imagawa\"},{\"authorId\":\"47199002\",\"name\":\"Hiroshi Tsutsui\"},{\"authorId\":\"1798697\",\"name\":\"Y. Miyanaga\"},{\"authorId\":\"1992671\",\"name\":\"H. Ochi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3983d50775f2e9f9107f02857f310680d2e16909\",\"title\":\"Improving Global Motion Compensation for Frame Interpolation with High-Resolution and High-Frame-Rate Video\",\"url\":\"https://www.semanticscholar.org/paper/3983d50775f2e9f9107f02857f310680d2e16909\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.1109/ICIP.2019.8803436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de3680029069acdc287c62fa0b632f8140b1578a\",\"title\":\"Fast: Flow-Assisted Shearlet Transform for Densely-Sampled Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/de3680029069acdc287c62fa0b632f8140b1578a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31839358\",\"name\":\"A. Kumpf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8dd47f390db7f629036ad9a7990151fd558a6c55\",\"title\":\"Data-driven Ensemble Visualization\",\"url\":\"https://www.semanticscholar.org/paper/8dd47f390db7f629036ad9a7990151fd558a6c55\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10755743\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"2844427\",\"name\":\"M. Hamanaka\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.5220/0008876600270035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"title\":\"Audio-guided Video Interpolation via Human Pose Features\",\"url\":\"https://www.semanticscholar.org/paper/6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1804.06919\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"40943290\",\"name\":\"Nayan Singhal\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1007/978-3-030-01237-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"title\":\"Video Compression through Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.01717\",\"authors\":[{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"3440930\",\"name\":\"Sjoerd van Steenkiste\"},{\"authorId\":\"2006889\",\"name\":\"Karol Kurach\"},{\"authorId\":\"52153018\",\"name\":\"Rapha\\u00ebl Marinier\"},{\"authorId\":\"144859281\",\"name\":\"M. Michalski\"},{\"authorId\":\"1802148\",\"name\":\"S. Gelly\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b59233aab8364186603967bc12d88af48cc0992d\",\"title\":\"Towards Accurate Generative Models of Video: A New Metric & Challenges\",\"url\":\"https://www.semanticscholar.org/paper/b59233aab8364186603967bc12d88af48cc0992d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390858090\",\"name\":\"Sanghun Park\"},{\"authorId\":\"1920243364\",\"name\":\"Kwanggyoon Seo\"},{\"authorId\":\"104115248\",\"name\":\"Jun-yong Noh\"}],\"doi\":\"10.1145/3414685.3417797\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"225270c27942efaaa853436afa822f366306c6ad\",\"title\":\"Neural crossbreed\",\"url\":\"https://www.semanticscholar.org/paper/225270c27942efaaa853436afa822f366306c6ad\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rajat Arora\"},{\"authorId\":null,\"name\":\"Yong Jae Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7223fb56eeece5806f8d25718bbc78386e17f19f\",\"title\":\"SinGAN-GIF: Learning a Generative Video Model from a Single GIF\",\"url\":\"https://www.semanticscholar.org/paper/7223fb56eeece5806f8d25718bbc78386e17f19f\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9508145\",\"name\":\"Morten Hannemose\"},{\"authorId\":\"144454181\",\"name\":\"Janus N\\u00f8rtoft Jensen\"},{\"authorId\":\"48660142\",\"name\":\"G. Einarsson\"},{\"authorId\":\"2579225\",\"name\":\"J. Wilm\"},{\"authorId\":\"2253200\",\"name\":\"A. Dahl\"},{\"authorId\":\"2661305\",\"name\":\"J. Frisvad\"}],\"doi\":\"10.1007/978-3-030-20205-7_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"title\":\"Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow\",\"url\":\"https://www.semanticscholar.org/paper/7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"venue\":\"SCIA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123878263\",\"name\":\"Pierre A. David\"},{\"authorId\":\"51232337\",\"name\":\"Mika\\u00ebl Le Pendu\"},{\"authorId\":\"1780587\",\"name\":\"C. Guillemot\"}],\"doi\":\"10.1109/icme46284.2020.9102968\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5d3824523feb057b01c90efe3e1fbcb1bc84f83e\",\"title\":\"Angularly Consistent Light Field Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5d3824523feb057b01c90efe3e1fbcb1bc84f83e\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2011.13084\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"13034a395d5c6728c9b11e777828d9998018cbf6\",\"title\":\"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/13034a395d5c6728c9b11e777828d9998018cbf6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04950\",\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"35462690\",\"name\":\"Jungwon Lee\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d52448d649ce5d35189abdeecdc62db647b4246\",\"title\":\"HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0d52448d649ce5d35189abdeecdc62db647b4246\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"2512006\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1117/1.JEI.28.4.043002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"title\":\"Multiframe interpolation for video using phase features\",\"url\":\"https://www.semanticscholar.org/paper/579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01402\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49621147\",\"name\":\"D. Li\"},{\"authorId\":\"145008147\",\"name\":\"E. Lee\"},{\"authorId\":\"52107628\",\"name\":\"Elijah Schwelling\"},{\"authorId\":\"144046222\",\"name\":\"M. Quick\"},{\"authorId\":\"115820702\",\"name\":\"P. Meyers\"},{\"authorId\":\"152272089\",\"name\":\"R. Du\"},{\"authorId\":\"1405623639\",\"name\":\"Amitabh Varshney\"}],\"doi\":\"10.1145/3334480.3382921\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bd71d9c4e5d2f2cdc7f18c2d221b44647a052ab\",\"title\":\"MeteoVis: Visualizing Meteorological Events in Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/2bd71d9c4e5d2f2cdc7f18c2d221b44647a052ab\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1902.09680\",\"authors\":[{\"authorId\":\"51495548\",\"name\":\"Zihao W. Wang\"},{\"authorId\":\"8385095\",\"name\":\"Weixin Jiang\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"},{\"authorId\":\"1793812\",\"name\":\"O. Cossairt\"}],\"doi\":\"10.1109/ICCVW.2019.00532\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ab864d234049df7745416cc0d2e9357842a6b11\",\"title\":\"Event-Driven Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/0ab864d234049df7745416cc0d2e9357842a6b11\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.07722\",\"authors\":[{\"authorId\":\"1694635\",\"name\":\"T. Delbr\\u00fcck\"},{\"authorId\":\"2175899\",\"name\":\"Yuhuang Hu\"},{\"authorId\":\"145251558\",\"name\":\"Zhe He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7378e4cfd219518789980059b5aaeb0442484a18\",\"title\":\"V2E: From video frames to realistic DVS event camera streams\",\"url\":\"https://www.semanticscholar.org/paper/7378e4cfd219518789980059b5aaeb0442484a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.01026\",\"authors\":[{\"authorId\":\"46917346\",\"name\":\"Amy Zhao\"},{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"40649030\",\"name\":\"Kathleen M. Lewis\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"}],\"doi\":\"10.1109/cvpr42600.2020.00846\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"title\":\"Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings\",\"url\":\"https://www.semanticscholar.org/paper/5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"153197501\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053987\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"23c9b2b3d315dd81563f57bbec8fda28d53700a6\",\"title\":\"Video Frame Interpolation Via Residue Refinement\",\"url\":\"https://www.semanticscholar.org/paper/23c9b2b3d315dd81563f57bbec8fda28d53700a6\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"}],\"doi\":\"10.3929/ethz-b-000315026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"971b2b96c43e5dc0bd2946a1de92e1072a36f82a\",\"title\":\"Video Frame Interpolation and Editing with Implicit Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/971b2b96c43e5dc0bd2946a1de92e1072a36f82a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050685\",\"name\":\"N. Zeng\"},{\"authorId\":\"50579892\",\"name\":\"Y. Chen\"},{\"authorId\":\"66471163\",\"name\":\"Y. Gu\"},{\"authorId\":\"27630525\",\"name\":\"Dong-dong Liu\"},{\"authorId\":\"1430778430\",\"name\":\"Yunbing Xing\"}],\"doi\":\"10.1109/SMC42975.2020.9283193\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"title\":\"Highly Fluent Sign Language Synthesis Based on Variable Motion Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999658893\",\"name\":\"Peiyao Guo\"},{\"authorId\":\"2026144643\",\"name\":\"Zhan Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ddfbcc46369f333223a983ce39ec9eb24dac7baf\",\"title\":\"Low-light Color Imaging via Dual Camera Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/ddfbcc46369f333223a983ce39ec9eb24dac7baf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49889937\",\"name\":\"Yimeng Zhang\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"1993581583\",\"name\":\"Bo Wu\"},{\"authorId\":\"30910424\",\"name\":\"A. Walid\"}],\"doi\":\"10.1145/3394171.3413527\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"title\":\"Video Synthesis via Transform-Based Tensor Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143744989\",\"name\":\"Qianshu Zhu\"},{\"authorId\":\"1641959671\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"50350340\",\"name\":\"Tien-Tsin Wong\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1109/tpami.2020.3001644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27500d4c7a6cef1deb79abdff016217e34a2af71\",\"title\":\"Video Snapshot: Single Image Motion Expansion via Invertible Motion Embedding.\",\"url\":\"https://www.semanticscholar.org/paper/27500d4c7a6cef1deb79abdff016217e34a2af71\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1905.06567\",\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"145772051\",\"name\":\"Sifeng Xia\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"}],\"doi\":\"10.1109/TMM.2019.2961504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d873fdfc43afd675432af22362283bf202837164\",\"title\":\"Deep Reference Generation With Multi-Domain Hierarchical Constraints for Inter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d873fdfc43afd675432af22362283bf202837164\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"144816141\",\"name\":\"J. Campos\"},{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/ICCV.2019.00652\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"title\":\"Neural Inter-Frame Compression for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00434\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5981bb0678578dcf75536bdc476a38a7e501a301\",\"title\":\"PoSNet: 4x Video Frame Interpolation Using Position-Specific Flow\",\"url\":\"https://www.semanticscholar.org/paper/5981bb0678578dcf75536bdc476a38a7e501a301\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151487048\",\"name\":\"Daekwan Ko\"},{\"authorId\":\"50403430\",\"name\":\"Dong-han Lee\"},{\"authorId\":\"51492435\",\"name\":\"Soo-Chul Lim\"}],\"doi\":\"10.1109/TII.2020.2991764\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6fd5084a4729b874483a1a43b6fbe588a9cdbbd\",\"title\":\"Continuous Image Generation From Low-Update-Rate Images and Physical Sensors Through a Conditional GAN for Robot Teleoperation\",\"url\":\"https://www.semanticscholar.org/paper/d6fd5084a4729b874483a1a43b6fbe588a9cdbbd\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":\"2008.04149\",\"authors\":[{\"authorId\":\"1597361648\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"1723442179\",\"name\":\"Bo Zhang\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"title\":\"Deep Sketch-guided Cartoon Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10399052\",\"name\":\"Irene Viola\"},{\"authorId\":\"32111266\",\"name\":\"J. Mulder\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"144022557\",\"name\":\"P. C\\u00e9sar\"}],\"doi\":\"10.1109/AIVR46125.2019.00022\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"title\":\"Temporal Interpolation of Dynamic Digital Humans using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34939083\",\"name\":\"W. Wei\"},{\"authorId\":\"8602737\",\"name\":\"Shi-guang Liu\"}],\"doi\":\"10.1007/978-3-030-63426-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bae1bb7b3ffff59700d3635efed3d7a68d21304\",\"title\":\"Interpolating Frames for Super-Resolution Smoke Simulation with GANs\",\"url\":\"https://www.semanticscholar.org/paper/2bae1bb7b3ffff59700d3635efed3d7a68d21304\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807658969\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"1807805250\",\"name\":\"Muchen Li\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2999209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c379cf37b936d43767e4e3a6bdde7f5022446a3\",\"title\":\"Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/4c379cf37b936d43767e4e3a6bdde7f5022446a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Tgt . ( a ) GT sequence ( b ) ImagineFlow ( c ) Backward warping Before After\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91926911\",\"name\":\"Minho Park\"},{\"authorId\":\"2909533\",\"name\":\"Sangmin Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054744\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"title\":\"Video Frame Interpolation Via Exceptional Motion-Aware Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2007.02501\",\"authors\":[{\"authorId\":\"116046679\",\"name\":\"Zixu Zhao\"},{\"authorId\":\"33981465\",\"name\":\"Yueming Jin\"},{\"authorId\":\"143953230\",\"name\":\"Xiaojie Gao\"},{\"authorId\":\"46981662\",\"name\":\"Qi Dou\"},{\"authorId\":\"72434829\",\"name\":\"P. Heng\"}],\"doi\":\"10.1007/978-3-030-59716-0_65\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"434c8edb70cb682691f1c677a18b681edf709e06\",\"title\":\"Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video\",\"url\":\"https://www.semanticscholar.org/paper/434c8edb70cb682691f1c677a18b681edf709e06\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48915513\",\"name\":\"P. Johnston\"},{\"authorId\":\"1807106\",\"name\":\"Eyad Elyan\"}],\"doi\":\"10.1016/J.DIIN.2019.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"title\":\"A review of digital video tampering: From simple editing to full synthesis\",\"url\":\"https://www.semanticscholar.org/paper/cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"venue\":\"Digit. Investig.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1809.05286\",\"authors\":[{\"authorId\":\"80480198\",\"name\":\"Kian Ghodoussi\"},{\"authorId\":\"48253357\",\"name\":\"Nihar Sheth\"},{\"authorId\":\"80726083\",\"name\":\"Zane Durante\"},{\"authorId\":\"145472140\",\"name\":\"M. Wagner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc0d9e4478a444b170bbd3311dde7713e1debaf2\",\"title\":\"Deep CNN Frame Interpolation with Lessons Learned from Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/cc0d9e4478a444b170bbd3311dde7713e1debaf2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50105307\",\"name\":\"Wenchao Hu\"},{\"authorId\":\"50218026\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-31723-2_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f9224ec46346e53aeaa5951906e48699f914b9f\",\"title\":\"A Multi-frame Video Interpolation Neural Network for Large Motion\",\"url\":\"https://www.semanticscholar.org/paper/7f9224ec46346e53aeaa5951906e48699f914b9f\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396258325\",\"name\":\"Thejan Wijesinghe\"},{\"authorId\":\"151480047\",\"name\":\"Chamath Abeysinghe\"},{\"authorId\":\"1396258323\",\"name\":\"Chanuka Wijayakoon\"},{\"authorId\":\"1396258319\",\"name\":\"Lahiru Jayathilake\"},{\"authorId\":\"1935355\",\"name\":\"U. Thayasivam\"}],\"doi\":\"10.1007/978-3-030-50347-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f891d2df1974865f55dea248685e1ada70f12b8\",\"title\":\"FlowChroma - A Deep Recurrent Neural Network for Video Colorization\",\"url\":\"https://www.semanticscholar.org/paper/5f891d2df1974865f55dea248685e1ada70f12b8\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123797012\",\"name\":\"Christopher May\"},{\"authorId\":\"145869839\",\"name\":\"M. Oliveira\"},{\"authorId\":\"1698910\",\"name\":\"D. Aliaga\"}],\"doi\":\"10.1109/TVCG.2020.2992670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"title\":\"Video Folding: Increased Framerate for Semi-Repetitive Sequences.\",\"url\":\"https://www.semanticscholar.org/paper/e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49402727\",\"name\":\"Jiyang Yu\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1109/CVPR.2019.00392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c5752b88f5c287e7b6c051f6df08cc80d9e39d4\",\"title\":\"Robust Video Stabilization by Optimization in CNN Weight Space\",\"url\":\"https://www.semanticscholar.org/paper/8c5752b88f5c287e7b6c051f6df08cc80d9e39d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8526699\",\"name\":\"Jean Begaint\"},{\"authorId\":\"1679157\",\"name\":\"Franck Galpin\"},{\"authorId\":\"1871505\",\"name\":\"Philippe Guillotel\"},{\"authorId\":\"1780587\",\"name\":\"Christine Guillemot\"}],\"doi\":\"10.1109/DCC.2019.00068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"866fd28fc5381032a96d45e81c551c1af99bdec9\",\"title\":\"Deep Frame Interpolation for Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/866fd28fc5381032a96d45e81c551c1af99bdec9\",\"venue\":\"2019 Data Compression Conference (DCC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144324729\",\"name\":\"Jun Han\"},{\"authorId\":\"40505818\",\"name\":\"Chaoli Wang\"}],\"doi\":\"10.1109/TVCG.2019.2934255\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"107e9ea4a3ee66cfb85ec84dbe53e6831f793a8b\",\"title\":\"TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization\",\"url\":\"https://www.semanticscholar.org/paper/107e9ea4a3ee66cfb85ec84dbe53e6831f793a8b\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32168317\",\"name\":\"Neerav Karani\"},{\"authorId\":\"40062416\",\"name\":\"L. Zhang\"},{\"authorId\":\"145057506\",\"name\":\"C. Tanner\"},{\"authorId\":\"1796918\",\"name\":\"E. Konukoglu\"}],\"doi\":\"10.1016/j.media.2019.02.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9358edc050f8df0d86c93e43a0a9bd532bd6bda6\",\"title\":\"An image interpolation approach for acquisition time reduction in navigator\\u2010based 4D MRI\",\"url\":\"https://www.semanticscholar.org/paper/9358edc050f8df0d86c93e43a0a9bd532bd6bda6\",\"venue\":\"Medical Image Anal.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102510752\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"153731442\",\"name\":\"Zhiyong Gao\"}],\"doi\":\"10.1109/TIP.2020.3033617\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"title\":\"Video Frame Interpolation and Enhancement via Pyramid Recurrent Framework\",\"url\":\"https://www.semanticscholar.org/paper/a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13267204\",\"name\":\"M. Bemana\"},{\"authorId\":\"1790911\",\"name\":\"K. Myszkowski\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"1659982824\",\"name\":\"T. Ritschel\"}],\"doi\":\"10.1145/3414685.3417827\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e5933ce99cfe2ed1bbbb8b7654bda0cb3671950e\",\"title\":\"X-Fields\",\"url\":\"https://www.semanticscholar.org/paper/e5933ce99cfe2ed1bbbb8b7654bda0cb3671950e\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668913\",\"name\":\"A. Kokaram\"},{\"authorId\":\"90126681\",\"name\":\"Davinder Singh\"},{\"authorId\":\"2000355837\",\"name\":\"Simon Robinson\"}],\"doi\":\"10.1109/ICIP40778.2020.9191152\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"74510e871016eb629b504bab5df12f8b4ca9e9ec\",\"title\":\"A Bayesian View of Frame Interpolation and a Comparison with Existing Motion Picture Effects Tools\",\"url\":\"https://www.semanticscholar.org/paper/74510e871016eb629b504bab5df12f8b4ca9e9ec\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753738047\",\"name\":\"Kshitija Pandya\"},{\"authorId\":\"1753737879\",\"name\":\"Disha Varshney\"},{\"authorId\":\"1753607722\",\"name\":\"Ashray Aggarwal\"},{\"authorId\":\"115827410\",\"name\":\"Anil Singh Parihar\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"682e288a5870f182e0f92bb4735f5659dff8b94c\",\"title\":\"An Analytical Study of CNN-based Video Frame Interpolation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/682e288a5870f182e0f92bb4735f5659dff8b94c\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39866194\",\"name\":\"Meiguang Jin\"},{\"authorId\":\"144869275\",\"name\":\"Zhe Hu\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1109/CVPR.2019.00830\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9e9e9da2cd3f4946570d19891a108a02b93611ad\",\"title\":\"Learning to Extract Flawless Slow Motion From Blurry Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e9e9da2cd3f4946570d19891a108a02b93611ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2141bb1226997c49123731d97b484ca19696485a\",\"title\":\"Robust Temporal Super-Resolution for Dynamic Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/2141bb1226997c49123731d97b484ca19696485a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153690347\",\"name\":\"Yoonmo Yang\"},{\"authorId\":\"1831183\",\"name\":\"Byung Tae Oh\"}],\"doi\":\"10.1016/j.image.2020.115982\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"title\":\"Video frame interpolation using deep cascaded network structure\",\"url\":\"https://www.semanticscholar.org/paper/a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2931513\",\"name\":\"Nestor Z. Salamon\"},{\"authorId\":\"21300772\",\"name\":\"M. Billeter\"},{\"authorId\":\"1737690\",\"name\":\"E. Eisemann\"}],\"doi\":\"10.1111/cgf.13870\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"866b02e6cb928aa5ce1c5b5c2b8c7a82319fd266\",\"title\":\"ShutterApp: Spatio\\u2010temporal Exposure Control for Videos\",\"url\":\"https://www.semanticscholar.org/paper/866b02e6cb928aa5ce1c5b5c2b8c7a82319fd266\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"2004.11566\",\"authors\":[{\"authorId\":\"102460658\",\"name\":\"Kai Fukami\"},{\"authorId\":\"151486054\",\"name\":\"K. Fukagata\"},{\"authorId\":\"51093147\",\"name\":\"Kunihiko Taira\"}],\"doi\":\"10.1017/jfm.2020.948\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5722e8069a2ef43338455c514e4b3e8910ee8326\",\"title\":\"Machine learning based spatio-temporal super resolution reconstruction of turbulent flows\",\"url\":\"https://www.semanticscholar.org/paper/5722e8069a2ef43338455c514e4b3e8910ee8326\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.09219\",\"authors\":[{\"authorId\":\"35622441\",\"name\":\"Jean-Yves Franceschi\"},{\"authorId\":\"32278921\",\"name\":\"Edouard Delasalles\"},{\"authorId\":\"51301828\",\"name\":\"Mickael Chen\"},{\"authorId\":\"1782552\",\"name\":\"Sylvain Lamprier\"},{\"authorId\":\"150259685\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"title\":\"Stochastic Latent Residual Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657493720\",\"name\":\"Mengshun Hu\"},{\"authorId\":\"144326503\",\"name\":\"L. Liao\"},{\"authorId\":\"91353860\",\"name\":\"Jing Xiao\"},{\"authorId\":\"151484085\",\"name\":\"Lin Gu\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053223\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6dd58d9765210b676ef07298470e227a077c160b\",\"title\":\"Motion Feedback Design for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6dd58d9765210b676ef07298470e227a077c160b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1811.00684\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"144391743\",\"name\":\"R. Kirby\"},{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"2924393\",\"name\":\"D. Tarjan\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01234-2_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"title\":\"SDC-Net: Video Prediction Using Spatially-Displaced Convolution\",\"url\":\"https://www.semanticscholar.org/paper/c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.12361\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"145772856\",\"name\":\"Z. Lv\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/ICCV.2019.00329\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ef98dd2520136be3fda1549ff68a65e172ce14a\",\"title\":\"SENSE: A Shared Encoder Network for Scene-Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/1ef98dd2520136be3fda1549ff68a65e172ce14a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144667531\",\"name\":\"Jean B\\u00e9gaint\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"title\":\"Towards novel inter-prediction methods for image and video compression. (Nouvelles m\\u00e9thodes de pr\\u00e9diction inter-images pour la compression d'images et de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405687143\",\"name\":\"Hu Xing-hong\"},{\"authorId\":\"9332673\",\"name\":\"L. Xue-ting\"},{\"authorId\":\"9080467\",\"name\":\"Zhang Zhu-ming\"},{\"authorId\":\"148376409\",\"name\":\"Xia Menghan\"},{\"authorId\":\"1389675806\",\"name\":\"Li Chengze\"},{\"authorId\":\"1405687156\",\"name\":\"Wong Tien-Tsin\"}],\"doi\":\"10.1145/3355089.3356534\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d880a761ce2f85c5b0460747a66bea5c839cd71c\",\"title\":\"Colorblind-shareable videos by synthesizing temporal-coherent polynomial coefficients\",\"url\":\"https://www.semanticscholar.org/paper/d880a761ce2f85c5b0460747a66bea5c839cd71c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51450968\",\"name\":\"Antea Hadviger\"},{\"authorId\":\"2346045\",\"name\":\"I. Markovic\"},{\"authorId\":\"143888607\",\"name\":\"I. Petrovic\"}],\"doi\":\"10.1080/01691864.2020.1821770\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0b991a87218bb26e238e61a7e42824c1be86979\",\"title\":\"Stereo dense depth tracking based on optical flow using frames and events\",\"url\":\"https://www.semanticscholar.org/paper/e0b991a87218bb26e238e61a7e42824c1be86979\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.05794\",\"authors\":[{\"authorId\":\"1625349614\",\"name\":\"Zhe Jiang\"},{\"authorId\":\"80266998\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"1500380173\",\"name\":\"Jimmy Ren\"},{\"authorId\":\"9074167\",\"name\":\"Jiancheng Lv\"},{\"authorId\":\"119924337\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.00338\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8494799f38b40045dbaf3b5c55edc7b018eb5de\",\"title\":\"Learning Event-Based Motion Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/f8494799f38b40045dbaf3b5c55edc7b018eb5de\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.11762\",\"authors\":[{\"authorId\":\"35793956\",\"name\":\"Zhixiang Chi\"},{\"authorId\":\"49456126\",\"name\":\"R. Nasiri\"},{\"authorId\":\"2114344\",\"name\":\"Z. Liu\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"37932469\",\"name\":\"K. Plataniotis\"}],\"doi\":\"10.1007/978-3-030-58583-9_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e07d015d548162756e479934b245299e4aa737d0\",\"title\":\"All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e07d015d548162756e479934b245299e4aa737d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.06294\",\"authors\":[{\"authorId\":\"14042304\",\"name\":\"Zhewei Huang\"},{\"authorId\":\"123437116\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"145577184\",\"name\":\"Wen Heng\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"35132667\",\"name\":\"Shuchang Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"title\":\"RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491637046\",\"name\":\"Kang Liao\"},{\"authorId\":\"49043799\",\"name\":\"C. Lin\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"}],\"doi\":\"10.1109/TCSVT.2019.2958199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea50f28ec26924163c878f89cb33e2b7ab2d4d0c\",\"title\":\"Distortion Rectification From Static to Dynamic: A Distortion Sequence Construction Perspective\",\"url\":\"https://www.semanticscholar.org/paper/ea50f28ec26924163c878f89cb33e2b7ab2d4d0c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744579\",\"name\":\"Hui Men\"},{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"46356710\",\"name\":\"D. Saupe\"}],\"doi\":\"10.1109/QoMEX48832.2020.9123096\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45f5f51b95345ac4847eb3c1540dc43dede90c52\",\"title\":\"Visual Quality Assessment for Interpolated Slow-Motion Videos Based on a Novel Database\",\"url\":\"https://www.semanticscholar.org/paper/45f5f51b95345ac4847eb3c1540dc43dede90c52\",\"venue\":\"2020 Twelfth International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145567286\",\"name\":\"Hoang Le\"},{\"authorId\":\"50208066\",\"name\":\"F. Liu\"}],\"doi\":\"10.1111/cgf.13860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26d8da3d2f67e914aa564942d2721e89e221ef52\",\"title\":\"Appearance Flow Completion for Novel View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/26d8da3d2f67e914aa564942d2721e89e221ef52\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe2dba4d494e5a3c68eba14cc09a808de00f3f57\",\"title\":\"Supplementary Material: X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe2dba4d494e5a3c68eba14cc09a808de00f3f57\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.11698\",\"authors\":[{\"authorId\":\"1491292845\",\"name\":\"Zhaotao Wu\"},{\"authorId\":\"1471334007\",\"name\":\"J. Wei\"},{\"authorId\":\"150341007\",\"name\":\"Wenguang Yuan\"},{\"authorId\":\"2246972\",\"name\":\"J. Wang\"},{\"authorId\":\"3198175\",\"name\":\"T. Tasdizen\"}],\"doi\":\"10.3233/FAIA200314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"title\":\"Inter-slice image augmentation based on frame interpolation for boosting medical image segmentation accuracy\",\"url\":\"https://www.semanticscholar.org/paper/f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2012.06134\",\"authors\":[{\"authorId\":\"49576412\",\"name\":\"L. Yang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"3246404\",\"name\":\"P. Ren\"},{\"authorId\":\"14104497\",\"name\":\"Siwei Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"title\":\"Intrinsic Temporal Regularization for High-resolution Human Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13033\",\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c890b5ef847de07393526be4b6e337215e9dc1b6\",\"title\":\"An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c890b5ef847de07393526be4b6e337215e9dc1b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.07137\",\"authors\":[{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"151502853\",\"name\":\"Kang Liao\"},{\"authorId\":\"2212400\",\"name\":\"Chunyu Lin\"},{\"authorId\":\"152621482\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"}],\"doi\":\"10.3390/s20061573\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"de3775c0499d036da4097ae3ab89db00a10c5c6e\",\"title\":\"PLIN: A Network for Pseudo-LiDAR Point Cloud Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/de3775c0499d036da4097ae3ab89db00a10c5c6e\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2012.09790\",\"authors\":[{\"authorId\":\"15394275\",\"name\":\"Yilun Du\"},{\"authorId\":\"1922259572\",\"name\":\"Yinan Zhang\"},{\"authorId\":\"14878299\",\"name\":\"Hong-Xing Yu\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1112ef0a80e7cb59e0dee6c2ff5e48f4a182b7dd\",\"title\":\"Neural Radiance Flow for 4D View Synthesis and Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/1112ef0a80e7cb59e0dee6c2ff5e48f4a182b7dd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.10066\",\"authors\":[{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"46946977\",\"name\":\"Zhijun Li\"},{\"authorId\":\"2341727\",\"name\":\"Y. Liu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b7e6377d5d5d42c8b06a197465a281624dca8a4d\",\"title\":\"PointINet: Point Cloud Frame Interpolation Network\",\"url\":\"https://www.semanticscholar.org/paper/b7e6377d5d5d42c8b06a197465a281624dca8a4d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.00779\",\"authors\":[{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"},{\"authorId\":\"9535762\",\"name\":\"Janghoon Choi\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00946\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"title\":\"Scene-Adaptive Video Frame Interpolation via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.02909\",\"authors\":[{\"authorId\":\"9757384\",\"name\":\"Woon-Sung Park\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b87df69011057c700f581798e8c13667f5205b8e\",\"title\":\"Deep Predictive Video Compression with Bi-directional Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b87df69011057c700f581798e8c13667f5205b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"144992103\",\"name\":\"C. Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"77f5496935d01c06a4e0c301be42d388e9d73a99\",\"title\":\"Depth-Aware Video Frame Interpolation Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/77f5496935d01c06a4e0c301be42d388e9d73a99\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"151270904\",\"name\":\"Zhaojing Wen\"},{\"authorId\":\"151483658\",\"name\":\"Wenxue Cui\"},{\"authorId\":\"39618906\",\"name\":\"Rui Wang\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/ICME.2019.00304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"title\":\"Continuous Bidirectional Optical Flow for Video Frame Sequence Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"af63b7390d92d1875105ed607cd3b09399bdce4f\",\"title\":\"MeteoVis: Visualizing Meteorological Events in Virtual Environments\",\"url\":\"https://www.semanticscholar.org/paper/af63b7390d92d1875105ed607cd3b09399bdce4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.05571\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/TPAMI.2019.2894353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc294b251085b76f166c2ec16c3ee77f02800ec0\",\"title\":\"Models Matter, So Does Training: An Empirical Study of CNNs for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/bc294b251085b76f166c2ec16c3ee77f02800ec0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.23919/EUSIPCO.2019.8903168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"title\":\"IEST: Interpolation-Enhanced Shearlet Transform for Light Field Reconstruction Using Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":\"2012.00212\",\"authors\":[{\"authorId\":\"35615871\",\"name\":\"Kunming Luo\"},{\"authorId\":\"121900506\",\"name\":\"C. Wang\"},{\"authorId\":\"2202149\",\"name\":\"Shuaicheng Liu\"},{\"authorId\":\"1934546\",\"name\":\"Haoqiang Fan\"},{\"authorId\":\"40470662\",\"name\":\"J. Wang\"},{\"authorId\":\"2084926\",\"name\":\"J. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"accb178d3d7a00edf3447901b8dbe204b3925218\",\"title\":\"UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning\",\"url\":\"https://www.semanticscholar.org/paper/accb178d3d7a00edf3447901b8dbe204b3925218\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13205\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"152198491\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"title\":\"Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors\",\"url\":\"https://www.semanticscholar.org/paper/8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576068163\",\"name\":\"Sui Li\"},{\"authorId\":\"152223850\",\"name\":\"Manman Zhu\"},{\"authorId\":\"3256389\",\"name\":\"D. Li\"},{\"authorId\":\"144890921\",\"name\":\"Q. Gao\"},{\"authorId\":\"1904517\",\"name\":\"Z. Bian\"},{\"authorId\":\"1475662292\",\"name\":\"Dong Zeng\"},{\"authorId\":\"143979190\",\"name\":\"J. Ma\"}],\"doi\":\"10.1109/NSS/MIC42101.2019.9060075\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43c7557f1daddc6b1a3e514538aa196f10871eab\",\"title\":\"Task-driven Deep Learning Network for Dynamic Cerebral Perfusion Computed Tomography Protocol Determination\",\"url\":\"https://www.semanticscholar.org/paper/43c7557f1daddc6b1a3e514538aa196f10871eab\",\"venue\":\"2019 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC)\",\"year\":2019},{\"arxivId\":\"1804.04440\",\"authors\":[{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"32168317\",\"name\":\"Neerav Karani\"},{\"authorId\":\"145057506\",\"name\":\"C. Tanner\"},{\"authorId\":\"1796918\",\"name\":\"E. Konukoglu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0e7eb94ae7311ec9d8d0c8b75c6d675ec8d7e16b\",\"title\":\"Temporal Interpolation via Motion Field Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0e7eb94ae7311ec9d8d0c8b75c6d675ec8d7e16b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.05532\",\"authors\":[{\"authorId\":\"14925412\",\"name\":\"Prasan A. Shedligeri\"},{\"authorId\":\"71834567\",\"name\":\"S. Anupama\"},{\"authorId\":\"1879114299\",\"name\":\"Kaushik Mitra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"57cbe673125a9e6775e9e16c7355f062ce6eae82\",\"title\":\"A Unified Framework for Compressive Video Recovery from Coded Exposure Techniques\",\"url\":\"https://www.semanticscholar.org/paper/57cbe673125a9e6775e9e16c7355f062ce6eae82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13170\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR42600.2020.00293\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"title\":\"Space-Time-Aware Multi-Resolution Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150258541\",\"name\":\"Paulino Cristovao\"},{\"authorId\":\"1754192\",\"name\":\"H. Nakada\"},{\"authorId\":\"144739206\",\"name\":\"Yusuke Tanimura\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"}],\"doi\":\"10.1109/ACCESS.2020.3016313\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bb617a6b46c8f3b6bccaf8974853143d161221ed\",\"title\":\"Generating In-Between Images Through Learned Latent Space Representation Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/bb617a6b46c8f3b6bccaf8974853143d161221ed\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.11481\",\"authors\":[{\"authorId\":\"1490999400\",\"name\":\"Haojie Liu\"},{\"authorId\":\"1491637046\",\"name\":\"Kang Liao\"},{\"authorId\":\"2212400\",\"name\":\"Chunyu Lin\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"50f7c1fecdd2ef2ed1fafaac3b5b2f3b434050e0\",\"title\":\"Pseudo-LiDAR Point Cloud Interpolation Based on 3D Motion Representation and Spatial Supervision\",\"url\":\"https://www.semanticscholar.org/paper/50f7c1fecdd2ef2ed1fafaac3b5b2f3b434050e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02749\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"69869231\",\"name\":\"R. Pottorf\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8a7ae2b9dbc825407ccf67a5e6c9e2a857766d75\",\"title\":\"Video Interpolation and Prediction with Unsupervised Landmarks\",\"url\":\"https://www.semanticscholar.org/paper/8a7ae2b9dbc825407ccf67a5e6c9e2a857766d75\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.00389\",\"authors\":[{\"authorId\":\"32879676\",\"name\":\"Jiezhang Cao\"},{\"authorId\":\"90891818\",\"name\":\"Langyuan Mo\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"143670622\",\"name\":\"Yong Guo\"},{\"authorId\":\"144259957\",\"name\":\"P. Zhao\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cec7f2172d4e09db5a62e8a4f83c4f32a3e32e9\",\"title\":\"Joint Wasserstein Distribution Matching\",\"url\":\"https://www.semanticscholar.org/paper/3cec7f2172d4e09db5a62e8a4f83c4f32a3e32e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.06034\",\"authors\":[{\"authorId\":\"144796690\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/WACV.2019.00237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ed892e7787805e2202d006687ac69fea6bab0a5\",\"title\":\"High-Speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/9ed892e7787805e2202d006687ac69fea6bab0a5\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1912.07213\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"107606159\",\"name\":\"Jihyong Oh\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":\"10.1609/AAAI.V34I07.6788\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c4801dd2249f912c655887bc0bb6a53ddbab7f\",\"title\":\"FISR: Deep Joint Frame Interpolation and Super-Resolution with A Multi-scale Temporal Loss\",\"url\":\"https://www.semanticscholar.org/paper/09c4801dd2249f912c655887bc0bb6a53ddbab7f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2041295391\",\"name\":\"Joi Shimizu\"},{\"authorId\":\"71418271\",\"name\":\"Z. Cheng\"},{\"authorId\":\"3294614\",\"name\":\"H. Sun\"},{\"authorId\":null,\"name\":\"Masaru Takeuchi\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/GCCE50665.2020.9291852\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fde17c99e7b2b6235608531c5342fc6306ab006f\",\"title\":\"HEVC Video Coding with Deep Learning Based Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/fde17c99e7b2b6235608531c5342fc6306ab006f\",\"venue\":\"2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)\",\"year\":2020},{\"arxivId\":\"2002.12680\",\"authors\":[{\"authorId\":\"7000208\",\"name\":\"Yu-yu Guo\"},{\"authorId\":\"49117537\",\"name\":\"Lei Bi\"},{\"authorId\":\"2130901\",\"name\":\"Euijoon Ahn\"},{\"authorId\":\"11675891\",\"name\":\"D. Feng\"},{\"authorId\":\"49110419\",\"name\":\"Q. Wang\"},{\"authorId\":\"46454386\",\"name\":\"Jinman Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.00478\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57561a45ccde67ea6e3db870e4994106e4d61a69\",\"title\":\"A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical Image\",\"url\":\"https://www.semanticscholar.org/paper/57561a45ccde67ea6e3db870e4994106e4d61a69\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.09905\",\"authors\":[{\"authorId\":\"146270823\",\"name\":\"Beibei Jin\"},{\"authorId\":\"1943030\",\"name\":\"Y. Hu\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"66692321\",\"name\":\"Jingyu Niu\"},{\"authorId\":\"144578811\",\"name\":\"Z. Shi\"},{\"authorId\":\"152713339\",\"name\":\"Yinhe Han\"},{\"authorId\":\"40613624\",\"name\":\"Xiaowei Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00461\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a280048e69d41750c42d6f96e451e75c52c07741\",\"title\":\"Exploring Spatial-Temporal Multi-Frequency Analysis for High-Fidelity and Temporal-Consistency Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a280048e69d41750c42d6f96e451e75c52c07741\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145020198\",\"name\":\"L. Gao\"},{\"authorId\":\"30681669\",\"name\":\"Hongjie Jiang\"},{\"authorId\":\"1505461492\",\"name\":\"Kaiming Fu\"},{\"authorId\":\"96084589\",\"name\":\"Weikai He\"}],\"doi\":\"10.1109/BigData47090.2019.9005665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abbeea4bed73047308fee2fdc7fdc16e0f52e134\",\"title\":\"On Understanding Degradation Kinetics of Pharmaceutic Gelatin Matrices for Precision Medicine: A Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/abbeea4bed73047308fee2fdc7fdc16e0f52e134\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":\"2009.04642\",\"authors\":[{\"authorId\":\"49422053\",\"name\":\"Yihao Liu\"},{\"authorId\":\"1604613100\",\"name\":\"Liangbin Xie\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"title\":\"Enhanced Quadratic Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38994280\",\"name\":\"Euihyeok Lee\"},{\"authorId\":\"3028172\",\"name\":\"Seungwoo Kang\"}],\"doi\":\"10.1145/3307334.3328665\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3359d82ee25adaaff0db1bec3e05158b77443ffe\",\"title\":\"Towards the Experience of Daytime Driving at Night (poster)\",\"url\":\"https://www.semanticscholar.org/paper/3359d82ee25adaaff0db1bec3e05158b77443ffe\",\"venue\":\"MobiSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32168317\",\"name\":\"Neerav Karani\"},{\"authorId\":\"145057506\",\"name\":\"C. Tanner\"},{\"authorId\":\"3299349\",\"name\":\"S. Kozerke\"},{\"authorId\":\"1796918\",\"name\":\"E. Konukoglu\"}],\"doi\":\"10.1109/TMI.2018.2831442\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87466fa5073fd3f66ca53a1c8896b5fad406b7c4\",\"title\":\"Reducing Navigators in Free-Breathing Abdominal MRI via Temporal Interpolation Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/87466fa5073fd3f66ca53a1c8896b5fad406b7c4\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2018},{\"arxivId\":\"1905.11271\",\"authors\":[{\"authorId\":\"123205572\",\"name\":\"Julia Navarro\"},{\"authorId\":\"144797921\",\"name\":\"Neus Sabater\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e709d45a0b50516cd04a09619ef6597ec41d225\",\"title\":\"Learning Occlusion-Aware View Synthesis for Light Fields\",\"url\":\"https://www.semanticscholar.org/paper/6e709d45a0b50516cd04a09619ef6597ec41d225\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.08768\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/tpami.2019.2941941\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d833c48334e906537f21757b6f9fa44da66f6c76\",\"title\":\"MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d833c48334e906537f21757b6f9fa44da66f6c76\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"2002.12106\",\"authors\":[{\"authorId\":\"51308376\",\"name\":\"A. Paliwal\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"}],\"doi\":\"10.1109/TPAMI.2020.2987316\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"5c82944c88e0be99857a280d8246593842c515a0\",\"title\":\"Deep Slow Motion Video Reconstruction With Hybrid Imaging System\",\"url\":\"https://www.semanticscholar.org/paper/5c82944c88e0be99857a280d8246593842c515a0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2011.10185\",\"authors\":[{\"authorId\":\"2545360\",\"name\":\"Zhouyong Liu\"},{\"authorId\":\"1996150477\",\"name\":\"Shun Luo\"},{\"authorId\":\"3335945\",\"name\":\"Wubin Li\"},{\"authorId\":\"2027604839\",\"name\":\"Jingben Lu\"},{\"authorId\":\"1390683331\",\"name\":\"Yufan Wu\"},{\"authorId\":\"1726286\",\"name\":\"Chunguo Li\"},{\"authorId\":\"97745176\",\"name\":\"L. Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"43df53137dfaac590600c4c3dfe1fa0f54148774\",\"title\":\"ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/43df53137dfaac590600c4c3dfe1fa0f54148774\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384172999\",\"name\":\"Jiankai Zhuang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1994473526\",\"name\":\"Jialu Chen\"},{\"authorId\":\"153482287\",\"name\":\"Tao Wan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191039\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e3ea880503b53238fa6fcc4e4a1a24c230874999\",\"title\":\"A Lightweight Network Model For Video Frame Interpolation Using Spatial Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/e3ea880503b53238fa6fcc4e4a1a24c230874999\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1441855505\",\"name\":\"Minh-Man Ho\"},{\"authorId\":\"3237233\",\"name\":\"J. Zhou\"},{\"authorId\":\"119905363\",\"name\":\"Yibo Fan\"}],\"doi\":\"10.1145/3359998.3369403\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"313dc9256bd30424c36ac27a70ce75bcb6563021\",\"title\":\"Respecting low-level components of content with skip connections and semantic information in image style transfer\",\"url\":\"https://www.semanticscholar.org/paper/313dc9256bd30424c36ac27a70ce75bcb6563021\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"6615978\",\"name\":\"Yang Zhao\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"}],\"doi\":\"10.1007/978-3-030-58595-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"title\":\"A Flexible Recurrent Residual Pyramid Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.08872\",\"authors\":[{\"authorId\":\"1573986321\",\"name\":\"Liad Pollak Zuckerman\"},{\"authorId\":\"1944189\",\"name\":\"S. Bagon\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1007/978-3-030-58571-6_4\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"02772404c8c6e1903a00798ce01492bc6820f665\",\"title\":\"Across Scales \\\\& Across Dimensions: Temporal Super-Resolution using Deep Internal Learning\",\"url\":\"https://www.semanticscholar.org/paper/02772404c8c6e1903a00798ce01492bc6820f665\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.16078\",\"authors\":[{\"authorId\":\"150022340\",\"name\":\"Aradhya Neeraj Mathur\"},{\"authorId\":\"1658817894\",\"name\":\"Devansh Batra\"},{\"authorId\":\"50793081\",\"name\":\"Y. Kumar\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"1379977554\",\"name\":\"Amanda Stent\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db81ba0c66f00ee9aaa4d1a975567d853724a95c\",\"title\":\"LIFI: Towards Linguistically Informed Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/db81ba0c66f00ee9aaa4d1a975567d853724a95c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.13622\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"39775678\",\"name\":\"O. Gallo\"},{\"authorId\":\"143785523\",\"name\":\"Jinwei Gu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14e1b4b9463bc0e90d774260b57b45eac722e44a\",\"title\":\"Video Stitching for Linear Camera Arrays\",\"url\":\"https://www.semanticscholar.org/paper/14e1b4b9463bc0e90d774260b57b45eac722e44a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1809.10352\",\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"15702255\",\"name\":\"M. Billah\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/GlobalSIP.2018.8646380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b04ee4e92e990519cf0a554862fa111cabf83e3\",\"title\":\"MULTI-VIEW FRAME RECONSTRUCTION WITH CONDITIONAL GAN\",\"url\":\"https://www.semanticscholar.org/paper/6b04ee4e92e990519cf0a554862fa111cabf83e3\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":\"1905.10240\",\"authors\":[{\"authorId\":\"2469811\",\"name\":\"Yunpeng Li\"},{\"authorId\":\"3181733\",\"name\":\"Dominik Roblek\"},{\"authorId\":\"1749128\",\"name\":\"M. Tagliasacchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"063700c45e10362f5642c08849348c41ee5b08a3\",\"title\":\"From Here to There: Video Inbetweening Using Direct 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/063700c45e10362f5642c08849348c41ee5b08a3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.01233\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"48206011\",\"name\":\"Hee-won Kim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152283843\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"1585142097\",\"name\":\"Zhiyong Gaon\"},{\"authorId\":\"2812984\",\"name\":\"G. Chen\"},{\"authorId\":\"7774660\",\"name\":\"Yunhua Lu\"},{\"authorId\":\"46585842\",\"name\":\"R. Duan\"},{\"authorId\":\"150321531\",\"name\":\"Tong Liu\"},{\"authorId\":\"47059427\",\"name\":\"L. Zhang\"},{\"authorId\":\"120878650\",\"name\":\"Woonsung Park\"},{\"authorId\":\"47596916\",\"name\":\"M. Kim\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"104101992\",\"name\":\"L. Aloni\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"116295634\",\"name\":\"Ze Pan\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00421\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3247a8640db63c638a1386493a87202aa2a0b15b\",\"title\":\"AIM 2019 Challenge on Video Temporal Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/3247a8640db63c638a1386493a87202aa2a0b15b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2002.12259\",\"authors\":[{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.00516\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"title\":\"Blurry Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chance Hamilton\"},{\"authorId\":\"6439443\",\"name\":\"J. Ventura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0ca6a22a0b5a2e7ec1544e72a27758a3c790bc2\",\"title\":\"Video Frame Interpolation via Pixel Polynomial Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c0ca6a22a0b5a2e7ec1544e72a27758a3c790bc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2006.00781\",\"authors\":[{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"1693096275\",\"name\":\"Lu Wang\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"47087084\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"28094546\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"88cc19540cd3785ae2225980220bfe8f91dd0015\",\"title\":\"Reducing the X-ray radiation exposure frequency in cardio-angiography via deep-learning based video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88cc19540cd3785ae2225980220bfe8f91dd0015\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"123227163\",\"name\":\"M. Soler\"},{\"authorId\":\"145956252\",\"name\":\"S. Ayache\"},{\"authorId\":\"80777440\",\"name\":\"U. G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"145121526\",\"name\":\"J. Wan\"},{\"authorId\":\"50161696\",\"name\":\"M. Madadi\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"46987321\",\"name\":\"I. Guyon\"}],\"doi\":\"10.1007/978-3-030-25614-2_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c72bb4dc1bf154c79b6a709dbdb26e1b794a6fdc\",\"title\":\"ChaLearn Looking at People: Inpainting and denoising challenges\",\"url\":\"https://www.semanticscholar.org/paper/c72bb4dc1bf154c79b6a709dbdb26e1b794a6fdc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.10298\",\"authors\":[{\"authorId\":\"1902051648\",\"name\":\"Robin Kips\"},{\"authorId\":\"1742163277\",\"name\":\"Pietro Gori\"},{\"authorId\":\"35243423\",\"name\":\"M. Perrot\"},{\"authorId\":\"1695917\",\"name\":\"I. Bloch\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"921bffbcbd9742399f523c0d12ebbd8d2864ac99\",\"title\":\"CA-GAN: Weakly Supervised Color Aware GAN for Controllable Makeup Transfer\",\"url\":\"https://www.semanticscholar.org/paper/921bffbcbd9742399f523c0d12ebbd8d2864ac99\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482675\",\"name\":\"Z. \\u00c1. Milacski\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"32414762\",\"name\":\"A. L\\u00f6rincz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42d7856dc20be6b0b6584ec6ee09d558025150bb\",\"title\":\"VideoOneNet: Bidirectional Convolutional Recurrent OneNet with Trainable Data Steps for Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/42d7856dc20be6b0b6584ec6ee09d558025150bb\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1809.00263\",\"authors\":[{\"authorId\":\"12601304\",\"name\":\"Qiangeng Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Weiyue Wang\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1109/WACV45572.2020.9093530\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"title\":\"Stochastic Dynamics for Video Infilling\",\"url\":\"https://www.semanticscholar.org/paper/56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2008.05084\",\"authors\":[{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"},{\"authorId\":\"92493482\",\"name\":\"M. Alain\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/MMSP48831.2020.9287105\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9456d33164705981170f0bd94ed6c93a1eeb792\",\"title\":\"Self-supervised Light Field View Synthesis Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/b9456d33164705981170f0bd94ed6c93a1eeb792\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1811.11745\",\"authors\":[{\"authorId\":\"145661449\",\"name\":\"T. Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":\"10.1109/CVPR.2019.00700\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c945dfec0137bcd7886898fa61f46705e00173dc\",\"title\":\"Learning to Synthesize Motion Blur\",\"url\":\"https://www.semanticscholar.org/paper/c945dfec0137bcd7886898fa61f46705e00173dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153058038\",\"name\":\"Y. Pan\"},{\"authorId\":\"1382510356\",\"name\":\"Feiyu Zhu\"},{\"authorId\":\"4590999\",\"name\":\"Hongfeng Yu\"}],\"doi\":\"10.1109/BigDataService.2019.00010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0b7d1171fe036913d14cfb87692ceff9b913f0b\",\"title\":\"A Scientific Data Representation Through Particle Flow Based Linear Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e0b7d1171fe036913d14cfb87692ceff9b913f0b\",\"venue\":\"2019 IEEE Fifth International Conference on Big Data Computing Service and Applications (BigDataService)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471436975\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"2257525\",\"name\":\"W. Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"},{\"authorId\":\"104009756\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/ACCESS.2019.2959019\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"title\":\"Video Frame Synthesis via Plug-and-Play Deep Locally Temporal Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"103356373\",\"name\":\"Kunyi Lu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TPAMI.2019.2951667\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64dadf96304f65af96fc6b4f82c11bc69589f547\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/64dadf96304f65af96fc6b4f82c11bc69589f547\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2009.00905\",\"authors\":[{\"authorId\":\"1390858090\",\"name\":\"Sanghun Park\"},{\"authorId\":\"1920243364\",\"name\":\"Kwanggyoon Seo\"},{\"authorId\":\"104115248\",\"name\":\"Jun-yong Noh\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7a1775d0a3ca422314f105c3c9cc341afa9609c2\",\"title\":\"Neural Crossbreed: Neural Based Image Metamorphosis\",\"url\":\"https://www.semanticscholar.org/paper/7a1775d0a3ca422314f105c3c9cc341afa9609c2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2943460\",\"name\":\"Thomas Vandal\"},{\"authorId\":\"153866793\",\"name\":\"R. Nemani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"003ef05f414b2eca59d2a04712138f75b4b4d318\",\"title\":\"Optical Flow for Intermediate Frame Interpolation of Multispectral Geostationary Satellite Data\",\"url\":\"https://www.semanticscholar.org/paper/003ef05f414b2eca59d2a04712138f75b4b4d318\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.09655\",\"authors\":[{\"authorId\":\"145879692\",\"name\":\"E. Logacheva\"},{\"authorId\":\"1956107\",\"name\":\"R. Suvorov\"},{\"authorId\":\"50168812\",\"name\":\"Oleg Khomenko\"},{\"authorId\":\"51995877\",\"name\":\"A. Mashikhin\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7594d6e232599e7f792e416a420a4102435ce631\",\"title\":\"DeepLandscape: Adversarial Modeling of Landscape Video\",\"url\":\"https://www.semanticscholar.org/paper/7594d6e232599e7f792e416a420a4102435ce631\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2003.14030\",\"authors\":[{\"authorId\":\"121670758\",\"name\":\"Fabio Tosi\"},{\"authorId\":\"51169259\",\"name\":\"Filippo Aleotti\"},{\"authorId\":\"80804241\",\"name\":\"Pierluigi Zama Ramirez\"},{\"authorId\":\"2509750\",\"name\":\"M. Poggi\"},{\"authorId\":\"2607607\",\"name\":\"S. Salti\"},{\"authorId\":\"9395079\",\"name\":\"L. Stefano\"},{\"authorId\":\"10261545\",\"name\":\"S. Mattoccia\"}],\"doi\":\"10.1109/CVPR42600.2020.00471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09c008020426c637591c7ce35d49ba5c8e5c2cec\",\"title\":\"Distilled Semantics for Comprehensive Scene Understanding from Videos\",\"url\":\"https://www.semanticscholar.org/paper/09c008020426c637591c7ce35d49ba5c8e5c2cec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1903.00913\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Unsupervised Bi-directional Flow-based Video Generation from one Snapshot\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.12009\",\"authors\":[{\"authorId\":\"2040217564\",\"name\":\"Uugur cCougalan\"},{\"authorId\":\"13267204\",\"name\":\"M. Bemana\"},{\"authorId\":\"1790911\",\"name\":\"K. Myszkowski\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"1759347\",\"name\":\"T. Ritschel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"276b2c7ad623c51287b3db1fabfaaac0bc9ce66b\",\"title\":\"HDR Denoising and Deblurring by Learning Spatio-temporal Distortion Models\",\"url\":\"https://www.semanticscholar.org/paper/276b2c7ad623c51287b3db1fabfaaac0bc9ce66b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.10244\",\"authors\":[{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"3191728\",\"name\":\"T. Chung\"},{\"authorId\":\"48322708\",\"name\":\"D. Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00536\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"title\":\"AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.11616\",\"authors\":[{\"authorId\":\"48147750\",\"name\":\"Xiaoyu Xiang\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"},{\"authorId\":\"1741931\",\"name\":\"J. Allebach\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00343\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"title\":\"Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.07957\",\"authors\":[{\"authorId\":\"49724177\",\"name\":\"Hao-Tian Zhang\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"1680236\",\"name\":\"J. Collomosse\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/ICCV.2019.00281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"title\":\"An Internal Learning Approach to Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ccbb652bca1b5f795333c7dc148ad2f01caf9e35\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"},{\"authorId\":\"92733026\",\"name\":\"Soon-chul Kwon\"},{\"authorId\":\"1773696\",\"name\":\"Ji-Sang Yoo\"}],\"doi\":\"10.3390/sym11101251\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"title\":\"A Fast 4K Video Frame Interpolation Using a Multi-Scale Optical Flow Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8344be8d1417ed53b8ffea3af7061ce91d68321\",\"title\":\"Supplementary Material for Disentangling Propagation and Generation for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c8344be8d1417ed53b8ffea3af7061ce91d68321\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486417554\",\"name\":\"Ren-Yu Tseng\"},{\"authorId\":\"1604961801\",\"name\":\"Yao-Kai Liu\"},{\"authorId\":\"37284667\",\"name\":\"Ju-Chin Chen\"},{\"authorId\":\"21754565\",\"name\":\"Kawuu W. Lin\"}],\"doi\":\"10.1109/TAAI48200.2019.8959822\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"title\":\"Adaptive Frame Interpolation using an End-to-End Deep Net with High Quality Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"venue\":\"2019 International Conference on Technologies and Applications of Arti\\ufb01cial Intelligence (TAAI)\",\"year\":2019},{\"arxivId\":\"2005.06684\",\"authors\":[{\"authorId\":\"31265269\",\"name\":\"R. Saha\"},{\"authorId\":\"1696513867\",\"name\":\"Abenezer Teklemariam\"},{\"authorId\":\"39007058\",\"name\":\"Ian Hsu\"},{\"authorId\":\"145497462\",\"name\":\"A. Moses\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"52a0df13066799d8774408fb576bb07802789764\",\"title\":\"W-Cell-Net: Multi-frame Interpolation of Cellular Microscopy Videos\",\"url\":\"https://www.semanticscholar.org/paper/52a0df13066799d8774408fb576bb07802789764\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49522643\",\"name\":\"Rei Narita\"},{\"authorId\":\"1684365\",\"name\":\"K. Hirakawa\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"}],\"doi\":\"10.1109/ICIP.2019.8803506\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43d5ef1d4737a1da4ad3dbacd9c243186913eee0\",\"title\":\"Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings\",\"url\":\"https://www.semanticscholar.org/paper/43d5ef1d4737a1da4ad3dbacd9c243186913eee0\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2009.00382\",\"authors\":[{\"authorId\":\"1388671682\",\"name\":\"Tomoki Yoshida\"},{\"authorId\":\"38957626\",\"name\":\"K. Akita\"},{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1119cd6e63dcde287af9e6098144456fab649400\",\"title\":\"Image Super-Resolution using Explicit Perceptual Loss\",\"url\":\"https://www.semanticscholar.org/paper/1119cd6e63dcde287af9e6098144456fab649400\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.10680\",\"authors\":[{\"authorId\":\"49473017\",\"name\":\"Zhihao Shi\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"153250595\",\"name\":\"K. Shi\"},{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"title\":\"Video Interpolation via Generalized Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48017049\",\"name\":\"H. Wang\"},{\"authorId\":\"6972447\",\"name\":\"J. Feng\"},{\"authorId\":\"34992655\",\"name\":\"Xiaoying Pan\"},{\"authorId\":\"49262921\",\"name\":\"Di Yang\"},{\"authorId\":\"2076082\",\"name\":\"B. Chen\"}],\"doi\":\"10.1007/978-3-030-59520-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5069481d745621baada82174981c5194f22b9d1b\",\"title\":\"High-Quality Interpolation of Breast DCE-MRI Using Learned Transformations\",\"url\":\"https://www.semanticscholar.org/paper/5069481d745621baada82174981c5194f22b9d1b\",\"venue\":\"SASHIMI@MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"}],\"doi\":\"10.1109/ICME.2019.00040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e64ee0308d0223ce0ff06d071dd6c628baf2e9fc\",\"title\":\"MAST: Mask-Accelerated Shearlet Transform for Densely-Sampled Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/e64ee0308d0223ce0ff06d071dd6c628baf2e9fc\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1912.03095\",\"authors\":[{\"authorId\":\"51152279\",\"name\":\"Daniel Gehrig\"},{\"authorId\":\"8329387\",\"name\":\"M. Gehrig\"},{\"authorId\":\"1406402485\",\"name\":\"Javier Hidalgo-Carri'o\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":\"10.1109/cvpr42600.2020.00364\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d6d6f121e8dd049b1dee993599123c3e9852d07\",\"title\":\"Video to Events: Recycling Video Datasets for Event Cameras\",\"url\":\"https://www.semanticscholar.org/paper/7d6d6f121e8dd049b1dee993599123c3e9852d07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1902.04394\",\"authors\":[{\"authorId\":\"1573439731\",\"name\":\"Alex Bauerle\"},{\"authorId\":\"51262596\",\"name\":\"Christian van van Onzenoodt\"},{\"authorId\":\"1703058\",\"name\":\"T. Ropinski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65c90fc43814c3eb9412fc133610c571d96de9a4\",\"title\":\"Net2Vis -- A Visual Grammar for Automatically Generating Publication-Ready CNN Architecture Visualizations\",\"url\":\"https://www.semanticscholar.org/paper/65c90fc43814c3eb9412fc133610c571d96de9a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31488832\",\"name\":\"F. Yang\"},{\"authorId\":\"2028675326\",\"name\":\"Daniel Thalmann \\u00b7 Weiwei Xu\"},{\"authorId\":\"38465624\",\"name\":\"J. Zhang\"},{\"authorId\":\"1713611\",\"name\":\"J. Filipe\"},{\"authorId\":\"17324395\",\"name\":\"A. Ghosh\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"1557327513\",\"name\":\"Feng Tian\"},{\"authorId\":\"1820892609\",\"name\":\"Xiaosong Yang\"},{\"authorId\":\"1689760\",\"name\":\"D. Thalmann\"},{\"authorId\":\"1684883672\",\"name\":\"Weiwei Xu\"},{\"authorId\":\"66023109\",\"name\":\"N. M. Thalmann\"},{\"authorId\":\"144891213\",\"name\":\"J. Chang\"}],\"doi\":\"10.1007/978-3-030-63426-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a4ff80f2b5f466fcb92dbbf6d365e497d03093b\",\"title\":\"Computer Animation and Social Agents: 33rd International Conference on Computer Animation and Social Agents, CASA 2020, Bournemouth, UK, October 13-15, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/2a4ff80f2b5f466fcb92dbbf6d365e497d03093b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02432\",\"authors\":[{\"authorId\":\"2784241\",\"name\":\"Jaeyeon Kang\"},{\"authorId\":\"50008226\",\"name\":\"Younghyun Jo\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-58607-2_41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"title\":\"Deep Space-Time Video Upsampling Networks\",\"url\":\"https://www.semanticscholar.org/paper/fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.06102\",\"authors\":[{\"authorId\":\"1727193\",\"name\":\"V. Rengarajan\"},{\"authorId\":\"144520001\",\"name\":\"S. Zhao\"},{\"authorId\":\"2796634\",\"name\":\"Ruiwen Zhen\"},{\"authorId\":\"15303210\",\"name\":\"J. Glotzbach\"},{\"authorId\":\"2387140\",\"name\":\"H. Sheikh\"},{\"authorId\":\"1745861\",\"name\":\"Aswin C. Sankaranarayanan\"}],\"doi\":\"10.1109/CVPRW50498.2020.00263\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0465eea84313ef76d897272c627dc8fa6b05bbfd\",\"title\":\"Photosequencing of Motion Blur using Short and Long Exposures\",\"url\":\"https://www.semanticscholar.org/paper/0465eea84313ef76d897272c627dc8fa6b05bbfd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1904.06903\",\"authors\":[{\"authorId\":\"2291143\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"2692368\",\"name\":\"Muchen Li\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c29e8379f11afe7a5f4e4cde03ebea08a2420af8\",\"title\":\"Learning Deformable Kernels for Image and Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/c29e8379f11afe7a5f4e4cde03ebea08a2420af8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144796690\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"title\":\"High-speed Video from Asynchronous Camera Array Si\",\"url\":\"https://www.semanticscholar.org/paper/1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2679394\",\"name\":\"Tim Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a42e4c2b70a74b9315c1c19f0d4a7993c0727fcf\",\"title\":\"Learning to Synthesize Motion Blur Supplement\",\"url\":\"https://www.semanticscholar.org/paper/a42e4c2b70a74b9315c1c19f0d4a7993c0727fcf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51152279\",\"name\":\"Daniel Gehrig\"},{\"authorId\":\"8329387\",\"name\":\"M. Gehrig\"},{\"authorId\":\"1406402485\",\"name\":\"Javier Hidalgo-Carri'o\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f877010d390ea6ab73608637ba1f0865ba066f12\",\"title\":\"Video to Events: Bringing Modern Computer Vision Closer to Event Cameras\",\"url\":\"https://www.semanticscholar.org/paper/f877010d390ea6ab73608637ba1f0865ba066f12\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557382867\",\"name\":\"Siyao Li\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"98350705\",\"name\":\"Z. Pan\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":\"10.1109/ICCVW.2019.00425\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"title\":\"Quadratic Video Interpolation for VTSR Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153269936\",\"name\":\"J. Xiao\"},{\"authorId\":\"49997317\",\"name\":\"Xiaojun Bi\"}],\"doi\":\"10.1109/ACCESS.2020.2995705\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"title\":\"Multi-Scale Attention Generative Adversarial Networks for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1909.13051\",\"authors\":[{\"authorId\":\"143657783\",\"name\":\"M. Cheng\"},{\"authorId\":\"152986975\",\"name\":\"Z. Ma\"},{\"authorId\":\"27996204\",\"name\":\"M. Asif\"},{\"authorId\":\"1800270\",\"name\":\"Y. Xu\"},{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"48480375\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2020.2983371\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c15f40465508aebd351640817ea04cbb881c28e6\",\"title\":\"A Dual Camera System for High Spatiotemporal Resolution Video Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/c15f40465508aebd351640817ea04cbb881c28e6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"}],\"doi\":\"10.15496/PUBLIKATION-4524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3d7ebfa0199d7d49f4ca95b80fa136aafb43b88\",\"title\":\"Towards Geometric Understanding of Motion\",\"url\":\"https://www.semanticscholar.org/paper/c3d7ebfa0199d7d49f4ca95b80fa136aafb43b88\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.10052\",\"authors\":[{\"authorId\":\"71834567\",\"name\":\"S. Anupama\"},{\"authorId\":\"14925412\",\"name\":\"Prasan A. Shedligeri\"},{\"authorId\":\"47178809\",\"name\":\"A. Pal\"},{\"authorId\":\"1879114299\",\"name\":\"Kaushik Mitra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bd9a9105192f08430f2a42adbd4e5cacbd24c07\",\"title\":\"Video Reconstruction by Spatio-Temporal Fusion of Blurred-Coded Image Pair\",\"url\":\"https://www.semanticscholar.org/paper/8bd9a9105192f08430f2a42adbd4e5cacbd24c07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1961467739\",\"name\":\"M. Tseng\"},{\"authorId\":\"2007619711\",\"name\":\"Yen-Chung Chen\"},{\"authorId\":\"1959578097\",\"name\":\"Yi-Lun Lee\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"title\":\"Dual-Stream Fusion Network for Spatiotemporal Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"venue\":\"\",\"year\":2020}],\"corpusId\":10817557,\"doi\":\"10.1109/CVPR.2018.00938\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":64,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Delbracio\"},{\"authorId\":null,\"name\":\"J. Wang\"},{\"authorId\":null,\"name\":\"G. Sapiro\"},{\"authorId\":null,\"name\":\"W. Heidrich\"},{\"authorId\":null,\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deep video deblurring Learning optical flow\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15808204\",\"name\":\"J. L. Barron\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"46818737\",\"name\":\"S. Beauchemin\"}],\"doi\":\"10.1007/BF01420984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"400f4afb2a055d95483d83c4bedab10281a8639d\",\"title\":\"Performance of optical flow techniques\",\"url\":\"https://www.semanticscholar.org/paper/400f4afb2a055d95483d83c4bedab10281a8639d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805741\",\"name\":\"F. Zhang\"},{\"authorId\":\"2779420\",\"name\":\"Shibiao Xu\"},{\"authorId\":\"21458018\",\"name\":\"Xiaopeng Zhang\"}],\"doi\":\"10.1007/s11042-020-08633-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c44f679d0c095446711e06a6b08ce263455c72ea\",\"title\":\"High accuracy correspondence field estimation via MST based patch matching\",\"url\":\"https://www.semanticscholar.org/paper/c44f679d0c095446711e06a6b08ce263455c72ea\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2469811\",\"name\":\"Yunpeng Li\"},{\"authorId\":\"1713089\",\"name\":\"D. Huttenlocher\"}],\"doi\":\"10.1007/978-3-540-88688-4_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"845cdefd119f5c9afc79dee410d74885595959b4\",\"title\":\"Learning for Optical Flow Using Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/845cdefd119f5c9afc79dee410d74885595959b4\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143814637\",\"name\":\"B. Horn\"},{\"authorId\":\"1717435\",\"name\":\"B. Schunck\"}],\"doi\":\"10.1016/0004-3702(81)90024-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbe9176abf0c98c7abdfd136f53d58620f8acfec\",\"title\":\"Determining Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/cbe9176abf0c98c7abdfd136f53d58620f8acfec\",\"venue\":\"Artif. Intell.\",\"year\":1981},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"},{\"authorId\":\"37108776\",\"name\":\"Philip Lenz\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2012.6248074\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42\",\"title\":\"Are we ready for autonomous driving? The KITTI vision benchmark suite\",\"url\":\"https://www.semanticscholar.org/paper/de5b0fd02ea4f4d67fe3ae0d74603b9822df4e42\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"37021642\",\"name\":\"F. Huang\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"}],\"doi\":\"10.1145/1576246.1531348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"title\":\"Moving gradients: a path-based method for plausible image interpolation\",\"url\":\"https://www.semanticscholar.org/paper/d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"venue\":\"SIGGRAPH '09\",\"year\":2009},{\"arxivId\":\"1611.08387\",\"authors\":[{\"authorId\":\"1758739\",\"name\":\"Shuochen Su\"},{\"authorId\":\"2346590\",\"name\":\"M. Delbracio\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"},{\"authorId\":\"1752192\",\"name\":\"W. Heidrich\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2bfd90a12fcb363ff32087459c93541c2e47faa7\",\"title\":\"Deep Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/2bfd90a12fcb363ff32087459c93541c2e47faa7\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/s11263-006-0016-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a15488466ee9d465e5caf739b4b035d2b8dda197\",\"title\":\"On the Spatial Statistics of Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/a15488466ee9d465e5caf739b4b035d2b8dda197\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10678970\",\"name\":\"Joel Janai\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1109/CVPR.2017.154\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8bd59b6111c21ca9f133b2ac9f0a8b102e344076\",\"title\":\"Slow Flow: Exploiting High-Speed Cameras for Accurate and Diverse Optical Flow Reference Data\",\"url\":\"https://www.semanticscholar.org/paper/8bd59b6111c21ca9f133b2ac9f0a8b102e344076\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.01352\",\"authors\":[{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.731\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"857bc1f10bbfb5ff340230114d5c30bcf2224d1c\",\"title\":\"Optical Flow in Mostly Rigid Scenes\",\"url\":\"https://www.semanticscholar.org/paper/857bc1f10bbfb5ff340230114d5c30bcf2224d1c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1511.06309\",\"authors\":[{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"},{\"authorId\":\"34653454\",\"name\":\"A. Handa\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"title\":\"Spatio-temporal video autoencoder with differentiable memory\",\"url\":\"https://www.semanticscholar.org/paper/b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.05842\",\"authors\":[{\"authorId\":\"97583830\",\"name\":\"J. J. Yu\"},{\"authorId\":\"34939798\",\"name\":\"Adam W. Harley\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"}],\"doi\":\"10.1007/978-3-319-49409-8_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"375b6972d4185ce275dcad51581c9bbb03fb3f4f\",\"title\":\"Back to Basics: Unsupervised Learning of Optical Flow via Brightness Constancy and Motion Smoothness\",\"url\":\"https://www.semanticscholar.org/paper/375b6972d4185ce275dcad51581c9bbb03fb3f4f\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-540-88690-7_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad61eebde119131f845dc902e1c8f7a4c6d66233\",\"title\":\"Learning Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/ad61eebde119131f845dc902e1c8f7a4c6d66233\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.04597\",\"authors\":[{\"authorId\":\"1737326\",\"name\":\"O. Ronneberger\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-24574-4_28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"title\":\"U-Net: Convolutional Networks for Biomedical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6364fdaa0a0eccd823a779fcdd489173f938e91a\",\"venue\":\"MICCAI\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1501.02565\",\"authors\":[{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2015.7298720\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"title\":\"EpicFlow: Edge-preserving interpolation of correspondences for optical flow\",\"url\":\"https://www.semanticscholar.org/paper/f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/TPAMI.2010.143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"title\":\"Large Displacement Optical Flow: Descriptor Matching in Variational Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ffd97ed7408fa75b86d4c8e4280f8d730ffa2cf0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2086328\",\"name\":\"Christoph Rhemann\"},{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"1990797\",\"name\":\"M. Gelautz\"},{\"authorId\":\"143967473\",\"name\":\"Pushmeet Kohli\"},{\"authorId\":\"37701201\",\"name\":\"P. Rott\"}],\"doi\":\"10.1109/cvprw.2009.5206503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c24a5acb52c81acadb0ba76e0da270e10ad6eca\",\"title\":\"A perceptually motivated online benchmark for image matting\",\"url\":\"https://www.semanticscholar.org/paper/2c24a5acb52c81acadb0ba76e0da270e10ad6eca\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"}],\"doi\":\"10.1109/TPAMI.2011.236\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"title\":\"Motion Detail Preserving Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6376655\",\"name\":\"E. Herbst\"},{\"authorId\":\"116149486\",\"name\":\"S. Seitz\"},{\"authorId\":\"145347688\",\"name\":\"S. Baker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d41b37c103e3a09f327f28fac6ce18680f3b068e\",\"title\":\"Occlusion Reasoning for Temporal Interpolation using Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/d41b37c103e3a09f327f28fac6ce18680f3b068e\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1709.02371\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00931\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"title\":\"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1705.02997\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1145/3072959.3073614\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"614bf8b9ffbf564c8cf66f5b9837c1d13322ee02\",\"title\":\"Light field video capture using a learning-based hybrid imaging system\",\"url\":\"https://www.semanticscholar.org/paper/614bf8b9ffbf564c8cf66f5b9837c1d13322ee02\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.194\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1109/ICCV.1999.790301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5a42788e0ffcf73f59cdc1f8eca5144f4054c43\",\"title\":\"Prediction error as a quality metric for motion and stereo\",\"url\":\"https://www.semanticscholar.org/paper/b5a42788e0ffcf73f59cdc1f8eca5144f4054c43\",\"venue\":\"Proceedings of the Seventh IEEE International Conference on Computer Vision\",\"year\":1999},{\"arxivId\":\"1704.07325\",\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"2774325\",\"name\":\"Ren\\u00e9 Ranftl\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/CVPR.2017.615\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"143e10cae07f27f2db9de171eb04a332ddbfeab4\",\"title\":\"Accurate Optical Flow via Direct Cost Volume Processing\",\"url\":\"https://www.semanticscholar.org/paper/143e10cae07f27f2db9de171eb04a332ddbfeab4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}],\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"topics\":[{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Approximation algorithm\",\"topicId\":\"87\",\"url\":\"https://www.semanticscholar.org/topic/87\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Frame (video)\",\"topicId\":\"4108263\",\"url\":\"https://www.semanticscholar.org/topic/4108263\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Jumbo frame\",\"topicId\":\"1265749\",\"url\":\"https://www.semanticscholar.org/topic/1265749\"},{\"topic\":\"Frame language\",\"topicId\":\"224664\",\"url\":\"https://www.semanticscholar.org/topic/224664\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Coherence (physics)\",\"topicId\":\"921\",\"url\":\"https://www.semanticscholar.org/topic/921\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"YANG\",\"topicId\":\"811002\",\"url\":\"https://www.semanticscholar.org/topic/811002\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"