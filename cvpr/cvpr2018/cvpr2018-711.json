"{\"abstract\":\"This paper addresses a new problem - jointly inferring human attention, intentions, and tasks from videos. Given an RGB-D video where a human performs a task, we answer three questions simultaneously: 1) where the human is looking - attention prediction; 2) why the human is looking there - intention prediction; and 3) what task the human is performing - task recognition. We propose a hierarchical model of human-attention-object (HAO) which represents tasks, intentions, and attention under a unified framework. A task is represented as sequential intentions which transition to each other. An intention is composed of the human pose, attention, and objects. A beam search algorithm is adopted for inference on the HAO graph to output the attention, intention, and task results. We built a new video dataset of tasks, intentions, and attention. It contains 14 task classes, 70 intention categories, 28 object classes, 809 videos, and approximately 330,000 frames. Experiments show that our approach outperforms existing approaches.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"145708707\",\"name\":\"P. Wei\",\"url\":\"https://www.semanticscholar.org/author/145708707\"},{\"authorId\":\"46179714\",\"name\":\"Y. Liu\",\"url\":\"https://www.semanticscholar.org/author/46179714\"},{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\",\"url\":\"https://www.semanticscholar.org/author/1844358\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\",\"url\":\"https://www.semanticscholar.org/author/145608731\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\",\"url\":\"https://www.semanticscholar.org/author/145380991\"}],\"citationVelocity\":5,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"22415364\",\"name\":\"Chaoran Huang\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"}],\"doi\":\"10.1007/978-3-030-63833-7_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8907a5514ef818b9b3f46f61855bc18d19b79dfe\",\"title\":\"Active Object Estimation for Human-Robot Collaborative Tasks\",\"url\":\"https://www.semanticscholar.org/paper/8907a5514ef818b9b3f46f61855bc18d19b79dfe\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1902.10953\",\"authors\":[{\"authorId\":\"51441396\",\"name\":\"B. Mass\\u00e9\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"2793152\",\"name\":\"Pablo Mesejo\"},{\"authorId\":\"1794229\",\"name\":\"R. Horaud\"}],\"doi\":\"10.1109/FG.2019.8756555\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c018c6d80b0dbcc8fcc64b8dcf2b46f785184da7\",\"title\":\"Extended Gaze Following: Detecting Objects in Videos Beyond the Camera Field of View\",\"url\":\"https://www.semanticscholar.org/paper/c018c6d80b0dbcc8fcc64b8dcf2b46f785184da7\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31377493\",\"name\":\"J. Cui\"},{\"authorId\":\"121866012\",\"name\":\"G. Liu\"},{\"authorId\":\"48813128\",\"name\":\"Z. Jia\"},{\"authorId\":\"30798713\",\"name\":\"M. Qi\"},{\"authorId\":\"144983709\",\"name\":\"M. Tang\"}],\"doi\":\"10.1109/ACCESS.2019.2946695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0095a3d8ddd65a63ae5967a6ab98866860d68a1\",\"title\":\"Similar Visual Complexity Analysis Model Based on Subjective Perception\",\"url\":\"https://www.semanticscholar.org/paper/f0095a3d8ddd65a63ae5967a6ab98866860d68a1\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2011.06219\",\"authors\":[{\"authorId\":\"2008850512\",\"name\":\"Stuart Synakowski\"},{\"authorId\":\"145972081\",\"name\":\"Q. Feng\"},{\"authorId\":\"145358414\",\"name\":\"A. Mart\\u00ednez\"}],\"doi\":\"10.1007/s11263-020-01404-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"461e5c60e3ea892731b59d724d294824c8792649\",\"title\":\"Adding Knowledge to Unsupervised Algorithms for the Recognition of Intent\",\"url\":\"https://www.semanticscholar.org/paper/461e5c60e3ea892731b59d724d294824c8792649\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.09796\",\"authors\":[{\"authorId\":\"144350809\",\"name\":\"Bingjie Xu\"},{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TMM.2019.2943753\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"40c1aec7e0830bf9dd8a689d671024567311ae72\",\"title\":\"Interact as You Intend: Intention-Driven Human-Object Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/40c1aec7e0830bf9dd8a689d671024567311ae72\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153825264\",\"name\":\"Tao Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e38114f470f09fadeac4e9e403fb3b1a9e9e940\",\"title\":\"A Cognition Platform for Joint Inference of 3D Geometry, Object States, and Human Belief\",\"url\":\"https://www.semanticscholar.org/paper/4e38114f470f09fadeac4e9e403fb3b1a9e9e940\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.12248\",\"authors\":[{\"authorId\":\"153825264\",\"name\":\"Tao Yuan\"},{\"authorId\":\"3440176\",\"name\":\"H. Liu\"},{\"authorId\":\"3041430\",\"name\":\"Li-Feng Fan\"},{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"144792423\",\"name\":\"Tao Gao\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICRA40945.2020.9197355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fe09c145752ba8707991a782e4e945a0267712a\",\"title\":\"Joint Inference of States, Robot Knowledge, and Human (False-)Beliefs\",\"url\":\"https://www.semanticscholar.org/paper/2fe09c145752ba8707991a782e4e945a0267712a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"}],\"doi\":\"10.1109/ICIP.2019.8803155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1069d9cc11006078dfb9ed76bc2c44379ae325f\",\"title\":\"Help by Predicting What to Do\",\"url\":\"https://www.semanticscholar.org/paper/c1069d9cc11006078dfb9ed76bc2c44379ae325f\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2002.08945\",\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"51257737\",\"name\":\"Abhijeet Shenoi\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/LRA.2020.2976305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a6196e1c2e0da3f63f600f10f8d6eaa8c9051ac\",\"title\":\"Spatiotemporal Relationship Reasoning for Pedestrian Intent Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8a6196e1c2e0da3f63f600f10f8d6eaa8c9051ac\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2007.12656\",\"authors\":[{\"authorId\":\"27883493\",\"name\":\"Shuwen Qiu\"},{\"authorId\":\"3440176\",\"name\":\"H. Liu\"},{\"authorId\":\"48805947\",\"name\":\"Zeyu Zhang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6203c7daaeb10e9b9c66e67b42320625710a338a\",\"title\":\"Human-Robot Interaction in a Shared Augmented Reality Workspace\",\"url\":\"https://www.semanticscholar.org/paper/6203c7daaeb10e9b9c66e67b42320625710a338a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008177645\",\"name\":\"Hisashi Kamezawa\"},{\"authorId\":\"8058716\",\"name\":\"Noriki Nishida\"},{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"47615106\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88288c5ebea5da91bb699ec0cd2d9806f06955c1\",\"title\":\"A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses\",\"url\":\"https://www.semanticscholar.org/paper/88288c5ebea5da91bb699ec0cd2d9806f06955c1\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.02501\",\"authors\":[{\"authorId\":\"39832600\",\"name\":\"E. Chong\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/cvpr42600.2020.00544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95bdf80c6d53003374694eea9707a1d20ac93195\",\"title\":\"Detecting Attended Visual Targets in Video\",\"url\":\"https://www.semanticscholar.org/paper/95bdf80c6d53003374694eea9707a1d20ac93195\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410010039\",\"name\":\"Hao Zhao\"},{\"authorId\":\"123554573\",\"name\":\"M. Lu\"},{\"authorId\":\"1405606408\",\"name\":\"Anbang Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"48571207\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s11263-019-01263-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"title\":\"Learning to Draw Sight Lines\",\"url\":\"https://www.semanticscholar.org/paper/5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51904472\",\"name\":\"Riccardo Bovo\"},{\"authorId\":\"5950074\",\"name\":\"Nicola Binetti\"},{\"authorId\":\"144958736\",\"name\":\"D. Brumby\"},{\"authorId\":\"1751475\",\"name\":\"S. Julier\"}],\"doi\":\"10.1145/3377325.3377497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9181a6645fd09bcd2ab073aea32e273a3f0f5a\",\"title\":\"Detecting errors in pick and place procedures: detecting errors in multi-stage and sequence-constrained manual retrieve-assembly procedures\",\"url\":\"https://www.semanticscholar.org/paper/fe9181a6645fd09bcd2ab073aea32e273a3f0f5a\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":\"2004.09044\",\"authors\":[{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"144792423\",\"name\":\"Tao Gao\"},{\"authorId\":\"3041430\",\"name\":\"Li-Feng Fan\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"37156109\",\"name\":\"Mark Edmonds\"},{\"authorId\":\"3440176\",\"name\":\"H. Liu\"},{\"authorId\":\"144516508\",\"name\":\"Feng Gao\"},{\"authorId\":\"145657495\",\"name\":\"Chi Zhang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1016/j.eng.2020.01.011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"862bca372c0c7475f9e5eb4951b9309f39cd4ace\",\"title\":\"Dark, Beyond Deep: A Paradigm Shift to Cognitive AI with Humanlike Common Sense\",\"url\":\"https://www.semanticscholar.org/paper/862bca372c0c7475f9e5eb4951b9309f39cd4ace\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":4569601,\"doi\":\"10.1109/CVPR.2018.00711\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"07098ec7f9b66ddeb21314fd3630a9e45decdd4e\",\"references\":[{\"arxivId\":\"1504.02863\",\"authors\":[{\"authorId\":\"2520795\",\"name\":\"Xucong Zhang\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1109/CVPR.2015.7299081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f29d9fb0c713397daf8a09b53153a4ffbf41f1fb\",\"title\":\"Appearance-based gaze estimation in the wild\",\"url\":\"https://www.semanticscholar.org/paper/f29d9fb0c713397daf8a09b53153a4ffbf41f1fb\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"title\":\"Probabilistic learning of task-specific visual attention\",\"url\":\"https://www.semanticscholar.org/paper/6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3298395\",\"name\":\"M. S. Arulampalam\"},{\"authorId\":\"1731320\",\"name\":\"S. Maskell\"},{\"authorId\":\"144998829\",\"name\":\"N. Gordon\"},{\"authorId\":\"40294077\",\"name\":\"T. Clapp\"}],\"doi\":\"10.1109/78.978374\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"763493cf694f3a7365c02676c139ee01cbac30b9\",\"title\":\"A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking\",\"url\":\"https://www.semanticscholar.org/paper/763493cf694f3a7365c02676c139ee01cbac30b9\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2901441\",\"name\":\"A. Belardinelli\"},{\"authorId\":\"2979998\",\"name\":\"O. Herbort\"},{\"authorId\":\"1732540\",\"name\":\"M. Butz\"}],\"doi\":\"10.1016/j.visres.2014.11.003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b66893f732d922e78dc69c47afe1f61fdaa00d88\",\"title\":\"Goal-oriented gaze strategies afforded by object interaction\",\"url\":\"https://www.semanticscholar.org/paper/b66893f732d922e78dc69c47afe1f61fdaa00d88\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2331345\",\"name\":\"L. Jeni\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"}],\"doi\":\"10.1109/CVPRW.2016.104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3146fabd5631a7d1387327918b184103d06c2211\",\"title\":\"Person-Independent 3D Gaze Estimation Using Face Frontalization\",\"url\":\"https://www.semanticscholar.org/paper/3146fabd5631a7d1387327918b184103d06c2211\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"4781463\",\"name\":\"Deniz Oktay\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.327\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03c48850373b40f32b2bc0b1fbf7c13ccf0c8063\",\"title\":\"Predicting Motivations of Actions by Leveraging Text\",\"url\":\"https://www.semanticscholar.org/paper/03c48850373b40f32b2bc0b1fbf7c13ccf0c8063\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138933\",\"name\":\"H. Ravichandar\"},{\"authorId\":\"50333339\",\"name\":\"A. Kumar\"},{\"authorId\":\"1729843\",\"name\":\"Ashwin P. Dani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0696f3fe4435aae6765d0ae82844c2f40f76f07d\",\"title\":\"Bayesian human intention inference through multiple model filtering with gaze-based priors\",\"url\":\"https://www.semanticscholar.org/paper/0696f3fe4435aae6765d0ae82844c2f40f76f07d\",\"venue\":\"2016 19th International Conference on Information Fusion (FUSION)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2836466\",\"name\":\"L. Smith\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1056c2c39ea32b3f9d77998758083353b1c3d287\",\"title\":\"Linking Joint Attention with Hand-Eye Coordination - A Sensorimotor Approach to Understanding Child-Parent Social Interaction\",\"url\":\"https://www.semanticscholar.org/paper/1056c2c39ea32b3f9d77998758083353b1c3d287\",\"venue\":\"CogSci\",\"year\":2015},{\"arxivId\":\"1601.02644\",\"authors\":[{\"authorId\":\"2990756\",\"name\":\"M. Mansouryar\"},{\"authorId\":\"2920056\",\"name\":\"Julian Steil\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/2857491.2857530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db165f1d59d20097616838219ba931104cff54b2\",\"title\":\"3D gaze estimation from 2D pupil positions on monocular head-mounted eye trackers\",\"url\":\"https://www.semanticscholar.org/paper/db165f1d59d20097616838219ba931104cff54b2\",\"venue\":\"ETRA\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143612308\",\"name\":\"D. Parks\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1016/j.visres.2014.10.027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de133b03624e91db8861ca94f075998dc26259ee\",\"title\":\"Augmented saliency model using automatic 3D head pose detection and learned gaze following in natural scenes\",\"url\":\"https://www.semanticscholar.org/paper/de133b03624e91db8861ca94f075998dc26259ee\",\"venue\":\"Vision Research\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2899726\",\"name\":\"J. Pelz\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"},{\"authorId\":\"32259738\",\"name\":\"R. Loeber\"}],\"doi\":\"10.1007/s002210100745\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0555b0aded41322a34e8d1be6dfdedd3f6501091\",\"title\":\"The coordination of eye, head, and hand movements in a natural task\",\"url\":\"https://www.semanticscholar.org/paper/0555b0aded41322a34e8d1be6dfdedd3f6501091\",\"venue\":\"Experimental Brain Research\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2017.318\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"414c85e333a24456a3bb5b194d97e95e69175dea\",\"title\":\"Jointly Recognizing Object Fluents and Tasks in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/414c85e333a24456a3bb5b194d97e95e69175dea\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145491223\",\"name\":\"Pieter Moors\"},{\"authorId\":\"6879357\",\"name\":\"F. Germeys\"},{\"authorId\":\"4036542\",\"name\":\"I. Pomianowska\"},{\"authorId\":\"6691817\",\"name\":\"K. Verfaillie\"}],\"doi\":\"10.3389/fpsyg.2015.00909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95cbcda53b4072418b5d3128629e1ef46a72248f\",\"title\":\"Perceiving where another person is looking: the integration of head and body information in estimating another person\\u2019s gaze\",\"url\":\"https://www.semanticscholar.org/paper/95cbcda53b4072418b5d3128629e1ef46a72248f\",\"venue\":\"Front. Psychol.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40466012\",\"name\":\"M. Land\"},{\"authorId\":\"145491204\",\"name\":\"N. Mennie\"},{\"authorId\":\"48874150\",\"name\":\"J. Rusted\"}],\"doi\":\"10.1068/p2935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1af1ada3d7232a1bb9b8bdc7e29fb5842dacf033\",\"title\":\"The Roles of Vision and Eye Movements in the Control of Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/1af1ada3d7232a1bb9b8bdc7e29fb5842dacf033\",\"venue\":\"Perception\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9206411\",\"name\":\"K. Mora\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1007/s11263-015-0863-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d53493916cdf49ba29aebef955ab6b32a05762f\",\"title\":\"Gaze Estimation in the 3D Space Using RGB-D Sensors\",\"url\":\"https://www.semanticscholar.org/paper/3d53493916cdf49ba29aebef955ab6b32a05762f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1611.09819\",\"authors\":[{\"authorId\":\"38872009\",\"name\":\"Daniel Harari\"},{\"authorId\":\"48753544\",\"name\":\"T. Gao\"},{\"authorId\":\"1931482\",\"name\":\"N. Kanwisher\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fc730d22f33d08be927e5449f359dc15b5c3503\",\"title\":\"Measuring and modeling the perception of natural and unconstrained gaze in humans and machines\",\"url\":\"https://www.semanticscholar.org/paper/8fc730d22f33d08be927e5449f359dc15b5c3503\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"},{\"authorId\":\"38872009\",\"name\":\"Daniel Harari\"},{\"authorId\":\"145364369\",\"name\":\"N. Dorfman\"}],\"doi\":\"10.1073/pnas.1207690109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb139c7bb8dc024cdcd1f4b8caac9384a985b17f\",\"title\":\"From simple innate biases to complex visual concepts\",\"url\":\"https://www.semanticscholar.org/paper/cb139c7bb8dc024cdcd1f4b8caac9384a985b17f\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923920\",\"name\":\"B. Scholl\"}],\"doi\":\"10.1016/S0010-0277(00)00152-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e32be6db00da2d6ea9ff2be0482abac4daf7ecac\",\"title\":\"Objects and attention: the state of the art\",\"url\":\"https://www.semanticscholar.org/paper/e32be6db00da2d6ea9ff2be0482abac4daf7ecac\",\"venue\":\"Cognition\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"48811777\",\"name\":\"Dan Xie\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.24963/ijcai.2017/180\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fab0d19c58815eccb0db7215fe45d6a32066ca1c\",\"title\":\"Inferring Human Attention by Learning Latent Intentions\",\"url\":\"https://www.semanticscholar.org/paper/fab0d19c58815eccb0db7215fe45d6a32066ca1c\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40529331\",\"name\":\"C. Huang\"},{\"authorId\":\"2211183\",\"name\":\"Sean Andrist\"},{\"authorId\":\"2354698\",\"name\":\"Allison Saupp\\u00e9\"},{\"authorId\":\"145656551\",\"name\":\"B. Mutlu\"}],\"doi\":\"10.3389/fpsyg.2015.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03686afbbb854ef995200bd6196d404371466286\",\"title\":\"Using gaze patterns to predict task intent in collaboration\",\"url\":\"https://www.semanticscholar.org/paper/03686afbbb854ef995200bd6196d404371466286\",\"venue\":\"Front. Psychol.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792053\",\"name\":\"B. Scassellati\"}],\"doi\":\"10.1037/e446982006-001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1d1a60a5d4da0d0c680bb2a79e0821780f8cf07\",\"title\":\"Foundations for a theory of mind for a humanoid robot\",\"url\":\"https://www.semanticscholar.org/paper/b1d1a60a5d4da0d0c680bb2a79e0821780f8cf07\",\"venue\":\"\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46925940\",\"name\":\"Dan Song\"},{\"authorId\":\"1731447\",\"name\":\"Nikolaos Kyriazis\"},{\"authorId\":\"1725054\",\"name\":\"I. Oikonomidis\"},{\"authorId\":\"2976711\",\"name\":\"Chavdar Papazov\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"},{\"authorId\":\"1791260\",\"name\":\"Darius Burschka\"},{\"authorId\":\"1731490\",\"name\":\"D. Kragic\"}],\"doi\":\"10.1109/ICRA.2013.6630785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a818c58ca10bab45aa53168de7afa0e7f431c57\",\"title\":\"Predicting human intention in visual observations of hand/object interactions\",\"url\":\"https://www.semanticscholar.org/paper/9a818c58ca10bab45aa53168de7afa0e7f431c57\",\"venue\":\"2013 IEEE International Conference on Robotics and Automation\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2012.6247805\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"title\":\"Social interactions: A first-person perspective\",\"url\":\"https://www.semanticscholar.org/paper/014e1186209e4f942f3b5ba29b6b039c8e99ad88\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kenneth A. Funes-Mora\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09ba6b87736fa29aae88c5b4cf30f25188e4c6ef\",\"title\":\"Gaze Estimation in the 3 D Space Using RGB-D sensors Towards Head-Pose And User Invariance\",\"url\":\"https://www.semanticscholar.org/paper/09ba6b87736fa29aae88c5b4cf30f25188e4c6ef\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1933419\",\"name\":\"S. Butterfill\"},{\"authorId\":\"3084968\",\"name\":\"I. Apperly\"},{\"authorId\":\"2103798\",\"name\":\"H. Rakoczy\"},{\"authorId\":\"16004075\",\"name\":\"Shannon Spaulding\"},{\"authorId\":\"114343187\",\"name\":\"Tadeusz W. Zawidzki\"}],\"doi\":\"10.1111/MILA.12036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3b55ed9ceb0fb26d8cce75e438ac2ae85a82172\",\"title\":\"Symposium on S. Butterfill and I. Apperly, \\\"How to Construct a Minimal Theory of Mind\\\"\",\"url\":\"https://www.semanticscholar.org/paper/a3b55ed9ceb0fb26d8cce75e438ac2ae85a82172\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Liu J. Wang\"},{\"authorId\":null,\"name\":\"Y. Wu\"},{\"authorId\":null,\"name\":\"J. Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"dicting motivations of actions by leveraging text\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50707365\",\"name\":\"F. Stulp\"},{\"authorId\":\"2325078\",\"name\":\"Jonathan Grizou\"},{\"authorId\":\"2004158\",\"name\":\"Baptiste Busch\"},{\"authorId\":\"144518313\",\"name\":\"M. Lopes\"}],\"doi\":\"10.1109/IROS.2015.7353529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f41401912c8f690e1e28043f54dd044954c1605\",\"title\":\"Facilitating intention prediction for humans by optimizing robot motions\",\"url\":\"https://www.semanticscholar.org/paper/2f41401912c8f690e1e28043f54dd044954c1605\",\"venue\":\"2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TSMC.2013.2279715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc537a1505d749ead53a08bb91cf1a53fdcf18b\",\"title\":\"What/Where to Look Next? Modeling Top-Down Visual Attention in Complex Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/abc537a1505d749ead53a08bb91cf1a53fdcf18b\",\"venue\":\"IEEE Transactions on Systems, Man, and Cybernetics: Systems\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7294d3ac0001e4b36c67aeb5c31d1db8ba1da23a\",\"title\":\"Where are they looking?\",\"url\":\"https://www.semanticscholar.org/paper/7294d3ac0001e4b36c67aeb5c31d1db8ba1da23a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849128\",\"name\":\"Rong-En Fan\"},{\"authorId\":\"2782886\",\"name\":\"Kai-Wei Chang\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"},{\"authorId\":\"8415802\",\"name\":\"Xiang-Rui Wang\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"}],\"doi\":\"10.1145/1390681.1442794\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"268a4f8da15a42f3e0e71691f760ff5edbf9cec8\",\"title\":\"LIBLINEAR: A Library for Large Linear Classification\",\"url\":\"https://www.semanticscholar.org/paper/268a4f8da15a42f3e0e71691f760ff5edbf9cec8\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118013316\",\"name\":\"Sarah-Jayne Blakemore\"},{\"authorId\":\"3235030\",\"name\":\"J. Decety\"}],\"doi\":\"10.1038/35086023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fae843b9ed63607aa9170c612b3d18a0760b14a\",\"title\":\"From the perception of action to the understanding of intention\",\"url\":\"https://www.semanticscholar.org/paper/5fae843b9ed63607aa9170c612b3d18a0760b14a\",\"venue\":\"Nature reviews. Neuroscience\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924487\",\"name\":\"Jiang Wang\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TPAMI.2013.198\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"329274800f45c2004ce3053a0b652b8ef0a73eaa\",\"title\":\"Learning Actionlet Ensemble for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/329274800f45c2004ce3053a0b652b8ef0a73eaa\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713712\",\"name\":\"Jixu Chen\"},{\"authorId\":\"145371875\",\"name\":\"Yan Tong\"},{\"authorId\":\"2926253\",\"name\":\"Wayne D. Gray\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1145/1344471.1344518\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb9064b0c318ed7738852184af659a267b1d0360\",\"title\":\"A robust 3D eye gaze tracking system using noise reduction\",\"url\":\"https://www.semanticscholar.org/paper/bb9064b0c318ed7738852184af659a267b1d0360\",\"venue\":\"ETRA '08\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48811777\",\"name\":\"Dan Xie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15abb2bd1a374bf20f803c9ca1974aa9980bd5a8\",\"title\":\"Inferring the Intentions and Attentions of Agents from Videos\",\"url\":\"https://www.semanticscholar.org/paper/15abb2bd1a374bf20f803c9ca1974aa9980bd5a8\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2014.235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87e297fe4eeb57eed6d6badef2838fb25529b48d\",\"title\":\"Learning-by-Synthesis for Appearance-Based 3D Gaze Estimation\",\"url\":\"https://www.semanticscholar.org/paper/87e297fe4eeb57eed6d6badef2838fb25529b48d\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"46317361\",\"name\":\"Yibiao Zhao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/TPAMI.2016.2574712\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"475034ca17f22aad2bc075c368d224d46826cf4f\",\"title\":\"Modeling 4D Human-Object Interactions for Joint Event Segmentation, Recognition, and Object Localization\",\"url\":\"https://www.semanticscholar.org/paper/475034ca17f22aad2bc075c368d224d46826cf4f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Where and Why are They Looking? Jointly Inferring Human Attention and Intentions in Complex Tasks\",\"topics\":[{\"topic\":\"Beam search\",\"topicId\":\"215017\",\"url\":\"https://www.semanticscholar.org/topic/215017\"},{\"topic\":\"Search algorithm\",\"topicId\":\"12313\",\"url\":\"https://www.semanticscholar.org/topic/12313\"},{\"topic\":\"Temporal logic\",\"topicId\":\"480\",\"url\":\"https://www.semanticscholar.org/topic/480\"},{\"topic\":\"Hierarchical database model\",\"topicId\":\"110806\",\"url\":\"https://www.semanticscholar.org/topic/110806\"},{\"topic\":\"Robotics\",\"topicId\":\"2759\",\"url\":\"https://www.semanticscholar.org/topic/2759\"},{\"topic\":\"Unified Framework\",\"topicId\":\"105596\",\"url\":\"https://www.semanticscholar.org/topic/105596\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Asch conformity experiments\",\"topicId\":\"837418\",\"url\":\"https://www.semanticscholar.org/topic/837418\"}],\"url\":\"https://www.semanticscholar.org/paper/07098ec7f9b66ddeb21314fd3630a9e45decdd4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"