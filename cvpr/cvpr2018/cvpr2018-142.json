"{\"abstract\":\"In this paper, we address referring expression comprehension: localizing an image region described by a natural language expression. While most recent work treats expressions as a single unit, we propose to decompose them into three modular components related to subject appearance, location, and relationship to other objects. This allows us to flexibly adapt to expressions containing different types of information in an end-to-end framework. In our model, which we call the Modular Attention Network (MAttNet), two types of attention are utilized: language-based attention that learns the module weights as well as the word/phrase attention that each module should focus on; and visual attention that allows the subject and relationship modules to focus on relevant image components. Module weights combine scores from all three modules dynamically to output an overall score. Experiments show that MAttNet outperforms previous state-of-the-art methods by a large margin on both bounding-box-level and pixel-level comprehension tasks. Demo1 and code2 are provided.\",\"arxivId\":\"1801.08186\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\",\"url\":\"https://www.semanticscholar.org/author/1714982\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\",\"url\":\"https://www.semanticscholar.org/author/145527707\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\",\"url\":\"https://www.semanticscholar.org/author/1720987\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\",\"url\":\"https://www.semanticscholar.org/author/1768964\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\",\"url\":\"https://www.semanticscholar.org/author/145574672\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\",\"url\":\"https://www.semanticscholar.org/author/143977268\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\",\"url\":\"https://www.semanticscholar.org/author/1685538\"}],\"citationVelocity\":66,\"citations\":[{\"arxivId\":\"1909.08164\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/ICCV.2019.00474\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8b8a2d61cdd9592faebb6aca262ec3a64e6d43\",\"title\":\"Dynamic Graph Attention for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/6c8b8a2d61cdd9592faebb6aca262ec3a64e6d43\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"48625377\",\"name\":\"Weiming Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"81436348\",\"name\":\"Q. Wang\"},{\"authorId\":\"46392484\",\"name\":\"Wooshik Kim\"},{\"authorId\":\"48836299\",\"name\":\"Sunghoon Hong\"}],\"doi\":\"10.1145/3343031.3351063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4dbc17138e7b610214359bb1659a30e01d183482\",\"title\":\"Referring Expression Comprehension with Semantic Visual Relationship and Word Mapping\",\"url\":\"https://www.semanticscholar.org/paper/4dbc17138e7b610214359bb1659a30e01d183482\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf2f9f9ebe16b2574ad6de69f5806e5d44c14217\",\"title\":\"Explainability by Parsing: Neural Module Tree Networks for Natural Language Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/bf2f9f9ebe16b2574ad6de69f5806e5d44c14217\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2012.08939\",\"authors\":[{\"authorId\":\"70171830\",\"name\":\"D. Kothandaraman\"},{\"authorId\":\"1562037323\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"624f723d3b830fbb6d0118743006295b9acb2e92\",\"title\":\"SAfE: Self-Attention Based Unsupervised Road Safety Classification in Hazardous Environments\",\"url\":\"https://www.semanticscholar.org/paper/624f723d3b830fbb6d0118743006295b9acb2e92\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.11683\",\"authors\":[{\"authorId\":\"145559125\",\"name\":\"H. Akbari\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"1754397\",\"name\":\"Surabhi Bhargava\"},{\"authorId\":\"143852868\",\"name\":\"B. Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.01276\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"title\":\"Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ashish Vaswani\"},{\"authorId\":null,\"name\":\"Noam Shazeer\"},{\"authorId\":null,\"name\":\"Niki Parmar\"},{\"authorId\":null,\"name\":\"Jakob\"},{\"authorId\":null,\"name\":\"Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"title\":\"Words aren\\u2019t enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a9c8a5a95a6b62a661aa66394a1d35d372de8c60\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.12104\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"143973868\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"title\":\"Towards Human-Friendly Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.06066\",\"authors\":[{\"authorId\":\"24661938\",\"name\":\"N. Rufus\"},{\"authorId\":\"30900327\",\"name\":\"U. Nair\"},{\"authorId\":\"145211574\",\"name\":\"K. Krishna\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6887b5680d0041f3bea85bb85a2d9f77dd41067\",\"title\":\"Cosine meets Softmax: A tough-to-beat baseline for visual grounding\",\"url\":\"https://www.semanticscholar.org/paper/f6887b5680d0041f3bea85bb85a2d9f77dd41067\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ba7890a5e9e51bf6181cc3c03144796cb3e5e254\",\"title\":\"Query : \\\" A man in a red sweatshirt performing breakdance \\\"\",\"url\":\"https://www.semanticscholar.org/paper/ba7890a5e9e51bf6181cc3c03144796cb3e5e254\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1902.04213\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"49560222\",\"name\":\"Guanghui Xu\"},{\"authorId\":\"153009573\",\"name\":\"Z. Yu\"},{\"authorId\":null,\"name\":\"Yanwu Xu\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8b54f188af9e71f5790f10c406d888ea006387d\",\"title\":\"You Only Look & Listen Once: Towards Fast and Accurate Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/d8b54f188af9e71f5790f10c406d888ea006387d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1016/j.neucom.2020.04.066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33cd369bbc8825a812d672b15e184ae43ca69352\",\"title\":\"Visually grounded paraphrase identification via gating and phrase localization\",\"url\":\"https://www.semanticscholar.org/paper/33cd369bbc8825a812d672b15e184ae43ca69352\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.00403\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"97992296\",\"name\":\"P. Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01010\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"title\":\"Cops-Ref: A New Dataset and Task on Compositional Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2f84c74b0c1b66420d06ad07f8a6b58fbf215ff6\",\"title\":\"Video Tree Attention Network Phrase Embedding ds Query Phrase Embedding dc Phrase Embedding dm Sentence Embedding hroot Temporal Localization Module Temporal Relationship Module + Matching\",\"url\":\"https://www.semanticscholar.org/paper/2f84c74b0c1b66420d06ad07f8a6b58fbf215ff6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.04446\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"34675041\",\"name\":\"Mathieu Seurin\"},{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"34682317\",\"name\":\"P. Preux\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.1007/978-3-030-01228-1_48\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0654e75bfea7af13e021a22a21422b36270c08b7\",\"title\":\"Visual Reasoning with Multi-hop Feature Modulation\",\"url\":\"https://www.semanticscholar.org/paper/0654e75bfea7af13e021a22a21422b36270c08b7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.07072\",\"authors\":[{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"9296457\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"47557603\",\"name\":\"Yanjie Chen\"},{\"authorId\":null,\"name\":\"Chen Qian\"},{\"authorId\":\"33980717\",\"name\":\"B. Li\"}],\"doi\":\"10.1109/CVPR42600.2020.01089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1588b47c51cf719bcfdf1889349164d541fb3825\",\"title\":\"A Real-Time Cross-Modality Correlation Filtering Method for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/1588b47c51cf719bcfdf1889349164d541fb3825\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443432976\",\"name\":\"Zhenxiong Tan\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"1584278646\",\"name\":\"Jinyu Chen\"},{\"authorId\":\"47179923\",\"name\":\"S. Liu\"}],\"doi\":\"10.1007/978-3-030-60633-6_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99a02592befa3741ebeefd8d02fbe2960817b6fa\",\"title\":\"Multi-granularity Multimodal Feature Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/99a02592befa3741ebeefd8d02fbe2960817b6fa\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"1901.00850\",\"authors\":[{\"authorId\":\"9326827\",\"name\":\"Runtao Liu\"},{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"48442730\",\"name\":\"Y. Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2019.00431\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9695676deace8c05d4e95274b92f20ed1e97470c\",\"title\":\"CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9695676deace8c05d4e95274b92f20ed1e97470c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.10093\",\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"676d624c7b8642acde0bc70e06b462e93fd83e64\",\"title\":\"Pay attention! - Robustifying a Deep Visuomotor Policy through Task-Focused Attention\",\"url\":\"https://www.semanticscholar.org/paper/676d624c7b8642acde0bc70e06b462e93fd83e64\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.13324\",\"authors\":[{\"authorId\":\"33299173\",\"name\":\"Ozan Arkan Can\"},{\"authorId\":\"51007563\",\"name\":\"Pedro Zuidberg Dos Martires\"},{\"authorId\":\"40501403\",\"name\":\"A. Persson\"},{\"authorId\":\"116833794\",\"name\":\"Julian Gaal\"},{\"authorId\":\"49494953\",\"name\":\"A. Loutfi\"},{\"authorId\":\"1740042\",\"name\":\"L. D. Raedt\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"},{\"authorId\":\"1815138\",\"name\":\"A. Saffiotti\"}],\"doi\":\"10.18653/v1/W19-1604\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec10209c9f739df1e0d76ebdd80e089d0b30e435\",\"title\":\"Learning from Implicit Information in Natural Language Instructions for Robotic Manipulations\",\"url\":\"https://www.semanticscholar.org/paper/ec10209c9f739df1e0d76ebdd80e089d0b30e435\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.03846\",\"authors\":[{\"authorId\":\"3178508\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3343031.3350879\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"21ad966d7cc9812e2e96f37a577456947e5b694e\",\"title\":\"Exploiting Temporal Relationships in Video Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/21ad966d7cc9812e2e96f37a577456947e5b694e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"38218215\",\"name\":\"Xin Wang\"},{\"authorId\":\"49336516\",\"name\":\"W. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/cvpr42600.2020.01000\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fd8ad5cc71f8108177206fa4844c8d06dd57cdc0\",\"title\":\"REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments\",\"url\":\"https://www.semanticscholar.org/paper/fd8ad5cc71f8108177206fa4844c8d06dd57cdc0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.13922\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d16bce335338372c1927f69d4b1f667a330b59d2\",\"title\":\"A Recurrent Vision-and-Language BERT for Navigation\",\"url\":\"https://www.semanticscholar.org/paper/d16bce335338372c1927f69d4b1f667a330b59d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07384\",\"authors\":[{\"authorId\":\"32481910\",\"name\":\"Valts Blukis\"},{\"authorId\":\"2678110\",\"name\":\"Ross A. Knepper\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddd74358d7e11535ee77e2c323dd662d115a0f20\",\"title\":\"Few-shot Object Grounding and Mapping for Natural Language Robot Instruction Following\",\"url\":\"https://www.semanticscholar.org/paper/ddd74358d7e11535ee77e2c323dd662d115a0f20\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48016309\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/ICCV.2019.00404\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"title\":\"Asymmetric Cross-Guided Attention Network for Actor and Action Video Segmentation From Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.02330\",\"authors\":[{\"authorId\":\"145749362\",\"name\":\"Jing Shi\"},{\"authorId\":\"145857587\",\"name\":\"Ning Xu\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"1500397567\",\"name\":\"Zheng Wen\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"58b7c7834e794c53b78a3a78dda54d92f2faba26\",\"title\":\"A Benchmark and Baseline for Language-Driven Image Editing\",\"url\":\"https://www.semanticscholar.org/paper/58b7c7834e794c53b78a3a78dda54d92f2faba26\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01059\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58568-6_23\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"a3be9acba7b1f847e6d091c540536753ec66669c\",\"title\":\"Improving One-stage Visual Grounding by Recursive Sub-query Construction\",\"url\":\"https://www.semanticscholar.org/paper/a3be9acba7b1f847e6d091c540536753ec66669c\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.12831\",\"authors\":[{\"authorId\":\"32562635\",\"name\":\"Liunian Harold Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"2513111\",\"name\":\"Zhecan Wang\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"},{\"authorId\":\"101751639\",\"name\":\"Kai-Wei Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"16f82c1dae2f6e5149c1be95165d7081f08298b6\",\"title\":\"Weakly-supervised VisualBERT: Pre-training without Parallel Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/16f82c1dae2f6e5149c1be95165d7081f08298b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04557\",\"authors\":[{\"authorId\":\"47798280\",\"name\":\"T. Ogura\"},{\"authorId\":\"31428186\",\"name\":\"A. Magassouba\"},{\"authorId\":\"2332462\",\"name\":\"K. Sugiura\"},{\"authorId\":\"134790239\",\"name\":\"Tsubasa Hirakawa\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"1687968\",\"name\":\"H. Fujiyoshi\"},{\"authorId\":\"153476449\",\"name\":\"H. Kawai\"}],\"doi\":\"10.1109/lra.2020.3010735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8665698dd9c9093f03d3d672454ae4db33d381ef\",\"title\":\"Alleviating the Burden of Labeling: Sentence Generation by Attention Branch Encoder\\u2013Decoder Network\",\"url\":\"https://www.semanticscholar.org/paper/8665698dd9c9093f03d3d672454ae4db33d381ef\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941780\",\"name\":\"Zhiwei Hu\"},{\"authorId\":\"49081953\",\"name\":\"Guang Feng\"},{\"authorId\":\"1491083353\",\"name\":\"Jiayu Sun\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00448\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31422b7cbcabe22d24975129fafe9a3258051b2d\",\"title\":\"Bi-Directional Relationship Inferring Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/31422b7cbcabe22d24975129fafe9a3258051b2d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"title\":\"Refer360$^\\\\circ$: A Referring Expression Recognition Dataset in 360$^\\\\circ$ Images\",\"url\":\"https://www.semanticscholar.org/paper/6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"46246806\",\"name\":\"Chia-Wen Lin\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414006\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"24f2a18c54ab017d00ce1f714600b6bede6c0820\",\"title\":\"Cascade Grouped Attention Network for Referring Expression Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/24f2a18c54ab017d00ce1f714600b6bede6c0820\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.06941\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"2422046\",\"name\":\"Baoxing Huai\"},{\"authorId\":\"145078771\",\"name\":\"J. Yuan\"}],\"doi\":\"10.24963/ijcai.2020/149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"title\":\"Object-Aware Multi-Branch Relation Networks for Spatio-Temporal Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2086bd08d3921bc1e83fdad306ec0c5ac3b43428\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.10606\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR42600.2020.01043\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"title\":\"Video Object Grounding Using Semantic Roles in Language Description\",\"url\":\"https://www.semanticscholar.org/paper/70ea5d98141cd845d1c8131f25ddbc77f962f3d8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.01629\",\"authors\":[{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"47417383\",\"name\":\"Dongyang Liu\"},{\"authorId\":\"144462039\",\"name\":\"H. Li\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413905\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"3a08274632296de2f98d11180ce3e2b06776a3a0\",\"title\":\"Give Me Something to Eat: Referring Expression Comprehension with Commonsense Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3a08274632296de2f98d11180ce3e2b06776a3a0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1910.04748\",\"authors\":[{\"authorId\":\"12650171\",\"name\":\"Yi-Wen Chen\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0096ee35502910ef560fc554b2980010aa1947b5\",\"title\":\"Referring Expression Object Segmentation with Caption-Aware Consistency\",\"url\":\"https://www.semanticscholar.org/paper/0096ee35502910ef560fc554b2980010aa1947b5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"1466481870\",\"name\":\"Bencheng Yan\"}],\"doi\":\"10.1007/978-3-030-36718-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77465a0ae333a9ce4cf3969b93e756772714fc63\",\"title\":\"Watch and Ask: Video Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/77465a0ae333a9ce4cf3969b93e756772714fc63\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1812.03299\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1109/ICCV.2019.00477\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e504843bfd3ca81b859895439bbe19efc1f3dc61\",\"title\":\"Learning to Assemble Neural Module Tree Networks for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/e504843bfd3ca81b859895439bbe19efc1f3dc61\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"13094241\",\"name\":\"G. Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1007/978-3-030-58529-7_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"692cfd9b60a240f225ea23fae92d148de0001adf\",\"title\":\"Propagating Over Phrase Relations for One-Stage Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/692cfd9b60a240f225ea23fae92d148de0001adf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35212676\",\"name\":\"J. Peyre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"caffa07ead18aae78bf654bc57023eef58e74faf\",\"title\":\"Learning to detect visual relations\",\"url\":\"https://www.semanticscholar.org/paper/caffa07ead18aae78bf654bc57023eef58e74faf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1803.08006\",\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-20870-7_8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da30d00c9490768e7726725482e3ecbd102f18cd\",\"title\":\"Video Object Segmentation with Language Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/da30d00c9490768e7726725482e3ecbd102f18cd\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2011.02655\",\"authors\":[{\"authorId\":\"47297245\",\"name\":\"H. Zhu\"},{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"29962444\",\"name\":\"Zhao-Heng Zheng\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1cb961c8bea36d5faf3c6011f15dc23832a3e8fc\",\"title\":\"Utilizing Every Image Object for Semi-supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/1cb961c8bea36d5faf3c6011f15dc23832a3e8fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49887532\",\"name\":\"J. Shi\"},{\"authorId\":\"153173166\",\"name\":\"J. Xu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/CVPR.2019.01069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8842a793e10d35f917345f7290fc671edd8cc7bf\",\"title\":\"Not All Frames Are Equal: Weakly-Supervised Video Grounding With Contextual Similarity and Visual Clustering Losses\",\"url\":\"https://www.semanticscholar.org/paper/8842a793e10d35f917345f7290fc671edd8cc7bf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8004535\",\"name\":\"Chaojun Han\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f51d9d34635ad9f6310d767869710e78fc4174bf\",\"title\":\"Visual Spatial Attention Network for Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/f51d9d34635ad9f6310d767869710e78fc4174bf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1911.02103\",\"authors\":[{\"authorId\":\"1404351074\",\"name\":\"Alba Herrera-Palacio\"},{\"authorId\":\"38478804\",\"name\":\"C. Ventura\"},{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"50322207\",\"name\":\"Ionut-Teodor Sorodoc\"},{\"authorId\":\"1807810\",\"name\":\"Gemma Boleda\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27be94b980ecdffaa56934477e1e0988da379189\",\"title\":\"Recurrent Instance Segmentation using Sequences of Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/27be94b980ecdffaa56934477e1e0988da379189\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87784907\",\"name\":\"X. Li\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"2168639\",\"name\":\"Kaiping Xu\"},{\"authorId\":\"50144856\",\"name\":\"Zhehuan Zhao\"},{\"authorId\":\"153318657\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9191285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6553ee7945543eb47f239fd7150a6d6a266130fe\",\"title\":\"A Context-Based Network For Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6553ee7945543eb47f239fd7150a6d6a266130fe\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"2809150\",\"name\":\"Songhao Jia\"},{\"authorId\":\"2849249\",\"name\":\"Yi-Chen Lo\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1109/ICCV.2019.00755\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"661d82c26fad099f28a8da02d2c9d1cfee32cff4\",\"title\":\"See-Through-Text Grouping for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/661d82c26fad099f28a8da02d2c9d1cfee32cff4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2738930\",\"name\":\"Fenglin Luo\"},{\"authorId\":\"3608837\",\"name\":\"M. Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"121809417\",\"name\":\"X. Zhao\"},{\"authorId\":\"36001341\",\"name\":\"A. Li\"}],\"doi\":\"10.1093/bioinformatics/bty1051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"690e0cc60a37f94f2fee4ad95bb3ecd23f9c8b4e\",\"title\":\"DeepPhos: prediction of protein phosphorylation sites with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/690e0cc60a37f94f2fee4ad95bb3ecd23f9c8b4e\",\"venue\":\"Bioinform.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"title\":\"Sentence Encoder Video Encoder Frame-Specific Sentence Representation Cross Gating Matching Aggregation Self Interactor Segment Localizer Cross Modal\",\"url\":\"https://www.semanticscholar.org/paper/631d21ee2e0de4227be1dfe000006acf1e0fe783\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"153500661\",\"name\":\"S. Cohen\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/CVPR42600.2020.01023\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a1ebc58f6c055eac8555d9850cb849a38c22c67d\",\"title\":\"PhraseCut: Language-Based Image Segmentation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/a1ebc58f6c055eac8555d9850cb849a38c22c67d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.01045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.10364\",\"authors\":[{\"authorId\":\"31213065\",\"name\":\"Mohamadreza Faridghasemnia\"},{\"authorId\":\"144143747\",\"name\":\"D. Nardi\"},{\"authorId\":\"1815138\",\"name\":\"A. Saffiotti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebb8de3ec8aec2134a77545bcdaae552484e4340\",\"title\":\"Towards Abstract Relational Learning in Human Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ebb8de3ec8aec2134a77545bcdaae552484e4340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.10838\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"83754395\",\"name\":\"Simon Vandenhende\"},{\"authorId\":\"1388019229\",\"name\":\"Dusan Grujicic\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.18653/v1/D19-1215\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"61ac1603c0ad5268b202506bb2cddbfe10c45d9f\",\"title\":\"Talk2Car: Taking Control of Your Self-Driving Car\",\"url\":\"https://www.semanticscholar.org/paper/61ac1603c0ad5268b202506bb2cddbfe10c45d9f\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"title\":\"Efficient Attention Mechanism for Handling All the Interactions between Many Inputs with Application to Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.08527\",\"authors\":[{\"authorId\":\"1911972\",\"name\":\"Tanmay Gupta\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/ICCV.2019.00752\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"title\":\"ViCo: Word Embeddings From Visual Co-Occurrences\",\"url\":\"https://www.semanticscholar.org/paper/ae1764ffaa2fe68dafe33664624be38273c4ccef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"}],\"doi\":\"10.3929/ethz-b-000359170\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b6cbafe557680d52d32df8a7af600a6adcbfcc2c\",\"title\":\"Automatic Alignment Methods for Visual and Textual Data with Narrative Content\",\"url\":\"https://www.semanticscholar.org/paper/b6cbafe557680d52d32df8a7af600a6adcbfcc2c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.02834\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"46184233\",\"name\":\"Nathan Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1288aaf45ff85916ccef13668ceba421273a3c36\",\"title\":\"Weakly-Supervised Video Object Grounding from Text by Loss Weighting and Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/1288aaf45ff85916ccef13668ceba421273a3c36\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1908.08530\",\"authors\":[{\"authorId\":\"145499378\",\"name\":\"Weijie Su\"},{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":\"47746274\",\"name\":\"Y. Cao\"},{\"authorId\":\"48218753\",\"name\":\"B. Li\"},{\"authorId\":\"152309485\",\"name\":\"Lewei Lu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2527626c11a84f15709e943fbfa2356e19930e3b\",\"title\":\"VL-BERT: Pre-training of Generic Visual-Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/2527626c11a84f15709e943fbfa2356e19930e3b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2003.08027\",\"authors\":[{\"authorId\":\"39024831\",\"name\":\"Shuai Wang\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40912079\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102714\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b65ffe7ada51e34a0a8e3e46b90d71099141a8e\",\"title\":\"Mutatt: Visual-Textual Mutual Guidance For Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3b65ffe7ada51e34a0a8e3e46b90d71099141a8e\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1909.12637\",\"authors\":[{\"authorId\":\"1387974329\",\"name\":\"Margherita Rosnati\"},{\"authorId\":\"41031794\",\"name\":\"Vincent Fortuin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"428645d60ca80f7244290f0e38e7f47ec01095ef\",\"title\":\"MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction of Sepsis\",\"url\":\"https://www.semanticscholar.org/paper/428645d60ca80f7244290f0e38e7f47ec01095ef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51444310\",\"name\":\"Seonguk Seo\"},{\"authorId\":\"51319129\",\"name\":\"Joonyoung Lee\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1007/978-3-030-58555-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd0255491af35c5bc5f7cfa473718c19f67fcac3\",\"title\":\"URVOS: Unified Referring Video Object Segmentation Network with a Large-Scale Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/cd0255491af35c5bc5f7cfa473718c19f67fcac3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49441320\",\"name\":\"H. Ding\"},{\"authorId\":\"1879014003\",\"name\":\"S. Cohen\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"}],\"doi\":\"10.1007/978-3-030-58580-8_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55f9831547577106695a57ee2d1cc0f0b563a948\",\"title\":\"PhraseClick: Toward Achieving Flexible Interactive Segmentation by Phrase and Click\",\"url\":\"https://www.semanticscholar.org/paper/55f9831547577106695a57ee2d1cc0f0b563a948\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.10675\",\"authors\":[{\"authorId\":\"31428186\",\"name\":\"A. Magassouba\"},{\"authorId\":\"2332462\",\"name\":\"K. Sugiura\"},{\"authorId\":\"153476449\",\"name\":\"H. Kawai\"}],\"doi\":\"10.1109/LRA.2019.2963649\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a191be5a2d986ed2e1df0e38a6651dee4aa1b0f6\",\"title\":\"A Multimodal Target-Source Classifier With Attention Branches to Understand Ambiguous Instructions for Fetching Daily Objects\",\"url\":\"https://www.semanticscholar.org/paper/a191be5a2d986ed2e1df0e38a6651dee4aa1b0f6\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2003.12739\",\"authors\":[{\"authorId\":\"33299173\",\"name\":\"Ozan Arkan Can\"},{\"authorId\":\"116865200\",\"name\":\"Ilker Kesen\"},{\"authorId\":\"2808366\",\"name\":\"Deniz Yuret\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a84a38a190b90d161bcdd5585ab7a87f5b8c974d\",\"title\":\"BiLingUNet: Image Segmentation by Modulating Top-Down and Bottom-Up Visual Processing with Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a84a38a190b90d161bcdd5585ab7a87f5b8c974d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.03426\",\"authors\":[{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"title\":\"Real-Time Referring Expression Comprehension by Single-Stage Grounding Network\",\"url\":\"https://www.semanticscholar.org/paper/e9db75c5dc7c2a11f3623ac5f83aa7a5297951bb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2009.05684\",\"authors\":[{\"authorId\":\"46662193\",\"name\":\"V. Mittal\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"dd6df4febb7135007077f835f9c44d12514aa522\",\"title\":\"AttnGrounder: Talking to Cars with Attention\",\"url\":\"https://www.semanticscholar.org/paper/dd6df4febb7135007077f835f9c44d12514aa522\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2101328\",\"name\":\"Xue-Jing Liu\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"2797676\",\"name\":\"Dechao Meng\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413677\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"0767d8241f959f42e2e747cf17813c78cacc79e1\",\"title\":\"Transferrable Referring Expression Grounding with Concept Transfer and Context Inheritance\",\"url\":\"https://www.semanticscholar.org/paper/0767d8241f959f42e2e747cf17813c78cacc79e1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.07832\",\"authors\":[{\"authorId\":\"3461751\",\"name\":\"Tzu-Jui Wang\"},{\"authorId\":\"1390466817\",\"name\":\"Selen Pehlivan\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11a4e51c95fd4d5e11b4a1b9258dc4698ce59e63\",\"title\":\"Tackling the Unannotated: Scene Graph Generation with Bias-Reduced Models\",\"url\":\"https://www.semanticscholar.org/paper/11a4e51c95fd4d5e11b4a1b9258dc4698ce59e63\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.03768\",\"authors\":[{\"authorId\":\"33516562\",\"name\":\"Mohit Shridhar\"},{\"authorId\":\"2854297\",\"name\":\"Xingdi Yuan\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"398a0625e8707a0b41ac58eaec51e8feb87dd7cb\",\"title\":\"ALFWorld: Aligning Text and Embodied Environments for Interactive Learning\",\"url\":\"https://www.semanticscholar.org/paper/398a0625e8707a0b41ac58eaec51e8feb87dd7cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152673712\",\"name\":\"Youming Gao\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"47362529\",\"name\":\"T. Xu\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-30508-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"title\":\"Referring Expression Comprehension via Co-attention and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1904.04745\",\"authors\":[{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"2532612\",\"name\":\"Mrigank Rochan\"},{\"authorId\":\"143962643\",\"name\":\"Zhi Liu\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/CVPR.2019.01075\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"69455376f5ad52cac5b72d5e8c6cf03fb466b55c\",\"title\":\"Cross-Modal Self-Attention Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/69455376f5ad52cac5b72d5e8c6cf03fb466b55c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2008.01180\",\"authors\":[{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"143903550\",\"name\":\"M. Timm\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1007/978-3-030-58452-8_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86f0fb3791761cdb5e9108721a536d752641d4bf\",\"title\":\"Describing Textures using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/86f0fb3791761cdb5e9108721a536d752641d4bf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.12764\",\"authors\":[{\"authorId\":\"143972253\",\"name\":\"R. Corona\"},{\"authorId\":\"153825694\",\"name\":\"D. Fried\"},{\"authorId\":\"144373380\",\"name\":\"C. Devin\"},{\"authorId\":\"152494587\",\"name\":\"D. Klein\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"83d2d970db0eeb645d087a7f37bb05adb780706e\",\"title\":\"Modularity Improves Out-of-Domain Instruction Following\",\"url\":\"https://www.semanticscholar.org/paper/83d2d970db0eeb645d087a7f37bb05adb780706e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"1993659018\",\"name\":\"Xinjian Gao\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3394171.3413610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"title\":\"Weakly-Supervised Video Object Grounding by Exploring Spatio-Temporal Contexts\",\"url\":\"https://www.semanticscholar.org/paper/b839e6b1f65672d154feb6f6668d64a2333c71ee\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.08814\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/cvpr42600.2020.00997\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"434bccb2743fbb918b5666000c839b390cb209ae\",\"title\":\"Graph-Structured Referring Expression Reasoning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/434bccb2743fbb918b5666000c839b390cb209ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32791167\",\"name\":\"Chenchen Jing\"},{\"authorId\":\"150352923\",\"name\":\"Yuwei Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6776\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"title\":\"Overcoming Language Priors in VQA via Decomposed Linguistic Representations\",\"url\":\"https://www.semanticscholar.org/paper/5ac43583eedebd895fcfd45e9670a542c4c4070f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.08814\",\"authors\":[{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"72347323\",\"name\":\"X. Yang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-030-58539-6_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13ee363f71e07112210ac2ff27d46625f6f8edab\",\"title\":\"Visual Relation Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/13ee363f71e07112210ac2ff27d46625f6f8edab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.03283\",\"authors\":[{\"authorId\":\"93947530\",\"name\":\"D. Moro\"},{\"authorId\":\"144343783\",\"name\":\"Stacy Black\"},{\"authorId\":\"2061232\",\"name\":\"C. Kennington\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83989d1dcf1bb533d37db6a6ff9af478feeb4aae\",\"title\":\"Composing and Embedding the Words-as-Classifiers Model of Grounded Semantics\",\"url\":\"https://www.semanticscholar.org/paper/83989d1dcf1bb533d37db6a6ff9af478feeb4aae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.08717\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"144481186\",\"name\":\"Guillem Collell\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2bc42a9ebf099b84c02feac5b99e81ce5777eb07\",\"title\":\"Giving Commands to a Self-driving Car: A Multimodal Reasoner for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2bc42a9ebf099b84c02feac5b99e81ce5777eb07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.14301\",\"authors\":[{\"authorId\":\"1944052136\",\"name\":\"Peiyao Wang\"},{\"authorId\":\"2074878\",\"name\":\"Weixin Luo\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2579920\",\"name\":\"Haojie Li\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"47988335\",\"name\":\"Jianyu Yang\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71c5700882c6b22d5557b0831cd4bbe9ff18937d\",\"title\":\"SIRI: Spatial Relation Induced Network For Spatial Description Resolution\",\"url\":\"https://www.semanticscholar.org/paper/71c5700882c6b22d5557b0831cd4bbe9ff18937d\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031180\",\"name\":\"Xiaofeng Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"2753987\",\"name\":\"Fengmao Lv\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":\"10.1007/978-3-030-58589-1_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"title\":\"TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.02925\",\"authors\":[{\"authorId\":\"22199114\",\"name\":\"Panos Achlioptas\"},{\"authorId\":\"5586582\",\"name\":\"Judy Fan\"},{\"authorId\":\"8932668\",\"name\":\"Robert X. D. Hawkins\"},{\"authorId\":\"144002017\",\"name\":\"Noah D. Goodman\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":\"10.1109/ICCV.2019.00903\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9018a815a8a43ef8e27a9af55abdf6a270d7bc28\",\"title\":\"Shapeglot: Learning Language for Shape Differentiation\",\"url\":\"https://www.semanticscholar.org/paper/9018a815a8a43ef8e27a9af55abdf6a270d7bc28\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49831019\",\"name\":\"Pengcheng Wang\"},{\"authorId\":\"50341413\",\"name\":\"S. Li\"}],\"doi\":\"10.1117/12.2513868\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6f8e35dfcbd99269a38915f1b268452c9b5dab0\",\"title\":\"Structural-attentioned LSTM for action recognition based on skeleton\",\"url\":\"https://www.semanticscholar.org/paper/e6f8e35dfcbd99269a38915f1b268452c9b5dab0\",\"venue\":\"Other Conferences\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361839\",\"name\":\"X. Lin\"},{\"authorId\":\"47003295\",\"name\":\"Yonggang Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"49499914\",\"name\":\"J. Yang\"}],\"doi\":\"10.1007/978-3-030-04179-3_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"337befcc1df242a903ac2b5c70cb1b99c7c2ddb1\",\"title\":\"Scene Graph Generation Based on Node-Relation Context Module\",\"url\":\"https://www.semanticscholar.org/paper/337befcc1df242a903ac2b5c70cb1b99c7c2ddb1\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150018075\",\"name\":\"Anant Khandelwal\"},{\"authorId\":\"1474541779\",\"name\":\"Niraj Kumar\"}],\"doi\":\"10.1145/3371158.3371165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e959c04a7ef0a38235f21a7876e98869595f100\",\"title\":\"AggressionNet: Generalised Multi-Modal Deep Temporal and Sequential Learning for Aggression Identification\",\"url\":\"https://www.semanticscholar.org/paper/7e959c04a7ef0a38235f21a7876e98869595f100\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2010.06260\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"title\":\"DORi: Discovering Object Relationship for Moment Localization of a Natural-Language Query in Video\",\"url\":\"https://www.semanticscholar.org/paper/a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"3261071\",\"name\":\"M. Shah\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":\"10.1109/CVPR.2019.00438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f500cc63c446a2c897122008e3d9295cad21bd\",\"title\":\"Pay Attention! - Robustifying a Deep Visuomotor Policy Through Task-Focused Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/83f500cc63c446a2c897122008e3d9295cad21bd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"145159522\",\"name\":\"Ahmed Elgammal\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/CVPR.2019.01180\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0a4a62cccc182c3602ea0c604a21b8d91b99867a\",\"title\":\"Graphical Contrastive Losses for Scene Graph Parsing\",\"url\":\"https://www.semanticscholar.org/paper/0a4a62cccc182c3602ea0c604a21b8d91b99867a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.07129\",\"authors\":[{\"authorId\":\"152229386\",\"name\":\"Arka Sadhu\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2019.00479\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"666d9a766de11c22d9fd7d8e3c36a80ecd6f0bd0\",\"title\":\"Zero-Shot Grounding of Objects From Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/666d9a766de11c22d9fd7d8e3c36a80ecd6f0bd0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.08977\",\"authors\":[{\"authorId\":\"7289061\",\"name\":\"Hyemin Ahn\"},{\"authorId\":\"98605657\",\"name\":\"O. Kwon\"},{\"authorId\":\"9086571\",\"name\":\"Kyoungdo Kim\"},{\"authorId\":\"30742686\",\"name\":\"Dongheui Lee\"},{\"authorId\":\"34184385\",\"name\":\"Songhwai Oh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"052fd049bc6a3cad1dd7d516c406b1d5d08c5d60\",\"title\":\"Visually Grounding Instruction for History-Dependent Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/052fd049bc6a3cad1dd7d516c406b1d5d08c5d60\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.16934\",\"authors\":[{\"authorId\":\"40471592\",\"name\":\"Fei Yu\"},{\"authorId\":\"11713158\",\"name\":\"Jiji Tang\"},{\"authorId\":\"2318321\",\"name\":\"Weichong Yin\"},{\"authorId\":\"144825828\",\"name\":\"Y. Sun\"},{\"authorId\":null,\"name\":\"Hao Tian\"},{\"authorId\":\"120155201\",\"name\":\"Hua Wu\"},{\"authorId\":\"144270729\",\"name\":\"Haifeng Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e34cf702b9c90889e268380572bec782280b59c3\",\"title\":\"ERNIE-ViL: Knowledge Enhanced Vision-Language Representations Through Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/e34cf702b9c90889e268380572bec782280b59c3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.03478\",\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"51230543\",\"name\":\"G. Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"46246806\",\"name\":\"Chia-Wen Lin\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3165d8c9a3466ecac5f6e9dc7e61b65c62c1decb\",\"title\":\"A Real-time Global Inference Network for One-stage Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3165d8c9a3466ecac5f6e9dc7e61b65c62c1decb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404351074\",\"name\":\"Alba Herrera-Palacio\"},{\"authorId\":\"38478804\",\"name\":\"C. Ventura\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":\"10.1145/3347450.3357662\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"86d0605e766d4e204ec25bd5e80106af936dcb36\",\"title\":\"Video Object Linguistic Grounding\",\"url\":\"https://www.semanticscholar.org/paper/86d0605e766d4e204ec25bd5e80106af936dcb36\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.00263\",\"authors\":[{\"authorId\":\"37923017\",\"name\":\"Miriam Bellver\"},{\"authorId\":\"38478804\",\"name\":\"C. Ventura\"},{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"40954941\",\"name\":\"Ioannis Kazakos\"},{\"authorId\":\"144345280\",\"name\":\"J. Torres\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"574cfdc454a6b44026fcbc5539127ca507ca3045\",\"title\":\"RefVOS: A Closer Look at Referring Expressions for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/574cfdc454a6b44026fcbc5539127ca507ca3045\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.07119\",\"authors\":[{\"authorId\":\"2221563\",\"name\":\"N. Vo\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2019.00660\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d\",\"title\":\"Composing Text and Image for Image Retrieval - an Empirical Odyssey\",\"url\":\"https://www.semanticscholar.org/paper/fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145747299\",\"name\":\"Shaonan Wei\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"}],\"doi\":\"10.1007/978-3-030-31726-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f13152e19d8381b2df13bbd8d4b0718c57635d3d\",\"title\":\"Scenario Referring Expression Comprehension via Attributes of Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/f13152e19d8381b2df13bbd8d4b0718c57635d3d\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1912.06316\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"37557835\",\"name\":\"T. Kumar\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2020.3038720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e88bca2232e2c1d9ce7258aaed84bc89a799ee\",\"title\":\"Grounding-Tracking-Integration\",\"url\":\"https://www.semanticscholar.org/paper/c3e88bca2232e2c1d9ce7258aaed84bc89a799ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.acl-main.644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4887113b68c6b9dfda201019c99bcb99b18d642e\",\"title\":\"Refer360\\u2218: A Referring Expression Recognition Dataset in 360: A Referring Expression Recognition Dataset in 360\\u2218 Images Images\",\"url\":\"https://www.semanticscholar.org/paper/4887113b68c6b9dfda201019c99bcb99b18d642e\",\"venue\":\"ACL 2020\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.00514\",\"authors\":[{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"},{\"authorId\":\"1776665\",\"name\":\"Luoqi Liu\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"}],\"doi\":\"10.1109/CVPR42600.2020.01050\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"66566337664bee69915d3a46e0c5b66b15a8f5b5\",\"title\":\"Referring Image Segmentation via Cross-Modal Progressive Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/66566337664bee69915d3a46e0c5b66b15a8f5b5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.07630\",\"authors\":[{\"authorId\":\"51447154\",\"name\":\"Pavel Ostyakov\"},{\"authorId\":\"1956107\",\"name\":\"R. Suvorov\"},{\"authorId\":\"145879692\",\"name\":\"E. Logacheva\"},{\"authorId\":\"50168812\",\"name\":\"Oleg Khomenko\"},{\"authorId\":\"1742235\",\"name\":\"S. Nikolenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4994dd3557d76c9dd864e96215162f0471ad0d50\",\"title\":\"SEIGAN: Towards Compositional Image Generation by Simultaneously Learning to Segment, Enhance, and Inpaint\",\"url\":\"https://www.semanticscholar.org/paper/4994dd3557d76c9dd864e96215162f0471ad0d50\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740660\",\"name\":\"Jingyuan Chen\"},{\"authorId\":\"3179887\",\"name\":\"Xinpeng Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.18653/v1/D18-1015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"title\":\"Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/452aca244ef62a533d8b46a54c6212fe9fa3ce9a\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1903.02728\",\"authors\":[{\"authorId\":\"49051218\",\"name\":\"Ji Zhang\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"145159522\",\"name\":\"Ahmed Elgammal\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"debca9b7eccca1c1b704df0fbe187f56cd869842\",\"title\":\"Graphical Contrastive Losses for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/debca9b7eccca1c1b704df0fbe187f56cd869842\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.05493\",\"authors\":[{\"authorId\":\"150018075\",\"name\":\"Anant Khandelwal\"},{\"authorId\":\"1474541779\",\"name\":\"Niraj Kumar\"}],\"doi\":\"10.1145/3371158.3371165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e63a57e0d9ac211e80163345ef14380be2b60b9d\",\"title\":\"A Unified System for Aggression Identification in English Code-Mixed and Uni-Lingual Texts\",\"url\":\"https://www.semanticscholar.org/paper/e63a57e0d9ac211e80163345ef14380be2b60b9d\",\"venue\":\"COMAD/CODS\",\"year\":2020},{\"arxivId\":\"2004.08744\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"title\":\"Are we pretraining it right? Digging deeper into visio-linguistic pretraining\",\"url\":\"https://www.semanticscholar.org/paper/43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.00515\",\"authors\":[{\"authorId\":\"151475424\",\"name\":\"Tianrui Hui\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"15633953\",\"name\":\"Shaofei Huang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"1977587202\",\"name\":\"Sansi Yu\"},{\"authorId\":\"1977074324\",\"name\":\"Faxi Zhang\"},{\"authorId\":\"150147352\",\"name\":\"Jizhong Han\"}],\"doi\":\"10.1007/978-3-030-58607-2_4\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b907a8d6c6fc5a0c3a8857a9db4225dc922397ad\",\"title\":\"Linguistic Structure Guided Context Modeling for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b907a8d6c6fc5a0c3a8857a9db4225dc922397ad\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145488619\",\"name\":\"M. Liu\"},{\"authorId\":null,\"name\":\"Xiang Wang\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175864710def9b3e8b42e4613856d0b840c37615\",\"title\":\"Cross-modal Moment Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/175864710def9b3e8b42e4613856d0b840c37615\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1904.10151\",\"authors\":[{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"39471238\",\"name\":\"M. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3824bd35badf05e05cb6cbd22e2cf2b955a2734d\",\"title\":\"RERERE: Remote Embodied Referring Expressions in Real indoor Environments\",\"url\":\"https://www.semanticscholar.org/paper/3824bd35badf05e05cb6cbd22e2cf2b955a2734d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"143931909\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8e59f4cd2651ffb36a6009231dead1cae16d5987\",\"title\":\"Language Attention Proposal Attention + Training Inference man in white on the left holding a bat Subject Location Context Input query Input image\",\"url\":\"https://www.semanticscholar.org/paper/8e59f4cd2651ffb36a6009231dead1cae16d5987\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.05010\",\"authors\":[{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6897\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"title\":\"Temporally Grounding Language Queries in Videos by Contextual Boundary-aware Prediction\",\"url\":\"https://www.semanticscholar.org/paper/aa6c925c5f2fe61cdf8e09dd4ecbf1e7d220eac0\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2001.09308\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"144963373\",\"name\":\"Peng Tang\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02c9abd1c4567ba82289b1a989a51243087c6521\",\"title\":\"Look Closer to Ground Better: Weakly-Supervised Temporal Grounding of Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/02c9abd1c4567ba82289b1a989a51243087c6521\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08028\",\"authors\":[{\"authorId\":\"9724803\",\"name\":\"Chuanzi He\"},{\"authorId\":\"47297245\",\"name\":\"H. Zhu\"},{\"authorId\":\"1474350644\",\"name\":\"Jiyang Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"66449153\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPRW50498.2020.00482\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"badd03737b57e5595b1367ac22f4fbe649f26bf7\",\"title\":\"CPARR: Category-based Proposal Analysis for Referring Relationships\",\"url\":\"https://www.semanticscholar.org/paper/badd03737b57e5595b1367ac22f4fbe649f26bf7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1812.04794\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1715610\",\"name\":\"Qi Wu\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00206\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8ca91ad7763be4da05238aa17a9e5628f619dc0b\",\"title\":\"Neighbourhood Watch: Referring Expression Comprehension via Language-Guided Graph Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/8ca91ad7763be4da05238aa17a9e5628f619dc0b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48016903\",\"name\":\"Huiqing Wang\"},{\"authorId\":\"91924832\",\"name\":\"Z. Yan\"},{\"authorId\":\"2034349129\",\"name\":\"Dan Liu\"},{\"authorId\":\"3246784\",\"name\":\"H. Zhao\"},{\"authorId\":\"93110981\",\"name\":\"J. Zhao\"}],\"doi\":\"10.1109/ACCESS.2020.3041044\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"1ba31e857684030c0e0587472d6b9d4bd425f6ef\",\"title\":\"MDC-Kace: A Model for Predicting Lysine Acetylation Sites Based on Modular Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1ba31e857684030c0e0587472d6b9d4bd425f6ef\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1903.00839\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"50218594\",\"name\":\"Z. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/CVPR.2019.00205\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"title\":\"Improving Referring Expression Grounding With Cross-Modal Attention-Guided Erasing\",\"url\":\"https://www.semanticscholar.org/paper/cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.07669\",\"authors\":[{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":\"10.1109/CVPR.2019.00430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e973b927ec80a6d7db9835a7378c7c9d25fd35e3\",\"title\":\"Neural Sequential Phrase Grounding (SeqGROUND)\",\"url\":\"https://www.semanticscholar.org/paper/e973b927ec80a6d7db9835a7378c7c9d25fd35e3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.11561\",\"authors\":[{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"143962644\",\"name\":\"Zhi Liu\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/TMM.2020.2971171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28bd4e070c12b421db0f7b32438142038b82af53\",\"title\":\"Dual Convolutional LSTM Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/28bd4e070c12b421db0f7b32438142038b82af53\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1906.01784\",\"authors\":[{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"12086460\",\"name\":\"Xiaoyu Mo\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/TPAMI.2019.2911066\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2db3da6c2279c5a7e8238a63d5e79681e25c97cb\",\"title\":\"Learning to Compose and Reason with Language Tree Structures for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/2db3da6c2279c5a7e8238a63d5e79681e25c97cb\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1805.00545\",\"authors\":[{\"authorId\":null,\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f93ad8732ed2e92f09536ad744d1111cab93522\",\"title\":\"Weakly Supervised Attention Learning for Textual Phrases Grounding\",\"url\":\"https://www.semanticscholar.org/paper/3f93ad8732ed2e92f09536ad744d1111cab93522\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.03885\",\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.18653/v1/W19-1802\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e164e75632e23a7fba6a46d2ee2dc328720601af\",\"title\":\"Referring to Objects in Videos using Spatio-Temporal Identifying Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e164e75632e23a7fba6a46d2ee2dc328720601af\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"12086460\",\"name\":\"Xiaoyu Mo\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b31d3016349c164d7cad574b64f2bcb74eb2490\",\"title\":\"Recursive Grounding Pruning Input Language the skis of the man in the red jacket skis of man in red jacket RvG-Tree Constructor\",\"url\":\"https://www.semanticscholar.org/paper/8b31d3016349c164d7cad574b64f2bcb74eb2490\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"33c10383189c118465f8b40e8dba9213f57fa570\",\"title\":\"UNITER: Learning UNiversal Image-TExt Representations\",\"url\":\"https://www.semanticscholar.org/paper/33c10383189c118465f8b40e8dba9213f57fa570\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.11747\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a792ff56eeed530fab1935168510cbb16b0f1b68\",\"title\":\"Weak Supervision and Referring Attention for Temporal-Textual Association Learning\",\"url\":\"https://www.semanticscholar.org/paper/a792ff56eeed530fab1935168510cbb16b0f1b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1016/j.neucom.2020.06.091\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a26f46dec34e640b6a6ccb69cc28eda3c1eaac0d\",\"title\":\"vtGraphNet: Learning weakly-supervised scene graph for complex visual grounding\",\"url\":\"https://www.semanticscholar.org/paper/a26f46dec34e640b6a6ccb69cc28eda3c1eaac0d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3725761\",\"name\":\"XiaoQing Bu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"1519272531\",\"name\":\"Jianming Wang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"1709000\",\"name\":\"T. Chung\"}],\"doi\":\"10.1016/j.neucom.2020.06.129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e24b67d8fe5780f8685ee791cba8518c4174529d\",\"title\":\"Weakly supervised video object segmentation initialized with referring expression\",\"url\":\"https://www.semanticscholar.org/paper/e24b67d8fe5780f8685ee791cba8518c4174529d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.00753\",\"authors\":[{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"title\":\"Structured Multimodal Attentions for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.09042\",\"authors\":[{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1609/aaai.v34i07.6833\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c6d410891bef95ce4240eaa6d4908feb493527c\",\"title\":\"Learning Cross-modal Context Graph for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7c6d410891bef95ce4240eaa6d4908feb493527c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1904.12770\",\"authors\":[{\"authorId\":\"144966664\",\"name\":\"Mohammed Amer\"},{\"authorId\":\"2411411\",\"name\":\"T. Maul\"}],\"doi\":\"10.1007/s10462-019-09706-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b676bc4dc264c31a54cdd93f7cfaa7ade6bae86e\",\"title\":\"A review of modularization techniques in artificial neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b676bc4dc264c31a54cdd93f7cfaa7ade6bae86e\",\"venue\":\"Artificial Intelligence Review\",\"year\":2019},{\"arxivId\":\"1908.01189\",\"authors\":[{\"authorId\":\"1387996941\",\"name\":\"Hazan Anayurt\"},{\"authorId\":\"1387996951\",\"name\":\"Sezai Artun Ozyegin\"},{\"authorId\":\"1387997004\",\"name\":\"Ulfet Cetin\"},{\"authorId\":\"153160880\",\"name\":\"Utku Akta\\u015f\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"669c4c85770f13a2ff5508aef8ef62c9208948f1\",\"title\":\"Searching for Ambiguous Objects in Videos using Relational Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/669c4c85770f13a2ff5508aef8ef62c9208948f1\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.05049\",\"authors\":[{\"authorId\":\"2008154246\",\"name\":\"Zongheng Tang\"},{\"authorId\":\"47303356\",\"name\":\"Yue Liao\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2103483\",\"name\":\"X. Jin\"},{\"authorId\":\"2292508\",\"name\":\"Hongxu Jiang\"},{\"authorId\":\"1410184682\",\"name\":\"Qian Yu\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"74c30c601d5de21af098389abf7be0f8261e6c13\",\"title\":\"Human-centric Spatio-Temporal Video Grounding With Visual Transformers\",\"url\":\"https://www.semanticscholar.org/paper/74c30c601d5de21af098389abf7be0f8261e6c13\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.01655\",\"authors\":[{\"authorId\":\"2947115\",\"name\":\"Arjun Reddy Akula\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1403907739\",\"name\":\"Yaser Al-Onaizan\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"}],\"doi\":\"10.18653/v1/2020.acl-main.586\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"title\":\"Words aren't enough, their order matters: On the Robustness of Grounding Visual Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1bc3c2b305d0b508caa2a39f4663c6e79402c9e1\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2003.08813\",\"authors\":[{\"authorId\":\"51230543\",\"name\":\"G. Luo\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"40626740\",\"name\":\"Liujuan Cao\"},{\"authorId\":\"2867893\",\"name\":\"Cheng-Lin Wu\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/cvpr42600.2020.01005\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8d1bc83cc65d30e4619c49f53115012a209fd8c9\",\"title\":\"Multi-Task Collaborative Network for Joint Referring Expression Comprehension and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8d1bc83cc65d30e4619c49f53115012a209fd8c9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.02549\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/P19-1183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"title\":\"Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2001.06891\",\"authors\":[{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"90148415\",\"name\":\"Yang Zhao\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46936306\",\"name\":\"H. Liu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.01068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"title\":\"Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0a709bb1b4bce51de5aa67a362ea69e51a43d1e5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"145855898\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"title\":\"Supplementary Material : Referring to Object in Video using Spatio-Temporal Identifying Description\",\"url\":\"https://www.semanticscholar.org/paper/ef6dbe27031265a4663721883008f4c3e6a89c4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145515370\",\"name\":\"Qi Feng\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"},{\"authorId\":\"2132890\",\"name\":\"Qinxun Bai\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04fbfa561fc9dff9d7e495157e0dccb7ec3f21c7\",\"title\":\"Tell Me What to Track\",\"url\":\"https://www.semanticscholar.org/paper/04fbfa561fc9dff9d7e495157e0dccb7ec3f21c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3725761\",\"name\":\"XiaoQing Bu\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"}],\"doi\":\"10.1007/978-3-030-31723-2_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb92398ee4ecf17963bc2b261ca6e5c69128f63c\",\"title\":\"One-Shot Video Object Segmentation Initialized with Referring Expression\",\"url\":\"https://www.semanticscholar.org/paper/eb92398ee4ecf17963bc2b261ca6e5c69128f63c\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1909.02860\",\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"73596205\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47809582\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3343031.3351074\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"28691804ea6e9bb00249d864be36354f6c548ba5\",\"title\":\"Knowledge-guided Pairwise Reconstruction Network for Weakly Supervised Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/28691804ea6e9bb00249d864be36354f6c548ba5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1694585\",\"name\":\"Fanglin Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"title\":\"Referring Expression Grounding by Marginalizing Scene Graph Likelihood\",\"url\":\"https://www.semanticscholar.org/paper/4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.03589\",\"authors\":[{\"authorId\":\"6818270\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1109/CVPR.2019.00654\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"92366e3c446c30e4c783c61dcf420edd17695c73\",\"title\":\"Modularized Textual Grounding for Counterfactual Resilience\",\"url\":\"https://www.semanticscholar.org/paper/92366e3c446c30e4c783c61dcf420edd17695c73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.09099\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1007/978-3-030-58589-1_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"title\":\"TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09554\",\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/tmm.2020.3042066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d8398d9c36d25ad1363d9a5dd922dbbfa7be3be\",\"title\":\"Referring Expression Comprehension: A Survey of Methods and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/9d8398d9c36d25ad1363d9a5dd922dbbfa7be3be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.04686\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2019.00647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68a2eb5890eb67989df5fb42b929d10e5e8e5a47\",\"title\":\"Multi-Target Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/68a2eb5890eb67989df5fb42b929d10e5e8e5a47\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.08481\",\"authors\":[{\"authorId\":\"7264115\",\"name\":\"Oier Mees\"},{\"authorId\":\"1490646250\",\"name\":\"A. Emek\"},{\"authorId\":\"21271105\",\"name\":\"Johan Vertens\"},{\"authorId\":\"1725973\",\"name\":\"W. Burgard\"}],\"doi\":\"10.1109/ICRA40945.2020.9197472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"686908bd36c69fdb673c06f179a77de13ffb1f7b\",\"title\":\"Learning Object Placements For Relational Instructions by Hallucinating Scene Representations\",\"url\":\"https://www.semanticscholar.org/paper/686908bd36c69fdb673c06f179a77de13ffb1f7b\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47988382\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1007/978-3-030-60633-6_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e64cbc4818b30e32f7068d2454a365a785919ab\",\"title\":\"Global Context Enhanced Multi-modal Fusion for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2e64cbc4818b30e32f7068d2454a365a785919ab\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"2012.10890\",\"authors\":[{\"authorId\":\"2018700866\",\"name\":\"Chao Yang\"},{\"authorId\":\"50248868\",\"name\":\"Guoqing Wang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"2476503\",\"name\":\"H. Shen\"},{\"authorId\":\"145030306\",\"name\":\"S. Feng\"},{\"authorId\":\"1796274181\",\"name\":\"Bin Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1275efae4f9f749b876c1f9dd527302de63a88c3\",\"title\":\"PPGN: Phrase-Guided Proposal Generation Network For Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/1275efae4f9f749b876c1f9dd527302de63a88c3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.15124\",\"authors\":[{\"authorId\":\"83574123\",\"name\":\"Emanuele Bugliarello\"},{\"authorId\":\"1750769\",\"name\":\"Ryan Cotterell\"},{\"authorId\":\"102837708\",\"name\":\"N. Okazaki\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"title\":\"Multimodal Pretraining Unmasked: Unifying the Vision and Language BERTs\",\"url\":\"https://www.semanticscholar.org/paper/82a6f9cce3e8acd0ef9e3ca5c7592bd7b9c058fd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.04678\",\"authors\":[{\"authorId\":\"2081195\",\"name\":\"Tzu-Hsiang Lin\"},{\"authorId\":\"1783635\",\"name\":\"Alexander I. Rudnicky\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"153586399\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"acc12e338ec6d77f371d1123667110daa8770ecd\",\"title\":\"Adjusting Image Attributes of Localized Regions with Low-level Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/acc12e338ec6d77f371d1123667110daa8770ecd\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1909.11740\",\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"83147159\",\"name\":\"Faisal Ahmed\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1007/978-3-030-58577-8_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"title\":\"UNITER: UNiversal Image-TExt Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/d8a305b9366608d54452ac30459ee57b4f5cf1c9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"50e9aabc46ea2d1ee80aacfcade14746776a6761\",\"title\":\"Woman BrownPerson BluePerson Boy Counterfactual Phrase Grounding : woman in brown Result N / A\",\"url\":\"https://www.semanticscholar.org/paper/50e9aabc46ea2d1ee80aacfcade14746776a6761\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100818163\",\"name\":\"Chen-chen Jing\"},{\"authorId\":\"145558278\",\"name\":\"Y. Wu\"},{\"authorId\":\"144315453\",\"name\":\"Mingtao Pei\"},{\"authorId\":\"46972595\",\"name\":\"Yao Hu\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1145/3394171.3413902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc24a5a8d6629eec5c8d87d48ab891bc17e862ff\",\"title\":\"Visual-Semantic Graph Matching for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/cc24a5a8d6629eec5c8d87d48ab891bc17e862ff\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35137594\",\"name\":\"Jinpeng Mi\"},{\"authorId\":\"1939598\",\"name\":\"Jian-Zhi Lyu\"},{\"authorId\":\"1739175813\",\"name\":\"Song Tang\"},{\"authorId\":\"153082688\",\"name\":\"Qingdu Li\"},{\"authorId\":\"50561627\",\"name\":\"J. Zhang\"}],\"doi\":\"10.3389/fnbot.2020.00043\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ceb666a47c683b0555f8976e7d2a0f15f9cf8be2\",\"title\":\"Interactive Natural Language Grounding via Referring Expression Comprehension and Scene Graph Parsing\",\"url\":\"https://www.semanticscholar.org/paper/ceb666a47c683b0555f8976e7d2a0f15f9cf8be2\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":\"1908.10568\",\"authors\":[{\"authorId\":\"49544460\",\"name\":\"Xuejing Liu\"},{\"authorId\":\"143931909\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICCV.2019.00270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"958f102ce7fdaa9f2467f0c2f6b3071b824394af\",\"title\":\"Adaptive Reconstruction Network for Weakly Supervised Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/958f102ce7fdaa9f2467f0c2f6b3071b824394af\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1906.00534\",\"authors\":[{\"authorId\":\"2358097\",\"name\":\"Xiao Zhang\"},{\"authorId\":\"2877164\",\"name\":\"Dan Goldwasser\"}],\"doi\":\"10.18653/v1/P19-1055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9dd02d90e79d3d005a91bbe09e5b74a21810def\",\"title\":\"Sentiment Tagging with Partial Labels using Modular Architectures\",\"url\":\"https://www.semanticscholar.org/paper/c9dd02d90e79d3d005a91bbe09e5b74a21810def\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"152599661\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2019.00589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"949959250e487617faa3035b05b52aa03a8e9895\",\"title\":\"Generating Easy-to-Understand Referring Expressions for Target Identifications\",\"url\":\"https://www.semanticscholar.org/paper/949959250e487617faa3035b05b52aa03a8e9895\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2009.08792\",\"authors\":[{\"authorId\":\"1388019217\",\"name\":\"Thierry Deruyttere\"},{\"authorId\":\"83754395\",\"name\":\"Simon Vandenhende\"},{\"authorId\":\"1388019229\",\"name\":\"Dusan Grujicic\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1758219\",\"name\":\"Matthew B. Blaschko\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9a43ed50d4ae027cfd29ab3fdbb731f8439c49c5\",\"title\":\"Commands 4 Autonomous Vehicles (C4AV) Workshop Summary\",\"url\":\"https://www.semanticscholar.org/paper/9a43ed50d4ae027cfd29ab3fdbb731f8439c49c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.03208\",\"authors\":[{\"authorId\":\"153866008\",\"name\":\"Kunal Pratap Singh\"},{\"authorId\":\"1978789684\",\"name\":\"Suvaansh Bhambri\"},{\"authorId\":\"2032185280\",\"name\":\"Byeonghwi Kim\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"817d92d05f768678eb32e82ac46ad65ec447dca4\",\"title\":\"MOCA: A Modular Object-Centric Approach for Interactive Instruction Following\",\"url\":\"https://www.semanticscholar.org/paper/817d92d05f768678eb32e82ac46ad65ec447dca4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10972\",\"authors\":[{\"authorId\":\"49039823\",\"name\":\"Weixia Zhang\"},{\"authorId\":\"1409866378\",\"name\":\"Chao Ma\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1109/TCSVT.2020.3039522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38bb24348dbcec08285a8670596ec7c9b3895603\",\"title\":\"Language-guided Navigation via Cross-Modal Grounding and Alternate Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/38bb24348dbcec08285a8670596ec7c9b3895603\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.02206\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"47621053\",\"name\":\"A. Gholami\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"title\":\"Scan2Cap: Context-aware Dense Captioning in RGB-D Scans\",\"url\":\"https://www.semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02448\",\"authors\":[{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1855095179\",\"name\":\"Pengwei Tang\"},{\"authorId\":\"3008849\",\"name\":\"Zhikang Zhou\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":\"10.1145/3394171.3414053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"title\":\"Fine-grained Iterative Attention Network for Temporal Language Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66125335\",\"name\":\"Heqian Qiu\"},{\"authorId\":\"30548955\",\"name\":\"Hongliang Li\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"},{\"authorId\":\"1706784\",\"name\":\"Fanman Meng\"},{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"},{\"authorId\":\"1993661016\",\"name\":\"Taijin Zhao\"},{\"authorId\":\"1684869\",\"name\":\"K. N. Ngan\"}],\"doi\":\"10.1145/3394171.3413850\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ee97b258b907a8859a67014d1bdb8bf3fcc4894\",\"title\":\"Language-Aware Fine-Grained Object Representation for Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/7ee97b258b907a8859a67014d1bdb8bf3fcc4894\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2006.03776\",\"authors\":[{\"authorId\":\"3456962\",\"name\":\"Amar Shrestha\"},{\"authorId\":\"9091383\",\"name\":\"Krittaphat Pugdeethosapol\"},{\"authorId\":\"122851204\",\"name\":\"Haowen Fang\"},{\"authorId\":\"1862322\",\"name\":\"Q. Qiu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"032a517f0c7e27a5fa95522c49de423633036b5f\",\"title\":\"MAGNet: Multi-Region Attention-Assisted Grounding of Natural Language Queries at Phrase Level\",\"url\":\"https://www.semanticscholar.org/paper/032a517f0c7e27a5fa95522c49de423633036b5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.02724\",\"authors\":[{\"authorId\":\"47070750\",\"name\":\"Daniel Fried\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ede8ba65c4db10d357d9c3bf8e75b092f536fc84\",\"title\":\"Speaker-Follower Models for Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/ede8ba65c4db10d357d9c3bf8e75b092f536fc84\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2009.01449\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"144735552\",\"name\":\"Wenbo Ma\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8382e838ffba7a940b80679d9724710fd0143215\",\"title\":\"Ref-NMS: Breaking Proposal Bottlenecks in Two-Stage Referring Expression Grounding\",\"url\":\"https://www.semanticscholar.org/paper/8382e838ffba7a940b80679d9724710fd0143215\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.04405\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2019.01039\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2dc698077cb178286c737484dcf67c5ab19314d0\",\"title\":\"Language-Conditioned Graph Networks for Relational Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2dc698077cb178286c737484dcf67c5ab19314d0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2007.14626\",\"authors\":[{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"1840579673\",\"name\":\"Zizheng Pan\"},{\"authorId\":\"47180098\",\"name\":\"S. Zhang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58607-2_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0152a8fd87cb60ad30c296823829802c13a9986\",\"title\":\"Object-and-Action Aware Model for Visual Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/f0152a8fd87cb60ad30c296823829802c13a9986\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1906.03561\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"title\":\"Joint Visual Grounding with Language Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b32459b8ebed74efed3d29fa6703fff855ea365\",\"title\":\"Task Focused Robotic Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7b32459b8ebed74efed3d29fa6703fff855ea365\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.06354\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00478\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"title\":\"A Fast and Accurate One-Stage Approach to Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/46559d98a516a9520afa0638bba28f5fe7fb4ceb\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327993\",\"name\":\"A. Khoreva\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-030-11018-5_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acb8b640596ab63b56832c730d69522633c721eb\",\"title\":\"Video Object Segmentation with Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/acb8b640596ab63b56832c730d69522633c721eb\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1907.03609\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/TPAMI.2019.2926266\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"title\":\"Variational Context: Exploiting Visual and Textual Context for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/df9c0a59bdbd54be299ca63b60773eed62e2c611\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":\"2004.02707\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"title\":\"Sub-Instruction Aware Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c71cf890f1e6169c28407a985dcfd2b0b156d9e2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.07660\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"2008198436\",\"name\":\"Abhaysinh Zala\"},{\"authorId\":\"2008207270\",\"name\":\"Graham Burri\"},{\"authorId\":\"1725438390\",\"name\":\"H. Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8a95123dfd60ed5424cb669b7f4336127c6770f\",\"title\":\"ArraMon: A Joint Navigation-Assembly Instruction Interpretation Task in Dynamic Environments\",\"url\":\"https://www.semanticscholar.org/paper/d8a95123dfd60ed5424cb669b7f4336127c6770f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":3441497,\"doi\":\"10.1109/CVPR.2018.00142\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":62,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"references\":[{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/TPAMI.2018.2844175\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a0912bb76777469295bb2c059faee907e7f3258\",\"title\":\"Mask R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/1a0912bb76777469295bb2c059faee907e7f3258\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00525\",\"authors\":[{\"authorId\":\"3081378\",\"name\":\"Varun K. Nagaraja\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46493-0_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"title\":\"Modeling Context Between Objects for Referring Expression Understanding\",\"url\":\"https://www.semanticscholar.org/paper/86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1603.06180\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46448-0_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b133e361e2f8af22b823d25060b2e7c47f690985\",\"title\":\"Segmentation from Natural Language Expressions\",\"url\":\"https://www.semanticscholar.org/paper/b133e361e2f8af22b823d25060b2e7c47f690985\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1612.09542\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2017.375\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"a5b64709c677c131ec8b7846d3493df53987fa6f\",\"title\":\"A Joint Speaker-Listener-Reinforcer Model for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a5b64709c677c131ec8b7846d3493df53987fa6f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.02814\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2708709\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"title\":\"Image Captioning and Visual Question Answering Based on Attributes and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/6acd385b2742f65359efb99543ebfb9a0d1b850f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"2022168\",\"name\":\"Diyi Yang\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.18653/v1/N16-1174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"455afd748e8834ef521e4b67c7c056d3c33429e2\",\"title\":\"Hierarchical Attention Networks for Document Classification\",\"url\":\"https://www.semanticscholar.org/paper/455afd748e8834ef521e4b67c7c056d3c33429e2\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"acc4e56c44771ebf69302a06af51498aeb0a6ac8\",\"title\":\"Parsing with Compositional Vector Grammars\",\"url\":\"https://www.semanticscholar.org/paper/acc4e56c44771ebf69302a06af51498aeb0a6ac8\",\"venue\":\"ACL\",\"year\":2013},{\"arxivId\":\"1611.01796\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a13f7c43b767b1fb72ef107ef62a4ddd48dd2a7\",\"title\":\"Modular Multitask Reinforcement Learning with Policy Sketches\",\"url\":\"https://www.semanticscholar.org/paper/3a13f7c43b767b1fb72ef107ef62a4ddd48dd2a7\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1703.07939\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2017.143\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"title\":\"Recurrent Multimodal Interaction for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3d69edb02e935b782b90175cb691f6ab5f4bd64f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1608.00272\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"3451188\",\"name\":\"Patrick Poirson\"},{\"authorId\":\"144947353\",\"name\":\"S. Yang\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46475-6_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"title\":\"Modeling Context in Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/29efbe391950ae438c63d86ad5c82b2942efb0b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1708.08874\",\"authors\":[{\"authorId\":\"3393384\",\"name\":\"Jong-Chyi Su\"},{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2017.53\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"title\":\"Reasoning About Fine-Grained Attribute Phrases Using Reference Games\",\"url\":\"https://www.semanticscholar.org/paper/956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Yu\"},{\"authorId\":null,\"name\":\"P. Poirson\"},{\"authorId\":null,\"name\":\"S. Yang\"},{\"authorId\":null,\"name\":\"A. C. Berg\"},{\"authorId\":null,\"name\":\"T. L. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"eling context in referring expressions\",\"url\":\"\",\"venue\":\"In ECCV\",\"year\":null},{\"arxivId\":\"1704.05526\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.93\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a396a6febdacb84340d139096455e67049ac1e22\",\"title\":\"Learning to Reason: End-to-End Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a396a6febdacb84340d139096455e67049ac1e22\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1701.03439\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2017.333\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9b45e9a40313096abf530df3b98a1dfa1553f17b\",\"title\":\"Comprehension-Guided Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9b45e9a40313096abf530df3b98a1dfa1553f17b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.01676\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3407447\",\"name\":\"Rama Kovvuri\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2017.95\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"title\":\"Query-Guided Regression Network with Context Policy for Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/ff4b351dccb970f13a345adf0647ffe8c2021f1f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.03470\",\"authors\":[{\"authorId\":\"145602574\",\"name\":\"L. Wang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"19353632\",\"name\":\"J. Huang\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/TPAMI.2018.2797921\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"title\":\"Learning Two-Branch Neural Networks for Image-Text Matching Tasks\",\"url\":\"https://www.semanticscholar.org/paper/f865268b81eeb29d94775f22c6bc24dcc5e1b2e9\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"C. Shen\"},{\"authorId\":null,\"name\":\"P. Wang\"},{\"authorId\":null,\"name\":\"A. Dick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and A\",\"url\":\"\",\"venue\":\"van den Hengel. Image captioning and visual question answering based on attributes and external knowledge. IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Qiu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Image captioning with semantic attention eling context in referring expressions\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1702.02138\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bca1b3e663600824b87d19de66d06cd338b5309a\",\"title\":\"An Implementation of Faster RCNN with Study for Region Sampling\",\"url\":\"https://www.semanticscholar.org/paper/bca1b3e663600824b87d19de66d06cd338b5309a\",\"venue\":\"ArXiv\",\"year\":2017}],\"title\":\"MAttNet: Modular Attention Network for Referring Expression Comprehension\",\"topics\":[{\"topic\":\"List comprehension\",\"topicId\":\"263264\",\"url\":\"https://www.semanticscholar.org/topic/263264\"},{\"topic\":\"Microsoft Research\",\"topicId\":\"73897\",\"url\":\"https://www.semanticscholar.org/topic/73897\"},{\"topic\":\"Minimum bounding box\",\"topicId\":\"195508\",\"url\":\"https://www.semanticscholar.org/topic/195508\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"}],\"url\":\"https://www.semanticscholar.org/paper/fdce9cbe5c726201575b3c8a8c1af0752f1af53f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"