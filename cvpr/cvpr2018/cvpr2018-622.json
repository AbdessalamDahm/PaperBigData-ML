"{\"abstract\":\"Existing methods to recognize actions in static images take the images at their face value, learning the appearances-objects, scenes, and body poses-that distinguish each action class. However, such models are deprived of the rich dynamic structure and motions that also define human activity. We propose an approach that hallucinates the unobserved future motion implied by a single snapshot to help static-image action recognition. The key idea is to learn a prior over short-term dynamics from thousands of unlabeled videos, infer the anticipated optical flow on novel static images, and then train discriminative models that exploit both streams of information. Our main contributions are twofold. First, we devise an encoder-decoder convolutional neural network and a novel optical flow encoding that can translate a static image into an accurate flow map. Second, we show the power of hallucinated flow for recognition, successfully transferring the learned motion into a standard two-stream network for activity recognition. On seven datasets, we demonstrate the power of the approach. It not only achieves state-of-the-art accuracy for dense optical flow prediction, but also consistently enhances recognition of actions and dynamic scenes.\",\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\",\"url\":\"https://www.semanticscholar.org/author/3387849\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\",\"url\":\"https://www.semanticscholar.org/author/144752314\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\",\"url\":\"https://www.semanticscholar.org/author/1794409\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"23982870\",\"name\":\"Badour Albahar\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"b6ef158d95042f39765df04373c01546524c9ccd\",\"title\":\"Im2Vid: Future Video Prediction for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b6ef158d95042f39765df04373c01546524c9ccd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.09102\",\"authors\":[{\"authorId\":\"51249823\",\"name\":\"Pengze Liu\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78569509e61269f5d2276b80f4fd41c22617ccc4\",\"title\":\"Localization Guided Learning for Pedestrian Attribute Recognition\",\"url\":\"https://www.semanticscholar.org/paper/78569509e61269f5d2276b80f4fd41c22617ccc4\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.05674\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":\"10.1007/978-981-15-3651-9_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f99d62a02d91de622dbf5208ef859938980c16d6\",\"title\":\"Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/f99d62a02d91de622dbf5208ef859938980c16d6\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.11481\",\"authors\":[{\"authorId\":\"121860170\",\"name\":\"Lingzhi Zhang\"},{\"authorId\":\"24524012\",\"name\":\"J. Wang\"},{\"authorId\":\"46865173\",\"name\":\"Jianbo Shi\"}],\"doi\":\"10.1109/WACV45572.2020.9093636\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4482318f80173f35fe47e78f3f2982cf816440ec\",\"title\":\"Multimodal Image Outpainting with Regularized Normalized Diversification\",\"url\":\"https://www.semanticscholar.org/paper/4482318f80173f35fe47e78f3f2982cf816440ec\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1910.07192\",\"authors\":[{\"authorId\":\"2420042\",\"name\":\"Y. Endo\"},{\"authorId\":\"2504432\",\"name\":\"Y. Kanamori\"},{\"authorId\":\"36375845\",\"name\":\"Shigeru Kuriyama\"}],\"doi\":\"10.1145/3355089.3356523\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf234eb0d6f4eae787be83c8d9756e8c34e2e80a\",\"title\":\"Animating landscape\",\"url\":\"https://www.semanticscholar.org/paper/bf234eb0d6f4eae787be83c8d9756e8c34e2e80a\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":\"2006.02038\",\"authors\":[{\"authorId\":\"121860170\",\"name\":\"Lingzhi Zhang\"},{\"authorId\":\"24524012\",\"name\":\"J. Wang\"},{\"authorId\":\"89982379\",\"name\":\"Yinshuang Xu\"},{\"authorId\":\"46934441\",\"name\":\"Jie Min\"},{\"authorId\":\"1388640925\",\"name\":\"Tarmily Wen\"},{\"authorId\":\"144716639\",\"name\":\"J. Gee\"},{\"authorId\":\"46865173\",\"name\":\"Jianbo Shi\"}],\"doi\":\"10.1109/cvpr42600.2020.00552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11d4a2e09b5de6ee7d0de92f6c2133591c34097a\",\"title\":\"Nested Scale-Editing for Conditional Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/11d4a2e09b5de6ee7d0de92f6c2133591c34097a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669190956\",\"name\":\"Quanling Meng\"},{\"authorId\":\"9517714\",\"name\":\"Heyan Zhu\"},{\"authorId\":\"8660383\",\"name\":\"W. Zhang\"},{\"authorId\":\"37507545\",\"name\":\"Xuefeng Piao\"},{\"authorId\":\"1669161026\",\"name\":\"A. Zhang\"}],\"doi\":\"10.1145/3350840\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a27008678d149d4d286654217a29559c2a55b96\",\"title\":\"Action Recognition Using Form and Motion Modalities\",\"url\":\"https://www.semanticscholar.org/paper/8a27008678d149d4d286654217a29559c2a55b96\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144910246\",\"name\":\"Chi Xu\"},{\"authorId\":\"1689334\",\"name\":\"Y. Makihara\"},{\"authorId\":\"48569208\",\"name\":\"Xiaohong Li\"},{\"authorId\":\"1715071\",\"name\":\"Y. Yagi\"},{\"authorId\":\"144784108\",\"name\":\"Jianfeng Lu\"}],\"doi\":\"10.1007/978-3-030-58529-7_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48bdf0d57c76f0e9a1b97dd454b857502b05e93f\",\"title\":\"Gait Recognition from a Single Image Using a Phase-Aware Gait Cycle Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/48bdf0d57c76f0e9a1b97dd454b857502b05e93f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"1471440106\",\"name\":\"W. Meng\"},{\"authorId\":\"4169031\",\"name\":\"Hui-quan Li\"},{\"authorId\":\"8628276\",\"name\":\"Xuehong Cui\"}],\"doi\":\"10.1109/ACCESS.2019.2959206\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"430ee2f6b5a1d4c194e26088ca8e3b58ae571605\",\"title\":\"Multimodal Spatiotemporal Networks for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/430ee2f6b5a1d4c194e26088ca8e3b58ae571605\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036790405\",\"name\":\"Kiyohiko Iwamura\"},{\"authorId\":\"34769384\",\"name\":\"Jun Younes Louhi Kasahara\"},{\"authorId\":\"24316406\",\"name\":\"A. Moro\"},{\"authorId\":\"152521159\",\"name\":\"A. Yamashita\"},{\"authorId\":\"50631807\",\"name\":\"H. Asama\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b6bea157580146a416540b467fa3002ccd044b7d\",\"title\":\"Potential of Incorporating Motion Estimation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b6bea157580146a416540b467fa3002ccd044b7d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.03173\",\"authors\":[{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":\"10.1109/ICCV.2019.01018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bbfde97cb870408c4c78c9ec1c47c962b268b8d\",\"title\":\"Ego-Pose Estimation and Forecasting As Real-Time PD Control\",\"url\":\"https://www.semanticscholar.org/paper/7bbfde97cb870408c4c78c9ec1c47c962b268b8d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1614034792\",\"name\":\"Yang Liu\"},{\"authorId\":\"8559994\",\"name\":\"Qingchao Chen\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58568-6_15\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0d9f0a0844ebf33d38bbbd3da5d1cd3dbd4ffd2d\",\"title\":\"Amplifying Key Cues for Human-Object-Interaction Detection\",\"url\":\"https://www.semanticscholar.org/paper/0d9f0a0844ebf33d38bbbd3da5d1cd3dbd4ffd2d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46739281\",\"name\":\"A. Batra\"},{\"authorId\":\"48039353\",\"name\":\"Suriya Singh\"},{\"authorId\":\"35708956\",\"name\":\"Guan Pang\"},{\"authorId\":\"122607384\",\"name\":\"S. Basu\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2019.01063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a794fe1321a9a27867ffba33bb84163c8298b986\",\"title\":\"Improved Road Connectivity by Joint Learning of Orientation and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a794fe1321a9a27867ffba33bb84163c8298b986\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"}],\"doi\":\"10.1007/978-3-030-11024-6_56\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c144f5de26acfb37b6f3dd828fafa0582f87df36\",\"title\":\"\\\"What Is Optical Flow For?\\\": Workshop Results and Summary\",\"url\":\"https://www.semanticscholar.org/paper/c144f5de26acfb37b6f3dd828fafa0582f87df36\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1812.08249\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/WACV45572.2020.9093274\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2766379db5d9907766dab034a52867d7394a265e\",\"title\":\"D3D: Distilled 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2766379db5d9907766dab034a52867d7394a265e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37947229\",\"name\":\"Hoang-An Le\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"31582751\",\"name\":\"Anil S. Baslamisli\"},{\"authorId\":\"1968574\",\"name\":\"Sezer Karaoglu\"},{\"authorId\":\"152909053\",\"name\":\"T. Gevers\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"07921f59f9a68bb6e302462f39587861e41c8fe0\",\"title\":\"Image matching ARAP 2 D image deformation Image segmentation Image warping Background generating Supervised training\",\"url\":\"https://www.semanticscholar.org/paper/07921f59f9a68bb6e302462f39587861e41c8fe0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5520c2d70595da6db1c43c9c5b1476f8ca1b4469\",\"title\":\"Learning to Predict Human Behavior from Video\",\"url\":\"https://www.semanticscholar.org/paper/5520c2d70595da6db1c43c9c5b1476f8ca1b4469\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27039516\",\"name\":\"Almoctar Hassoumi\"},{\"authorId\":\"2231675\",\"name\":\"Vsevolod Peysakhovich\"},{\"authorId\":\"2433007\",\"name\":\"C. Hurter\"}],\"doi\":\"10.1145/3314111.3319820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4738fd376d281a1d6bb14e888ba93892a23ef7\",\"title\":\"EyeFlow: pursuit interactions using an unmodified camera\",\"url\":\"https://www.semanticscholar.org/paper/9f4738fd376d281a1d6bb14e888ba93892a23ef7\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":\"1908.04781\",\"authors\":[{\"authorId\":\"49050667\",\"name\":\"Jason Y. Zhang\"},{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2019.00721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20ac7634e9b406c37b0867ea8e6c0e37ae0794ae\",\"title\":\"Predicting 3D Human Dynamics From Video\",\"url\":\"https://www.semanticscholar.org/paper/20ac7634e9b406c37b0867ea8e6c0e37ae0794ae\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.01946\",\"authors\":[{\"authorId\":\"37947229\",\"name\":\"Hoang-An Le\"},{\"authorId\":\"52230565\",\"name\":\"Tushar Nimbhorkar\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"31582751\",\"name\":\"Anil S. Baslamisli\"},{\"authorId\":\"1968574\",\"name\":\"Sezer Karaoglu\"},{\"authorId\":\"1695527\",\"name\":\"T. Gevers\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"428f7a68e3d787fc4ed490b5b3efe86c9f475c72\",\"title\":\"Unsupervised Generation of Optical Flow Datasets\",\"url\":\"https://www.semanticscholar.org/paper/428f7a68e3d787fc4ed490b5b3efe86c9f475c72\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1912.00308\",\"authors\":[{\"authorId\":\"121310313\",\"name\":\"Yiyi Zhang\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"13944031\",\"name\":\"Ziqi Pan\"},{\"authorId\":\"1438947172\",\"name\":\"Meichao Luo\"},{\"authorId\":\"49051251\",\"name\":\"Jianfu Zhang\"},{\"authorId\":\"2476347\",\"name\":\"Dawei Cheng\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6990\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"223eba328e72650eda1cc85817f4d396cc116eb4\",\"title\":\"Exploiting Motion Information from Unlabeled Videos for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/223eba328e72650eda1cc85817f4d396cc116eb4\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"114320931\",\"name\":\"Hai-Zhen Xuan\"},{\"authorId\":\"41189853\",\"name\":\"H. Zhang\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"2840539\",\"name\":\"Kim-Kwang Raymond Choo\"}],\"doi\":\"10.1109/JIOT.2019.2911669\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"title\":\"Adaptive Fusion and Category-Level Dictionary Learning Model for Multiview Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2019},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"title\":\"2.5D Visual Sound\",\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.13399\",\"authors\":[{\"authorId\":\"151136071\",\"name\":\"Mattia Segu\"},{\"authorId\":\"1781788981\",\"name\":\"Federico Pirovano\"},{\"authorId\":\"2029237675\",\"name\":\"Gianmario Fumagalli\"},{\"authorId\":\"1557389943\",\"name\":\"Amedeo Fabris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"title\":\"Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal Heatmaps\",\"url\":\"https://www.semanticscholar.org/paper/ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740811711\",\"name\":\"Shinya Michibata\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"},{\"authorId\":\"1733070603\",\"name\":\"Atsushi Hashimoto\"}],\"doi\":\"10.1145/3379175.3391712\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66bead45f2fff3f9175658eb036f1a38031f2ba7\",\"title\":\"Cooking Activity Recognition in Egocentric Videos with a Hand Mask Image Branch in the Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/66bead45f2fff3f9175658eb036f1a38031f2ba7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.15128\",\"authors\":[{\"authorId\":\"118300344\",\"name\":\"Aleksander Holynski\"},{\"authorId\":\"1396759259\",\"name\":\"Brian Curless\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"title\":\"Animating Pictures with Eulerian Motion Fields\",\"url\":\"https://www.semanticscholar.org/paper/a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.01601\",\"authors\":[{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"},{\"authorId\":\"49050667\",\"name\":\"Jason Y. Zhang\"},{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2019.00576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"436142577b23f89832fe6ee2d77ee9585e103729\",\"title\":\"Learning 3D Human Dynamics From Video\",\"url\":\"https://www.semanticscholar.org/paper/436142577b23f89832fe6ee2d77ee9585e103729\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.00729\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"1784457521\",\"name\":\"Rodrigo Rene Rai Munoz Abujder\"},{\"authorId\":\"35064523\",\"name\":\"K. Foster\"},{\"authorId\":\"31933153\",\"name\":\"S. Hagstrom\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"145625889\",\"name\":\"Myron Z. Brown\"}],\"doi\":\"10.1109/cvpr42600.2020.01452\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e3af408dabdce9349370e646c48e6dc34571b9e\",\"title\":\"Learning Geocentric Object Pose in Oblique Monocular Images\",\"url\":\"https://www.semanticscholar.org/paper/3e3af408dabdce9349370e646c48e6dc34571b9e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49350890\",\"name\":\"Kwang-Yon Kim\"},{\"authorId\":\"2499044\",\"name\":\"Yeong Jun Koh\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/ACCESS.2020.3003751\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cee7fa07f5eb672d700220c0c89eb19cbda284b5\",\"title\":\"Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression and Semi-Supervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/cee7fa07f5eb672d700220c0c89eb19cbda284b5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.11799\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"26485115\",\"name\":\"Lianqiang Zhou\"}],\"doi\":\"10.24963/ijcai.2019/130\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"37252f8cd1324a972131fc6a92f778835ba2fac3\",\"title\":\"Hallucinating Optical Flow Features for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/37252f8cd1324a972131fc6a92f778835ba2fac3\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378263\",\"name\":\"Kyungrae Kim\"},{\"authorId\":\"10702381\",\"name\":\"W. Choi\"},{\"authorId\":\"2499044\",\"name\":\"Yeong Jun Koh\"},{\"authorId\":\"40581495\",\"name\":\"Seong-Gyun Jeong\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/ICCV.2019.00036\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"30d36795ef383051d6f1f5db3d6f3c22f8beb0e5\",\"title\":\"Instance-Level Future Motion Estimation in a Single Image Based on Ordinal Regression\",\"url\":\"https://www.semanticscholar.org/paper/30d36795ef383051d6f1f5db3d6f3c22f8beb0e5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1638059605\",\"name\":\"Yuki Endo\"},{\"authorId\":\"2504432\",\"name\":\"Y. Kanamori\"},{\"authorId\":\"36375845\",\"name\":\"Shigeru Kuriyama\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ab351fa2be0a268742905b04f9ce0f0369139a41\",\"title\":\"Animating Landscape: Self-Supervised Learning of Decoupled Motion and Appearance for Single-Image Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/ab351fa2be0a268742905b04f9ce0f0369139a41\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.01455\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2019.01018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"title\":\"Representation Flow for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.03958\",\"authors\":[{\"authorId\":\"32446834\",\"name\":\"Vinoj Jayasundara\"},{\"authorId\":\"1443776158\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c4fed2db84c9579bf67f465f8bcccb22d358e93\",\"title\":\"FlowCaps: Optical Flow Estimation with Capsule Networks For Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c4fed2db84c9579bf67f465f8bcccb22d358e93\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":5028408,\"doi\":\"10.1109/CVPR.2018.00622\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":11,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"references\":[{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2003.1238420\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"804d86dd7ab3498266922244e73a88c1add5a6ab\",\"title\":\"Recognizing action at a distance\",\"url\":\"https://www.semanticscholar.org/paper/804d86dd7ab3498266922244e73a88c1add5a6ab\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1701.05349\",\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d541bf669dda499f86b4dd2ac4e263134a3cd4c\",\"title\":\"Pixel Objectness\",\"url\":\"https://www.semanticscholar.org/paper/2d541bf669dda499f86b4dd2ac4e263134a3cd4c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1703.10593\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"145599603\",\"name\":\"T. Park\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2017.244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43d954cf8133e6254499f3d68e45218067e4941\",\"title\":\"Unpaired Image-to-Image Translation Using Cycle-Consistent Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c43d954cf8133e6254499f3d68e45218067e4941\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1701.05384\",\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2017.228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a76dc85d8c458eebdffa87c64233d1345163478\",\"title\":\"FusionSeg: Learning to Combine Motion and Appearance for Fully Automatic Segmentation of Generic Objects in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a76dc85d8c458eebdffa87c64233d1345163478\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2862000\",\"name\":\"A. Prest\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"}],\"doi\":\"10.1109/TPAMI.2011.158\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a2427eeb32d59ccfc634b46eae350be14d10e88\",\"title\":\"Weakly Supervised Learning of Interactions between Humans and Objects\",\"url\":\"https://www.semanticscholar.org/paper/3a2427eeb32d59ccfc634b46eae350be14d10e88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Wang\"},{\"authorId\":null,\"name\":\"Y. Qiao\"},{\"authorId\":null,\"name\":\"D. Lin\"},{\"authorId\":null,\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Mid - level 3 d parts for human motion recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145874477\",\"name\":\"Li Cheng\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":\"10.1109/TIP.2016.2605305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acf4f1387de054984a735fa9f9c3a827bebc32d1\",\"title\":\"Action Recognition in Still Images With Minimum Annotation Efforts\",\"url\":\"https://www.semanticscholar.org/paper/acf4f1387de054984a735fa9f9c3a827bebc32d1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M.-Y. Liu\"},{\"authorId\":null,\"name\":\"T. Breuel\"},{\"authorId\":null,\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsupervised image-toimage translation networks\",\"url\":\"\",\"venue\":\"NIPS,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49039493\",\"name\":\"W. Zhang\"},{\"authorId\":\"2717876\",\"name\":\"Menglong Zhu\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"}],\"doi\":\"10.1109/ICCV.2013.280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7636582c8abb648c4bb870b228f9ffbc6843c34\",\"title\":\"From Actemes to Action: A Strongly-Supervised Representation for Detailed Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f7636582c8abb648c4bb870b228f9ffbc6843c34\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1511.07122\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"title\":\"Multi-Scale Context Aggregation by Dilated Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50170517\",\"name\":\"M. Blank\"},{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/ICCV.2005.28\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"title\":\"Actions as space-time shapes\",\"url\":\"https://www.semanticscholar.org/paper/1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620865361\",\"name\":\"Seguin Hen\"}],\"doi\":\"10.1515/9783111576855-015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"title\":\"J\",\"url\":\"https://www.semanticscholar.org/paper/048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1704.03432\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/CVPR.2017.388\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e5e25db9957411ed2ba1e60d2d34d67b4408a20\",\"title\":\"Forecasting Human Dynamics from Static Images\",\"url\":\"https://www.semanticscholar.org/paper/1e5e25db9957411ed2ba1e60d2d34d67b4408a20\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49049934\",\"name\":\"J. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"title\":\"The PASCAL Visual Object Classes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/0ec48ac86456cea3d6d6172ca81ef68e98b21a61\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ec7433aeb4777e7d5c903920ae945e5429d3bc4\",\"title\":\"Recurrent Network Models for Human Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/1ec7433aeb4777e7d5c903920ae945e5429d3bc4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35561551\",\"name\":\"Arpit Jain\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"144113391\",\"name\":\"Mikel Rodriguez\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2013.332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eece43a4680e80e9dfba7027927b5e4ecae70eb2\",\"title\":\"Representing Videos Using Mid-level Discriminative Patches\",\"url\":\"https://www.semanticscholar.org/paper/eece43a4680e80e9dfba7027927b5e4ecae70eb2\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/TPAMI.2009.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a8da6accff92f915c1b8ac26d8176308c425b61\",\"title\":\"Observing Human-Object Interactions: Using Spatial and Functional Compatibility for Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a8da6accff92f915c1b8ac26d8176308c425b61\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-642-33765-9_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8a5addbd17d2c7c8043d8877234675da19938a\",\"title\":\"Activity Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/0d8a5addbd17d2c7c8043d8877234675da19938a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"}],\"doi\":\"10.1016/j.patcog.2014.04.018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b612877c4fb6fb7faf395357cd8092e5ec5dae7\",\"title\":\"A survey on still image based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b612877c4fb6fb7faf395357cd8092e5ec5dae7\",\"venue\":\"Pattern Recognit.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"2310278\",\"name\":\"Cagdas Bas\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1007/978-3-642-33885-4_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a89eae439dfa7cb727bd5193a5130ae6afcd42e8\",\"title\":\"On Recognizing Actions in Still Images via Multiple Features\",\"url\":\"https://www.semanticscholar.org/paper/a89eae439dfa7cb727bd5193a5130ae6afcd42e8\",\"venue\":\"ECCV Workshops\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1704.04394\",\"authors\":[{\"authorId\":\"2702448\",\"name\":\"N. Lee\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"2998590\",\"name\":\"Paul Vernaza\"},{\"authorId\":\"15239369\",\"name\":\"Christopher B. Choy\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":\"10.1109/CVPR.2017.233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"864ad6b8f2778bf7238e8a983551edc2072f08a9\",\"title\":\"DESIRE: Distant Future Prediction in Dynamic Scenes with Interacting Agents\",\"url\":\"https://www.semanticscholar.org/paper/864ad6b8f2778bf7238e8a983551edc2072f08a9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"2195129\",\"name\":\"X. Jiang\"},{\"authorId\":\"120643531\",\"name\":\"A. Khosla\"},{\"authorId\":\"32157394\",\"name\":\"A. L. Lin\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2011.6126386\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8e15dc51de6da2bc5cabbb733cf2adf5a2c1f72c\",\"title\":\"Human action recognition by learning bases of action attributes and parts\",\"url\":\"https://www.semanticscholar.org/paper/8e15dc51de6da2bc5cabbb733cf2adf5a2c1f72c\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020614\",\"name\":\"Christian Thurau\"},{\"authorId\":\"1752515\",\"name\":\"V. Hlav\\u00e1c\"}],\"doi\":\"10.1109/CVPR.2008.4587721\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b421a2d18af4db0998ae450136aa74cd99f20de\",\"title\":\"Pose primitive based human action recognition in videos or still images\",\"url\":\"https://www.semanticscholar.org/paper/2b421a2d18af4db0998ae450136aa74cd99f20de\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"},{\"authorId\":\"1685292\",\"name\":\"T. Poggio\"}],\"doi\":\"10.1109/ICCV.2007.4408988\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"124d967683544973581f951ee93b3f7c069e3ced\",\"title\":\"A Biologically Inspired System for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/124d967683544973581f951ee93b3f7c069e3ced\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2011.5995631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12fe91ab616b797e22543ae6c2afa7866dbc9a49\",\"title\":\"Action recognition from a distributed representation of pose and appearance\",\"url\":\"https://www.semanticscholar.org/paper/12fe91ab616b797e22543ae6c2afa7866dbc9a49\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1603.03590\",\"authors\":[{\"authorId\":\"2515835\",\"name\":\"Till Kroeger\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46493-0_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"title\":\"Fast Optical Flow Using Dense Inverse Search\",\"url\":\"https://www.semanticscholar.org/paper/9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1501.02565\",\"authors\":[{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2015.7298720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"title\":\"EpicFlow: Edge-preserving interpolation of correspondences for optical flow\",\"url\":\"https://www.semanticscholar.org/paper/f08e462b77347dc3cf483ca24dcd484c0ba5b432\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37335907\",\"name\":\"G. Willems\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-540-88688-4_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"title\":\"An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector\",\"url\":\"https://www.semanticscholar.org/paper/117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-642-15552-9_51\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ed01c2706c1dd05de8664bee1e42a628a49480ad\",\"title\":\"A Data-Driven Approach for Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ed01c2706c1dd05de8664bee1e42a628a49480ad\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d0703a75e6b76cbf1558c6dcc20ac386ff78bf\",\"title\":\"Learning person-object interactions for action recognition in still images\",\"url\":\"https://www.semanticscholar.org/paper/f2d0703a75e6b76cbf1558c6dcc20ac386ff78bf\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.01197\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"title\":\"Contextual Action Recognition with R*CNN\",\"url\":\"https://www.semanticscholar.org/paper/1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"150426657\",\"name\":\"\\u62d3\\u6d77 \\u6749\\u5c71\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e8a5f27e7805f8de84ea008d59452ff864271696\",\"title\":\"\\u201cUnpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks\\u201d\\u306e\\u5b66\\u7fd2\\u5831\\u544a\",\"url\":\"https://www.semanticscholar.org/paper/e8a5f27e7805f8de84ea008d59452ff864271696\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8774938\",\"name\":\"Alex Kuefler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f2005df165721dabf6c3ec4384de0625e52faaf\",\"title\":\"Deep View Morphing\",\"url\":\"https://www.semanticscholar.org/paper/7f2005df165721dabf6c3ec4384de0625e52faaf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"50218076\",\"name\":\"Z. Wang\"},{\"authorId\":\"3390922\",\"name\":\"Yugeng He\"},{\"authorId\":\"3381089\",\"name\":\"J. Wang\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/ICCV.2015.122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0fa318f20ed622a3f28e424b8d98ff5f8ca41b5\",\"title\":\"HICO: A Benchmark for Recognizing Human-Object Interactions in Images\",\"url\":\"https://www.semanticscholar.org/paper/c0fa318f20ed622a3f28e424b8d98ff5f8ca41b5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792719\",\"name\":\"Vincent Delaitre\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.5244/C.24.97\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"33079a9baa2609b545e91d443a26087fa84077e7\",\"title\":\"Recognizing human actions in still images: a study of bag-of-features and part-based representations\",\"url\":\"https://www.semanticscholar.org/paper/33079a9baa2609b545e91d443a26087fa84077e7\",\"venue\":\"BMVC\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"},{\"authorId\":\"2228323\",\"name\":\"M. Felsberg\"}],\"doi\":\"10.1109/ICPR.2014.269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f74fe5cfb9b216e0c60a6f90ba86b1bb90af209\",\"title\":\"Scale Coding Bag-of-Words for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0f74fe5cfb9b216e0c60a6f90ba86b1bb90af209\",\"venue\":\"2014 22nd International Conference on Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.07004\",\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2017.632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8acbe90d5b852dadea7810345451a99608ee54c7\",\"title\":\"Image-to-Image Translation with Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8acbe90d5b852dadea7810345451a99608ee54c7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1715959\",\"name\":\"Stefano Soatto\"}],\"doi\":\"10.1109/CVPR.2012.6247807\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a973c756b50869e918b1dd43f6add5dbcdc5f791\",\"title\":\"Discovering discriminative action parts from mid-level video representations\",\"url\":\"https://www.semanticscholar.org/paper/a973c756b50869e918b1dd43f6add5dbcdc5f791\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1504.08023\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fb3b63090f95af97723efe565893eb25ea9188c\",\"title\":\"Anticipating the future by watching unlabeled video\",\"url\":\"https://www.semanticscholar.org/paper/0fb3b63090f95af97723efe565893eb25ea9188c\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2013.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2633f6a4bb683aafecd86e9484258c0767196422\",\"title\":\"Motionlets: Mid-level 3D Parts for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2633f6a4bb683aafecd86e9484258c0767196422\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.80\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"title\":\"Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots\",\"url\":\"https://www.semanticscholar.org/paper/db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2014.260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c99798fce885b41ab1de66bbacf04b7de7274f85\",\"title\":\"Predicting Object Dynamics in Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c99798fce885b41ab1de66bbacf04b7de7274f85\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1506.06825\",\"authors\":[{\"authorId\":\"48001135\",\"name\":\"J. Flynn\"},{\"authorId\":\"1725327\",\"name\":\"Ivan Neulander\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2016.595\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"title\":\"Deep Stereo: Learning to Predict New Views from the World's Imagery\",\"url\":\"https://www.semanticscholar.org/paper/73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"34145947\",\"name\":\"Zhuolin Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2009.5459184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5894aca916753fabd97cda127e8f9ce230c3fb61\",\"title\":\"Recognizing actions by shape-motion prototype trees\",\"url\":\"https://www.semanticscholar.org/paper/5894aca916753fabd97cda127e8f9ce230c3fb61\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"10251113\",\"name\":\"C. Jacobs\"},{\"authorId\":\"145709776\",\"name\":\"N. Oliver\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"}],\"doi\":\"10.1145/383259.383295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923562d216386a88947d40da310d94bbb1376a41\",\"title\":\"Image analogies\",\"url\":\"https://www.semanticscholar.org/paper/923562d216386a88947d40da310d94bbb1376a41\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2013.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a180caf10c5a386c45e80a786a538d6b12764f54\",\"title\":\"Expanded Parts Model for Human Attribute and Action Recognition in Still Images\",\"url\":\"https://www.semanticscholar.org/paper/a180caf10c5a386c45e80a786a538d6b12764f54\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1502.00501\",\"authors\":[{\"authorId\":\"1742286\",\"name\":\"Zhujin Liang\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"40372975\",\"name\":\"Rui Huang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/ICME.2014.6890158\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"026465e90ae62a75d45f76255f7283bc780f402f\",\"title\":\"An expressive deep model for human action parsing from a single image\",\"url\":\"https://www.semanticscholar.org/paper/026465e90ae62a75d45f76255f7283bc780f402f\",\"venue\":\"2014 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.786\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"title\":\"Temporal Residual Networks for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e999d9054c5c84f7839dd050150e28a84e1cdec\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2775451\",\"name\":\"Z. Kourtzi\"},{\"authorId\":\"1931482\",\"name\":\"N. Kanwisher\"}],\"doi\":\"10.1162/08989290051137594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9bac57750ec2e079c75cc3d852d153a6a03fb2c\",\"title\":\"Activation in Human MT/MST by Static Images with Implied Motion\",\"url\":\"https://www.semanticscholar.org/paper/c9bac57750ec2e079c75cc3d852d153a6a03fb2c\",\"venue\":\"Journal of Cognitive Neuroscience\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2014.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"title\":\"Patch to the Future: Unsupervised Visual Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145989594\",\"name\":\"M. Goodale\"},{\"authorId\":\"2471113\",\"name\":\"A. Milner\"}],\"doi\":\"10.1016/0166-2236(92)90344-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a995afa8d3c114b2b431c4e2737777a0e051bff\",\"title\":\"Separate visual pathways for perception and action\",\"url\":\"https://www.semanticscholar.org/paper/0a995afa8d3c114b2b431c4e2737777a0e051bff\",\"venue\":\"Trends in Neurosciences\",\"year\":1992},{\"arxivId\":\"1510.04908\",\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2016.07.008\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"128d66ca1400cc22d7cdd879b4a7a7edf8c96a3c\",\"title\":\"No spare parts: Sharing part detectors for image categorization\",\"url\":\"https://www.semanticscholar.org/paper/128d66ca1400cc22d7cdd879b4a7a7edf8c96a3c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66313d48a6352e731e40450f80a66c64aabae817\",\"title\":\"Exploring new representations and applications for motion analysis\",\"url\":\"https://www.semanticscholar.org/paper/66313d48a6352e731e40450f80a66c64aabae817\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Kl\\u00e4ser\"},{\"authorId\":null,\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Action recognition by dense trajectories Action recognition with improved trajectories\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Kingma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A method for stochastic optimization\",\"url\":\"\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.00295\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2015.281\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"title\":\"Dense Optical Flow Prediction from a Static Image\",\"url\":\"https://www.semanticscholar.org/paper/098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1704.05831\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8299168\",\"name\":\"Y. Zou\"},{\"authorId\":\"2459821\",\"name\":\"Sungryull Sohn\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f230cacc511b17b491bf3d90015bbbf85b9ef6af\",\"title\":\"Learning to Generate Long-term Future via Hierarchical Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f230cacc511b17b491bf3d90015bbbf85b9ef6af\",\"venue\":\"ICML\",\"year\":2017}],\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"topics\":[{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"Discriminative model\",\"topicId\":\"39987\",\"url\":\"https://www.semanticscholar.org/topic/39987\"},{\"topic\":\"Flow map\",\"topicId\":\"143836\",\"url\":\"https://www.semanticscholar.org/topic/143836\"},{\"topic\":\"Open collaboration\",\"topicId\":\"324307\",\"url\":\"https://www.semanticscholar.org/topic/324307\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Snapshot (computer storage)\",\"topicId\":\"186784\",\"url\":\"https://www.semanticscholar.org/topic/186784\"},{\"topic\":\"Weitao Yang\",\"topicId\":\"3454739\",\"url\":\"https://www.semanticscholar.org/topic/3454739\"},{\"topic\":\"Chao (Sonic)\",\"topicId\":\"336017\",\"url\":\"https://www.semanticscholar.org/topic/336017\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Anil K. Jain (electrical engineer, born 1946)\",\"topicId\":\"1143852\",\"url\":\"https://www.semanticscholar.org/topic/1143852\"},{\"topic\":\"Entity\\u2013relationship model\",\"topicId\":\"251981\",\"url\":\"https://www.semanticscholar.org/topic/251981\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"}],\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"