"{\"abstract\":\"Despite recent emergence of video caption methods, how to generate fine-grained video descriptions (i.e., long and detailed commentary about individual movements of multiple subjects as well as their frequent interactions) is far from being solved, which however has great applications such as automatic sports narrative. To this end, this work makes the following contributions. First, to facilitate this novel research of fine-grained video caption, we collected a novel dataset called Fine-grained Sports Narrative dataset (FSN) that contains 2K sports videos with ground-truth narratives from YouTube.com. Second, we develop a novel performance evaluation metric named Fine-grained Captioning Evaluation (FCE) to cope with this novel task. Considered as an extension of the widely used METEOR, it measures not only the linguistic performance but also whether the action details and their temporal orders are correctly described. Third, we propose a new framework for fine-grained sports narrative task. This network features three branches: 1) a spatio-temporal entity localization and role discovering sub-network; 2) a fine-grained action modeling sub-network for local skeleton motion description; and 3) a group relationship modeling sub-network to model interactions between players. We further fuse the features and decode them into long narratives by a hierarchically recurrent structure. Extensive experiments on the FSN dataset demonstrates the validity of the proposed framework for fine-grained video caption.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"41030694\",\"name\":\"Huanyu Yu\",\"url\":\"https://www.semanticscholar.org/author/41030694\"},{\"authorId\":\"3392007\",\"name\":\"Shuo Cheng\",\"url\":\"https://www.semanticscholar.org/author/3392007\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\",\"url\":\"https://www.semanticscholar.org/author/5796401\"},{\"authorId\":\"7272302\",\"name\":\"Minsi Wang\",\"url\":\"https://www.semanticscholar.org/author/7272302\"},{\"authorId\":\"40430880\",\"name\":\"J. Zhang\",\"url\":\"https://www.semanticscholar.org/author/40430880\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\",\"url\":\"https://www.semanticscholar.org/author/50031361\"}],\"citationVelocity\":9,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"79723716\",\"name\":\"D. Di\"},{\"authorId\":\"66358686\",\"name\":\"J. Xiao\"},{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3323873.3325056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0388f5373a2f17a3c456346a52427c887667ea\",\"title\":\"Annotating Objects and Relations in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/fa0388f5373a2f17a3c456346a52427c887667ea\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8047613\",\"name\":\"Tahmida Mahmud\"},{\"authorId\":\"15702255\",\"name\":\"M. Billah\"},{\"authorId\":\"26559284\",\"name\":\"M. Hasan\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc2aa32e5ee30ba71bd6fb708cd70bdea0cedbe8\",\"title\":\"Captioning Near-Future Activity Sequences\",\"url\":\"https://www.semanticscholar.org/paper/dc2aa32e5ee30ba71bd6fb708cd70bdea0cedbe8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1591412916\",\"name\":\"Jiajie Su\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1007/s11042-020-08832-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"title\":\"Tell and guess: cooperative learning for natural image caption generation with hierarchical refined attention\",\"url\":\"https://www.semanticscholar.org/paper/814cfb898aa0bd011a97ebcf1774e42c32cf469e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1965909970\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"1755773\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"143930562\",\"name\":\"G. Chen\"},{\"authorId\":\"153016830\",\"name\":\"J. Guo\"}],\"doi\":\"10.1109/ACCESS.2020.3021857\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3a02eab3df6ec8bfaf0711cd1d87ab837fe437b\",\"title\":\"Understanding Objects in Video: Object-Oriented Video Captioning via Structured Trajectory and Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/e3a02eab3df6ec8bfaf0711cd1d87ab837fe437b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22214108\",\"name\":\"Zhaoyue Sun\"},{\"authorId\":\"3424694\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Hao Zhou\"},{\"authorId\":\"1725992\",\"name\":\"Deyu Zhou\"},{\"authorId\":\"143900009\",\"name\":\"Lei Li\"},{\"authorId\":\"11249500\",\"name\":\"Mingmin Jiang\"}],\"doi\":\"10.24963/ijcai.2019/959\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef62598377d3856624041cf1c84b36237a91b65e\",\"title\":\"GraspSnooker: Automatic Chinese Commentary Generation for Snooker Videos\",\"url\":\"https://www.semanticscholar.org/paper/ef62598377d3856624041cf1c84b36237a91b65e\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2079726\",\"name\":\"Y. Honda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57b8d49f1d14efa518bce3932c38ff6e52eee748\",\"title\":\"RNN-based Motion Prediction in Competitive Fencing Considering Interaction between Players\",\"url\":\"https://www.semanticscholar.org/paper/57b8d49f1d14efa518bce3932c38ff6e52eee748\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"1791344388\",\"name\":\"Lei Ji\"},{\"authorId\":\"1783553\",\"name\":\"Zhen-dong Niu\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3394171.3413498\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de4eabc5a672e5c3c1b3acbfa724cd8c85169c8c\",\"title\":\"Learning Semantic Concepts and Temporal Alignment for Narrated Video Procedural Captioning\",\"url\":\"https://www.semanticscholar.org/paper/de4eabc5a672e5c3c1b3acbfa724cd8c85169c8c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":\"3887469\",\"name\":\"Yaobo Liang\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"46915168\",\"name\":\"P. Chen\"},{\"authorId\":\"46764518\",\"name\":\"Zhendong Niu\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"}],\"doi\":\"10.18653/v1/P19-1641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea57ffa3e13400cad53dc061887a6fbbd45e7f12\",\"title\":\"Dense Procedure Captioning in Narrated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/ea57ffa3e13400cad53dc061887a6fbbd45e7f12\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93782401659fe26faef7e5f3b84ff632a12da47f\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Forged Videos\",\"url\":\"https://www.semanticscholar.org/paper/93782401659fe26faef7e5f3b84ff632a12da47f\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1911.05449\",\"authors\":[{\"authorId\":\"23604913\",\"name\":\"Liqi Yan\"},{\"authorId\":\"151478904\",\"name\":\"Mingjian Zhu\"},{\"authorId\":\"9792456\",\"name\":\"Changbin Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa00475c5819723b767e51e3b342d1ff4c64159f\",\"title\":\"Crowd Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fa00475c5819723b767e51e3b342d1ff4c64159f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.03715\",\"authors\":[{\"authorId\":\"4492316\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"145505204\",\"name\":\"J. Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d507f3088e5c8411bc06e274958cbe263169a39d\",\"title\":\"OVC-Net: Object-Oriented Video Captioning with Temporal Graph and Detail Enhancement.\",\"url\":\"https://www.semanticscholar.org/paper/d507f3088e5c8411bc06e274958cbe263169a39d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.04258\",\"authors\":[{\"authorId\":\"1397311046\",\"name\":\"Bastien Vanderplaetse\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.1109/CVPRW50498.2020.00456\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98b4c122b866c366fea3e6fccbabef10164c3a8c\",\"title\":\"Improved Soccer Action Spotting using both Audio and Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/98b4c122b866c366fea3e6fccbabef10164c3a8c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2007.06288\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"98256637\",\"name\":\"Zhou Yang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46946060\",\"name\":\"M. Jian\"},{\"authorId\":\"49217626\",\"name\":\"Boxuan Zhao\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.07.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50efde486726ae435c28211b6cd123c6b61e3a99\",\"title\":\"Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/50efde486726ae435c28211b6cd123c6b61e3a99\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47569376\",\"name\":\"Shijie Yang\"},{\"authorId\":\"73596205\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3350859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"952a74f839536bd7668acb8d65086b4f4e3a4dee\",\"title\":\"Structured Stochastic Recurrent Network for Linguistic Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/952a74f839536bd7668acb8d65086b4f4e3a4dee\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1912.01326\",\"authors\":[{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"},{\"authorId\":\"9870507\",\"name\":\"R. Gade\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/CVPR42600.2020.01314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"title\":\"A Context-Aware Loss Function for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1903.02874\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50792340\",\"name\":\"Dajun Ding\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\"},{\"authorId\":\"145473095\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/CVPR.2019.00130\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"title\":\"COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.10762\",\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d82091b1e817be4497fbe11c01ad473d99894c6\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Video Forgery\",\"url\":\"https://www.semanticscholar.org/paper/8d82091b1e817be4497fbe11c01ad473d99894c6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48699355\",\"name\":\"Z. Pan\"},{\"authorId\":\"1414569274\",\"name\":\"Chao Li\"}],\"doi\":\"10.1016/j.image.2020.115784\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"325400d6f527ef4210c0ab9905f706d16591eae4\",\"title\":\"Robust basketball sports recognition by leveraging motion block estimation\",\"url\":\"https://www.semanticscholar.org/paper/325400d6f527ef4210c0ab9905f706d16591eae4\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2003.09392\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TPAMI.2020.2980824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"title\":\"Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.04346\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"1737830\",\"name\":\"B. Morris\"}],\"doi\":\"10.1109/CVPR.2019.00039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3183228a83b1daffeb458f9041d51612589a5b3\",\"title\":\"What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/f3183228a83b1daffeb458f9041d51612589a5b3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1801.09108\",\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"2118698\",\"name\":\"Roddy Collins\"},{\"authorId\":\"2754027\",\"name\":\"E. Swears\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":\"10.1109/WACV.2019.00176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d772882cceb083ab053b83615e60c641fc3e7dbb\",\"title\":\"Deep Neural Networks in Fully Connected CRF for Image Labeling with Social Network Metadata\",\"url\":\"https://www.semanticscholar.org/paper/d772882cceb083ab053b83615e60c641fc3e7dbb\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4492316\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"145886114\",\"name\":\"Jun Guo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"745f54a822bdbd33cf08e65b665ab3f3528cdf78\",\"title\":\"Object-Oriented Video Captioning with Temporal Graph and Prior Knowledge Building\",\"url\":\"https://www.semanticscholar.org/paper/745f54a822bdbd33cf08e65b665ab3f3528cdf78\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150326297\",\"name\":\"Tianlun Zhang\"},{\"authorId\":\"144522892\",\"name\":\"R. Chen\"},{\"authorId\":\"40282825\",\"name\":\"Xi Yang\"},{\"authorId\":\"3467285\",\"name\":\"Shikai Guo\"}],\"doi\":\"10.1109/ACCESS.2018.2885164\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4961a4efd448e173d26a380d15bc11d7d57b04b3\",\"title\":\"Rich Feature Combination for Cost-Based Broad Learning System\",\"url\":\"https://www.semanticscholar.org/paper/4961a4efd448e173d26a380d15bc11d7d57b04b3\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2008.09791\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-58589-1_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"title\":\"Identity-Aware Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":52855297,\"doi\":\"10.1109/CVPR.2018.00629\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"f5876f67129a80a1ee753f715efcd2e2109bf432\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3312922\",\"name\":\"H. Aradhye\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1842163\",\"name\":\"J. Yagnik\"}],\"doi\":\"10.1109/ICDMW.2009.79\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cc75d0939454a42f81a0ed692bf9fd1cef11f8f\",\"title\":\"Video2Text: Learning to Annotate Video Content\",\"url\":\"https://www.semanticscholar.org/paper/0cc75d0939454a42f81a0ed692bf9fd1cef11f8f\",\"venue\":\"2009 IEEE International Conference on Data Mining Workshops\",\"year\":2009},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.06607\",\"authors\":[{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.356\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a7011346ce939e3251915e92ae2f252e4c7f777\",\"title\":\"A Hierarchical Approach for Generating Descriptive Image Paragraphs\",\"url\":\"https://www.semanticscholar.org/paper/3a7011346ce939e3251915e92ae2f252e4c7f777\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2013.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6a7a563640bf53953c4fda0997e4db176488510\",\"title\":\"YouTube2Text: Recognizing and Describing Arbitrary Activities Using Semantic Hierarchies and Zero-Shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6a7a563640bf53953c4fda0997e4db176488510\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1812.08008\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"2915997\",\"name\":\"T. \\u0160imon\"},{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2017.143\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e8db1519245426f3a78752a3d8360484f4626b1\",\"title\":\"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields\",\"url\":\"https://www.semanticscholar.org/paper/9e8db1519245426f3a78752a3d8360484f4626b1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-319-46487-9_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"title\":\"DAPs: Deep Action Proposals for Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c24bbbc5139eb2f8c5d0579174dbeae5cbaedbfc\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1604.01729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D16-1204\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"title\":\"Improving LSTM-based Video Description with Linguistic Knowledge Mined from Text\",\"url\":\"https://www.semanticscholar.org/paper/d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006928\",\"name\":\"N. Krishnamoorthy\"},{\"authorId\":\"3163967\",\"name\":\"Girish Malkarnenkar\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"title\":\"Generating Natural-Language Video Descriptions Using Text-Mined Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3b9f8101c61b415f946625b69f69fc9e3d0d6fc4\",\"venue\":\"AAAI\",\"year\":2013},{\"arxivId\":\"1704.01502\",\"authors\":[{\"authorId\":\"145314568\",\"name\":\"Zhiqiang Shen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"},{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"3700393\",\"name\":\"Minjun Li\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2017.548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"title\":\"Weakly Supervised Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"38916673\",\"name\":\"B. Yao\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2013.320\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"37c49d49817d9a689b57d7bbd2113cc80792bea1\",\"title\":\"Social Role Discovery in Human Events\",\"url\":\"https://www.semanticscholar.org/paper/37c49d49817d9a689b57d7bbd2113cc80792bea1\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Long\"},{\"authorId\":null,\"name\":\"C. Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and G\",\"url\":\"\",\"venue\":\"de Melo. Video captioning with multi-faceted attention. CoRR, abs/1612.00234\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.09312\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"153925540\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2017.339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"title\":\"Hierarchical Boundary-Aware Neural Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1707.09700\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"48884894\",\"name\":\"K. Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf2de559e5a6235783e0762862f6e42192f142a8\",\"title\":\"Scene Graph Generation from Objects, Phrases and Region Captions\",\"url\":\"https://www.semanticscholar.org/paper/cf2de559e5a6235783e0762862f6e42192f142a8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":\"1506.01698\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-24947-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"title\":\"The Long-Short Story of Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/49512d11c468dc2fe3fe832d8c4dc8e0a01b0a4b\",\"venue\":\"GCPR\",\"year\":2015},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1701.02426\",\"authors\":[{\"authorId\":\"2068265\",\"name\":\"Danfei Xu\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"15239369\",\"name\":\"Christopher B. Choy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2017.330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34b73c1aa158b892bbe41705b4ae5bf01ecaea86\",\"title\":\"Scene Graph Generation by Iterative Message Passing\",\"url\":\"https://www.semanticscholar.org/paper/34b73c1aa158b892bbe41705b4ae5bf01ecaea86\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1403.6173\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"113090874\",\"name\":\"W. Qiu\"},{\"authorId\":\"33985877\",\"name\":\"Annemarie Friedrich\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"889e723cd6d581e120ee6776b231fdf69707ab50\",\"title\":\"Coherent Multi-sentence Video Description with Variable Level of Detail\",\"url\":\"https://www.semanticscholar.org/paper/889e723cd6d581e120ee6776b231fdf69707ab50\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50842187\",\"name\":\"L. Ding\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"}],\"doi\":\"10.1007/978-3-642-15561-1_30\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"49a454bfaaac1e660b01bb82a91116e22e1196a0\",\"title\":\"Learning Relations among Movie Characters: A Social Network Perspective\",\"url\":\"https://www.semanticscholar.org/paper/49a454bfaaac1e660b01bb82a91116e22e1196a0\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1704.01518\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2017.447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db2fecc8b1bd175d39687eb471360707a5fddb03\",\"title\":\"Generating Descriptions with Grounded and Co-referenced People\",\"url\":\"https://www.semanticscholar.org/paper/db2fecc8b1bd175d39687eb471360707a5fddb03\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20ab42c9b93b6e41f6e1d7b546f87c5a871db020\",\"title\":\"Integrating Language and Vision to Generate Natural Language Descriptions of Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/20ab42c9b93b6e41f6e1d7b546f87c5a871db020\",\"venue\":\"COLING\",\"year\":2014},{\"arxivId\":\"1612.00234\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"}],\"doi\":\"10.1162/tacl_a_00013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a732016c3f74dc7d78899bf33cf25df03ef46b4\",\"title\":\"Video Captioning with Multi-Faceted Attention\",\"url\":\"https://www.semanticscholar.org/paper/5a732016c3f74dc7d78899bf33cf25df03ef46b4\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50842187\",\"name\":\"L. Ding\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"}],\"doi\":\"10.1109/ICCV.2011.6126306\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"46d001440f91ec8c9691bf3756c1740c81c804d4\",\"title\":\"Inferring social relations from visual concepts\",\"url\":\"https://www.semanticscholar.org/paper/46d001440f91ec8c9691bf3756c1740c81c804d4\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1611.05424\",\"authors\":[{\"authorId\":\"31688710\",\"name\":\"Alejandro Newell\"},{\"authorId\":\"18036051\",\"name\":\"Zhiao Huang\"},{\"authorId\":\"121806097\",\"name\":\"J. Deng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"239f500b6396cc97f51e5c53d165fae9ce13f661\",\"title\":\"Associative Embedding: End-to-End Learning for Joint Detection and Grouping\",\"url\":\"https://www.semanticscholar.org/paper/239f500b6396cc97f51e5c53d165fae9ce13f661\",\"venue\":\"NIPS\",\"year\":2017}],\"title\":\"Fine-Grained Video Captioning for Sports Narrative\",\"topics\":[{\"topic\":\"Subnetwork\",\"topicId\":\"36979\",\"url\":\"https://www.semanticscholar.org/topic/36979\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Meteor\",\"topicId\":\"131649\",\"url\":\"https://www.semanticscholar.org/topic/131649\"},{\"topic\":\"Performance Evaluation\",\"topicId\":\"91975\",\"url\":\"https://www.semanticscholar.org/topic/91975\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Emergence\",\"topicId\":\"5580\",\"url\":\"https://www.semanticscholar.org/topic/5580\"},{\"topic\":\"Lazy evaluation\",\"topicId\":\"19479\",\"url\":\"https://www.semanticscholar.org/topic/19479\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"}],\"url\":\"https://www.semanticscholar.org/paper/f5876f67129a80a1ee753f715efcd2e2109bf432\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"