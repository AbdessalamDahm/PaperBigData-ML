"{\"abstract\":\"Action recognition in still images has been recently promoted by deep learning. However, the success of these deep models heavily depends on huge amount of training images for various action categories, which may not be available in practice. Alternatively, humans can classify new action categories after seeing few images, since we may not only compare appearance similarities between images on hand, but also attempt to recall importance motion cues from relevant action videos in our memory. To mimic this capacity, we propose a novel Hybrid Video Memory (HVM) machine, which can hallucinate temporal features of still images from video memory, in order to boost action recognition with few still images. First, we design a temporal memory module consisting of temporal hallucinating and predicting. Temporal hallucinating can generate temporal features of still images in an unsupervised manner. Hence, it can be flexibly used in realistic scenarios, where image and video categories may not be consistent. Temporal predicting can effectively infer action categories for query image, by integrating temporal features of training images and videos within a domain-adaptation manner. Second, we design a spatial memory module for spatial predicting. As spatial and temporal features are complementary to represent different actions, we apply spatial-temporal prediction fusion to further boost performance. Finally, we design a video selection module to select strongly-relevant videos as memory. In this case, we can balance the number of images and videos to reduce prediction bias as well as preserve computation efficiency. To show the effectiveness, we conduct extensive experiments on three challenging data sets, where our HVM outperforms a number of recent approaches by temporal hallucinating from video memory.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"49415643\",\"name\":\"Y. Wang\",\"url\":\"https://www.semanticscholar.org/author/49415643\"},{\"authorId\":\"46696648\",\"name\":\"L. Zhou\",\"url\":\"https://www.semanticscholar.org/author/46696648\"},{\"authorId\":null,\"name\":\"Yu Qiao\",\"url\":null}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89056710\",\"name\":\"Jinhai Yang\"},{\"authorId\":\"48918787\",\"name\":\"Xiao Zhou\"},{\"authorId\":\"71227046\",\"name\":\"H. Yang\"}],\"doi\":\"10.1007/978-981-15-3341-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6968312b4280ca498f6ee55b3fe9b9b17c18b01\",\"title\":\"Attention-Based Top-Down Single-Task Action Recognition in Still Images\",\"url\":\"https://www.semanticscholar.org/paper/d6968312b4280ca498f6ee55b3fe9b9b17c18b01\",\"venue\":\"IFTC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72948821\",\"name\":\"S. Chen\"},{\"authorId\":\"8034625\",\"name\":\"Yuanyuan Shen\"},{\"authorId\":\"151494647\",\"name\":\"Y. Yan\"},{\"authorId\":\"1807704\",\"name\":\"Dahan Wang\"},{\"authorId\":\"7472429\",\"name\":\"Shunzhi Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.2966329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b90dab59171b30007e359f14e0e9fa0f7284dc0\",\"title\":\"Cholesky Decomposition-Based Metric Learning for Video-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6b90dab59171b30007e359f14e0e9fa0f7284dc0\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.04140\",\"authors\":[{\"authorId\":\"1381281389\",\"name\":\"Prashant Pandey\"},{\"authorId\":\"1411010600\",\"name\":\"P. PrathoshA.\"},{\"authorId\":\"49085157\",\"name\":\"Manu Kohli\"},{\"authorId\":\"49017407\",\"name\":\"J. Pritchard\"}],\"doi\":\"10.1609/aaai.v34i01.5383\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfefcb0901b173f0da0d4db3948d749ab9734198\",\"title\":\"Guided weak supervision for action recognition with scarce data to assess skills of children with autism\",\"url\":\"https://www.semanticscholar.org/paper/bfefcb0901b173f0da0d4db3948d749ab9734198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1912.06971\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1694235\",\"name\":\"Hanqing Lu\"}],\"doi\":\"10.1109/TIP.2020.3028207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5376cbbf263fb6433da15a81948c9d4060677a59\",\"title\":\"Skeleton-Based Action Recognition With Multi-Stream Adaptive Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5376cbbf263fb6433da15a81948c9d4060677a59\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1911.12509\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"title\":\"Action Recognition via Pose-Based Graph Convolutional Networks with Intermediate Dense Supervision\",\"url\":\"https://www.semanticscholar.org/paper/9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.05358\",\"authors\":[{\"authorId\":\"49262921\",\"name\":\"Di Yang\"},{\"authorId\":\"1478813684\",\"name\":\"Rui Dai\"},{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"116791593\",\"name\":\"Rupayan Mallick\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1096eac74cc81621e84de169163bb239a05c946\",\"title\":\"Selective Spatio-Temporal Aggregation Based Pose Refinement System: Towards Understanding Human Activities in Real-World Videos\",\"url\":\"https://www.semanticscholar.org/paper/e1096eac74cc81621e84de169163bb239a05c946\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.05667\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"title\":\"Explainable Deep Learning for Video Recognition Tasks: A Framework & Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020}],\"corpusId\":52846726,\"doi\":\"10.1109/CVPR.2018.00557\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1411.1792\",\"authors\":[{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1747909\",\"name\":\"Hod Lipson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"081651b38ff7533550a3adfc1c00da333a8fe86c\",\"title\":\"How transferable are features in deep neural networks?\",\"url\":\"https://www.semanticscholar.org/paper/081651b38ff7533550a3adfc1c00da333a8fe86c\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1606.05233\",\"authors\":[{\"authorId\":\"2271057\",\"name\":\"Luca Bertinetto\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1881617\",\"name\":\"Jack Valmadre\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4423357dd21cc59662c6fabaf9839b15ef0fb8a8\",\"title\":\"Learning feed-forward one-shot learners\",\"url\":\"https://www.semanticscholar.org/paper/4423357dd21cc59662c6fabaf9839b15ef0fb8a8\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1609.00153\",\"authors\":[{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2666739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c45ce0e5b795765d14b801b6b8ece2ee9bb641fb\",\"title\":\"Weakly Supervised PatchNets: Describing and Aggregating Local Patches for Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c45ce0e5b795765d14b801b6b8ece2ee9bb641fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"2871555\",\"name\":\"P. Gehler\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2014.471\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da8d53f9a85b40a695585aa461286e373c6b74d4\",\"title\":\"2D Human Pose Estimation: New Benchmark and State of the Art Analysis\",\"url\":\"https://www.semanticscholar.org/paper/da8d53f9a85b40a695585aa461286e373c6b74d4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1412.2604\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48e8cc2d5651053c0bc2fcd20787cca0782f2b94\",\"title\":\"Actions and Attributes from Wholes and Parts\",\"url\":\"https://www.semanticscholar.org/paper/48e8cc2d5651053c0bc2fcd20787cca0782f2b94\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Sukhbaatar\"},{\"authorId\":null,\"name\":\"A. Szlam\"},{\"authorId\":null,\"name\":\"J. Weston\"},{\"authorId\":null,\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"End-toend memory networks\",\"url\":\"\",\"venue\":\"In NIPS,\",\"year\":2015},{\"arxivId\":\"1612.03052\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"144660077\",\"name\":\"Jan Neumann\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"title\":\"ActionFlowNet: Learning Motion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00016-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"title\":\"P\",\"url\":\"https://www.semanticscholar.org/paper/db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1608.03217\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2016.387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1a2e08c8423a75672576c38eee482f4b82188bf\",\"title\":\"DeepCAMP: Deep Convolutional Action & Attribute Mid-Level Patterns\",\"url\":\"https://www.semanticscholar.org/paper/d1a2e08c8423a75672576c38eee482f4b82188bf\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.03126\",\"authors\":[{\"authorId\":\"143622869\",\"name\":\"Alexander H. Miller\"},{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"145926563\",\"name\":\"Amir-Hossein Karimi\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/D16-1147\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"bba5f2852b1db8a18004eb7328efa5e1d57cc62a\",\"title\":\"Key-Value Memory Networks for Directly Reading Documents\",\"url\":\"https://www.semanticscholar.org/paper/bba5f2852b1db8a18004eb7328efa5e1d57cc62a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gregory R. Koch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f216444d4f2959b4520c61d20003fa30a199670a\",\"title\":\"Siamese Neural Networks for One-Shot Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f216444d4f2959b4520c61d20003fa30a199670a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1605.06065\",\"authors\":[{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2258504\",\"name\":\"Sergey Bartunov\"},{\"authorId\":\"46378362\",\"name\":\"M. Botvinick\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbd0e204f48a45735e1065c8b90b298077b73192\",\"title\":\"One-shot Learning with Memory-Augmented Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/bbd0e204f48a45735e1065c8b90b298077b73192\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2373318\",\"name\":\"B. Lake\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":\"10.1126/science.aab3050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815c84ab906e43f3e6322f2ca3fd5e1360c64285\",\"title\":\"Human-level concept learning through probabilistic program induction\",\"url\":\"https://www.semanticscholar.org/paper/815c84ab906e43f3e6322f2ca3fd5e1360c64285\",\"venue\":\"Science\",\"year\":2015},{\"arxivId\":\"1703.03129\",\"authors\":[{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"7624658\",\"name\":\"Ofir Nachum\"},{\"authorId\":\"39788470\",\"name\":\"Aurko Roy\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a0d253053ce8646e49904efe0e062bcc30d8257\",\"title\":\"Learning to Remember Rare Events\",\"url\":\"https://www.semanticscholar.org/paper/6a0d253053ce8646e49904efe0e062bcc30d8257\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. E. Rasmussen\"},{\"authorId\":null,\"name\":\"C.K.I. Williams\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Gaussian Process for Machine learning\",\"url\":\"\",\"venue\":\"MIT Press\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49201933\",\"name\":\"Zhe Ren\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47bc34ae6f5dc104bc289ae3bb4fa75ef75fbc21\",\"title\":\"Unsupervised Deep Learning for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/47bc34ae6f5dc104bc289ae3bb4fa75ef75fbc21\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"}],\"doi\":\"10.1016/j.patcog.2014.04.018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b612877c4fb6fb7faf395357cd8092e5ec5dae7\",\"title\":\"A survey on still image based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b612877c4fb6fb7faf395357cd8092e5ec5dae7\",\"venue\":\"Pattern Recognit.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2016.534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"412bf8bf368d5820dbea415a4085fb72b1ce76dc\",\"title\":\"Thin-Slicing for Pose: Learning to Understand Pose without Explicit Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/412bf8bf368d5820dbea415a4085fb72b1ce76dc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.04080\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6\",\"title\":\"Matching Networks for One Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/be1bb4e4aa1fcf70281b4bd24d8cd31c04864bb6\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1612.06152\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/CVPR.2017.569\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91a59243c248478bc1f0f6542284eaa3c19f1ece\",\"title\":\"Few-Shot Object Recognition from Machine-Labeled Web Images\",\"url\":\"https://www.semanticscholar.org/paper/91a59243c248478bc1f0f6542284eaa3c19f1ece\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.01197\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"title\":\"Contextual Action Recognition with R*CNN\",\"url\":\"https://www.semanticscholar.org/paper/1ab237d7eb9dec8416947fce0b0cbf6c688a7229\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.02819\",\"authors\":[{\"authorId\":\"1790580\",\"name\":\"Bharath Hariharan\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48538ee653928c176d5b9fe3f67280a5db2b10f5\",\"title\":\"Low-shot visual object recognition\",\"url\":\"https://www.semanticscholar.org/paper/48538ee653928c176d5b9fe3f67280a5db2b10f5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2017.319\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"title\":\"Generating the Future with Adversarial Transformers\",\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49517463\",\"name\":\"S. Ravi\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29c887794eed2ca9462638ff853e6fe1ab91d5d8\",\"title\":\"Optimization as a Model for Few-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/29c887794eed2ca9462638ff853e6fe1ab91d5d8\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867148\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145874477\",\"name\":\"Li Cheng\"},{\"authorId\":\"1808816\",\"name\":\"Jianxin Wu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":\"10.1109/TIP.2016.2605305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acf4f1387de054984a735fa9f9c3a827bebc32d1\",\"title\":\"Action Recognition in Still Images With Minimum Annotation Efforts\",\"url\":\"https://www.semanticscholar.org/paper/acf4f1387de054984a735fa9f9c3a827bebc32d1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1410.5401\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3823aacea60bc1f2cabb9283144690a3d015db5\",\"title\":\"Neural Turing Machines\",\"url\":\"https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1708.00284\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"87068304\",\"name\":\"L. Lee\"},{\"authorId\":\"143716171\",\"name\":\"Wei Dai\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"title\":\"Dual Motion GAN for Future-Flow Embedded Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eb911796464b1e01e98c2b3d007a4ef9310272e2\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Temporal Hallucinating for Action Recognition with Few Still Images\",\"topics\":[{\"topic\":\"Memory module\",\"topicId\":\"182030\",\"url\":\"https://www.semanticscholar.org/topic/182030\"},{\"topic\":\"Video card\",\"topicId\":\"15656\",\"url\":\"https://www.semanticscholar.org/topic/15656\"},{\"topic\":\"Hardware-assisted virtualization\",\"topicId\":\"500011\",\"url\":\"https://www.semanticscholar.org/topic/500011\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Video RAM (dual-ported DRAM)\",\"topicId\":\"968535\",\"url\":\"https://www.semanticscholar.org/topic/968535\"}],\"url\":\"https://www.semanticscholar.org/paper/1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"