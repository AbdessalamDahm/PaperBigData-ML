"{\"abstract\":\"This paper explores gaze prediction in dynamic 360\\u00b0 immersive videos, i.e., based on the history scan path and VR contents, we predict where a viewer will look at an upcoming time. To tackle this problem, we first present the large-scale eye-tracking in dynamic VR scene dataset. Our dataset contains 208 360\\u00b0 videos captured in dynamic scenes, and each video is viewed by at least 31 subjects. Our analysis shows that gaze prediction depends on its history scan path and image contents. In terms of the image contents, those salient objects easily attract viewers' attention. On the one hand, the saliency is related to both appearance and motion of the objects. Considering that the saliency measured at different scales is different, we propose to compute saliency maps at different spatial scales: the sub-image patch centered at current gaze point, the sub-image corresponding to the Field of View (FoV), and the panorama image. Then we feed both the saliency maps and the corresponding images into a Convolutional Neural Network (CNN) for feature extraction. Meanwhile, we also use a Long-Short-Term-Memory (LSTM) to encode the history scan path. Then we combine the CNN features and LSTM features for gaze displacement prediction between gaze point at a current time and gaze point at an upcoming time. Extensive experiments validate the effectiveness of our method for gaze prediction in dynamic VR scenes.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\",\"url\":\"https://www.semanticscholar.org/author/7869872\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\",\"url\":\"https://www.semanticscholar.org/author/49266038\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\",\"url\":\"https://www.semanticscholar.org/author/3423101\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\",\"url\":\"https://www.semanticscholar.org/author/30581936\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\",\"url\":\"https://www.semanticscholar.org/author/34692825\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\",\"url\":\"https://www.semanticscholar.org/author/2152356\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\",\"url\":\"https://www.semanticscholar.org/author/1702868\"}],\"citationVelocity\":21,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391202254\",\"name\":\"Jiasi Chen\"},{\"authorId\":\"23148437\",\"name\":\"Xukan Ran\"}],\"doi\":\"10.1109/JPROC.2019.2921977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f2d4e821dd03ac5df7d5448948bc738aefdd6db\",\"title\":\"Deep Learning With Edge Computing: A Review\",\"url\":\"https://www.semanticscholar.org/paper/4f2d4e821dd03ac5df7d5448948bc738aefdd6db\",\"venue\":\"Proceedings of the IEEE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144480984\",\"name\":\"Qiang Hu\"},{\"authorId\":\"49895169\",\"name\":\"J. Zhou\"},{\"authorId\":\"47957191\",\"name\":\"Xiao-yun Zhang\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"49538591\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/s11042-019-08390-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"title\":\"Viewport-adaptive 360-degree video coding\",\"url\":\"https://www.semanticscholar.org/paper/9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941672\",\"name\":\"Zhiming Hu\"},{\"authorId\":\"72917175\",\"name\":\"Sheng Li\"},{\"authorId\":\"73114045\",\"name\":\"Congyi Zhang\"},{\"authorId\":\"1499256520\",\"name\":\"Kangrui Yi\"},{\"authorId\":\"92491739\",\"name\":\"G. Wang\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1109/TVCG.2020.2973473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5dc84061cb26efead2e73a7e7999d8c9b08674f0\",\"title\":\"DGaze: CNN-Based Gaze Prediction in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/5dc84061cb26efead2e73a7e7999d8c9b08674f0\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28310167\",\"name\":\"Majed Elwardy\"},{\"authorId\":\"50056520\",\"name\":\"Hans-J\\u00fcrgen Zepernick\"},{\"authorId\":\"2495682\",\"name\":\"V. Sundstedt\"}],\"doi\":\"10.1109/ICSPCS47537.2019.9008715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e35e941dc1caa87e054629d7ab7e0efde556369a\",\"title\":\"Annotated 360-Degree Image and Video Databases: A Comprehensive Survey\",\"url\":\"https://www.semanticscholar.org/paper/e35e941dc1caa87e054629d7ab7e0efde556369a\",\"venue\":\"2019 13th International Conference on Signal Processing and Communication Systems (ICSPCS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693368785\",\"name\":\"Carlos Mara\\u00f1es\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"116241758\",\"name\":\"A. Serrano\"}],\"doi\":\"10.1109/VR46266.2020.1580727911717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbe1f8b221b4ba55d8b45b626a6b36a2962681f5\",\"title\":\"Exploring the impact of 360\\u00b0 movie cuts in users\\u2019 attention\",\"url\":\"https://www.semanticscholar.org/paper/dbe1f8b221b4ba55d8b45b626a6b36a2962681f5\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3945608\",\"name\":\"J. Shi\"},{\"authorId\":\"3157810\",\"name\":\"Lingjun Pu\"},{\"authorId\":\"7169649\",\"name\":\"J. Xu\"}],\"doi\":\"10.1109/CLOUD49709.2020.00054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2c64623bdbcd2f0871d21027aba5f90637f7c1f\",\"title\":\"Allies: Tile-Based Joint Transcoding, Delivery and Caching of 360\\u00b0 Videos in Edge Cloud Networks\",\"url\":\"https://www.semanticscholar.org/paper/a2c64623bdbcd2f0871d21027aba5f90637f7c1f\",\"venue\":\"2020 IEEE 13th International Conference on Cloud Computing (CLOUD)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144542759\",\"name\":\"Jayesh S. Pillai\"},{\"authorId\":\"84559691\",\"name\":\"Manvi Verma\"}],\"doi\":\"10.1145/3359997.3365680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1997f86a0c9b845b381fc86abfe9c878c6deddb\",\"title\":\"Grammar of VR Storytelling: Narrative Immersion and Experiential Fidelity in VR Cinema\",\"url\":\"https://www.semanticscholar.org/paper/c1997f86a0c9b845b381fc86abfe9c878c6deddb\",\"venue\":\"VRCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5430156\",\"name\":\"Haojun Xu\"},{\"authorId\":\"152236895\",\"name\":\"Feng Tian\"}],\"doi\":\"10.1109/ITNEC48623.2020.9085055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06b681283c153037dcd58b59cf9f76398a4cc9e1\",\"title\":\"Biological Bias of Saliency Model in VR\",\"url\":\"https://www.semanticscholar.org/paper/06b681283c153037dcd58b59cf9f76398a4cc9e1\",\"venue\":\"2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2915363\",\"name\":\"Jounsup Park\"},{\"authorId\":\"1486321680\",\"name\":\"Mingyuan Wu\"},{\"authorId\":\"144127380\",\"name\":\"Eric Lee\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"69545597\",\"name\":\"K. Nahrstedt\"},{\"authorId\":\"1577098741\",\"name\":\"M. Zink\"},{\"authorId\":\"48121233\",\"name\":\"R. Sitaraman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"662abec986a3177dc6abac37480b5af7781d9261\",\"title\":\"SEAWARE: Semantic Aware View Prediction System for 360-degree Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/662abec986a3177dc6abac37480b5af7781d9261\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941672\",\"name\":\"Zhiming Hu\"},{\"authorId\":\"29862039\",\"name\":\"Congyi Zhang\"},{\"authorId\":\"79399264\",\"name\":\"S. Li\"},{\"authorId\":\"50248545\",\"name\":\"G. Wang\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1109/TVCG.2019.2899187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d78aedcfd74c8dc12d70f63ac104636c8729df04\",\"title\":\"SGaze: A Data-Driven Eye-Head Coordination Model for Realtime Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d78aedcfd74c8dc12d70f63ac104636c8729df04\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1926082\",\"name\":\"Xueshi Hou\"},{\"authorId\":\"144482324\",\"name\":\"S. Dey\"},{\"authorId\":\"144138586\",\"name\":\"Jianzhong Zhang\"},{\"authorId\":\"1729607\",\"name\":\"M. Budagavi\"}],\"doi\":\"10.1109/tmm.2020.2987693\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0748bc5bd5013b6285627bd5a8b7aa3589168f89\",\"title\":\"Predictive Adaptive Streaming to Enable Mobile 360-degree and VR Experiences\",\"url\":\"https://www.semanticscholar.org/paper/0748bc5bd5013b6285627bd5a8b7aa3589168f89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.13884\",\"authors\":[{\"authorId\":\"50652735\",\"name\":\"Xing Wei\"},{\"authorId\":\"2804716\",\"name\":\"Chenyang Yang\"},{\"authorId\":\"1679228\",\"name\":\"Shengqian Han\"}],\"doi\":\"10.1109/tcomm.2020.3040282\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2a628e981a1899b1f2dd7ac54c5c9b927e92486\",\"title\":\"Prediction, Communication, and Computing Duration Optimization for VR Video Streaming.\",\"url\":\"https://www.semanticscholar.org/paper/f2a628e981a1899b1f2dd7ac54c5c9b927e92486\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.04015\",\"authors\":[{\"authorId\":\"41036829\",\"name\":\"Tamay Aykut\"},{\"authorId\":\"1952976052\",\"name\":\"Basak Gulezyuz\"},{\"authorId\":\"1739786\",\"name\":\"B. Girod\"},{\"authorId\":\"1713579\",\"name\":\"E. Steinbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ab56d8519a24ea4fabffb631a250c5e280afb55\",\"title\":\"HSMF-Net: Semantic Viewport Prediction for Immersive Telepresence and On-Demand 360-degree Video\",\"url\":\"https://www.semanticscholar.org/paper/2ab56d8519a24ea4fabffb631a250c5e280afb55\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49673074\",\"name\":\"C. Li\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d8ff98a5740febb0e03972b7ff6686171f46557\",\"title\":\"Viewport Proposal CNN for 360\\u00b0 Video Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/8d8ff98a5740febb0e03972b7ff6686171f46557\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50652735\",\"name\":\"Xing Wei\"},{\"authorId\":\"2804716\",\"name\":\"Chenyang Yang\"}],\"doi\":\"10.1109/VTC2020-Spring48590.2020.9128459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98068699c544426cc459b383093e8c8ca574a18b\",\"title\":\"Matching Prediction to Communication and Computing for Proactive VR Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/98068699c544426cc459b383093e8c8ca574a18b\",\"venue\":\"2020 IEEE 91st Vehicular Technology Conference (VTC2020-Spring)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117333261\",\"name\":\"Y. Shinohara\"},{\"authorId\":\"1500422549\",\"name\":\"Satomi Shirasaki\"},{\"authorId\":\"48607324\",\"name\":\"Y. Wu\"},{\"authorId\":\"145758871\",\"name\":\"Kenji Kanai\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/ICCE-TW46550.2019.8991815\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f08848e5c33caefd61bd830484682474ae699a\",\"title\":\"Performance Evaluations of Tile-based 360-degree DASH Streaming with Clustering-based Viewport Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d6f08848e5c33caefd61bd830484682474ae699a\",\"venue\":\"2019 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47446930\",\"name\":\"M. Wang\"},{\"authorId\":\"1585598418\",\"name\":\"Xu-Quan Lyu\"},{\"authorId\":\"3013590\",\"name\":\"Y. Li\"},{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"}],\"doi\":\"10.1007/s41095-020-0162-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01ca56e323616ffa2c95de0659cc15c7f57bf36\",\"title\":\"VR content creation and exploration with deep learning: A survey\",\"url\":\"https://www.semanticscholar.org/paper/f01ca56e323616ffa2c95de0659cc15c7f57bf36\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":\"1909.04913\",\"authors\":[{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/JSTSP.2019.2957982\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bacab9f46f2ccd8fec34e8d37d43ef0df2807567\",\"title\":\"Distortion-Adaptive Salient Object Detection in 360$^\\\\circ$ Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/bacab9f46f2ccd8fec34e8d37d43ef0df2807567\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1442001156\",\"name\":\"Jayesh S. Pillai\"},{\"authorId\":\"84559691\",\"name\":\"Manvi Verma\"}],\"doi\":\"10.1145/3359998.3369402\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"39d20b492d3dd05abc23d5c87c2052996d44bdaf\",\"title\":\"Grammar of VR Storytelling: Analysis of Perceptual Cues in VR Cinema\",\"url\":\"https://www.semanticscholar.org/paper/39d20b492d3dd05abc23d5c87c2052996d44bdaf\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/2020.acl-main.644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4887113b68c6b9dfda201019c99bcb99b18d642e\",\"title\":\"Refer360\\u2218: A Referring Expression Recognition Dataset in 360: A Referring Expression Recognition Dataset in 360\\u2218 Images Images\",\"url\":\"https://www.semanticscholar.org/paper/4887113b68c6b9dfda201019c99bcb99b18d642e\",\"venue\":\"ACL 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"title\":\"Refer360$^\\\\circ$: A Referring Expression Recognition Dataset in 360$^\\\\circ$ Images\",\"url\":\"https://www.semanticscholar.org/paper/6d5fa3f69b521ab563cb24484049aeee13ea4b54\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40665624\",\"name\":\"D. Zhu\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"48985515\",\"name\":\"T. Han\"},{\"authorId\":\"50580169\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2958111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11957f33f3eb17d21f5ad7a66bd2b4025f14bd26\",\"title\":\"360 Degree Panorama Synthesis From Sequential Views Based on Improved FC-Densenets\",\"url\":\"https://www.semanticscholar.org/paper/11957f33f3eb17d21f5ad7a66bd2b4025f14bd26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2011.10600\",\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"2028199013\",\"name\":\"Marouane Tliba\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"title\":\"ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.00161\",\"authors\":[{\"authorId\":\"49235564\",\"name\":\"M. Xu\"},{\"authorId\":\"32462959\",\"name\":\"Chen Li\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/JSTSP.2020.2966864\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"title\":\"State-of-the-Art in 360\\u00b0 Video/Image Processing: Perception, Assessment and Compression\",\"url\":\"https://www.semanticscholar.org/paper/42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145504600\",\"name\":\"Jun Fu\"},{\"authorId\":\"46772727\",\"name\":\"Xiaoming Chen\"},{\"authorId\":\"39539779\",\"name\":\"Zhizheng Zhang\"},{\"authorId\":\"2247786\",\"name\":\"Shilin Wu\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"}],\"doi\":\"10.1109/ICME.2019.00058\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b76eebd79d4a6e1d170edff0d48a356adfe5ba1\",\"title\":\"360SRL: A Sequential Reinforcement Learning Approach for ABR Tile-Based 360 Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/3b76eebd79d4a6e1d170edff0d48a356adfe5ba1\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"17822951\",\"name\":\"Wen-Chih Lo\"},{\"authorId\":\"153057587\",\"name\":\"Yu-Tung Pai\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":\"10.1145/3329119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07abbd64b5fa2c530c5d06c42f88a133eb38a4e6\",\"title\":\"A Survey on 360\\u00b0 Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/07abbd64b5fa2c530c5d06c42f88a133eb38a4e6\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720767940\",\"name\":\"Yixiang Mao\"},{\"authorId\":\"2142369\",\"name\":\"L. Sun\"},{\"authorId\":\"14772306\",\"name\":\"Yuexun Liu\"},{\"authorId\":null,\"name\":\"Yao Wang\"}],\"doi\":\"10.1145/3394171.3413751\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"71f797f625d157aa00bda4e1793a16885b699c59\",\"title\":\"Low-latency FoV-adaptive Coding and Streaming for Interactive 360\\u00b0 Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/71f797f625d157aa00bda4e1793a16885b699c59\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"46759203\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"}],\"doi\":\"10.24963/ijcai.2020/689\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"title\":\"Human Gaze Assisted Artificial Intelligence: A Review\",\"url\":\"https://www.semanticscholar.org/paper/97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2009.13737\",\"authors\":[{\"authorId\":\"145504598\",\"name\":\"J. Fu\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"46772727\",\"name\":\"Xiaoming Chen\"},{\"authorId\":\"89187407\",\"name\":\"W. Li\"}],\"doi\":\"10.1109/tbc.2020.3028329\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6b3bf751032228bf02d21de9cc21de9c387daa7\",\"title\":\"Sequential Reinforced 360-Degree Video Adaptive Streaming with Cross-user Attentive Network\",\"url\":\"https://www.semanticscholar.org/paper/a6b3bf751032228bf02d21de9cc21de9c387daa7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26937848\",\"name\":\"X. Feng\"},{\"authorId\":\"1692826961\",\"name\":\"Yao Liu\"},{\"authorId\":\"1504978364\",\"name\":\"Sheng Wei\"}],\"doi\":\"10.1109/VR46266.2020.1584727730619\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a0729022af9291559e23a43917bf036c5593c2f\",\"title\":\"LiveDeep: Online Viewport Prediction for Live Virtual Reality Streaming Using Lifelong Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2a0729022af9291559e23a43917bf036c5593c2f\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2020},{\"arxivId\":\"1904.07080\",\"authors\":[{\"authorId\":\"1743773\",\"name\":\"Mai Xu\"},{\"authorId\":\"40248914\",\"name\":\"Li Yang\"},{\"authorId\":\"144978572\",\"name\":\"Xiaoming Tao\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"1754571\",\"name\":\"Zulin Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"title\":\"Saliency Prediction on Omnidirectional Images with Generative Adversarial Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/89fdf25a9ced9484512c911e23afbbb54f98b9ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153170974\",\"name\":\"D. K. Sharma\"},{\"authorId\":\"1577865199\",\"name\":\"A. Khera\"},{\"authorId\":\"144996780\",\"name\":\"Dharmesh Singh\"}],\"doi\":\"10.1007/978-3-030-35252-3_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d58f38a8a82fa310867f8b323d46f1dbbf113fd6\",\"title\":\"Using Artificial Intelligence to Bring Accurate Real-Time Simulation to Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/d58f38a8a82fa310867f8b323d46f1dbbf113fd6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.01439\",\"authors\":[{\"authorId\":\"4870207\",\"name\":\"Chenge Li\"},{\"authorId\":\"50550408\",\"name\":\"Weixi Zhang\"},{\"authorId\":\"1679704\",\"name\":\"Y. Liu\"},{\"authorId\":\"49418346\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/MIPR.2019.00060\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"58e727bbdd9593b257e698dce335adc3a5a174d9\",\"title\":\"Very Long Term Field of View Prediction for 360-Degree Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/58e727bbdd9593b257e698dce335adc3a5a174d9\",\"venue\":\"2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5702271d612281e09627d873cc08c92bab0f715c\",\"title\":\"Distortion-adaptive Salient Object Detection in 360\\u00b0 Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/5702271d612281e09627d873cc08c92bab0f715c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9517723\",\"name\":\"Mariem Ben Yahia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31e7f57faa85a2e6a424b3e7fd188b731f888dbe\",\"title\":\"Low latency video streaming solutions based on HTTP/2. (Solutions de transmission vid\\u00e9o avec faible latence bas\\u00e9es sur HTTP/2)\",\"url\":\"https://www.semanticscholar.org/paper/31e7f57faa85a2e6a424b3e7fd188b731f888dbe\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"144754615\",\"name\":\"M. Winckler\"},{\"authorId\":\"51261519\",\"name\":\"Thomas Fisichella\"},{\"authorId\":\"49533972\",\"name\":\"R. Aparicio\"}],\"doi\":\"10.1145/3343031.3350601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"322a6fade1c850b28320fc51c3c2ce8f99655eae\",\"title\":\"User-Adaptive Editing for 360 degree Video Streaming with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/322a6fade1c850b28320fc51c3c2ce8f99655eae\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2010.08045\",\"authors\":[{\"authorId\":\"27478395\",\"name\":\"K. Bhandari\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3fe75c5f79a6a37d3cc9082ce74048cc48128fc4\",\"title\":\"Revisiting Optical Flow Estimation in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/3fe75c5f79a6a37d3cc9082ce74048cc48128fc4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23209172\",\"name\":\"Shahryar Afzal\"},{\"authorId\":\"1391202254\",\"name\":\"Jiasi Chen\"},{\"authorId\":\"145922660\",\"name\":\"K. Ramakrishnan\"}],\"doi\":\"10.1109/ICCCN49398.2020.9209659\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"236e92cdc51c7efa96d3942fe6eaea333b8b601d\",\"title\":\"Viewing the 360\\u00b0 Future: Trade-Off Between User Field-of-View Prediction, Network Bandwidth, and Delay\",\"url\":\"https://www.semanticscholar.org/paper/236e92cdc51c7efa96d3942fe6eaea333b8b601d\",\"venue\":\"2020 29th International Conference on Computer Communications and Networks (ICCCN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31057181\",\"name\":\"Gongwei Xiao\"},{\"authorId\":\"48282714\",\"name\":\"X. Chen\"},{\"authorId\":\"4731807\",\"name\":\"Muhong Wu\"},{\"authorId\":\"145447664\",\"name\":\"Zhi Zhou\"}],\"doi\":\"10.1145/3321408.3321603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f30a5aa2404776e93316141bd63e1e158154acb9\",\"title\":\"Deep reinforcement learning-driven intelligent panoramic video bitrate adaptation\",\"url\":\"https://www.semanticscholar.org/paper/f30a5aa2404776e93316141bd63e1e158154acb9\",\"venue\":\"ACM TUR-C\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3363882\",\"name\":\"I. Agtzidis\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":\"10.1145/3314111.3319829\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"402b41604f4047668159eaf068cb3ac0c9c1ae44\",\"title\":\"Getting (more) real: bringing eye movement classification to HMD experiments with equirectangular stimuli\",\"url\":\"https://www.semanticscholar.org/paper/402b41604f4047668159eaf068cb3ac0c9c1ae44\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878895877\",\"name\":\"Yucheng Zhu\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"}],\"doi\":\"10.1109/TMM.2019.2957986\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"title\":\"The Prediction of Saliency Map for Head and Eye Movements in 360 Degree Images\",\"url\":\"https://www.semanticscholar.org/paper/42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27541643\",\"name\":\"A. Li\"},{\"authorId\":\"48243913\",\"name\":\"L. Sun\"},{\"authorId\":\"4870207\",\"name\":\"Chenge Li\"},{\"authorId\":null,\"name\":\"Yao Wang\"},{\"authorId\":\"47908474\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d50dd1b4356f21202ba6ec5af7292b93f1c0191\",\"title\":\"360-degree Video Streaming by Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0d50dd1b4356f21202ba6ec5af7292b93f1c0191\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959507901\",\"name\":\"Xiaolan Jiang\"},{\"authorId\":\"1961460065\",\"name\":\"Si Ahmed Naas\"},{\"authorId\":\"2427829\",\"name\":\"Yi-Han Chiang\"},{\"authorId\":\"49772612\",\"name\":\"S. Sigg\"},{\"authorId\":\"2609825\",\"name\":\"Yusheng Ji\"}],\"doi\":\"10.1109/ACCESS.2020.3022062\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c6ff0f183c701b2b7386021e03e79baa088fad6\",\"title\":\"SVP: Sinusoidal Viewport Prediction for 360-Degree Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/7c6ff0f183c701b2b7386021e03e79baa088fad6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"1406778933\",\"name\":\"F. Precioso\"}],\"doi\":\"10.1145/3339825.3394934\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"510ce0a4796e467b8c0a4a4dcf71bf2d64255435\",\"title\":\"A unified evaluation framework for head motion prediction methods in 360\\u00b0 videos\",\"url\":\"https://www.semanticscholar.org/paper/510ce0a4796e467b8c0a4a4dcf71bf2d64255435\",\"venue\":\"MMSys\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89792046\",\"name\":\"Abid Yaqoob\"},{\"authorId\":\"98357144\",\"name\":\"T. Bi\"},{\"authorId\":\"145576345\",\"name\":\"G. Muntean\"}],\"doi\":\"10.1109/COMST.2020.3006999\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6d086d96567c88024fa69fecdf703304a882cc7\",\"title\":\"A Survey on Adaptive 360\\u00b0 Video Streaming: Solutions, Challenges and Opportunities\",\"url\":\"https://www.semanticscholar.org/paper/b6d086d96567c88024fa69fecdf703304a882cc7\",\"venue\":\"IEEE Communications Surveys & Tutorials\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118381655\",\"name\":\"Omar Arafa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0815551207d653caeb368f6ea2ca875bea8894ad\",\"title\":\"Bandwidth estimation and rate adaptation for 360-degree mobile video streaming\",\"url\":\"https://www.semanticscholar.org/paper/0815551207d653caeb368f6ea2ca875bea8894ad\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31057181\",\"name\":\"Gongwei Xiao\"},{\"authorId\":\"4731807\",\"name\":\"Muhong Wu\"},{\"authorId\":\"2494213\",\"name\":\"Qian Shi\"},{\"authorId\":\"145447664\",\"name\":\"Zhi Zhou\"},{\"authorId\":\"121022998\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/TCCN.2019.2938947\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"193b8b36f5d62a05b9501baa93d54c764a631df9\",\"title\":\"DeepVR: Deep Reinforcement Learning for Predictive Panoramic Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/193b8b36f5d62a05b9501baa93d54c764a631df9\",\"venue\":\"IEEE Transactions on Cognitive Communications and Networking\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9517723\",\"name\":\"Mariem Ben Yahia\"},{\"authorId\":\"2360157\",\"name\":\"Yannick Le Lou\\u00e9dec\"},{\"authorId\":\"1835841\",\"name\":\"G. Simon\"},{\"authorId\":\"2907264\",\"name\":\"L. Nuaymi\"}],\"doi\":\"10.1109/ISM.2018.00023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88fff6f608a3a1c2ab022afdba513a5264924baa\",\"title\":\"HTTP/2-Based Streaming Solutions for Tiled Omnidirectional Videos\",\"url\":\"https://www.semanticscholar.org/paper/88fff6f608a3a1c2ab022afdba513a5264924baa\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":\"1912.05971\",\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"1474358241\",\"name\":\"Ke Gu\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"title\":\"Toward Better Understanding of Saliency Prediction in Augmented 360 Degree Videos\",\"url\":\"https://www.semanticscholar.org/paper/0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"46286370\",\"name\":\"Yiwei Yang\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"title\":\"A Saliency Dataset of Head and Eye Movements for Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1441978593\",\"name\":\"Johanna Vielhaben\"},{\"authorId\":\"112840504\",\"name\":\"H. Camalan\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49545174\",\"name\":\"Markus Wenzel\"}],\"doi\":\"10.1109/AIVR46125.2019.00020\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f48c51c4467a2e1b48b971fbc43a26ce611d06c\",\"title\":\"Viewport Forecasting in 360\\u00b0 Virtual Reality Videos with Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/7f48c51c4467a2e1b48b971fbc43a26ce611d06c\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":\"1911.11702\",\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"150103589\",\"name\":\"F. Precioso\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"title\":\"Revisiting Deep Architectures for Head Motion Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51439202\",\"name\":\"T. V. Gemert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c48b8893aa5a4fb5a796bc95495a940793f6e0ee\",\"title\":\"Dynamic Viewport-Adaptive Rendering in Distributed Interactive VR Streaming : Optimizing viewport resolution under latency and viewport orientation constraints\",\"url\":\"https://www.semanticscholar.org/paper/c48b8893aa5a4fb5a796bc95495a940793f6e0ee\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31910818\",\"name\":\"P. Shi\"},{\"authorId\":\"21300772\",\"name\":\"M. Billeter\"},{\"authorId\":\"1737690\",\"name\":\"E. Eisemann\"}],\"doi\":\"10.1016/j.cag.2020.06.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9f06b84e46528242ac7d2f2291b33a84604c7d0\",\"title\":\"SalientGaze: Saliency-based gaze correction in virtual reality\",\"url\":\"https://www.semanticscholar.org/paper/e9f06b84e46528242ac7d2f2291b33a84604c7d0\",\"venue\":\"Comput. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153186485\",\"name\":\"Guangxiao Ma\"},{\"authorId\":\"1423476966\",\"name\":\"Shuai Li\"},{\"authorId\":\"3289090\",\"name\":\"Chenglizhao Chen\"},{\"authorId\":\"2252725\",\"name\":\"Ai-min Hao\"},{\"authorId\":\"1830614308\",\"name\":\"Hong Qin\"}],\"doi\":\"10.1109/TVCG.2020.3023636\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f8cb32d4caddf8a1e25d47ed527a54e682af4f9\",\"title\":\"Stage-wise Salient Object Detection in 360\\u00b0 Omnidirectional Image via Object-level Semantical Saliency Ranking\",\"url\":\"https://www.semanticscholar.org/paper/4f8cb32d4caddf8a1e25d47ed527a54e682af4f9\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":\"2010.08539\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"152462956\",\"name\":\"D. Gordon\"},{\"authorId\":\"151492449\",\"name\":\"T. Nguyen\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d27eca39a42d1bf618c827f5472d58a8423c5568\",\"title\":\"What Can You Learn from Your Muscles? Learning Visual Representation from Human Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d27eca39a42d1bf618c827f5472d58a8423c5568\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941672\",\"name\":\"Zhiming Hu\"}],\"doi\":\"10.1109/VRW50115.2020.00123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b068985d1a4f1fa2e3423b4f844ac56a17807d1\",\"title\":\"Gaze Analysis and Prediction in Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/7b068985d1a4f1fa2e3423b4f844ac56a17807d1\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\",\"year\":2020},{\"arxivId\":\"2001.07960\",\"authors\":[{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48571144\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1931304\",\"name\":\"W. Hamidouche\"},{\"authorId\":\"144598687\",\"name\":\"O. D\\u00e9forges\"}],\"doi\":\"10.1109/ICIP40778.2020.9191158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5be1490c62df8e5a14e96aeab3175e9215d136dc\",\"title\":\"A Fixation-Based 360\\u00b0 Benchmark Dataset For Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/5be1490c62df8e5a14e96aeab3175e9215d136dc\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46380828\",\"name\":\"J. Yu\"},{\"authorId\":\"143711913\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1145/3304113.3326118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfc0ee29c4c0882acacf652ac59a09ccaba23f06\",\"title\":\"Field-of-view prediction in 360-degree videos with attention-based neural encoder-decoder networks\",\"url\":\"https://www.semanticscholar.org/paper/cfc0ee29c4c0882acacf652ac59a09ccaba23f06\",\"venue\":\"MMVE@MMSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"1406778933\",\"name\":\"F. Precioso\"}],\"doi\":\"10.1109/ICIP40778.2020.9191331\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa261df24ba051650572dff9dfa65843ff2f4547\",\"title\":\"Track: a Multi-Modal Deep Architecture for Head Motion Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/fa261df24ba051650572dff9dfa65843ff2f4547\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2003.00429\",\"authors\":[{\"authorId\":\"46771958\",\"name\":\"X. Chen\"},{\"authorId\":\"35475146\",\"name\":\"Ali Taleb Zadeh Kasgari\"},{\"authorId\":\"145412071\",\"name\":\"W. Saad\"}],\"doi\":\"10.1109/LNET.2020.2977124\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b42a33c1c7b2afe4123d6d606f3bc5cd5fe60d6f\",\"title\":\"Deep Learning for Content-Based Personalized Viewport Prediction of 360-Degree VR Videos\",\"url\":\"https://www.semanticscholar.org/paper/b42a33c1c7b2afe4123d6d606f3bc5cd5fe60d6f\",\"venue\":\"IEEE Networking Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51310992\",\"name\":\"Yihua Cheng\"},{\"authorId\":\"2520795\",\"name\":\"Xucong Zhang\"},{\"authorId\":\"1388864077\",\"name\":\"Feng Lu\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.2982828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf7257caa35675c5637e21279b3e405c71a63ef6\",\"title\":\"Gaze Estimation by Exploring Two-Eye Asymmetry\",\"url\":\"https://www.semanticscholar.org/paper/bf7257caa35675c5637e21279b3e405c71a63ef6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":52847184,\"doi\":\"10.1109/CVPR.2018.00559\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":12,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050482\",\"name\":\"J. Zhang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1693589\",\"name\":\"M. Kan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-319-10605-2_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"581f5c2e00aaa19942355ef99ecd46bcff55be08\",\"title\":\"Coarse-to-Fine Auto-Encoder Networks (CFAN) for Real-Time Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/581f5c2e00aaa19942355ef99ecd46bcff55be08\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1507.06550\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"33932184\",\"name\":\"Pulkit Agrawal\"},{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2016.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66d4475f0eee4b65983e06b1fbafad533eb81b2a\",\"title\":\"Human Pose Estimation with Iterative Error Feedback\",\"url\":\"https://www.semanticscholar.org/paper/66d4475f0eee4b65983e06b1fbafad533eb81b2a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Koch\"},{\"authorId\":null,\"name\":\"P. Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph - based visual salien\",\"url\":\"\",\"venue\":\"Proceedings of the Twenty - Sixth International Joint Conference on Artificial Intelligence\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"7503327\",\"name\":\"Vennela Gudisa\"},{\"authorId\":\"2313878\",\"name\":\"Jaley H. Dholakiya\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/CVPR.2016.623\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ca43c217aceabea4cff14bff1d81df2debe058f\",\"title\":\"Saliency Unified: A Deep Architecture for simultaneous Eye Fixation Prediction and Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1ca43c217aceabea4cff14bff1d81df2debe058f\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143929120\",\"name\":\"F. Guo\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ICME.2014.6890321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c44de3f7bf2596715459082a6ea976b852c2201\",\"title\":\"Learning to detect stereo saliency\",\"url\":\"https://www.semanticscholar.org/paper/0c44de3f7bf2596715459082a6ea976b852c2201\",\"venue\":\"2014 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50295846\",\"name\":\"K. Yamada\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"1805464\",\"name\":\"K. Hiraki\"}],\"doi\":\"10.1007/978-3-642-25367-6_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2e5b460fbc692e63e160cdef26141d236f5211f\",\"title\":\"Attention Prediction in Egocentric Video Using Motion and Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f2e5b460fbc692e63e160cdef26141d236f5211f\",\"venue\":\"PSIVT\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5021307\",\"name\":\"Vincent Sitzmann\"},{\"authorId\":\"143772343\",\"name\":\"Ana Serrano\"},{\"authorId\":\"48453720\",\"name\":\"A. Pavel\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"}],\"doi\":\"10.1109/TVCG.2018.2793599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"title\":\"Saliency in VR: How Do People Explore Virtual Environments?\",\"url\":\"https://www.semanticscholar.org/paper/c3d382d1aad38e7e1a9249a7bd323f9a5cf92ca8\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1604.08010\",\"authors\":[{\"authorId\":\"3393537\",\"name\":\"Souad Chaabouni\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2803728\",\"name\":\"O. Hadar\"},{\"authorId\":\"3410172\",\"name\":\"C. Amar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05d1e0ee52c5796aa58d16f176721348e6317e41\",\"title\":\"Deep Learning for Saliency Prediction in Natural Video\",\"url\":\"https://www.semanticscholar.org/paper/05d1e0ee52c5796aa58d16f176721348e6317e41\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/CVPR.2017.377\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/TPAMI.2009.112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62eb421cdac9de9255578f14fba55146d958be44\",\"title\":\"Spatiotemporal Saliency in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/62eb421cdac9de9255578f14fba55146d958be44\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35113211\",\"name\":\"Yashas Rai\"},{\"authorId\":\"1398172020\",\"name\":\"Jes\\u00fas Guti\\u00e9rrez-Cill\\u00e1n\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1145/3083187.3083218\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"080bdf42c6de4a89a268cf90f56f5c4ec68df419\",\"title\":\"A Dataset of Head and Eye Movements for 360 Degree Images\",\"url\":\"https://www.semanticscholar.org/paper/080bdf42c6de4a89a268cf90f56f5c4ec68df419\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":\"1411.5878\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"97483166\",\"name\":\"J. Li\"}],\"doi\":\"10.1007/s41095-019-0149-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6bbd62f7b5a33d10a6ca8935db76c58f6256d25\",\"title\":\"Salient object detection: A survey\",\"url\":\"https://www.semanticscholar.org/paper/f6bbd62f7b5a33d10a6ca8935db76c58f6256d25\",\"venue\":\"Computational Visual Media\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2011.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"title\":\"Context-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685004\",\"name\":\"H. Hadizadeh\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":\"10.1109/TIP.2013.2282897\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edf3d2f5ad0473698fcdb5dad712734ef1365524\",\"title\":\"Saliency-Aware Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/edf3d2f5ad0473698fcdb5dad712734ef1365524\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403256\",\"name\":\"Xavier Corbillon\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"1835841\",\"name\":\"G. Simon\"}],\"doi\":\"10.1145/3083187.3083215\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b64310dd13e71e6b192ca70c76a3ab65143614c\",\"title\":\"360-Degree Video Head Movement Dataset\",\"url\":\"https://www.semanticscholar.org/paper/3b64310dd13e71e6b192ca70c76a3ab65143614c\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3143425\",\"name\":\"A. Gibaldi\"},{\"authorId\":\"47007246\",\"name\":\"M. Vanegas\"},{\"authorId\":\"2766209\",\"name\":\"P. Bex\"},{\"authorId\":\"145250314\",\"name\":\"Guido Maiello\"}],\"doi\":\"10.3758/s13428-016-0762-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12474ffd07a6bf922abfb58eca3828cf8d4f86b7\",\"title\":\"Evaluation of the Tobii EyeX Eye tracking controller and Matlab toolkit for research\",\"url\":\"https://www.semanticscholar.org/paper/12474ffd07a6bf922abfb58eca3828cf8d4f86b7\",\"venue\":\"Behavior research methods\",\"year\":2017},{\"arxivId\":\"1705.01759\",\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.153\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba227bb94ea9414bad8846673c904a10d813e443\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360\\u00b0 Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba227bb94ea9414bad8846673c904a10d813e443\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2675203\",\"name\":\"Seyed Hossein Khatoonabadi\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"},{\"authorId\":\"37207452\",\"name\":\"Yufeng Shan\"}],\"doi\":\"10.1109/CVPR.2015.7299189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12c1df9b8c6e55bd6597b335dd9d9bac9fe5ee26\",\"title\":\"How many bits does it take for a stimulus to be salient?\",\"url\":\"https://www.semanticscholar.org/paper/12c1df9b8c6e55bd6597b335dd9d9bac9fe5ee26\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1602.07261\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"122113652\",\"name\":\"Alexander Amir Alemi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"title\":\"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.24963/ijcai.2017/386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa95ce52d821499547a68048d35f35a0dd171a25\",\"title\":\"Forecast the Plausible Paths in Crowd Scenes\",\"url\":\"https://www.semanticscholar.org/paper/fa95ce52d821499547a68048d35f35a0dd171a25\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2330182\",\"name\":\"S. Wen\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"}],\"doi\":\"10.1109/CVPR.2015.7298633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"title\":\"Predicting eye fixations using convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/c6551c3c5e4c9779b2bbc6c8edcdeab545bc824d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph - based visual salien\",\"url\":\"\",\"venue\":\"Proceedings of the Twenty - Sixth International Joint Conference on Artificial Intelligence\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34317938\",\"name\":\"S. Hacisalihzade\"},{\"authorId\":\"1731863\",\"name\":\"L. Stark\"},{\"authorId\":\"145222337\",\"name\":\"John S. Allen\"}],\"doi\":\"10.1109/21.155948\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8a4737b2279a6d6a3e780aa418a7cb53170e63e\",\"title\":\"Visual perception and sequences of eye movement fixations: a stochastic modeling approach\",\"url\":\"https://www.semanticscholar.org/paper/c8a4737b2279a6d6a3e780aa418a7cb53170e63e\",\"venue\":\"IEEE Trans. Syst. Man Cybern.\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1007/s12559-010-9074-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"title\":\"Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion\",\"url\":\"https://www.semanticscholar.org/paper/27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233370\",\"name\":\"Alexis Gabadinho\"},{\"authorId\":\"1824611\",\"name\":\"G. Ritschard\"},{\"authorId\":\"2540489\",\"name\":\"Nicolas S. M\\u00fcller\"},{\"authorId\":\"143905948\",\"name\":\"Matthias Studer\"}],\"doi\":\"10.18637/JSS.V040.I04\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c50d1ed3f988745f7b969cfb42d38be1a6580f76\",\"title\":\"Analyzing and Visualizing State Sequences in R with TraMineR\",\"url\":\"https://www.semanticscholar.org/paper/c50d1ed3f988745f7b969cfb42d38be1a6580f76\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2447593\",\"name\":\"Shuai Yi\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-319-46448-0_16\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"259e4aca87b8724b4c9df2315b976237481a1929\",\"title\":\"Pedestrian Behavior Understanding and Prediction with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/259e4aca87b8724b4c9df2315b976237481a1929\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/TIP.2009.2030969\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01825573781674bcf85d0f5d2ec456842f75ad3c\",\"title\":\"A Novel Multiresolution Spatiotemporal Saliency Detection Model and Its Applications in Image and Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/01825573781674bcf85d0f5d2ec456842f75ad3c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/CVPR.2016.80\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1c4bb9974990f70d46c9d4bd5cca7e7940273e6\",\"title\":\"DHSNet: Deep Hierarchical Saliency Network for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/c1c4bb9974990f70d46c9d4bd5cca7e7940273e6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144248905\",\"name\":\"M. Yu\"},{\"authorId\":\"2052685\",\"name\":\"H. Lakshman\"},{\"authorId\":\"1739786\",\"name\":\"B. Girod\"}],\"doi\":\"10.1109/ISMAR.2015.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3c9a67d5c1aadcabf6c6c25ce9729f077c9f302\",\"title\":\"A Framework to Evaluate Omnidirectional Video Coding Schemes\",\"url\":\"https://www.semanticscholar.org/paper/b3c9a67d5c1aadcabf6c6c25ce9729f077c9f302\",\"venue\":\"2015 IEEE International Symposium on Mixed and Augmented Reality\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17822951\",\"name\":\"Wen-Chih Lo\"},{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"8152707\",\"name\":\"J. Lee\"},{\"authorId\":\"2194011\",\"name\":\"C. Huang\"},{\"authorId\":\"6270307\",\"name\":\"Kuan-Ta Chen\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":\"10.1145/3083187.3083219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d576ebcb4a0fa54825f0ba05eaf18cd8f9bdda80\",\"title\":\"360\\u00b0 Video Viewing Dataset in Head-Mounted Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/d576ebcb4a0fa54825f0ba05eaf18cd8f9bdda80\",\"venue\":\"MMSys\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12525266\",\"name\":\"Xinyi Cui\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1145/1631272.1631370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3257d74e4ad050a1a518a53b0d23751f771f483\",\"title\":\"Temporal spectral residual: fast motion saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/b3257d74e4ad050a1a518a53b0d23751f771f483\",\"venue\":\"MM '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34469457\",\"name\":\"R. Liu\"},{\"authorId\":\"1839803\",\"name\":\"J. Cao\"},{\"authorId\":\"33383055\",\"name\":\"Zhouchen Lin\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"}],\"doi\":\"10.1109/CVPR.2014.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99c0aafbe9bf2ca9b36f6350a22098357b922b86\",\"title\":\"Adaptive Partial Differential Equation Learning for Visual Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/99c0aafbe9bf2ca9b36f6350a22098357b922b86\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141668\",\"name\":\"Kathryn Koehler\"},{\"authorId\":\"152831016\",\"name\":\"F. Guo\"},{\"authorId\":\"38654394\",\"name\":\"Shenmin Zhang\"},{\"authorId\":\"1895768\",\"name\":\"M. Eckstein\"}],\"doi\":\"10.1167/14.3.14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ab4347176ac94b17065fea285f952b1de32c2c0\",\"title\":\"What do saliency models predict?\",\"url\":\"https://www.semanticscholar.org/paper/0ab4347176ac94b17065fea285f952b1de32c2c0\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Eye tracking\",\"topicId\":\"7621\",\"url\":\"https://www.semanticscholar.org/topic/7621\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Feature extraction\",\"topicId\":\"4259\",\"url\":\"https://www.semanticscholar.org/topic/4259\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Field of view in video games\",\"topicId\":\"3405532\",\"url\":\"https://www.semanticscholar.org/topic/3405532\"},{\"topic\":\"Headphones\",\"topicId\":\"175779\",\"url\":\"https://www.semanticscholar.org/topic/175779\"},{\"topic\":\"Spatial scale\",\"topicId\":\"302443\",\"url\":\"https://www.semanticscholar.org/topic/302443\"},{\"topic\":\"Displacement mapping\",\"topicId\":\"412637\",\"url\":\"https://www.semanticscholar.org/topic/412637\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"}],\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"