"{\"abstract\":\"Training robust deep video representations has proven to be much more challenging than learning deep image representations. This is in part due to the enormous size of raw video streams and the high temporal redundancy; the true and interesting signal is often drowned in too much irrelevant data. Motivated by that the superfluous information can be reduced by up to two orders of magnitude by video compression (using H.264, HEVC, etc.), we propose to train a deep network directly on the compressed video. This representation has a higher information density, and we found the training to be easier. In addition, the signals in a compressed video provide free, albeit noisy, motion information. We propose novel techniques to use them effectively. Our approach is about 4.6 times faster than Res3D and 2.7 times faster than ResNet-152. On the task of action recognition, our approach outperforms all the other methods on the UCF-101, HMDB-51, and Charades dataset.\",\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\",\"url\":\"https://www.semanticscholar.org/author/2978413\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\",\"url\":\"https://www.semanticscholar.org/author/1771307\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\",\"url\":\"https://www.semanticscholar.org/author/2804000\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\",\"url\":\"https://www.semanticscholar.org/author/1758550\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\",\"url\":\"https://www.semanticscholar.org/author/46234526\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\",\"url\":\"https://www.semanticscholar.org/author/2562966\"}],\"citationVelocity\":41,\"citations\":[{\"arxivId\":\"1912.04462\",\"authors\":[{\"authorId\":\"3264239\",\"name\":\"Shi-Yuan Huang\"},{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"title\":\"Flow-Distilled IP Two-Stream Networks for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150270522\",\"name\":\"Qiankun Liu\"},{\"authorId\":\"145117692\",\"name\":\"B. Liu\"},{\"authorId\":\"46220633\",\"name\":\"Yue Wu\"},{\"authorId\":\"3313781\",\"name\":\"Weihai Li\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"}],\"doi\":\"10.1109/ACCESS.2019.2921975\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5aa62121aeed6908bb90a4871a9dc7425477befb\",\"title\":\"Real-Time Online Multi-Object Tracking in Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/5aa62121aeed6908bb90a4871a9dc7425477befb\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51904284\",\"name\":\"Ionut Ficiu\"},{\"authorId\":\"51915954\",\"name\":\"Radu Stilpeanu\"},{\"authorId\":\"3397314\",\"name\":\"Cosmin Toca\"},{\"authorId\":\"144473538\",\"name\":\"A. Petre\"},{\"authorId\":\"3205856\",\"name\":\"C. Patrascu\"},{\"authorId\":\"1789088\",\"name\":\"M. Ciuc\"}],\"doi\":\"10.1109/ICCP.2018.8516608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be5c16a3db2efd50ce361bda76837c019eaf40ab\",\"title\":\"Automatic Annotation of Object Instances by Region-Based Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/be5c16a3db2efd50ce361bda76837c019eaf40ab\",\"venue\":\"2018 IEEE 14th International Conference on Intelligent Computer Communication and Processing (ICCP)\",\"year\":2018},{\"arxivId\":\"2006.02958\",\"authors\":[{\"authorId\":\"102780514\",\"name\":\"M. Daum\"},{\"authorId\":\"144843868\",\"name\":\"Brandon Haynes\"},{\"authorId\":\"1798553\",\"name\":\"D. He\"},{\"authorId\":\"19170117\",\"name\":\"Amrita Mazumdar\"},{\"authorId\":\"1718134\",\"name\":\"M. Balazinska\"},{\"authorId\":\"144385783\",\"name\":\"A. Cheung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5fc3c3870adb5218709dd4caab9990806836410\",\"title\":\"TASM: A Tile-Based Storage Manager for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/b5fc3c3870adb5218709dd4caab9990806836410\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40929891\",\"name\":\"Tiantu Xu\"},{\"authorId\":\"34199964\",\"name\":\"Luis Materon Botelho\"},{\"authorId\":\"1774176\",\"name\":\"F. Lin\"}],\"doi\":\"10.1145/3302424.3303971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78150d0f113679dcd7525c244488148ba762b12c\",\"title\":\"VStore: A Data Store for Analytics on Large Videos\",\"url\":\"https://www.semanticscholar.org/paper/78150d0f113679dcd7525c244488148ba762b12c\",\"venue\":\"EuroSys\",\"year\":2019},{\"arxivId\":\"2002.12416\",\"authors\":[{\"authorId\":\"1384602097\",\"name\":\"Kai Xu\"},{\"authorId\":\"39449475\",\"name\":\"Minghai Qin\"},{\"authorId\":\"143770110\",\"name\":\"Fei Sun\"},{\"authorId\":null,\"name\":\"Yuhao Wang\"},{\"authorId\":\"123331823\",\"name\":\"Yen-Kuang Chen\"},{\"authorId\":\"40615963\",\"name\":\"Fengbo Ren\"}],\"doi\":\"10.1109/cvpr42600.2020.00181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0921b722ccc4015167c9b80a83eb41a457a86cd\",\"title\":\"Learning in the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/c0921b722ccc4015167c9b80a83eb41a457a86cd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.09029\",\"authors\":[{\"authorId\":\"1581871399\",\"name\":\"Abdolmaged Alkhulaifi\"},{\"authorId\":\"1387124746\",\"name\":\"F. Alsahli\"},{\"authorId\":\"72137044\",\"name\":\"I. Ahmad\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a11c31ccf0238c6d294cdf5f3c0b08f75679877\",\"title\":\"Knowledge Distillation in Deep Learning and its Applications\",\"url\":\"https://www.semanticscholar.org/paper/1a11c31ccf0238c6d294cdf5f3c0b08f75679877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1641886189\",\"name\":\"Vali Ollah Maraghi\"},{\"authorId\":\"1692435\",\"name\":\"K. Faez\"}],\"doi\":\"10.1109/ICSPIS48872.2019.9066160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d1b7d73baf3482275532604607d6756275be73\",\"title\":\"Zero-Shot Learning on Human-Object Interaction Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/f3d1b7d73baf3482275532604607d6756275be73\",\"venue\":\"2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31586818\",\"name\":\"H. G. Chen\"},{\"authorId\":\"8133623\",\"name\":\"Wanjia Liu\"},{\"authorId\":\"46186660\",\"name\":\"R. Goel\"},{\"authorId\":\"2492444\",\"name\":\"Rhonald C. Lua\"},{\"authorId\":\"47732006\",\"name\":\"S. Mittal\"},{\"authorId\":\"35633657\",\"name\":\"Yuzhong Huang\"},{\"authorId\":\"145280967\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"46463998\",\"name\":\"Ankit B. Patel\"}],\"doi\":\"10.1109/TCI.2019.2948755\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7377982e58702e0f44beff2c00ab2d32825cf557\",\"title\":\"Fast Retinomorphic Event-Driven Representations for Video Gameplay and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7377982e58702e0f44beff2c00ab2d32825cf557\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95906612\",\"name\":\"D. Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"30477181\",\"name\":\"Yie-Tarng Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCVW.2019.00125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a160c956afc22ad837e61f865eb80169bd12259\",\"title\":\"Extreme Low Resolution Action Recognition with Spatial-Temporal Multi-Head Self-Attention and Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/2a160c956afc22ad837e61f865eb80169bd12259\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145560668\",\"name\":\"T. C. Deveci\"},{\"authorId\":\"34847767\",\"name\":\"S. \\u00c7akir\"},{\"authorId\":\"66196385\",\"name\":\"A. E. Cetin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ada415932c391acc3347ddf04f0988480c4385c2\",\"title\":\"C V ] 1 4 M ay 2 01 8 Energy Efficient Hadamard Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ada415932c391acc3347ddf04f0988480c4385c2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.11091\",\"authors\":[{\"authorId\":\"1491169373\",\"name\":\"Mohamad Ballout\"},{\"authorId\":\"1381681564\",\"name\":\"Mohammad Tuqan\"},{\"authorId\":\"1790873\",\"name\":\"Daniel C. Asmar\"},{\"authorId\":\"48810394\",\"name\":\"Elie Shammas\"},{\"authorId\":\"1768700\",\"name\":\"George E. Sakr\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"title\":\"The benefits of synthetic data for action categorization\",\"url\":\"https://www.semanticscholar.org/paper/7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICASSP.2019.8683606\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"750c885ee644cb19d89f52ab31639f56254273a2\",\"title\":\"Neuromorphic Vision Sensing for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/750c885ee644cb19d89f52ab31639f56254273a2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"41c21f12f6896c458004f26b1fd704f4058aaac1\",\"title\":\"CV-C3D: Action Recognition on Compressed Videos with Convolutional 3D Networks\",\"url\":\"https://www.semanticscholar.org/paper/41c21f12f6896c458004f26b1fd704f4058aaac1\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":\"1810.03964\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"},{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"}],\"doi\":\"10.1109/ICIP.2018.8451666\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2007.05840\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1980683\",\"name\":\"S. Aeron\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a2ef52618bc02c12e9edf59088d9fafee829185\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/4a2ef52618bc02c12e9edf59088d9fafee829185\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.08408\",\"authors\":[{\"authorId\":\"103102295\",\"name\":\"Benjamin Deguerre\"},{\"authorId\":\"1712446\",\"name\":\"Cl\\u00e9ment Chatelain\"},{\"authorId\":\"2378576\",\"name\":\"G. Gasso\"}],\"doi\":\"10.1109/ITSC.2019.8916937\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8fdec0ef2d4fc4d82663b61d74853b023359b274\",\"title\":\"Fast object detection in compressed JPEG Images\",\"url\":\"https://www.semanticscholar.org/paper/8fdec0ef2d4fc4d82663b61d74853b023359b274\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738178502\",\"name\":\"Matheus Gutoski\"},{\"authorId\":\"3225435\",\"name\":\"A. E. Lazzaretti\"},{\"authorId\":\"1806302\",\"name\":\"H. Lopes\"}],\"doi\":\"10.1007/s00521-020-05009-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f449b6f662a729b045b7bed80254b5bd30505d1\",\"title\":\"Deep metric learning for open-set human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/1f449b6f662a729b045b7bed80254b5bd30505d1\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38df033adc8b89ad02a638db823be439260113bd\",\"title\":\"Tiny Video Networks: Architecture Search for Efficient Video Models\",\"url\":\"https://www.semanticscholar.org/paper/38df033adc8b89ad02a638db823be439260113bd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.14426\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"title\":\"Deep Learning Towards Edge Computing: Neural Networks Straight from Compressed Data\",\"url\":\"https://www.semanticscholar.org/paper/1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.12432\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00137\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0a98ef88bae12639d8770e5680564b8f9a188bec\",\"title\":\"AdaFrame: Adaptive Frame Selection for Fast Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0a98ef88bae12639d8770e5680564b8f9a188bec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1907.10015\",\"authors\":[{\"authorId\":\"80977068\",\"name\":\"Shao-Yuan Lo\"},{\"authorId\":\"144922393\",\"name\":\"H. Hang\"}],\"doi\":\"10.1145/3338533.3366557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14076c146281e4ebca08cf4d5ae6e7a3128ddf62\",\"title\":\"Exploring Semantic Segmentation on the DCT Representation\",\"url\":\"https://www.semanticscholar.org/paper/14076c146281e4ebca08cf4d5ae6e7a3128ddf62\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40896248\",\"name\":\"Samvit Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd070be9327291e229d3149ec60388dd4dbf74b1\",\"title\":\"Fast Semantic Segmentation on Video Using Motion Vector-Based Feature Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/fd070be9327291e229d3149ec60388dd4dbf74b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1016/j.patcog.2020.107695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e69494bfc8e8156a7f4cc42d9052b57b6e4241\",\"title\":\"Temporal filtering networks for online action detection\",\"url\":\"https://www.semanticscholar.org/paper/86e69494bfc8e8156a7f4cc42d9052b57b6e4241\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151476159\",\"name\":\"Ali Abdari\"},{\"authorId\":\"30971240\",\"name\":\"Pouria Amirjan\"},{\"authorId\":\"2972300\",\"name\":\"A. Mansouri\"}],\"doi\":\"10.1109/PRIA.2019.8785055\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8488b7776cca63912c2a651eb61b5046878fe8d6\",\"title\":\"Action Recognition in Compressed Domain Using Residual Information\",\"url\":\"https://www.semanticscholar.org/paper/8488b7776cca63912c2a651eb61b5046878fe8d6\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885339245\",\"name\":\"Ana-Cosmina Popescu\"},{\"authorId\":\"2595036\",\"name\":\"I. Mocanu\"},{\"authorId\":\"143623623\",\"name\":\"B. Cramariuc\"}],\"doi\":\"10.1109/ACCESS.2020.3013406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"444cebeebce47adec38e43a0789d6cf2610c1fc9\",\"title\":\"Fusion Mechanisms for Human Activity Recognition Using Automated Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/444cebeebce47adec38e43a0789d6cf2610c1fc9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1749395\",\"name\":\"Xianghua Xu\"}],\"doi\":\"10.1109/ACCESS.2020.3003939\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f99d0990c255c635f731cefa434912b09598e8cd\",\"title\":\"Recurrent Compressed Convolutional Networks for Short Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/f99d0990c255c635f731cefa434912b09598e8cd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773194\",\"name\":\"Fei Pan\"},{\"authorId\":\"1720424\",\"name\":\"Y. Guo\"},{\"authorId\":\"151485208\",\"name\":\"Z. Yan\"},{\"authorId\":\"50115448\",\"name\":\"Jie Guo\"}],\"doi\":\"10.1109/ICME.2019.00283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"title\":\"Temporal Segment Convolutional Kernel Networks for Sequence Modeling of Videos\",\"url\":\"https://www.semanticscholar.org/paper/85427b81ea2d3b0aea44fe82f6520507e7241c2f\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1804.06919\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"40943290\",\"name\":\"Nayan Singhal\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1007/978-3-030-01237-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"title\":\"Video Compression through Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.02189\",\"authors\":[{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682466\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d63dc4f0eb83ceea8c2bfcd71300b7c12eff13a1\",\"title\":\"BLP - Boundary Likelihood Pinpointing Networks for Accurate Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d63dc4f0eb83ceea8c2bfcd71300b7c12eff13a1\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1912.03632\",\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41d621492203f42a52317163b4091670a360324b\",\"title\":\"View-invariant Deep Architecture for Human Action Recognition using late fusion\",\"url\":\"https://www.semanticscholar.org/paper/41d621492203f42a52317163b4091670a360324b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b217f438697476c3fbffd3f1595c17fd05ee89\",\"title\":\"Adapting computer vision models to limitations on input dimensionality and model complexity\",\"url\":\"https://www.semanticscholar.org/paper/38b217f438697476c3fbffd3f1595c17fd05ee89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.01794\",\"authors\":[{\"authorId\":\"40929891\",\"name\":\"Tiantu Xu\"},{\"authorId\":\"34199964\",\"name\":\"Luis Materon Botelho\"},{\"authorId\":\"1774176\",\"name\":\"F. Lin\"}],\"doi\":\"10.1145/3302424.3303971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5be20a6d6c79ec3e4c9220df75f827662bddeae9\",\"title\":\"Reinventing Data Stores for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/5be20a6d6c79ec3e4c9220df75f827662bddeae9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67135648\",\"name\":\"Meixia Fu\"},{\"authorId\":\"145732482\",\"name\":\"N. Chen\"},{\"authorId\":\"14042415\",\"name\":\"Zhongjie Huang\"},{\"authorId\":\"51940516\",\"name\":\"Kaili Ni\"},{\"authorId\":\"47908920\",\"name\":\"Yuhao Liu\"},{\"authorId\":\"1770819\",\"name\":\"Songlin Sun\"},{\"authorId\":\"35181056\",\"name\":\"X. Ma\"}],\"doi\":\"10.1007/978-981-13-7123-3_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"608efb376175bb8b1c26076fe2fe3fbf7d750720\",\"title\":\"Human Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/608efb376175bb8b1c26076fe2fe3fbf7d750720\",\"venue\":\"ICSINC 2018 Fall\",\"year\":2018},{\"arxivId\":\"1910.02533\",\"authors\":[{\"authorId\":\"1384812397\",\"name\":\"Haoyuan Cao\"},{\"authorId\":\"48932880\",\"name\":\"Shining Yu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"title\":\"Compressed Video Action Recognition with Refined Motion Vector\",\"url\":\"https://www.semanticscholar.org/paper/1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"134883142\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2018.2887408\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification With Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2020.2984904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"title\":\"STA-CNN: Convolutional Spatial-Temporal Attention Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1911.01060\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1410071510\",\"name\":\"Hongru Li\"},{\"authorId\":\"144410963\",\"name\":\"S. Kung\"}],\"doi\":\"10.1109/tmm.2020.3042077\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbcb5f600f0fde2cc94f90b96a830652a47e7af5\",\"title\":\"Temporal Action Localization using Long Short-Term Dependency\",\"url\":\"https://www.semanticscholar.org/paper/fbcb5f600f0fde2cc94f90b96a830652a47e7af5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48882412\",\"name\":\"Tasweer Ahmad\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"153285152\",\"name\":\"J. Feng\"},{\"authorId\":\"153073573\",\"name\":\"Guozhi Tang\"}],\"doi\":\"10.1109/ACCESS.2019.2937344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3fd39dad90b6326b87f0bed5074b4885a013033\",\"title\":\"Human Action Recognition in Unconstrained Trimmed Videos Using Residual Attention Network and Joints Path Signature\",\"url\":\"https://www.semanticscholar.org/paper/d3fd39dad90b6326b87f0bed5074b4885a013033\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1805.05421\",\"authors\":[{\"authorId\":\"145560668\",\"name\":\"T. C. Deveci\"},{\"authorId\":\"34847767\",\"name\":\"S. \\u00c7akir\"},{\"authorId\":\"144807321\",\"name\":\"A. \\u00c7etin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2de38d515d275e8b29b6086af0919fe39393c794\",\"title\":\"Energy Efficient Hadamard Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2de38d515d275e8b29b6086af0919fe39393c794\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.11690\",\"authors\":[{\"authorId\":\"39876126\",\"name\":\"Max Ehrlich\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2019.00358\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50b500f8ee8c6aaec7968b16cd73d7c3a8597b8a\",\"title\":\"Deep Residual Learning in the JPEG Transform Domain\",\"url\":\"https://www.semanticscholar.org/paper/50b500f8ee8c6aaec7968b16cd73d7c3a8597b8a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1911.09243\",\"authors\":[{\"authorId\":null,\"name\":\"Ya Wang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145724892\",\"name\":\"Fu Li\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"1685259\",\"name\":\"Jinwen Ma\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/AAAI.V34I07.6909\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"8cc97fff3292f13cfc73721dc4ae26d8f970692f\",\"title\":\"Multi-Label Classification with Label Graph Superimposing\",\"url\":\"https://www.semanticscholar.org/paper/8cc97fff3292f13cfc73721dc4ae26d8f970692f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40962452\",\"name\":\"Chhavi Dhiman\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1109/TIP.2020.2965299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"title\":\"View-Invariant Deep Architecture for Human Action Recognition Using Two-Stream Motion and Shape Temporal Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d46dbc7933d930a07a3e07d78de1c54291c54aec\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":\"2010.10637\",\"authors\":[{\"authorId\":\"120281172\",\"name\":\"Xiaofeng Liu\"},{\"authorId\":\"2000231390\",\"name\":\"Linghao Jin\"},{\"authorId\":\"145343933\",\"name\":\"X. Han\"},{\"authorId\":\"144329386\",\"name\":\"J. You\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07bc6dd2a128e0a433b928faba484c5831227690\",\"title\":\"Mutual Information Regularized Identity-aware Facial ExpressionRecognition in Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/07bc6dd2a128e0a433b928faba484c5831227690\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.05674\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":\"10.1007/978-981-15-3651-9_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f99d62a02d91de622dbf5208ef859938980c16d6\",\"title\":\"Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/f99d62a02d91de622dbf5208ef859938980c16d6\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1912.01601\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"title\":\"LiteEval: A Coarse-to-Fine Framework for Resource Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/92020e4a2ed14a5f3fd421bcf1111dd2403a237a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.06961\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"title\":\"Tiny Video Networks\",\"url\":\"https://www.semanticscholar.org/paper/7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.00101\",\"authors\":[{\"authorId\":\"144273442\",\"name\":\"Guo Lu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"8674725\",\"name\":\"C. Cai\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/CVPR.2019.01126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab995c4273111cde3e31ff7347c475aace10f1a5\",\"title\":\"DVC: An End-To-End Deep Video Compression Framework\",\"url\":\"https://www.semanticscholar.org/paper/ab995c4273111cde3e31ff7347c475aace10f1a5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143997136\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"116759974\",\"name\":\"T. Hussain\"},{\"authorId\":\"134151536\",\"name\":\"J. Del Ser\"},{\"authorId\":\"145940006\",\"name\":\"V. Palade\"},{\"authorId\":\"51905607\",\"name\":\"V. H. C. de Albuquerque\"}],\"doi\":\"10.1109/TII.2019.2960536\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd118153dad5c79e376fcd42b449416bc40b8b01\",\"title\":\"DeepReS: A Deep Learning-Based Video Summarization Strategy for Resource-Constrained Industrial Surveillance Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/bd118153dad5c79e376fcd42b449416bc40b8b01\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yongchen Wang\"},{\"authorId\":null,\"name\":\"Ying Wang\"},{\"authorId\":\"15445240\",\"name\":\"H. Li\"},{\"authorId\":\"152713339\",\"name\":\"Yinhe Han\"},{\"authorId\":\"48569730\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/DAC18072.2020.9218743\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2ca00e97a096178184c2f4e2a914d10635e2bff\",\"title\":\"An Efficient Deep Learning Accelerator for Compressed Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/b2ca00e97a096178184c2f4e2a914d10635e2bff\",\"venue\":\"2020 57th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d51fe8c751b43ffa79feae581d555dfcbced6e3d\",\"title\":\"Supplementary material: SCSampler: Sampling Salient Clips from Video for Efficient Action Recognition 1. Action classification networks\",\"url\":\"https://www.semanticscholar.org/paper/d51fe8c751b43ffa79feae581d555dfcbced6e3d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476823732\",\"name\":\"Sami Jaballah\"},{\"authorId\":\"47102170\",\"name\":\"Mohamed-Chaker Larabi\"}],\"doi\":\"10.1109/EUVIP47703.2019.8946214\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"831d69d84f2b2322dc349e2dd1cc98db3145fef7\",\"title\":\"Fast Object Detection in H264/AVC and HEVC Compressed Domains for Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/831d69d84f2b2322dc349e2dd1cc98db3145fef7\",\"venue\":\"2019 8th European Workshop on Visual Information Processing (EUVIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66697353\",\"name\":\"Suvash Sharma\"},{\"authorId\":\"50689828\",\"name\":\"C. Hudson\"},{\"authorId\":\"144601570\",\"name\":\"Daniel W. Carruth\"},{\"authorId\":\"9037806\",\"name\":\"Matthew Doude\"},{\"authorId\":\"145672842\",\"name\":\"J. Ball\"},{\"authorId\":\"144411033\",\"name\":\"B. Tang\"},{\"authorId\":\"2514342\",\"name\":\"C. Goodin\"},{\"authorId\":\"1831201\",\"name\":\"Lalitha Dabbiru\"}],\"doi\":\"10.1117/12.2557928\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a3242eb9c298b0fcc08e8dce28fdd6546fe462\",\"title\":\"Performance analysis of semantic segmentation algorithms trained with JPEG compressed datasets\",\"url\":\"https://www.semanticscholar.org/paper/10a3242eb9c298b0fcc08e8dce28fdd6546fe462\",\"venue\":\"Defense + Commercial Sensing\",\"year\":2020},{\"arxivId\":\"2006.05732\",\"authors\":[{\"authorId\":\"103102295\",\"name\":\"Benjamin Deguerre\"},{\"authorId\":\"1712446\",\"name\":\"Cl\\u00e9ment Chatelain\"},{\"authorId\":\"2378576\",\"name\":\"G. Gasso\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"623a8a93e5a76ef7873210ac78a093d2441c6326\",\"title\":\"Object Detection in the DCT Domain: is Luminance the Solution?\",\"url\":\"https://www.semanticscholar.org/paper/623a8a93e5a76ef7873210ac78a093d2441c6326\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.07742\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":\"10.1007/978-3-030-11018-5_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e4aac6f2dddf0f068f664b666a21a304275ebe0c\",\"title\":\"Fast Semantic Segmentation on Video Using Block Motion-Based Feature Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e4aac6f2dddf0f068f664b666a21a304275ebe0c\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1812.02817\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"2252963\",\"name\":\"Xinyu Li\"},{\"authorId\":\"3302978\",\"name\":\"Kaixiang Huang\"},{\"authorId\":\"7707929\",\"name\":\"Yehan Wang\"},{\"authorId\":\"51231992\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"144555425\",\"name\":\"Ivan Marsic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"556ca2389246b0a848b578dc824b930e1337a4bc\",\"title\":\"Tri-axial Self-Attention for Concurrent Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/556ca2389246b0a848b578dc824b930e1337a4bc\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":\"3403509\",\"name\":\"Y. Lu\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/MMSP.2019.8901826\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a2f484e9db5cd7d2821845e15f19c9b07c36f9f4\",\"title\":\"Semantic Segmentation in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/a2f484e9db5cd7d2821845e15f19c9b07c36f9f4\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2005.01344\",\"authors\":[{\"authorId\":\"1508389232\",\"name\":\"Junyi Feng\"},{\"authorId\":\"47319889\",\"name\":\"Songyuan Li\"},{\"authorId\":\"1596827299\",\"name\":\"Yifeng Chen\"},{\"authorId\":\"50187585\",\"name\":\"Fuxian Huang\"},{\"authorId\":\"10250973\",\"name\":\"Jiabao Cui\"},{\"authorId\":\"92384987\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b3438f35ab6ed712b97ebec534c2c7781524daf\",\"title\":\"How to Train Your Dragon: Tamed Warping Network for Semantic Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9b3438f35ab6ed712b97ebec534c2c7781524daf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152511353\",\"name\":\"S. Abirami\"},{\"authorId\":\"145737021\",\"name\":\"G. Kousalya\"},{\"authorId\":\"2995706\",\"name\":\"P. Balakrishnan\"}],\"doi\":\"10.4018/978-1-7998-3069-6.ch014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cf01f00f0c174b1c0957c9999ffabc33a798ce0\",\"title\":\"Activity Recognition System Through Deep Learning Analysis as an Early Biomarker of ASD Characteristics\",\"url\":\"https://www.semanticscholar.org/paper/0cf01f00f0c174b1c0957c9999ffabc33a798ce0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07848\",\"authors\":[{\"authorId\":\"80447592\",\"name\":\"Yunzhong Hou\"},{\"authorId\":\"144436089\",\"name\":\"L. Zheng\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/cvpr42600.2020.01013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94889c780749b6c86a7be8defbb1fc4e915ccbd4\",\"title\":\"Learning to Structure an Image With Few Colors\",\"url\":\"https://www.semanticscholar.org/paper/94889c780749b6c86a7be8defbb1fc4e915ccbd4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1810.04047\",\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"d94395882da6da17cee0a6ea6f1058314f091f05\",\"title\":\"Inter-BMV: Interpolation with Block Motion Vectors for Fast Semantic Segmentation on Video\",\"url\":\"https://www.semanticscholar.org/paper/d94395882da6da17cee0a6ea6f1058314f091f05\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"},{\"authorId\":\"113011036\",\"name\":\"Kun-Hsuan Wu\"}],\"doi\":\"10.1109/ICASSP.2019.8682450\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"title\":\"Multi-teacher Knowledge Distillation for Compressed Video Action Recognition on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740612\",\"name\":\"C. Wu\"},{\"authorId\":\"50171534\",\"name\":\"Xiaojun Wu\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/ICCVW.2019.00216\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"title\":\"Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2023715016\",\"name\":\"Lukas Bommes\"},{\"authorId\":\"82230848\",\"name\":\"X. Lin\"},{\"authorId\":\"6042827\",\"name\":\"Jun-Hong Zhou\"}],\"doi\":\"10.1109/ICIEA48937.2020.9248145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6de4d23125f436ef678359fbb1fa25a4459a1deb\",\"title\":\"MVmed: Fast Multi-Object Tracking in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/6de4d23125f436ef678359fbb1fa25a4459a1deb\",\"venue\":\"2020 15th IEEE Conference on Industrial Electronics and Applications (ICIEA)\",\"year\":2020},{\"arxivId\":\"2012.10283\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"title\":\"Temporal Bilinear Encoding Network of Audio-Visual Features at Low Sampling Rates\",\"url\":\"https://www.semanticscholar.org/paper/eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143622755\",\"name\":\"W. Yuan\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"},{\"authorId\":null,\"name\":\"Hao Li\"},{\"authorId\":\"47073793\",\"name\":\"Chunxiang Wang\"},{\"authorId\":\"144461644\",\"name\":\"Bing Wang\"}],\"doi\":\"10.1049/TRIT.2018.1025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3310ab12dc5ca83cab1b2aa809bb587c33e2431c\",\"title\":\"End-to-end learning for high-precision lane keeping via multi-state model\",\"url\":\"https://www.semanticscholar.org/paper/3310ab12dc5ca83cab1b2aa809bb587c33e2431c\",\"venue\":\"CAAI Trans. Intell. Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40896248\",\"name\":\"S. Jain\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49b911544ebfca12bed8cbf09b4f48679a8a8ae2\",\"title\":\"Efficient Inference on Video, In Real-Time and At Scale\",\"url\":\"https://www.semanticscholar.org/paper/49b911544ebfca12bed8cbf09b4f48679a8a8ae2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2012.13726\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00017\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"title\":\"Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":\"2003.13260\",\"authors\":[{\"authorId\":\"1508389232\",\"name\":\"Junyi Feng\"},{\"authorId\":\"47319889\",\"name\":\"Songyuan Li\"},{\"authorId\":\"92384987\",\"name\":\"X. Li\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"}],\"doi\":\"10.1109/TPAMI.2020.3024646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f86bfe5174aa24a33087a4456b1a9734ffb68f8c\",\"title\":\"TapLab: A Fast Framework for Semantic Video Segmentation Tapping into Compressed-Domain Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/f86bfe5174aa24a33087a4456b1a9734ffb68f8c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1905.13209\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"title\":\"AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures\",\"url\":\"https://www.semanticscholar.org/paper/a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1908.10155\",\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"145525059\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"title\":\"Mobile Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16c8f1d316e0235d20a60cae8fb9f5f83e35574c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.08206\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"1420126809\",\"name\":\"Haim Barad\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"},{\"authorId\":\"3243137\",\"name\":\"Amit Bleiweiss\"}],\"doi\":\"10.1109/CVPRW50498.2020.00350\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da2934c24a9de690ff399736711b754cc10ae1ec\",\"title\":\"Mimic The Raw Domain: Accelerating Action Recognition in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/da2934c24a9de690ff399736711b754cc10ae1ec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"1980683\",\"name\":\"Shuchin Aeron\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8c001c449cec20221ba3daa76536a124cddc0e5\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport /Author=Cherian, Anoop; Aeron, Shuchin /CreationDate=July 3, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8c001c449cec20221ba3daa76536a124cddc0e5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.07212\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1007/978-3-030-01261-8_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"title\":\"Cross-Modal and Hierarchical Modeling of Video and Text\",\"url\":\"https://www.semanticscholar.org/paper/ea133d0067740902bc26a082c842d9e7ba48ecf6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50562323\",\"name\":\"J. Zhang\"},{\"authorId\":\"46335268\",\"name\":\"D. Zhang\"},{\"authorId\":\"2028614323\",\"name\":\"Xiaohui Xu\"},{\"authorId\":\"2028616174\",\"name\":\"Fucheng Jia\"},{\"authorId\":\"3180228\",\"name\":\"Yunxin Liu\"},{\"authorId\":\"8016688\",\"name\":\"X. Liu\"},{\"authorId\":\"145847892\",\"name\":\"Ju Ren\"},{\"authorId\":\"1754576\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1145/3384419.3430726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dd6b5fa47441cae9cb0da5fab045b7610084e82\",\"title\":\"MobiPose: real-time multi-person pose estimation on mobile devices\",\"url\":\"https://www.semanticscholar.org/paper/3dd6b5fa47441cae9cb0da5fab045b7610084e82\",\"venue\":\"SenSys\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.11799\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"26485115\",\"name\":\"Lianqiang Zhou\"}],\"doi\":\"10.24963/ijcai.2019/130\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37252f8cd1324a972131fc6a92f778835ba2fac3\",\"title\":\"Hallucinating Optical Flow Features for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/37252f8cd1324a972131fc6a92f778835ba2fac3\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1811.11057\",\"authors\":[{\"authorId\":\"49183840\",\"name\":\"S. Wang\"},{\"authorId\":\"46386380\",\"name\":\"Hongchao Lu\"},{\"authorId\":\"144690532\",\"name\":\"P. Dmitriev\"},{\"authorId\":\"144165738\",\"name\":\"Z. Deng\"}],\"doi\":\"10.1109/ICCV.2019.00720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6be40f3f375066e02ab53a7967b8d651a680097d\",\"title\":\"Fast Object Detection in Compressed Video\",\"url\":\"https://www.semanticscholar.org/paper/6be40f3f375066e02ab53a7967b8d651a680097d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46528640\",\"name\":\"H. T. Binh\"},{\"authorId\":\"9283769\",\"name\":\"Ma Thi Chau\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"9349062\",\"name\":\"B. Duy\"}],\"doi\":\"10.1109/ICCCE.2018.8539313\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3901f177642912be3fd132807a1e7d16796d1011\",\"title\":\"Selecting active frames for action recognition with vote fusion method\",\"url\":\"https://www.semanticscholar.org/paper/3901f177642912be3fd132807a1e7d16796d1011\",\"venue\":\"2018 7th International Conference on Computer and Communication Engineering (ICCCE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47319654\",\"name\":\"S. Li\"},{\"authorId\":\"1741668\",\"name\":\"Zhicheng Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/VCIP47243.2019.8965878\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"title\":\"A Spatio-temporal Hybrid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eced654a4b8467a6b52194af8e4d83bcbe1730cb\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":\"2011.13273\",\"authors\":[{\"authorId\":\"143626433\",\"name\":\"Tingtian Li\"},{\"authorId\":\"21072153\",\"name\":\"Zixun Sun\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3394171.3416280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e6a67a46883eb1e975ad52c30cd20f0668f5593\",\"title\":\"Group-Skeleton-Based Human Action Recognition in Complex Events\",\"url\":\"https://www.semanticscholar.org/paper/8e6a67a46883eb1e975ad52c30cd20f0668f5593\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":4518974,\"doi\":\"10.1109/CVPR.2018.00631\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":20,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695601\",\"name\":\"Vadim Kantorov\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2014.332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"482f7471c708f371cbd7658aa4a48187dc830e17\",\"title\":\"Efficient Feature Extraction, Encoding, and Classification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482f7471c708f371cbd7658aa4a48187dc830e17\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1612.06371\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2017.599\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"title\":\"Asynchronous Temporal Fields for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61c8ec6e26df76c8f0a174740f86510a786c93b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"},{\"authorId\":\"3083483\",\"name\":\"D. Nist\\u00e9r\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"},{\"authorId\":\"145517633\",\"name\":\"A. Akbarzadeh\"},{\"authorId\":\"1706145\",\"name\":\"Philippos Mordohai\"},{\"authorId\":\"2628245\",\"name\":\"Brian Clipp\"},{\"authorId\":\"35242421\",\"name\":\"C. Engels\"},{\"authorId\":\"144866265\",\"name\":\"David Gallup\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"},{\"authorId\":\"143708084\",\"name\":\"P. Merrell\"},{\"authorId\":\"114701302\",\"name\":\"C. Salmi\"},{\"authorId\":\"1757937\",\"name\":\"Sudipta N. Sinha\"},{\"authorId\":\"3189884\",\"name\":\"B. Talton\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"},{\"authorId\":\"1777434\",\"name\":\"Q. Yang\"},{\"authorId\":\"3086037\",\"name\":\"Henrik Stew\\u00e9nius\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"},{\"authorId\":\"145715427\",\"name\":\"G. Welch\"},{\"authorId\":\"145681799\",\"name\":\"H. Towles\"}],\"doi\":\"10.1007/s11263-007-0086-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a90553400bf65567a6712b2b7e5303af5ff1aae\",\"title\":\"Detailed Real-Time Urban 3D Reconstruction from Video\",\"url\":\"https://www.semanticscholar.org/paper/8a90553400bf65567a6712b2b7e5303af5ff1aae\",\"venue\":\"International Journal of Computer Vision\",\"year\":2007},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B U T\\u00f6reyin\"},{\"authorId\":null,\"name\":\"A E Cetin\"},{\"authorId\":null,\"name\":\"A Aksay\"},{\"authorId\":null,\"name\":\"M B Akhan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Moving object detection in wavelet compressed video. Signal Processing: Image Communication\",\"url\":\"\",\"venue\":\"\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yue-Hei Ng\"},{\"authorId\":null,\"name\":\"M. Hausknecht\"},{\"authorId\":null,\"name\":\"S. Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"O. Vinyals\"},{\"authorId\":null,\"name\":\"R. Monga\"},{\"authorId\":null,\"name\":\"G. Toderici\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Spatiotempo - ral pyramid network for video action recognition Rapid scene analysis on compressed video\",\"url\":\"\",\"venue\":\"IEEE Transactions on circuits and systems for video technology\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C Zach\"},{\"authorId\":null,\"name\":\"T Pock\"},{\"authorId\":null,\"name\":\"H Bischof\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A duality based approach for realtime tv-l 1 optical flow. Pattern Recognition\",\"url\":\"\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2972680\",\"name\":\"D. L. Gall\"}],\"doi\":\"10.1145/103085.103090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bafe1e3aba293f978ec0f44599d7d62eca9206c\",\"title\":\"MPEG: a video compression standard for multimedia applications\",\"url\":\"https://www.semanticscholar.org/paper/6bafe1e3aba293f978ec0f44599d7d62eca9206c\",\"venue\":\"CACM\",\"year\":1991},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1611.05216\",\"authors\":[{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"144424248\",\"name\":\"Wei Zeng\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/ICCV.2017.84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"title\":\"Learning Long-Term Dependencies for Action Recognition with a Biologically-Inspired Deep Network\",\"url\":\"https://www.semanticscholar.org/paper/d145edb79ec035d6cf3f50714429f51fb18f0a2f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L V D Maaten\"},{\"authorId\":null,\"name\":\"G Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing data using t-SNE. JMLR\",\"url\":\"\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1903.01038\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2017.226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1f66207713871da193af24e19a5d8855bfe7f5a\",\"title\":\"Spatiotemporal Pyramid Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1f66207713871da193af24e19a5d8855bfe7f5a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692339\",\"name\":\"B. Yeo\"},{\"authorId\":\"1687498\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/76.475896\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04142ae104d552672620c88cb9cdbcee33ceb7bc\",\"title\":\"Rapid scene analysis on compressed video\",\"url\":\"https://www.semanticscholar.org/paper/04142ae104d552672620c88cb9cdbcee33ceb7bc\",\"venue\":\"IEEE Trans. Circuits Syst. Video Technol.\",\"year\":1995},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51981561\",\"name\":\"O. Sukmarg\"},{\"authorId\":\"144593419\",\"name\":\"K. Rao\"}],\"doi\":\"10.1109/TENCON.2000.892290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a3ebd005b0ce05c6398ae2f6daf8b6240bd12b3\",\"title\":\"Fast object detection and segmentation in MPEG compressed domain\",\"url\":\"https://www.semanticscholar.org/paper/1a3ebd005b0ce05c6398ae2f6daf8b6240bd12b3\",\"venue\":\"2000 TENCON Proceedings. Intelligent Systems and Technologies for the New Millennium (Cat. No.00CH37119)\",\"year\":2000},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145292956\",\"name\":\"I. Richardson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a78d0e8efbd6349c6cc4d46bf5a505e9c7df544\",\"title\":\"Video Codec Design: Developing Image and Video Compression Systems\",\"url\":\"https://www.semanticscholar.org/paper/8a78d0e8efbd6349c6cc4d46bf5a505e9c7df544\",\"venue\":\"\",\"year\":2002},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1506.04214\",\"authors\":[{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"2192200\",\"name\":\"Zhourong Chen\"},{\"authorId\":\"49528584\",\"name\":\"Hao Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"145771919\",\"name\":\"W. Wong\"},{\"authorId\":\"2183294\",\"name\":\"Wang-chun Woo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"title\":\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021714\",\"name\":\"B. U. T\\u00f6reyin\"},{\"authorId\":\"144807321\",\"name\":\"A. \\u00c7etin\"},{\"authorId\":\"2218100\",\"name\":\"A. Aksay\"},{\"authorId\":\"145847947\",\"name\":\"M. Akhan\"}],\"doi\":\"10.1016/j.image.2004.12.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a57909c9cb6abfeaeb87b369c3b36bb9f33179d\",\"title\":\"Moving object detection in wavelet compressed video\",\"url\":\"https://www.semanticscholar.org/paper/0a57909c9cb6abfeaeb87b369c3b36bb9f33179d\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2005},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1601.06759\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"41f1d50c85d3180476c4c7b3eea121278b0d8474\",\"title\":\"Pixel Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/41f1d50c85d3180476c4c7b3eea121278b0d8474\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1609.08675\",\"authors\":[{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"144317839\",\"name\":\"Nisarg Kothari\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"title\":\"YouTube-8M: A Large-Scale Video Classification Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017}],\"title\":\"Compressed Video Action Recognition\",\"topics\":[{\"topic\":\"Data compression\",\"topicId\":\"41454\",\"url\":\"https://www.semanticscholar.org/topic/41454\"},{\"topic\":\"Information design\",\"topicId\":\"218478\",\"url\":\"https://www.semanticscholar.org/topic/218478\"},{\"topic\":\"H.264/MPEG-4 AVC\",\"topicId\":\"26410\",\"url\":\"https://www.semanticscholar.org/topic/26410\"},{\"topic\":\"Streaming media\",\"topicId\":\"1357\",\"url\":\"https://www.semanticscholar.org/topic/1357\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Uncompressed video\",\"topicId\":\"649403\",\"url\":\"https://www.semanticscholar.org/topic/649403\"},{\"topic\":\"High Efficiency Video Coding\",\"topicId\":\"1798\",\"url\":\"https://www.semanticscholar.org/topic/1798\"}],\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"