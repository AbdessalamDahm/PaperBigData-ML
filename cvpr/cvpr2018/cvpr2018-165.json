"{\"abstract\":\"Visual signals in a video can be divided into content and motion. While content specifies which objects are in the video, motion describes their dynamics. Based on this prior, we propose the Motion and Content decomposed Generative Adversarial Network (MoCoGAN) framework for video generation. The proposed framework generates a video by mapping a sequence of random vectors to a sequence of video frames. Each random vector consists of a content part and a motion part. While the content part is kept fixed, the motion part is realized as a stochastic process. To learn motion and content decomposition in an unsupervised manner, we introduce a novel adversarial learning scheme utilizing both image and video discriminators. Extensive experimental results on several challenging datasets with qualitative and quantitative comparison to the state-of-the-art approaches, verify effectiveness of the proposed framework. In addition, we show that MoCoGAN allows one to generate videos with same content but different motion as well as videos with different content and same motion. Our code is available at https://github.com/sergeytulyakov/mocogan.\",\"arxivId\":\"1707.04993\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\",\"url\":\"https://www.semanticscholar.org/author/145582202\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\",\"url\":\"https://www.semanticscholar.org/author/39793900\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\",\"url\":\"https://www.semanticscholar.org/author/144434220\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\",\"url\":\"https://www.semanticscholar.org/author/1690538\"}],\"citationVelocity\":129,\"citations\":[{\"arxivId\":\"1709.07592\",\"authors\":[{\"authorId\":\"39272336\",\"name\":\"W. Xiong\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2018.00251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87a818723a2ada66a1193baf17b0383d9766781b\",\"title\":\"Learning to Generate Time-Lapse Videos Using Multi-stage Dynamic Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/87a818723a2ada66a1193baf17b0383d9766781b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92905200\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ACCESS.2020.2995383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaa0b603ce97b8c4cbd78a3a28e30c406bfd0b62\",\"title\":\"Pose-Forecasting Aided Human Video Prediction With Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/aaa0b603ce97b8c4cbd78a3a28e30c406bfd0b62\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.04776\",\"authors\":[{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"145194966\",\"name\":\"Chao Xu\"},{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1490938675\",\"name\":\"Xia Wu\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"},{\"authorId\":\"122376816\",\"name\":\"Yunliang Jiang\"}],\"doi\":\"10.1007/978-3-030-58558-7_18\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c1847cbb4064ca05593f7b408783e9f183953488\",\"title\":\"DTVNet: Dynamic Time-lapse Video Generation via Single Still Image\",\"url\":\"https://www.semanticscholar.org/paper/c1847cbb4064ca05593f7b408783e9f183953488\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1804.06300\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"2429210\",\"name\":\"Zhifeng Gao\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d718941506d2adabc4792cb13d49e6336957e52e\",\"title\":\"PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning\",\"url\":\"https://www.semanticscholar.org/paper/d718941506d2adabc4792cb13d49e6336957e52e\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31123128\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2848440\",\"name\":\"Meshia C\\u00e9dric Oveneke\"},{\"authorId\":\"48219791\",\"name\":\"Dongmei Jiang\"},{\"authorId\":\"48077408\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1007/s11042-018-6952-y\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6880855cfe631cbd2cbe2df98ff99ef9ddf77c0e\",\"title\":\"A video prediction approach for animating single face image\",\"url\":\"https://www.semanticscholar.org/paper/6880855cfe631cbd2cbe2df98ff99ef9ddf77c0e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1808.07371\",\"authors\":[{\"authorId\":\"1715365\",\"name\":\"C. Chan\"},{\"authorId\":\"2361255\",\"name\":\"Shiry Ginosar\"},{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2019.00603\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"title\":\"Everybody Dance Now\",\"url\":\"https://www.semanticscholar.org/paper/e3a10973ee4e3be5fc53bee96e4d8e56469e432a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151482822\",\"name\":\"Sailun Xu\"},{\"authorId\":\"47118922\",\"name\":\"Xinze Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5aeccdefc98a451d076a8a3f537a151d4bd6b677\",\"title\":\"Video Content Swapping Using GAN\",\"url\":\"https://www.semanticscholar.org/paper/5aeccdefc98a451d076a8a3f537a151d4bd6b677\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145292840\",\"name\":\"Mingwei Zhu\"},{\"authorId\":\"145095208\",\"name\":\"Min Zhao\"},{\"authorId\":\"144563358\",\"name\":\"Min Yao\"},{\"authorId\":\"9202170\",\"name\":\"Ruipeng Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddc8a6272b971bfbfb3a127edce8b99ac04a122c\",\"title\":\"Generative Adversarial Networks For Data Scarcity Industrial Positron Images With Attention\",\"url\":\"https://www.semanticscholar.org/paper/ddc8a6272b971bfbfb3a127edce8b99ac04a122c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50819441\",\"name\":\"R. Qiu\"},{\"authorId\":\"72863851\",\"name\":\"Danilo Vasconcellos Vargas\"},{\"authorId\":\"1485772943\",\"name\":\"Kouich Sakurai\"}],\"doi\":\"10.1109/CANDARW.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"151cd66d9fe95b13465084d1407824260ec8e057\",\"title\":\"Frame Difference Generative Adversarial Networks: Clearer Contour Video Generating\",\"url\":\"https://www.semanticscholar.org/paper/151cd66d9fe95b13465084d1407824260ec8e057\",\"venue\":\"2019 Seventh International Symposium on Computing and Networking Workshops (CANDARW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TAI.2020.3031581\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8ad1580246c895760198888ff7c0ee0237114f7\",\"title\":\"Self-Supervised Pose Adaptation for Cross-Domain Image Animation\",\"url\":\"https://www.semanticscholar.org/paper/f8ad1580246c895760198888ff7c0ee0237114f7\",\"venue\":\"IEEE Transactions on Artificial Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41015732\",\"name\":\"Fu-En Yang\"},{\"authorId\":\"121393599\",\"name\":\"Jing-Cheng Chang\"},{\"authorId\":\"2816067\",\"name\":\"Chung-Chi Tsai\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TIP.2019.2952707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a099396434872ac29d431a767ba88e3a4d74ad93\",\"title\":\"A Multi-Domain and Multi-Modal Representation Disentangler for Cross-Domain Image Manipulation and Classification\",\"url\":\"https://www.semanticscholar.org/paper/a099396434872ac29d431a767ba88e3a4d74ad93\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2009.11763\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1519286448\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88310a0fce6890a8be557790a5ca3cbc0efebf2e\",\"title\":\"Unsupervised Transfer Learning for Spatiotemporal Predictive Networks\",\"url\":\"https://www.semanticscholar.org/paper/88310a0fce6890a8be557790a5ca3cbc0efebf2e\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1912.02401\",\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-58610-2_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"title\":\"Generating Videos of Zero-Shot Compositions of Actions and Objects\",\"url\":\"https://www.semanticscholar.org/paper/4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1109/FG.2019.8756560\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c482665657ead74aee5513809ecfd2c55242ebb1\",\"title\":\"The Many Variations of Emotion\",\"url\":\"https://www.semanticscholar.org/paper/c482665657ead74aee5513809ecfd2c55242ebb1\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"1904.05408\",\"authors\":[{\"authorId\":\"1839268\",\"name\":\"J. Wu\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"32610154\",\"name\":\"D. Acharya\"},{\"authorId\":\"50135099\",\"name\":\"W. Li\"},{\"authorId\":\"30691454\",\"name\":\"Janine L Thoma\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2019.00383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d20253a2c87c8c6a30441051a373d6ce269fb83\",\"title\":\"Sliced Wasserstein Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/2d20253a2c87c8c6a30441051a373d6ce269fb83\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.03086\",\"authors\":[{\"authorId\":\"1381330664\",\"name\":\"Vajira Thambawita\"},{\"authorId\":\"1398626299\",\"name\":\"Paal Halvorsen\"},{\"authorId\":\"33095617\",\"name\":\"H. Hammer\"},{\"authorId\":\"10395256\",\"name\":\"M. Riegler\"},{\"authorId\":\"144004453\",\"name\":\"T. B. Haugen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"038876de38c7b1c90ecf3d789aa63352968e1759\",\"title\":\"Stacked dense optical flows and dropout layers to predict sperm motility and morphology\",\"url\":\"https://www.semanticscholar.org/paper/038876de38c7b1c90ecf3d789aa63352968e1759\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":\"1808.05174\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1007/978-3-030-01228-1_8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ad3c383a79e85159098112127300dfd08c21319\",\"title\":\"Recycle-GAN: Unsupervised Video Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/8ad3c383a79e85159098112127300dfd08c21319\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145582147\",\"name\":\"Rodrigo de Bem\"},{\"authorId\":\"144317747\",\"name\":\"A. Ghosh\"},{\"authorId\":\"144722114\",\"name\":\"Thalaiyasingam Ajanthan\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1504e2c186611e3b79c1942cb767aac7cf46e965\",\"title\":\"DGPose: Disentangled Semi-supervised Deep Generative Models for Human Body Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1504e2c186611e3b79c1942cb767aac7cf46e965\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.10240\",\"authors\":[{\"authorId\":\"2469811\",\"name\":\"Yunpeng Li\"},{\"authorId\":\"3181733\",\"name\":\"Dominik Roblek\"},{\"authorId\":\"1749128\",\"name\":\"M. Tagliasacchi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"063700c45e10362f5642c08849348c41ee5b08a3\",\"title\":\"From Here to There: Video Inbetweening Using Direct 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/063700c45e10362f5642c08849348c41ee5b08a3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.00475\",\"authors\":[{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"},{\"authorId\":\"46917346\",\"name\":\"Amy Zhao\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/ICCV.2019.00026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"374162524b3fffc1f926c05c5539f01a5d542014\",\"title\":\"Visual Deprojection: Probabilistic Recovery of Collapsed Dimensions\",\"url\":\"https://www.semanticscholar.org/paper/374162524b3fffc1f926c05c5539f01a5d542014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"153142893\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCV.2019.00767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"title\":\"View-LSTM: Novel-View Video Synthesis Through View Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.09154\",\"authors\":[{\"authorId\":\"3468426\",\"name\":\"Athanasios Vlontzos\"},{\"authorId\":\"10757438\",\"name\":\"Henrique Bergallo Rocha\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"2015193\",\"name\":\"Bernhard Kainz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef9f35af432109c1f9bb5f428ea13d65ae1aeb94\",\"title\":\"Causal Future Prediction in a Minkowski Space-Time\",\"url\":\"https://www.semanticscholar.org/paper/ef9f35af432109c1f9bb5f428ea13d65ae1aeb94\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0501b8a99270a20c7536ed2f6df6569413810f6d\",\"title\":\"Apprentissage neuronal profond pour l'analyse de contenus multimodaux et temporels. (Deep learning for multimodal and temporal contents analysis)\",\"url\":\"https://www.semanticscholar.org/paper/0501b8a99270a20c7536ed2f6df6569413810f6d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9638825\",\"name\":\"N. Ronquillo\"},{\"authorId\":\"1745184\",\"name\":\"Josh Harguess\"}],\"doi\":\"10.1109/AIPR.2018.8707431\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f23d889dce3453da1795a5463869efc76ae0507f\",\"title\":\"On Evaluating Video-based Generative Adversarial Networks (GANs)\",\"url\":\"https://www.semanticscholar.org/paper/f23d889dce3453da1795a5463869efc76ae0507f\",\"venue\":\"2018 IEEE Applied Imagery Pattern Recognition Workshop (AIPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1523761688\",\"name\":\"Aziz Siyaev\"},{\"authorId\":\"144089347\",\"name\":\"G. Jo\"}],\"doi\":\"10.1007/978-3-030-41964-6_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ef69c67e3129526ad616985a38fbd51f360d218\",\"title\":\"GOHAG: GANs Orchestration for Human Actions Generation\",\"url\":\"https://www.semanticscholar.org/paper/2ef69c67e3129526ad616985a38fbd51f360d218\",\"venue\":\"ACIIDS\",\"year\":2020},{\"arxivId\":\"1911.07806\",\"authors\":[{\"authorId\":\"11519650\",\"name\":\"Yuge Shi\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1007/978-3-030-01249-6_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3200539538eca54a85223bf0ec4f3ed132d0493\",\"title\":\"Action Anticipation with RBF Kernelized Feature Mapping RNN\",\"url\":\"https://www.semanticscholar.org/paper/b3200539538eca54a85223bf0ec4f3ed132d0493\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959025244\",\"name\":\"Xuan-Bac Nguyen\"},{\"authorId\":\"98196896\",\"name\":\"Guee Sang Lee\"},{\"authorId\":\"153274504\",\"name\":\"Soo Hyung Kim\"},{\"authorId\":\"1736218\",\"name\":\"H. J. Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3021469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edaa65d8bd38b7f5e99442f9a120489a1a16370c\",\"title\":\"Self-Supervised Learning Based on Spatial Awareness for Medical Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/edaa65d8bd38b7f5e99442f9a120489a1a16370c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29972240\",\"name\":\"Z. Hu\"},{\"authorId\":\"2000928\",\"name\":\"Turki Turki\"},{\"authorId\":\"152924797\",\"name\":\"J. T. Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2982750\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a55e120636fe8d656fb54879c62eb57564537665\",\"title\":\"Generative Adversarial Networks for Stochastic Video Prediction With Action Control\",\"url\":\"https://www.semanticscholar.org/paper/a55e120636fe8d656fb54879c62eb57564537665\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145552467\",\"name\":\"A. Kuznetsov\"},{\"authorId\":\"34701024\",\"name\":\"Milos Hasan\"},{\"authorId\":\"2615346\",\"name\":\"Zexiang Xu\"},{\"authorId\":\"2162776\",\"name\":\"L. Yan\"},{\"authorId\":\"35813794\",\"name\":\"B. Walter\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"},{\"authorId\":\"2593798\",\"name\":\"Steve Marschner\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1145/3355089.3356525\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd9da522b2cf4dbdc307eb519b560eef9658a9f0\",\"title\":\"Learning generative models for rendering specular microgeometry\",\"url\":\"https://www.semanticscholar.org/paper/cd9da522b2cf4dbdc307eb519b560eef9658a9f0\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143624101\",\"name\":\"R. Zhao\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22fcd10806e3dc89f862c55bbbf81edc957f3929\",\"title\":\"An Adversarial Hierarchical Hidden Markov Model for Human Pose Modeling and Generation\",\"url\":\"https://www.semanticscholar.org/paper/22fcd10806e3dc89f862c55bbbf81edc957f3929\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2012.02598\",\"authors\":[{\"authorId\":\"1900527137\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"67084339\",\"name\":\"Jianjin Zhang\"},{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f30c275a34e4b8eaa0059cc9f3843ab0c8d5712\",\"title\":\"Towards Good Practices of U-Net for Traffic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/5f30c275a34e4b8eaa0059cc9f3843ab0c8d5712\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48002920\",\"name\":\"Hongyuan Yu\"},{\"authorId\":\"13557066\",\"name\":\"Y. Huang\"},{\"authorId\":\"150192018\",\"name\":\"Lihong Pi\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1007/978-3-030-31723-2_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c6e9b53df1c21649d21fd1d77765fc20154a3a3\",\"title\":\"Recurrent Deconvolutional Generative Adversarial Networks with Application to Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/9c6e9b53df1c21649d21fd1d77765fc20154a3a3\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66933647\",\"name\":\"Debapriya Hazra\"},{\"authorId\":\"1730636\",\"name\":\"Yungcheol Byun\"}],\"doi\":\"10.3390/electronics9081312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c03f51a33b2ffe479f2995482143207f889f2c9b\",\"title\":\"Upsampling Real-Time, Low-Resolution CCTV Videos Using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c03f51a33b2ffe479f2995482143207f889f2c9b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19902610\",\"name\":\"Zhihang Hu\"},{\"authorId\":\"2487504\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-030-56150-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f6a63e12030d6b126acd5bf0bbdca274e75dd60\",\"title\":\"Generative Adversarial Networks for Video Prediction with Action Control\",\"url\":\"https://www.semanticscholar.org/paper/0f6a63e12030d6b126acd5bf0bbdca274e75dd60\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1902.08900\",\"authors\":[{\"authorId\":\"21697786\",\"name\":\"Zhenglin Geng\"},{\"authorId\":\"36005450\",\"name\":\"Chen Cao\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"}],\"doi\":\"10.1109/CVPR.2019.01005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3ba039764e38dd4fac37a091867c4c29f5f7855\",\"title\":\"3D Guided Fine-Grained Face Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/d3ba039764e38dd4fac37a091867c4c29f5f7855\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2040100376\",\"name\":\"Aiwen Xv\"},{\"authorId\":\"1574329003\",\"name\":\"Hui Zhang\"},{\"authorId\":\"153171668\",\"name\":\"Jian Wu\"}],\"doi\":\"10.1145/3434581.3434697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9e0e1edd8f066a38cbd3aec9f801a13853feaa9\",\"title\":\"Research on Image Generation Based on Guide Map\",\"url\":\"https://www.semanticscholar.org/paper/a9e0e1edd8f066a38cbd3aec9f801a13853feaa9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.12003\",\"authors\":[{\"authorId\":\"50876245\",\"name\":\"Chaoyou Fu\"},{\"authorId\":\"49995036\",\"name\":\"Y. Hu\"},{\"authorId\":\"144589611\",\"name\":\"Xiang Wu\"},{\"authorId\":\"1736332\",\"name\":\"G. Wang\"},{\"authorId\":\"1737486\",\"name\":\"Q. Zhang\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0a3737381fe393f6d761ddba16c795b31bcdad2\",\"title\":\"High Fidelity Face Manipulation with Extreme Pose and Expression\",\"url\":\"https://www.semanticscholar.org/paper/e0a3737381fe393f6d761ddba16c795b31bcdad2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.04786\",\"authors\":[{\"authorId\":\"115504645\",\"name\":\"Y. Song\"},{\"authorId\":\"145532978\",\"name\":\"Jingwen Zhu\"},{\"authorId\":\"49620929\",\"name\":\"Dawei Li\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"144117139\",\"name\":\"Hairong Qi\"}],\"doi\":\"10.24963/ijcai.2019/129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c223baccf679fc212dd4d9ecbebf30b7a8616af\",\"title\":\"Talking Face Generation by Conditional Recurrent Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/7c223baccf679fc212dd4d9ecbebf30b7a8616af\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1903.04480\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":null,\"name\":\"Chengyu Wang\"},{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00385\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f66d531439f5847afa7b31f49db87a44b788690\",\"title\":\"Video Generation From Single Semantic Label Map\",\"url\":\"https://www.semanticscholar.org/paper/2f66d531439f5847afa7b31f49db87a44b788690\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.10283\",\"authors\":[{\"authorId\":\"47397111\",\"name\":\"Chia-Hung Huang\"},{\"authorId\":\"145039745\",\"name\":\"Hang Yin\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"Chi-Keung Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80f86a11cf5995081d8678c53b37f3c9024f16d9\",\"title\":\"StableNet: Semi-Online, Multi-Scale Deep Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/80f86a11cf5995081d8678c53b37f3c9024f16d9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.09646\",\"authors\":[{\"authorId\":\"1581479411\",\"name\":\"Abhinav Sagar\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b367a582b8921997bbbea433bf99c4671568b44c\",\"title\":\"HRVGAN: High Resolution Video Generation using Spatio-Temporal GAN\",\"url\":\"https://www.semanticscholar.org/paper/b367a582b8921997bbbea433bf99c4671568b44c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49107901\",\"name\":\"Albert Pumarola\"},{\"authorId\":\"144003484\",\"name\":\"A. Agudo\"},{\"authorId\":\"145358414\",\"name\":\"A. Mart\\u00ednez\"},{\"authorId\":\"1791054\",\"name\":\"A. Sanfeliu\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"}],\"doi\":\"10.1007/s11263-019-01210-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9c41d7cd81c3af37ac68a4f348122aead4f53962\",\"title\":\"GANimation: One-Shot Anatomically Consistent Facial Animation\",\"url\":\"https://www.semanticscholar.org/paper/9c41d7cd81c3af37ac68a4f348122aead4f53962\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1711.05914\",\"authors\":[{\"authorId\":\"5782992\",\"name\":\"Yongjun Hong\"},{\"authorId\":\"27642187\",\"name\":\"Uiwon Hwang\"},{\"authorId\":\"8351553\",\"name\":\"Jaeyoon Yoo\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":\"10.1145/3301282\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1fabec40714e78012d4edfcd79204162de6d461f\",\"title\":\"How Generative Adversarial Networks and Their Variants Work\",\"url\":\"https://www.semanticscholar.org/paper/1fabec40714e78012d4edfcd79204162de6d461f\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1588352298\",\"name\":\"Xianggang Yu\"},{\"authorId\":\"1491649176\",\"name\":\"Haolin Liu\"},{\"authorId\":\"1491234351\",\"name\":\"Xiaoguang Han\"},{\"authorId\":\"49969637\",\"name\":\"Zhuguo Li\"},{\"authorId\":\"144723535\",\"name\":\"Z. Xiong\"},{\"authorId\":\"144404242\",\"name\":\"Shuguang Cui\"}],\"doi\":\"10.1145/3394171.3414001\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b9f9e10579dc96a540356509d6e529e22535dd6\",\"title\":\"JAFPro: Joint Appearance Fusion and Propagation for Human Video Motion Transfer from Multiple Reference Images\",\"url\":\"https://www.semanticscholar.org/paper/9b9f9e10579dc96a540356509d6e529e22535dd6\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1812.08861\",\"authors\":[{\"authorId\":\"10753214\",\"name\":\"Aliaksandr Siarohin\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2019.00248\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"edce7f037c840b7db2612f47c35ae374c4a80e3a\",\"title\":\"Animating Arbitrary Objects via Deep Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/edce7f037c840b7db2612f47c35ae374c4a80e3a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.05495\",\"authors\":[{\"authorId\":\"2881401\",\"name\":\"Yanchao Yang\"},{\"authorId\":\"1519044563\",\"name\":\"Yutong Chen\"},{\"authorId\":\"1715959\",\"name\":\"Stefano Soatto\"}],\"doi\":\"10.1109/CVPR42600.2020.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d938f5d7c6216c40c42b712e8ba16a466c21e991\",\"title\":\"Learning to Manipulate Individual Objects in an Image\",\"url\":\"https://www.semanticscholar.org/paper/d938f5d7c6216c40c42b712e8ba16a466c21e991\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"},{\"authorId\":\"144742695\",\"name\":\"D. Xu\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2019.2963621\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92027cb7282f2cae56f223ca313150f7e9ce0055\",\"title\":\"Learning How to Smile: Expression Video Generation With Conditional Adversarial Recurrent Nets\",\"url\":\"https://www.semanticscholar.org/paper/92027cb7282f2cae56f223ca313150f7e9ce0055\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1808.06847\",\"authors\":[{\"authorId\":\"3451442\",\"name\":\"Kfir Aberman\"},{\"authorId\":\"5807605\",\"name\":\"M. Shi\"},{\"authorId\":\"1400217664\",\"name\":\"Jing Liao\"},{\"authorId\":\"1684384\",\"name\":\"Dani Lischinski\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"}],\"doi\":\"10.1111/cgf.13632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c14e77fc10f133358903019f45132d694682ab88\",\"title\":\"Deep Video\\u2010Based Performance Cloning\",\"url\":\"https://www.semanticscholar.org/paper/c14e77fc10f133358903019f45132d694682ab88\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"NEOUS ENVIRONMENTS\"},{\"authorId\":null,\"name\":\"\\u00d0ord\\u0304e Miladinovi\\u0107\"},{\"authorId\":\"1682548\",\"name\":\"J. Buhmann\"},{\"authorId\":\"19313401\",\"name\":\"Waleed M. Gondal\"},{\"authorId\":\"144771902\",\"name\":\"S. Bauer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"737a6e529fe5a532575c5e7afed74679a0affa80\",\"title\":\"DISENTANGLED STATE SPACE MODELS: UNSUPER-\",\"url\":\"https://www.semanticscholar.org/paper/737a6e529fe5a532575c5e7afed74679a0affa80\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6287360\",\"name\":\"S. Liu\"},{\"authorId\":\"31902430\",\"name\":\"Chenglong Zeng\"},{\"authorId\":\"10001427\",\"name\":\"H. Fan\"},{\"authorId\":\"145357056\",\"name\":\"Ho-Cheung Ng\"},{\"authorId\":\"147113836\",\"name\":\"Jiuxi Meng\"},{\"authorId\":\"144514893\",\"name\":\"Zhiqiang Que\"},{\"authorId\":\"143825108\",\"name\":\"Xinyu Niu\"},{\"authorId\":\"144708627\",\"name\":\"W. Luk\"}],\"doi\":\"10.1109/FPT.2018.00016\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dfbc0064a799dd0c4767b1fcc3f6aedc4bdae862\",\"title\":\"Memory-Efficient Architecture for Accelerating Generative Networks on FPGA\",\"url\":\"https://www.semanticscholar.org/paper/dfbc0064a799dd0c4767b1fcc3f6aedc4bdae862\",\"venue\":\"2018 International Conference on Field-Programmable Technology (FPT)\",\"year\":2018},{\"arxivId\":\"1909.02749\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"69869231\",\"name\":\"R. Pottorf\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a7ae2b9dbc825407ccf67a5e6c9e2a857766d75\",\"title\":\"Video Interpolation and Prediction with Unsupervised Landmarks\",\"url\":\"https://www.semanticscholar.org/paper/8a7ae2b9dbc825407ccf67a5e6c9e2a857766d75\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153439700\",\"name\":\"Y. Kwon\"},{\"authorId\":\"49360298\",\"name\":\"M. Park\"}],\"doi\":\"10.1109/CVPR.2019.00191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f373bccc69bec811fa93b27d59a560b9e4ed0946\",\"title\":\"Predicting Future Frames Using Retrospective Cycle GAN\",\"url\":\"https://www.semanticscholar.org/paper/f373bccc69bec811fa93b27d59a560b9e4ed0946\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.06628\",\"authors\":[{\"authorId\":\"121544228\",\"name\":\"Z. Li\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"1821761\",\"name\":\"M. Oswald\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbaa5a95aba6cccb7c9885db0329c413f12bbb22\",\"title\":\"Street-view Panoramic Video Synthesis from a Single Satellite Image\",\"url\":\"https://www.semanticscholar.org/paper/bbaa5a95aba6cccb7c9885db0329c413f12bbb22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.06298\",\"authors\":[{\"authorId\":\"7306249\",\"name\":\"Xianglei Xing\"},{\"authorId\":\"9659905\",\"name\":\"Ruiqi Gao\"},{\"authorId\":\"50495880\",\"name\":\"Tian Han\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/tpami.2020.3013905\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09a179cc3a195f2d414d46d3378eb74d0baa0292\",\"title\":\"Deformable Generator Network: Unsupervised Disentanglement of Appearance and Geometry\",\"url\":\"https://www.semanticscholar.org/paper/09a179cc3a195f2d414d46d3378eb74d0baa0292\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2007.12130\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"145237406\",\"name\":\"N. Ahuja\"}],\"doi\":\"10.1007/978-3-030-58583-9_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"title\":\"Sound2Sight: Generating Visual Dynamics from Sound and Context\",\"url\":\"https://www.semanticscholar.org/paper/02f3ced09497c5db59985b2a5db9d3d0aebe5074\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.02808\",\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"1804261\",\"name\":\"D. Boscaini\"},{\"authorId\":\"1753989\",\"name\":\"Fabio Poiesi\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"153142893\",\"name\":\"A. Cavallaro\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f21fec81c7eb3f8f657d88eee43ae99fa4d46260\",\"title\":\"Novel-View Human Action Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f21fec81c7eb3f8f657d88eee43ae99fa4d46260\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.03255\",\"authors\":[{\"authorId\":\"40220358\",\"name\":\"\\u00d0or\\u00f0e Miladinovic\"},{\"authorId\":\"51214165\",\"name\":\"Muhammad Waleed Gondal\"},{\"authorId\":\"46224364\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"1682548\",\"name\":\"J. Buhmann\"},{\"authorId\":\"144771900\",\"name\":\"S. Bauer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9f0774a4ff46ea7bb2028458928bb1fa2248ab5\",\"title\":\"Disentangled State Space Representations\",\"url\":\"https://www.semanticscholar.org/paper/b9f0774a4ff46ea7bb2028458928bb1fa2248ab5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.12226\",\"authors\":[{\"authorId\":\"47509360\",\"name\":\"Shir Gur\"},{\"authorId\":\"19310335\",\"name\":\"Sagie Benaim\"},{\"authorId\":\"48519520\",\"name\":\"L. Wolf\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d29bcdbb700a35634ac72e7694a396b26db2527\",\"title\":\"Hierarchical Patch VAE-GAN: Generating Diverse Videos from a Single Sample\",\"url\":\"https://www.semanticscholar.org/paper/7d29bcdbb700a35634ac72e7694a396b26db2527\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30888565\",\"name\":\"Padmaja Jonnalagedda\"},{\"authorId\":\"31762448\",\"name\":\"B. Weinberg\"},{\"authorId\":\"11892109\",\"name\":\"J. Allen\"},{\"authorId\":\"144452270\",\"name\":\"B. Bhanu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae25c3f67156a886f5a9336da66f72a0725296e0\",\"title\":\"Feature Disentanglement to Aid Imaging Biomarker Characterization for Genetic Mutations\",\"url\":\"https://www.semanticscholar.org/paper/ae25c3f67156a886f5a9336da66f72a0725296e0\",\"venue\":\"MIDL\",\"year\":2020},{\"arxivId\":\"1709.06298\",\"authors\":[{\"authorId\":\"9093463\",\"name\":\"Hao-Wen Dong\"},{\"authorId\":\"37188394\",\"name\":\"Wen-Yi Hsiao\"},{\"authorId\":\"9922427\",\"name\":\"Li-Chia Yang\"},{\"authorId\":\"1689230\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f83ef3250ba1166d7c1c7585da7dd78e0641fae7\",\"title\":\"MuseGAN: Multi-track Sequential Generative Adversarial Networks for Symbolic Music Generation and Accompaniment\",\"url\":\"https://www.semanticscholar.org/paper/f83ef3250ba1166d7c1c7585da7dd78e0641fae7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1911.11758\",\"authors\":[{\"authorId\":\"47003252\",\"name\":\"Yuheng Li\"},{\"authorId\":\"50339742\",\"name\":\"Krishna Kumar Singh\"},{\"authorId\":\"47284770\",\"name\":\"Utkarsh Ojha\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9cf3e873919f694c645aa459883ef3cca1315bfd\",\"title\":\"MixNMatch: Multifactor Disentanglement and Encoding for Conditional Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/9cf3e873919f694c645aa459883ef3cca1315bfd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.10645\",\"authors\":[{\"authorId\":\"31818765\",\"name\":\"Xiaohang Zhan\"},{\"authorId\":\"66056122\",\"name\":\"Jiahao Xie\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"8748397\",\"name\":\"Y. S. Ong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/cvpr42600.2020.00672\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39218170b4e4c8d1cee3c85219c8d72f00a14109\",\"title\":\"Online Deep Clustering for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/39218170b4e4c8d1cee3c85219c8d72f00a14109\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8449394\",\"name\":\"A. Torfi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ca59703ed577774957d99920131ba07e1957916\",\"title\":\"Privacy-Preserving Synthetic Medical Data Generation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3ca59703ed577774957d99920131ba07e1957916\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":\"1811.09245\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef29d5c85b70fd9dbe04a7b839fbc7d413b161e6\",\"title\":\"TGANv2: Efficient Training of Large Models for Video Generation with Multiple Subsampling Layers\",\"url\":\"https://www.semanticscholar.org/paper/ef29d5c85b70fd9dbe04a7b839fbc7d413b161e6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19235216\",\"name\":\"Zekun Hao\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d629ee73070e7c693ae6924aa52df129a127b33\",\"title\":\"Controllable Video Generation with Sparse Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/9d629ee73070e7c693ae6924aa52df129a127b33\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.00634\",\"authors\":[{\"authorId\":\"144576352\",\"name\":\"Jun Jin\"},{\"authorId\":\"145319396\",\"name\":\"Masood Dehghan\"},{\"authorId\":\"51320395\",\"name\":\"Laura Petrich\"},{\"authorId\":\"3560734\",\"name\":\"Steven Weikai Lu\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f88ce7504e58a839525a500a5b58d5723c334c61\",\"title\":\"Evaluation of state representation methods in robot hand-eye coordination learning from demonstration\",\"url\":\"https://www.semanticscholar.org/paper/f88ce7504e58a839525a500a5b58d5723c334c61\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29805373\",\"name\":\"Mrinal Kanti Baowaly\"},{\"authorId\":\"2551297\",\"name\":\"C. Lin\"},{\"authorId\":\"39986827\",\"name\":\"Chao-Lin Liu\"},{\"authorId\":\"6270307\",\"name\":\"Kuan-Ta Chen\"}],\"doi\":\"10.1093/jamia/ocy142\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37b6a6cea6742aa46ebc43d84c2445af9965a863\",\"title\":\"Synthesizing electronic health records using improved generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/37b6a6cea6742aa46ebc43d84c2445af9965a863\",\"venue\":\"J. Am. Medical Informatics Assoc.\",\"year\":2019},{\"arxivId\":\"1810.01325\",\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"119567230\",\"name\":\"Marco Korner\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-3-2019\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing GANs\",\"url\":\"https://www.semanticscholar.org/paper/b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193874\",\"name\":\"Ondrej Jamriska\"},{\"authorId\":\"151221841\",\"name\":\"S\\u00e1rka Sochorov\\u00e1\"},{\"authorId\":\"150255187\",\"name\":\"O. Texler\"},{\"authorId\":\"38589587\",\"name\":\"M. Luk\\u00e1c\"},{\"authorId\":\"2798088\",\"name\":\"J. Fiser\"},{\"authorId\":\"2054975\",\"name\":\"Jingwan Lu\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"7997286\",\"name\":\"D. S\\u00fdkora\"}],\"doi\":\"10.1145/3306346.3323006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b810da03b420d3105b35e166e99f24d9379d8aa6\",\"title\":\"Stylizing video by example\",\"url\":\"https://www.semanticscholar.org/paper/b810da03b420d3105b35e166e99f24d9379d8aa6\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22770939\",\"name\":\"Tsai-Ho Sun\"},{\"authorId\":\"12548782\",\"name\":\"Chien-Hsun Lai\"},{\"authorId\":\"1992587\",\"name\":\"S. Wong\"},{\"authorId\":null,\"name\":\"Yu-Shuen Wang\"}],\"doi\":\"10.1145/3343031.3351041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8136365526da5b5aa2717ea11676b63be985f93\",\"title\":\"Adversarial Colorization of Icons Based on Contour and Color Conditions\",\"url\":\"https://www.semanticscholar.org/paper/c8136365526da5b5aa2717ea11676b63be985f93\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2003.00877\",\"authors\":[{\"authorId\":\"51021226\",\"name\":\"Chuanxing Geng\"},{\"authorId\":\"1515128894\",\"name\":\"Zhenghao Tan\"},{\"authorId\":\"40633792\",\"name\":\"Song-Can Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb7f9199be024dc7eb51231a4374e90890c4935e\",\"title\":\"A Multi-view Perspective of Self-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/eb7f9199be024dc7eb51231a4374e90890c4935e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"title\":\"Multi-Variate Temporal GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"82619398\",\"name\":\"P. D'Oro\"},{\"authorId\":\"1390194542\",\"name\":\"D. Giordano\"},{\"authorId\":\"147598837\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s11263-019-01246-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d50b45969bef86bf29bcaf9052beade2282fa094\",\"title\":\"Adversarial Framework for Unsupervised Learning of Motion Dynamics in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d50b45969bef86bf29bcaf9052beade2282fa094\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49522516\",\"name\":\"B. Ghosh\"},{\"authorId\":\"47683491\",\"name\":\"I. Dutta\"},{\"authorId\":\"1474557546\",\"name\":\"Michael W. Totaro\"},{\"authorId\":\"121730356\",\"name\":\"M. Bayoumi\"}],\"doi\":\"10.1109/ICCCNT49239.2020.9225510\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac741f212c707f7a0f59fb081ec03dfea8645e0f\",\"title\":\"A Survey on the Progression and Performance of Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ac741f212c707f7a0f59fb081ec03dfea8645e0f\",\"venue\":\"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95115816\",\"name\":\"J. Wang\"},{\"authorId\":\"1993672083\",\"name\":\"Tong Sha\"},{\"authorId\":\"2236084\",\"name\":\"Weitong Zhang\"},{\"authorId\":\"2282019\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3394171.3413514\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c540a814bf2112d8140b15abcbaf70cf7b7091b\",\"title\":\"Down to the Last Detail: Virtual Try-on with Fine-grained Details\",\"url\":\"https://www.semanticscholar.org/paper/6c540a814bf2112d8140b15abcbaf70cf7b7091b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144767796\",\"name\":\"G. Yao\"},{\"authorId\":\"1514692044\",\"name\":\"Zongxuan Liu\"},{\"authorId\":\"49932624\",\"name\":\"Xufeng Guo\"},{\"authorId\":\"1978507980\",\"name\":\"Chaoshi Wei\"},{\"authorId\":\"3029423\",\"name\":\"Xin-Feng Li\"},{\"authorId\":\"152368978\",\"name\":\"Zhihao Chen\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"420b12c46469be6b448227351c7821062873a17f\",\"title\":\"Prediction of Weather Radar Images via a Deep LSTM for Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/420b12c46469be6b448227351c7821062873a17f\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1805.08657\",\"authors\":[{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0251807835a2d863c809c25b3d5899d6431dbe89\",\"title\":\"Robust Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/0251807835a2d863c809c25b3d5899d6431dbe89\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50021682\",\"name\":\"T. Liu\"},{\"authorId\":\"144280840\",\"name\":\"Y. Hong\"},{\"authorId\":\"50629383\",\"name\":\"S. Barbour\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"743bbf4a42f1d4e7952b42609a9b4392c82d8b7a\",\"title\":\"GENERATIVE SPATIOTEMPORAL MODELING OF NEUTROPHIL BEHAVIOR by NARITA PANDHE\",\"url\":\"https://www.semanticscholar.org/paper/743bbf4a42f1d4e7952b42609a9b4392c82d8b7a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1807.11152\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"40072288\",\"name\":\"Zhe Wang\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"1788070\",\"name\":\"J. Shi\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01249-6_13\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da219d1f43cc00de6c5a411e47feca956f88645f\",\"title\":\"Pose Guided Human Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/da219d1f43cc00de6c5a411e47feca956f88645f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.01874\",\"authors\":[{\"authorId\":\"5437547\",\"name\":\"Qiyang Hu\"},{\"authorId\":\"52148417\",\"name\":\"Adrian Waelchli\"},{\"authorId\":\"21529935\",\"name\":\"Tiziano Portenier\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"},{\"authorId\":\"145646305\",\"name\":\"P. Favaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"949ec7afb546060a8c8929462b2eb7bdb468f30a\",\"title\":\"Video Synthesis from a Single Image and Motion Stroke\",\"url\":\"https://www.semanticscholar.org/paper/949ec7afb546060a8c8929462b2eb7bdb468f30a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48201841\",\"name\":\"Yuki Hirose\"},{\"authorId\":\"145240776\",\"name\":\"K. Nakamura\"},{\"authorId\":\"2939508\",\"name\":\"Naoko Nitta\"},{\"authorId\":\"1727647\",\"name\":\"N. Babaguchi\"}],\"doi\":\"10.1587/transinf.2019edp7042\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d679c8d6dfbe801c1a8980ff27762d2a5857301\",\"title\":\"Discrimination between Genuine and Cloned Gait Silhouette Videos via Autoencoder-Based Training Data Generation\",\"url\":\"https://www.semanticscholar.org/paper/0d679c8d6dfbe801c1a8980ff27762d2a5857301\",\"venue\":\"IEICE Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":\"1711.11453\",\"authors\":[{\"authorId\":\"2208488\",\"name\":\"Bernhard Kratzwald\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"571b04fc6e624b730f9c924e33a2cf6ea8049992\",\"title\":\"Towards an Understanding of Our World by GANing Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/571b04fc6e624b730f9c924e33a2cf6ea8049992\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.09245\",\"authors\":[{\"authorId\":\"1725418556\",\"name\":\"Masaki Saito\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"},{\"authorId\":\"152400765\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"3456592\",\"name\":\"S. Kobayashi\"}],\"doi\":\"10.1007/s11263-020-01333-y\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"14b175654024c6b57653239674305fe91bca89a1\",\"title\":\"Train Sparsely, Generate Densely: Memory-Efficient Unsupervised Training of High-Resolution Temporal GAN\",\"url\":\"https://www.semanticscholar.org/paper/14b175654024c6b57653239674305fe91bca89a1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2005.10954\",\"authors\":[{\"authorId\":\"46193344\",\"name\":\"Mohammad Rami Koujan\"},{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"2931390\",\"name\":\"A. Roussos\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4a787b7177fec50da643a662a57db64ccc91ffc\",\"title\":\"Head2Head: Video-based Neural Head Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/e4a787b7177fec50da643a662a57db64ccc91ffc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.11437\",\"authors\":[{\"authorId\":null,\"name\":\"Yizhe Zhu\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/cvpr42600.2020.00657\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"68d6b024891a981f349016def772b90e116ea1af\",\"title\":\"S3VAE: Self-Supervised Sequential VAE for Representation Disentanglement and Data Generation\",\"url\":\"https://www.semanticscholar.org/paper/68d6b024891a981f349016def772b90e116ea1af\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.01971\",\"authors\":[{\"authorId\":\"40651388\",\"name\":\"Ping Yu\"},{\"authorId\":\"34340526\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"}],\"doi\":\"10.1007/978-3-030-58577-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd14a945520f412b1b7537c17693f734c0126f9d\",\"title\":\"Structure-Aware Human-Action Generation\",\"url\":\"https://www.semanticscholar.org/paper/cd14a945520f412b1b7537c17693f734c0126f9d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145708149\",\"name\":\"Y. Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7799f1e791515565697053ffdd733fb9ba72613\",\"title\":\"MaterialGAN: Reflectance Capture using a Generative SVBRDF Model\",\"url\":\"https://www.semanticscholar.org/paper/e7799f1e791515565697053ffdd733fb9ba72613\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1452981772\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1699643\",\"name\":\"C. Pollett\"},{\"authorId\":\"2508779\",\"name\":\"P. Heller\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c43302d64d1ae8092cf6f0758cf1981f83b5b7a7\",\"title\":\"Video Synthesis from the StyleGAN Latent Space\",\"url\":\"https://www.semanticscholar.org/paper/c43302d64d1ae8092cf6f0758cf1981f83b5b7a7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46756194\",\"name\":\"Cheng Yu\"},{\"authorId\":\"47825552\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"134233854\",\"name\":\"Jianhao Yan\"}],\"doi\":\"10.1109/ACCESS.2020.3008523\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c5b4b49dd322a4ffe50448e8810880c0f79453b\",\"title\":\"Self-Supervised Animation Synthesis Through Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/2c5b4b49dd322a4ffe50448e8810880c0f79453b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35175531\",\"name\":\"Patrick Esser\"},{\"authorId\":\"66964458\",\"name\":\"Johannes Haux\"},{\"authorId\":\"3334896\",\"name\":\"Timo Milbich\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1007/978-3-030-11012-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"715d9831214df8dc3c23b4c03cf5657b37a78eb0\",\"title\":\"Towards Learning a Realistic Rendering of Human Behavior\",\"url\":\"https://www.semanticscholar.org/paper/715d9831214df8dc3c23b4c03cf5657b37a78eb0\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46874123\",\"name\":\"W. Gao\"},{\"authorId\":\"50024008\",\"name\":\"Y. Li\"},{\"authorId\":\"2926974\",\"name\":\"Yihang Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0da4bd286cac8a8aa8577867ff87cab279ca964f\",\"title\":\"Fast Video Multi-Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/0da4bd286cac8a8aa8577867ff87cab279ca964f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"144978989\",\"name\":\"Y. Tian\"},{\"authorId\":\"1379758006\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/s11263-020-01328-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"title\":\"Towards Image-to-Video Translation: A Structure-Aware Approach via Multi-stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0ca9eb353e33e37e725a8f89bd07ca1fc09a285\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1909.11975\",\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2934852\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4b2207e6de1e759ac7a7f45abe7a0b1d1da4558\",\"title\":\"Learning Energy-based Spatial-Temporal Generative ConvNets for Dynamic Patterns\",\"url\":\"https://www.semanticscholar.org/paper/a4b2207e6de1e759ac7a7f45abe7a0b1d1da4558\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1712.03534\",\"authors\":[{\"authorId\":\"2017906\",\"name\":\"Wissam J. Baddar\"},{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"2909533\",\"name\":\"S. Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"title\":\"Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image\",\"url\":\"https://www.semanticscholar.org/paper/deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2002.08641\",\"authors\":[{\"authorId\":\"1500376187\",\"name\":\"Tanya Motwani\"},{\"authorId\":\"48646575\",\"name\":\"Manojkumar Somabhai Parmar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"079e909770f4cf80293da44dbb2ec5d5280457c1\",\"title\":\"A Novel Framework for Selection of GANs for an Application\",\"url\":\"https://www.semanticscholar.org/paper/079e909770f4cf80293da44dbb2ec5d5280457c1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.12043\",\"authors\":[{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"title\":\"Video-to-Video Translation for Visual Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.02793\",\"authors\":[{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"555e7029e8fd3b759300edfd2a4b7dfa2fd34a48\",\"title\":\"Generative Adversarial Networks for Image and Video Synthesis: Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/555e7029e8fd3b759300edfd2a4b7dfa2fd34a48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08571\",\"authors\":[{\"authorId\":\"40084973\",\"name\":\"Tianlin Xu\"},{\"authorId\":\"49432923\",\"name\":\"Li K Wenliang\"},{\"authorId\":\"40484552\",\"name\":\"M. Munn\"},{\"authorId\":\"1902556\",\"name\":\"B. Acciaio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"53073458ad3f387f6c97af28467749c9f148c9cd\",\"title\":\"COT-GAN: Generating Sequential Data via Causal Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/53073458ad3f387f6c97af28467749c9f148c9cd\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40617564\",\"name\":\"W. Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/icme46284.2020.9102778\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3f072ef328c2a9fd0649ce8f27fab8839ff4bdd\",\"title\":\"Moflowgan: Video Generation With Flow Guidance\",\"url\":\"https://www.semanticscholar.org/paper/d3f072ef328c2a9fd0649ce8f27fab8839ff4bdd\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845209\",\"name\":\"Zihao Yan\"},{\"authorId\":\"2154334\",\"name\":\"Ruizhen Hu\"},{\"authorId\":\"66060467\",\"name\":\"Xingguang Yan\"},{\"authorId\":\"49329812\",\"name\":\"L. Chen\"},{\"authorId\":\"3276873\",\"name\":\"O. V. Kaick\"},{\"authorId\":\"114464478\",\"name\":\"Hao Zhang\"},{\"authorId\":\"40586368\",\"name\":\"Hui Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b9e893a1825f9106b7232ddbdfa34d32a32802a\",\"title\":\"RPM-Net: Recurrent Prediction of Motion and Parts from Point Cloud\",\"url\":\"https://www.semanticscholar.org/paper/4b9e893a1825f9106b7232ddbdfa34d32a32802a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146372255\",\"name\":\"Caglar Gulcehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"83138063\",\"name\":\"Fethi\"},{\"authorId\":null,\"name\":\"Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425c8668e0add6a8966242a24da58bf2bb4aa5\",\"title\":\"Adversarial Training for Multi-Channel Sign Language Production\",\"url\":\"https://www.semanticscholar.org/paper/5f425c8668e0add6a8966242a24da58bf2bb4aa5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.09388\",\"authors\":[{\"authorId\":\"70508259\",\"name\":\"S. Chen\"},{\"authorId\":\"144833642\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"1561145507\",\"name\":\"Beihao Xia\"},{\"authorId\":\"1744228\",\"name\":\"Xinge You\"},{\"authorId\":\"47060588\",\"name\":\"Zehong Cao\"},{\"authorId\":\"47736691\",\"name\":\"Weiping Ding\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"548b79a5a66c0860af9456bb9efc185bf5d27081\",\"title\":\"CDE-GAN: Cooperative Dual Evolution Based Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/548b79a5a66c0860af9456bb9efc185bf5d27081\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.11294\",\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"9659905\",\"name\":\"Ruiqi Gao\"},{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6931\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d905d787372549ea445cc0c87c9fcb9de4ffa8a1\",\"title\":\"Motion-Based Generator Model: Unsupervised Disentanglement of Appearance, Trackable and Intrackable Motions in Dynamic Patterns\",\"url\":\"https://www.semanticscholar.org/paper/d905d787372549ea445cc0c87c9fcb9de4ffa8a1\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699643\",\"name\":\"C. Pollett\"},{\"authorId\":\"50082102\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd355230db355e11d66aed1625cda46082178fe7\",\"title\":\"GAN-BASED PHOTO VIDEO SYNTHESIS\",\"url\":\"https://www.semanticscholar.org/paper/dd355230db355e11d66aed1625cda46082178fe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.09542\",\"authors\":[{\"authorId\":\"8780767\",\"name\":\"B. Chettri\"},{\"authorId\":\"98067310\",\"name\":\"T. Kinnunen\"},{\"authorId\":\"2109397\",\"name\":\"Emmanouil Benetos\"}],\"doi\":\"10.1016/j.csl.2020.101092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e886e87c122b983cae94f760efba6383ac779e5e\",\"title\":\"Deep generative variational autoencoding for replay spoof detection in automatic speaker verification\",\"url\":\"https://www.semanticscholar.org/paper/e886e87c122b983cae94f760efba6383ac779e5e\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":\"2005.12126\",\"authors\":[{\"authorId\":\"2596437\",\"name\":\"Seung Wook Kim\"},{\"authorId\":\"2481662\",\"name\":\"Y. Zhou\"},{\"authorId\":\"103688686\",\"name\":\"Jonah Philion\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/cvpr42600.2020.00131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28e4fa2cb562816542e90d264f4b69f341eccf38\",\"title\":\"Learning to Simulate Dynamic Environments With GameGAN\",\"url\":\"https://www.semanticscholar.org/paper/28e4fa2cb562816542e90d264f4b69f341eccf38\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1809.00263\",\"authors\":[{\"authorId\":\"12601304\",\"name\":\"Qiangeng Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Weiyue Wang\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1109/WACV45572.2020.9093530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"title\":\"Stochastic Dynamics for Video Infilling\",\"url\":\"https://www.semanticscholar.org/paper/56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"1801809\",\"name\":\"F. Jurie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f63b593149f5d292e18fddea413b138b621195dc\",\"title\":\"Neutral NeutralNeutral Surprised Surprised Surprised Happy Happy Happy Sad SadSad DisgustedFearful Fearful Disgusted Disgusted Angry Angry Angry C A B\",\"url\":\"https://www.semanticscholar.org/paper/f63b593149f5d292e18fddea413b138b621195dc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152718961\",\"name\":\"Yun-Chieh Tien\"},{\"authorId\":\"3228778\",\"name\":\"Chen-Min Hsu\"},{\"authorId\":\"145120643\",\"name\":\"Fang Yu\"}],\"doi\":\"10.1007/978-3-030-30484-3_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21f6362b98032eee26a5238c2cabc6a1f65f2731\",\"title\":\"HiSeqGAN: Hierarchical Sequence Synthesis and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/21f6362b98032eee26a5238c2cabc6a1f65f2731\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"2007.08786\",\"authors\":[{\"authorId\":\"79372499\",\"name\":\"Subin Jeon\"},{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-58586-0_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d30ae95b116c2b7c2214dbf0d3301ffb410d5d8d\",\"title\":\"Cross-Identity Motion Transfer for Arbitrary Objects through Pose-Attentive Video Reassembling\",\"url\":\"https://www.semanticscholar.org/paper/d30ae95b116c2b7c2214dbf0d3301ffb410d5d8d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.01529\",\"authors\":[{\"authorId\":\"50218817\",\"name\":\"Zhengwei Wang\"},{\"authorId\":\"1486411393\",\"name\":\"Qi She\"},{\"authorId\":\"144582016\",\"name\":\"T. Ward\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2673354bc246e65962a6dca32d5f41cc8f11a249\",\"title\":\"Generative Adversarial Networks in Computer Vision: A Survey and Taxonomy.\",\"url\":\"https://www.semanticscholar.org/paper/2673354bc246e65962a6dca32d5f41cc8f11a249\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47932716\",\"name\":\"X. Huang\"},{\"authorId\":\"151474565\",\"name\":\"Mingjie Wang\"},{\"authorId\":\"1473876432\",\"name\":\"M. Gong\"}],\"doi\":\"10.1007/S00371-020-01982-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef6467ddba06210c7cd0677955234e2e850274f0\",\"title\":\"Fine-grained talking face generation with video reinterpretation\",\"url\":\"https://www.semanticscholar.org/paper/ef6467ddba06210c7cd0677955234e2e850274f0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.11138\",\"authors\":[{\"authorId\":\"2934352\",\"name\":\"Yisroel Mirsky\"},{\"authorId\":\"49627181\",\"name\":\"W. Lee\"}],\"doi\":\"10.1145/3425780\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92b4c8deecee703569b9e909dfb88aa70e691219\",\"title\":\"The Creation and Detection of Deepfakes: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/92b4c8deecee703569b9e909dfb88aa70e691219\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.00680\",\"authors\":[{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\"},{\"authorId\":\"1797422\",\"name\":\"Chongyang Ma\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"48858384\",\"name\":\"William Brendel\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1109/CVPR.2019.00150\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54efdd4c03e47a11db7ef710b8dc87c70d34e529\",\"title\":\"End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image\",\"url\":\"https://www.semanticscholar.org/paper/54efdd4c03e47a11db7ef710b8dc87c70d34e529\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.05523\",\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/CVPR42600.2020.00531\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33392bb15145ba1c7681061ce891f2e49354ca17\",\"title\":\"G3AN: Disentangling Appearance and Motion for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/33392bb15145ba1c7681061ce891f2e49354ca17\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1812.10157\",\"authors\":[{\"authorId\":\"3234769\",\"name\":\"V. Prinet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3b934bc47fd6c0adedaaab9e694b64336899317\",\"title\":\"Motion Selective Prediction for Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c3b934bc47fd6c0adedaaab9e694b64336899317\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1910.12906\",\"authors\":[{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"3352747\",\"name\":\"Tanmay Randhavane\"},{\"authorId\":\"2718563\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1609/aaai.v34i02.5490\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23135a88c48de1b15bfdf2f4c09621385ae5d3de\",\"title\":\"STEP: Spatial Temporal Graph Convolutional Networks for Emotion Perception from Gaits\",\"url\":\"https://www.semanticscholar.org/paper/23135a88c48de1b15bfdf2f4c09621385ae5d3de\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2394159\",\"name\":\"Bruno Q. Bastos\"},{\"authorId\":\"35198930\",\"name\":\"F. Oliveira\"},{\"authorId\":\"1662762055\",\"name\":\"R. L. Milidiu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"937145068867f4a4b67a5d2dae4d038506ecf169\",\"title\":\"Spatio-Temporal Wind Speed Forecasting with Models based on Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/937145068867f4a4b67a5d2dae4d038506ecf169\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.12713\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea92a69b48287caa3a25ff3dfe727bed8888348\",\"title\":\"Few-shot Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bea92a69b48287caa3a25ff3dfe727bed8888348\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100486091\",\"name\":\"D. Dirvanauskas\"},{\"authorId\":\"1922138\",\"name\":\"R. Maskeli\\u016bnas\"},{\"authorId\":\"48103505\",\"name\":\"V. Raudonis\"},{\"authorId\":\"1801351\",\"name\":\"Robertas Dama\\u0161evi\\u010dius\"},{\"authorId\":\"1710827\",\"name\":\"R. Scherer\"}],\"doi\":\"10.3390/s19163578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1849392799a75c4a5a2b15c55050f56a9265c6f3\",\"title\":\"HEMIGEN: Human Embryo Image Generator Based on Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1849392799a75c4a5a2b15c55050f56a9265c6f3\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19902610\",\"name\":\"Zhihang Hu\"},{\"authorId\":\"2487504\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICCVW.2019.00101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa1c7aeda73eec4c577c545bc449aec29e4086c4\",\"title\":\"A Novel Adversarial Inference Framework for Video Prediction with Action Control\",\"url\":\"https://www.semanticscholar.org/paper/aa1c7aeda73eec4c577c545bc449aec29e4086c4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2005.06508\",\"authors\":[{\"authorId\":\"47374789\",\"name\":\"P. Chandramouli\"},{\"authorId\":\"1557628372\",\"name\":\"Kanchana Vaishnavi Gandikota\"},{\"authorId\":\"46257916\",\"name\":\"Andreas G\\u00f6rlitz\"},{\"authorId\":\"40858478\",\"name\":\"A. Kolb\"},{\"authorId\":\"48352475\",\"name\":\"M. Moeller\"}],\"doi\":\"10.1109/TPAMI.2020.3039841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12891c20a6f0735a3820c1624bb5133c58775a5a\",\"title\":\"Generative Models for Generic Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/12891c20a6f0735a3820c1624bb5133c58775a5a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35687142\",\"name\":\"Daichi Horita\"},{\"authorId\":\"49359527\",\"name\":\"Wataru Shimoda\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1145/3347448.3357166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02e0e0be1c9e8badce971a40a3ba267e93833434\",\"title\":\"Unseen Food Creation by Mixing Existing Food Images with Conditional StyleGAN\",\"url\":\"https://www.semanticscholar.org/paper/02e0e0be1c9e8badce971a40a3ba267e93833434\",\"venue\":\"MADiMa @ ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2012.09855\",\"authors\":[{\"authorId\":\"2926666\",\"name\":\"A. Liu\"},{\"authorId\":\"4129805\",\"name\":\"R. Tucker\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"2159982\",\"name\":\"A. Makadia\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"714143e49c3476bf1aa4e6d0454151e6ab490be3\",\"title\":\"Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/714143e49c3476bf1aa4e6d0454151e6ab490be3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"46220633\",\"name\":\"Yue Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"683448543f44fb46a0ddf5420c254a7329df873a\",\"title\":\"Demystifying Self-Supervised Learning: An Information-Theoretical Framework\",\"url\":\"https://www.semanticscholar.org/paper/683448543f44fb46a0ddf5420c254a7329df873a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14721\",\"authors\":[{\"authorId\":\"19169739\",\"name\":\"Mohamed Abbas Hedjazi\"},{\"authorId\":\"2369727\",\"name\":\"Yakup Genc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53d24dd3ce9674728cf6921fe1e349cb76238dd8\",\"title\":\"Texture-aware Multi-resolution Image Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/53d24dd3ce9674728cf6921fe1e349cb76238dd8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.12405\",\"authors\":[{\"authorId\":\"119739494\",\"name\":\"Ben Saunders\"},{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61ff9694321710cac36b3822bcc08a28df6240c\",\"title\":\"Adversarial Training for Multi-Channel Sign Language Production\",\"url\":\"https://www.semanticscholar.org/paper/e61ff9694321710cac36b3822bcc08a28df6240c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09194\",\"authors\":[{\"authorId\":\"23696685\",\"name\":\"Baiwu Zhang\"},{\"authorId\":\"1455858501\",\"name\":\"J. Zhou\"},{\"authorId\":\"47473421\",\"name\":\"Ilia Shumailov\"},{\"authorId\":\"1967156\",\"name\":\"Nicolas Papernot\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e5129475757d03f34031b4fb00b5fcb8accf0bf\",\"title\":\"Not My Deepfake: Towards Plausible Deniability for Machine-Generated Media\",\"url\":\"https://www.semanticscholar.org/paper/4e5129475757d03f34031b4fb00b5fcb8accf0bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.08841\",\"authors\":[{\"authorId\":\"3365029\",\"name\":\"Diane Bouchacourt\"},{\"authorId\":\"2870603\",\"name\":\"Ryota Tomioka\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"12fcb2637f241d515827fb193a650b7e6bf6b1f7\",\"title\":\"Multi-Level Variational Autoencoder: Learning Disentangled Representations from Grouped Observations\",\"url\":\"https://www.semanticscholar.org/paper/12fcb2637f241d515827fb193a650b7e6bf6b1f7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1908.08522\",\"authors\":[{\"authorId\":\"9653518\",\"name\":\"Yufei Ye\"},{\"authorId\":\"144337606\",\"name\":\"M. Singh\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"}],\"doi\":\"10.1109/ICCV.2019.01045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf65c7310c66489642a72823996eb08ac5a592d5\",\"title\":\"Compositional Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cf65c7310c66489642a72823996eb08ac5a592d5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.14865\",\"authors\":[{\"authorId\":\"5102388\",\"name\":\"Zihao Yan\"},{\"authorId\":\"2154334\",\"name\":\"Ruizhen Hu\"},{\"authorId\":\"66060467\",\"name\":\"Xingguang Yan\"},{\"authorId\":\"49329812\",\"name\":\"L. Chen\"},{\"authorId\":\"3276873\",\"name\":\"O. V. Kaick\"},{\"authorId\":\"3410520\",\"name\":\"Hongxing Zhang\"},{\"authorId\":\"40586368\",\"name\":\"Hui Huang\"}],\"doi\":\"10.1145/3355089.3356573\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a57df2413afa2448f50cad4d4357ab8d5006c2ba\",\"title\":\"RPM-Net\",\"url\":\"https://www.semanticscholar.org/paper/a57df2413afa2448f50cad4d4357ab8d5006c2ba\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151230204\",\"name\":\"Hongtao Yang\"},{\"authorId\":\"144388019\",\"name\":\"P. Shi\"},{\"authorId\":\"9726771\",\"name\":\"Dixiu Zhong\"},{\"authorId\":\"2420511\",\"name\":\"D. Pan\"},{\"authorId\":\"29444563\",\"name\":\"Zefeng Ying\"}],\"doi\":\"10.1109/ACCESS.2019.2957235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204a8b5eb6d9dfdc868950d6b2d86fc3d23f6f1f\",\"title\":\"Blind Image Quality Assessment of Natural Distorted Image Based on Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/204a8b5eb6d9dfdc868950d6b2d86fc3d23f6f1f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35687142\",\"name\":\"Daichi Horita\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":\"10.1007/978-3-030-41404-7_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d682b993762623c1fea5c91e19429df04a4c87d\",\"title\":\"SSA-GAN: End-to-End Time-Lapse Video Generation with Spatial Self-Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d682b993762623c1fea5c91e19429df04a4c87d\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381418640\",\"name\":\"Teppei Tsutsumi\"},{\"authorId\":\"145240776\",\"name\":\"K. Nakamura\"},{\"authorId\":\"1969310\",\"name\":\"S. Myojin\"},{\"authorId\":\"2939508\",\"name\":\"Naoko Nitta\"},{\"authorId\":\"1727647\",\"name\":\"N. Babaguchi\"}],\"doi\":\"10.1109/ICIP.2019.8803818\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"655bfb5083bf8754f186fce8bae82dc777e459a4\",\"title\":\"Training-Free Method for Generating Motion Video Clones From A Still Image Considering Self-Occlusion of Human Body\",\"url\":\"https://www.semanticscholar.org/paper/655bfb5083bf8754f186fce8bae82dc777e459a4\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1909.12400\",\"authors\":[{\"authorId\":\"1389556562\",\"name\":\"V. Yushchenko\"},{\"authorId\":\"1942495\",\"name\":\"Nikita Araslanov\"},{\"authorId\":\"46840930\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/ICCVW.2019.00190\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa6bb4f4ad12ca1ff14faff0c2147de3be059e79\",\"title\":\"Markov Decision Process for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/aa6bb4f4ad12ca1ff14faff0c2147de3be059e79\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1912.11675\",\"authors\":[{\"authorId\":\"51139139\",\"name\":\"Zengjie Song\"},{\"authorId\":\"143812875\",\"name\":\"O. Koyejo\"},{\"authorId\":\"123275655\",\"name\":\"Jiang-She Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"79ac71d085a7d1dfefcbd8395e0ecedd51f03545\",\"title\":\"Learning Controllable Disentangled Representations with Decorrelation Regularization\",\"url\":\"https://www.semanticscholar.org/paper/79ac71d085a7d1dfefcbd8395e0ecedd51f03545\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.06337\",\"authors\":[{\"authorId\":\"2160245\",\"name\":\"Konstantinos Vougioukas\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1007/s11263-019-01251-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f06ab43069480c09d7170075a6ea74669a71f139\",\"title\":\"Realistic Speech-Driven Facial Animation with GANs\",\"url\":\"https://www.semanticscholar.org/paper/f06ab43069480c09d7170075a6ea74669a71f139\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1812.03704\",\"authors\":[{\"authorId\":\"145848547\",\"name\":\"A. Romero\"},{\"authorId\":\"144115963\",\"name\":\"P. Arbel\\u00e1ez\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":\"10.1109/ICCVW.2019.00410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"384ed183aa4dcde3bfaadeeb990ec9212eaca39a\",\"title\":\"SMIT: Stochastic Multi-Label Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/384ed183aa4dcde3bfaadeeb990ec9212eaca39a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48915513\",\"name\":\"P. Johnston\"},{\"authorId\":\"1807106\",\"name\":\"Eyad Elyan\"}],\"doi\":\"10.1016/J.DIIN.2019.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"title\":\"A review of digital video tampering: From simple editing to full synthesis\",\"url\":\"https://www.semanticscholar.org/paper/cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"venue\":\"Digit. Investig.\",\"year\":2019},{\"arxivId\":\"2010.15075\",\"authors\":[{\"authorId\":\"11016722\",\"name\":\"Noushin Hajarolasvadi\"},{\"authorId\":\"32286131\",\"name\":\"M. Ram\\u00edrez\"},{\"authorId\":\"40986317\",\"name\":\"Wesley Beccaro\"},{\"authorId\":\"2128977\",\"name\":\"H. Demirel\"}],\"doi\":\"10.1109/ACCESS.2020.3042328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5122bc767bcbdde57761c64973c72e945ba7bd22\",\"title\":\"Generative Adversarial Networks in Human Emotion Synthesis: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5122bc767bcbdde57761c64973c72e945ba7bd22\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/WACV45572.2020.9093492\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"title\":\"ImaGINator: Conditional Spatio-Temporal GAN for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1812.01037\",\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV45572.2020.9093557\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"05c43f1791787e78e343536a65a2853af699fe68\",\"title\":\"TwoStreamVAN: Improving Motion Modeling in Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/05c43f1791787e78e343536a65a2853af699fe68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1802.01873\",\"authors\":[{\"authorId\":\"47825302\",\"name\":\"Wei Wang\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"},{\"authorId\":\"145851646\",\"name\":\"D. Xu\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CVPR.2018.00740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb13cbbaa7647177746ab86983273317dd5bcf51\",\"title\":\"Every Smile is Unique: Landmark-Guided Diverse Smile Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb13cbbaa7647177746ab86983273317dd5bcf51\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.04013\",\"authors\":[{\"authorId\":\"145079398\",\"name\":\"Kun Cheng\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"},{\"authorId\":\"152131383\",\"name\":\"Lingyiqing Zhou\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01e7f4a72bb7b4747b171764c499f126317b45f2\",\"title\":\"Multi-Frame Content Integration with a Spatio-Temporal Attention Mechanism for Person Video Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/01e7f4a72bb7b4747b171764c499f126317b45f2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3440249\",\"name\":\"Ruozi Huang\"},{\"authorId\":\"46353980\",\"name\":\"Huang Hu\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"2505139\",\"name\":\"K. Sawada\"},{\"authorId\":\"144315664\",\"name\":\"Mi Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b210d4594f19342ff625cf50d8d4bccfdc0d2ae5\",\"title\":\"Dance Revolution: Long Sequence Dance Generation with Music via Curriculum Learning\",\"url\":\"https://www.semanticscholar.org/paper/b210d4594f19342ff625cf50d8d4bccfdc0d2ae5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819450790\",\"name\":\"Qi Chen\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"49251914\",\"name\":\"Jun-kai Chen\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TIP.2020.3003227\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a2418fd9c453492f1ca833d5595571249a3ee55\",\"title\":\"Scripted Video Generation With a Bottom-Up Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/5a2418fd9c453492f1ca833d5595571249a3ee55\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2204726\",\"name\":\"I. Chaturvedi\"},{\"authorId\":\"151507346\",\"name\":\"J. Xiang\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207617\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e5c35201c6fd73bbba9738003d520938878ed33\",\"title\":\"Constrained Manifold Learning for Videos\",\"url\":\"https://www.semanticscholar.org/paper/8e5c35201c6fd73bbba9738003d520938878ed33\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102509914\",\"name\":\"Radamanthys Stivaktakis\"},{\"authorId\":\"47952527\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"1694755\",\"name\":\"P. Tsakalides\"}],\"doi\":\"10.3390/make2030017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d3d8366c5186914be2cfbf43a6457df6d83db861\",\"title\":\"Semantic Predictive Coding with Arbitrated Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d3d8366c5186914be2cfbf43a6457df6d83db861\",\"venue\":\"Mach. Learn. Knowl. Extr.\",\"year\":2020},{\"arxivId\":\"1807.02635\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ec868ebe59918f94140bb2889b9027c55c09b65\",\"title\":\"Video Prediction with Appearance and Motion Conditions\",\"url\":\"https://www.semanticscholar.org/paper/5ec868ebe59918f94140bb2889b9027c55c09b65\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1811.10699\",\"authors\":[{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc941fbbc906bf7834a21eea520e2d2277aa57f5\",\"title\":\"Time-Aware and View-Aware Video Rendering for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc941fbbc906bf7834a21eea520e2d2277aa57f5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9723532\",\"name\":\"Subham Mukherjee\"},{\"authorId\":\"29780808\",\"name\":\"S. Ghosh\"},{\"authorId\":\"7137430\",\"name\":\"S. Ghosh\"},{\"authorId\":\"144385555\",\"name\":\"P. Kumar\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1109/ICASSP.2019.8682158\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"554cf535bdb6e8c36a13fb85c22aa4f23fdc735a\",\"title\":\"Predicting Video-frames Using Encoder-convlstm Combination\",\"url\":\"https://www.semanticscholar.org/paper/554cf535bdb6e8c36a13fb85c22aa4f23fdc735a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491259261\",\"name\":\"Hong-Bin Liu\"},{\"authorId\":\"1849483\",\"name\":\"Ickjai Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2995187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3e2d7aa11b5dbc35a4e38b232923e759d428eaa\",\"title\":\"MPL-GAN: Toward Realistic Meteorological Predictive Learning Using Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/d3e2d7aa11b5dbc35a4e38b232923e759d428eaa\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.03864\",\"authors\":[{\"authorId\":\"2007745319\",\"name\":\"Cade Gordon\"},{\"authorId\":\"2326758\",\"name\":\"Natalie Parde\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac4e977aba1731ce1bd5ddeb9ea466fa86c10a5f\",\"title\":\"Latent Neural Differential Equations for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/ac4e977aba1731ce1bd5ddeb9ea466fa86c10a5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1007/s11263-020-01348-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f58d7fc87a9c276965e604fbe83592bae7f4e5\",\"title\":\"RoCGAN: Robust Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/b4f58d7fc87a9c276965e604fbe83592bae7f4e5\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2001.03569\",\"authors\":[{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TIP.2020.3016485\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c1007dd5518ac0ce41f2d8f72ed8c5fd4971caf\",\"title\":\"Video Coding for Machines: A Paradigm of Collaborative Compression and Intelligent Analytics\",\"url\":\"https://www.semanticscholar.org/paper/4c1007dd5518ac0ce41f2d8f72ed8c5fd4971caf\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1803.00657\",\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143901532\",\"name\":\"X. Yao\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TEVC.2019.2895748\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbca46c24c800bee41b21ac0258651db54892e80\",\"title\":\"Evolutionary Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/cbca46c24c800bee41b21ac0258651db54892e80\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1912.06606\",\"authors\":[{\"authorId\":\"1466503743\",\"name\":\"X. Ren\"},{\"authorId\":null,\"name\":\"Haoran Li\"},{\"authorId\":\"48783196\",\"name\":\"Zijian Huang\"},{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3803023eb13d986b8776d5856df70e801efd74da\",\"title\":\"Music-oriented Dance Video Synthesis with Pose Perceptual Loss\",\"url\":\"https://www.semanticscholar.org/paper/3803023eb13d986b8776d5856df70e801efd74da\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.04603\",\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"2814161\",\"name\":\"M. Saffar\"},{\"authorId\":\"35006479\",\"name\":\"Danijar Hafner\"},{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ef097ea041aa4fdb17e8125f1c116b0c898f0\",\"title\":\"Models, Pixels, and Rewards: Evaluating Design Trade-offs in Visual Model-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/704ef097ea041aa4fdb17e8125f1c116b0c898f0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.04732\",\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1007/978-3-030-01219-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60104351ac65115503c9e92e856bcab6a13b0ce8\",\"title\":\"Multimodal Unsupervised Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/60104351ac65115503c9e92e856bcab6a13b0ce8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9328269\",\"name\":\"Ngoc-Dung T. Tieu\"},{\"authorId\":\"40415016\",\"name\":\"Huy H. Nguyen\"},{\"authorId\":\"2912817\",\"name\":\"Hoang-Quoc Nguyen-Son\"},{\"authorId\":\"1716857\",\"name\":\"J. Yamagishi\"},{\"authorId\":\"1678602\",\"name\":\"I. Echizen\"}],\"doi\":\"10.1016/J.JISA.2019.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a15a3813040ee1a5a181ed781290a6a18d953777\",\"title\":\"Spatio-temporal generative adversarial network for gait anonymization\",\"url\":\"https://www.semanticscholar.org/paper/a15a3813040ee1a5a181ed781290a6a18d953777\",\"venue\":\"J. Inf. Secur. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7550195\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"47474011\",\"name\":\"M. Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":\"10.1145/3394171.3414003\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"title\":\"Self-Paced Video Data Augmentation by Generative Adversarial Networks with Insufficient Samples\",\"url\":\"https://www.semanticscholar.org/paper/1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1961262790\",\"name\":\"Yiwei Fu\"},{\"authorId\":\"1961307935\",\"name\":\"Shiraj Sen\"},{\"authorId\":\"1961309452\",\"name\":\"Johan Reimann\"},{\"authorId\":\"35030051\",\"name\":\"Charles Theurer\"}],\"doi\":\"10.1109/ICRA40945.2020.9196858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e8abb38214f2de8f68fa59be41548bebf6e0fa5\",\"title\":\"Spatiotemporal Representation Learning with GAN Trained LSTM-LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/3e8abb38214f2de8f68fa59be41548bebf6e0fa5\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1812.01261\",\"authors\":[{\"authorId\":\"48333400\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"1399435786\",\"name\":\"Antonio Tejero-de-Pablos\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8de3d97d14344d13d15701eea8d6a27c696e27a\",\"title\":\"Conditional Video Generation Using Action-Appearance Captions\",\"url\":\"https://www.semanticscholar.org/paper/e8de3d97d14344d13d15701eea8d6a27c696e27a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1709.06298\",\"authors\":[{\"authorId\":\"9093463\",\"name\":\"Hao-Wen Dong\"},{\"authorId\":\"37188394\",\"name\":\"Wen-Yi Hsiao\"},{\"authorId\":\"9922427\",\"name\":\"Li-Chia Yang\"},{\"authorId\":\"1689230\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4275d4c4bd10742b321467f175f16198ed7d17d7\",\"title\":\"MuseGAN: Symbolic-domain Music Generation and Accompaniment with Multi-track Sequential Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/4275d4c4bd10742b321467f175f16198ed7d17d7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1907.06571\",\"authors\":[{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"24262bd12149b0b8322e0691fa30ec1a4c06b9a8\",\"title\":\"Efficient Video Generation on Complex Datasets\",\"url\":\"https://www.semanticscholar.org/paper/24262bd12149b0b8322e0691fa30ec1a4c06b9a8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e98a7f4e73f49248c912b141c43031a241d4ac33\",\"title\":\"Self-supervised learning of predictive segmentation models from video. (Apprentissage autosupervis\\u00e9 de mod\\u00e8les pr\\u00e9dictifs de segmentation \\u00e0 partir de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/e98a7f4e73f49248c912b141c43031a241d4ac33\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.09987\",\"authors\":[{\"authorId\":\"49419803\",\"name\":\"Dhruv Patel\"},{\"authorId\":\"2625599\",\"name\":\"A. Oberai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a95417d8f17bd90e8049051f8a71037ea38146f9\",\"title\":\"Bayesian Inference with Generative Adversarial Network Priors\",\"url\":\"https://www.semanticscholar.org/paper/a95417d8f17bd90e8049051f8a71037ea38146f9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.09221\",\"authors\":[{\"authorId\":\"145141048\",\"name\":\"H. Qu\"},{\"authorId\":\"48378576\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720771646\",\"name\":\"Qi Chang\"},{\"authorId\":\"1720773026\",\"name\":\"Zhennan Yan\"},{\"authorId\":\"46729486\",\"name\":\"C. Chen\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58583-9_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b350d0e76a48f9877bbaa91ad51d2d23e0b668\",\"title\":\"Learn distributed GAN with Temporary Discriminators\",\"url\":\"https://www.semanticscholar.org/paper/30b350d0e76a48f9877bbaa91ad51d2d23e0b668\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9055516\",\"name\":\"L. Zhao\"},{\"authorId\":\"1390618187\",\"name\":\"Sihuan Lin\"},{\"authorId\":\"1384783474\",\"name\":\"Ailin Li\"},{\"authorId\":\"2535945\",\"name\":\"Huaizhong Lin\"},{\"authorId\":\"1993725687\",\"name\":\"Wei Xing\"},{\"authorId\":\"7382721\",\"name\":\"D. Lu\"}],\"doi\":\"10.1145/3394171.3413760\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c7b3b4c76a0c19355248b6d86fdd6676ddf1d56\",\"title\":\"SpatialGAN: Progressive Image Generation Based on Spatial Recursive Adversarial Expansion\",\"url\":\"https://www.semanticscholar.org/paper/1c7b3b4c76a0c19355248b6d86fdd6676ddf1d56\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.02567\",\"authors\":[{\"authorId\":\"143624567\",\"name\":\"Lei Kang\"},{\"authorId\":\"40420775\",\"name\":\"Pau Riba\"},{\"authorId\":null,\"name\":\"Yaxing Wang\"},{\"authorId\":\"134466999\",\"name\":\"Marccal Rusinol\"},{\"authorId\":\"1686569\",\"name\":\"A. Forn\\u00e9s\"},{\"authorId\":\"41206897\",\"name\":\"M. Villegas\"}],\"doi\":\"10.1007/978-3-030-58592-1_17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c08403b0f530a98a4854b583193b77269f974feb\",\"title\":\"GANwriting: Content-Conditioned Generation of Styled Handwritten Word Images\",\"url\":\"https://www.semanticscholar.org/paper/c08403b0f530a98a4854b583193b77269f974feb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22803355\",\"name\":\"Beibei Jin\"},{\"authorId\":\"144985887\",\"name\":\"Y. Hu\"},{\"authorId\":\"145492828\",\"name\":\"Y. Zeng\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"32758259\",\"name\":\"Shice Liu\"},{\"authorId\":\"144030865\",\"name\":\"Jing Ye\"}],\"doi\":\"10.1109/IROS.2018.8594264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9431e81519d16c87859a55bb1735f61a9e013f7e\",\"title\":\"VarNet: Exploring Variations for Unsupervised Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9431e81519d16c87859a55bb1735f61a9e013f7e\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5782992\",\"name\":\"Yongjun Hong\"},{\"authorId\":\"27642187\",\"name\":\"Uiwon Hwang\"},{\"authorId\":\"8351553\",\"name\":\"Jaeyoon Yoo\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"44e2a38b4fa86c75ea8bdd2f181cede157627493\",\"title\":\"How Generative Adversarial Nets and its variants Work: An Overview of GAN\",\"url\":\"https://www.semanticscholar.org/paper/44e2a38b4fa86c75ea8bdd2f181cede157627493\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1906.02839\",\"authors\":[{\"authorId\":\"1749373\",\"name\":\"Dim P. Papadopoulos\"},{\"authorId\":\"3430216\",\"name\":\"Y. Tamaazousti\"},{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"1684687\",\"name\":\"Ingmar Weber\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2019.00819\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17faab87b74d42e02b407c149c398c33ef4cfc0a\",\"title\":\"How to Make a Pizza: Learning a Compositional Layer-Based GAN Model\",\"url\":\"https://www.semanticscholar.org/paper/17faab87b74d42e02b407c149c398c33ef4cfc0a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.06607\",\"authors\":[{\"authorId\":\"2565547\",\"name\":\"Zhaoxiang Liu\"},{\"authorId\":\"49375968\",\"name\":\"Huan Hu\"},{\"authorId\":\"2229043\",\"name\":\"Zi-Peng Wang\"},{\"authorId\":\"37833805\",\"name\":\"Kai Wang\"},{\"authorId\":\"19252060\",\"name\":\"Jinqiang Bai\"},{\"authorId\":\"143763658\",\"name\":\"Shiguo Lian\"}],\"doi\":\"10.1109/ISMAR-Adjunct.2019.00-47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"894ec1315baf15a56e2bdc2ecd2be7cf0a89e9ed\",\"title\":\"Video Synthesis of Human Upper Body with Realistic Face\",\"url\":\"https://www.semanticscholar.org/paper/894ec1315baf15a56e2bdc2ecd2be7cf0a89e9ed\",\"venue\":\"2019 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153725817\",\"name\":\"Yuki Nakahira\"},{\"authorId\":\"3063432\",\"name\":\"K. Kawamoto\"}],\"doi\":\"10.23919/APSIPA.2018.8659648\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d39e72274d410b5e769c92eeefb5f32832140a19\",\"title\":\"Generative adversarial networks for generating RGB-D videos\",\"url\":\"https://www.semanticscholar.org/paper/d39e72274d410b5e769c92eeefb5f32832140a19\",\"venue\":\"2018 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147998545\",\"name\":\"Stefan Ainetter\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"}],\"doi\":\"10.3217/978-3-85125-652-9-03\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f224be6f39aca5bbdb08671127aa825fc8815fe\",\"title\":\"A Spatiotemporal Generative Adversarial Network to Generate Human Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/7f224be6f39aca5bbdb08671127aa825fc8815fe\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.01655\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"8104240\",\"name\":\"A. Pathak\"},{\"authorId\":\"143862402\",\"name\":\"Harini Kannan\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aec380c44646a7e467cd9f6d78cba301f877734c\",\"title\":\"High Fidelity Video Prediction with Large Stochastic Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/aec380c44646a7e467cd9f6d78cba301f877734c\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8449394\",\"name\":\"A. Torfi\"},{\"authorId\":\"1581639631\",\"name\":\"Mohammadreza Beyki\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7e3bf4f9eb4c96ed6291f0415c0f3ddf8f57475\",\"title\":\"Generating Synthetic Healthcare Records Using Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/a7e3bf4f9eb4c96ed6291f0415c0f3ddf8f57475\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82342433\",\"name\":\"G. Jin\"},{\"authorId\":\"47599111\",\"name\":\"Q. Wang\"},{\"authorId\":\"143850511\",\"name\":\"X. Zhao\"},{\"authorId\":\"3038982\",\"name\":\"Yanghe Feng\"},{\"authorId\":\"145433266\",\"name\":\"Q. Cheng\"},{\"authorId\":\"2078113\",\"name\":\"Jincai Huang\"}],\"doi\":\"10.1109/BigData47090.2019.9006388\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fad3475af250a85bd34792030711dc207b37794\",\"title\":\"Crime-GAN: A Context-based Sequence Generative Network for Crime Forecasting with Adversarial Loss\",\"url\":\"https://www.semanticscholar.org/paper/4fad3475af250a85bd34792030711dc207b37794\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":\"2006.10704\",\"authors\":[{\"authorId\":\"145411379\",\"name\":\"R. Rakhimov\"},{\"authorId\":\"9937997\",\"name\":\"Denis Volkhonskiy\"},{\"authorId\":\"145235439\",\"name\":\"A. Artemov\"},{\"authorId\":\"145516498\",\"name\":\"D. Zorin\"},{\"authorId\":\"51139941\",\"name\":\"Evgeny Burnaev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef25fe928b5a9f53296a938339dff5aeffcf6e7b\",\"title\":\"Latent Video Transformer\",\"url\":\"https://www.semanticscholar.org/paper/ef25fe928b5a9f53296a938339dff5aeffcf6e7b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15597895\",\"name\":\"Hamed AlQahtani\"},{\"authorId\":\"1400351274\",\"name\":\"Manolya Kavakli-Thorne\"},{\"authorId\":\"1384018582\",\"name\":\"G. Kumar\"}],\"doi\":\"10.1007/s11831-019-09388-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42e5ce74677cc10144b2d352f7f7cc37fd54f0bc\",\"title\":\"Applications of Generative Adversarial Networks (GANs): An Updated Review\",\"url\":\"https://www.semanticscholar.org/paper/42e5ce74677cc10144b2d352f7f7cc37fd54f0bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.08776\",\"authors\":[{\"authorId\":\"123830349\",\"name\":\"Aliaksandra Shysheya\"},{\"authorId\":\"144395395\",\"name\":\"E. Zakharov\"},{\"authorId\":\"120510842\",\"name\":\"Kara-Ali Aliev\"},{\"authorId\":\"145182807\",\"name\":\"R. Bashirov\"},{\"authorId\":\"52225338\",\"name\":\"Egor Burkov\"},{\"authorId\":\"119521640\",\"name\":\"K. Iskakov\"},{\"authorId\":\"117502209\",\"name\":\"Aleksei Ivakhnenko\"},{\"authorId\":\"2104662\",\"name\":\"Yury Malkov\"},{\"authorId\":\"102773016\",\"name\":\"I. Pasechnik\"},{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"144029627\",\"name\":\"Alexander Vakhitov\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":\"10.1109/CVPR.2019.00249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbd6a81b792c751e121bfec2d7fcd16cb1d32266\",\"title\":\"Textured Neural Avatars\",\"url\":\"https://www.semanticscholar.org/paper/bbd6a81b792c751e121bfec2d7fcd16cb1d32266\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.07490\",\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"67084339\",\"name\":\"Jianjin Zhang\"},{\"authorId\":\"7296530\",\"name\":\"Hongyu Zhu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/CVPR.2019.00937\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16f9bfac4a68cc99c38c06db2aa523bc6537db0d\",\"title\":\"Memory in Memory: A Predictive Neural Network for Learning Higher-Order Non-Stationarity From Spatiotemporal Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/16f9bfac4a68cc99c38c06db2aa523bc6537db0d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1703.08738\",\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"37278009\",\"name\":\"Fangda Han\"},{\"authorId\":\"102737340\",\"name\":\"X. Peng\"},{\"authorId\":\"49470520\",\"name\":\"X. Zhang\"},{\"authorId\":\"143980996\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"144658464\",\"name\":\"V. Pavlovic\"},{\"authorId\":\"1387332262\",\"name\":\"Dimitris N. Metaxas\"}],\"doi\":\"10.1016/j.cag.2019.01.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34ad523bfefd8307e8b98187d9bf0a199fa81fc6\",\"title\":\"Sketch-based Face Editing in Video Using Identity Deformation Transfer\",\"url\":\"https://www.semanticscholar.org/paper/34ad523bfefd8307e8b98187d9bf0a199fa81fc6\",\"venue\":\"Comput. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819425273\",\"name\":\"Luyao Jiang\"},{\"authorId\":\"143833189\",\"name\":\"Y. Hao\"}],\"doi\":\"10.1109/ICAIBD49809.2020.9137462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e62c0a03ee13f1f660e4584abe78161458dcf0d9\",\"title\":\"Applying Machine Learning to Predict Film Daily Audience Data: System and Dataset\",\"url\":\"https://www.semanticscholar.org/paper/e62c0a03ee13f1f660e4584abe78161458dcf0d9\",\"venue\":\"2020 3rd International Conference on Artificial Intelligence and Big Data (ICAIBD)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103664864\",\"name\":\"Chia-chi Cheng\"},{\"authorId\":\"40846050\",\"name\":\"Hungyu Chen\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":\"10.1109/cvpr42600.2020.00568\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"title\":\"Time Flies: Animating a Still Image With Time-Lapse Video As Reference\",\"url\":\"https://www.semanticscholar.org/paper/4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51404668\",\"name\":\"M. Wang\"},{\"authorId\":\"9429451\",\"name\":\"Congyan Lang\"},{\"authorId\":\"1845796835\",\"name\":\"Liqian Liang\"},{\"authorId\":\"2443426\",\"name\":\"S. Feng\"},{\"authorId\":\"46958821\",\"name\":\"T. Wang\"},{\"authorId\":\"1884356\",\"name\":\"Yutong Gao\"}],\"doi\":\"10.1145/3391709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74b7a806cd94c1571037f7cceacf3fffa7110912\",\"title\":\"End-to-End Text-to-Image Synthesis with Spatial Constrains\",\"url\":\"https://www.semanticscholar.org/paper/74b7a806cd94c1571037f7cceacf3fffa7110912\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2020},{\"arxivId\":\"1810.00110\",\"authors\":[{\"authorId\":\"1788247\",\"name\":\"Karl Ridgeway\"},{\"authorId\":\"144473519\",\"name\":\"Michael C. Mozer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11418a871c8b9a0d106938b3502f4c10b73c976e\",\"title\":\"Open-Ended Content-Style Recombination Via Leakage Filtering\",\"url\":\"https://www.semanticscholar.org/paper/11418a871c8b9a0d106938b3502f4c10b73c976e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491174614\",\"name\":\"Kohei Matsuzaki\"},{\"authorId\":\"2764854\",\"name\":\"Kazuyuki Tasaka\"}],\"doi\":\"10.1109/IROS40897.2019.8967842\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e9fcbaffe21d80067db719066ae7f964868f310\",\"title\":\"Representation Learning via Parallel Subset Reconstruction for 3D Point Cloud Generation\",\"url\":\"https://www.semanticscholar.org/paper/2e9fcbaffe21d80067db719066ae7f964868f310\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"},{\"authorId\":\"1379747201\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44681a63e794b72c3bd2653e54a1439c1e89f7f5\",\"title\":\"1 Generative Adversarial Network Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/44681a63e794b72c3bd2653e54a1439c1e89f7f5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.03410\",\"authors\":[{\"authorId\":\"9308965\",\"name\":\"A. Pal\"},{\"authorId\":\"19089337\",\"name\":\"Aniket Das\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"010cf56447ca225c2537f29426bbab53520582c3\",\"title\":\"TorchGAN: A Flexible Framework for GAN Training and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/010cf56447ca225c2537f29426bbab53520582c3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.00452\",\"authors\":[{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"46193391\",\"name\":\"Qi-Zhi Cai\"},{\"authorId\":\"46886239\",\"name\":\"R. Wang\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2019.00910\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce71c5b4c959c34715503a5980e457e700db9e70\",\"title\":\"Disentangling Propagation and Generation for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ce71c5b4c959c34715503a5980e457e700db9e70\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.02784\",\"authors\":[{\"authorId\":\"50024168\",\"name\":\"Yitong Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1752875\",\"name\":\"Y. Shen\"},{\"authorId\":\"31617773\",\"name\":\"J. Liu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"145006559\",\"name\":\"L. Carin\"},{\"authorId\":\"144752689\",\"name\":\"David Edwin Carlson\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1109/CVPR.2019.00649\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3b87e795f1f501843f7f99e83e38f125f6af8600\",\"title\":\"StoryGAN: A Sequential Conditional GAN for Story Visualization\",\"url\":\"https://www.semanticscholar.org/paper/3b87e795f1f501843f7f99e83e38f125f6af8600\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-58583-9_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"title\":\"Multi-view Action Recognition Using Cross-View Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394540217\",\"name\":\"Gao Wanshun\"},{\"authorId\":\"47696756\",\"name\":\"Wang Zhong-hao\"}],\"doi\":\"10.1109/ICACI.2018.8377529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90f66ec888f693241b423ef9c2612c840b005553\",\"title\":\"Max-margin generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/90f66ec888f693241b423ef9c2612c840b005553\",\"venue\":\"2018 Tenth International Conference on Advanced Computational Intelligence (ICACI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102255414\",\"name\":\"Y. Kwon\"},{\"authorId\":\"2668884\",\"name\":\"S. Petrangeli\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2918969\",\"name\":\"Haoliang Wang\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"153571209\",\"name\":\"Viswanathan Swaminathan\"},{\"authorId\":\"145472944\",\"name\":\"H. Fuchs\"}],\"doi\":\"10.1007/978-3-030-58548-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95be0cac6347b6df9b41c6a03196047c9dc401ce\",\"title\":\"Rotationally-Temporally Consistent Novel View Synthesis of Human Performance Video\",\"url\":\"https://www.semanticscholar.org/paper/95be0cac6347b6df9b41c6a03196047c9dc401ce\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400408486\",\"name\":\"Garima Sharma\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"}],\"doi\":\"10.1007/978-3-030-51870-7_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5aabd468e2b8738a7487774d31e90e62b05f726\",\"title\":\"A Survey on Automatic Multimodal Emotion Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f5aabd468e2b8738a7487774d31e90e62b05f726\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2008.12595\",\"authors\":[{\"authorId\":\"1780746\",\"name\":\"Laurent Girin\"},{\"authorId\":\"1996023\",\"name\":\"Simon Leglaive\"},{\"authorId\":\"35508778\",\"name\":\"Xiaoyu Bie\"},{\"authorId\":\"1678896\",\"name\":\"J. Diard\"},{\"authorId\":\"2159078\",\"name\":\"T. Hueber\"},{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ad9db9f7a3a6f9c14b0ede8c25aa2e65f0e65d7\",\"title\":\"Dynamical Variational Autoencoders: A Comprehensive Review\",\"url\":\"https://www.semanticscholar.org/paper/0ad9db9f7a3a6f9c14b0ede8c25aa2e65f0e65d7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48954595\",\"name\":\"Akanksha Sharma\"},{\"authorId\":\"2150759\",\"name\":\"Neeru Jindal\"},{\"authorId\":\"145480208\",\"name\":\"A. Thakur\"}],\"doi\":\"10.1109/ICSCCC.2018.8703267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86f8de55fd90b6ff3c43c7846abdd5c40b46ad10\",\"title\":\"Comparison on Generative Adversarial Networks \\u2013A Study\",\"url\":\"https://www.semanticscholar.org/paper/86f8de55fd90b6ff3c43c7846abdd5c40b46ad10\",\"venue\":\"2018 First International Conference on Secure Cyber Computing and Communication (ICSCCC)\",\"year\":2018},{\"arxivId\":\"1711.09165\",\"authors\":[{\"authorId\":\"3407358\",\"name\":\"Ershad Banijamali\"},{\"authorId\":\"1905469\",\"name\":\"Ahmad Khajenezhad\"},{\"authorId\":\"38565890\",\"name\":\"A. Ghodsi\"},{\"authorId\":\"1678622\",\"name\":\"M. Ghavamzadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267ec67d3d1b8295d937ee05870b643065ebcaf5\",\"title\":\"Disentangling Dynamics and Content for Control and Planning\",\"url\":\"https://www.semanticscholar.org/paper/267ec67d3d1b8295d937ee05870b643065ebcaf5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1806.04166\",\"authors\":[{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d38ee16ed990689c3a85160dbc20e22b72afb6d\",\"title\":\"Learning to Decompose and Disentangle Representations for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1d38ee16ed990689c3a85160dbc20e22b72afb6d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.00154\",\"authors\":[{\"authorId\":\"50178247\",\"name\":\"Najmeh Sadoughi\"},{\"authorId\":\"2106794\",\"name\":\"C. Busso\"}],\"doi\":\"10.1109/TAFFC.2019.2916031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b0e2250a2eb250682cfef8e369742cf10d0dfa2\",\"title\":\"Speech-Driven Expressive Talking Lips with Conditional Sequential Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b0e2250a2eb250682cfef8e369742cf10d0dfa2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.05856\",\"authors\":[{\"authorId\":\"48002920\",\"name\":\"Hongyuan Yu\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"150192018\",\"name\":\"Lihong Pi\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8ac4c4c5dacd16a3a06fe75f95564af0a1d0a79\",\"title\":\"Recurrent Deconvolutional Generative Adversarial Networks with Application to Text Guided Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/e8ac4c4c5dacd16a3a06fe75f95564af0a1d0a79\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"title\":\"A Two-Stream Variational Adversarial Network for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65861787\",\"name\":\"Jielin Qiu\"},{\"authorId\":\"50775220\",\"name\":\"G. Huang\"},{\"authorId\":\"1684927\",\"name\":\"T. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee1185ea5c16fde7f1af8c0eda810a5200246cd1\",\"title\":\"A Model Cortical Network for Spatiotemporal Sequence Learning and Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ee1185ea5c16fde7f1af8c0eda810a5200246cd1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.09346\",\"authors\":[{\"authorId\":\"8449394\",\"name\":\"A. Torfi\"},{\"authorId\":\"1705950\",\"name\":\"E. Fox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b0d23bc36b994a6afbea4339f629a5714cbb278\",\"title\":\"COR-GAN: Correlation-Capturing Convolutional Neural Networks for Generating Synthetic Healthcare Records\",\"url\":\"https://www.semanticscholar.org/paper/8b0d23bc36b994a6afbea4339f629a5714cbb278\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21697786\",\"name\":\"Zhenglin Geng\"},{\"authorId\":\"143773131\",\"name\":\"C. Cao\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"}],\"doi\":\"10.1007/s11263-020-01361-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57fb5abab8a90a22d46f014d184471046b2dcab4\",\"title\":\"Towards Photo-Realistic Facial Expression Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/57fb5abab8a90a22d46f014d184471046b2dcab4\",\"venue\":\"Int. J. Comput. Vis.\",\"year\":2020},{\"arxivId\":\"1910.11106\",\"authors\":[{\"authorId\":\"70616844\",\"name\":\"David M. Donahue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf2c83107bec96fae2d7928190f41f2f0a27ef0f\",\"title\":\"Label-Conditioned Next-Frame Video Generation with Neural Flows\",\"url\":\"https://www.semanticscholar.org/paper/cf2c83107bec96fae2d7928190f41f2f0a27ef0f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34413657\",\"name\":\"G. Shen\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1145/3343031.3350981\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42733f865df60e735014097f7136cb13bfda0351\",\"title\":\"Facial Image-to-Video Translation by a Hidden Affine Transformation\",\"url\":\"https://www.semanticscholar.org/paper/42733f865df60e735014097f7136cb13bfda0351\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19207644\",\"name\":\"M. \\u0160kali\\u010d\"},{\"authorId\":\"143903771\",\"name\":\"J. Jim\\u00e9nez\"},{\"authorId\":\"2689124\",\"name\":\"Davide Sabbadin\"},{\"authorId\":null,\"name\":\"Gianni De Fabritiis\"}],\"doi\":\"10.1021/acs.jcim.8b00706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d203dce25fd45dfc0c6f154f6558b046a6d25011\",\"title\":\"Shape-Based Generative Modeling for de Novo Drug Design\",\"url\":\"https://www.semanticscholar.org/paper/d203dce25fd45dfc0c6f154f6558b046a6d25011\",\"venue\":\"J. Chem. Inf. Model.\",\"year\":2019},{\"arxivId\":\"2006.05132\",\"authors\":[{\"authorId\":\"145196525\",\"name\":\"A. Jabbar\"},{\"authorId\":\"121856937\",\"name\":\"X. Li\"},{\"authorId\":\"1739254961\",\"name\":\"Bourahla Omar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d54d8c402785006faaf5de19e81f04eb484a3aa2\",\"title\":\"A Survey on Generative Adversarial Networks: Variants, Applications, and Training\",\"url\":\"https://www.semanticscholar.org/paper/d54d8c402785006faaf5de19e81f04eb484a3aa2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46602660\",\"name\":\"Thanh-Hai Tran\"},{\"authorId\":\"1565673788\",\"name\":\"Viet-Dung Bach\"},{\"authorId\":\"1909194\",\"name\":\"H. Doan\"}],\"doi\":\"10.1007/978-981-15-3651-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a0c50fae31bfc064de96820520a4bcc8ae3f7ab\",\"title\":\"vi-MoCoGAN: A Variant of MoCoGAN for Video Generation of Human Hand Gestures Under Different Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/5a0c50fae31bfc064de96820520a4bcc8ae3f7ab\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22803355\",\"name\":\"Beibei Jin\"},{\"authorId\":\"145957556\",\"name\":\"Rong Zhou\"},{\"authorId\":\"2357433\",\"name\":\"Zhisheng Zhang\"},{\"authorId\":\"144124218\",\"name\":\"M. Dai\"}],\"doi\":\"10.1109/M2VIP.2018.8600864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f30062e3cec68bb313e38e5134e24e25ebb73f65\",\"title\":\"Unsupervised Video Prediction Network with Spatio-temporal Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/f30062e3cec68bb313e38e5134e24e25ebb73f65\",\"venue\":\"2018 25th International Conference on Mechatronics and Machine Vision in Practice (M2VIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48954595\",\"name\":\"Akanksha Sharma\"},{\"authorId\":\"2150759\",\"name\":\"Neeru Jindal\"},{\"authorId\":\"1828828101\",\"name\":\"P. S. Rana\"}],\"doi\":\"10.1007/s11042-020-09308-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"488f1390252f68695957a74ac16f0958c9155f24\",\"title\":\"Potential of generative adversarial net algorithms in image and video processing applications\\u2013 a survey\",\"url\":\"https://www.semanticscholar.org/paper/488f1390252f68695957a74ac16f0958c9155f24\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2007.15240\",\"authors\":[{\"authorId\":\"1794679\",\"name\":\"C. Guo\"},{\"authorId\":\"2407738\",\"name\":\"Xinxin Zuo\"},{\"authorId\":\"1768118967\",\"name\":\"Sen Wang\"},{\"authorId\":\"9399556\",\"name\":\"Shihao Zou\"},{\"authorId\":\"1841581716\",\"name\":\"Qingyao Sun\"},{\"authorId\":\"1841709579\",\"name\":\"Annan Deng\"},{\"authorId\":\"1473876432\",\"name\":\"M. Gong\"},{\"authorId\":\"145193182\",\"name\":\"L. Cheng\"}],\"doi\":\"10.1145/3394171.3413635\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b7b4996858b91bc4db5dd5ce13215b5422591529\",\"title\":\"Action2Motion: Conditioned Generation of 3D Human Motions\",\"url\":\"https://www.semanticscholar.org/paper/b7b4996858b91bc4db5dd5ce13215b5422591529\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1710.00421\",\"authors\":[{\"authorId\":\"2664705\",\"name\":\"Y. Li\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144752689\",\"name\":\"David Edwin Carlson\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"title\":\"Video Generation From Text\",\"url\":\"https://www.semanticscholar.org/paper/3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143758901\",\"name\":\"Jungbeom Lee\"},{\"authorId\":\"3300485\",\"name\":\"J. Lee\"},{\"authorId\":\"153310690\",\"name\":\"Sungmin Lee\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca39fe1518cd12fcbc9c653fcf6c79949be236ef\",\"title\":\"Mutual Suppression Network for Video Prediction using Disentangled Features\",\"url\":\"https://www.semanticscholar.org/paper/ca39fe1518cd12fcbc9c653fcf6c79949be236ef\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1903.12161\",\"authors\":[{\"authorId\":\"1413064976\",\"name\":\"S. Caelles\"},{\"authorId\":\"49107901\",\"name\":\"Albert Pumarola\"},{\"authorId\":\"1397181875\",\"name\":\"F. Moreno-Noguer\"},{\"authorId\":\"49743313\",\"name\":\"A. Sanfeliu\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8b83e7e26a22891cab3907079f392366cf4cfa4\",\"title\":\"Fast video object segmentation with Spatio-Temporal GANs\",\"url\":\"https://www.semanticscholar.org/paper/c8b83e7e26a22891cab3907079f392366cf4cfa4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.01523\",\"authors\":[{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"title\":\"Stochastic Adversarial Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1911.02001\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"47008546\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"153699069\",\"name\":\"Mingyu Liu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"8646392\",\"name\":\"Yu-Ding Lu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"title\":\"Dancing to Music\",\"url\":\"https://www.semanticscholar.org/paper/12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10753214\",\"name\":\"Aliaksandr Siarohin\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b473ad2bf0348c8a912c3af206fbf275f286320\",\"title\":\"Animating Arbitrary Objects via Deep Motion Transfer Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/4b473ad2bf0348c8a912c3af206fbf275f286320\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cfb522acca27ee7b0cdd1e4a8f5af492ac5c87d\",\"title\":\"G3AN: This video does not exist. Disentangling motion and appearance for video generation\",\"url\":\"https://www.semanticscholar.org/paper/8cfb522acca27ee7b0cdd1e4a8f5af492ac5c87d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.03142\",\"authors\":[{\"authorId\":\"48116039\",\"name\":\"Jian Ren\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dce3f80b0e1f43aa6fa94288710da0a5bdae2a9d\",\"title\":\"Human Motion Transfer from Poses in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/dce3f80b0e1f43aa6fa94288710da0a5bdae2a9d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.09077\",\"authors\":[{\"authorId\":\"145503864\",\"name\":\"M. Chaabane\"},{\"authorId\":\"50877557\",\"name\":\"A. Trabelsi\"},{\"authorId\":\"2963886\",\"name\":\"N. Blanchard\"},{\"authorId\":\"143905691\",\"name\":\"J. Beveridge\"}],\"doi\":\"10.1109/WACV45572.2020.9093426\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b58038ab32141eab536ddadd21f87077808ab53\",\"title\":\"Looking Ahead: Anticipating Pedestrians Crossing with Future Frames Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4b58038ab32141eab536ddadd21f87077808ab53\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1806.01794\",\"authors\":[{\"authorId\":\"7497792\",\"name\":\"Adam R. Kosiorek\"},{\"authorId\":\"3407176\",\"name\":\"Hyunjik Kim\"},{\"authorId\":\"1834086\",\"name\":\"I. Posner\"},{\"authorId\":\"1725303\",\"name\":\"Y. Teh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8928371206f313d409eeb5242d646a8e71061d90\",\"title\":\"Sequential Attend, Infer, Repeat: Generative Modelling of Moving Objects\",\"url\":\"https://www.semanticscholar.org/paper/8928371206f313d409eeb5242d646a8e71061d90\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8449394\",\"name\":\"A. Torfi\"},{\"authorId\":\"1705950\",\"name\":\"E. Fox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a5ad87449ab75dbc281a229c8b08e6baa8413e9\",\"title\":\"CorGAN: Correlation-Capturing Convolutional Generative Adversarial Networks for Generating Synthetic Healthcare Records\",\"url\":\"https://www.semanticscholar.org/paper/5a5ad87449ab75dbc281a229c8b08e6baa8413e9\",\"venue\":\"FLAIRS Conference\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47883221\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1007/s11263-020-01389-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e81249d8f00e54a627785a47e62c694cce119e3\",\"title\":\"Progressive Multi-granularity Analysis for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6e81249d8f00e54a627785a47e62c694cce119e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.08614\",\"authors\":[{\"authorId\":\"1729222937\",\"name\":\"P. Sreekar\"},{\"authorId\":\"121701447\",\"name\":\"U. Tiwari\"},{\"authorId\":\"3185334\",\"name\":\"A. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a391f92d0479295f24043bc388ce5bd292fab0e5\",\"title\":\"Mutual Information Based Method for Unsupervised Disentanglement of Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/a391f92d0479295f24043bc388ce5bd292fab0e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.09412\",\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018263\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c970f99e844f774236511a40bf43b8950dde339f\",\"title\":\"Cubic LSTMs for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c970f99e844f774236511a40bf43b8950dde339f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1466503743\",\"name\":\"X. Ren\"},{\"authorId\":\"49403981\",\"name\":\"H. Li\"},{\"authorId\":\"1993645766\",\"name\":\"Zijian Huang\"},{\"authorId\":\"1559427865\",\"name\":\"Qifeng Chen\"}],\"doi\":\"10.1145/3394171.3413932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d3af080ac123a224a40ab0bb2929d63061451ee\",\"title\":\"Self-supervised Dance Video Synthesis Conditioned on Music\",\"url\":\"https://www.semanticscholar.org/paper/6d3af080ac123a224a40ab0bb2929d63061451ee\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143692919\",\"name\":\"Ying Tan\"},{\"authorId\":\"144792066\",\"name\":\"B. Shi\"}],\"doi\":\"10.1007/978-3-030-26369-0_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3902975179ca4986d7e8951d66c0ef6dc1aaceb8\",\"title\":\"Generative Adversarial Optimization\",\"url\":\"https://www.semanticscholar.org/paper/3902975179ca4986d7e8951d66c0ef6dc1aaceb8\",\"venue\":\"ICSI\",\"year\":2019},{\"arxivId\":\"1812.10587\",\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"9659905\",\"name\":\"Ruiqi Gao\"},{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1609/aaai.v33i01.33015498\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b4b2787aed8b1652f5268c6b7dbfd63d9795939\",\"title\":\"Learning Dynamic Generator Model by Alternating Back-Propagation Through Time\",\"url\":\"https://www.semanticscholar.org/paper/7b4b2787aed8b1652f5268c6b7dbfd63d9795939\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746387\",\"name\":\"Xin Jin\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"89187407\",\"name\":\"W. Li\"}],\"doi\":\"10.1016/j.patcog.2019.107143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc2c28f85fcc6380e759a92c6d85aab11b693e83\",\"title\":\"AI-GAN: Asynchronous interactive generative adversarial network for single image rain removal\",\"url\":\"https://www.semanticscholar.org/paper/cc2c28f85fcc6380e759a92c6d85aab11b693e83\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1911.11544\",\"authors\":[{\"authorId\":\"94395014\",\"name\":\"Rameen Abdal\"},{\"authorId\":\"2408885\",\"name\":\"Yipeng Qin\"},{\"authorId\":\"1798011\",\"name\":\"Peter Wonka\"}],\"doi\":\"10.1109/cvpr42600.2020.00832\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95d0a22672cd9e4e943648fbe73df4a6fd290d7f\",\"title\":\"Image2StyleGAN++: How to Edit the Embedded Images?\",\"url\":\"https://www.semanticscholar.org/paper/95d0a22672cd9e4e943648fbe73df4a6fd290d7f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50190972\",\"name\":\"Dan Zeng\"},{\"authorId\":\"1753948451\",\"name\":\"Han Liu\"},{\"authorId\":\"46933412\",\"name\":\"H. Lin\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1145/3394171.3413844\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"79a511eca03dbfd0b48bd876f6bc99ca1690d1cc\",\"title\":\"Talking Face Generation with Expression-Tailored Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/79a511eca03dbfd0b48bd876f6bc99ca1690d1cc\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.11376\",\"authors\":[{\"authorId\":\"11064745\",\"name\":\"Raha Moraffah\"},{\"authorId\":\"3375132\",\"name\":\"Bahman Moraffah\"},{\"authorId\":\"145084368\",\"name\":\"Mansooreh Karami\"},{\"authorId\":\"19251475\",\"name\":\"A. Raglin\"},{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa358792257a9016f5f6ab74dcafd15d19f28b31\",\"title\":\"CAN: A Causal Adversarial Network for Learning Observational and Interventional Distributions\",\"url\":\"https://www.semanticscholar.org/paper/aa358792257a9016f5f6ab74dcafd15d19f28b31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.07461\",\"authors\":[{\"authorId\":\"40897818\",\"name\":\"Seyed Ali Jalalifar\"},{\"authorId\":\"40480237\",\"name\":\"H. Hasani\"},{\"authorId\":\"32609045\",\"name\":\"H. Aghajan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3774776f2a5ec29c946a89d6ad6b6e16d2f471ec\",\"title\":\"Speech-Driven Facial Reenactment Using Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3774776f2a5ec29c946a89d6ad6b6e16d2f471ec\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.03962\",\"authors\":[{\"authorId\":\"46207499\",\"name\":\"Leonhard Helminger\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"145848224\",\"name\":\"R. Weber\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94239dda3c207b734331073a0f7eea25fe8571cf\",\"title\":\"Disentangled Dynamic Representations from Unordered Data\",\"url\":\"https://www.semanticscholar.org/paper/94239dda3c207b734331073a0f7eea25fe8571cf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326507\",\"name\":\"L. Liao\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"48363848\",\"name\":\"J. Xiao\"},{\"authorId\":\"38655501\",\"name\":\"Zhongyuan Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2905268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c434ef9d6d4eedca6e7b3903f2c567978c056999\",\"title\":\"Artist-Net: Decorating the Inferred Content With Unified Style for Image Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/c434ef9d6d4eedca6e7b3903f2c567978c056999\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1910.02027\",\"authors\":[{\"authorId\":\"49170402\",\"name\":\"Yunji Kim\"},{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\"},{\"authorId\":\"4078629\",\"name\":\"I. Cho\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"882fc8a75baf03a01dd18385f50728bada85ed6a\",\"title\":\"Unsupervised Keypoint Learning for Guiding Class-Conditional Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/882fc8a75baf03a01dd18385f50728bada85ed6a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323584\",\"name\":\"A. Malhotra\"},{\"authorId\":\"153571209\",\"name\":\"Viswanathan Swaminathan\"},{\"authorId\":\"145394457\",\"name\":\"G. Wu\"},{\"authorId\":\"2741560\",\"name\":\"I. Schizas\"}],\"doi\":\"10.1109/MMSP.2019.8901706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d010349436a65f91f03d574597d44689cf83ae7\",\"title\":\"Generative Networks for Synthesizing Human Videos in Text-Defined Outfits\",\"url\":\"https://www.semanticscholar.org/paper/6d010349436a65f91f03d574597d44689cf83ae7\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50631209\",\"name\":\"N. Yashwanth\"},{\"authorId\":\"152678516\",\"name\":\"P. Navya\"},{\"authorId\":\"121017419\",\"name\":\"Md. Rukhiya\"},{\"authorId\":null,\"name\":\"K. S. V. Prasad\"},{\"authorId\":\"6936812\",\"name\":\"K. S. Deepthi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c31616144f2b2f1fd351f48a739eefb99bc78db\",\"title\":\"Survey on generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/9c31616144f2b2f1fd351f48a739eefb99bc78db\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35494343\",\"name\":\"Pranjal Sahu\"},{\"authorId\":\"33830021\",\"name\":\"D. Yu\"},{\"authorId\":\"1780708\",\"name\":\"K. Yager\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"145199626\",\"name\":\"H. Qin\"}],\"doi\":\"10.1145/3217197.3217204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc4b1a6ac94d3af019d4a0db089cafa6b5c701cb\",\"title\":\"In-Operando Tracking and Prediction of Transition in Material System using LSTM\",\"url\":\"https://www.semanticscholar.org/paper/dc4b1a6ac94d3af019d4a0db089cafa6b5c701cb\",\"venue\":\"AI-Science@HPDC\",\"year\":2018},{\"arxivId\":\"1910.05026\",\"authors\":[{\"authorId\":\"50067121\",\"name\":\"Alex Bird\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c408b44423f21016b11d1b77632f6b5044aa44d\",\"title\":\"Customizing Sequence Generation with Multi-Task Dynamical Systems\",\"url\":\"https://www.semanticscholar.org/paper/5c408b44423f21016b11d1b77632f6b5044aa44d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.11585\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/CVPR.2018.00917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851\",\"title\":\"High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs\",\"url\":\"https://www.semanticscholar.org/paper/f0a0c0f0d6a7ff53abea40a8c0c678ed570bf851\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.06364\",\"authors\":[{\"authorId\":\"145582147\",\"name\":\"Rodrigo de Bem\"},{\"authorId\":\"143606226\",\"name\":\"A. Ghosh\"},{\"authorId\":\"144722114\",\"name\":\"Thalaiyasingam Ajanthan\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"},{\"authorId\":\"2984583\",\"name\":\"Adnane Boukhayma\"},{\"authorId\":\"40155668\",\"name\":\"N. Siddharth\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1007/s11263-020-01306-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa747db22e9e6cd7a64019eec6e0dd53e94be4b3\",\"title\":\"DGPose: Deep Generative Models for Human Body Analysis\",\"url\":\"https://www.semanticscholar.org/paper/fa747db22e9e6cd7a64019eec6e0dd53e94be4b3\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2007.13098\",\"authors\":[{\"authorId\":\"151230204\",\"name\":\"Hongtao Yang\"},{\"authorId\":\"49104770\",\"name\":\"T. Zhang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1145/3422852.3423480\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2d5620d12d3c9a6620200185fd0206ff51e2a6b\",\"title\":\"Towards Purely Unsupervised Disentanglement of Appearance and Shape for Person Images Generation\",\"url\":\"https://www.semanticscholar.org/paper/c2d5620d12d3c9a6620200185fd0206ff51e2a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51189950\",\"name\":\"M. C. Comes\"},{\"authorId\":\"1564226524\",\"name\":\"J. Filippi\"},{\"authorId\":\"1717202\",\"name\":\"A. Mencattini\"},{\"authorId\":\"47233879\",\"name\":\"P. Casti\"},{\"authorId\":\"153937073\",\"name\":\"G. Cerrato\"},{\"authorId\":\"7019503\",\"name\":\"A. Sauvat\"},{\"authorId\":\"5049762\",\"name\":\"E. Vacchelli\"},{\"authorId\":\"7429517\",\"name\":\"A. De Ninno\"},{\"authorId\":\"26627439\",\"name\":\"D. Di Giuseppe\"},{\"authorId\":\"1561708132\",\"name\":\"M. D'Orazio\"},{\"authorId\":\"98905579\",\"name\":\"F. Mattei\"},{\"authorId\":\"103903938\",\"name\":\"G. Schiavoni\"},{\"authorId\":\"2281062\",\"name\":\"L. Businaro\"},{\"authorId\":\"48258172\",\"name\":\"C. Di Natale\"},{\"authorId\":\"145056884\",\"name\":\"G. Kroemer\"},{\"authorId\":\"1664192352\",\"name\":\"E. Martinelli\"}],\"doi\":\"10.1007/s00521-020-05226-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c72442cc6bef3bf0d0fe61c13895bb687d5442a\",\"title\":\"Multi-scale generative adversarial network for improved evaluation of cell\\u2013cell interactions observed in organ-on-chip experiments\",\"url\":\"https://www.semanticscholar.org/paper/6c72442cc6bef3bf0d0fe61c13895bb687d5442a\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66438378\",\"name\":\"Kongtao Zhu\"},{\"authorId\":\"3300934\",\"name\":\"Xiwei Liu\"},{\"authorId\":\"27391286\",\"name\":\"Hongxue Yang\"}],\"doi\":\"10.1109/CAC.2018.8623645\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f571725ffc18c6249702ab457b287495302a4e68\",\"title\":\"A Survey of Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f571725ffc18c6249702ab457b287495302a4e68\",\"venue\":\"2018 Chinese Automation Congress (CAC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46197900\",\"name\":\"F. Roche\"},{\"authorId\":\"2159078\",\"name\":\"T. Hueber\"},{\"authorId\":\"51044751\",\"name\":\"Samuel Limier\"},{\"authorId\":\"1780746\",\"name\":\"Laurent Girin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6505b1d4d2485d91304dc267fc12332e1ccdd008\",\"title\":\"Autoencoders for music sound modeling: a comparison of linear, shallow, deep, recurrent and variational models\",\"url\":\"https://www.semanticscholar.org/paper/6505b1d4d2485d91304dc267fc12332e1ccdd008\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.01766\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"49588480\",\"name\":\"A. Myers\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2019.00756\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c41a11c0e9b8b92b4faaf97749841170b760760a\",\"title\":\"VideoBERT: A Joint Model for Video and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/c41a11c0e9b8b92b4faaf97749841170b760760a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae02e601eae125ce137324c678ab68e9ab272ea0\",\"title\":\"Self-supervised learning of predictive segmentation models from video\",\"url\":\"https://www.semanticscholar.org/paper/ae02e601eae125ce137324c678ab68e9ab272ea0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.11376\",\"authors\":[{\"authorId\":\"11064745\",\"name\":\"Raha Moraffah\"},{\"authorId\":\"3375132\",\"name\":\"Bahman Moraffah\"},{\"authorId\":\"145084368\",\"name\":\"Mansooreh Karami\"},{\"authorId\":\"19251475\",\"name\":\"A. Raglin\"},{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e005ccfb430f960c522c1eef6916585dbf2b7637\",\"title\":\"Causal Adversarial Network for Learning Conditional and Interventional Distributions.\",\"url\":\"https://www.semanticscholar.org/paper/e005ccfb430f960c522c1eef6916585dbf2b7637\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"2453402\",\"name\":\"Meng-Yao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"53ea5e0448c309c3614bba25bac58f46f06690c7\",\"title\":\"Zero-Shot Generation of Human-Object Interaction Videos\",\"url\":\"https://www.semanticscholar.org/paper/53ea5e0448c309c3614bba25bac58f46f06690c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7040e2a78bdb6ed01c237e52f0ace6c4f8608ba2\",\"title\":\"Unsupervised Learning of Sensorimotor Affordances by Stochastic Future Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7040e2a78bdb6ed01c237e52f0ace6c4f8608ba2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"144811736\",\"name\":\"L. Jiang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eb604863b671763de17905ad715a225d9fe43e9\",\"title\":\"Unit Frame 3 : T + 2 Frame 1 : T Frame 2 : T + 1 FrameT + 1 FrameT + 2 FrameT + 3\",\"url\":\"https://www.semanticscholar.org/paper/2eb604863b671763de17905ad715a225d9fe43e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1679427\",\"name\":\"Marina L. Gavrilova\"},{\"authorId\":\"144891213\",\"name\":\"Jian Chang\"},{\"authorId\":\"41183001\",\"name\":\"Nadia Magnenat Thalmann\"},{\"authorId\":\"3278789\",\"name\":\"Eckhard Hitzer\"},{\"authorId\":\"145102331\",\"name\":\"Hiroshi Ishikawa\"}],\"doi\":\"10.1007/978-3-030-22514-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a4583c3db9ffb78c8942b0054024465033a76d2\",\"title\":\"Advances in Computer Graphics\",\"url\":\"https://www.semanticscholar.org/paper/8a4583c3db9ffb78c8942b0054024465033a76d2\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8407304\",\"name\":\"Jeong-Woo Son\"},{\"authorId\":\"114781093\",\"name\":\"Han Min-Ho\"},{\"authorId\":\"102897760\",\"name\":\"Kim Sun-Joong\"}],\"doi\":\"10.22648/ETRI.2019.J.340304\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4de8acb1d62e9f0c131d05a2f2246bab67f7e0ab\",\"title\":\"Artificial Intelligence-Based Video Content Generation\",\"url\":\"https://www.semanticscholar.org/paper/4de8acb1d62e9f0c131d05a2f2246bab67f7e0ab\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1605999515\",\"name\":\"Rakib Hyder\"},{\"authorId\":\"27996204\",\"name\":\"M. Asif\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"34697d133f69201a5fab15fdf60dacda01314bd2\",\"title\":\"Non-Adversarial Video Synthesis with Learned Priors (Supplementary Material)\",\"url\":\"https://www.semanticscholar.org/paper/34697d133f69201a5fab15fdf60dacda01314bd2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38973849\",\"name\":\"Fatma Ben Aissa\"},{\"authorId\":\"2769143\",\"name\":\"M. Mejdoub\"},{\"authorId\":\"1730155\",\"name\":\"M. Zaied\"}],\"doi\":\"10.1117/12.2559848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe50822a700c7104f8d7e6fcb797103ee5f903dd\",\"title\":\"A survey on generative adversarial networks and their variants methods\",\"url\":\"https://www.semanticscholar.org/paper/fe50822a700c7104f8d7e6fcb797103ee5f903dd\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":\"1908.07683\",\"authors\":[{\"authorId\":\"150176607\",\"name\":\"KwanYong Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3343031.3350864\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"title\":\"Preserving Semantic and Temporal Consistency for Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/e12184b519c14d6964d1ab45ff13fd87f24891c5\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121811973\",\"name\":\"Xiangli Ji\"},{\"authorId\":\"103717726\",\"name\":\"Bairong Li\"},{\"authorId\":\"2073517\",\"name\":\"Yuesheng Zhu\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207231\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e67f4b94716f22f02058a49068e256cd0c074f1\",\"title\":\"TAM-Net: Temporal Enhanced Appearance-to-Motion Generative Network for Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/0e67f4b94716f22f02058a49068e256cd0c074f1\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.11252\",\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"143775101\",\"name\":\"R. Campbell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"title\":\"Stochastic Variational Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"2008.01352\",\"authors\":[{\"authorId\":\"1853488882\",\"name\":\"J'er'emie Dona\"},{\"authorId\":\"35622441\",\"name\":\"Jean-Yves Franceschi\"},{\"authorId\":\"1782552\",\"name\":\"Sylvain Lamprier\"},{\"authorId\":\"150259685\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9130668c2927ee5989854e09ad565a2dd1bd6391\",\"title\":\"PDE-Driven Spatiotemporal Disentanglement\",\"url\":\"https://www.semanticscholar.org/paper/9130668c2927ee5989854e09ad565a2dd1bd6391\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.14695\",\"authors\":[{\"authorId\":\"6044420\",\"name\":\"Risheng Huang\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1766319\",\"name\":\"Chu-Hsing Lin\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd9089461dadc59bbb3e40a90f9f281830d3bd6b\",\"title\":\"Adaptive Compact Attention For Few-shot Video-to-video Translation\",\"url\":\"https://www.semanticscholar.org/paper/dd9089461dadc59bbb3e40a90f9f281830d3bd6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.07991\",\"authors\":[{\"authorId\":\"1469066868\",\"name\":\"Yatin Dandi\"},{\"authorId\":\"19089337\",\"name\":\"Aniket Das\"},{\"authorId\":\"1466543874\",\"name\":\"Soumye Singhal\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"145593549\",\"name\":\"P. Rai\"}],\"doi\":\"10.1109/WACV45572.2020.9093308\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c33a293453240a02ee335b5b27d2b23c9882fb1b\",\"title\":\"Jointly Trained Image and Video Generation using Residual Vectors\",\"url\":\"https://www.semanticscholar.org/paper/c33a293453240a02ee335b5b27d2b23c9882fb1b\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.04035\",\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"40550616\",\"name\":\"D. Casas\"},{\"authorId\":\"2895238\",\"name\":\"Yotam Doron\"},{\"authorId\":\"51042571\",\"name\":\"Albin Cassirer\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"title\":\"Transformation-based Adversarial Video Prediction on Large-Scale Data\",\"url\":\"https://www.semanticscholar.org/paper/e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.12165\",\"authors\":[{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2019.00770\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a80e33fc646482b9fedc9f153238d960d670e5\",\"title\":\"Improved Conditional VRNNs for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/08a80e33fc646482b9fedc9f153238d960d670e5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2660868\",\"name\":\"Po-Hsiang Huang\"},{\"authorId\":\"41015732\",\"name\":\"Fu-En Yang\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e393f107578d250bec23c2c5d076b692001f128\",\"title\":\"Learning Identity-Invariant Motion Representations for Cross-ID Face Reenactment\",\"url\":\"https://www.semanticscholar.org/paper/5e393f107578d250bec23c2c5d076b692001f128\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395873384\",\"name\":\"Rui Zhao\"},{\"authorId\":\"1563539653\",\"name\":\"Hui Su\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1109/cvpr42600.2020.00626\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1fd40a93a0cdac88f53bf5612fa1604a897eea5\",\"title\":\"Bayesian Adversarial Human Motion Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/b1fd40a93a0cdac88f53bf5612fa1604a897eea5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1812.01874\",\"authors\":[{\"authorId\":\"5437547\",\"name\":\"Qiyang Hu\"},{\"authorId\":\"1822120361\",\"name\":\"Adrian Walchli\"},{\"authorId\":\"21529935\",\"name\":\"Tiziano Portenier\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bb74e29321772ea815f88769d31a902a2c3e996\",\"title\":\"Learning to Take Directions One Step at a Time\",\"url\":\"https://www.semanticscholar.org/paper/6bb74e29321772ea815f88769d31a902a2c3e996\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"},{\"authorId\":\"144538257\",\"name\":\"Y. Weiss\"}],\"doi\":\"10.1007/978-3-030-01228-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"474c8f4e31a51e2cb3c1e9fed83202b4483efb35\",\"title\":\"Computer Vision \\u2013 ECCV 2018\",\"url\":\"https://www.semanticscholar.org/paper/474c8f4e31a51e2cb3c1e9fed83202b4483efb35\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144620586\",\"name\":\"X. Wu\"},{\"authorId\":\"144024533\",\"name\":\"Kun Xu\"},{\"authorId\":\"144003456\",\"name\":\"P. Hall\"}],\"doi\":\"10.23919/TST.2017.8195348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"722514cf193ea8b301475de9da5a0061f2e47bdd\",\"title\":\"A survey of image synthesis and editing with generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/722514cf193ea8b301475de9da5a0061f2e47bdd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9653518\",\"name\":\"Yufei Ye\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"153701831\",\"name\":\"G. Sigurdsson\"},{\"authorId\":\"32424449\",\"name\":\"A. Murali\"},{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"145456137\",\"name\":\"Tao Chen\"},{\"authorId\":\"144177386\",\"name\":\"N. Kulkarni\"},{\"authorId\":null,\"name\":\"Wenxuan Zhou\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"7463216\",\"name\":\"Gaurav Pathak\"},{\"authorId\":\"50465425\",\"name\":\"P. Sharma\"},{\"authorId\":\"3393217\",\"name\":\"Dhiraj Gandhi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a933264cc20eab7859fa6002f4aaecbf89d09395\",\"title\":\"Leveraging Structure for Generalization and Prediction in Visual System\",\"url\":\"https://www.semanticscholar.org/paper/a933264cc20eab7859fa6002f4aaecbf89d09395\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.11104\",\"authors\":[{\"authorId\":\"1382655643\",\"name\":\"Facundo Tuesca\"},{\"authorId\":\"2588271\",\"name\":\"Lucas C. Uzal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e1ad81593de36b622e5d5c9b44e00496c73c240\",\"title\":\"Exploiting video sequences for unsupervised disentangling in generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/6e1ad81593de36b622e5d5c9b44e00496c73c240\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.01301\",\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"47103864\",\"name\":\"Yi-fei Xu\"},{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26e01ac7c24119c4a6b469ab737efe9df58c7ff7\",\"title\":\"Generative PointNet: Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification\",\"url\":\"https://www.semanticscholar.org/paper/26e01ac7c24119c4a6b469ab737efe9df58c7ff7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.09905\",\"authors\":[{\"authorId\":\"146270823\",\"name\":\"Beibei Jin\"},{\"authorId\":\"1943030\",\"name\":\"Y. Hu\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"66692321\",\"name\":\"Jingyu Niu\"},{\"authorId\":\"144578811\",\"name\":\"Z. Shi\"},{\"authorId\":\"152713339\",\"name\":\"Yinhe Han\"},{\"authorId\":\"40613624\",\"name\":\"Xiaowei Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00461\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a280048e69d41750c42d6f96e451e75c52c07741\",\"title\":\"Exploring Spatial-Temporal Multi-Frequency Analysis for High-Fidelity and Temporal-Consistency Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a280048e69d41750c42d6f96e451e75c52c07741\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.09165\",\"authors\":[{\"authorId\":\"76957736\",\"name\":\"Minhyeok Lee\"},{\"authorId\":\"3067436\",\"name\":\"Junhee Seok\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b5d1991cfcca4f868e7984146b169a486e038e2\",\"title\":\"Regularization Methods for Generative Adversarial Networks: An Overview of Recent Studies\",\"url\":\"https://www.semanticscholar.org/paper/4b5d1991cfcca4f868e7984146b169a486e038e2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13763932\",\"name\":\"Dongxu Wei\"},{\"authorId\":\"144838755\",\"name\":\"Xiaowei Xu\"},{\"authorId\":\"1888007\",\"name\":\"Haibin Shen\"},{\"authorId\":\"47942157\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/tmm.2020.3011290\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1df6cc2507dd90adaafe5f9915a261558b88008c\",\"title\":\"GAC-GAN: A General Method for Appearance-Controllable Human Video Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1df6cc2507dd90adaafe5f9915a261558b88008c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.09219\",\"authors\":[{\"authorId\":\"35622441\",\"name\":\"Jean-Yves Franceschi\"},{\"authorId\":\"32278921\",\"name\":\"Edouard Delasalles\"},{\"authorId\":\"51301828\",\"name\":\"Mickael Chen\"},{\"authorId\":\"1782552\",\"name\":\"Sylvain Lamprier\"},{\"authorId\":\"150259685\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"title\":\"Stochastic Latent Residual Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788247\",\"name\":\"K. Ridgeway\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"edc8fca49b9c1ebfd638a5b820b9deb0c0485d72\",\"title\":\"Content-Style Decomposition: Representation Discovery and Applications\",\"url\":\"https://www.semanticscholar.org/paper/edc8fca49b9c1ebfd638a5b820b9deb0c0485d72\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1805.09313\",\"authors\":[{\"authorId\":\"2160245\",\"name\":\"Konstantinos Vougioukas\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f722b0a7a9b7709d693b9d39195c779832a943fe\",\"title\":\"End-to-End Speech-Driven Facial Animation with Temporal GANs\",\"url\":\"https://www.semanticscholar.org/paper/f722b0a7a9b7709d693b9d39195c779832a943fe\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2004.01823\",\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"title\":\"Temporal Shift GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.09565\",\"authors\":[{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"12212948\",\"name\":\"Rakib Hyder\"},{\"authorId\":\"27996204\",\"name\":\"M. Asif\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/cvpr42600.2020.00613\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6a55aad6a51662da2d1e454a41878935a86a5d4a\",\"title\":\"Non-Adversarial Video Synthesis with Learned Priors\",\"url\":\"https://www.semanticscholar.org/paper/6a55aad6a51662da2d1e454a41878935a86a5d4a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1804.04810\",\"authors\":[{\"authorId\":\"143758901\",\"name\":\"Jungbeom Lee\"},{\"authorId\":\"2808551\",\"name\":\"Jangho Lee\"},{\"authorId\":\"47090426\",\"name\":\"Sungmin Lee\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3497be24bcecb698a700b02c12e23b305ea0c24c\",\"title\":\"MSnet: Mutual Suppression Network for Disentangled Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/3497be24bcecb698a700b02c12e23b305ea0c24c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.10427\",\"authors\":[{\"authorId\":\"2020968\",\"name\":\"Qunwei Li\"},{\"authorId\":\"1749353\",\"name\":\"B. Kailkhura\"},{\"authorId\":\"2860488\",\"name\":\"Rushil Anirudh\"},{\"authorId\":\"46432859\",\"name\":\"Y. Zhou\"},{\"authorId\":\"145097686\",\"name\":\"Y. Liang\"},{\"authorId\":\"1925309\",\"name\":\"P. Varshney\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52b97b4b1f379cd7317a5d987fe74a7134f6ed1c\",\"title\":\"MR-GAN: Manifold Regularized Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/52b97b4b1f379cd7317a5d987fe74a7134f6ed1c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145582147\",\"name\":\"Rodrigo de Bem\"},{\"authorId\":\"144317747\",\"name\":\"A. Ghosh\"},{\"authorId\":\"144722114\",\"name\":\"Thalaiyasingam Ajanthan\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1007/978-3-030-11012-3_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26d06d00bdacb4864399b9c701ab00f30f5b468d\",\"title\":\"A Semi-supervised Deep Generative Model for Human Body Analysis\",\"url\":\"https://www.semanticscholar.org/paper/26d06d00bdacb4864399b9c701ab00f30f5b468d\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17659319\",\"name\":\"Zackary P. T. Sin\"},{\"authorId\":\"2774268\",\"name\":\"P. H. Ng\"},{\"authorId\":\"1738911\",\"name\":\"S. Shiu\"},{\"authorId\":\"145288211\",\"name\":\"K. Chung\"},{\"authorId\":\"1714454\",\"name\":\"H. Leong\"}],\"doi\":\"10.1145/3297280.3297301\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"a1cf969cca9a3dcbe042ecf0a4a0ec5bb80022c1\",\"title\":\"2D character animating networks: bringing static characters to move via motion transfer\",\"url\":\"https://www.semanticscholar.org/paper/a1cf969cca9a3dcbe042ecf0a4a0ec5bb80022c1\",\"venue\":\"SAC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"2388085\",\"name\":\"M. K\\u00f6rner\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fc9b202107bafa4b755c913c904d8ab046b8113\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing Autoencoder GANs\",\"url\":\"https://www.semanticscholar.org/paper/0fc9b202107bafa4b755c913c904d8ab046b8113\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2160245\",\"name\":\"Konstantinos Vougioukas\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aed99738a2ad6d99bad710bdf4938de3403221be\",\"title\":\"End-to-End Speech-Driven Realistic Facial Animation with Temporal GANs\",\"url\":\"https://www.semanticscholar.org/paper/aed99738a2ad6d99bad710bdf4938de3403221be\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151368062\",\"name\":\"Yukitaka Tsuchiya\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"41015901\",\"name\":\"R. Natsume\"},{\"authorId\":\"48333526\",\"name\":\"S. Yamamoto\"},{\"authorId\":\"1707631\",\"name\":\"T. Kato\"},{\"authorId\":\"1731030\",\"name\":\"S. Morishima\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1fb788324287f7e7d84606f32f1878196764b36\",\"title\":\"Generating Video from Single Image and Sound\",\"url\":\"https://www.semanticscholar.org/paper/c1fb788324287f7e7d84606f32f1878196764b36\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49351324\",\"name\":\"A. Grigor'ev\"},{\"authorId\":\"10784511\",\"name\":\"A. Sevastopolsky\"},{\"authorId\":\"144029627\",\"name\":\"Alexander Vakhitov\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":\"10.1109/CVPR.2019.01241\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddeb225eb472c9aab1b86ba8f30c8dc937445b3e\",\"title\":\"Coordinate-Based Texture Inpainting for Pose-Guided Human Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/ddeb225eb472c9aab1b86ba8f30c8dc937445b3e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.05253\",\"authors\":[{\"authorId\":\"22770939\",\"name\":\"Tsai-Ho Sun\"},{\"authorId\":\"1685457535\",\"name\":\"Chien-Hsun Lai\"},{\"authorId\":\"1992587\",\"name\":\"S. Wong\"},{\"authorId\":null,\"name\":\"Yu-Shuen Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc6ae3b30cf755a944995e8d96ffe088c829e2c6\",\"title\":\"Adversarial Colorization Of Icons Based On Structure And Color Conditions\",\"url\":\"https://www.semanticscholar.org/paper/cc6ae3b30cf755a944995e8d96ffe088c829e2c6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.09139\",\"authors\":[{\"authorId\":\"7164154\",\"name\":\"Polina Zablotskaia\"},{\"authorId\":\"10753214\",\"name\":\"Aliaksandr Siarohin\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2706b994697b1653a5bf72c64061f517c062f86\",\"title\":\"DwNet: Dense warp-based network for pose-guided human video generation\",\"url\":\"https://www.semanticscholar.org/paper/e2706b994697b1653a5bf72c64061f517c062f86\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2207742\",\"name\":\"F. Marulli\"},{\"authorId\":\"1717023\",\"name\":\"C. A. Visaggio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a5322de9c577229d9f32d0bc2986921257ee4b6f\",\"title\":\"Adversarial deep learning for energy management in buildings\",\"url\":\"https://www.semanticscholar.org/paper/a5322de9c577229d9f32d0bc2986921257ee4b6f\",\"venue\":\"SummerSim\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":\"1905.01680\",\"authors\":[{\"authorId\":\"3451442\",\"name\":\"Kfir Aberman\"},{\"authorId\":\"1406236938\",\"name\":\"Rundi Wu\"},{\"authorId\":\"1684384\",\"name\":\"Dani Lischinski\"},{\"authorId\":\"1748939\",\"name\":\"B. Chen\"},{\"authorId\":\"1388323541\",\"name\":\"D. Cohen-Or\"}],\"doi\":\"10.1145/3306346.3322999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d26b787d3f765be81f2d0268f86003a5942760c\",\"title\":\"Learning character-agnostic motion for motion retargeting in 2D\",\"url\":\"https://www.semanticscholar.org/paper/8d26b787d3f765be81f2d0268f86003a5942760c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":\"2012.07304\",\"authors\":[{\"authorId\":\"1488670226\",\"name\":\"N. Kumar\"},{\"authorId\":\"14085625\",\"name\":\"Srishti Goel\"},{\"authorId\":\"34275551\",\"name\":\"A. Narang\"},{\"authorId\":\"2036952884\",\"name\":\"Brejesh Lall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dc9ec9cde734084888a6e529488aed42abbd2c8e\",\"title\":\"Multi Modal Adaptive Normalization for Audio to Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/dc9ec9cde734084888a6e529488aed42abbd2c8e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17659319\",\"name\":\"Zackary P. T. Sin\"},{\"authorId\":\"2774268\",\"name\":\"P. H. Ng\"},{\"authorId\":\"1738911\",\"name\":\"S. Shiu\"},{\"authorId\":\"145288211\",\"name\":\"K. Chung\"},{\"authorId\":\"1714454\",\"name\":\"H. Leong\"}],\"doi\":\"10.1007/978-3-030-22514-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"725d8d026e1b9be741c10ae6bc0608ccea0d8ddb\",\"title\":\"Multi-level Motion-Informed Approach for Video Generation with Key Frames\",\"url\":\"https://www.semanticscholar.org/paper/725d8d026e1b9be741c10ae6bc0608ccea0d8ddb\",\"venue\":\"CGI\",\"year\":2019},{\"arxivId\":\"1803.03330\",\"authors\":[{\"authorId\":\"34586458\",\"name\":\"Grigorios G. Chrysos\"},{\"authorId\":\"145646305\",\"name\":\"P. Favaro\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":\"10.1007/s11263-018-1138-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"377c6563f97e76a4dc836a0bd23d7673492b1aae\",\"title\":\"Motion Deblurring of Faces\",\"url\":\"https://www.semanticscholar.org/paper/377c6563f97e76a4dc836a0bd23d7673492b1aae\",\"venue\":\"Int. J. Comput. Vis.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"83769658\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"12c37cb419121cdb43f2c6620303932f43e2e1b7\",\"title\":\"Adversarial Video Generation on Complex Datasets\",\"url\":\"https://www.semanticscholar.org/paper/12c37cb419121cdb43f2c6620303932f43e2e1b7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.02265\",\"authors\":[{\"authorId\":\"7217794\",\"name\":\"Haozhi Qi\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1845785824\",\"name\":\"Yi Ma\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4053a225b189852df0ef5d24bc5c400987778ac4\",\"title\":\"Learning Long-term Visual Dynamics with Region Proposal Interaction Networks\",\"url\":\"https://www.semanticscholar.org/paper/4053a225b189852df0ef5d24bc5c400987778ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.02018\",\"authors\":[{\"authorId\":\"48693251\",\"name\":\"D. Kim\"},{\"authorId\":\"50001046\",\"name\":\"Donggyu Joo\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/ACCESS.2020.3017881\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49e9fa120e4cdcaa2aebea59d3e882fd8ef0bd0a\",\"title\":\"TiVGAN: Text to Image to Video Generation With Step-by-Step Evolutionary Generator\",\"url\":\"https://www.semanticscholar.org/paper/49e9fa120e4cdcaa2aebea59d3e882fd8ef0bd0a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1812.01717\",\"authors\":[{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"3440930\",\"name\":\"Sjoerd van Steenkiste\"},{\"authorId\":\"2006889\",\"name\":\"Karol Kurach\"},{\"authorId\":\"52153018\",\"name\":\"Rapha\\u00ebl Marinier\"},{\"authorId\":\"144859281\",\"name\":\"M. Michalski\"},{\"authorId\":\"1802148\",\"name\":\"S. Gelly\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b59233aab8364186603967bc12d88af48cc0992d\",\"title\":\"Towards Accurate Generative Models of Video: A New Metric & Challenges\",\"url\":\"https://www.semanticscholar.org/paper/b59233aab8364186603967bc12d88af48cc0992d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.11459\",\"authors\":[{\"authorId\":\"26957065\",\"name\":\"A. Grigorev\"},{\"authorId\":\"10784511\",\"name\":\"A. Sevastopolsky\"},{\"authorId\":\"144029627\",\"name\":\"Alexander Vakhitov\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"66fbe029982737acbf6c80897ea6ba8ce119fad9\",\"title\":\"Coordinate-based Texture Inpainting for Pose-Guided Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/66fbe029982737acbf6c80897ea6ba8ce119fad9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.04545\",\"authors\":[{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"51114494\",\"name\":\"Akash Rastogi\"},{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1733732\",\"name\":\"Sunil Hadap\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":\"10.1007/978-3-030-01228-1_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ce852f1e9b6d8d97787127d43dcbec1cdeeda09\",\"title\":\"MT-VAE: Learning Motion Transformations to Generate Multimodal Human Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/2ce852f1e9b6d8d97787127d43dcbec1cdeeda09\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.01002\",\"authors\":[{\"authorId\":\"48064265\",\"name\":\"Linlin Yang\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":\"10.1109/CVPR.2019.01011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6300a88665387476b4db55b24f9f06926857d526\",\"title\":\"Disentangling Latent Hands for Image Synthesis and Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/6300a88665387476b4db55b24f9f06926857d526\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1441501099\",\"name\":\"Sinuo Fan\"},{\"authorId\":\"1918747628\",\"name\":\"Fanjie Meng\"}],\"doi\":\"10.1109/ICCIA49625.2020.00031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ce175a3837f2420878caddbd1aab0892e253ae4\",\"title\":\"Video Prediction and Anomaly Detection Algorithm Based On Dual Discriminator\",\"url\":\"https://www.semanticscholar.org/paper/9ce175a3837f2420878caddbd1aab0892e253ae4\",\"venue\":\"2020 5th International Conference on Computational Intelligence and Applications (ICCIA)\",\"year\":2020},{\"arxivId\":\"2003.01460\",\"authors\":[{\"authorId\":\"3965182\",\"name\":\"V. Guen\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/cvpr42600.2020.01149\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"603a0764092fbda01f3414071ea2813c49e1efa3\",\"title\":\"Disentangling Physical Dynamics From Unknown Factors for Unsupervised Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/603a0764092fbda01f3414071ea2813c49e1efa3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.11264\",\"authors\":[{\"authorId\":\"1916516\",\"name\":\"M. Khodabandeh\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"15623770\",\"name\":\"I. Zharkov\"},{\"authorId\":\"3811436\",\"name\":\"V. Pradeep\"}],\"doi\":\"10.1109/CVPRW.2018.00194\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"title\":\"DIY Human Action Dataset Generation\",\"url\":\"https://www.semanticscholar.org/paper/74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1807.09951\",\"authors\":[{\"authorId\":\"48096253\",\"name\":\"Long Zhao\"},{\"authorId\":\"144152346\",\"name\":\"Xi Peng\"},{\"authorId\":\"6812347\",\"name\":\"Yu Tian\"},{\"authorId\":\"143980996\",\"name\":\"Mubbasir Kapadia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-01267-0_24\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ec5cdb68fa5a1dc011c9df01e45a0a1c4d59d110\",\"title\":\"Learning to Forecast and Refine Residual Motion for Image-to-Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/ec5cdb68fa5a1dc011c9df01e45a0a1c4d59d110\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66787135\",\"name\":\"Z. Huang\"},{\"authorId\":\"48623702\",\"name\":\"Y. Yu\"},{\"authorId\":\"2621689\",\"name\":\"Xiangru Chen\"},{\"authorId\":\"90091535\",\"name\":\"W. Wei\"}],\"doi\":\"10.1109/ICCT.2018.8600154\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e0ca290b84f6dccfdb33c9b1ff428ac1029d3f6\",\"title\":\"Prediction of Human Body Motion from Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/2e0ca290b84f6dccfdb33c9b1ff428ac1029d3f6\",\"venue\":\"2018 IEEE 18th International Conference on Communication Technology (ICCT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153842978\",\"name\":\"Yangjie Cao\"},{\"authorId\":\"144255281\",\"name\":\"L. Jia\"},{\"authorId\":\"7377127\",\"name\":\"Yong-Xia Chen\"},{\"authorId\":\"144650470\",\"name\":\"N. Lin\"},{\"authorId\":\"143617701\",\"name\":\"C. Yang\"},{\"authorId\":\"38738132\",\"name\":\"B. Zhang\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"12074832\",\"name\":\"X. Li\"},{\"authorId\":\"134052572\",\"name\":\"Honghua Dai\"}],\"doi\":\"10.1109/ACCESS.2018.2886814\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4af1d879281da729a824d5825a507ac9ec54b50\",\"title\":\"Recent Advances of Generative Adversarial Networks in Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/a4af1d879281da729a824d5825a507ac9ec54b50\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1803.08085\",\"authors\":[{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"145170722\",\"name\":\"Joseph Marino\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/978-3-030-01228-1_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f53044c0a9cec1af142b8b0e9f5ddf389fe7b6a6\",\"title\":\"Probabilistic Video Generation using Holistic Attribute Control\",\"url\":\"https://www.semanticscholar.org/paper/f53044c0a9cec1af142b8b0e9f5ddf389fe7b6a6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024168\",\"name\":\"Yitong Li\"},{\"authorId\":\"5477477\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":null,\"name\":\"Dinghan Shen\"},{\"authorId\":null,\"name\":\"David Carlson\"},{\"authorId\":\"145006560\",\"name\":\"Lawrence Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"13cdaa567cee45a83bd47cad047c591e04336d0c\",\"title\":\"\\u223c N ( 0 , 1 ) Video Generator Video Discriminator Real ? Fake ?\",\"url\":\"https://www.semanticscholar.org/paper/13cdaa567cee45a83bd47cad047c591e04336d0c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"115939427\",\"name\":\"R. Campbell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d4841ad9dd4caaec61b5921950df477d7b75b2b\",\"title\":\"S Tochastic V Ariational V Ideo P Rediction\",\"url\":\"https://www.semanticscholar.org/paper/0d4841ad9dd4caaec61b5921950df477d7b75b2b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20609447\",\"name\":\"Dasaem Jeong\"},{\"authorId\":\"49905923\",\"name\":\"Taegyun Kwon\"},{\"authorId\":\"50681480\",\"name\":\"Y. Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea0795592a0b45af0af546f9c9491119865ffb8c\",\"title\":\"Graph Neural Network for Music Score Data and Modeling Expressive Piano Performance\",\"url\":\"https://www.semanticscholar.org/paper/ea0795592a0b45af0af546f9c9491119865ffb8c\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67084339\",\"name\":\"Jianjin Zhang\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"46583978\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/ICME.2019.00048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7115885e400cca5fa5cb4cd351605dda665f4d92\",\"title\":\"Z-Order Recurrent Neural Networks for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7115885e400cca5fa5cb4cd351605dda665f4d92\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1908.08919\",\"authors\":[{\"authorId\":\"6673984\",\"name\":\"Vandad Davoodnia\"},{\"authorId\":\"1966561\",\"name\":\"S. Ghorbani\"},{\"authorId\":\"48485067\",\"name\":\"A. Etemad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2600a8e2fbbe221602047c80409b89d9b3a85cb\",\"title\":\"In-bed Pressure-based Pose Estimation using Image Space Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/d2600a8e2fbbe221602047c80409b89d9b3a85cb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.00196\",\"authors\":[{\"authorId\":\"10753214\",\"name\":\"Aliaksandr Siarohin\"},{\"authorId\":\"3099587\",\"name\":\"St\\u00e9phane Lathuili\\u00e8re\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"797389ca052efd160ed759d7ef7adf9c30a917d6\",\"title\":\"First Order Motion Model for Image Animation\",\"url\":\"https://www.semanticscholar.org/paper/797389ca052efd160ed759d7ef7adf9c30a917d6\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151500851\",\"name\":\"K. Deng\"},{\"authorId\":\"115706403\",\"name\":\"Tianyi Fei\"},{\"authorId\":\"100599451\",\"name\":\"Xin Huang\"},{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"}],\"doi\":\"10.24963/ijcai.2019/307\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb7ec8735c831fe34ef709c16c9569a1f1021aab\",\"title\":\"IRC-GAN: Introspective Recurrent Convolutional GAN for Text-to-video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb7ec8735c831fe34ef709c16c9569a1f1021aab\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chao Yuan Kao\"},{\"authorId\":\"81950948\",\"name\":\"Hanseok Ko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8747c8e93b7d67fbedb1b18f2f3465bb521b0aff\",\"title\":\"Combining multi-task autoencoder with Wasserstein generative adversarial networks for improving speech recognition performance\",\"url\":\"https://www.semanticscholar.org/paper/8747c8e93b7d67fbedb1b18f2f3465bb521b0aff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458479\",\"name\":\"Y. Balaji\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"144490441\",\"name\":\"Bing Bai\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.24963/ijcai.2019/276\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4c3d103d8ddb863d1e74e51d9ee2b3ef8529e30\",\"title\":\"Conditional GAN with Discriminative Filter Generation for Text-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f4c3d103d8ddb863d1e74e51d9ee2b3ef8529e30\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47785129\",\"name\":\"Lingyun Yu\"},{\"authorId\":\"119883542\",\"name\":\"J. Yu\"},{\"authorId\":\"40177644\",\"name\":\"Q. Ling\"}],\"doi\":\"10.1109/ICDM.2019.00089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c93fb94cbc6e5cc67851c9436127f56ab7e8725\",\"title\":\"Mining Audio, Text and Visual Information for Talking Face Generation\",\"url\":\"https://www.semanticscholar.org/paper/6c93fb94cbc6e5cc67851c9436127f56ab7e8725\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"1910.14673\",\"authors\":[{\"authorId\":\"100529381\",\"name\":\"Tian-tian Fang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faea5b2c2b3cf56561f7dca2437bdc71a2a9a1c5\",\"title\":\"Co-Generation with GANs using AIS based HMC\",\"url\":\"https://www.semanticscholar.org/paper/faea5b2c2b3cf56561f7dca2437bdc71a2a9a1c5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1906.07889\",\"authors\":[{\"authorId\":\"50852139\",\"name\":\"Matthias Minderer\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"39578349\",\"name\":\"F. Cole\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52b367ce0cd2c3f92ea26d295a6212ce23f2f041\",\"title\":\"Unsupervised Learning of Object Structure and Dynamics from Videos\",\"url\":\"https://www.semanticscholar.org/paper/52b367ce0cd2c3f92ea26d295a6212ce23f2f041\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392265907\",\"name\":\"V\\u00e9ronique Prinet\"}],\"doi\":\"10.1109/ICIP.2019.8803620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ce3a4efc6e3f9bc8280c2074ec3f079ba69376c\",\"title\":\"Domain-Agnostic Video Prediction from Motion Selective Kernels\",\"url\":\"https://www.semanticscholar.org/paper/4ce3a4efc6e3f9bc8280c2074ec3f079ba69376c\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2012.07842\",\"authors\":[{\"authorId\":\"1488670226\",\"name\":\"N. Kumar\"},{\"authorId\":\"14085625\",\"name\":\"Srishti Goel\"},{\"authorId\":\"34275551\",\"name\":\"A. Narang\"},{\"authorId\":\"1491237789\",\"name\":\"Hasan Mujtaba\"}],\"doi\":\"10.1109/CVPRW50498.2020.00393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61c52febf4c0a12f20326af58633077a9e218ce3\",\"title\":\"Robust One Shot Audio to Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/61c52febf4c0a12f20326af58633077a9e218ce3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1912.06265\",\"authors\":[{\"authorId\":\"40389846\",\"name\":\"Chao Yang\"},{\"authorId\":\"49544204\",\"name\":\"Xiao-Feng Liu\"},{\"authorId\":\"49264864\",\"name\":\"Qingming Tang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f39341aa091cf9a968a6f0a1740fa529be1c5f4\",\"title\":\"Towards Disentangled Representations for Human Retargeting by Multi-view Learning\",\"url\":\"https://www.semanticscholar.org/paper/6f39341aa091cf9a968a6f0a1740fa529be1c5f4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48928085\",\"name\":\"A. Klein\"},{\"authorId\":\"1730934\",\"name\":\"Zerrin Yumak\"},{\"authorId\":\"1389222399\",\"name\":\"Arjen Beij\"},{\"authorId\":\"9494525\",\"name\":\"A. Stappen\"}],\"doi\":\"10.1145/3359566.3360054\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d864fe3d8145f32a23e4f5bafb2c8e2af67c062\",\"title\":\"Data-driven Gaze Animation using Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2d864fe3d8145f32a23e4f5bafb2c8e2af67c062\",\"venue\":\"MIG\",\"year\":2019},{\"arxivId\":\"1909.10341\",\"authors\":[{\"authorId\":\"123898484\",\"name\":\"Ricard Durall\"},{\"authorId\":\"1918587\",\"name\":\"F. Pfreundt\"},{\"authorId\":\"1708103\",\"name\":\"U. K\\u00f6the\"},{\"authorId\":\"3299100\",\"name\":\"J. Keuper\"}],\"doi\":\"10.1007/978-3-030-33676-9_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fa9a7459f838b2dd7e939303fb19e6498901ff7\",\"title\":\"Object Segmentation using Pixel-wise Adversarial Loss\",\"url\":\"https://www.semanticscholar.org/paper/9fa9a7459f838b2dd7e939303fb19e6498901ff7\",\"venue\":\"GCPR\",\"year\":2019},{\"arxivId\":\"1803.07031\",\"authors\":[{\"authorId\":\"8181586\",\"name\":\"Agisilaos Chartsias\"},{\"authorId\":\"80988323\",\"name\":\"T. Joyce\"},{\"authorId\":\"6846362\",\"name\":\"G. Papanastasiou\"},{\"authorId\":\"144787995\",\"name\":\"S. Semple\"},{\"authorId\":\"49149745\",\"name\":\"M. Williams\"},{\"authorId\":\"145265776\",\"name\":\"D. Newby\"},{\"authorId\":\"2684123\",\"name\":\"R. Dharmakumar\"},{\"authorId\":\"1919157\",\"name\":\"S. Tsaftaris\"}],\"doi\":\"10.1007/978-3-030-00934-2_55\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c23580b872735db8f0ba38936f14b67f61fa12bc\",\"title\":\"Factorised spatial representation learning: application in semi-supervised myocardial segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c23580b872735db8f0ba38936f14b67f61fa12bc\",\"venue\":\"MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3460423\",\"name\":\"Yichao Yan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1780882\",\"name\":\"W. Zhang\"},{\"authorId\":\"47883221\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/TMM.2018.2885235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7d96828d37c47543fbe9a2a6ce49ea3b44d0178\",\"title\":\"Structure-Constrained Motion Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/e7d96828d37c47543fbe9a2a6ce49ea3b44d0178\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145582147\",\"name\":\"Rodrigo de Bem\"},{\"authorId\":\"144317747\",\"name\":\"A. Ghosh\"},{\"authorId\":\"2984583\",\"name\":\"Adnane Boukhayma\"},{\"authorId\":\"144722114\",\"name\":\"Thalaiyasingam Ajanthan\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/WACV.2019.00159\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"652d3fdd337e0c1a7cb37215df2429f0c36b028f\",\"title\":\"A Conditional Deep Generative Model of People in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/652d3fdd337e0c1a7cb37215df2429f0c36b028f\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1907.10087\",\"authors\":[{\"authorId\":\"26997269\",\"name\":\"Naima Otberdout\"},{\"authorId\":\"2909056\",\"name\":\"M. Daoudi\"},{\"authorId\":\"46243487\",\"name\":\"A. Kacem\"},{\"authorId\":\"2062946\",\"name\":\"Lahoucine Ballihi\"},{\"authorId\":\"2507859\",\"name\":\"S. Berretti\"}],\"doi\":\"10.1109/TPAMI.2020.3002500\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4ea07e4cf344ed5fbc2aa833eec5b6bf2f6b759\",\"title\":\"Dynamic Facial Expression Generation on Hilbert Hypersphere with Conditional Wasserstein Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/b4ea07e4cf344ed5fbc2aa833eec5b6bf2f6b759\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1909.12507\",\"authors\":[{\"authorId\":\"47009264\",\"name\":\"Yuqing Ma\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"151475528\",\"name\":\"Shihao Bai\"},{\"authorId\":\"120692505\",\"name\":\"L. Wang\"},{\"authorId\":\"153152072\",\"name\":\"Aishan Liu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"1679753\",\"name\":\"E. Hancock\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"952230d916df788499fe0c40d7ba6787cf8a3006\",\"title\":\"Region-wise Generative Adversarial ImageInpainting for Large Missing Areas\",\"url\":\"https://www.semanticscholar.org/paper/952230d916df788499fe0c40d7ba6787cf8a3006\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153725817\",\"name\":\"Yuki Nakahira\"},{\"authorId\":\"3063432\",\"name\":\"K. Kawamoto\"}],\"doi\":\"10.1109/ICIP.2019.8803764\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3fe732ce588319a744e2b59c143b4958b54dbd06\",\"title\":\"DCVGAN: Depth Conditional Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/3fe732ce588319a744e2b59c143b4958b54dbd06\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5458428\",\"name\":\"M. Chen\"},{\"authorId\":\"121900636\",\"name\":\"Changbo Wang\"},{\"authorId\":\"47968194\",\"name\":\"Ligang Liu\"}],\"doi\":\"10.1111/cgf.13859\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63cb1daa3b2276eb8872790c6b1f3a03994f2ac9\",\"title\":\"Deep Video\\u2010Based Performance Synthesis from Sparse Multi\\u2010View Capture\",\"url\":\"https://www.semanticscholar.org/paper/63cb1daa3b2276eb8872790c6b1f3a03994f2ac9\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"1901.11384\",\"authors\":[{\"authorId\":\"153804922\",\"name\":\"Isabela Albuquerque\"},{\"authorId\":\"144903711\",\"name\":\"J. Monteiro\"},{\"authorId\":\"2632038\",\"name\":\"T. Falk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15767267a679da3a41e37f19fdcf68e0c2eb86ad\",\"title\":\"Learning to navigate image manifolds induced by generative adversarial networks for unsupervised video generation\",\"url\":\"https://www.semanticscholar.org/paper/15767267a679da3a41e37f19fdcf68e0c2eb86ad\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028218872\",\"name\":\"Kara Marie Schatz\"},{\"authorId\":\"1607110764\",\"name\":\"Erik Quintanilla\"},{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":\"10.1007/978-3-030-58583-9_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64eba0de822754df1bc1303f96163265dea9ac4f\",\"title\":\"A Recurrent Transformer Network for Novel View Action Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/64eba0de822754df1bc1303f96163265dea9ac4f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1902.09641\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144338675\",\"name\":\"P. Karlsson\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"906c03e6e188d301b85ca6521955a8584f9babe7\",\"title\":\"Stochastic Prediction of Multi-Agent Interactions from Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/906c03e6e188d301b85ca6521955a8584f9babe7\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"2007.01738\",\"authors\":[{\"authorId\":\"153173254\",\"name\":\"J. Xu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc23b1c8538a6810ad6fde3a95a60da617c38ec1\",\"title\":\"Video Prediction via Example Guidance\",\"url\":\"https://www.semanticscholar.org/paper/dc23b1c8538a6810ad6fde3a95a60da617c38ec1\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2008.09655\",\"authors\":[{\"authorId\":\"145879692\",\"name\":\"E. Logacheva\"},{\"authorId\":\"1956107\",\"name\":\"R. Suvorov\"},{\"authorId\":\"50168812\",\"name\":\"Oleg Khomenko\"},{\"authorId\":\"51995877\",\"name\":\"A. Mashikhin\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7594d6e232599e7f792e416a420a4102435ce631\",\"title\":\"DeepLandscape: Adversarial Modeling of Landscape Video\",\"url\":\"https://www.semanticscholar.org/paper/7594d6e232599e7f792e416a420a4102435ce631\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"2007.08509\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"36775862\",\"name\":\"K. Sapra\"},{\"authorId\":\"1596793949\",\"name\":\"M. Liu\"}],\"doi\":\"10.1007/978-3-030-58598-3_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"633a7a0c92dd8c254b65a11b759b99c157e115c7\",\"title\":\"World-Consistent Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/633a7a0c92dd8c254b65a11b759b99c157e115c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.02250\",\"authors\":[{\"authorId\":\"51235324\",\"name\":\"Nuha Aldausari\"},{\"authorId\":\"145313633\",\"name\":\"A. Sowmya\"},{\"authorId\":\"47600265\",\"name\":\"N. Marcus\"},{\"authorId\":\"4911295\",\"name\":\"G. Mohammadi\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b\",\"title\":\"Video Generative Adversarial Networks: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5c1b1ab734ebc6ba56ea5d8af9d01a9fe8e0ba8b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.00913\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Unsupervised Bi-directional Flow-based Video Generation from one Snapshot\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.09071\",\"authors\":[{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"150936463\",\"name\":\"Benoit Lagadec\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38489e185cafc2a6ff87843984ed23f273a15f1f\",\"title\":\"Joint Generative and Contrastive Learning for Unsupervised Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/38489e185cafc2a6ff87843984ed23f273a15f1f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1806.09655\",\"authors\":[{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a53874f5c63b31468ad2fe3f5dea558a6ce35820\",\"title\":\"Learning what you can do before doing anything\",\"url\":\"https://www.semanticscholar.org/paper/a53874f5c63b31468ad2fe3f5dea558a6ce35820\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1808.04859\",\"authors\":[{\"authorId\":\"145462888\",\"name\":\"Hao Tang\"},{\"authorId\":\"40231554\",\"name\":\"W. Wang\"},{\"authorId\":\"144742694\",\"name\":\"D. Xu\"},{\"authorId\":\"47971190\",\"name\":\"Yan Yan\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/3240508.3240704\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a64aec4e006a91be4f27f1ba968055d39fe35d0a\",\"title\":\"GestureGAN for Hand Gesture-to-Gesture Translation in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/a64aec4e006a91be4f27f1ba968055d39fe35d0a\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.03429\",\"authors\":[{\"authorId\":\"2399563\",\"name\":\"Chongxuan Li\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"},{\"authorId\":\"145254043\",\"name\":\"J. Zhu\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f17c56540118af065cf2a72f4b56d5b17d84f5ca\",\"title\":\"Graphical Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f17c56540118af065cf2a72f4b56d5b17d84f5ca\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1912.05833\",\"authors\":[{\"authorId\":\"1456151087\",\"name\":\"Triantafyllos Kefalas\"},{\"authorId\":\"2160245\",\"name\":\"Konstantinos Vougioukas\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"145387779\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054469\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"12fa689bd284f7e79bed7003bafc508f71c220de\",\"title\":\"Speech-Driven Facial Animation Using Polynomial Fusion of Features\",\"url\":\"https://www.semanticscholar.org/paper/12fa689bd284f7e79bed7003bafc508f71c220de\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":\"10.1109/CVPR42600.2020.01084\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14e0c1b8e8356cc4d4084765fead2f5ea191c00f\",\"title\":\"Probabilistic Video Prediction From Noisy Data With a Posterior Confidence\",\"url\":\"https://www.semanticscholar.org/paper/14e0c1b8e8356cc4d4084765fead2f5ea191c00f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1893334\",\"name\":\"Zhaoqing Pan\"},{\"authorId\":\"47218149\",\"name\":\"Weijie Yu\"},{\"authorId\":\"15641030\",\"name\":\"Xiaokai Yi\"},{\"authorId\":\"2916228\",\"name\":\"A. Khan\"},{\"authorId\":\"145831066\",\"name\":\"F. Yuan\"},{\"authorId\":\"46323585\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1109/ACCESS.2019.2905015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fba409648eb6087a1e7d741655967815b9f0377\",\"title\":\"Recent Progress on Generative Adversarial Networks (GANs): A Survey\",\"url\":\"https://www.semanticscholar.org/paper/0fba409648eb6087a1e7d741655967815b9f0377\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2003.14401\",\"authors\":[{\"authorId\":\"51126032\",\"name\":\"Zhuoqian Yang\"},{\"authorId\":\"48506702\",\"name\":\"W. Zhu\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"1384754989\",\"name\":\"Qiang Zhou\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/cvpr42600.2020.00535\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caa0d7e51edd936b7b35d0ccbd6db1ee0ac5220b\",\"title\":\"TransMoMo: Invariance-Driven Unsupervised Video Motion Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/caa0d7e51edd936b7b35d0ccbd6db1ee0ac5220b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29805373\",\"name\":\"Mrinal Kanti Baowaly\"},{\"authorId\":\"151506520\",\"name\":\"Chao-Lin Liu\"},{\"authorId\":\"6270307\",\"name\":\"Kuan-Ta Chen\"}],\"doi\":\"10.1109/AIKE.2019.00057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36840396467e46fc2db1d215c57c60f7baaa5e5f\",\"title\":\"Realistic Data Synthesis Using Enhanced Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/36840396467e46fc2db1d215c57c60f7baaa5e5f\",\"venue\":\"2019 IEEE Second International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Tgt . ( a ) GT sequence ( b ) ImagineFlow ( c ) Backward warping Before After\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Binghao Deng\"},{\"authorId\":\"46615314\",\"name\":\"Weizhao Shao\"},{\"authorId\":\"66886160\",\"name\":\"Si-Yu Gao\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2b297a71e783613b84fdc62203a58252ad22369b\",\"title\":\"Motion-Object-Background Disentangled Representation from Video\",\"url\":\"https://www.semanticscholar.org/paper/2b297a71e783613b84fdc62203a58252ad22369b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"},{\"authorId\":null,\"name\":\"UEC Toyko\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d549112f0cad6fbfb40bee9109164eeb37fa393\",\"title\":\"SSA-GAN: Cloud Video Generation from a Single Image with Spatial Self-Attention Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d549112f0cad6fbfb40bee9109164eeb37fa393\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738471\",\"name\":\"Chenyang Zhang\"},{\"authorId\":\"1860612\",\"name\":\"X. Yang\"},{\"authorId\":\"33768582\",\"name\":\"Yongqiang Tang\"},{\"authorId\":\"40538957\",\"name\":\"Wensheng Zhang\"}],\"doi\":\"10.1109/LGRS.2019.2922326\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ae5b2ef9e7043f3c7015de386d85d42718dc3c3\",\"title\":\"Learning to Generate Radar Image Sequences Using Two-Stage Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/1ae5b2ef9e7043f3c7015de386d85d42718dc3c3\",\"venue\":\"IEEE Geoscience and Remote Sensing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147363738\",\"name\":\"Lukas Ryll\"},{\"authorId\":\"1657641683\",\"name\":\"Mary Emma Barton\"},{\"authorId\":\"80197296\",\"name\":\"Bryan Zheng Zhang\"},{\"authorId\":\"1657643235\",\"name\":\"R. J. McWaters\"},{\"authorId\":\"1657638502\",\"name\":\"Emmanuel Schizas\"},{\"authorId\":\"144915622\",\"name\":\"R. Hao\"},{\"authorId\":\"1582411177\",\"name\":\"Keith Bear\"},{\"authorId\":\"1657640106\",\"name\":\"Massimo Preziuso\"},{\"authorId\":\"40437610\",\"name\":\"E. Seger\"},{\"authorId\":\"5044315\",\"name\":\"Robert L. Wardrop\"},{\"authorId\":\"145829335\",\"name\":\"P. R. Rau\"},{\"authorId\":\"88536572\",\"name\":\"Pradeep Debata\"},{\"authorId\":\"121739197\",\"name\":\"Philip Rowan\"},{\"authorId\":\"143863832\",\"name\":\"N. Adams\"},{\"authorId\":\"47769078\",\"name\":\"M. Gray\"},{\"authorId\":\"122339184\",\"name\":\"Nikos Yerolemou\"}],\"doi\":\"10.2139/ssrn.3532038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abc0dae616eed6723752173c520d6a6b1fcc9bee\",\"title\":\"Transforming Paradigms: A Global AI in Financial Services Survey\",\"url\":\"https://www.semanticscholar.org/paper/abc0dae616eed6723752173c520d6a6b1fcc9bee\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.09846\",\"authors\":[{\"authorId\":\"119739494\",\"name\":\"Ben Saunders\"},{\"authorId\":\"40163061\",\"name\":\"N. C. Camgoz\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64934681480d28a1fb313c5de4922e92a2bd0ac3\",\"title\":\"Everybody Sign Now: Translating Spoken Language to Photo Realistic Sign Language Video\",\"url\":\"https://www.semanticscholar.org/paper/64934681480d28a1fb313c5de4922e92a2bd0ac3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.06937\",\"authors\":[{\"authorId\":\"48603577\",\"name\":\"Jie Gui\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"title\":\"A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.00155\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"27577617\",\"name\":\"Xiangyu Yue\"},{\"authorId\":\"2437353\",\"name\":\"Shanghang Zhang\"},{\"authorId\":\"143771567\",\"name\":\"Bo Li\"},{\"authorId\":\"1390716752\",\"name\":\"Han Zhao\"},{\"authorId\":\"3130257\",\"name\":\"B. Wu\"},{\"authorId\":\"143781417\",\"name\":\"R. Krishna\"},{\"authorId\":\"144307989\",\"name\":\"J. Gonzalez\"},{\"authorId\":\"1388394865\",\"name\":\"A. Sangiovanni-Vincentelli\"},{\"authorId\":\"1775517\",\"name\":\"S. Seshia\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1109/TNNLS.2020.3028503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcdf35d5238b65e5084c16075613e2327197ce1d\",\"title\":\"A Review of Single-Source Deep Unsupervised Visual Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bcdf35d5238b65e5084c16075613e2327197ce1d\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":\"1912.08860\",\"authors\":[{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":\"10.1016/j.neunet.2020.09.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f313226533edea306c4de79df945cc5a90d153c\",\"title\":\"Lower Dimensional Kernels for Video Discriminators\",\"url\":\"https://www.semanticscholar.org/paper/1f313226533edea306c4de79df945cc5a90d153c\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3021550\",\"name\":\"Jiachen Yang\"},{\"authorId\":\"47073826\",\"name\":\"Chenguang Wang\"},{\"authorId\":\"1796274181\",\"name\":\"Bin Jiang\"},{\"authorId\":\"72482162\",\"name\":\"H. Song\"},{\"authorId\":\"49092308\",\"name\":\"Qinggang Meng\"}],\"doi\":\"10.1109/TII.2020.2998818\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c86bc8fd739151a8c692fd30aacb16141dc7b8b2\",\"title\":\"Visual Perception Enabled Industry Intelligence: State of the Art, Challenges and Prospects\",\"url\":\"https://www.semanticscholar.org/paper/c86bc8fd739151a8c692fd30aacb16141dc7b8b2\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48531958\",\"name\":\"Jonathan Rosenthal\"},{\"authorId\":\"113138355\",\"name\":\"Saturday\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f58c94d7158c89af03a16b48678ce37b37192af\",\"title\":\"Generative Temporal Models for Cosmology Master Thesis\",\"url\":\"https://www.semanticscholar.org/paper/2f58c94d7158c89af03a16b48678ce37b37192af\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1785411921\",\"name\":\"Ping-Sung Cheng\"},{\"authorId\":\"1785372532\",\"name\":\"Chieh-Ying Lai\"},{\"authorId\":\"50205803\",\"name\":\"C. Chang\"},{\"authorId\":\"50385111\",\"name\":\"Shu-Fen Chiou\"},{\"authorId\":\"3682532\",\"name\":\"Yu-Chieh Yang\"}],\"doi\":\"10.1145/3399871.3399888\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a44c61b43c50190d4dec9f00580bad93c9231eb7\",\"title\":\"A Variant Model of TGAN for Music Generation\",\"url\":\"https://www.semanticscholar.org/paper/a44c61b43c50190d4dec9f00580bad93c9231eb7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2208488\",\"name\":\"Bernhard Kratzwald\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"71879671\",\"name\":\"A. Dinesh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0b936f643f7462068517e0a840e775d6bd4abfb\",\"title\":\"Improving Video Generation for Multi-functional Applications.\",\"url\":\"https://www.semanticscholar.org/paper/d0b936f643f7462068517e0a840e775d6bd4abfb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.11566\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f52df35087ef9f93c211d679c65485250b11ac1\",\"title\":\"Hybrid VAE: Improving Deep Generative Models using Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/1f52df35087ef9f93c211d679c65485250b11ac1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.03189\",\"authors\":[{\"authorId\":\"94395014\",\"name\":\"Rameen Abdal\"},{\"authorId\":\"2408885\",\"name\":\"Yipeng Qin\"},{\"authorId\":\"1798011\",\"name\":\"Peter Wonka\"}],\"doi\":\"10.1109/ICCV.2019.00453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62931b3e0dce8748364e19c87ef318e22ec59c7f\",\"title\":\"Image2StyleGAN: How to Embed Images Into the StyleGAN Latent Space?\",\"url\":\"https://www.semanticscholar.org/paper/62931b3e0dce8748364e19c87ef318e22ec59c7f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"879eca33fa23688eb0b586e6b84a3a30351541c5\",\"title\":\"Dynamic Pattern Synthesis by Spatial-Temporal Generative ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/879eca33fa23688eb0b586e6b84a3a30351541c5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.00971\",\"authors\":[{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"2208488\",\"name\":\"Bernhard Kratzwald\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1839268\",\"name\":\"J. Wu\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"834f5ab0cb374b13a6e19198d550e7a32901a4b2\",\"title\":\"Face Translation between Images and Videos using Identity-aware CycleGAN\",\"url\":\"https://www.semanticscholar.org/paper/834f5ab0cb374b13a6e19198d550e7a32901a4b2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1905.08474\",\"authors\":[{\"authorId\":\"46183801\",\"name\":\"Yakov Miron\"},{\"authorId\":\"120106969\",\"name\":\"Yona Coscas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22c4be3b470348c2d846e24cec30f7a3ed1de20c\",\"title\":\"S-Flow GAN\",\"url\":\"https://www.semanticscholar.org/paper/22c4be3b470348c2d846e24cec30f7a3ed1de20c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82623793\",\"name\":\"Sameerah Talafha\"},{\"authorId\":\"1966492\",\"name\":\"Banafsheh Rekabdar\"},{\"authorId\":\"2698203\",\"name\":\"Chinwe Ekenna\"},{\"authorId\":\"2278522\",\"name\":\"Christos Mousas\"}],\"doi\":\"10.1109/ICSC.2020.00014\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e8b89b33935d2eb9098a568640bfb5ce6160f81\",\"title\":\"Attentional Adversarial Variational Video Generation via Decomposing Motion and Content\",\"url\":\"https://www.semanticscholar.org/paper/8e8b89b33935d2eb9098a568640bfb5ce6160f81\",\"venue\":\"2020 IEEE 14th International Conference on Semantic Computing (ICSC)\",\"year\":2020},{\"arxivId\":\"1808.02992\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1609/aaai.v33i01.33013510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1bb03b7c37bea7536eb62d5db7a8462dc992777\",\"title\":\"Controllable Image-to-Video Translation: A Case Study on Facial Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/e1bb03b7c37bea7536eb62d5db7a8462dc992777\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48446876\",\"name\":\"Huajun Liu\"},{\"authorId\":\"1414569274\",\"name\":\"Chao Li\"},{\"authorId\":\"1825780805\",\"name\":\"Dian Lei\"},{\"authorId\":\"153138255\",\"name\":\"Q. Zhu\"}],\"doi\":\"10.1007/s00371-020-01913-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3ae2a3e7c30150817c2e3c8561eb60e49f26a25\",\"title\":\"Unsupervised video-to-video translation with preservation of frame modification tendency\",\"url\":\"https://www.semanticscholar.org/paper/e3ae2a3e7c30150817c2e3c8561eb60e49f26a25\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1810.13197\",\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"},{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"2642628\",\"name\":\"S. Pateux\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aeb09c11a94a1589b0404b5d14a68cc40fcc0705\",\"title\":\"The Many Moods of Emotion\",\"url\":\"https://www.semanticscholar.org/paper/aeb09c11a94a1589b0404b5d14a68cc40fcc0705\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1903.11633\",\"authors\":[{\"authorId\":\"4056993\",\"name\":\"J. P. Robinson\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"}],\"doi\":\"10.1109/ICCV.2019.01020\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d684c197c06139319bf575e2498fe040d9ea32f\",\"title\":\"Laplace Landmark Localization\",\"url\":\"https://www.semanticscholar.org/paper/5d684c197c06139319bf575e2498fe040d9ea32f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.06458\",\"authors\":[{\"authorId\":\"38376240\",\"name\":\"Kyle Olszewski\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"2731900\",\"name\":\"Oliver J. Woodford\"},{\"authorId\":\"144966716\",\"name\":\"Hao Li\"},{\"authorId\":\"40359898\",\"name\":\"L. Luo\"}],\"doi\":\"10.1109/ICCV.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b3d2c5d389b7f3184c4ba1ec13a8786abb72901\",\"title\":\"Transformable Bottleneck Networks\",\"url\":\"https://www.semanticscholar.org/paper/0b3d2c5d389b7f3184c4ba1ec13a8786abb72901\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.10949\",\"authors\":[{\"authorId\":\"3366919\",\"name\":\"Massimiliano Patacchiola\"},{\"authorId\":\"1401704946\",\"name\":\"P. Fox-Roberts\"},{\"authorId\":\"1721991\",\"name\":\"E. Rosten\"}],\"doi\":\"10.1016/J.PATREC.2020.09.025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5c870b9908c561380db64b893b0c88bac3a5b83\",\"title\":\"Y-Autoencoders: disentangling latent representations via sequential-encoding\",\"url\":\"https://www.semanticscholar.org/paper/e5c870b9908c561380db64b893b0c88bac3a5b83\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"2010.00114\",\"authors\":[{\"authorId\":\"145708149\",\"name\":\"Y. Guo\"},{\"authorId\":\"40168061\",\"name\":\"C. Smith\"},{\"authorId\":\"1824181511\",\"name\":\"Milovs Havsan\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"49113034\",\"name\":\"Shuang Zhao\"}],\"doi\":\"10.1145/3414685.3417779\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"373df7f6ab86855f5058efdb3c9a4bf75fe1d16d\",\"title\":\"MaterialGAN: Reflectance Capture using a Generative SVBRDF Model\",\"url\":\"https://www.semanticscholar.org/paper/373df7f6ab86855f5058efdb3c9a4bf75fe1d16d\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2535399\",\"name\":\"Dechen Yao\"},{\"authorId\":\"49724808\",\"name\":\"Sun Qiang\"},{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"102897428\",\"name\":\"Liu Hengchang\"},{\"authorId\":\"26808688\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1155/2020/8823050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e248b9f494c9ae7db99f2ae943c39f4d0db0650\",\"title\":\"Railway Fastener Fault Diagnosis Based on Generative Adversarial Network and Residual Network Model\",\"url\":\"https://www.semanticscholar.org/paper/1e248b9f494c9ae7db99f2ae943c39f4d0db0650\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.06134\",\"authors\":[{\"authorId\":\"49576412\",\"name\":\"L. Yang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"3246404\",\"name\":\"P. Ren\"},{\"authorId\":\"14104497\",\"name\":\"Siwei Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"title\":\"Intrinsic Temporal Regularization for High-resolution Human Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146713167\",\"name\":\"F. Hauptfleisch\"},{\"authorId\":\"150255187\",\"name\":\"O. Texler\"},{\"authorId\":\"2028209631\",\"name\":\"A. Texler\"},{\"authorId\":\"40015757\",\"name\":\"J. Krivanek\"},{\"authorId\":\"101677388\",\"name\":\"D. S\\u00fdkora\"}],\"doi\":\"10.1111/cgf.14169\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5090c8c0f29f5328b28b08a8a188d899adc87ec1\",\"title\":\"StyleProp: Real\\u2010time Example\\u2010based Stylization of 3D Models\",\"url\":\"https://www.semanticscholar.org/paper/5090c8c0f29f5328b28b08a8a188d899adc87ec1\",\"venue\":\"Comput. Graph. Forum\",\"year\":2020},{\"arxivId\":\"2004.03132\",\"authors\":[{\"authorId\":\"1406041324\",\"name\":\"Jun Ling\"},{\"authorId\":\"1455962923\",\"name\":\"Han Xue\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"},{\"authorId\":\"1694444\",\"name\":\"Shuhui Yang\"},{\"authorId\":\"1773394\",\"name\":\"Rong Xie\"},{\"authorId\":null,\"name\":\"Xiao Gu\"}],\"doi\":\"10.1007/978-3-030-58604-1_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"be8466427dabfcade797fb802a36a71b90325c30\",\"title\":\"Toward Fine-grained Facial Expression Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/be8466427dabfcade797fb802a36a71b90325c30\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15327\",\"authors\":[{\"authorId\":\"48319922\",\"name\":\"A. Bar\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"122024152\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"title\":\"Compositional Video Synthesis with Action Graphs\",\"url\":\"https://www.semanticscholar.org/paper/cdc4ae0adcff94e9ea4591f25b81f88c93cb4fbe\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":4475365,\"doi\":\"10.1109/CVPR.2018.00165\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":84,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778989\",\"name\":\"Martin Szummer\"},{\"authorId\":\"1719389\",\"name\":\"Rosalind W. Picard\"}],\"doi\":\"10.1109/ICIP.1996.560871\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd6b50322a2850a66c0363719dff58f9c788af92\",\"title\":\"Temporal texture modeling\",\"url\":\"https://www.semanticscholar.org/paper/dd6b50322a2850a66c0363719dff58f9c788af92\",\"venue\":\"Proceedings of 3rd IEEE International Conference on Image Processing\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1795764\",\"name\":\"Niki Aifanti\"},{\"authorId\":\"144385012\",\"name\":\"C. Papachristou\"},{\"authorId\":\"143685457\",\"name\":\"A. Delopoulos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1af714b92372c8e606485a3982eab2f16772ad8\",\"title\":\"The MUG facial expression database\",\"url\":\"https://www.semanticscholar.org/paper/f1af714b92372c8e606485a3982eab2f16772ad8\",\"venue\":\"11th International Workshop on Image Analysis for Multimedia Interactive Services WIAMIS 10\",\"year\":2010},{\"arxivId\":\"1611.06624\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":\"10.1109/ICCV.2017.308\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"title\":\"Temporal Generative Adversarial Nets with Singular Value Clipping\",\"url\":\"https://www.semanticscholar.org/paper/062c41dad67bb68fefd9ff0c5c4d296e796004dc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.01844\",\"authors\":[{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e0c341351f8f4a39ac890b96217c7f4bde5369\",\"title\":\"A note on the evaluation of generative models\",\"url\":\"https://www.semanticscholar.org/paper/39e0c341351f8f4a39ac890b96217c7f4bde5369\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1507.08750\",\"authors\":[{\"authorId\":\"2894414\",\"name\":\"Junhyuk Oh\"},{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4257bc131c36504a04382290cbc27ca8bb27813\",\"title\":\"Action-Conditional Video Prediction using Deep Networks in Atari Games\",\"url\":\"https://www.semanticscholar.org/paper/e4257bc131c36504a04382290cbc27ca8bb27813\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1610.09585\",\"authors\":[{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"37232298\",\"name\":\"Christopher Olah\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7\",\"title\":\"Conditional Image Synthesis with Auxiliary Classifier GANs\",\"url\":\"https://www.semanticscholar.org/paper/ecc0edd450ae7e52f65ddf61405b30ad6dbabdd7\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1705.10915\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"3468723\",\"name\":\"Vighnesh Birodkar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a8d3ad2b400bcebc9f17b309901ca5ef2e95315\",\"title\":\"Unsupervised Learning of Disentangled Representations from Video\",\"url\":\"https://www.semanticscholar.org/paper/1a8d3ad2b400bcebc9f17b309901ca5ef2e95315\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Xue\"},{\"authorId\":null,\"name\":\"J. Wu\"},{\"authorId\":null,\"name\":\"K. Bouman\"},{\"authorId\":null,\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Probabilistic modeling of future frames from a single image\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems (NIPS)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Kingma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A method for stochastic optimization\",\"url\":\"\",\"venue\":\"International Conference on Learning Representations\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34437150\",\"name\":\"L. Wei\"},{\"authorId\":\"1801789\",\"name\":\"M. Levoy\"}],\"doi\":\"10.1145/344779.345009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1e1a39534aed2cf4894896de75d0ba1fa75ab6a\",\"title\":\"Fast texture synthesis using tree-structured vector quantization\",\"url\":\"https://www.semanticscholar.org/paper/e1e1a39534aed2cf4894896de75d0ba1fa75ab6a\",\"venue\":\"SIGGRAPH '00\",\"year\":2000},{\"arxivId\":\"1606.07536\",\"authors\":[{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2577513\",\"name\":\"Oncel Tuzel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"372bc106c61e7eb004835e85bbfee997409f176a\",\"title\":\"Coupled Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/372bc106c61e7eb004835e85bbfee997409f176a\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1773498\",\"name\":\"Brandon Amos\"},{\"authorId\":\"71697943\",\"name\":\"Bartosz Ludwiczuk\"},{\"authorId\":\"1747303\",\"name\":\"M. Satyanarayanan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"82e66c4832386cafcec16b92ac88088ffd1a1bc9\",\"title\":\"OpenFace: A general-purpose face recognition library with mobile applications\",\"url\":\"https://www.semanticscholar.org/paper/82e66c4832386cafcec16b92ac88088ffd1a1bc9\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1502.04623\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"title\":\"DRAW: A Recurrent Neural Network For Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1711.11566\",\"authors\":[{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"47139824\",\"name\":\"A. Fitzgibbon\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f52df35087ef9f93c211d679c65485250b11ac1\",\"title\":\"Hybrid VAE: Improving Deep Generative Models using Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/1f52df35087ef9f93c211d679c65485250b11ac1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Hong\"},{\"authorId\":null,\"name\":\"X. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Decom - posing motion and content for natural video sequence prediction Generating videos with scene dynamics\",\"url\":\"\",\"venue\":\"Advances In Neural Information Processing Systems\",\"year\":2016},{\"arxivId\":\"1705.09367\",\"authors\":[{\"authorId\":\"145169194\",\"name\":\"K. Roth\"},{\"authorId\":\"40401747\",\"name\":\"A. Lucchi\"},{\"authorId\":\"2388416\",\"name\":\"Sebastian Nowozin\"},{\"authorId\":\"143936663\",\"name\":\"Thomas Hofmann\"}],\"doi\":\"10.3929/ETHZ-B-000223162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"698d3b667a7f3073eed8368d9daf84f990c24a65\",\"title\":\"Stabilizing Training of Generative Adversarial Networks through Regularization\",\"url\":\"https://www.semanticscholar.org/paper/698d3b667a7f3073eed8368d9daf84f990c24a65\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1804.08264\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3123266.3127905\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"883224c3b28b0563a393746066738f52e6fcc70d\",\"title\":\"To Create What You Tell: Generating Videos from Captions\",\"url\":\"https://www.semanticscholar.org/paper/883224c3b28b0563a393746066738f52e6fcc70d\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1312.6114\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"title\":\"Auto-Encoding Variational Bayes\",\"url\":\"https://www.semanticscholar.org/paper/5f5dc5b9a2ba710937e2c413b37b053cd673df02\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1701.00160\",\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c740e574eea66fdcf473e15ed2c228baef2eccd\",\"title\":\"NIPS 2016 Tutorial: Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2c740e574eea66fdcf473e15ed2c228baef2eccd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1502.02761\",\"authors\":[{\"authorId\":\"1980990\",\"name\":\"Y. Li\"},{\"authorId\":\"1754860\",\"name\":\"Kevin Swersky\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8b509be29721ee6b12c880b4d97ed6b60bad217\",\"title\":\"Generative Moment Matching Networks\",\"url\":\"https://www.semanticscholar.org/paper/c8b509be29721ee6b12c880b4d97ed6b60bad217\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1701.08435\",\"authors\":[{\"authorId\":\"3038326\",\"name\":\"Joost R. van Amersfoort\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8be0084625e2baffcbb2e39f9f61aadbd658b1cc\",\"title\":\"Transformation-Based Models of Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/8be0084625e2baffcbb2e39f9f61aadbd658b1cc\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I. Durugkar\"},{\"authorId\":null,\"name\":\"I. Gemp\"},{\"authorId\":null,\"name\":\"S. Mahadevan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Generative multiadversarial networks\",\"url\":\"\",\"venue\":\"International Conference on Learning Representation\",\"year\":2017},{\"arxivId\":\"1706.08033\",\"authors\":[{\"authorId\":\"144543406\",\"name\":\"R. Villegas\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"2241528\",\"name\":\"Seunghoon Hong\"},{\"authorId\":\"10668384\",\"name\":\"Xunyu Lin\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"title\":\"Decomposing Motion and Content for Natural Video Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b8375ff50b8a6f1a10dd809129a18df96888ac8b\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1605.05396\",\"authors\":[{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2876316\",\"name\":\"L. Logeswaran\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"title\":\"Generative Adversarial Text to Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1812.08008\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"2915997\",\"name\":\"T. \\u0160imon\"},{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2017.143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e8db1519245426f3a78752a3d8360484f4626b1\",\"title\":\"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields\",\"url\":\"https://www.semanticscholar.org/paper/9e8db1519245426f3a78752a3d8360484f4626b1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1412.3555\",\"authors\":[{\"authorId\":\"8270717\",\"name\":\"J. Chung\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"title\":\"Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling\",\"url\":\"https://www.semanticscholar.org/paper/adfcf065e15fd3bc9badf6145034c84dfb08f204\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1710.10196\",\"authors\":[{\"authorId\":\"2976930\",\"name\":\"Tero Karras\"},{\"authorId\":\"1761103\",\"name\":\"Timo Aila\"},{\"authorId\":\"36436218\",\"name\":\"S. Laine\"},{\"authorId\":\"49244945\",\"name\":\"J. Lehtinen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"744fe47157477235032f7bb3777800f9f2f45e52\",\"title\":\"Progressive Growing of GANs for Improved Quality, Stability, and Variation\",\"url\":\"https://www.semanticscholar.org/paper/744fe47157477235032f7bb3777800f9f2f45e52\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1703.00848\",\"authors\":[{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":null,\"name\":\"Thomas Breuel\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b69badabc3fddc9710faa44c530473397303b0b9\",\"title\":\"Unsupervised Image-to-Image Translation Networks\",\"url\":\"https://www.semanticscholar.org/paper/b69badabc3fddc9710faa44c530473397303b0b9\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M.-Y. Liu\"},{\"authorId\":null,\"name\":\"T. Breuel\"},{\"authorId\":null,\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsupervised image-toimage translation networks\",\"url\":\"\",\"venue\":\"Advances in Neural Information Processing Systems (NIPS)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1401.4082\",\"authors\":[{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"14594344\",\"name\":\"S. Mohamed\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f87247fb37f6b48da0757d7a1acf38da44510cdb\",\"title\":\"Stochastic Back-propagation and Variational Inference in Deep Latent Gaussian Models\",\"url\":\"https://www.semanticscholar.org/paper/f87247fb37f6b48da0757d7a1acf38da44510cdb\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1606.03498\",\"authors\":[{\"authorId\":\"2887364\",\"name\":\"Tim Salimans\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"34415167\",\"name\":\"Vicki Cheung\"},{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"571b0750085ae3d939525e62af510ee2cee9d5ea\",\"title\":\"Improved Techniques for Training GANs\",\"url\":\"https://www.semanticscholar.org/paper/571b0750085ae3d939525e62af510ee2cee9d5ea\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1610.00527\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b01871c114b122340209562972ff515b86b16ccf\",\"title\":\"Video Pixel Networks\",\"url\":\"https://www.semanticscholar.org/paper/b01871c114b122340209562972ff515b86b16ccf\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736352\",\"name\":\"Gianfranco Doretto\"},{\"authorId\":\"1689638\",\"name\":\"A. Chiuso\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"},{\"authorId\":\"1715959\",\"name\":\"Stefano Soatto\"}],\"doi\":\"10.1023/A:1021669406132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eff232152d27e3f8f0d82457187ce7caf3edec66\",\"title\":\"Dynamic Textures\",\"url\":\"https://www.semanticscholar.org/paper/eff232152d27e3f8f0d82457187ce7caf3edec66\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":\"1611.04076\",\"authors\":[{\"authorId\":\"34443348\",\"name\":\"Xudong Mao\"},{\"authorId\":\"153082769\",\"name\":\"Q. Li\"},{\"authorId\":\"49838750\",\"name\":\"Haoran Xie\"},{\"authorId\":\"144031692\",\"name\":\"Raymond Y. K. Lau\"},{\"authorId\":\"50218420\",\"name\":\"Z. Wang\"},{\"authorId\":\"32309056\",\"name\":\"Stephen Paul Smolley\"}],\"doi\":\"10.1109/ICCV.2017.304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74ff6d48f9c62e937023106629d27ef2d2ddf8bc\",\"title\":\"Least Squares Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/74ff6d48f9c62e937023106629d27ef2d2ddf8bc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":\"1606.05328\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"2311318\",\"name\":\"Lasse Espeholt\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0936352b78a52bc5d2b5e3f04233efc56664af51\",\"title\":\"Conditional Image Generation with PixelCNN Decoders\",\"url\":\"https://www.semanticscholar.org/paper/0936352b78a52bc5d2b5e3f04233efc56664af51\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1612.00005\",\"authors\":[{\"authorId\":\"151414531\",\"name\":\"Anh M Nguyen\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"}],\"doi\":\"10.1109/CVPR.2017.374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b40fe1a9d25d5694c7ea40a57d0aaa2e2cd5dd1\",\"title\":\"Plug & Play Generative Networks: Conditional Iterative Generation of Images in Latent Space\",\"url\":\"https://www.semanticscholar.org/paper/1b40fe1a9d25d5694c7ea40a57d0aaa2e2cd5dd1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1602.05110\",\"authors\":[{\"authorId\":\"2903841\",\"name\":\"D. Im\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"145079150\",\"name\":\"Hui Jiang\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"32c09d2933a4638b034343f9be20544dacf6031f\",\"title\":\"Generating images with recurrent adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/32c09d2933a4638b034343f9be20544dacf6031f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50170517\",\"name\":\"Moshe Blank\"},{\"authorId\":\"3089071\",\"name\":\"Lena Gorelick\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1760994\",\"name\":\"R. Basri\"}],\"doi\":\"10.1109/ICCV.2005.28\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"title\":\"Actions as space-time shapes\",\"url\":\"https://www.semanticscholar.org/paper/1a9eb04b9b07d4a58aa78eb9f68a77ade0199fab\",\"venue\":\"Tenth IEEE International Conference on Computer Vision (ICCV'05) Volume 1\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/CVPR.2017.119\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f909213520fdb58ac30f60a81d9fd3ca665b638c\",\"title\":\"Synthesizing Dynamic Patterns by Spatial-Temporal Generative ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/f909213520fdb58ac30f60a81d9fd3ca665b638c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1701.07875\",\"authors\":[{\"authorId\":\"2877311\",\"name\":\"Mart\\u00edn Arjovsky\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f85b7376769473d2bed56f855f115e23d727094\",\"title\":\"Wasserstein GAN\",\"url\":\"https://www.semanticscholar.org/paper/2f85b7376769473d2bed56f855f115e23d727094\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1606.03657\",\"authors\":[{\"authorId\":\"41192764\",\"name\":\"Xi Chen\"},{\"authorId\":\"144581158\",\"name\":\"Yan Duan\"},{\"authorId\":\"3127100\",\"name\":\"Rein Houthooft\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35da0a2001eea88486a5de677ab97868c93d0824\",\"title\":\"InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/35da0a2001eea88486a5de677ab97868c93d0824\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"8252749\",\"name\":\"E. Matsumoto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0f4f16d5b5f9efe304369120651fa688a03d495\",\"title\":\"Temporal Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/f0f4f16d5b5f9efe304369120651fa688a03d495\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1506.05751\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"title\":\"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"venue\":\"NIPS\",\"year\":2015}],\"title\":\"MoCoGAN: Decomposing Motion and Content for Video Generation\",\"topics\":[{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Stochastic process\",\"topicId\":\"21302\",\"url\":\"https://www.semanticscholar.org/topic/21302\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"STRIDE (security)\",\"topicId\":\"472435\",\"url\":\"https://www.semanticscholar.org/topic/472435\"},{\"topic\":\"Padding (cryptography)\",\"topicId\":\"190727\",\"url\":\"https://www.semanticscholar.org/topic/190727\"},{\"topic\":\"Nonlinear system\",\"topicId\":\"5329\",\"url\":\"https://www.semanticscholar.org/topic/5329\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Kernel (operating system)\",\"topicId\":\"22866\",\"url\":\"https://www.semanticscholar.org/topic/22866\"}],\"url\":\"https://www.semanticscholar.org/paper/e76edb86f270c3a77ed9f5a1e1b305461f36f96f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"