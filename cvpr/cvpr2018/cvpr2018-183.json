"{\"abstract\":\"Video frame interpolation algorithms typically estimate optical flow or its variations and then use it to guide the synthesis of an intermediate frame between two consecutive original frames. To handle challenges like occlusion, bidirectional flow between the two input frames is often estimated and used to warp and blend the input frames. However, how to effectively blend the two warped frames still remains a challenging problem. This paper presents a context-aware synthesis approach that warps not only the input frames but also their pixel-wise contextual information and uses them to interpolate a high-quality intermediate frame. Specifically, we first use a pre-trained neural network to extract per-pixel contextual information for input frames. We then employ a state-of-the-art optical flow algorithm to estimate bidirectional flow between them and pre-warp both input frames and their context maps. Finally, unlike common approaches that blend the pre-warped frames, our method feeds them and their context maps to a video frame synthesis neural network to produce the interpolated frame in a context-aware fashion. Our neural network is fully convolutional and is trained end to end. Our experiments show that our method can handle challenging scenarios such as occlusion and large motion and outperforms representative state-of-the-art approaches.\",\"arxivId\":\"1803.10967\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\",\"url\":\"https://www.semanticscholar.org/author/39644974\"},{\"authorId\":\"40405236\",\"name\":\"Feng Liu\",\"url\":\"https://www.semanticscholar.org/author/40405236\"}],\"citationVelocity\":40,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"11383846\",\"name\":\"Huayi Jin\"},{\"authorId\":\"3070171\",\"name\":\"Chentao Wu\"},{\"authorId\":\"144629981\",\"name\":\"X. Xie\"},{\"authorId\":\"37514980\",\"name\":\"J. Li\"},{\"authorId\":\"1697293\",\"name\":\"M. Guo\"},{\"authorId\":\"145423618\",\"name\":\"H. Lin\"},{\"authorId\":\"49051516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1145/3337821.3337869\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dee0e379fa0a513969c345f239b15cfdeea33c8e\",\"title\":\"Approximate Code: A Cost-Effective Erasure Coding Framework for Tiered Video Storage in Cloud Systems\",\"url\":\"https://www.semanticscholar.org/paper/dee0e379fa0a513969c345f239b15cfdeea33c8e\",\"venue\":\"ICPP\",\"year\":2019},{\"arxivId\":\"2008.04149\",\"authors\":[{\"authorId\":\"1597361648\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"1723442179\",\"name\":\"Bo Zhang\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"title\":\"Deep Sketch-guided Cartoon Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66152807\",\"name\":\"J. Lee\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"34273166\",\"name\":\"Hoang M. Le\"},{\"authorId\":\"153035663\",\"name\":\"F. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"title\":\"/ Appearance Flow Completion for Novel View Synthesis Dense Flow Estimator Sparse Flow Estimator Sparse Flow Estimator Sparse Flow Estimator\",\"url\":\"https://www.semanticscholar.org/paper/55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\"}],\"doi\":\"10.1109/CVPR.2019.00250\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557382867\",\"name\":\"Siyao Li\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"98350705\",\"name\":\"Z. Pan\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":\"10.1109/ICCVW.2019.00425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"title\":\"Quadratic Video Interpolation for VTSR Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/CVPR42600.2020.00548\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"144992103\",\"name\":\"C. Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"77f5496935d01c06a4e0c301be42d388e9d73a99\",\"title\":\"Depth-Aware Video Frame Interpolation Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/77f5496935d01c06a4e0c301be42d388e9d73a99\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.06348\",\"authors\":[{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"11815649\",\"name\":\"H. Shen\"},{\"authorId\":\"47033130\",\"name\":\"Lichao Huang\"},{\"authorId\":\"98788334\",\"name\":\"Meining Lu\"},{\"authorId\":\"71628916\",\"name\":\"Tong Chen\"},{\"authorId\":\"1762531\",\"name\":\"Zhan Ma\"}],\"doi\":\"10.1609/AAAI.V34I07.6825\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"239f5664c65312b9baab166028918944d466553c\",\"title\":\"Learned Video Compression via Joint Spatial-Temporal Correlation Exploration\",\"url\":\"https://www.semanticscholar.org/paper/239f5664c65312b9baab166028918944d466553c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486417554\",\"name\":\"Ren-Yu Tseng\"},{\"authorId\":\"1604961801\",\"name\":\"Yao-Kai Liu\"},{\"authorId\":\"37284667\",\"name\":\"Ju-Chin Chen\"},{\"authorId\":\"21754565\",\"name\":\"Kawuu W. Lin\"}],\"doi\":\"10.1109/TAAI48200.2019.8959822\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"title\":\"Adaptive Frame Interpolation using an End-to-End Deep Net with High Quality Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"venue\":\"2019 International Conference on Technologies and Applications of Arti\\ufb01cial Intelligence (TAAI)\",\"year\":2019},{\"arxivId\":\"2002.12259\",\"authors\":[{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.00516\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"title\":\"Blurry Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152993838\",\"name\":\"Junwoo Park\"},{\"authorId\":\"145212199\",\"name\":\"Je-Chang Jeong\"}],\"doi\":\"10.1109/CVPRW50498.2020.00258\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"938615f99f3d31fad4f3930b780b6afcb9ab9e9c\",\"title\":\"Joint Learning of Blind Video Denoising and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/938615f99f3d31fad4f3930b780b6afcb9ab9e9c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1909.09725\",\"authors\":[{\"authorId\":\"2181063\",\"name\":\"Qiqi Hou\"},{\"authorId\":\"48521790\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00423\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b966323f8ba738d9a50bc093fb6ab9fef7a9f3d\",\"title\":\"Context-Aware Image Matting for Simultaneous Foreground and Alpha Estimation\",\"url\":\"https://www.semanticscholar.org/paper/9b966323f8ba738d9a50bc093fb6ab9fef7a9f3d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00433\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2141bb1226997c49123731d97b484ca19696485a\",\"title\":\"Robust Temporal Super-Resolution for Dynamic Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/2141bb1226997c49123731d97b484ca19696485a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1911.00627\",\"authors\":[{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"123100665\",\"name\":\"Q. Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6296ec34c6e792729ec47195727d2ab17d27a50e\",\"title\":\"Quadratic video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6296ec34c6e792729ec47195727d2ab17d27a50e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2006.00781\",\"authors\":[{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"1693096275\",\"name\":\"Lu Wang\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"47087084\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"28094546\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"88cc19540cd3785ae2225980220bfe8f91dd0015\",\"title\":\"Reducing the X-ray radiation exposure frequency in cardio-angiography via deep-learning based video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88cc19540cd3785ae2225980220bfe8f91dd0015\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05666\",\"authors\":[{\"authorId\":\"3320198\",\"name\":\"Hyomin Choi\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7583d4f74b2e3dd76084a1166bdc9ea1ecbbe075\",\"title\":\"Affine Transformation-Based Deep Frame Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7583d4f74b2e3dd76084a1166bdc9ea1ecbbe075\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.10680\",\"authors\":[{\"authorId\":\"49473017\",\"name\":\"Zhihao Shi\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"153250595\",\"name\":\"K. Shi\"},{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"title\":\"Video Interpolation via Generalized Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153690347\",\"name\":\"Yoonmo Yang\"},{\"authorId\":\"1831183\",\"name\":\"Byung Tae Oh\"}],\"doi\":\"10.1016/j.image.2020.115982\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"title\":\"Video frame interpolation using deep cascaded network structure\",\"url\":\"https://www.semanticscholar.org/paper/a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626101034\",\"name\":\"Nguyen Van Thang\"},{\"authorId\":\"1390764531\",\"name\":\"Kyujoong Lee\"},{\"authorId\":\"3090069\",\"name\":\"Hyuk-Jae Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2982039\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"title\":\"A Stacked Deep MEMC Network for Frame Rate Up Conversion and its Application to HEVC\",\"url\":\"https://www.semanticscholar.org/paper/1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.13084\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13034a395d5c6728c9b11e777828d9998018cbf6\",\"title\":\"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/13034a395d5c6728c9b11e777828d9998018cbf6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388359\",\"name\":\"C. Li\"},{\"authorId\":\"1987649\",\"name\":\"Youdong Ding\"},{\"authorId\":\"46806278\",\"name\":\"Ting Yu\"},{\"authorId\":\"145093161\",\"name\":\"M. Xu\"},{\"authorId\":\"1769443\",\"name\":\"Q. Zhang\"}],\"doi\":\"10.1109/ICALIP.2018.8455233\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd5ec545315814204d4aae64647347caa92493f6\",\"title\":\"Inpainting of Continuous Frames of Old Movies Based on Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/dd5ec545315814204d4aae64647347caa92493f6\",\"venue\":\"2018 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2018},{\"arxivId\":\"2002.12106\",\"authors\":[{\"authorId\":\"51308376\",\"name\":\"A. Paliwal\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"}],\"doi\":\"10.1109/TPAMI.2020.2987316\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"5c82944c88e0be99857a280d8246593842c515a0\",\"title\":\"Deep Slow Motion Video Reconstruction With Hybrid Imaging System\",\"url\":\"https://www.semanticscholar.org/paper/5c82944c88e0be99857a280d8246593842c515a0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98080420\",\"name\":\"Hyeongmin Lee\"},{\"authorId\":\"48271129\",\"name\":\"Taeoh Kim\"},{\"authorId\":\"3305074\",\"name\":\"Tae-Young Chung\"},{\"authorId\":\"48322708\",\"name\":\"Daehyun Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"3055035\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"946a9a5d18a423de9c109087ecae818809276b9c\",\"title\":\"Learning Spatial Transform for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/946a9a5d18a423de9c109087ecae818809276b9c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050685\",\"name\":\"N. Zeng\"},{\"authorId\":\"50579892\",\"name\":\"Y. Chen\"},{\"authorId\":\"66471163\",\"name\":\"Y. Gu\"},{\"authorId\":\"27630525\",\"name\":\"Dong-dong Liu\"},{\"authorId\":\"1430778430\",\"name\":\"Yunbing Xing\"}],\"doi\":\"10.1109/SMC42975.2020.9283193\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"title\":\"Highly Fluent Sign Language Synthesis Based on Variable Motion Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145871212\",\"name\":\"M. Lu\"},{\"authorId\":\"143657776\",\"name\":\"M. Cheng\"},{\"authorId\":\"3237008\",\"name\":\"Q. Shen\"},{\"authorId\":\"1800270\",\"name\":\"Y. Xu\"},{\"authorId\":\"1762531\",\"name\":\"Zhan Ma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"375f3cf2950dc948cbecc6eede13123979ab5f92\",\"title\":\"Collaborative Processing System for Networked Video Applications\",\"url\":\"https://www.semanticscholar.org/paper/375f3cf2950dc948cbecc6eede13123979ab5f92\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491246951\",\"name\":\"Nour Hobloss\"},{\"authorId\":\"3150575\",\"name\":\"Andrei I. Purica\"},{\"authorId\":\"1768915\",\"name\":\"Attilio Fiandrotti\"},{\"authorId\":\"3129876\",\"name\":\"Marco Cagnazzo\"},{\"authorId\":\"1491246955\",\"name\":\"R\\u00e9mi Cozot\"},{\"authorId\":\"1931304\",\"name\":\"W. Hamidouche\"}],\"doi\":\"10.1109/IC3D48390.2019.8976000\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c888e6180bfbad01e65622f5fbdb1b4cdaac4846\",\"title\":\"A Hybrid Approach to Wide Baseline View Synthesis with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c888e6180bfbad01e65622f5fbdb1b4cdaac4846\",\"venue\":\"2019 International Conference on 3D Immersion (IC3D)\",\"year\":2019},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00779\",\"authors\":[{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"},{\"authorId\":\"9535762\",\"name\":\"Janghoon Choi\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00946\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"title\":\"Scene-Adaptive Video Frame Interpolation via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.10898\",\"authors\":[{\"authorId\":\"89952912\",\"name\":\"M. Claus\"},{\"authorId\":\"21225169\",\"name\":\"J. V. Gemert\"}],\"doi\":\"10.1109/CVPRW.2019.00235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b42fd2d5e4167a5b4c29b71e086ce2487032a6e\",\"title\":\"ViDeNN: Deep Blind Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/0b42fd2d5e4167a5b4c29b71e086ce2487032a6e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1909.05483\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"48521790\",\"name\":\"F. Liu\"}],\"doi\":\"10.1145/3355089.3356528\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6ff787a0190e5275e193c9bf57f672c48011d33\",\"title\":\"3D Ken Burns effect from a single image\",\"url\":\"https://www.semanticscholar.org/paper/c6ff787a0190e5275e193c9bf57f672c48011d33\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":\"1906.05928\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/ICCV.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"title\":\"Unsupervised Video Interpolation Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.06294\",\"authors\":[{\"authorId\":\"14042304\",\"name\":\"Zhewei Huang\"},{\"authorId\":\"123437116\",\"name\":\"Tianyuan Zhang\"},{\"authorId\":\"145577184\",\"name\":\"Wen Heng\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"35132667\",\"name\":\"Shuchang Zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"title\":\"RIFE: Real-Time Intermediate Flow Estimation for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/62282171ef5ea9fa6dd5be80874336f04cfb6939\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98485019\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"title\":\"High-speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.02641\",\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3363550\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1d6d8458ba00395159871106a0665403a00cfe5\",\"title\":\"Deep Iterative Frame Interpolation for Full-frame Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/c1d6d8458ba00395159871106a0665403a00cfe5\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2005.01233\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"48206011\",\"name\":\"Hee-won Kim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152283843\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"1585142097\",\"name\":\"Zhiyong Gaon\"},{\"authorId\":\"2812984\",\"name\":\"G. Chen\"},{\"authorId\":\"7774660\",\"name\":\"Yunhua Lu\"},{\"authorId\":\"46585842\",\"name\":\"R. Duan\"},{\"authorId\":\"150321531\",\"name\":\"Tong Liu\"},{\"authorId\":\"47059427\",\"name\":\"L. Zhang\"},{\"authorId\":\"120878650\",\"name\":\"Woonsung Park\"},{\"authorId\":\"47596916\",\"name\":\"M. Kim\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"104101992\",\"name\":\"L. Aloni\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"116295634\",\"name\":\"Ze Pan\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00421\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3247a8640db63c638a1386493a87202aa2a0b15b\",\"title\":\"AIM 2019 Challenge on Video Temporal Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/3247a8640db63c638a1386493a87202aa2a0b15b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"2512006\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1117/1.JEI.28.4.043002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"title\":\"Multiframe interpolation for video using phase features\",\"url\":\"https://www.semanticscholar.org/paper/579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3030828\",\"name\":\"Arun Sankisa\"},{\"authorId\":\"48654737\",\"name\":\"Arjun Punjabi\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"}],\"doi\":\"10.1007/s11760-020-01671-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4eb9d45b42bea8abc3aeb591f45049ae7595525\",\"title\":\"Temporal capsule networks for video motion estimation and error concealment\",\"url\":\"https://www.semanticscholar.org/paper/d4eb9d45b42bea8abc3aeb591f45049ae7595525\",\"venue\":\"Signal Image Video Process.\",\"year\":2020},{\"arxivId\":\"1901.06034\",\"authors\":[{\"authorId\":\"144796690\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/WACV.2019.00237\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9ed892e7787805e2202d006687ac69fea6bab0a5\",\"title\":\"High-Speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/9ed892e7787805e2202d006687ac69fea6bab0a5\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2007.11762\",\"authors\":[{\"authorId\":\"35793956\",\"name\":\"Zhixiang Chi\"},{\"authorId\":\"49456126\",\"name\":\"R. Nasiri\"},{\"authorId\":\"2114344\",\"name\":\"Z. Liu\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"37932469\",\"name\":\"K. Plataniotis\"}],\"doi\":\"10.1007/978-3-030-58583-9_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e07d015d548162756e479934b245299e4aa737d0\",\"title\":\"All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e07d015d548162756e479934b245299e4aa737d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.01026\",\"authors\":[{\"authorId\":\"46917346\",\"name\":\"Amy Zhao\"},{\"authorId\":\"47231927\",\"name\":\"G. Balakrishnan\"},{\"authorId\":\"40649030\",\"name\":\"Kathleen M. Lewis\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1724429\",\"name\":\"J. Guttag\"},{\"authorId\":\"3046516\",\"name\":\"Adrian V. Dalca\"}],\"doi\":\"10.1109/cvpr42600.2020.00846\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"title\":\"Painting Many Pasts: Synthesizing Time Lapse Videos of Paintings\",\"url\":\"https://www.semanticscholar.org/paper/5e65da0b6621deb8427b8c6794a1b08b47c4a907\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890383\",\"name\":\"Yu Zhang\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"144667540\",\"name\":\"Z. Jiang\"},{\"authorId\":\"10775732\",\"name\":\"Xiaohao Chen\"}],\"doi\":\"10.1109/CVPR.2019.00601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06e89127926108353b02fd64e60e80fc24412816\",\"title\":\"Structure-Preserving Stereoscopic View Synthesis With Multi-Scale Adversarial Correlation Matching\",\"url\":\"https://www.semanticscholar.org/paper/06e89127926108353b02fd64e60e80fc24412816\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.12942\",\"authors\":[{\"authorId\":\"92403059\",\"name\":\"Zheyu Yang\"},{\"authorId\":\"72500851\",\"name\":\"Yujie Wu\"},{\"authorId\":\"80816621\",\"name\":\"Guanrui Wang\"},{\"authorId\":\"3365623\",\"name\":\"Y. Yang\"},{\"authorId\":\"1730243\",\"name\":\"Guoqi Li\"},{\"authorId\":\"144284633\",\"name\":\"Lei Deng\"},{\"authorId\":\"47055094\",\"name\":\"J. Zhu\"},{\"authorId\":\"29889772\",\"name\":\"Luping Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"636e62fc0b06c6e5b7d87e07a5bf088eb3ab711e\",\"title\":\"DashNet: A Hybrid Artificial and Spiking Neural Network for High-speed Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/636e62fc0b06c6e5b7d87e07a5bf088eb3ab711e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.00263\",\"authors\":[{\"authorId\":\"12601304\",\"name\":\"Qiangeng Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Weiyue Wang\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1109/WACV45572.2020.9093530\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"title\":\"Stochastic Dynamics for Video Infilling\",\"url\":\"https://www.semanticscholar.org/paper/56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143744989\",\"name\":\"Qianshu Zhu\"},{\"authorId\":\"1641959671\",\"name\":\"Chu Han\"},{\"authorId\":\"2513505\",\"name\":\"Guoqiang Han\"},{\"authorId\":\"50350340\",\"name\":\"Tien-Tsin Wong\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1109/tpami.2020.3001644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27500d4c7a6cef1deb79abdff016217e34a2af71\",\"title\":\"Video Snapshot: Single Image Motion Expansion via Invertible Motion Embedding.\",\"url\":\"https://www.semanticscholar.org/paper/27500d4c7a6cef1deb79abdff016217e34a2af71\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123797012\",\"name\":\"Christopher May\"},{\"authorId\":\"145869839\",\"name\":\"M. Oliveira\"},{\"authorId\":\"1698910\",\"name\":\"D. Aliaga\"}],\"doi\":\"10.1109/TVCG.2020.2992670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"title\":\"Video Folding: Increased Framerate for Semi-Repetitive Sequences.\",\"url\":\"https://www.semanticscholar.org/paper/e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2020},{\"arxivId\":\"1905.11271\",\"authors\":[{\"authorId\":\"123205572\",\"name\":\"Julia Navarro\"},{\"authorId\":\"144797921\",\"name\":\"Neus Sabater\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e709d45a0b50516cd04a09619ef6597ec41d225\",\"title\":\"Learning Occlusion-Aware View Synthesis for Light Fields\",\"url\":\"https://www.semanticscholar.org/paper/6e709d45a0b50516cd04a09619ef6597ec41d225\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39744579\",\"name\":\"Hui Men\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"33920690\",\"name\":\"D. Maurer\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"46356710\",\"name\":\"D. Saupe\"}],\"doi\":\"10.1109/QoMEX.2019.8743221\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af3218b2122817eebfc5d271bbed120504f05342\",\"title\":\"Visual Quality Assessment for Motion Compensated Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af3218b2122817eebfc5d271bbed120504f05342\",\"venue\":\"2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"},{\"authorId\":null,\"name\":\"Yang Zhao\"}],\"doi\":\"10.1109/ACCESS.2019.2940510\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"title\":\"Multi-Frame Pyramid Refinement Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00434\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5981bb0678578dcf75536bdc476a38a7e501a301\",\"title\":\"PoSNet: 4x Video Frame Interpolation Using Position-Specific Flow\",\"url\":\"https://www.semanticscholar.org/paper/5981bb0678578dcf75536bdc476a38a7e501a301\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1811.11745\",\"authors\":[{\"authorId\":\"145661449\",\"name\":\"T. Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":\"10.1109/CVPR.2019.00700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c945dfec0137bcd7886898fa61f46705e00173dc\",\"title\":\"Learning to Synthesize Motion Blur\",\"url\":\"https://www.semanticscholar.org/paper/c945dfec0137bcd7886898fa61f46705e00173dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753738047\",\"name\":\"Kshitija Pandya\"},{\"authorId\":\"1753737879\",\"name\":\"Disha Varshney\"},{\"authorId\":\"1753607722\",\"name\":\"Ashray Aggarwal\"},{\"authorId\":\"115827410\",\"name\":\"Anil Singh Parihar\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"682e288a5870f182e0f92bb4735f5659dff8b94c\",\"title\":\"An Analytical Study of CNN-based Video Frame Interpolation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/682e288a5870f182e0f92bb4735f5659dff8b94c\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59d8f54ac2346a1e31aead38e8a88da64199f941\",\"title\":\"With the emergence of deep neural networks , learning-based techniques have become an increasingly popular tool for novel view synthesis\",\"url\":\"https://www.semanticscholar.org/paper/59d8f54ac2346a1e31aead38e8a88da64199f941\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153269936\",\"name\":\"J. Xiao\"},{\"authorId\":\"49997317\",\"name\":\"Xiaojun Bi\"}],\"doi\":\"10.1109/ACCESS.2020.2995705\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"title\":\"Multi-Scale Attention Generative Adversarial Networks for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2939143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"title\":\"A Multi-Scale Position Feature Transform Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2010.08919\",\"authors\":[{\"authorId\":\"48147750\",\"name\":\"Xiaoyu Xiang\"},{\"authorId\":\"1509526758\",\"name\":\"Qian Lin\"},{\"authorId\":\"1741931\",\"name\":\"J. Allebach\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa47dc058ad0ecdf436d91d9c3308b4a6f919c5e\",\"title\":\"Boosting High-Level Vision with Joint Compression Artifacts Reduction and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/fa47dc058ad0ecdf436d91d9c3308b4a6f919c5e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13170\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR42600.2020.00293\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"title\":\"Space-Time-Aware Multi-Resolution Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94109286\",\"name\":\"Changxu Zhang\"},{\"authorId\":\"22037109\",\"name\":\"T. Chen\"},{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"3237008\",\"name\":\"Q. Shen\"},{\"authorId\":\"152986975\",\"name\":\"Z. Ma\"}],\"doi\":\"10.1109/ICIP.2019.8803151\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4843c54e897c79367a97c56602e8810f57bbff1a\",\"title\":\"Looking-Ahead: Neural Future Video Frame Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4843c54e897c79367a97c56602e8810f57bbff1a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2001.11698\",\"authors\":[{\"authorId\":\"1491292845\",\"name\":\"Zhaotao Wu\"},{\"authorId\":\"1471334007\",\"name\":\"J. Wei\"},{\"authorId\":\"150341007\",\"name\":\"Wenguang Yuan\"},{\"authorId\":\"2246972\",\"name\":\"J. Wang\"},{\"authorId\":\"3198175\",\"name\":\"T. Tasdizen\"}],\"doi\":\"10.3233/FAIA200314\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"title\":\"Inter-slice image augmentation based on frame interpolation for boosting medical image segmentation accuracy\",\"url\":\"https://www.semanticscholar.org/paper/f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2005.01244\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPRW50498.2020.00216\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a64aa20039c7995eb6ff21ae51f92f9e0e2ffe8\",\"title\":\"NTIRE 2020 Challenge on Image and Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/4a64aa20039c7995eb6ff21ae51f92f9e0e2ffe8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2004.10290\",\"authors\":[{\"authorId\":\"71772906\",\"name\":\"Jianping Lin\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"1521935487\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPR42600.2020.00360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5063e8a3f7b5d9997ccc8007762f6e934a1f2d63\",\"title\":\"M-LVC: Multiple Frames Prediction for Learned Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/5063e8a3f7b5d9997ccc8007762f6e934a1f2d63\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1810.08768\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/tpami.2019.2941941\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d833c48334e906537f21757b6f9fa44da66f6c76\",\"title\":\"MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d833c48334e906537f21757b6f9fa44da66f6c76\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1909.13051\",\"authors\":[{\"authorId\":\"143657783\",\"name\":\"M. Cheng\"},{\"authorId\":\"152986975\",\"name\":\"Z. Ma\"},{\"authorId\":\"27996204\",\"name\":\"M. Asif\"},{\"authorId\":\"1800270\",\"name\":\"Y. Xu\"},{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"48480375\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2020.2983371\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c15f40465508aebd351640817ea04cbb881c28e6\",\"title\":\"A Dual Camera System for High Spatiotemporal Resolution Video Acquisition\",\"url\":\"https://www.semanticscholar.org/paper/c15f40465508aebd351640817ea04cbb881c28e6\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2008.05084\",\"authors\":[{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"},{\"authorId\":\"92493482\",\"name\":\"M. Alain\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/MMSP48831.2020.9287105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9456d33164705981170f0bd94ed6c93a1eeb792\",\"title\":\"Self-supervised Light Field View Synthesis Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/b9456d33164705981170f0bd94ed6c93a1eeb792\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":\"2012.13033\",\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c890b5ef847de07393526be4b6e337215e9dc1b6\",\"title\":\"An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c890b5ef847de07393526be4b6e337215e9dc1b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.04642\",\"authors\":[{\"authorId\":\"49422053\",\"name\":\"Yihao Liu\"},{\"authorId\":\"1604613100\",\"name\":\"Liangbin Xie\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"title\":\"Enhanced Quadratic Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"39876415\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023270\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"title\":\"Deep Learning Approach to Video Frame Rate Up-Conversion Using Bilateral Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47939269\",\"name\":\"Fangyuan Wang\"},{\"authorId\":\"1730575\",\"name\":\"Rujing Wang\"},{\"authorId\":\"1994566\",\"name\":\"Chengjun Xie\"},{\"authorId\":\"144861563\",\"name\":\"Po Yang\"},{\"authorId\":\"46458396\",\"name\":\"L. Liu\"}],\"doi\":\"10.1016/j.compag.2020.105222\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4eed3ae3b25ee92607a8f9270725eafe3581be7a\",\"title\":\"Fusing multi-scale context-aware information representation for automatic in-field pest detection and recognition\",\"url\":\"https://www.semanticscholar.org/paper/4eed3ae3b25ee92607a8f9270725eafe3581be7a\",\"venue\":\"Comput. Electron. Agric.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10399052\",\"name\":\"Irene Viola\"},{\"authorId\":\"32111266\",\"name\":\"J. Mulder\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"144022557\",\"name\":\"P. C\\u00e9sar\"}],\"doi\":\"10.1109/AIVR46125.2019.00022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"title\":\"Temporal Interpolation of Dynamic Digital Humans using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47943365\",\"name\":\"Y. Zhou\"},{\"authorId\":\"12186775\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"143663465\",\"name\":\"Huimin Lu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3394171.3413788\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92ff7b00d7782c483ddc239e107acb034cda5536\",\"title\":\"Temporal Denoising Mask Synthesis Network for Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/92ff7b00d7782c483ddc239e107acb034cda5536\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.00346\",\"authors\":[{\"authorId\":\"50096784\",\"name\":\"Ce Wang\"},{\"authorId\":\"145668226\",\"name\":\"S. Zhou\"},{\"authorId\":\"46504246\",\"name\":\"Zhi-wei Cheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"847748ff022accaa73323cf34593fcae8c9f42af\",\"title\":\"First image then video: A two-stage network for spatiotemporal video denoising\",\"url\":\"https://www.semanticscholar.org/paper/847748ff022accaa73323cf34593fcae8c9f42af\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"I. S. Kweon\"}],\"doi\":\"10.1109/ICCVW.2019.00463\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b259156df1f12fd7be68c29462b0f70b97bdb70\",\"title\":\"DIFRINT: Deep Iterative Frame Interpolation for Full-Frame Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/3b259156df1f12fd7be68c29462b0f70b97bdb70\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanru Wang\"},{\"authorId\":\"144616958\",\"name\":\"Zhihao Huang\"},{\"authorId\":\"145153297\",\"name\":\"Hao Zhu\"},{\"authorId\":\"48625282\",\"name\":\"Wei-peng Li\"},{\"authorId\":\"2001120\",\"name\":\"Xun Cao\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1016/j.vrih.2020.04.004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c40e16d81def08d8f9f789acb3f681165fedc78a\",\"title\":\"Interactive free-viewpoint video generation\",\"url\":\"https://www.semanticscholar.org/paper/c40e16d81def08d8f9f789acb3f681165fedc78a\",\"venue\":\"Virtual Real. Intell. Hardw.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145567286\",\"name\":\"Hoang Le\"},{\"authorId\":\"50208066\",\"name\":\"F. Liu\"}],\"doi\":\"10.1111/cgf.13860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26d8da3d2f67e914aa564942d2721e89e221ef52\",\"title\":\"Appearance Flow Completion for Novel View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/26d8da3d2f67e914aa564942d2721e89e221ef52\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657493720\",\"name\":\"Mengshun Hu\"},{\"authorId\":\"144326503\",\"name\":\"L. Liao\"},{\"authorId\":\"91353860\",\"name\":\"Jing Xiao\"},{\"authorId\":\"151484085\",\"name\":\"Lin Gu\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dd58d9765210b676ef07298470e227a077c160b\",\"title\":\"Motion Feedback Design for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6dd58d9765210b676ef07298470e227a077c160b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1809.07759\",\"authors\":[{\"authorId\":\"84509959\",\"name\":\"Mart Kartasev\"},{\"authorId\":\"84650046\",\"name\":\"Carlo Rapisarda\"},{\"authorId\":\"47414172\",\"name\":\"Dominik Fay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1aed5cd540275f86b7019e494be57437c604715\",\"title\":\"Implementing Adaptive Separable Convolution for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f1aed5cd540275f86b7019e494be57437c604715\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2743020\",\"name\":\"Saghi Hajisharif\"}],\"doi\":\"10.3384/diss.diva-163693\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5835e78b7cf7236d4e9b05a4bbf109a0a7184a43\",\"title\":\"Computational Photography : High Dynamic Rangeand Light Fields\",\"url\":\"https://www.semanticscholar.org/paper/5835e78b7cf7236d4e9b05a4bbf109a0a7184a43\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91926911\",\"name\":\"Minho Park\"},{\"authorId\":\"2909533\",\"name\":\"Sangmin Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054744\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"title\":\"Video Frame Interpolation Via Exceptional Motion-Aware Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9508145\",\"name\":\"Morten Hannemose\"},{\"authorId\":\"144454181\",\"name\":\"Janus N\\u00f8rtoft Jensen\"},{\"authorId\":\"48660142\",\"name\":\"G. Einarsson\"},{\"authorId\":\"2579225\",\"name\":\"J. Wilm\"},{\"authorId\":\"2253200\",\"name\":\"A. Dahl\"},{\"authorId\":\"2661305\",\"name\":\"J. Frisvad\"}],\"doi\":\"10.1007/978-3-030-20205-7_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"title\":\"Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow\",\"url\":\"https://www.semanticscholar.org/paper/7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"venue\":\"SCIA\",\"year\":2019},{\"arxivId\":\"2002.11616\",\"authors\":[{\"authorId\":\"48147750\",\"name\":\"Xiaoyu Xiang\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"},{\"authorId\":\"1741931\",\"name\":\"J. Allebach\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00343\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"title\":\"Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.06409\",\"authors\":[{\"authorId\":\"39744579\",\"name\":\"Hui Men\"},{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"69032233\",\"name\":\"D. Saupe\"}],\"doi\":\"10.1007/s41233-020-00037-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2130669a20586814e90aa9feeeae9b165001b4f\",\"title\":\"Subjective annotation for a frame interpolation benchmark using artefact amplification\",\"url\":\"https://www.semanticscholar.org/paper/b2130669a20586814e90aa9feeeae9b165001b4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.00702\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2994471\",\"name\":\"X. Zhang\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"},{\"authorId\":\"34004812\",\"name\":\"N. Wadhwa\"},{\"authorId\":\"145203564\",\"name\":\"R. Garg\"},{\"authorId\":\"1733730707\",\"name\":\"F. Liu\"},{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e982a9f3b6ae7d9e3522d475993e1cc4675f0a6d\",\"title\":\"Learned Dual-View Reflection Removal\",\"url\":\"https://www.semanticscholar.org/paper/e982a9f3b6ae7d9e3522d475993e1cc4675f0a6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.10244\",\"authors\":[{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"3191728\",\"name\":\"T. Chung\"},{\"authorId\":\"48322708\",\"name\":\"D. Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00536\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"title\":\"AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10755743\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"2844427\",\"name\":\"M. Hamanaka\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.5220/0008876600270035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"title\":\"Audio-guided Video Interpolation via Human Pose Features\",\"url\":\"https://www.semanticscholar.org/paper/6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471436975\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"2257525\",\"name\":\"W. Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"},{\"authorId\":\"104009756\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/ACCESS.2019.2959019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"title\":\"Video Frame Synthesis via Plug-and-Play Deep Locally Temporal Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"49521471\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2936549\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"title\":\"FI-Net: A Lightweight Video Frame Interpolation Network Using Feature-Level Flow\",\"url\":\"https://www.semanticscholar.org/paper/00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"6615978\",\"name\":\"Yang Zhao\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"}],\"doi\":\"10.1007/978-3-030-58595-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"title\":\"A Flexible Recurrent Residual Pyramid Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30259343\",\"name\":\"G. Denes\"},{\"authorId\":\"151398439\",\"name\":\"Akshay Jindal\"},{\"authorId\":\"1403855246\",\"name\":\"Aliaksei Mikhailiuk\"},{\"authorId\":\"1742235737\",\"name\":\"Rafa\\u0142 K. Mantiuk\"}],\"doi\":\"10.1145/3386569.3392411\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4623a5414212e1920ad2a84a666cee3eeb86277\",\"title\":\"A perceptual model of motion quality for rendering with adaptive refresh-rate and resolution\",\"url\":\"https://www.semanticscholar.org/paper/f4623a5414212e1920ad2a84a666cee3eeb86277\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2005.08925\",\"authors\":[{\"authorId\":\"2994471\",\"name\":\"X. Zhang\"},{\"authorId\":\"38997345\",\"name\":\"J. Barron\"},{\"authorId\":\"2182697\",\"name\":\"Yun-Ta Tsai\"},{\"authorId\":\"39192292\",\"name\":\"R. Pandey\"},{\"authorId\":\"47957203\",\"name\":\"Xiuming Zhang\"},{\"authorId\":\"47383180\",\"name\":\"R. Ng\"},{\"authorId\":\"48226420\",\"name\":\"D. Jacobs\"}],\"doi\":\"10.1145/3386569.3392390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b8b95cdc82b946d1fca0e461de60a5ba1536590\",\"title\":\"Portrait shadow manipulation\",\"url\":\"https://www.semanticscholar.org/paper/5b8b95cdc82b946d1fca0e461de60a5ba1536590\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"1904.02909\",\"authors\":[{\"authorId\":\"9757384\",\"name\":\"Woon-Sung Park\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b87df69011057c700f581798e8c13667f5205b8e\",\"title\":\"Deep Predictive Video Compression with Bi-directional Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b87df69011057c700f581798e8c13667f5205b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.05362\",\"authors\":[{\"authorId\":\"39744579\",\"name\":\"Hui Men\"},{\"authorId\":\"1745028\",\"name\":\"Hanhe Lin\"},{\"authorId\":\"2215920\",\"name\":\"Vlad Hosu\"},{\"authorId\":\"33920690\",\"name\":\"D. Maurer\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"1775428\",\"name\":\"D. Saupe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec898f980ab2fc9bf7b6ae91948449a338468832\",\"title\":\"Technical Report on Visual Quality Assessment for Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/ec898f980ab2fc9bf7b6ae91948449a338468832\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144796690\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"title\":\"High-speed Video from Asynchronous Camera Array Si\",\"url\":\"https://www.semanticscholar.org/paper/1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8526699\",\"name\":\"Jean Begaint\"},{\"authorId\":\"1679157\",\"name\":\"Franck Galpin\"},{\"authorId\":\"1871505\",\"name\":\"Philippe Guillotel\"},{\"authorId\":\"1780587\",\"name\":\"Christine Guillemot\"}],\"doi\":\"10.1109/DCC.2019.00068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866fd28fc5381032a96d45e81c551c1af99bdec9\",\"title\":\"Deep Frame Interpolation for Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/866fd28fc5381032a96d45e81c551c1af99bdec9\",\"venue\":\"2019 Data Compression Conference (DCC)\",\"year\":2019},{\"arxivId\":\"1912.07213\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"107606159\",\"name\":\"Jihyong Oh\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":\"10.1609/AAAI.V34I07.6788\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09c4801dd2249f912c655887bc0bb6a53ddbab7f\",\"title\":\"FISR: Deep Joint Frame Interpolation and Super-Resolution with A Multi-scale Temporal Loss\",\"url\":\"https://www.semanticscholar.org/paper/09c4801dd2249f912c655887bc0bb6a53ddbab7f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12485\",\"authors\":[{\"authorId\":\"51009710\",\"name\":\"Y. Wu\"},{\"authorId\":\"8159641\",\"name\":\"Qiurui He\"},{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"145203564\",\"name\":\"R. Garg\"},{\"authorId\":\"50763062\",\"name\":\"Jiawen Chen\"},{\"authorId\":\"93554569\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c20889d8497671884a29110ddd8ff1e203c4aee0\",\"title\":\"Single-Image Lens Flare Removal\",\"url\":\"https://www.semanticscholar.org/paper/c20889d8497671884a29110ddd8ff1e203c4aee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49522643\",\"name\":\"Rei Narita\"},{\"authorId\":\"1684365\",\"name\":\"K. Hirakawa\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"}],\"doi\":\"10.1109/ICIP.2019.8803506\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43d5ef1d4737a1da4ad3dbacd9c243186913eee0\",\"title\":\"Optical Flow Based Line Drawing Frame Interpolation Using Distance Transform to Support Inbetweenings\",\"url\":\"https://www.semanticscholar.org/paper/43d5ef1d4737a1da4ad3dbacd9c243186913eee0\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2007.12622\",\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"51268282\",\"name\":\"Keunsoo Ko\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1007/978-3-030-58568-6_7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"title\":\"BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yiding Wang\"},{\"authorId\":\"2601624\",\"name\":\"Weiyan Wang\"},{\"authorId\":\"1908497\",\"name\":\"Junxue Zhang\"},{\"authorId\":\"1727978\",\"name\":\"J. Jiang\"},{\"authorId\":\"40611817\",\"name\":\"K. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ba6bb6915df9b352ed8be591f50ed3d00244670\",\"title\":\"Bridging the Edge-Cloud Barrier for Real-time Advanced Vision Analytics\",\"url\":\"https://www.semanticscholar.org/paper/7ba6bb6915df9b352ed8be591f50ed3d00244670\",\"venue\":\"HotCloud\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152359151\",\"name\":\"Chenxi Tu\"},{\"authorId\":\"49567362\",\"name\":\"E. Takeuchi\"},{\"authorId\":\"1856242\",\"name\":\"Alexander Carballo\"},{\"authorId\":\"1709999\",\"name\":\"K. Takeda\"}],\"doi\":\"10.1109/ACCESS.2019.2935253\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1f39bcb64a8483a57c6301bc878fe95628ec78b\",\"title\":\"Real-Time Streaming Point Cloud Compression for 3D LiDAR Sensor Using U-Net\",\"url\":\"https://www.semanticscholar.org/paper/f1f39bcb64a8483a57c6301bc878fe95628ec78b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"title\":\"A Fast 4 K Video Frame Interpolation Using a Hybrid Task-Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"144816141\",\"name\":\"J. Campos\"},{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/ICCV.2019.00652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"title\":\"Neural Inter-Frame Compression for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01402\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144667531\",\"name\":\"Jean B\\u00e9gaint\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"title\":\"Towards novel inter-prediction methods for image and video compression. (Nouvelles m\\u00e9thodes de pr\\u00e9diction inter-images pour la compression d'images et de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.23919/EUSIPCO.2019.8903168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"title\":\"IEST: Interpolation-Enhanced Shearlet Transform for Light Field Reconstruction Using Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":\"1912.05193\",\"authors\":[{\"authorId\":\"102580872\",\"name\":\"Andr\\u00e9 Nortje\"},{\"authorId\":\"40021784\",\"name\":\"Herman A. Engelbrecht\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1012d2e369d1bc0b49f201fad95fd851bc654467\",\"title\":\"Deep motion estimation for parallel inter-frame prediction in video compression\",\"url\":\"https://www.semanticscholar.org/paper/1012d2e369d1bc0b49f201fad95fd851bc654467\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.02432\",\"authors\":[{\"authorId\":\"2784241\",\"name\":\"Jaeyeon Kang\"},{\"authorId\":\"50008226\",\"name\":\"Younghyun Jo\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-58607-2_41\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"title\":\"Deep Space-Time Video Upsampling Networks\",\"url\":\"https://www.semanticscholar.org/paper/fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10013212\",\"name\":\"Y. Chen\"},{\"authorId\":\"1660984094\",\"name\":\"L. Yan\"},{\"authorId\":\"87178256\",\"name\":\"X. Lin\"}],\"doi\":\"10.5194/isprs-archives-xliii-b2-2020-567-2020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6bdb0acddce0918c8235df0d687a0630571fe40\",\"title\":\"AN AUTOMATIC KEY-FRAME SELECTION METHOD FOR VISUAL ODOMETRY BASED ON THE IMPROVED PWC-NET\",\"url\":\"https://www.semanticscholar.org/paper/c6bdb0acddce0918c8235df0d687a0630571fe40\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"151270904\",\"name\":\"Zhaojing Wen\"},{\"authorId\":\"151483658\",\"name\":\"Wenxue Cui\"},{\"authorId\":\"39618906\",\"name\":\"Rui Wang\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/ICME.2019.00304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"title\":\"Continuous Bidirectional Optical Flow for Video Frame Sequence Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"},{\"authorId\":\"92733026\",\"name\":\"Soon-chul Kwon\"},{\"authorId\":\"1773696\",\"name\":\"Ji-Sang Yoo\"}],\"doi\":\"10.3390/sym11101251\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"title\":\"A Fast 4K Video Frame Interpolation Using a Multi-Scale Optical Flow Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1961467739\",\"name\":\"M. Tseng\"},{\"authorId\":\"2007619711\",\"name\":\"Yen-Chung Chen\"},{\"authorId\":\"1959578097\",\"name\":\"Yi-Lun Lee\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"title\":\"Dual-Stream Fusion Network for Spatiotemporal Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"venue\":\"\",\"year\":2020}],\"corpusId\":4459013,\"doi\":\"10.1109/CVPR.2018.00183\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":26,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"65fadccad0fc743876a259c2b779622636c2ffde\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"101841672\",\"name\":\"Moritz Menze\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1109/CVPR.2015.7298925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edf455c3b5b8d1c6337c72e39940125036354d03\",\"title\":\"Object scene flow for autonomous vehicles\",\"url\":\"https://www.semanticscholar.org/paper/edf455c3b5b8d1c6337c72e39940125036354d03\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153009621\",\"name\":\"Zhefei Yu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1694827\",\"name\":\"Zeng Hu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/TCSVT.2013.2242631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c83b1573163b8794b85e35021a0650945e958da\",\"title\":\"Multi-Level Video Frame Interpolation: Exploiting the Interaction Among Different Levels\",\"url\":\"https://www.semanticscholar.org/paper/2c83b1573163b8794b85e35021a0650945e958da\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/978-1-84882-935-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4282a344671189e17c9c9e00e329fe2d0fa71769\",\"title\":\"Computer Vision - Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/4282a344671189e17c9c9e00e329fe2d0fa71769\",\"venue\":\"Texts in Computer Science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2798258\",\"name\":\"S. E. Chen\"},{\"authorId\":\"145706573\",\"name\":\"L. Williams\"}],\"doi\":\"10.1145/166117.166153\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f68cff502414a4ea054e154c880be150b2ca74eb\",\"title\":\"View interpolation for image synthesis\",\"url\":\"https://www.semanticscholar.org/paper/f68cff502414a4ea054e154c880be150b2ca74eb\",\"venue\":\"SIGGRAPH '93\",\"year\":1993},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2362189\",\"name\":\"L. Rak\\u00eat\"},{\"authorId\":\"3264146\",\"name\":\"Lars Roholm\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-642-33179-4_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"215332019795204eab7cdaae9bc9d8b4ac42e46a\",\"title\":\"Motion Compensated Frame Interpolation with a Symmetric Optical Flow Constraint\",\"url\":\"https://www.semanticscholar.org/paper/215332019795204eab7cdaae9bc9d8b4ac42e46a\",\"venue\":\"ISVC\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1801.06397\",\"authors\":[{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"1695302\",\"name\":\"D. Cremers\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/s11263-018-1082-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec1f3f1f1d9af3046650c3a30f95a7f2f0a78390\",\"title\":\"What Makes Good Synthetic Training Data for Learning Disparity and Optical Flow Estimation?\",\"url\":\"https://www.semanticscholar.org/paper/ec1f3f1f1d9af3046650c3a30f95a7f2f0a78390\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1602.02644\",\"authors\":[{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9179e740dad4ca4c183f7677b854e5b15f9a122f\",\"title\":\"Generating Images with Perceptual Similarity Metrics based on Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/9179e740dad4ca4c183f7677b854e5b15f9a122f\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1707.09405\",\"authors\":[{\"authorId\":\"143832240\",\"name\":\"Qifeng Chen\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/ICCV.2017.168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28eceb438da0b841bbd3d02684dbfa263838ed60\",\"title\":\"Photographic Image Synthesis with Cascaded Refinement Networks\",\"url\":\"https://www.semanticscholar.org/paper/28eceb438da0b841bbd3d02684dbfa263838ed60\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1707.07958\",\"authors\":[{\"authorId\":\"7838570\",\"name\":\"Damien Fourure\"},{\"authorId\":\"2003050\",\"name\":\"R. Emonet\"},{\"authorId\":\"1687778\",\"name\":\"\\u00c9lisa Fromont\"},{\"authorId\":\"1706185\",\"name\":\"D. Muselet\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":\"10.5244/C.31.181\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fb5d9c589ea53f25b981673a7a750e854e7d687\",\"title\":\"Residual Conv-Deconv Grid Network for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1fb5d9c589ea53f25b981673a7a750e854e7d687\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1410.0759\",\"authors\":[{\"authorId\":\"3003738\",\"name\":\"Sharan Chetlur\"},{\"authorId\":\"2266717\",\"name\":\"C. Woolley\"},{\"authorId\":\"2101730\",\"name\":\"Philippe Vandermersch\"},{\"authorId\":\"145678733\",\"name\":\"J. Cohen\"},{\"authorId\":\"145927488\",\"name\":\"John Tran\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31c36d445367ba204244bb74893c5654e31c3869\",\"title\":\"cuDNN: Efficient Primitives for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/31c36d445367ba204244bb74893c5654e31c3869\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2886023\",\"name\":\"Manuel Werlberger\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"2443335\",\"name\":\"M. Unger\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-642-23094-3_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"title\":\"Optical Flow Guided TV-L1 Video Interpolation and Restoration\",\"url\":\"https://www.semanticscholar.org/paper/fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"venue\":\"EMMCVPR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1701.04128\",\"authors\":[{\"authorId\":\"49756115\",\"name\":\"W. Luo\"},{\"authorId\":\"1980990\",\"name\":\"Y. Li\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01a4f33da8ad94ced3cf58548b28dbbb44148571\",\"title\":\"Understanding the Effective Receptive Field in Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/01a4f33da8ad94ced3cf58548b28dbbb44148571\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1609.04802\",\"authors\":[{\"authorId\":\"1779917\",\"name\":\"C. Ledig\"},{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3108066\",\"name\":\"Ferenc Husz\\u00e1r\"},{\"authorId\":\"79382929\",\"name\":\"J. Caballero\"},{\"authorId\":\"83015038\",\"name\":\"Andrew Aitken\"},{\"authorId\":\"41203992\",\"name\":\"Alykhan Tejani\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"152554375\",\"name\":\"W. Shi\"}],\"doi\":\"10.1109/CVPR.2017.19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"title\":\"Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/df0c54fe61f0ffb9f0e36a17c2038d9a1964cba3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1702.06506\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec3472acc24fe5ef9eb07a31697f2cd446c8facc\",\"title\":\"PixelNet: Representation of the pixels, by the pixels, and for the pixels\",\"url\":\"https://www.semanticscholar.org/paper/ec3472acc24fe5ef9eb07a31697f2cd446c8facc\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.03590\",\"authors\":[{\"authorId\":\"2515835\",\"name\":\"Till Kroeger\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46493-0_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"title\":\"Fast Optical Flow Using Dense Inverse Search\",\"url\":\"https://www.semanticscholar.org/paper/9ceb5b92cad5cb135aaab43d4f25a6e34afe6e9f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"}],\"doi\":\"10.1109/TPAMI.2011.236\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"title\":\"Motion Detail Preserving Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10678970\",\"name\":\"Joel Janai\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1109/CVPR.2017.154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bd59b6111c21ca9f133b2ac9f0a8b102e344076\",\"title\":\"Slow Flow: Exploiting High-Speed Cameras for Accurate and Diverse Optical Flow Reference Data\",\"url\":\"https://www.semanticscholar.org/paper/8bd59b6111c21ca9f133b2ac9f0a8b102e344076\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49201933\",\"name\":\"Zhe Ren\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47bc34ae6f5dc104bc289ae3bb4fa75ef75fbc21\",\"title\":\"Unsupervised Deep Learning for Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/47bc34ae6f5dc104bc289ae3bb4fa75ef75fbc21\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2624088\",\"name\":\"Augustus Odena\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"39628969\",\"name\":\"Christopher Olah\"}],\"doi\":\"10.23915/DISTILL.00003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9dab7574d56ae81efe6c90c213c6509b36cf950\",\"title\":\"Deconvolution and Checkerboard Artifacts\",\"url\":\"https://www.semanticscholar.org/paper/d9dab7574d56ae81efe6c90c213c6509b36cf950\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1704.07325\",\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"2774325\",\"name\":\"Ren\\u00e9 Ranftl\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/CVPR.2017.615\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"143e10cae07f27f2db9de171eb04a332ddbfeab4\",\"title\":\"Accurate Optical Flow via Direct Cost Volume Processing\",\"url\":\"https://www.semanticscholar.org/paper/143e10cae07f27f2db9de171eb04a332ddbfeab4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1506.03011\",\"authors\":[{\"authorId\":\"2558463\",\"name\":\"R. Goroshin\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"dd2fa69647160bb2ea25dcc7b2f6409b01e40222\",\"title\":\"Learning to Linearize Under Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/dd2fa69647160bb2ea25dcc7b2f6409b01e40222\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1612.02177\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"1679219\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPR.2017.35\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"65b16da51891a6b98140d425804c8a0fd0299219\",\"title\":\"Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/65b16da51891a6b98140d425804c8a0fd0299219\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1709.02371\",\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00931\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"title\":\"PWC-Net: CNNs for Optical Flow Using Pyramid, Warping, and Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/d92ef81e39d65d89f2c35d63088d1950ed862e7d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1707.05776\",\"authors\":[{\"authorId\":\"2329288\",\"name\":\"P. Bojanowski\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1401804750\",\"name\":\"David Lopez-Paz\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2ef0f1a528cd0f415be8265a04466a6d3f74e6c\",\"title\":\"Optimizing the Latent Space of Generative Networks\",\"url\":\"https://www.semanticscholar.org/paper/e2ef0f1a528cd0f415be8265a04466a6d3f74e6c\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1612.07919\",\"authors\":[{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"}],\"doi\":\"10.1109/ICCV.2017.481\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fddc32f3880688238847077fd927ab3025db7a6a\",\"title\":\"EnhanceNet: Single Image Super-Resolution Through Automated Texture Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/fddc32f3880688238847077fd927ab3025db7a6a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779107\",\"name\":\"Andrea Fusiello\"}],\"doi\":\"10.1201/9781439864319-30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffe6ea1c06641c4f64a6c9612ce832f79344ff7e\",\"title\":\"Image-based Rendering *\",\"url\":\"https://www.semanticscholar.org/paper/ffe6ea1c06641c4f64a6c9612ce832f79344ff7e\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1512.01815\",\"authors\":[{\"authorId\":\"3117463\",\"name\":\"David Gadot\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2016.459\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"cdae1edd4bd2c4c110f992cca57e88afecf5658a\",\"title\":\"PatchBatch: A Batch Augmented Loss for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/cdae1edd4bd2c4c110f992cca57e88afecf5658a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1607.08022\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"63de0ad39d807f0c256f851428f211e8d5fcd3bb\",\"title\":\"Instance Normalization: The Missing Ingredient for Fast Stylization\",\"url\":\"https://www.semanticscholar.org/paper/63de0ad39d807f0c256f851428f211e8d5fcd3bb\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1611.08323\",\"authors\":[{\"authorId\":\"3408089\",\"name\":\"Tobias Pohlen\"},{\"authorId\":\"36665147\",\"name\":\"A. Hermans\"},{\"authorId\":\"11983029\",\"name\":\"Markus Mathias\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":\"10.1109/CVPR.2017.353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bb5081766d84549b3411cb56e60483c33cca52d\",\"title\":\"Full-Resolution Residual Networks for Semantic Segmentation in Street Scenes\",\"url\":\"https://www.semanticscholar.org/paper/1bb5081766d84549b3411cb56e60483c33cca52d\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41210105\",\"name\":\"Zhou Wang\"},{\"authorId\":\"144492850\",\"name\":\"A. Bovik\"},{\"authorId\":\"120732976\",\"name\":\"H.R. Sheikh\"},{\"authorId\":\"122128303\",\"name\":\"E.P. Simoncelli\"}],\"doi\":\"10.1109/TIP.2003.819861\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"title\":\"Image quality assessment: from error visibility to structural similarity\",\"url\":\"https://www.semanticscholar.org/paper/eae2e0fa72e898c289365c0af16daf57a7a6cf40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":\"1609.03552\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46454-1_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc7822f56dd255a872326b9536a0821bbf0277dd\",\"title\":\"Generative Visual Manipulation on the Natural Image Manifold\",\"url\":\"https://www.semanticscholar.org/paper/fc7822f56dd255a872326b9536a0821bbf0277dd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1707.02921\",\"authors\":[{\"authorId\":\"144717485\",\"name\":\"Bee Lim\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"2117564\",\"name\":\"Heewon Kim\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPRW.2017.151\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ba5d3808e117e7a68dc40331ce1d483ceeedcb2\",\"title\":\"Enhanced Deep Residual Networks for Single Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/7ba5d3808e117e7a68dc40331ce1d483ceeedcb2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6376655\",\"name\":\"E. Herbst\"},{\"authorId\":\"116149486\",\"name\":\"S. Seitz\"},{\"authorId\":\"145347688\",\"name\":\"S. Baker\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d41b37c103e3a09f327f28fac6ce18680f3b068e\",\"title\":\"Occlusion Reasoning for Temporal Interpolation using Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/d41b37c103e3a09f327f28fac6ce18680f3b068e\",\"venue\":\"\",\"year\":2009}],\"title\":\"Context-Aware Synthesis for Video Frame Interpolation\",\"topics\":[{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Hidden surface determination\",\"topicId\":\"54802\",\"url\":\"https://www.semanticscholar.org/topic/54802\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Motion estimation\",\"topicId\":\"21398\",\"url\":\"https://www.semanticscholar.org/topic/21398\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Maximum flow problem\",\"topicId\":\"29249\",\"url\":\"https://www.semanticscholar.org/topic/29249\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Jumbo frame\",\"topicId\":\"1265749\",\"url\":\"https://www.semanticscholar.org/topic/1265749\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Frame grabber\",\"topicId\":\"73343\",\"url\":\"https://www.semanticscholar.org/topic/73343\"}],\"url\":\"https://www.semanticscholar.org/paper/65fadccad0fc743876a259c2b779622636c2ffde\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"