"{\"abstract\":\"Automatic saliency prediction in 360\\u00b0 videos is critical for viewpoint guidance applications (e.g., Facebook 360 Guide). We propose a spatial-temporal network which is (1) weakly-supervised trained and (2) tailor-made for 360\\u00b0 viewing sphere. Note that most existing methods are less scalable since they rely on annotated saliency map for training. Most importantly, they convert 360\\u00b0 sphere to 2D images (e.g., a single equirectangular image or multiple separate Normal Field-of-View (NFoV) images) which introduces distortion and image boundaries. In contrast, we propose a simple and effective Cube Padding (CP) technique as follows. Firstly, we render the 360\\u00b0 view on six faces of a cube using perspective projection. Thus, it introduces very little distortion. Then, we concatenate all six faces while utilizing the connectivity between faces on the cube for image padding (i.e., Cube Padding) in convolution, pooling, convolutional LSTM layers. In this way, CP introduces no image boundary while being applicable to almost all Convolutional Neural Network (CNN) structures. To evaluate our method, we propose Wild-360, a new 360\\u00b0 video saliency dataset, containing challenging videos with saliency heatmap annotations. In experiments, our method outperforms baseline methods in both speed and quality.\",\"arxivId\":\"1806.01320\",\"authors\":[{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\",\"url\":\"https://www.semanticscholar.org/author/10796879\"},{\"authorId\":\"50993085\",\"name\":\"Chun-Hung Chao\",\"url\":\"https://www.semanticscholar.org/author/50993085\"},{\"authorId\":\"46181955\",\"name\":\"Jin-Dong Dong\",\"url\":\"https://www.semanticscholar.org/author/46181955\"},{\"authorId\":\"2486384\",\"name\":\"Hao-Kai Wen\",\"url\":\"https://www.semanticscholar.org/author/2486384\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\",\"url\":\"https://www.semanticscholar.org/author/1805102\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\",\"url\":\"https://www.semanticscholar.org/author/145718481\"}],\"citationVelocity\":20,\"citations\":[{\"arxivId\":\"1905.00161\",\"authors\":[{\"authorId\":\"49235564\",\"name\":\"M. Xu\"},{\"authorId\":\"32462959\",\"name\":\"Chen Li\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"}],\"doi\":\"10.1109/JSTSP.2020.2966864\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"title\":\"State-of-the-Art in 360\\u00b0 Video/Image Processing: Perception, Assessment and Compression\",\"url\":\"https://www.semanticscholar.org/paper/42251c77e93610b753afd6b520bc36d5b1f0f33d\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49339104\",\"name\":\"Yufei Zhao\"},{\"authorId\":\"144328506\",\"name\":\"Yong Song\"},{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"7028410\",\"name\":\"Muhammad Sulaman\"},{\"authorId\":\"40908347\",\"name\":\"Zhengkun Guo\"},{\"authorId\":\"38751989\",\"name\":\"X. Yang\"},{\"authorId\":\"9112778\",\"name\":\"F. Wang\"},{\"authorId\":\"1486127476\",\"name\":\"Qun Hao\"}],\"doi\":\"10.1016/j.jvcir.2019.102706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68a002b2280c181f9a78cbd6b931a59dcf269706\",\"title\":\"IR saliency detection via a GCF-SB visual attention framework\",\"url\":\"https://www.semanticscholar.org/paper/68a002b2280c181f9a78cbd6b931a59dcf269706\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3343031.3351019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0a071de110ddf6403939f05b2b751426c1a064c\",\"title\":\"Self-supervised Representation Learning Using 360\\u00b0 Data\",\"url\":\"https://www.semanticscholar.org/paper/c0a071de110ddf6403939f05b2b751426c1a064c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1912.05971\",\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"1474358241\",\"name\":\"Ke Gu\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"title\":\"Toward Better Understanding of Saliency Prediction in Augmented 360 Degree Videos\",\"url\":\"https://www.semanticscholar.org/paper/0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.07064\",\"authors\":[{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1109/cvpr42600.2020.01428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"title\":\"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location\",\"url\":\"https://www.semanticscholar.org/paper/e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"venue\":\"CVPR\",\"year\":2020},{\"arxivId\":\"2003.11927\",\"authors\":[{\"authorId\":\"103275667\",\"name\":\"Jonathan A. Weyn\"},{\"authorId\":\"2787536\",\"name\":\"D. Durran\"},{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"}],\"doi\":\"10.1029/2020MS002109\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c070f42909b6a187c548cac29903e01e4c6bf0\",\"title\":\"Improving data-driven global weather prediction using deep convolutional neural networks on a cubed sphere\",\"url\":\"https://www.semanticscholar.org/paper/51c070f42909b6a187c548cac29903e01e4c6bf0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49673074\",\"name\":\"C. Li\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8d8ff98a5740febb0e03972b7ff6686171f46557\",\"title\":\"Viewport Proposal CNN for 360\\u00b0 Video Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/8d8ff98a5740febb0e03972b7ff6686171f46557\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.09649\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/tpami.2019.2952095\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"title\":\"Learning to Localize Sound Sources in Visual Scenes: Analysis and Applications\",\"url\":\"https://www.semanticscholar.org/paper/edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1901.00979\",\"authors\":[{\"authorId\":\"66982830\",\"name\":\"Alisha Sharma\"},{\"authorId\":\"6439443\",\"name\":\"J. Ventura\"}],\"doi\":\"10.1109/AIVR46125.2019.00018\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"175e69c1b7da1a15b87b24989d61e4c45db9d0f6\",\"title\":\"Unsupervised Learning of Depth and Ego-Motion From Cylindrical Panoramic Video\",\"url\":\"https://www.semanticscholar.org/paper/175e69c1b7da1a15b87b24989d61e4c45db9d0f6\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3459139\",\"name\":\"Fu-En Wang\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"145155317\",\"name\":\"Shang-Ta Yang\"},{\"authorId\":\"9944380\",\"name\":\"Meng-Li Shih\"},{\"authorId\":\"1771281\",\"name\":\"Hung-Kuo Chu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-030-20873-8_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fccaa2a34cdf65b22e86f8fe7aa345caafd5220f\",\"title\":\"Self-supervised Learning of Depth and Camera Motion from 360 ^\\\\circ Videos\",\"url\":\"https://www.semanticscholar.org/paper/fccaa2a34cdf65b22e86f8fe7aa345caafd5220f\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2010.08045\",\"authors\":[{\"authorId\":\"27478395\",\"name\":\"K. Bhandari\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fe75c5f79a6a37d3cc9082ce74048cc48128fc4\",\"title\":\"Revisiting Optical Flow Estimation in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/3fe75c5f79a6a37d3cc9082ce74048cc48128fc4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.00979\",\"authors\":[{\"authorId\":\"66982830\",\"name\":\"Alisha Sharma\"},{\"authorId\":\"6439443\",\"name\":\"J. Ventura\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b430a7b8ba27ffdd992e7bf1d88f2d82849d523e\",\"title\":\"Unsupervised Learning of Depth and Ego-Motion from Panoramic Video\",\"url\":\"https://www.semanticscholar.org/paper/b430a7b8ba27ffdd992e7bf1d88f2d82849d523e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47446930\",\"name\":\"M. Wang\"},{\"authorId\":\"1585598418\",\"name\":\"Xu-Quan Lyu\"},{\"authorId\":\"3013590\",\"name\":\"Y. Li\"},{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"}],\"doi\":\"10.1007/s41095-020-0162-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f01ca56e323616ffa2c95de0659cc15c7f57bf36\",\"title\":\"VR content creation and exploration with deep learning: A survey\",\"url\":\"https://www.semanticscholar.org/paper/f01ca56e323616ffa2c95de0659cc15c7f57bf36\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d62a944e73d47dfb5926c5f4900f624a42e038de\",\"title\":\"COCO-GAN: CONDITIONAL COORDINATE GENERA-\",\"url\":\"https://www.semanticscholar.org/paper/d62a944e73d47dfb5926c5f4900f624a42e038de\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.01712\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"92886287\",\"name\":\"C. Sun\"},{\"authorId\":\"145722791\",\"name\":\"Wen-Yen Chang\"},{\"authorId\":\"122442849\",\"name\":\"Wan-Ting Hsu\"},{\"authorId\":\"152126337\",\"name\":\"Mingqian Sun\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1109/WACV45572.2020.9093262\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bf689dde6301dba14c8492402157ea31dcce6bd\",\"title\":\"360-Indoor: Towards Learning Real-World Objects in 360\\u00b0 Indoor Equirectangular Images\",\"url\":\"https://www.semanticscholar.org/paper/0bf689dde6301dba14c8492402157ea31dcce6bd\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1811.08196\",\"authors\":[{\"authorId\":\"152884180\",\"name\":\"Y. K. Lee\"},{\"authorId\":\"1891887\",\"name\":\"J. Jeong\"},{\"authorId\":\"48422463\",\"name\":\"J. S. Yun\"},{\"authorId\":\"51971351\",\"name\":\"Cho Won June\"},{\"authorId\":\"144295528\",\"name\":\"Kuk-jin Yoon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"65cf0bebf0059edd3527944be581e6a2ab7e9828\",\"title\":\"SpherePHD: Applying CNNs on a Spherical PolyHeDron Representation of 360 degree Images\",\"url\":\"https://www.semanticscholar.org/paper/65cf0bebf0059edd3527944be581e6a2ab7e9828\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.04913\",\"authors\":[{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/JSTSP.2019.2957982\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bacab9f46f2ccd8fec34e8d37d43ef0df2807567\",\"title\":\"Distortion-Adaptive Salient Object Detection in 360$^\\\\circ$ Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/bacab9f46f2ccd8fec34e8d37d43ef0df2807567\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1907.12849\",\"authors\":[{\"authorId\":\"145418233\",\"name\":\"Chao Zhang\"},{\"authorId\":\"2297234\",\"name\":\"Stephan Liwicki\"},{\"authorId\":\"144074557\",\"name\":\"W. Smith\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":\"10.1109/ICCV.2019.00363\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49e0c18ed3d9ca8b9530664b7b544f576a1fdf68\",\"title\":\"Orientation-Aware Semantic Segmentation on Icosahedron Spheres\",\"url\":\"https://www.semanticscholar.org/paper/49e0c18ed3d9ca8b9530664b7b544f576a1fdf68\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380233567\",\"name\":\"Benjamin Attal\"},{\"authorId\":\"153033906\",\"name\":\"Selena Ling\"},{\"authorId\":\"8278433\",\"name\":\"Aaron Gokaslan\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"}],\"doi\":\"10.1007/978-3-030-58452-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ca4088150cab021aae1fd8436faa5631919ae9f\",\"title\":\"MatryODShka: Real-time 6DoF Video View Synthesis using Multi-Sphere Images\",\"url\":\"https://www.semanticscholar.org/paper/2ca4088150cab021aae1fd8436faa5631919ae9f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"27818503\",\"name\":\"Shou-Cheng Yen\"},{\"authorId\":\"2194011\",\"name\":\"C. Huang\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":\"10.1109/TMM.2019.2931807\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee4d8d26ae47a6a8a670d2457700274723cbf357\",\"title\":\"Optimizing Fixation Prediction Using Recurrent Neural Networks for 360$^{\\\\circ }$ Video Streaming in Head-Mounted Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/ee4d8d26ae47a6a8a670d2457700274723cbf357\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3459139\",\"name\":\"Fu-En Wang\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"145155317\",\"name\":\"Shang-Ta Yang\"},{\"authorId\":\"9944380\",\"name\":\"Meng-Li Shih\"},{\"authorId\":\"1771281\",\"name\":\"Hung-Kuo Chu\"},{\"authorId\":\"151688086\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c910351f5555a71acb9c713d639a1e19a48261ac\",\"title\":\"Self-Supervised Learning of Depth and Camera Motion from 360{\\\\deg} Videos\",\"url\":\"https://www.semanticscholar.org/paper/c910351f5555a71acb9c713d639a1e19a48261ac\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.02993\",\"authors\":[{\"authorId\":\"1850406\",\"name\":\"T. Hara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ba1c44ac91b92de1a09a4bb8197fd049e91c4ce\",\"title\":\"Spherical Image Generation from a Single Normal Field of View Image by Considering Scene Symmetry\",\"url\":\"https://www.semanticscholar.org/paper/5ba1c44ac91b92de1a09a4bb8197fd049e91c4ce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.08112\",\"authors\":[{\"authorId\":\"2418323\",\"name\":\"Nikolaos Zioulis\"},{\"authorId\":\"51150187\",\"name\":\"Antonis Karakottas\"},{\"authorId\":\"1737843\",\"name\":\"D. Zarpalas\"},{\"authorId\":\"144827073\",\"name\":\"F. \\u00c1lvarez\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":\"10.1109/3DV.2019.00081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de25d588ba8362713a1d31a5665acab54987eab6\",\"title\":\"Spherical View Synthesis for Self-Supervised 360\\u00b0 Depth Estimation\",\"url\":\"https://www.semanticscholar.org/paper/de25d588ba8362713a1d31a5665acab54987eab6\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145615355\",\"name\":\"Ville M\\u00e4kel\\u00e4\"},{\"authorId\":\"2027121\",\"name\":\"Tuuli Keskinen\"},{\"authorId\":\"134184993\",\"name\":\"J. M\\u00e4kel\\u00e4\"},{\"authorId\":\"2226415\",\"name\":\"Pekka Kallioniemi\"},{\"authorId\":\"36954089\",\"name\":\"Jussi Karhu\"},{\"authorId\":\"4281903\",\"name\":\"K. Ronkainen\"},{\"authorId\":\"81203574\",\"name\":\"A. Burova\"},{\"authorId\":\"3105421\",\"name\":\"Jaakko Hakulinen\"},{\"authorId\":\"2016931\",\"name\":\"M. Turunen\"}],\"doi\":\"10.1145/3317697.3323351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2d6e95fdb42c197abeff0aa6884e7008191e5ba\",\"title\":\"What Are Others Looking at? Exploring 360\\u00b0 Videos on HMDs with Visual Cues about Other Viewers\",\"url\":\"https://www.semanticscholar.org/paper/b2d6e95fdb42c197abeff0aa6884e7008191e5ba\",\"venue\":\"TVX\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153186485\",\"name\":\"Guangxiao Ma\"},{\"authorId\":\"1423476966\",\"name\":\"Shuai Li\"},{\"authorId\":\"3289090\",\"name\":\"Chenglizhao Chen\"},{\"authorId\":\"2252725\",\"name\":\"Ai-min Hao\"},{\"authorId\":\"1830614308\",\"name\":\"Hong Qin\"}],\"doi\":\"10.1109/TVCG.2020.3023636\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4f8cb32d4caddf8a1e25d47ed527a54e682af4f9\",\"title\":\"Stage-wise Salient Object Detection in 360\\u00b0 Omnidirectional Image via Object-level Semantical Saliency Ranking\",\"url\":\"https://www.semanticscholar.org/paper/4f8cb32d4caddf8a1e25d47ed527a54e682af4f9\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103275667\",\"name\":\"Jonathan A. Weyn\"},{\"authorId\":\"2787536\",\"name\":\"D. Durran\"},{\"authorId\":\"145727186\",\"name\":\"R. Caruana\"}],\"doi\":\"10.1002/essoar.10502543.1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"294f64f1890376795003e217ee339708d5347b1d\",\"title\":\"Improving data-driven global weather prediction using deep convolutional neural networks on a cubed sphere\",\"url\":\"https://www.semanticscholar.org/paper/294f64f1890376795003e217ee339708d5347b1d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153664765\",\"name\":\"Stefan Schubert\"},{\"authorId\":\"46380986\",\"name\":\"Peer Neubert\"},{\"authorId\":\"1415115305\",\"name\":\"Johannes P\\u00f6schmann\"},{\"authorId\":\"1789547\",\"name\":\"P. Protzel\"}],\"doi\":\"10.1109/IVS.2019.8813862\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"12ed9158001fc359d9900eae0fe41ef3c4b91d7f\",\"title\":\"Circular Convolutional Neural Networks for Panoramic Images and Laser Data\",\"url\":\"https://www.semanticscholar.org/paper/12ed9158001fc359d9900eae0fe41ef3c4b91d7f\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693368785\",\"name\":\"Carlos Mara\\u00f1es\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"},{\"authorId\":\"116241758\",\"name\":\"A. Serrano\"}],\"doi\":\"10.1109/VR46266.2020.1580727911717\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbe1f8b221b4ba55d8b45b626a6b36a2962681f5\",\"title\":\"Exploring the impact of 360\\u00b0 movie cuts in users\\u2019 attention\",\"url\":\"https://www.semanticscholar.org/paper/dbe1f8b221b4ba55d8b45b626a6b36a2962681f5\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2020},{\"arxivId\":\"2011.10600\",\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"2028199013\",\"name\":\"Marouane Tliba\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"title\":\"ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"5349760\",\"name\":\"Jinming Su\"},{\"authorId\":\"2749565\",\"name\":\"Changqun Xia\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5702271d612281e09627d873cc08c92bab0f715c\",\"title\":\"Distortion-adaptive Salient Object Detection in 360\\u00b0 Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/5702271d612281e09627d873cc08c92bab0f715c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xinyi Wu\"},{\"authorId\":\"153006222\",\"name\":\"Zhenyao Wu\"},{\"authorId\":\"24392163\",\"name\":\"J. Zhang\"},{\"authorId\":\"47668707\",\"name\":\"Li-li Ju\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6927\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"title\":\"SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation-Based ConvLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.08942\",\"authors\":[{\"authorId\":\"1500384130\",\"name\":\"Hong-xiang Chen\"},{\"authorId\":\"9452298\",\"name\":\"Kunhong Li\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"},{\"authorId\":\"35487423\",\"name\":\"Zhiheng Fu\"},{\"authorId\":\"1730228\",\"name\":\"M. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"754cb424e0f9cdcbe4be2e683d503a7e82130f75\",\"title\":\"Distortion-aware Monocular Depth Estimation for Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/754cb424e0f9cdcbe4be2e683d503a7e82130f75\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7956594\",\"name\":\"Mengke Huang\"},{\"authorId\":\"49293102\",\"name\":\"Z. Liu\"},{\"authorId\":\"47949448\",\"name\":\"Gongyang Li\"},{\"authorId\":\"1792646\",\"name\":\"X. Zhou\"},{\"authorId\":\"21120270\",\"name\":\"Olivier Le Meur\"}],\"doi\":\"10.1109/LSP.2020.3028192\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc9522d4e9a70da852087e045efae609e510f26a\",\"title\":\"FANet: Features Adaptation Network for 360$^{\\\\circ }$ Omnidirectional Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/cc9522d4e9a70da852087e045efae609e510f26a\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"1903.06474\",\"authors\":[{\"authorId\":\"3363882\",\"name\":\"I. Agtzidis\"},{\"authorId\":\"145305263\",\"name\":\"M. Startsev\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":\"10.1145/3343031.3350947\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"937bd749a5ab0e3cf5988eab50b5a1e6e7098c9b\",\"title\":\"A Ground-Truth Data Set and a Classification Algorithm for Eye Movements in 360-degree Videos\",\"url\":\"https://www.semanticscholar.org/paper/937bd749a5ab0e3cf5988eab50b5a1e6e7098c9b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.13516\",\"authors\":[{\"authorId\":\"3459139\",\"name\":\"Fu-En Wang\"},{\"authorId\":\"46489395\",\"name\":\"Yu-Hsuan Yeh\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca32372a7fa22b7da98df0d9c420930011debb28\",\"title\":\"LayoutMP3D: Layout Annotation of Matterport3D\",\"url\":\"https://www.semanticscholar.org/paper/ca32372a7fa22b7da98df0d9c420930011debb28\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3459139\",\"name\":\"Fu-En Wang\"},{\"authorId\":\"46489395\",\"name\":\"Yu-Hsuan Yeh\"},{\"authorId\":\"151688086\",\"name\":\"Min Sun\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"}],\"doi\":\"10.1109/CVPR42600.2020.00054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16bda011bb41a6acddb2b6fbc95f305184300153\",\"title\":\"BiFuse: Monocular 360 Depth Estimation via Bi-Projection Fusion\",\"url\":\"https://www.semanticscholar.org/paper/16bda011bb41a6acddb2b6fbc95f305184300153\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.11718\",\"authors\":[{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"36775862\",\"name\":\"K. Sapra\"},{\"authorId\":\"1751019\",\"name\":\"Zhiding Yu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cde8679a0171220d50ac76a629cd4c163323cf2\",\"title\":\"Partial Convolution based Padding\",\"url\":\"https://www.semanticscholar.org/paper/0cde8679a0171220d50ac76a629cd4c163323cf2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2007.06891\",\"authors\":[{\"authorId\":\"12266188\",\"name\":\"Ren Komatsu\"},{\"authorId\":\"2910106\",\"name\":\"H. Fujii\"},{\"authorId\":\"1835421\",\"name\":\"Y. Tamura\"},{\"authorId\":\"152521159\",\"name\":\"A. Yamashita\"},{\"authorId\":\"50631807\",\"name\":\"H. Asama\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8aaed7a13c52e34d97deedd32d45a8900535ca25\",\"title\":\"360\\u00b0 Depth Estimation from Multiple Fisheye Images with Origami Crown Representation of Icosahedron\",\"url\":\"https://www.semanticscholar.org/paper/8aaed7a13c52e34d97deedd32d45a8900535ca25\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51919650\",\"name\":\"Ricardo Eiris\"},{\"authorId\":\"47283344\",\"name\":\"Brendan John\"},{\"authorId\":\"2617152\",\"name\":\"E. Jain\"},{\"authorId\":\"98477711\",\"name\":\"Masoud Gheisari\"}],\"doi\":\"10.1109/VRW50115.2020.00236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afc1c9896b355800f9968acd235e3e704297d9fc\",\"title\":\"Effect of marker location on user detection in omnidirectional images\",\"url\":\"https://www.semanticscholar.org/paper/afc1c9896b355800f9968acd235e3e704297d9fc\",\"venue\":\"2020 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093452\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"title\":\"Visual Question Answering on 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/0e0c5d868d84908bb7a26c27c1aedea43fdc493d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2010.08055\",\"authors\":[{\"authorId\":\"27478395\",\"name\":\"K. Bhandari\"},{\"authorId\":\"1998945138\",\"name\":\"Mario A. DeLaGarza\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"3422205\",\"name\":\"Hugo Latapie\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"title\":\"Egok360: A 360 Egocentric Kinetic Human Activity Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151075211\",\"name\":\"K. Kang\"},{\"authorId\":\"143965167\",\"name\":\"Sunghyun Cho\"}],\"doi\":\"10.1145/3306346.3323046\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"4f5356599808d170c0a523acba1170dccdb45e97\",\"title\":\"Interactive and automatic navigation for 360\\u00b0 video playback\",\"url\":\"https://www.semanticscholar.org/paper/4f5356599808d170c0a523acba1170dccdb45e97\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90563574\",\"name\":\"Bhishma Dedhia\"},{\"authorId\":\"29806142\",\"name\":\"R. Chiang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"98e8e73717e5059b4dbba77efedf44d83e31dc3c\",\"title\":\"Saliency Prediction for Omnidirectional Images\",\"url\":\"https://www.semanticscholar.org/paper/98e8e73717e5059b4dbba77efedf44d83e31dc3c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"46286370\",\"name\":\"Yiwei Yang\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"title\":\"A Saliency Dataset of Head and Eye Movements for Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152808637\",\"name\":\"M. Wang\"},{\"authorId\":\"50024008\",\"name\":\"Y. Li\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"153056077\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/ISMAR50242.2020.00040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12e1b4045d24555e7ed6c3cb7841e81a8c689a89\",\"title\":\"Transitioning360: Content-aware NFoV Virtual Camera Paths for 360\\u00b0 Video Playback\",\"url\":\"https://www.semanticscholar.org/paper/12e1b4045d24555e7ed6c3cb7841e81a8c689a89\",\"venue\":\"2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1811.05304\",\"authors\":[{\"authorId\":\"3459139\",\"name\":\"Fu-En Wang\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"145155317\",\"name\":\"Shang-Ta Yang\"},{\"authorId\":\"9944380\",\"name\":\"Meng-Li Shih\"},{\"authorId\":\"1771281\",\"name\":\"Hung-Kuo Chu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"33e8f91cf656e85df15b9748c0a0560b2338d3d8\",\"title\":\"Self-Supervised Learning of Depth and Camera Motion from 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/33e8f91cf656e85df15b9748c0a0560b2338d3d8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2551562\",\"name\":\"Seunghoon Cha\"},{\"authorId\":\"1677580279\",\"name\":\"Jungjin Lee\"},{\"authorId\":\"1677632730\",\"name\":\"Seunghwa Jeong\"},{\"authorId\":\"1453398949\",\"name\":\"Y. Kim\"},{\"authorId\":\"104115248\",\"name\":\"Jun-yong Noh\"}],\"doi\":\"10.1145/3183794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"862dbaad97bed05af13d34139b7dac845bc3852c\",\"title\":\"Enhanced Interactive 360\\u00b0 Viewing via Automatic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/862dbaad97bed05af13d34139b7dac845bc3852c\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2011.11498\",\"authors\":[{\"authorId\":\"152873451\",\"name\":\"Cheng Sun\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"335637b2a3facaee05bda38c9c5af50e4a4ecfed\",\"title\":\"HoHoNet: 360 Indoor Holistic Understanding with Latent Horizontal Features\",\"url\":\"https://www.semanticscholar.org/paper/335637b2a3facaee05bda38c9c5af50e4a4ecfed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2541152\",\"name\":\"Ching-Ling Fan\"},{\"authorId\":\"17822951\",\"name\":\"Wen-Chih Lo\"},{\"authorId\":\"153057587\",\"name\":\"Yu-Tung Pai\"},{\"authorId\":\"1806563\",\"name\":\"C. Hsu\"}],\"doi\":\"10.1145/3329119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07abbd64b5fa2c530c5d06c42f88a133eb38a4e6\",\"title\":\"A Survey on 360\\u00b0 Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/07abbd64b5fa2c530c5d06c42f88a133eb38a4e6\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144709006\",\"name\":\"Yeonkun Lee\"},{\"authorId\":\"1891887\",\"name\":\"J. Jeong\"},{\"authorId\":\"80332178\",\"name\":\"Jongseob Yun\"},{\"authorId\":\"73200885\",\"name\":\"W. Cho\"},{\"authorId\":\"144295528\",\"name\":\"Kuk-jin Yoon\"}],\"doi\":\"10.1109/CVPR.2019.00940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4fafaf19fd45a0aa21db827d6714fbcbf64e398\",\"title\":\"SpherePHD: Applying CNNs on a Spherical PolyHeDron Representation of 360\\u00b0 Images\",\"url\":\"https://www.semanticscholar.org/paper/a4fafaf19fd45a0aa21db827d6714fbcbf64e398\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.03115\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00967\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3efaf9015e28e72cc511f94de5d33378a1364d64\",\"title\":\"Kernel Transformer Networks for Compact Spherical Convolution\",\"url\":\"https://www.semanticscholar.org/paper/3efaf9015e28e72cc511f94de5d33378a1364d64\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.04460\",\"authors\":[{\"authorId\":\"1405898278\",\"name\":\"Ning-Hsu Wang\"},{\"authorId\":\"1400422217\",\"name\":\"Bol\\u00edvar Solarte\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICRA40945.2020.9196975\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5f349b710bc9456dc9d8bd481c86488c115cd608\",\"title\":\"360SD-Net: 360\\u00b0 Stereo Depth Estimation with Learnable Cost Volume\",\"url\":\"https://www.semanticscholar.org/paper/5f349b710bc9456dc9d8bd481c86488c115cd608\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1904.00284\",\"authors\":[{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"48695200\",\"name\":\"Chia-Che Chang\"},{\"authorId\":\"47558260\",\"name\":\"Y. Chen\"},{\"authorId\":\"144854012\",\"name\":\"Da-Cheng Juan\"},{\"authorId\":\"145673180\",\"name\":\"W. Wei\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"}],\"doi\":\"10.1109/ICCV.2019.00461\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db05062e6119a4646ed1da035e2935e305987732\",\"title\":\"COCO-GAN: Generation by Parts via Conditional Coordinating\",\"url\":\"https://www.semanticscholar.org/paper/db05062e6119a4646ed1da035e2935e305987732\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878895877\",\"name\":\"Yucheng Zhu\"},{\"authorId\":\"13903793\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"}],\"doi\":\"10.1109/TMM.2019.2957986\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"title\":\"The Prediction of Saliency Map for Head and Eye Movements in 360 Degree Images\",\"url\":\"https://www.semanticscholar.org/paper/42f8fc610fed03fb9e91a05dbb132956fb719f60\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3363882\",\"name\":\"I. Agtzidis\"},{\"authorId\":\"145305263\",\"name\":\"M. Startsev\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":\"10.1145/3343031.3350947\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c6e701eb3dcc0c51fe608dc1784b46c3fd9b3ab\",\"title\":\"360-degree Video Gaze Behaviour: A Ground-Truth Data Set and a Classification Algorithm for Eye Movements\",\"url\":\"https://www.semanticscholar.org/paper/9c6e701eb3dcc0c51fe608dc1784b46c3fd9b3ab\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2001.03339\",\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"150336480\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8d27640ce75557156de13fb827b64446ef9cc0e4\",\"title\":\"Visual Question Answering on 360{\\\\deg} Images.\",\"url\":\"https://www.semanticscholar.org/paper/8d27640ce75557156de13fb827b64446ef9cc0e4\",\"venue\":\"\",\"year\":2020}],\"corpusId\":46937879,\"doi\":\"10.1109/CVPR.2018.00154\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":10,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"12525266\",\"name\":\"Xinyi Cui\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1145/1631272.1631370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3257d74e4ad050a1a518a53b0d23751f771f483\",\"title\":\"Temporal spectral residual: fast motion saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/b3257d74e4ad050a1a518a53b0d23751f771f483\",\"venue\":\"MM '09\",\"year\":2009},{\"arxivId\":\"1704.00675\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1413064976\",\"name\":\"S. Caelles\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"title\":\"The 2017 DAVIS Challenge on Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144664176\",\"name\":\"David Tsai\"},{\"authorId\":\"2990157\",\"name\":\"Matthew Flagg\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.5244/C.24.56\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56c10c97ae53e882783b25300fa272c098f0349a\",\"title\":\"Motion Coherent Tracking with Multi-label MRF optimization\",\"url\":\"https://www.semanticscholar.org/paper/56c10c97ae53e882783b25300fa272c098f0349a\",\"venue\":\"BMVC\",\"year\":2010},{\"arxivId\":\"1506.04214\",\"authors\":[{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"2192200\",\"name\":\"Zhourong Chen\"},{\"authorId\":\"49528584\",\"name\":\"Hao Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"145771919\",\"name\":\"W. Wong\"},{\"authorId\":\"2183294\",\"name\":\"Wang-chun Woo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"title\":\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1703.03937\",\"authors\":[{\"authorId\":\"1382657362\",\"name\":\"Xavier Alameda-Pineda\"},{\"authorId\":\"9970029\",\"name\":\"Andrea Pilzer\"},{\"authorId\":\"145851646\",\"name\":\"D. Xu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"40811261\",\"name\":\"E. Ricci\"}],\"doi\":\"10.1109/CVPR.2017.59\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3c7f65bd93983cea91b7bb2a07e4bc73ab563a4\",\"title\":\"Viraliency: Pooling Local Virality\",\"url\":\"https://www.semanticscholar.org/paper/f3c7f65bd93983cea91b7bb2a07e4bc73ab563a4\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.00495\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2017.150\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e8230369f11b7c1dee7071806874dc0f66290c22\",\"title\":\"Making 360\\u00b0 Video Watchable in 2D: Learning Videography for Click Free Viewing\",\"url\":\"https://www.semanticscholar.org/paper/e8230369f11b7c1dee7071806874dc0f66290c22\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3209359\",\"name\":\"P. Ochs\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/TPAMI.2013.242\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c78d5aee1e886fb5e975bc3503e02621dd1578be\",\"title\":\"Segmentation of Moving Objects by Long Term Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c78d5aee1e886fb5e975bc3503e02621dd1578be\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"144818403\",\"name\":\"Qi Ma\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2008.4587715\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"title\":\"Spatio-temporal Saliency detection using phase spectrum of quaternion fourier transform\",\"url\":\"https://www.semanticscholar.org/paper/16f4cfd4cbf504a151827b5a94df5deafd4930ac\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/CVPR.2016.80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1c4bb9974990f70d46c9d4bd5cca7e7940273e6\",\"title\":\"DHSNet: Deep Hierarchical Saliency Network for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/c1c4bb9974990f70d46c9d4bd5cca7e7940273e6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118589\",\"name\":\"R. Achanta\"},{\"authorId\":\"1720838\",\"name\":\"S. Hemami\"},{\"authorId\":\"145337110\",\"name\":\"F. J. Estrada\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1109/CVPR.2009.5206596\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63d523a58d2cd24efbc1ab35acccc64e0f93162b\",\"title\":\"Frequency-tuned salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/63d523a58d2cd24efbc1ab35acccc64e0f93162b\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/TPAMI.2015.2473844\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"title\":\"Exploiting Surroundedness for Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/48f6af7b895465440ea13e6e85ae38d7209d5a5c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"}],\"doi\":\"10.1109/CVPR.2013.152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d7924e07914a147d7f6b868050d4edd093b952d\",\"title\":\"Learning Video Saliency from Human Gaze Using Candidate Selection\",\"url\":\"https://www.semanticscholar.org/paper/3d7924e07914a147d7f6b868050d4edd093b952d\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1007/s12559-010-9074-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"title\":\"Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion\",\"url\":\"https://www.semanticscholar.org/paper/27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3369864\",\"name\":\"B. Tatler\"}],\"doi\":\"10.1167/7.14.4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"title\":\"The central fixation bias in scene viewing: selecting an optimal viewing position independently of motor biases and image feature distributions.\",\"url\":\"https://www.semanticscholar.org/paper/caed9b6de0142c9a4e07c96043e85e38ec22dd1e\",\"venue\":\"Journal of vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"49070447\",\"name\":\"Y. Chen\"},{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f54252274514e8eb54adb6b9af7594f6189ec63a\",\"title\":\"Self-view Grounding Given a Narrated 360\\u00b0 Video\",\"url\":\"https://www.semanticscholar.org/paper/f54252274514e8eb54adb6b9af7594f6189ec63a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1701.01081\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"147166602\",\"name\":\"J. Torres\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"title\":\"SalGAN: Visual Saliency Prediction with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/258fad95e709b6d0572ae6cc99efbbb14d32bdf2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"47842446\",\"name\":\"MingYu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360{\\\\deg} Sports Video\",\"url\":\"https://www.semanticscholar.org/paper/16ee824eee42bf59664ab452bbd7bc93b8df9324\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"8025545\",\"name\":\"Christopher Catton\"},{\"authorId\":\"8464855\",\"name\":\"S. Janjic\"}],\"doi\":\"10.1109/CVPR.2016.62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"title\":\"A Deeper Look at Saliency: Feature Contrast, Semantics, and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/3fedbcec10c2ba74efe3ad256850e3cdec770ff5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/TPAMI.2009.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62eb421cdac9de9255578f14fba55146d958be44\",\"title\":\"Spatiotemporal Saliency in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/62eb421cdac9de9255578f14fba55146d958be44\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40279670\",\"name\":\"Teahyung Lee\"},{\"authorId\":\"2853877\",\"name\":\"Myung Hwangbo\"},{\"authorId\":\"34874882\",\"name\":\"Tanfer Alan\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"},{\"authorId\":\"144025680\",\"name\":\"R. Iyer\"}],\"doi\":\"10.1109/ICIP.2015.7351505\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9166f46aa3e58befaefd3537e5a11b31ebeea4d0\",\"title\":\"Low-complexity HOG for efficient video saliency\",\"url\":\"https://www.semanticscholar.org/paper/9166f46aa3e58befaefd3537e5a11b31ebeea4d0\",\"venue\":\"2015 IEEE International Conference on Image Processing (ICIP)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2081209\",\"name\":\"Kuang-Jui Hsu\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.5244/C.31.67\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ae910ef0cb2f193a43d3a592b7b62ef8bd13058\",\"title\":\"Weakly Supervised Saliency Detection with A Category-Driven Map Generator\",\"url\":\"https://www.semanticscholar.org/paper/0ae910ef0cb2f193a43d3a592b7b62ef8bd13058\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461088\",\"name\":\"L. Wang\"},{\"authorId\":\"145131953\",\"name\":\"L. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"}],\"doi\":\"10.1007/978-3-319-46493-0_50\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a7a18e1f3dddcc351403237ea5255099441d5d5\",\"title\":\"Saliency Detection with Recurrent Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7a7a18e1f3dddcc351403237ea5255099441d5d5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2608733\",\"name\":\"Stas Goferman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"},{\"authorId\":\"49653522\",\"name\":\"A. Tal\"}],\"doi\":\"10.1109/TPAMI.2011.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"title\":\"Context-Aware Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbe18b90b9e3031bfb7044226882cfc763e0a1ee\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2015.2460013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065ec79836040f89df3c850a3b065de9222a8871\",\"title\":\"Consistent Video Saliency Using Local Gradient Flow Optimization and Global Refinement\",\"url\":\"https://www.semanticscholar.org/paper/065ec79836040f89df3c850a3b065de9222a8871\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145131953\",\"name\":\"L. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"50812274\",\"name\":\"Yifan Wang\"},{\"authorId\":\"40117581\",\"name\":\"Mengyang Feng\"},{\"authorId\":\"40562844\",\"name\":\"D. Wang\"},{\"authorId\":\"1714354\",\"name\":\"B. Yin\"},{\"authorId\":\"144526777\",\"name\":\"X. Ruan\"}],\"doi\":\"10.1109/CVPR.2017.404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf9aee2857c39cfcc8f468aa93c81f48e2453d89\",\"title\":\"Learning to Detect Salient Objects with Image-Level Supervision\",\"url\":\"https://www.semanticscholar.org/paper/bf9aee2857c39cfcc8f468aa93c81f48e2453d89\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1801.10312\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"35272603\",\"name\":\"Joonil Na\"},{\"authorId\":\"35365676\",\"name\":\"J. Kang\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f14cdd95870baa38582f5d0022356cb241ea86f\",\"title\":\"A Deep Ranking Model for Spatio-Temporal Highlight Detection from a 360 Video\",\"url\":\"https://www.semanticscholar.org/paper/9f14cdd95870baa38582f5d0022356cb241ea86f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2375749\",\"name\":\"T. Durand\"},{\"authorId\":\"20525031\",\"name\":\"Taylor Mordan\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR.2017.631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1e714a9ec329629798a88ebff8657c349fec739\",\"title\":\"WILDCAT: Weakly Supervised Learning of Deep ConvNets for Image Classification, Pointwise Localization and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c1e714a9ec329629798a88ebff8657c349fec739\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1312.7570\",\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/TPAMI.2014.2366154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"title\":\"Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"8700083\",\"name\":\"Y. Huang\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4cd9b278009854fba50a2a92cb3157d60212816a\",\"title\":\"Semantic-driven Generation of Hyperlapse from $360^\\\\circ$ Video\",\"url\":\"https://www.semanticscholar.org/paper/4cd9b278009854fba50a2a92cb3157d60212816a\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1609.01064\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2016.7900174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"title\":\"A deep multi-level network for saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/57e143c96a41ba81d9d59120a1cd0dc04905d3f1\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6838061\",\"name\":\"J. Wang\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2016.2522380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57cf6509377136530db3e72e4fd907665a6a4831\",\"title\":\"Learning a Combined Model of Visual Saliency for Fixation Prediction\",\"url\":\"https://www.semanticscholar.org/paper/57cf6509377136530db3e72e4fd907665a6a4831\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-54190-7_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9100bb05210dcb4539c1e5d92f4401d5a2ec9c10\",\"title\":\"Pano2Vid: Automatic Cinematography for Watching 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/9100bb05210dcb4539c1e5d92f4401d5a2ec9c10\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":\"1709.06505\",\"authors\":[{\"authorId\":\"145030054\",\"name\":\"R. Monroy\"},{\"authorId\":\"32882525\",\"name\":\"S. Lutz\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"1741139\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1016/j.image.2018.05.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"title\":\"SalNet360: Saliency Maps for omni-directional images with CNN\",\"url\":\"https://www.semanticscholar.org/paper/b7020a28d8c29b2b6ccbb0daee07f41dd72b63ee\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1703.10798\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"8700083\",\"name\":\"Y. Huang\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bacf9a26e10fc87fab22fbcb8a43d3741f1a83ef\",\"title\":\"Semantic-driven Generation of Hyperlapse from 360\\u00b0 Video\",\"url\":\"https://www.semanticscholar.org/paper/bacf9a26e10fc87fab22fbcb8a43d3741f1a83ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1702.02295\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"661ef3583a36ac08ec7e7202a89c71327a1daf31\",\"title\":\"Guided Optical Flow Learning\",\"url\":\"https://www.semanticscholar.org/paper/661ef3583a36ac08ec7e7202a89c71327a1daf31\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"1782328\",\"name\":\"Y. Pritch\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2012.6247743\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7abac1f397a76bc06d7508ab4108462786395c0f\",\"title\":\"Saliency filters: Contrast based filtering for salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/7abac1f397a76bc06d7508ab4108462786395c0f\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31628804\",\"name\":\"Hauke S Meyerhoff\"},{\"authorId\":\"48540769\",\"name\":\"Stephan Schwan\"},{\"authorId\":\"2812064\",\"name\":\"M. Huff\"}],\"doi\":\"10.3758/s13423-013-0496-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f204b448c4299fe1d376c95d4910a6efb6b2cf2\",\"title\":\"Interobject spacing explains the attentional bias toward interacting objects\",\"url\":\"https://www.semanticscholar.org/paper/7f204b448c4299fe1d376c95d4910a6efb6b2cf2\",\"venue\":\"Psychonomic bulletin & review\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2508830\",\"name\":\"Q. Wang\"},{\"authorId\":\"144189790\",\"name\":\"W. Zheng\"},{\"authorId\":\"3221010\",\"name\":\"Robinson Piramuthu\"}],\"doi\":\"10.1109/CVPR.2016.64\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"837a35d6d9603c6d8704c83d8acb5374db88b6fe\",\"title\":\"GraB: Visual Saliency via Novel Graph Model and Background Priors\",\"url\":\"https://www.semanticscholar.org/paper/837a35d6d9603c6d8704c83d8acb5374db88b6fe\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.04992\",\"authors\":[{\"authorId\":\"145513196\",\"name\":\"R. Garg\"},{\"authorId\":\"144828045\",\"name\":\"B. V. Kumar\"},{\"authorId\":\"145575177\",\"name\":\"G. Carneiro\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1007/978-3-319-46484-8_45\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d3beb32fa0efdd10280bad003ef37e5f62f6cbd\",\"title\":\"Unsupervised CNN for Single View Depth Estimation: Geometry to the Rescue\",\"url\":\"https://www.semanticscholar.org/paper/4d3beb32fa0efdd10280bad003ef37e5f62f6cbd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.01759\",\"authors\":[{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/CVPR.2017.153\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ba227bb94ea9414bad8846673c904a10d813e443\",\"title\":\"Deep 360 Pilot: Learning a Deep Agent for Piloting through 360\\u00b0 Sports Videos\",\"url\":\"https://www.semanticscholar.org/paper/ba227bb94ea9414bad8846673c904a10d813e443\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49415774\",\"name\":\"Yen-Chen Lin\"},{\"authorId\":\"1684289\",\"name\":\"Yung-Ju Chang\"},{\"authorId\":\"10712411\",\"name\":\"Hou-Ning Hu\"},{\"authorId\":\"10796879\",\"name\":\"Hsien-Tzu Cheng\"},{\"authorId\":\"2376155\",\"name\":\"C. Huang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1145/3025453.3025757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7032f83832c99e1d034974a901ded0e764bbee39\",\"title\":\"Tell Me Where to Look: Investigating Ways for Assisting Focus in 360\\u00b0 Video\",\"url\":\"https://www.semanticscholar.org/paper/7032f83832c99e1d034974a901ded0e764bbee39\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144654836\",\"name\":\"J. Pratt\"},{\"authorId\":\"49369813\",\"name\":\"P. Radulescu\"},{\"authorId\":\"4280379\",\"name\":\"R. Guo\"},{\"authorId\":\"6193852\",\"name\":\"R. Abrams\"}],\"doi\":\"10.1177/0956797610387440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64bf41b38e6a954b8edbce25ab4fe7dd25e4ea67\",\"title\":\"It\\u2019s Alive!\",\"url\":\"https://www.semanticscholar.org/paper/64bf41b38e6a954b8edbce25ab4fe7dd25e4ea67\",\"venue\":\"Psychological science\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118589\",\"name\":\"R. Achanta\"},{\"authorId\":\"1720838\",\"name\":\"S. Hemami\"},{\"authorId\":\"145337110\",\"name\":\"F. J. Estrada\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1109/CVPRW.2009.5206596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f52d46714a3fccbe9ea293763b03550ada7bd7d\",\"title\":\"Frequency-tuned salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/2f52d46714a3fccbe9ea293763b03550ada7bd7d\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.480\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9c373b1a7d3a987ceca9d33919725ec4bb290683\",\"title\":\"Learning Video Object Segmentation with Visual Memory\",\"url\":\"https://www.semanticscholar.org/paper/9c373b1a7d3a987ceca9d33919725ec4bb290683\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":\"1707.03123\",\"authors\":[{\"authorId\":\"22206915\",\"name\":\"Marc Assens\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/ICCVW.2017.275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10816358c78a6f7372620e4f59b54ba1c69c2022\",\"title\":\"SaltiNet: Scan-Path Prediction on 360 Degree Images Using Saliency Volumes\",\"url\":\"https://www.semanticscholar.org/paper/10816358c78a6f7372620e4f59b54ba1c69c2022\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5299112\",\"name\":\"Yung-Ta Lin\"},{\"authorId\":\"3119590\",\"name\":\"Yi-Chi Liao\"},{\"authorId\":\"9935485\",\"name\":\"Shan-Yuan Teng\"},{\"authorId\":\"3395939\",\"name\":\"Yi-Ju Chung\"},{\"authorId\":\"3212475\",\"name\":\"Liwei Chan\"},{\"authorId\":\"1733344\",\"name\":\"B. Chen\"}],\"doi\":\"10.1145/3126594.3126656\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11bd2afe934c3cbfa5a3023b69b0f83caf5d4cc2\",\"title\":\"Outside-In: Visualizing Out-of-Sight Regions-of-Interest in a 360\\u00b0 Video Using Spatial Picture-in-Picture Previews\",\"url\":\"https://www.semanticscholar.org/paper/11bd2afe934c3cbfa5a3023b69b0f83caf5d4cc2\",\"venue\":\"UIST\",\"year\":2017},{\"arxivId\":\"1708.00919\",\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f9ebd7c724c641d2eb5f5f8edb95a42436610e0\",\"title\":\"Learning Spherical Convolution for Fast Features from 360\\u00b0 Imagery\",\"url\":\"https://www.semanticscholar.org/paper/9f9ebd7c724c641d2eb5f5f8edb95a42436610e0\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1608.05186\",\"authors\":[{\"authorId\":\"3152399\",\"name\":\"Y. Tang\"},{\"authorId\":\"47150160\",\"name\":\"Xiangqian Wu\"}],\"doi\":\"10.1007/978-3-319-46484-8_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88895926ce9c45aa8d340a0ffcc465157e122080\",\"title\":\"Saliency Detection via Combining Region-Level and Pixel-Level Predictions with CNNs\",\"url\":\"https://www.semanticscholar.org/paper/88895926ce9c45aa8d340a0ffcc465157e122080\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39523296\",\"name\":\"Yu-Chuan Su\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.2312/wiced.20171071\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"985f76d3acec86219c6a9c11c145214972611e2c\",\"title\":\"Pano2Vid: Automatic Cinematography for Watching 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/985f76d3acec86219c6a9c11c145214972611e2c\",\"venue\":\"WICED@Eurographics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"8700083\",\"name\":\"Y. Huang\"},{\"authorId\":\"39678486\",\"name\":\"N. Joshi\"},{\"authorId\":\"31790403\",\"name\":\"C. Buehler\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"}],\"doi\":\"10.1109/TVCG.2017.2750671\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54201d4044b8c78b51f687321b826c3a2af099e9\",\"title\":\"Semantic-Driven Generation of Hyperlapse from 360 Degree Video\",\"url\":\"https://www.semanticscholar.org/paper/54201d4044b8c78b51f687321b826c3a2af099e9\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31628804\",\"name\":\"Hauke S Meyerhoff\"},{\"authorId\":\"1682320\",\"name\":\"S. Schwan\"},{\"authorId\":\"2812064\",\"name\":\"M. Huff\"}],\"doi\":\"10.1037/a0034846\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"405dc72359357d5ef82926057c40cd69f856d0f7\",\"title\":\"Perceptual animacy: visual search for chasing objects among distractors.\",\"url\":\"https://www.semanticscholar.org/paper/405dc72359357d5ef82926057c40cd69f856d0f7\",\"venue\":\"Journal of experimental psychology. Human perception and performance\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":null,\"name\":\"Jian Sun\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1109/TPAMI.2010.70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4f03f0c435f8a2891b048d19d7a0b8e3e5263b4\",\"title\":\"Learning to Detect a Salient Object\",\"url\":\"https://www.semanticscholar.org/paper/f4f03f0c435f8a2891b048d19d7a0b8e3e5263b4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2093491\",\"name\":\"M. Oquab\"},{\"authorId\":\"119267979\",\"name\":\"L. Bottou\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2015.7298668\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec679c45e88fa25fec32c30bc7c1b7d7fd0facec\",\"title\":\"Is object localization for free? - Weakly-supervised learning with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/ec679c45e88fa25fec32c30bc7c1b7d7fd0facec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"Cube Padding for Weakly-Supervised Saliency Prediction in 360\\u00b0 Videos\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Distortion\",\"topicId\":\"15080\",\"url\":\"https://www.semanticscholar.org/topic/15080\"},{\"topic\":\"Cube\",\"topicId\":\"53858\",\"url\":\"https://www.semanticscholar.org/topic/53858\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Heat map\",\"topicId\":\"208268\",\"url\":\"https://www.semanticscholar.org/topic/208268\"},{\"topic\":\"Concatenation\",\"topicId\":\"2262\",\"url\":\"https://www.semanticscholar.org/topic/2262\"},{\"topic\":\"Padding oracle attack\",\"topicId\":\"1363352\",\"url\":\"https://www.semanticscholar.org/topic/1363352\"},{\"topic\":\"3D projection\",\"topicId\":\"379765\",\"url\":\"https://www.semanticscholar.org/topic/379765\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"}],\"url\":\"https://www.semanticscholar.org/paper/d502f17bf778b153cb7aec6eaba97a7129d96a02\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"