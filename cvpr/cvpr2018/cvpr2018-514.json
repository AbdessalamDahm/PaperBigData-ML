"{\"abstract\":\"In this work, we contribute to video saliency research in two ways. First, we introduce a new benchmark for predicting human eye movements during dynamic scene free-viewing, which is long-time urged in this field. Our dataset, named DHF1K (Dynamic Human Fixation), consists of 1K high-quality, elaborately selected video sequences spanning a large range of scenes, motions, object types and background complexity. Existing video saliency datasets lack variety and generality of common dynamic scenes and fall short in covering challenging situations in unconstrained environments. In contrast, DHF1K makes a significant leap in terms of scalability, diversity and difficulty, and is expected to boost video saliency modeling. Second, we propose a novel video saliency model that augments the CNN-LSTM network architecture with an attention mechanism to enable fast, end-to-end saliency learning. The attention mechanism explicitly encodes static saliency information, thus allowing LSTM to focus on learning more flexible temporal saliency representation across successive frames. Such a design fully leverages existing large-scale static fixation datasets, avoids overfitting, and significantly improves training efficiency and testing performance. We thoroughly examine the performance of our model, with respect to state-of-the-art saliency models, on three large-scale datasets (i.e., DHF1K, Hollywood2, UCF sports). Experimental results over more than 1.2K testing videos containing 400K frames demonstrate that our model outperforms other competitors.\",\"arxivId\":\"1801.07424\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\",\"url\":\"https://www.semanticscholar.org/author/2693875\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\",\"url\":\"https://www.semanticscholar.org/author/145953515\"},{\"authorId\":\"143929120\",\"name\":\"F. Guo\",\"url\":\"https://www.semanticscholar.org/author/143929120\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\",\"url\":\"https://www.semanticscholar.org/author/37535930\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\",\"url\":\"https://www.semanticscholar.org/author/3177797\"}],\"citationVelocity\":36,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"40186773\",\"name\":\"P. Lebreton\"},{\"authorId\":\"19421779\",\"name\":\"Stephan Fremerey\"},{\"authorId\":\"2403648\",\"name\":\"Alexander Raake\"}],\"doi\":\"10.1109/ICMEW.2018.8551523\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce5ede48af4b0d2820b2c2968431e65b6aabb4c5\",\"title\":\"V-BMS360: A Video Extention to the BMS360 Image Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/ce5ede48af4b0d2820b2c2968431e65b6aabb4c5\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"2004.02877\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6709fbca948e6b2bbdff4d52433de7992e44f5bf\",\"title\":\"Empirical Upper Bound, Error Diagnosis and Invariance Analysis of Modern Object Detectors\",\"url\":\"https://www.semanticscholar.org/paper/6709fbca948e6b2bbdff4d52433de7992e44f5bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67016734\",\"name\":\"S. Zhu\"},{\"authorId\":\"39772032\",\"name\":\"C. Liu\"},{\"authorId\":\"1765822\",\"name\":\"Ziyao Xu\"}],\"doi\":\"10.1109/TCSVT.2019.2911396\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"47abf02a79bb70cc9fd4ac14b6c9dc7b5063978b\",\"title\":\"High-Definition Video Compression System Based on Perception Guidance of Salient Information of a Convolutional Neural Network and HEVC Compression Domain\",\"url\":\"https://www.semanticscholar.org/paper/47abf02a79bb70cc9fd4ac14b6c9dc7b5063978b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890030\",\"name\":\"Youqiang Zhang\"},{\"authorId\":\"143743503\",\"name\":\"Feng Dai\"},{\"authorId\":\"3193532\",\"name\":\"Yike Ma\"},{\"authorId\":\"49404814\",\"name\":\"Hongliang Li\"},{\"authorId\":\"49033408\",\"name\":\"Q. Zhao\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/JSTSP.2019.2955824\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"title\":\"Saliency Prediction Network for $360^\\\\circ$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/059dcad31aca80e2393fb2ccdea0dffc4499e1be\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fd369da5f97e9d3ca6863030ec10a689754bcbb6\",\"title\":\"LINARDOS ET AL: TEMPORAL RECURRENCES FOR VIDEO SALIENCY PREDICTION 1 Temporal Recurrences for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd369da5f97e9d3ca6863030ec10a689754bcbb6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TPAMI.2019.2924417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"title\":\"Revisiting Video Saliency Prediction in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/60782ad3f40d13fae19fbe26b6f7c0ac5011f83d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72350529\",\"name\":\"Abdelhafid Dakhia\"},{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aa7c21dd045f248cac67e6298f32804b5e79548\",\"title\":\"A hybrid-backward refinement model for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/4aa7c21dd045f248cac67e6298f32804b5e79548\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36195510\",\"name\":\"S. Hegde\"},{\"authorId\":\"15328368\",\"name\":\"Jitender Maurya\"},{\"authorId\":\"3177394\",\"name\":\"R. Hebbalaguppe\"},{\"authorId\":\"1699607987\",\"name\":\"Aniruddha Kalkar\"}],\"doi\":\"10.1109/WACV45572.2020.9093587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"520f2aaa00ed05239f497e617472490a96900e92\",\"title\":\"SmartOverlays: A Visual Saliency Driven Label Placement for Intelligent Human-Computer Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/520f2aaa00ed05239f497e617472490a96900e92\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"46286370\",\"name\":\"Yiwei Yang\"},{\"authorId\":\"19269060\",\"name\":\"Huiyu Duan\"},{\"authorId\":\"2222210\",\"name\":\"Qiangqiang Zhou\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"title\":\"A Saliency Dataset of Head and Eye Movements for Augmented Reality\",\"url\":\"https://www.semanticscholar.org/paper/6eed131900c8ed2412acf7eecc70f472eb3b9b2b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.10274\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"23576567\",\"name\":\"P. Yuan\"},{\"authorId\":\"50987252\",\"name\":\"Daxin Gu\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/MMUL.2018.2883136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1101eeb5ec9ba5aefb019787d8e6ee6f3652610c\",\"title\":\"Hierarchical Deep Cosegmentation of Primary Objects in Aerial Videos\",\"url\":\"https://www.semanticscholar.org/paper/1101eeb5ec9ba5aefb019787d8e6ee6f3652610c\",\"venue\":\"IEEE MultiMedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1145/3379156.3391337\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"117877a5d29a6e3d0ad6f7520e6ff8b114d5670b\",\"title\":\"Deep Audio-Visual Saliency: Baseline Model and Data\",\"url\":\"https://www.semanticscholar.org/paper/117877a5d29a6e3d0ad6f7520e6ff8b114d5670b\",\"venue\":\"ETRA Short Papers\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2018.2883305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"title\":\"Video Saliency Prediction Based on Spatial-Temporal Two-Stream Network\",\"url\":\"https://www.semanticscholar.org/paper/6c54dfdace2a84d4b70fc31e87a3053be09cd863\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150188542\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"15661018\",\"name\":\"Shanyi Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1016/j.patcog.2020.107234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"947b42503e78f29fd64ab864a76721dae8cad26e\",\"title\":\"DeepCT: A novel deep complex-valued network with learnable transform for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/947b42503e78f29fd64ab864a76721dae8cad26e\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48162270\",\"name\":\"Chongyi Li\"},{\"authorId\":\"49053414\",\"name\":\"S. Anwar\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1016/j.patcog.2019.107038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de1a592912915a10fcd8637886203b688c03650\",\"title\":\"Underwater scene prior inspired deep underwater image and video enhancement\",\"url\":\"https://www.semanticscholar.org/paper/0de1a592912915a10fcd8637886203b688c03650\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1907.00480\",\"authors\":[{\"authorId\":\"30927077\",\"name\":\"Vitaliy Lyudvichenko\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"}],\"doi\":\"10.30987/graphicon-2019-2-127-130\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33e150f9891e06d057d23daa579f1c68a95956f3\",\"title\":\"Predicting video saliency using crowdsourced mouse-tracking data\",\"url\":\"https://www.semanticscholar.org/paper/33e150f9891e06d057d23daa579f1c68a95956f3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81631713\",\"name\":\"Ruize Han\"},{\"authorId\":\"1993386784\",\"name\":\"Jiewen Zhao\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"1993657362\",\"name\":\"Yiyang Gan\"},{\"authorId\":\"39124212\",\"name\":\"L. Wan\"},{\"authorId\":\"40912079\",\"name\":\"S. Wang\"}],\"doi\":\"10.1145/3394171.3413659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38041b7394b9808d28700990e2a706858b11c7db\",\"title\":\"Complementary-View Co-Interest Person Detection\",\"url\":\"https://www.semanticscholar.org/paper/38041b7394b9808d28700990e2a706858b11c7db\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23999143\",\"name\":\"Deng-Ping Fan\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/CVPR.2019.00875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21648dd098a3c0ae871844b254775fec14df6904\",\"title\":\"Shifting More Attention to Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/21648dd098a3c0ae871844b254775fec14df6904\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"37006600\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5bea0fddd9acb316179b895bb1d5f0e72a5c402\",\"title\":\"An Iterative and Cooperative Top-Down and Bottom-Up Inference Network for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/e5bea0fddd9acb316179b895bb1d5f0e72a5c402\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.01869\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"144011211\",\"name\":\"J. J. Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"title\":\"Simple vs complex temporal recurrences for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2212080\",\"name\":\"Yifan Cai\"},{\"authorId\":\"50579084\",\"name\":\"Harshita Sharma\"},{\"authorId\":\"49240796\",\"name\":\"P. Chatelain\"},{\"authorId\":\"101461032\",\"name\":\"A. T. Papageorghiou\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-39343-4_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0a9ed0f0e75ac22b4eaa99ccdee30fcf32c0c63\",\"title\":\"Towards Capturing Sonographic Experience: Cognition-Inspired Ultrasound Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a0a9ed0f0e75ac22b4eaa99ccdee30fcf32c0c63\",\"venue\":\"MIUA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"},{\"authorId\":\"47785924\",\"name\":\"Jianwu Li\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"},{\"authorId\":\"47599902\",\"name\":\"R. Tao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2020.3013162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"title\":\"MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"2863871\",\"name\":\"Xinyu Yan\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1145/3343031.3350882\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"775373c4992f616d4dc55a1eb4e2602aed48f6de\",\"title\":\"Ranking Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/775373c4992f616d4dc55a1eb4e2602aed48f6de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1858438\",\"name\":\"Zhengyi Liu\"},{\"authorId\":\"2647654\",\"name\":\"Quanlong Li\"},{\"authorId\":\"36251013\",\"name\":\"Wei Li\"}],\"doi\":\"10.1016/j.neucom.2019.09.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93868be49bfa2ccb12bbf30bfcb6e0b877c85e90\",\"title\":\"Deep layer guided network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/93868be49bfa2ccb12bbf30bfcb6e0b877c85e90\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1905.07984\",\"authors\":[{\"authorId\":\"144656873\",\"name\":\"O. Sidorov\"},{\"authorId\":\"3276066\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"35223379\",\"name\":\"Sumit Shekhar\"}],\"doi\":\"10.1145/3334480.3382980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995268b5ed1b688bc801337034e492cc49cff927\",\"title\":\"Are All the Frames Equally Important?\",\"url\":\"https://www.semanticscholar.org/paper/995268b5ed1b688bc801337034e492cc49cff927\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xinyi Wu\"},{\"authorId\":\"153006222\",\"name\":\"Zhenyao Wu\"},{\"authorId\":\"24392163\",\"name\":\"J. Zhang\"},{\"authorId\":\"47668707\",\"name\":\"Li-li Ju\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6927\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"title\":\"SalSAC: A Video Saliency Prediction Model with Shuffled Attentions and Correlation-Based ConvLSTM\",\"url\":\"https://www.semanticscholar.org/paper/3d51ce14a3be17ffc37bb94f9664429d0dad4564\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2009.06886\",\"authors\":[{\"authorId\":\"1492115154\",\"name\":\"Jinquan Li\"},{\"authorId\":\"1486405312\",\"name\":\"Ling Pei\"},{\"authorId\":\"71078457\",\"name\":\"Danping Zou\"},{\"authorId\":\"1944162339\",\"name\":\"Songpengcheng Xia\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"153051030\",\"name\":\"T. Li\"},{\"authorId\":\"145522783\",\"name\":\"Z. Sun\"},{\"authorId\":\"1969144\",\"name\":\"W. Yu\"}],\"doi\":\"10.1109/jsen.2020.3038432\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c902ed986820670e7a929ab5d20b732a8b4ef47\",\"title\":\"Attention-SLAM: A Visual Monocular SLAM Learning from Human Gaze\",\"url\":\"https://www.semanticscholar.org/paper/3c902ed986820670e7a929ab5d20b732a8b4ef47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.00292\",\"authors\":[{\"authorId\":\"29874425\",\"name\":\"Jyun-Ruei Chen\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"35954057\",\"name\":\"Bo Liu\"},{\"authorId\":\"143960771\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1016/j.patcog.2020.107615\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"title\":\"Video Saliency Prediction Using Enhanced Spatiotemporal Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/866cedefb15e4a4a3f1b1cf3b9bd844654eb6af1\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"title\":\"How Drones Look: Crowdsourced Knowledge Transfer for Aerial Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/737ca6dd41d8bc4f3ce06161bc2e3050a37b050a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007931\",\"name\":\"Kao Zhang\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"1792817\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/TIP.2020.3036749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"title\":\"A Spatial-Temporal Recurrent Neural Network for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/51b23ce1f48d769a31a4a4f4982fbfe5d4de41f4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1909.13258\",\"authors\":[{\"authorId\":\"145616459\",\"name\":\"M. Faisal\"},{\"authorId\":\"3130750\",\"name\":\"Ijaz Akhter\"},{\"authorId\":\"144908682\",\"name\":\"Mohsen Ali\"},{\"authorId\":\"49827339\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/WACV45572.2020.9093589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfa6e46377b0e8de1356732fb314f99eebe0b6ff\",\"title\":\"EpO-Net: Exploiting Geometric Constraints on Dense Trajectories for Motion Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cfa6e46377b0e8de1356732fb314f99eebe0b6ff\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2010.01220\",\"authors\":[{\"authorId\":\"1986291097\",\"name\":\"Giovanni Bellitto\"},{\"authorId\":\"1985894550\",\"name\":\"Federica Proietto Salanitri\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"50528328\",\"name\":\"F. Rundo\"},{\"authorId\":\"35906202\",\"name\":\"D. Giordano\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36081963c58871adc8706e2cfcbf94872a42c5ae\",\"title\":\"Video Saliency Detection with Domain Adaptation using Hierarchical Gradient Reversal Layers\",\"url\":\"https://www.semanticscholar.org/paper/36081963c58871adc8706e2cfcbf94872a42c5ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"72541446\",\"name\":\"Xu Wang\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"47320103\",\"name\":\"Shi-kai Li\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/CVPR.2019.00998\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"title\":\"Learning to Explore Intrinsic Saliency for Stereoscopic Video\",\"url\":\"https://www.semanticscholar.org/paper/273ebb14fc10d578a88a2c6cfea997e1c1b91009\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051436\",\"name\":\"Jianxin Zhang\"},{\"authorId\":\"1625349460\",\"name\":\"Zongkang Jiang\"},{\"authorId\":\"143863957\",\"name\":\"J. Dong\"},{\"authorId\":\"151472454\",\"name\":\"Y. Hou\"},{\"authorId\":\"50678180\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2983075\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbbbdc9655a244e90db48f7f9ee6032f6e2c05cb\",\"title\":\"Attention Gate ResU-Net for Automatic MRI Brain Tumor Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/bbbbdc9655a244e90db48f7f9ee6032f6e2c05cb\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2509726\",\"name\":\"Xingping Dong\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"38958903\",\"name\":\"Ruigang Yang\"}],\"doi\":\"10.1109/TPAMI.2019.2905607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"title\":\"Inferring Salient Objects from Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/39e79c92a0a7653ee4177c6b94eee4368f6ca4b0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.10603\",\"authors\":[{\"authorId\":\"3427162\",\"name\":\"Z. Chang\"},{\"authorId\":\"5159509\",\"name\":\"J. Matias Di Martino\"},{\"authorId\":\"83277545\",\"name\":\"Qiang Qiu\"},{\"authorId\":\"8698514\",\"name\":\"Steven Espinosa\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"}],\"doi\":\"10.1109/ICCVW.2019.00148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"401e127a7a7def6f6154e9ab200dc36d6fdcb837\",\"title\":\"SalGaze: Personalizing Gaze Estimation using Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/401e127a7a7def6f6154e9ab200dc36d6fdcb837\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"9284635\",\"name\":\"Hongmei Song\"},{\"authorId\":\"152836879\",\"name\":\"Shuyang Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/CVPR.2019.00318\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f53761ea6276df40089753a4e008d1283f28e768\",\"title\":\"Learning Unsupervised Video Object Segmentation Through Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f53761ea6276df40089753a4e008d1283f28e768\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"144812765\",\"name\":\"S. Khan\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ba651908d6cb9dd10635ee4d44069d9cb7399eb7\",\"title\":\"Human vs Machine Attention in Neural Networks: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/ba651908d6cb9dd10635ee4d44069d9cb7399eb7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102300440\",\"name\":\"Jakob Wiesinger\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"title\":\"Video Saliency Detection Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"2243473\",\"name\":\"Athanasios Katsamanis\"},{\"authorId\":\"46788705\",\"name\":\"A. Vatakis\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1016/J.IMAGE.2019.05.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"title\":\"A behaviorally inspired fusion approach for computational audiovisual saliency modeling\",\"url\":\"https://www.semanticscholar.org/paper/5cfa95cd409a47fbacce89c6a1df6d0410b810e5\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1912.05971\",\"authors\":[{\"authorId\":\"3404054\",\"name\":\"Y. Zhu\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"152867067\",\"name\":\"Dandan Zhu\"},{\"authorId\":\"1474358241\",\"name\":\"Ke Gu\"},{\"authorId\":\"66102996\",\"name\":\"Jian-Tao Zhou\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"title\":\"Toward Better Understanding of Saliency Prediction in Augmented 360 Degree Videos\",\"url\":\"https://www.semanticscholar.org/paper/0bd5d09cbe11ff6afa763529dd7bebde89dbe1f4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.04992\",\"authors\":[{\"authorId\":null,\"name\":\"Jia Li\"},{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"152836873\",\"name\":\"Shengwei Zhao\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1109/TIP.2019.2946102\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3f76324a4a26ff3d9097642676878aa7b1122581\",\"title\":\"Spatiotemporal Knowledge Distillation for Efficient Estimation of Aerial Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/3f76324a4a26ff3d9097642676878aa7b1122581\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1910.02618\",\"authors\":[{\"authorId\":\"1387992157\",\"name\":\"Memoona Tahira\"},{\"authorId\":\"1387992189\",\"name\":\"Sobas Mehboob\"},{\"authorId\":\"31321802\",\"name\":\"A. U. Rahman\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/ACCESS.2019.2956840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b141eabff673e534644f68929d4efcad2c34c74\",\"title\":\"CrowdFix: An Eyetracking Dataset of Real Life Crowd Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b141eabff673e534644f68929d4efcad2c34c74\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48462171\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"2005172320\",\"name\":\"Zhe Lin\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"},{\"authorId\":\"2986047\",\"name\":\"You He\"}],\"doi\":\"10.1007/978-3-030-58568-6_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0e7468e30d0be1bfacca5eb65499f95979c9253\",\"title\":\"Unsupervised Video Object Segmentation with Joint Hotspot Tracking\",\"url\":\"https://www.semanticscholar.org/paper/d0e7468e30d0be1bfacca5eb65499f95979c9253\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1858438\",\"name\":\"Zhengyi Liu\"},{\"authorId\":\"144578035\",\"name\":\"Q. Xiang\"},{\"authorId\":\"114622627\",\"name\":\"J. Tang\"},{\"authorId\":null,\"name\":\"Yuan Wang\"},{\"authorId\":\"145344370\",\"name\":\"Peng Zhao\"}],\"doi\":\"10.1007/s00371-019-01778-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"562582fce1439f568a2b13c67a100e287d884791\",\"title\":\"Robust salient object detection for RGB images\",\"url\":\"https://www.semanticscholar.org/paper/562582fce1439f568a2b13c67a100e287d884791\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1964987\",\"name\":\"W. Li\"},{\"authorId\":\"87181457\",\"name\":\"Siqin Feng\"},{\"authorId\":\"88345001\",\"name\":\"Hua-Ping Guan\"},{\"authorId\":\"87851074\",\"name\":\"Ziwei Zhan\"},{\"authorId\":\"143724076\",\"name\":\"Cheng Gong\"}],\"doi\":\"10.1117/1.JEI.28.1.013009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87c11e78141404316481e3495674c99c78fbca82\",\"title\":\"Video saliency detection based on low-level saliency fusion and saliency-aware geodesic\",\"url\":\"https://www.semanticscholar.org/paper/87c11e78141404316481e3495674c99c78fbca82\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1811.07480\",\"authors\":[{\"authorId\":\"50251712\",\"name\":\"Ziqi Zhou\"},{\"authorId\":\"40514580\",\"name\":\"Z. Wang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"47673404\",\"name\":\"S. Wang\"},{\"authorId\":\"2736861\",\"name\":\"M. Sun\"}],\"doi\":\"10.1016/j.patcog.2020.107275\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b7de478275fdc5e154f6d904b910e8d291033edd\",\"title\":\"Global and Local Sensitivity Guided Key Salient Object Re-augmentation for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7de478275fdc5e154f6d904b910e8d291033edd\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1805398\",\"name\":\"Haibin Ling\"}],\"doi\":\"10.1109/TPAMI.2018.2840724\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"title\":\"A Deep Network Solution for Attention and Aesthetics Aware Photo Cropping\",\"url\":\"https://www.semanticscholar.org/paper/55ba76bdca99a1ab07af91e0ebde0bf595d71652\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3387551\",\"name\":\"M. Startsev\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"}],\"doi\":\"10.1109/ACCESS.2019.2961835\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c45cfde00d5cf07fff6f004931a4856cb531cd3\",\"title\":\"Supersaliency: A Novel Pipeline for Predicting Smooth Pursuit-Based Attention Improves Generalisability of Video Saliency\",\"url\":\"https://www.semanticscholar.org/paper/2c45cfde00d5cf07fff6f004931a4856cb531cd3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2409654\",\"name\":\"Yun Xiao\"},{\"authorId\":\"144586298\",\"name\":\"B. Jiang\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"},{\"authorId\":\"144684074\",\"name\":\"A. Zhou\"},{\"authorId\":\"144664815\",\"name\":\"A. Hussain\"},{\"authorId\":\"144047975\",\"name\":\"J. Tang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a3fd8a42e30f356c9207c55f85c2d65abe25d0f\",\"title\":\"Saliency detection via multi-view graph based saliency optimization\",\"url\":\"https://www.semanticscholar.org/paper/7a3fd8a42e30f356c9207c55f85c2d65abe25d0f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294797\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1007/978-3-030-01234-2_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"title\":\"Saliency Detection in 360 ^\\\\circ \\u2218 Videos\",\"url\":\"https://www.semanticscholar.org/paper/6887fa749b8719f84aff3ed23b8cef0225583d1b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.05625\",\"authors\":[{\"authorId\":\"1967201\",\"name\":\"Kui Fu\"},{\"authorId\":\"9073063\",\"name\":\"Jiugang Li\"},{\"authorId\":\"2803144\",\"name\":\"Y. Zhang\"},{\"authorId\":\"121194391\",\"name\":\"Hongze Shen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/TIP.2020.2998977\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"title\":\"Model-Guided Multi-Path Knowledge Aggregation for Aerial Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fd2b919b6abb91657aa9104dfc2e7c18c114cbae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"3190022\",\"name\":\"Danping Liao\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICCVW.2019.00543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"title\":\"Learning Spatiotemporal Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47294217\",\"name\":\"Ziheng Zhang\"},{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"219bac0d46072291b129748809973618646935e6\",\"title\":\"Saliency Detection in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/219bac0d46072291b129748809973618646935e6\",\"venue\":\"ECCV 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50264088\",\"name\":\"M. Pan\"},{\"authorId\":\"2163097\",\"name\":\"Huihui Song\"},{\"authorId\":\"49298200\",\"name\":\"Junxia Li\"},{\"authorId\":\"11735382\",\"name\":\"K. Zhang\"},{\"authorId\":\"50383828\",\"name\":\"Qingshan Liu\"}],\"doi\":\"10.1007/978-3-030-60636-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec2e2c67de0e6cab54d369148ac16353af249234\",\"title\":\"Top-Down Fusing Multi-level Contextual Features for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/ec2e2c67de0e6cab54d369148ac16353af249234\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2148486\",\"name\":\"M. Buzzelli\"}],\"doi\":\"10.3390/app10155143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01eb72c05c0145774dd1112f3627d46a2e38bfae\",\"title\":\"Recent Advances in Saliency Estimation for Omnidirectional Images, Image Groups, and Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/01eb72c05c0145774dd1112f3627d46a2e38bfae\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.04051\",\"authors\":[{\"authorId\":\"7286894\",\"name\":\"P. Yan\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"144825236\",\"name\":\"Yuan Xie\"},{\"authorId\":\"49969893\",\"name\":\"Z. Li\"},{\"authorId\":\"121900506\",\"name\":\"C. Wang\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"97650833\",\"name\":\"Liang Lin\"}],\"doi\":\"10.1109/ICCV.2019.00738\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4b21b0fd659576a047a60a01de61ca1ad3cac1d\",\"title\":\"Semi-Supervised Video Salient Object Detection Using Pseudo-Labels\",\"url\":\"https://www.semanticscholar.org/paper/f4b21b0fd659576a047a60a01de61ca1ad3cac1d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.06170\",\"authors\":[{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"title\":\"AViNet: Diving Deep into Audio-Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144495450\",\"name\":\"Ye Liang\"},{\"authorId\":\"1689275\",\"name\":\"Hongzhe Liu\"},{\"authorId\":\"1453020678\",\"name\":\"Nan Ma\"}],\"doi\":\"10.1007/s00371-019-01781-9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b32259229cbd5f4758326264ef1a380bd4b8fea4\",\"title\":\"A novel deep network and aggregation model for saliency detection\",\"url\":\"https://www.semanticscholar.org/paper/b32259229cbd5f4758326264ef1a380bd4b8fea4\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91885328\",\"name\":\"B. Wang\"},{\"authorId\":\"50358059\",\"name\":\"Shuhan Chen\"},{\"authorId\":\"48093293\",\"name\":\"Jian Wang\"},{\"authorId\":\"1453025376\",\"name\":\"Xuelong Hu\"}],\"doi\":\"10.1007/s00371-019-01779-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8cda97d24d8ed34c321382d0a76cfb670485dd\",\"title\":\"Residual feature pyramid networks for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/dc8cda97d24d8ed34c321382d0a76cfb670485dd\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747564\",\"name\":\"Zheng Yang\"},{\"authorId\":\"93244159\",\"name\":\"B. Han\"},{\"authorId\":\"49688763\",\"name\":\"Guowei Wei\"},{\"authorId\":\"49358323\",\"name\":\"W. Qiu\"}],\"doi\":\"10.1007/978-981-32-9298-7_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ced5042c19baba634bf7e40b197f05a4ec6ee890\",\"title\":\"Video Saliency Detection Based on Eye-Movement Guided Region Matching and LDP Embedded Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/ced5042c19baba634bf7e40b197f05a4ec6ee890\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"184ffa4a4c36051de56e07d785e5b53928d8c472\",\"title\":\"DeepVS: A Deep Learning Based Video Saliency Prediction Approach\",\"url\":\"https://www.semanticscholar.org/paper/184ffa4a4c36051de56e07d785e5b53928d8c472\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2003.05477\",\"authors\":[{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-58558-7_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"title\":\"Unified Image and Video Saliency Modeling\",\"url\":\"https://www.semanticscholar.org/paper/b01cb5c42ba693c84967bfd2ec94e420586164cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3359577\",\"name\":\"Zhujun Xiao\"},{\"authorId\":\"3104076\",\"name\":\"Yanzi Zhu\"},{\"authorId\":\"1790059\",\"name\":\"Y. Chen\"},{\"authorId\":\"145970007\",\"name\":\"B. Zhao\"},{\"authorId\":\"1727978\",\"name\":\"J. Jiang\"},{\"authorId\":\"2704852\",\"name\":\"H. Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c924137ca87e8b4e1557465405744f8b639b16fc\",\"title\":\"Seeding Deep Learning using Wireless Localization\",\"url\":\"https://www.semanticscholar.org/paper/c924137ca87e8b4e1557465405744f8b639b16fc\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2212080\",\"name\":\"Yifan Cai\"},{\"authorId\":\"1430747783\",\"name\":\"Richard Droste\"},{\"authorId\":\"1796341399\",\"name\":\"Harshita Sharma\"},{\"authorId\":\"1430746442\",\"name\":\"P. Chatelain\"},{\"authorId\":\"46763663\",\"name\":\"L. Drukker\"},{\"authorId\":\"101461032\",\"name\":\"A. T. Papageorghiou\"},{\"authorId\":\"152169633\",\"name\":\"J. A. Noble\"}],\"doi\":\"10.1016/j.media.2020.101762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d96f24408ea2e671e358372a9935c6c90fd337ea\",\"title\":\"Spatio-temporal visual attention modelling of standard biometry plane-finding navigation\",\"url\":\"https://www.semanticscholar.org/paper/d96f24408ea2e671e358372a9935c6c90fd337ea\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121216817\",\"name\":\"Ming-hao Ning\"},{\"authorId\":\"50815695\",\"name\":\"C. Lu\"},{\"authorId\":\"1804482\",\"name\":\"Jianwei Gong\"}],\"doi\":\"10.1109/ITSC.2019.8917337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8207fd1d0c27b3a979ef7aeb0466fa9c11623662\",\"title\":\"An Efficient Model for Driving Focus of Attention Prediction using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/8207fd1d0c27b3a979ef7aeb0466fa9c11623662\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412870585\",\"name\":\"Pol Caselles Rico\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e6badd633f974013393353fb856534af30cece3e\",\"title\":\"Integrating low-level motion cues in deep video saliency\",\"url\":\"https://www.semanticscholar.org/paper/e6badd633f974013393353fb856534af30cece3e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51444483\",\"name\":\"Jila Hosseinkhani\"},{\"authorId\":\"145388725\",\"name\":\"C. Joslin\"}],\"doi\":\"10.4018/IJMDEM.2019040101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fc3323ea6593155e017ee709913c930769bb946\",\"title\":\"A Biologically Inspired Saliency Priority Extraction Using Bayesian Framework\",\"url\":\"https://www.semanticscholar.org/paper/7fc3323ea6593155e017ee709913c930769bb946\",\"venue\":\"Int. J. Multim. Data Eng. Manag.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2800072\",\"name\":\"W. Hoo\"},{\"authorId\":\"2863960\",\"name\":\"Chee Seng Chan\"}],\"doi\":\"10.1109/ICIP.2018.8451622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65e588575c1174523cae13d7c7e29ecffc2fa81b\",\"title\":\"Anisotropic Partial Differential Equation Based Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/65e588575c1174523cae13d7c7e29ecffc2fa81b\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"1735685\",\"name\":\"Jiantao Zhou\"},{\"authorId\":\"120069998\",\"name\":\"Xiaoping Zhang\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145394028\",\"name\":\"X. Guan\"}],\"doi\":\"10.1109/TIP.2020.2966082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c597fc740c296c3f3713cd88e9d65f5b119790c\",\"title\":\"A Multimodal Saliency Model for Videos With High Audio-Visual Correspondence\",\"url\":\"https://www.semanticscholar.org/paper/1c597fc740c296c3f3713cd88e9d65f5b119790c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390936291\",\"name\":\"Haoran Liang\"},{\"authorId\":\"1410304992\",\"name\":\"Ming Jiang\"},{\"authorId\":\"4487395\",\"name\":\"Ronghua Liang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1016/j.neucom.2019.09.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"title\":\"A structure-guided approach to the prediction of natural image saliency\",\"url\":\"https://www.semanticscholar.org/paper/126e0801de465f8d2092af3eb88a89a8f2e995f7\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731831\",\"name\":\"A. Chetouani\"},{\"authorId\":\"3349256\",\"name\":\"M. Qureshi\"},{\"authorId\":\"2500259\",\"name\":\"Mohamed Deriche\"},{\"authorId\":\"1731553\",\"name\":\"Azeddine Beghdadi\"}],\"doi\":\"10.1109/QoMEX.2019.8743152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c8f1bfe39c42448614df8421eba83b55d2ec26\",\"title\":\"A Novel Ranking Algorithm of Enhanced Images using a Convolutional Neural Network and a Saliency-based Patch Selection Scheme\",\"url\":\"https://www.semanticscholar.org/paper/55c8f1bfe39c42448614df8421eba83b55d2ec26\",\"venue\":\"2019 Eleventh International Conference on Quality of Multimedia Experience (QoMEX)\",\"year\":2019},{\"arxivId\":\"1905.06326\",\"authors\":[{\"authorId\":\"2994471\",\"name\":\"X. Zhang\"},{\"authorId\":\"40353974\",\"name\":\"K. Matzen\"},{\"authorId\":\"50393245\",\"name\":\"Vivien L. Nguyen\"},{\"authorId\":\"144210947\",\"name\":\"Dillon Yao\"},{\"authorId\":\"49890547\",\"name\":\"You Zhang\"},{\"authorId\":\"47383180\",\"name\":\"R. Ng\"}],\"doi\":\"10.1145/3306346.3323015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4150bde5405df091ad07e59e2480fd651758712f\",\"title\":\"Synthetic defocus and look-ahead autofocus for casual videography\",\"url\":\"https://www.semanticscholar.org/paper/4150bde5405df091ad07e59e2480fd651758712f\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48162270\",\"name\":\"Chongyi Li\"},{\"authorId\":\"18158517\",\"name\":\"C. Guo\"},{\"authorId\":\"2910007\",\"name\":\"J. Guo\"},{\"authorId\":\"145129110\",\"name\":\"Ping Han\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"3409475\",\"name\":\"Runmin Cong\"}],\"doi\":\"10.1109/TMM.2019.2933334\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dff09a591355b16c48f5051cc6db248eec81d1c\",\"title\":\"PDR-Net: Perception-Inspired Single Image Dehazing Network With Refinement\",\"url\":\"https://www.semanticscholar.org/paper/9dff09a591355b16c48f5051cc6db248eec81d1c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"2004323567\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/s11263-020-01371-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"title\":\"DeepVS2.0: A Saliency-Structured Deep Learning Method for Predicting Dynamic Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/540b4082b83335de2e08ac8a8e08e74e7756c9b5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6271074\",\"name\":\"Kirsten A Dalrymple\"},{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"3048594\",\"name\":\"J. Elison\"}],\"doi\":\"10.1038/s41598-019-42764-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5920514d8807b434fed19cb938c9a434b6979265\",\"title\":\"Machine learning accurately classifies age of toddlers based on eye tracking\",\"url\":\"https://www.semanticscholar.org/paper/5920514d8807b434fed19cb938c9a434b6979265\",\"venue\":\"Scientific Reports\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2657185\",\"name\":\"Ruohan Zhang\"},{\"authorId\":\"10978611\",\"name\":\"Akanksha Saran\"},{\"authorId\":\"73548014\",\"name\":\"Bo Liu\"},{\"authorId\":\"46759203\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1807482896\",\"name\":\"Sihang Guo\"},{\"authorId\":\"2791038\",\"name\":\"S. Niekum\"},{\"authorId\":\"1691804\",\"name\":\"D. Ballard\"},{\"authorId\":\"2848854\",\"name\":\"M. Hayhoe\"}],\"doi\":\"10.24963/ijcai.2020/689\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"title\":\"Human Gaze Assisted Artificial Intelligence: A Review\",\"url\":\"https://www.semanticscholar.org/paper/97a06ab02b44a696619c21de32d6ec0dcfc876eb\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7956594\",\"name\":\"Mengke Huang\"},{\"authorId\":\"49292977\",\"name\":\"Z. Liu\"},{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"1792646\",\"name\":\"X. Zhou\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.07.054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85caaf7f993d0bc70fe22853aff6e5dfad5fcccc\",\"title\":\"Saliency detection via multi-level integration and multi-scale fusion neural networks\",\"url\":\"https://www.semanticscholar.org/paper/85caaf7f993d0bc70fe22853aff6e5dfad5fcccc\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2019.00248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"3411472\",\"name\":\"G. Panagiotaropoulou\"},{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2018.00269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"113eda25ece35fd7ecb51cb104182a973ea2313e\",\"title\":\"Audio-Visual Temporal Saliency Modeling Validated by fMRI Data\",\"url\":\"https://www.semanticscholar.org/paper/113eda25ece35fd7ecb51cb104182a973ea2313e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"2011.10600\",\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"2028199013\",\"name\":\"Marouane Tliba\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"title\":\"ATSal: An Attention Based Architecture for Saliency Prediction in 360 Videos\",\"url\":\"https://www.semanticscholar.org/paper/39ebe1ff6f4087119fa9c70ff981f31b60613452\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409985550\",\"name\":\"Linardos Panagiotis\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1b02efcd0b2c26c9e68b3807d7e958af763b56ab\",\"title\":\"The impact of temporal regularisation in egocentric saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/1b02efcd0b2c26c9e68b3807d7e958af763b56ab\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1937240\",\"name\":\"Tariq Alshawi\"}],\"doi\":\"10.1109/IEEECONF44664.2019.9048740\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09af315002dd893b4946256ba18eeffbc7ad929d\",\"title\":\"Ultra-Fast Saliency Detection Using Qr Factorization\",\"url\":\"https://www.semanticscholar.org/paper/09af315002dd893b4946256ba18eeffbc7ad929d\",\"venue\":\"2019 53rd Asilomar Conference on Signals, Systems, and Computers\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":null,\"name\":\"Kevin Knight\"},{\"authorId\":\"7003054\",\"name\":\"C. Zhang\"},{\"authorId\":\"153633490\",\"name\":\"G. Holmes\"},{\"authorId\":\"3039887\",\"name\":\"M. Zhang\"},{\"authorId\":\"144995564\",\"name\":\"M. Rey\"}],\"doi\":\"10.1007/978-981-32-9298-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"95bd7b6c1ab025c8746676023d03161900760ece\",\"title\":\"Artificial Intelligence: Second CCF International Conference, ICAI 2019, Xuzhou, China, August 22-23, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/95bd7b6c1ab025c8746676023d03161900760ece\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2065050\",\"name\":\"P. Zhang\"},{\"authorId\":\"48211556\",\"name\":\"J. Liu\"},{\"authorId\":\"80645541\",\"name\":\"Xiaoyang Wang\"},{\"authorId\":\"145269215\",\"name\":\"Tian Pu\"},{\"authorId\":\"16101332\",\"name\":\"C. Fei\"},{\"authorId\":\"92138570\",\"name\":\"Z. Guo\"}],\"doi\":\"10.1016/j.neucom.2019.10.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53509f37648f20926a1e07b5ee0437b489552cba\",\"title\":\"Stereoscopic video saliency detection based on spatiotemporal correlation and depth confidence optimization\",\"url\":\"https://www.semanticscholar.org/paper/53509f37648f20926a1e07b5ee0437b489552cba\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47345303\",\"name\":\"M. Yang\"},{\"authorId\":\"50726606\",\"name\":\"Ke Hu\"},{\"authorId\":\"1389983742\",\"name\":\"Yixiang Du\"},{\"authorId\":\"1409683594\",\"name\":\"Zhiqiang Wei\"},{\"authorId\":\"97104927\",\"name\":\"Zhibin Sheng\"},{\"authorId\":\"50778914\",\"name\":\"Jintong Hu\"}],\"doi\":\"10.1016/j.image.2019.115723\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d4e19e1dcee9c75ca87740c944a0065a616a003\",\"title\":\"Underwater image enhancement based on conditional generative adversarial network\",\"url\":\"https://www.semanticscholar.org/paper/5d4e19e1dcee9c75ca87740c944a0065a616a003\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"1910.02793\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"Eric Hofesmann\"},{\"authorId\":\"46184233\",\"name\":\"N. Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"title\":\"ViP: Video Platform for PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.07912\",\"authors\":[{\"authorId\":\"30927077\",\"name\":\"Vitaliy Lyudvichenko\"},{\"authorId\":\"34966076\",\"name\":\"M. Erofeev\"},{\"authorId\":\"87834429\",\"name\":\"Alexander Ploshkin\"},{\"authorId\":\"1776883\",\"name\":\"D. Vatolin\"}],\"doi\":\"10.1145/3332340.3332358\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d6cc5dbb2a6f1af3ab8bb7e60611986c6d8aa23f\",\"title\":\"Improving Video Compression with Deep Visual-attention Models\",\"url\":\"https://www.semanticscholar.org/paper/d6cc5dbb2a6f1af3ab8bb7e60611986c6d8aa23f\",\"venue\":\"IMIP '19\",\"year\":2019},{\"arxivId\":\"2003.13141\",\"authors\":[{\"authorId\":\"46669153\",\"name\":\"J. Chen\"},{\"authorId\":\"48458657\",\"name\":\"Zhiheng Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00992\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bc2905c4436f3d0c64f9efd075a27bb065539a4\",\"title\":\"Learning a Weakly-Supervised Video Actor-Action Segmentation Model With a Wise Selection\",\"url\":\"https://www.semanticscholar.org/paper/5bc2905c4436f3d0c64f9efd075a27bb065539a4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2012.03255\",\"authors\":[{\"authorId\":\"41078113\",\"name\":\"Abdullah Abuolaim\"},{\"authorId\":\"2346590\",\"name\":\"M. Delbracio\"},{\"authorId\":\"2805563\",\"name\":\"D. Kelly\"},{\"authorId\":\"143955418\",\"name\":\"M. S. Brown\"},{\"authorId\":\"104191307\",\"name\":\"P. Milanfar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eeb0949868cee849df7ae1bd27425d252bf9778\",\"title\":\"Learning to Reduce Defocus Blur by Realistically Modeling Dual-Pixel Data\",\"url\":\"https://www.semanticscholar.org/paper/4eeb0949868cee849df7ae1bd27425d252bf9778\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.10693\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"title\":\"DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143619104\",\"name\":\"Hongmei Song\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"2901725\",\"name\":\"Sanyuan Zhao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144847940\",\"name\":\"K. Lam\"}],\"doi\":\"10.1007/978-3-030-01252-6_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b2807613304c0ee8dcedf0a78d448b95f33816be\",\"title\":\"Pyramid Dilated Deeper ConvLSTM for Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/b2807613304c0ee8dcedf0a78d448b95f33816be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2296560\",\"name\":\"Yasin Kavak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1016/j.image.2019.115694\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"03a6ad701627efdea485ef26dad1626c11fc8c86\",\"title\":\"Hedging static saliency models to predict dynamic saliency\",\"url\":\"https://www.semanticscholar.org/paper/03a6ad701627efdea485ef26dad1626c11fc8c86\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387992157\",\"name\":\"Memoona Tahira\"},{\"authorId\":\"1387992189\",\"name\":\"Sobas Mehboob\"},{\"authorId\":\"31321802\",\"name\":\"Anis Ur Rahman\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf6570f81e505d049dd28fd3e12e15121db5af0e\",\"title\":\"CrowdFix: An Eyetracking Data-set of Human Crowd Video\",\"url\":\"https://www.semanticscholar.org/paper/cf6570f81e505d049dd28fd3e12e15121db5af0e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.09559\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"51245064\",\"name\":\"M. Cherto\"},{\"authorId\":\"1737981\",\"name\":\"C. Gurrin\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"title\":\"Temporal Saliency Adaptation in Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf664deef0dbd74d4a7abf744560fe03bf90e863\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152764184\",\"name\":\"Ziyang Wang\"},{\"authorId\":\"50975061\",\"name\":\"Junxia Li\"},{\"authorId\":\"1700694473\",\"name\":\"Zefeng Pan\"}],\"doi\":\"10.1109/ACCESS.2020.3036533\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b560d6726779101d9f8b70be80389391de83f0d\",\"title\":\"Cross Complementary Fusion Network for Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2b560d6726779101d9f8b70be80389391de83f0d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100715052\",\"name\":\"Yi Tang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"98466827\",\"name\":\"Z. Jin\"},{\"authorId\":\"15524303\",\"name\":\"Xia Li\"}],\"doi\":\"10.1016/j.neucom.2019.09.064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a015dba578ac82532c0968053dc2fd109a6ea73f\",\"title\":\"Video salient object detection via spatiotemporal attention neural networks\",\"url\":\"https://www.semanticscholar.org/paper/a015dba578ac82532c0968053dc2fd109a6ea73f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2002.09315\",\"authors\":[{\"authorId\":\"152641281\",\"name\":\"Y. Zhou\"},{\"authorId\":\"79891004\",\"name\":\"Kangming Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ce21ac210a4d6b06ce97bbae45122f61f1eb378\",\"title\":\"Domain Adaptive Adversarial Learning Based on Physics Model Feedback for Underwater Image Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/2ce21ac210a4d6b06ce97bbae45122f61f1eb378\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119923978\",\"name\":\"Yufan Liu\"},{\"authorId\":\"27647516\",\"name\":\"Minglang Qiao\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1996319848\",\"name\":\"Bing Li\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"}],\"doi\":\"10.1007/978-3-030-58565-5_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"title\":\"Learning to Predict Salient Faces: A Novel Visual-Audio Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/2e4da9223bbaea0dd7d4ed44f3cc0a7d1e7a3b17\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09943\",\"authors\":[{\"authorId\":\"1823941979\",\"name\":\"Sucheng Ren\"},{\"authorId\":\"1641959671\",\"name\":\"Chu Han\"},{\"authorId\":\"6131290\",\"name\":\"X. Yang\"},{\"authorId\":\"2823769\",\"name\":\"G. Han\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1007/978-3-030-58558-7_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1caaf771cf0b8bd0105b01bf7f2b73a58904b5b0\",\"title\":\"TENet: Triple Excitation Network for Video Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/1caaf771cf0b8bd0105b01bf7f2b73a58904b5b0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50313388\",\"name\":\"Y. Fang\"},{\"authorId\":\"47957022\",\"name\":\"Xiaoqiang Zhang\"},{\"authorId\":\"152443510\",\"name\":\"Feiniu Yuan\"},{\"authorId\":\"1830032\",\"name\":\"N. Imamoglu\"},{\"authorId\":\"49958431\",\"name\":\"H. Liu\"}],\"doi\":\"10.1016/J.PATCOG.2019.106987\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"860a93926d62569b3e93214adca5a65e30f7a7c8\",\"title\":\"Video saliency detection by gestalt theory\",\"url\":\"https://www.semanticscholar.org/paper/860a93926d62569b3e93214adca5a65e30f7a7c8\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3289090\",\"name\":\"Chenglizhao Chen\"},{\"authorId\":\"47226794\",\"name\":\"G. Wang\"},{\"authorId\":\"49917512\",\"name\":\"C. Peng\"},{\"authorId\":\"47958351\",\"name\":\"X. Zhang\"},{\"authorId\":\"100787805\",\"name\":\"Hong Qin\"}],\"doi\":\"10.1109/TIP.2019.2934350\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46e4ea8b047064a3519f344413462ac13fe900c1\",\"title\":\"Improved Robust Video Saliency Detection Based on Long-Term Spatial-Temporal Information\",\"url\":\"https://www.semanticscholar.org/paper/46e4ea8b047064a3519f344413462ac13fe900c1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020}],\"corpusId\":4369462,\"doi\":\"10.1109/CVPR.2018.00514\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":23,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1941997\",\"name\":\"Chenlei Guo\"},{\"authorId\":\"29906646\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/TIP.2009.2030969\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"01825573781674bcf85d0f5d2ec456842f75ad3c\",\"title\":\"A Novel Multiresolution Spatiotemporal Saliency Detection Model and Its Applications in Image and Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/01825573781674bcf85d0f5d2ec456842f75ad3c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145021890\",\"name\":\"N. Liu\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"145251057\",\"name\":\"T. Liu\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/TNNLS.2016.2628878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf18c239a819dc179d4261fdfb39d16f0356b8d3\",\"title\":\"Learning to Predict Eye Fixations via Multiresolution Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cf18c239a819dc179d4261fdfb39d16f0356b8d3\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036170\",\"name\":\"Dashan Gao\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53ce6063ea4334389198e45b0525c94af5474ee7\",\"title\":\"Discriminant Saliency for Visual Recognition from Cluttered Scenes\",\"url\":\"https://www.semanticscholar.org/paper/53ce6063ea4334389198e45b0525c94af5474ee7\",\"venue\":\"NIPS\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2306103\",\"name\":\"Parag K. Mital\"},{\"authorId\":\"145165599\",\"name\":\"T. Smith\"},{\"authorId\":\"3252072\",\"name\":\"R. L. Hill\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1007/s12559-010-9074-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"title\":\"Clustering of Gaze During Dynamic Scene Viewing is Predicted by Motion\",\"url\":\"https://www.semanticscholar.org/paper/27266e3be4d9b9572e8e11f4ef34110a2a00f515\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123135459\",\"name\":\"Mikel D. Rodriguez\"},{\"authorId\":\"144643948\",\"name\":\"Javed Ahmed\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2008.4587727\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"title\":\"Action MACH a spatio-temporal Maximum Average Correlation Height filter for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c2629d53fd73ee42fb9a67b4d656688ef6a005f\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1506.04214\",\"authors\":[{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"2192200\",\"name\":\"Zhourong Chen\"},{\"authorId\":\"49528584\",\"name\":\"Hao Wang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"145771919\",\"name\":\"W. Wong\"},{\"authorId\":\"2183294\",\"name\":\"Wang-chun Woo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"title\":\"Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\",\"url\":\"https://www.semanticscholar.org/paper/f9c990b1b5724e50e5632b94fdb7484ece8a6ce7\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50814507\",\"name\":\"Cagdas Bak\"},{\"authorId\":\"3044594\",\"name\":\"Aysun Kocak\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1109/TMM.2017.2777665\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"title\":\"Spatio-Temporal Saliency Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1ebd1083ad9e10ed2feded8319c5d472bf9f420b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. S. Kruthiventi\"},{\"authorId\":null,\"name\":\"K. Ayush\"},{\"authorId\":null,\"name\":\"R. V. Babu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A method for stochastic optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2015.7298961\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4fd90ef2ff0f673faa1c89ea318341443939799\",\"title\":\"Saliency-aware geodesic video object segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a4fd90ef2ff0f673faa1c89ea318341443939799\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"46266511\",\"name\":\"Guo-Xin Zhang\"},{\"authorId\":\"1710455\",\"name\":\"N. Mitra\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/CVPR.2011.5995344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"689c97982f0ef6d8b0df3ec33a3abe29b8f97c1f\",\"title\":\"Global contrast based salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/689c97982f0ef6d8b0df3ec33a3abe29b8f97c1f\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1412.5027\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/TIP.2014.2383320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bb4e1ddfec4c5868c31685b6dfe8673df1d3e38\",\"title\":\"What is a Salient Object? A Dataset and a Baseline Model for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/8bb4e1ddfec4c5868c31685b6dfe8673df1d3e38\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1038/35058500\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"320b36777d57e772d88d278ceeccd1f5e746304c\",\"title\":\"Computational modelling of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/320b36777d57e772d88d278ceeccd1f5e746304c\",\"venue\":\"Nature Reviews Neuroscience\",\"year\":2001},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036170\",\"name\":\"Dashan Gao\"},{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"655f212f069e2a2f16b90c02dcae3f46e8bb3c2c\",\"title\":\"The discriminant center-surround hypothesis for bottom-up saliency\",\"url\":\"https://www.semanticscholar.org/paper/655f212f069e2a2f16b90c02dcae3f46e8bb3c2c\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2675203\",\"name\":\"Seyed Hossein Khatoonabadi\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"},{\"authorId\":\"37207452\",\"name\":\"Yufeng Shan\"}],\"doi\":\"10.1109/CVPR.2015.7299189\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"12c1df9b8c6e55bd6597b335dd9d9bac9fe5ee26\",\"title\":\"How many bits does it take for a stimulus to be salient?\",\"url\":\"https://www.semanticscholar.org/paper/12c1df9b8c6e55bd6597b335dd9d9bac9fe5ee26\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1710.08014\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/ICCV.2017.240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"title\":\"Deep Cropping via Attention Box Prediction and Aesthetics Assessment\",\"url\":\"https://www.semanticscholar.org/paper/b14ee992824177ddfbf369cc3d7d36bdfec7ad0e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":\"1702.00871\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1109/TIP.2017.2754941\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927e0a7b1f06102725a026f690077654fa53c76e\",\"title\":\"Video Salient Object Detection via Fully Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/927e0a7b1f06102725a026f690077654fa53c76e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Judd\"},{\"authorId\":null,\"name\":\"F. Durand\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliency in context\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/TIP.2015.2460013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"065ec79836040f89df3c850a3b065de9222a8871\",\"title\":\"Consistent Video Saliency Using Local Gradient Flow Optimization and Global Refinement\",\"url\":\"https://www.semanticscholar.org/paper/065ec79836040f89df3c850a3b065de9222a8871\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4639656\",\"name\":\"Y. Fang\"},{\"authorId\":\"91543683\",\"name\":\"Z. Wang\"},{\"authorId\":\"144968898\",\"name\":\"W. Lin\"},{\"authorId\":\"35301080\",\"name\":\"Zhijun Fang\"}],\"doi\":\"10.1109/TIP.2014.2336549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f4545275ca4240a7b127080b50950d3d99d6c23\",\"title\":\"Video saliency incorporating spatiotemporal cues and uncertainty weighting\",\"url\":\"https://www.semanticscholar.org/paper/0f4545275ca4240a7b127080b50950d3d99d6c23\",\"venue\":\"2013 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/TIP.2016.2601784\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"785337b262534e43a4e14d21283e180bbce23621\",\"title\":\"Correspondence Driven Saliency Transfer\",\"url\":\"https://www.semanticscholar.org/paper/785337b262534e43a4e14d21283e180bbce23621\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2016},{\"arxivId\":\"1506.03365\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"2507239\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3340170\",\"name\":\"Shuran Song\"},{\"authorId\":\"2233674\",\"name\":\"Ari Seff\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dcdae25a5e33682953f0853ee4cf7ca93be58a9\",\"title\":\"LSUN: Construction of a Large-scale Image Dataset using Deep Learning with Humans in the Loop\",\"url\":\"https://www.semanticscholar.org/paper/4dcdae25a5e33682953f0853ee4cf7ca93be58a9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9499991\",\"name\":\"Chunshui Cao\"},{\"authorId\":\"1958191\",\"name\":\"X. Liu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"2278628\",\"name\":\"Y. Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"},{\"authorId\":\"145501833\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"48908475\",\"name\":\"C. Huang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2015.338\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2260ad2f72b319b6b30569d451026b6290f5ebee\",\"title\":\"Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2260ad2f72b319b6b30569d451026b6290f5ebee\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1312.7570\",\"authors\":[{\"authorId\":\"37710702\",\"name\":\"Stefan Mathe\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/TPAMI.2014.2366154\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"title\":\"Actions in the Eye: Dynamic Gaze Datasets and Learnt Saliency Models for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e254d0e670ce8217e74aaf1421c72e63e62929e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2004.834657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"title\":\"Automatic foveation for video compression using a neurobiological model of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/bbb456acfec69d279b3f653b53dc1182d1b44eb6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92349749\",\"name\":\"T. Liu\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":null,\"name\":\"Jian Sun\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1109/TPAMI.2010.70\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4f03f0c435f8a2891b048d19d7a0b8e3e5263b4\",\"title\":\"Learning to Detect a Salient Object\",\"url\":\"https://www.semanticscholar.org/paper/f4f03f0c435f8a2891b048d19d7a0b8e3e5263b4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":\"1804.01793\",\"authors\":[{\"authorId\":\"35129473\",\"name\":\"Saumya Jetley\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"}],\"doi\":\"10.1109/CVPR.2016.620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4d42c041bf30021550e581775c1e04f253edf54\",\"title\":\"End-to-End Saliency Mapping via Probability Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4d42c041bf30021550e581775c1e04f253edf54\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"},{\"authorId\":\"1707383\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/TVCG.2016.2600594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7379a98b0ebb1a3e6992268f89ab2b95b2746272\",\"title\":\"Stereoscopic Thumbnail Creation via Efficient Stereo Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/7379a98b0ebb1a3e6992268f89ab2b95b2746272\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326805\",\"name\":\"Hae Jong Seo\"},{\"authorId\":\"1718280\",\"name\":\"P. Milanfar\"}],\"doi\":\"10.1167/9.12.15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"143973e23364190bc687fe694eb863417e8ba0ba\",\"title\":\"Static and space-time visual saliency detection by self-resemblance.\",\"url\":\"https://www.semanticscholar.org/paper/143973e23364190bc687fe694eb863417e8ba0ba\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":\"1705.02544\",\"authors\":[{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2017.2787612\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"title\":\"Deep Visual Attention Prediction\",\"url\":\"https://www.semanticscholar.org/paper/65c1a8cde4030217bec7cb96b8bf94c5321e8d8e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1611.04849\",\"authors\":[{\"authorId\":\"144525426\",\"name\":\"Q. Hou\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"38643770\",\"name\":\"X. Hu\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/TPAMI.2018.2815688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"727c44124329d6083130cce93a4ee502469c5d03\",\"title\":\"Deeply Supervised Salient Object Detection with Short Connections\",\"url\":\"https://www.semanticscholar.org/paper/727c44124329d6083130cce93a4ee502469c5d03\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"J. Shen\"},{\"authorId\":null,\"name\":\"R. Yang\"},{\"authorId\":null,\"name\":\"F. Porikli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliencyaware video object segmentation\",\"url\":\"\",\"venue\":\"IEEE TPAMI,\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Achanta\"},{\"authorId\":null,\"name\":\"S. Hemami\"},{\"authorId\":null,\"name\":\"F. Estrada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Susstrunk. Frequency-tuned salient region detection\",\"url\":\"\",\"venue\":\"In CVPR,\",\"year\":2009},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118589\",\"name\":\"R. Achanta\"},{\"authorId\":\"1720838\",\"name\":\"S. Hemami\"},{\"authorId\":\"145337110\",\"name\":\"F. J. Estrada\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1109/CVPR.2009.5206596\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"63d523a58d2cd24efbc1ab35acccc64e0f93162b\",\"title\":\"Frequency-tuned salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/63d523a58d2cd24efbc1ab35acccc64e0f93162b\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1776651\",\"name\":\"P. Callet\"},{\"authorId\":\"144812989\",\"name\":\"D. Barba\"},{\"authorId\":\"144843363\",\"name\":\"D. Thoreau\"}],\"doi\":\"10.1109/TPAMI.2006.86\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f30fed23882675422aada3bd60ed7d1ae84fcb09\",\"title\":\"A coherent computational approach to model bottom-up visual attention\",\"url\":\"https://www.semanticscholar.org/paper/f30fed23882675422aada3bd60ed7d1ae84fcb09\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2006},{\"arxivId\":\"1406.2807\",\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2014.43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40e71c10edc2afc68d079546e8f4952cd52dc671\",\"title\":\"The Secrets of Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/40e71c10edc2afc68d079546e8f4952cd52dc671\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1704.06904\",\"authors\":[{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"9563639\",\"name\":\"Mengqing Jiang\"},{\"authorId\":null,\"name\":\"Chen Qian\"},{\"authorId\":\"1692609\",\"name\":\"S. Yang\"},{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"1720776\",\"name\":\"H. Zhang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2017.683\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"77d30cf9a34fb6b50979c6a68863099da9a060ad\",\"title\":\"Residual Attention Network for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/77d30cf9a34fb6b50979c6a68863099da9a060ad\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/cvprw.2009.5206557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fd485daa491c0debcd900b3f6bc141c3883812d\",\"title\":\"Actions in context\",\"url\":\"https://www.semanticscholar.org/paper/1fd485daa491c0debcd900b3f6bc141c3883812d\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1510.02927\",\"authors\":[{\"authorId\":\"1784761\",\"name\":\"S. Kruthiventi\"},{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"}],\"doi\":\"10.1109/TIP.2017.2710620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"title\":\"DeepFix: A Fully Convolutional Neural Network for Predicting Human Eye Fixations\",\"url\":\"https://www.semanticscholar.org/paper/1295cbaf3b03de2eb8c79530289f5939d7819e5c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38497468\",\"name\":\"M. Cerf\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"1917767\",\"name\":\"W. Einh\\u00e4user\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"title\":\"Predicting human gaze using low-level saliency combined with face detection\",\"url\":\"https://www.semanticscholar.org/paper/a48dc9c898d6ff1cdb96dcf8a297bafb8ac1b9e2\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97586731\",\"name\":\"B. Motter\"}],\"doi\":\"10.1523/JNEUROSCI.14-04-02178.1994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4341a27911ba0b23c04b82a5296b8f71f7587fe\",\"title\":\"Neural correlates of attentive selection for color or luminance in extrastriate area V4\",\"url\":\"https://www.semanticscholar.org/paper/f4341a27911ba0b23c04b82a5296b8f71f7587fe\",\"venue\":\"The Journal of neuroscience : the official journal of the Society for Neuroscience\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2118589\",\"name\":\"R. Achanta\"},{\"authorId\":\"1720838\",\"name\":\"S. Hemami\"},{\"authorId\":\"145337110\",\"name\":\"F. J. Estrada\"},{\"authorId\":\"1735035\",\"name\":\"S. S\\u00fcsstrunk\"}],\"doi\":\"10.1109/CVPRW.2009.5206596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f52d46714a3fccbe9ea293763b03550ada7bd7d\",\"title\":\"Frequency-tuned salient region detection\",\"url\":\"https://www.semanticscholar.org/paper/2f52d46714a3fccbe9ea293763b03550ada7bd7d\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J M Wolfe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Guided search 4.0. Integrated models of cognitive systems\",\"url\":\"\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/CVPR.2007.383267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"title\":\"Saliency Detection: A Spectral Residual Approach\",\"url\":\"https://www.semanticscholar.org/paper/9ce3c18eb4fa86fd19bce46227be39895de4e4ab\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":\"1509.00685\",\"authors\":[{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/D15-1044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5082a1a13daea5c7026706738f8528391a1e6d59\",\"title\":\"A Neural Attention Model for Abstractive Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/5082a1a13daea5c7026706738f8528391a1e6d59\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1080/13506280444000661\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"463c3e8403b95b88f8e19cdaa3d9ec0a3105f6ac\",\"title\":\"Quantifying the contribution of low-level saliency to human eye movements in dynamic scenes\",\"url\":\"https://www.semanticscholar.org/paper/463c3e8403b95b88f8e19cdaa3d9ec0a3105f6ac\",\"venue\":\"\",\"year\":2005},{\"arxivId\":\"1709.06316\",\"authors\":[{\"authorId\":\"47420847\",\"name\":\"Lai Jiang\"},{\"authorId\":\"1743773\",\"name\":\"M. Xu\"},{\"authorId\":\"1754571\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-01264-9_37\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"title\":\"Predicting Video Saliency with Object-to-Motion CNN and Two-layer Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fb0942800a4bc36881785d1bd878b5e8c95d9fe4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717172\",\"name\":\"J. Wolfe\"}],\"doi\":\"10.1093/ACPROF:OSO/9780195189193.003.0008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"207ddf84bb5bd5006ad8e6124a5452524fca1c8a\",\"title\":\"Guided Search 4.0: Current Progress With a Model of Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/207ddf84bb5bd5006ad8e6124a5452524fca1c8a\",\"venue\":\"Integrated Models of Cognitive Systems\",\"year\":2007},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1760977\",\"name\":\"V. Lebor\\u00e1n\"},{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398517622\",\"name\":\"Xose R. Fdez-Vidal\"},{\"authorId\":\"1397906798\",\"name\":\"Xose M. Pardo\"}],\"doi\":\"10.1109/TPAMI.2016.2567391\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"822cf4868af46453dd7e9232ad8011e62c9c0400\",\"title\":\"Dynamic Whitening Saliency\",\"url\":\"https://www.semanticscholar.org/paper/822cf4868af46453dd7e9232ad8011e62c9c0400\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48493294\",\"name\":\"V. Mahadevan\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/TPAMI.2009.112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62eb421cdac9de9255578f14fba55146d958be44\",\"title\":\"Spatiotemporal Saliency in Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/62eb421cdac9de9255578f14fba55146d958be44\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2010},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1607.04730\",\"authors\":[{\"authorId\":\"34847250\",\"name\":\"\\u00c7agdas Bak\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"title\":\"Two-Stream Convolutional Networks for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/dac2e8365df576e6d3f16b01d48e0d5e4156b81f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. M. Wolfe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Guided search 4.0\",\"url\":\"\",\"venue\":\"Integrated models of cognitive systems,\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685004\",\"name\":\"H. Hadizadeh\"},{\"authorId\":\"3347231\",\"name\":\"Mario J. Enriquez\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":\"10.1109/TIP.2011.2165292\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1efdc78aee3be8af7e12941817d8c70797c48ef\",\"title\":\"Eye-Tracking Database for a Set of Standard Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/b1efdc78aee3be8af7e12941817d8c70797c48ef\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25942970\",\"name\":\"M. Wischnewski\"},{\"authorId\":\"2901441\",\"name\":\"A. Belardinelli\"},{\"authorId\":\"3030956\",\"name\":\"W. Schneider\"},{\"authorId\":\"27551792\",\"name\":\"Jochen J. Steil\"}],\"doi\":\"10.1007/s12559-010-9080-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e1757b9c1a47b98ce6f05ce23848bf9398e7da2\",\"title\":\"Where to Look Next? Combining Static and Dynamic Proto-objects in a TVA-based Model of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6e1757b9c1a47b98ce6f05ce23848bf9398e7da2\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":\"1606.01933\",\"authors\":[{\"authorId\":\"144729897\",\"name\":\"Ankur P. Parikh\"},{\"authorId\":\"2556289\",\"name\":\"Oscar T\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"143790066\",\"name\":\"Dipanjan Das\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"}],\"doi\":\"10.18653/v1/D16-1244\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2cd8e8f510c89c7c18268e8ad51c061e459ad321\",\"title\":\"A Decomposable Attention Model for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/2cd8e8f510c89c7c18268e8ad51c061e459ad321\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"5381034\",\"name\":\"L. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"title\":\"Dynamic visual attention: searching for coding length increments\",\"url\":\"https://www.semanticscholar.org/paper/4e7ec75337766f2b649bb9f99c6887ee0f1674a6\",\"venue\":\"NIPS\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40635259\",\"name\":\"D. Rudoy\"},{\"authorId\":\"1976171\",\"name\":\"D. Goldman\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1398327241\",\"name\":\"L. Zelnik-Manor\"}],\"doi\":\"10.1109/CVPR.2013.152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d7924e07914a147d7f6b868050d4edd093b952d\",\"title\":\"Learning Video Saliency from Human Gaze Using Candidate Selection\",\"url\":\"https://www.semanticscholar.org/paper/3d7924e07914a147d7f6b868050d4edd093b952d\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1501.02741\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"49712326\",\"name\":\"M. Cheng\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"97483166\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TIP.2015.2487833\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1260c42b86dcbe123ccc038857cd3b14e146032\",\"title\":\"Salient Object Detection: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/a1260c42b86dcbe123ccc038857cd3b14e146032\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2015}],\"title\":\"Revisiting Video Saliency: A Large-Scale Benchmark and a New Model\",\"topics\":[{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"Scalability\",\"topicId\":\"1360\",\"url\":\"https://www.semanticscholar.org/topic/1360\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"File spanning\",\"topicId\":\"2852713\",\"url\":\"https://www.semanticscholar.org/topic/2852713\"}],\"url\":\"https://www.semanticscholar.org/paper/fdf8c9c4c30c6005c2f0e92ce9db3de5ab8b5d29\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"