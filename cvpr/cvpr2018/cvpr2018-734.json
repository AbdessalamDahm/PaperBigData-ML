"{\"abstract\":\"Most state-of-the-art methods for action recognition rely on a two-stream architecture that processes appearance and motion independently. In this paper, we claim that considering them jointly offers rich information for action recognition. We introduce a novel representation that gracefully encodes the movement of some semantic keypoints. We use the human joints as these keypoints and term our Pose moTion representation PoTion. Specifically, we first run a state-of-the-art human pose estimator [4] and extract heatmaps for the human joints in each frame. We obtain our PoTion representation by temporally aggregating these probability maps. This is achieved by 'colorizing' each of them depending on the relative time of the frames in the video clip and summing them. This fixed-size representation for an entire video clip is suitable to classify actions using a shallow convolutional neural network. Our experimental evaluation shows that PoTion outperforms other state-of-the-art pose representations [6, 48]. Furthermore, it is complementary to standard appearance and motion streams. When combining PoTion with the recent two-stream I3D approach [5], we obtain state-of-the-art performance on the JHMDB, HMDB and UCF101 datasets.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\",\"url\":\"https://www.semanticscholar.org/author/52022007\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\",\"url\":\"https://www.semanticscholar.org/author/2492127\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\",\"url\":\"https://www.semanticscholar.org/author/3428663\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\",\"url\":\"https://www.semanticscholar.org/author/2462253\"}],\"citationVelocity\":37,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/TIP.2019.2922826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"title\":\"Compact and Low-Complexity Binary Feature Descriptor and Fisher Vectors for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2003.10663\",\"authors\":[{\"authorId\":\"2598007\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102717\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d706c38381ec095c8e456b0b0387ae212e0581be\",\"title\":\"Modeling Cross-View Interaction Consistency for Paired Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d706c38381ec095c8e456b0b0387ae212e0581be\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471304742\",\"name\":\"Manh-Hung Lu\"},{\"authorId\":\"40429856\",\"name\":\"Thi-Oanh Nguyen\"}],\"doi\":\"10.1145/3368926.3369726\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2965fc1c8f97339cac4a5869b2a5ee56dbd27d6\",\"title\":\"Spatio-temporal Multi-level Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2965fc1c8f97339cac4a5869b2a5ee56dbd27d6\",\"venue\":\"SoICT 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0008958003510358\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e9213f65145533551043f36b542ee549b08089d3\",\"title\":\"Multi-stream Architecture with Symmetric Extended Visual Rhythms for Deep Learning Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e9213f65145533551043f36b542ee549b08089d3\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":\"2004.10774\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"1648707714\",\"name\":\"Qazi Ammar Arshad\"},{\"authorId\":\"144212662\",\"name\":\"Chen Chen\"}],\"doi\":\"10.1007/978-3-030-03243-2_846-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e3ff4cad99d691ecb613b384d311cd411569b9\",\"title\":\"Action recognition in real-world videos\",\"url\":\"https://www.semanticscholar.org/paper/54e3ff4cad99d691ecb613b384d311cd411569b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27039516\",\"name\":\"Almoctar Hassoumi\"},{\"authorId\":\"2231675\",\"name\":\"Vsevolod Peysakhovich\"},{\"authorId\":\"2433007\",\"name\":\"C. Hurter\"}],\"doi\":\"10.1145/3314111.3319820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f4738fd376d281a1d6bb14e888ba93892a23ef7\",\"title\":\"EyeFlow: pursuit interactions using an unmodified camera\",\"url\":\"https://www.semanticscholar.org/paper/9f4738fd376d281a1d6bb14e888ba93892a23ef7\",\"venue\":\"ETRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"97474510\",\"name\":\"L. Xu\"},{\"authorId\":\"153940079\",\"name\":\"Guan Huang\"}],\"doi\":\"10.1109/LSP.2019.2942739\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"title\":\"Action Machine: Toward Person-Centric Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"88550057\",\"name\":\"Marc Pollefeys\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"title\":\"Unified Egocentric Recognition of 3 D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/d39d3de091a3fe65e42a5034e49ce44ee0397a69\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121067506\",\"name\":\"Karina Mariela Figueroa Mora\"},{\"authorId\":\"47506907\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143669366\",\"name\":\"J. Cerd\\u00e1\"},{\"authorId\":\"1398026763\",\"name\":\"J. A. Carrasco-Ochoa\"},{\"authorId\":\"1404558266\",\"name\":\"J. F. Mart\\u00ednez-Trinidad\"},{\"authorId\":\"1400326434\",\"name\":\"J. A. Olvera-L\\u00f3pez\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"},{\"authorId\":\"1752005681\",\"name\":\"Karina Mariela Figueroa\"}],\"doi\":\"10.1007/978-3-030-49076-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b38358f5be96b465fa18a8eee4b671532f9eeea4\",\"title\":\"Pattern Recognition: 12th Mexican Conference, MCPR 2020, Morelia, Mexico, June 24\\u201327, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/b38358f5be96b465fa18a8eee4b671532f9eeea4\",\"venue\":\"MCPR\",\"year\":2020},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICIP40778.2020.9191360\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a15dbfca55605bd3a5769ada375433c216822e0e\",\"title\":\"Coarse-to-Fine Aggregation for Cross-Granularity Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a15dbfca55605bd3a5769ada375433c216822e0e\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1911.08708\",\"authors\":[{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"1385119825\",\"name\":\"Christian Roncal\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1007/978-3-030-58607-2_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a718341f5db00071de408a4bd52e92541052e13\",\"title\":\"Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and Affective Mapping\",\"url\":\"https://www.semanticscholar.org/paper/3a718341f5db00071de408a4bd52e92541052e13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.04860\",\"authors\":[{\"authorId\":\"2019933\",\"name\":\"Nina Taherimakhsousi\"},{\"authorId\":\"1401407937\",\"name\":\"Benjamin P. MacLeod\"},{\"authorId\":\"15410514\",\"name\":\"F. G. Parlane\"},{\"authorId\":\"148222796\",\"name\":\"T. D. Morrissey\"},{\"authorId\":\"9647425\",\"name\":\"Edward P. Booker\"},{\"authorId\":\"4269934\",\"name\":\"Kevan E Dettelbach\"},{\"authorId\":\"4463265\",\"name\":\"C. Berlinguette\"}],\"doi\":\"10.1038/s41524-020-00380-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"447bde6c6fce26dcda1b13961d1ff6c2381cdd59\",\"title\":\"Quantifying defects in thin films using machine vision\",\"url\":\"https://www.semanticscholar.org/paper/447bde6c6fce26dcda1b13961d1ff6c2381cdd59\",\"venue\":\"npj Computational Materials\",\"year\":2020},{\"arxivId\":\"1909.09566\",\"authors\":[{\"authorId\":\"3421983\",\"name\":\"Behnaz Rezaei\"},{\"authorId\":\"1388732358\",\"name\":\"Yiorgos Christakis\"},{\"authorId\":\"91252281\",\"name\":\"Bryan Ho\"},{\"authorId\":\"49773841\",\"name\":\"K. Thomas\"},{\"authorId\":\"145859998\",\"name\":\"K. Erb\"},{\"authorId\":\"2225783\",\"name\":\"S. Ostadabbas\"},{\"authorId\":\"50260566\",\"name\":\"S. Patel\"}],\"doi\":\"10.3390/s19194266\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"84b5e88e319346385bbedb5d6c8d539693a3397f\",\"title\":\"Target-Specific Action Classification for Automated Assessment of Human Motor Behavior from Video\",\"url\":\"https://www.semanticscholar.org/paper/84b5e88e319346385bbedb5d6c8d539693a3397f\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1904.03249\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"40897068\",\"name\":\"Xin Chen\"},{\"authorId\":\"23614019\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76db87564c7e6a6f417fca41b9f659a879de5027\",\"title\":\"Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/76db87564c7e6a6f417fca41b9f659a879de5027\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"E. Morales\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/s10044-020-00924-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b3d22fad864939a5e630fda197e8584fef793e0\",\"title\":\"Second-order motion descriptors for efficient action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b3d22fad864939a5e630fda197e8584fef793e0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.08154\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"1500648246\",\"name\":\"Han Lu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"40370720\",\"name\":\"J. Liu\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f51b8b8fcdf881d2bb5b5fece37154907b17249b\",\"title\":\"Detailed 2D-3D Joint Representation for Human-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/f51b8b8fcdf881d2bb5b5fece37154907b17249b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.10636\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2019.00188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"title\":\"Evolving Space-Time Neural Architectures for Videos\",\"url\":\"https://www.semanticscholar.org/paper/793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"47634649\",\"name\":\"Akshay Dudhane\"},{\"authorId\":\"1430720118\",\"name\":\"Prashant W. Patil\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1109/AVSS.2019.8909835\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cee3f7cb4e13944404d8e92c2ff205cb990e3dc2\",\"title\":\"Pose Guided Dynamic Image Network for Human Action Recognition in Person Centric Videos\",\"url\":\"https://www.semanticscholar.org/paper/cee3f7cb4e13944404d8e92c2ff205cb990e3dc2\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.08077\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"}],\"doi\":\"10.1109/TPAMI.2020.2976014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145e426e378b29ea5cf62f5300f337561b3c2784\",\"title\":\"Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/145e426e378b29ea5cf62f5300f337561b3c2784\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40812342\",\"name\":\"Yeongtaek Song\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3390/s19051085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"title\":\"Spatio-Temporal Action Detection in Untrimmed Videos by Using Multimodal Features and Region Proposals\",\"url\":\"https://www.semanticscholar.org/paper/be95dc7acb8e31d118f4693af3cc7c62b8f7d5e7\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"Reinier Oves Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"Eduardo F. Morales\"},{\"authorId\":\"144763689\",\"name\":\"Luis Enrique Sucar\"}],\"doi\":\"10.1007/978-3-030-33904-3_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3497d8a0438bd69e857690ed1d60ce32ce8546f8\",\"title\":\"A Novel Scheme for Training Two-Stream CNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3497d8a0438bd69e857690ed1d60ce32ce8546f8\",\"venue\":\"CIARP\",\"year\":2019},{\"arxivId\":\"2007.05840\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1980683\",\"name\":\"S. Aeron\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a2ef52618bc02c12e9edf59088d9fafee829185\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/4a2ef52618bc02c12e9edf59088d9fafee829185\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48021090\",\"name\":\"B. Zhu\"},{\"authorId\":\"50290087\",\"name\":\"T. Li\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-030-31726-3_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46c899e661ed9c0bef182b8019035bf5a68cd61d\",\"title\":\"Exploiting Human Pose for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/46c899e661ed9c0bef182b8019035bf5a68cd61d\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"2010.08841\",\"authors\":[{\"authorId\":\"151478121\",\"name\":\"Soufiane Lamghari\"},{\"authorId\":\"1705256\",\"name\":\"Guillaume-Alexandre Bilodeau\"},{\"authorId\":\"48676026\",\"name\":\"N. Saunier\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f10fd7dd1b93c253b96952c27546709190d157cc\",\"title\":\"A Grid-based Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f10fd7dd1b93c253b96952c27546709190d157cc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"2001.04627\",\"authors\":[{\"authorId\":\"38403207\",\"name\":\"L. Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"title\":\"Hallucinating Statistical Moment and Subspace Descriptors from Object and Saliency Detectors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"title\":\"Part-aligned pose-guided recurrent network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153924558\",\"name\":\"Hsing-Yu Chen\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1007/978-3-030-41299-9_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"title\":\"Group Activity Recognition via Computing Human Pose Motion History and Collective Map from Video\",\"url\":\"https://www.semanticscholar.org/paper/aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144484106\",\"name\":\"J. Darby\"},{\"authorId\":\"145151744\",\"name\":\"Mar\\u00eda B. S\\u00e1nchez\"},{\"authorId\":\"52200111\",\"name\":\"S. Bew\"},{\"authorId\":\"82013125\",\"name\":\"I. D. Loram\"},{\"authorId\":\"144753808\",\"name\":\"P. B. Butler\"}],\"doi\":\"10.1016/j.eswa.2019.112992\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fd38a0bb04327a698b64eb8518d2e4d8c3c3382\",\"title\":\"The development of a video retrieval system using a clinician-led approach\",\"url\":\"https://www.semanticscholar.org/paper/1fd38a0bb04327a698b64eb8518d2e4d8c3c3382\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49494523\",\"name\":\"Ishwar Singh\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"},{\"authorId\":\"35019530\",\"name\":\"M. Greenspan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94e1219f1af29dc2aaf1ea362ed661c7c3fd2a4e\",\"title\":\"Multi-Modal Fusion With Observation Points For Skeleton Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94e1219f1af29dc2aaf1ea362ed661c7c3fd2a4e\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153154393\",\"name\":\"J. Li\"},{\"authorId\":\"3085483\",\"name\":\"S. Xia\"},{\"authorId\":\"153641684\",\"name\":\"Q. Ding\"}],\"doi\":\"10.1145/3372278.3390702\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"98b1c9c1dfe23cf5478f7ff45c641a5576b66107\",\"title\":\"Multi-level Recognition on Falls from Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/98b1c9c1dfe23cf5478f7ff45c641a5576b66107\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CRV.2019.00032\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"title\":\"Two-Stream Action Recognition in Ice Hockey using Player Pose Sequences and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":\"1911.12509\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"title\":\"Action Recognition via Pose-Based Graph Convolutional Networks with Intermediate Dense Supervision\",\"url\":\"https://www.semanticscholar.org/paper/9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.01053\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"title\":\"MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1909.05704\",\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95a2132a20615eeffd34a16fa9fb382c5ad0bbcf\",\"title\":\"Skeleton Image Representation for 3D Action Recognition Based on Tree Structure and Reference Joints\",\"url\":\"https://www.semanticscholar.org/paper/95a2132a20615eeffd34a16fa9fb382c5ad0bbcf\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"73365425\",\"name\":\"Y. Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCV.2019.00015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b76da17a060f1edb80b26f489f4b6256d785c57\",\"title\":\"Hierarchical Self-Attention Network for Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b76da17a060f1edb80b26f489f4b6256d785c57\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153082819\",\"name\":\"Qian Li\"},{\"authorId\":\"1992684694\",\"name\":\"Wenzhu Yang\"},{\"authorId\":\"1992715817\",\"name\":\"Xiangyang Chen\"},{\"authorId\":\"50090639\",\"name\":\"Tongtong Yuan\"},{\"authorId\":null,\"name\":\"Yuxia Wang\"}],\"doi\":\"10.1109/ACCESS.2020.3027386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0475918d855bbfcf4c693359935d9a483b7541ce\",\"title\":\"Temporal Segment Connection Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0475918d855bbfcf4c693359935d9a483b7541ce\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.00832\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"50031872\",\"name\":\"Yunsheng Ma\"},{\"authorId\":\"37989322\",\"name\":\"Y. Gu\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"151185822\",\"name\":\"Runbo Hu\"},{\"authorId\":\"144626314\",\"name\":\"Hua Chai\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1609/AAAI.V34I01.5364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"title\":\"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.12737\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"35663637\",\"name\":\"R. Sanford\"},{\"authorId\":\"145556010\",\"name\":\"M. Javan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"title\":\"Actor-Transformers for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.00745\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"79795951498660c539ff440d2ddcb32f3132b97e\",\"title\":\"Human Action Recognition with Deep Temporal Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/79795951498660c539ff440d2ddcb32f3132b97e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.05349\",\"authors\":[{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"1742208\",\"name\":\"M. Pollefeys\"}],\"doi\":\"10.1109/CVPR.2019.00464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"title\":\"H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5b94a0ecfb144423ca7c5275a31d0d16f99c84d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.05910\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9a9965c013be1269c05a96857c78ad8c87ee517\",\"title\":\"Hallucinating Bag-of-Words and Fisher Vector IDT terms for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9a9965c013be1269c05a96857c78ad8c87ee517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.10024\",\"authors\":[{\"authorId\":\"143884578\",\"name\":\"W. McNally\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"144304939\",\"name\":\"J. McPhee\"}],\"doi\":\"10.1109/CRV.2019.00015\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf3e15a9392621c45da6141a78a60d341ab2e506\",\"title\":\"STAR-Net: Action Recognition using Spatio-Temporal Activation Reprojection\",\"url\":\"https://www.semanticscholar.org/paper/bf3e15a9392621c45da6141a78a60d341ab2e506\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"49901469\",\"name\":\"G. Chen\"},{\"authorId\":\"49750905\",\"name\":\"Chong Chen\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"51470719\",\"name\":\"Xuanlu Xiang\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/ICCVW.2019.00234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a841017d4da8382841d1216ebeed8605bfaafaf\",\"title\":\"Instance-Based Video Search via Multi-Task Retrieval and Re-Ranking\",\"url\":\"https://www.semanticscholar.org/paper/9a841017d4da8382841d1216ebeed8605bfaafaf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"}],\"doi\":\"10.1109/IPAS.2018.8708877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"title\":\"Learning to Represent Spatio-Temporal Features for Fine Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":\"1910.06934\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a89c6d101ece92390b80b6196555fa22de0e458\",\"title\":\"Human Action Recognition with Multi-Laplacian Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3a89c6d101ece92390b80b6196555fa22de0e458\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404304087\",\"name\":\"Salah Al-Obaidi\"},{\"authorId\":\"2034275779\",\"name\":\"Hiba Al-Khafaji\"},{\"authorId\":\"74338570\",\"name\":\"Charith Abhayaratne\"}],\"doi\":\"10.1109/ACCESS.2020.3039740\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"title\":\"Modeling Temporal Visual Salience for Human Action Recognition Enabled Visual Anonymity Preservation\",\"url\":\"https://www.semanticscholar.org/paper/9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Joints\"},{\"authorId\":null,\"name\":\"Sibgrapi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf2aa5b7021ca4d28527c1dd731eac5cc1b925cb\",\"title\":\"Skeleton Image Representation for 3 D Action Recognition based on Tree Structure and Reference\",\"url\":\"https://www.semanticscholar.org/paper/cf2aa5b7021ca4d28527c1dd731eac5cc1b925cb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"2767515\",\"name\":\"Izaro Goienetxea\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"}],\"doi\":\"10.3390/s20082436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"708ef686a14105ba5f1d75d1c5f4db9f96e46c93\",\"title\":\"Shedding Light on People Action Recognition in Social Robotics by Means of Common Spatial Patterns\",\"url\":\"https://www.semanticscholar.org/paper/708ef686a14105ba5f1d75d1c5f4db9f96e46c93\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2004.01225\",\"authors\":[{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":\"10.1109/ICCVW.2019.00164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"title\":\"Temporal Accumulative Features for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2002.11644\",\"authors\":[{\"authorId\":\"1712429\",\"name\":\"Hugo Proen\\u00e7a\"},{\"authorId\":\"1411543040\",\"name\":\"Ehsan Yaghoubi\"},{\"authorId\":\"2145769\",\"name\":\"Pendar Alirezazadeh\"}],\"doi\":\"10.1109/TIFS.2020.3023304\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da94ecc33f8339abb6e1ceb3a17f27f4fcb16211\",\"title\":\"A Quadruplet Loss for Enforcing Semantically Coherent Embeddings in Multi-Output Classification Problems\",\"url\":\"https://www.semanticscholar.org/paper/da94ecc33f8339abb6e1ceb3a17f27f4fcb16211\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":\"2011.07787\",\"authors\":[{\"authorId\":\"81226618\",\"name\":\"Jinmiao Cai\"},{\"authorId\":\"2855391\",\"name\":\"N. Jiang\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49104090\",\"name\":\"Kui Jia\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2664de9388332008077c54278c4f59025dc0bab\",\"title\":\"JOLO-GCN: Mining Joint-Centered Light-Weight Information for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2664de9388332008077c54278c4f59025dc0bab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1007/978-981-15-1816-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c426717bed63d0afdfb16dd98c8cba915f52853\",\"title\":\"Action Recognition in Videos Using Multi-stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c426717bed63d0afdfb16dd98c8cba915f52853\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.00553\",\"authors\":[{\"authorId\":\"1485725797\",\"name\":\"Guoliang Liu\"},{\"authorId\":\"47835373\",\"name\":\"Qinghui Zhang\"},{\"authorId\":\"9310782\",\"name\":\"Y. Cao\"},{\"authorId\":\"46276708\",\"name\":\"Jun-Wei Li\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"153418687\",\"name\":\"Guohui Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0242f0b5b81ed30e404a211ee5664a620122926\",\"title\":\"Memory Group Sampling Based Online Action Recognition Using Kinetic Skeleton Features\",\"url\":\"https://www.semanticscholar.org/paper/b0242f0b5b81ed30e404a211ee5664a620122926\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.09423\",\"authors\":[{\"authorId\":\"31915818\",\"name\":\"D. Torpey\"},{\"authorId\":\"48627696\",\"name\":\"T. \\u00c7elik\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"5e7f485a76d95127158683b7bbe386df98394f42\",\"title\":\"Human Action Recognition using Local Two-Stream Convolution Neural Network Features and Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/5e7f485a76d95127158683b7bbe386df98394f42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.03520\",\"authors\":[{\"authorId\":\"121562147\",\"name\":\"Huy Hieu Pham\"},{\"authorId\":\"1942444\",\"name\":\"H. Salmane\"},{\"authorId\":\"1683263\",\"name\":\"L. Khoudour\"},{\"authorId\":\"1751089\",\"name\":\"A. Crouzil\"},{\"authorId\":\"144919173\",\"name\":\"P. Zegers\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1007/978-3-030-27202-9_2\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eae1b47a635d3cf70e096a95e94765d7b45dcede\",\"title\":\"A Deep Learning Approach for Real-Time 3D Human Action Recognition from Skeletal Data\",\"url\":\"https://www.semanticscholar.org/paper/eae1b47a635d3cf70e096a95e94765d7b45dcede\",\"venue\":\"ICIAR\",\"year\":2019},{\"arxivId\":\"2004.00945\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"151484848\",\"name\":\"Liang Xu\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"1409933106\",\"name\":\"Yue Xu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"48622851\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"title\":\"PaStaNet: Toward Human Activity Knowledge Engine\",\"url\":\"https://www.semanticscholar.org/paper/37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65773211\",\"name\":\"Carlos Ant\\u00f4nio Caetano J\\u00fanior\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"title\":\"Motion-based representations for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.08452\",\"authors\":[{\"authorId\":\"50841913\",\"name\":\"Asif Shahriyar Sushmit\"},{\"authorId\":\"10458138\",\"name\":\"P. Ghosh\"},{\"authorId\":\"1885311407\",\"name\":\"Md.Abrar Istiak\"},{\"authorId\":\"1742267771\",\"name\":\"Nayeeb Rashid\"},{\"authorId\":\"1742267920\",\"name\":\"Ahsan Habib Akash\"},{\"authorId\":\"144782474\",\"name\":\"T. Hasan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"title\":\"SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1452336884\",\"name\":\"Kathan Vyas\"},{\"authorId\":\"144114221\",\"name\":\"R. Ma\"},{\"authorId\":\"3421983\",\"name\":\"Behnaz Rezaei\"},{\"authorId\":\"144369660\",\"name\":\"Shuangjun Liu\"},{\"authorId\":\"145686690\",\"name\":\"Michael Neubauer\"},{\"authorId\":\"2191750\",\"name\":\"T. Pl\\u00f6tz\"},{\"authorId\":\"78362685\",\"name\":\"R. Oberleitner\"},{\"authorId\":\"2225783\",\"name\":\"S. Ostadabbas\"}],\"doi\":\"10.1109/MLSP.2019.8918863\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"39969262668b83d0687bf1624fd4821b604d8080\",\"title\":\"Recognition Of Atypical Behavior In Autism Diagnosis From Video Using Pose Estimation Over Time\",\"url\":\"https://www.semanticscholar.org/paper/39969262668b83d0687bf1624fd4821b604d8080\",\"venue\":\"2019 IEEE 29th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2961531\",\"name\":\"M. Hosseini\"},{\"authorId\":\"145226394\",\"name\":\"F. Ghaderi\"}],\"doi\":\"10.5829/ije.2020.33.05b.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"title\":\"A Hybrid Deep Learning Architecture Using 3D CNNs and GRUs for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.00714\",\"authors\":[{\"authorId\":\"65914312\",\"name\":\"Clebeson Canuto dos Santos\"},{\"authorId\":\"1746258\",\"name\":\"P. Moreno\"},{\"authorId\":\"143622442\",\"name\":\"J. A. Samatelo\"},{\"authorId\":\"21859276\",\"name\":\"Raquel Frizera Vassallo\"},{\"authorId\":\"1398909021\",\"name\":\"J. Santos-Victor\"}],\"doi\":\"10.1016/j.neucom.2020.07.135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5569fdf87bab94014615a04c1ad16204180e7d1\",\"title\":\"Action Anticipation for Collaborative Environments: The Impact of Contextual Information and Uncertainty-Based Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d5569fdf87bab94014615a04c1ad16204180e7d1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2489020\",\"name\":\"Brian Geuther\"},{\"authorId\":\"1995462965\",\"name\":\"Asaf Pe'er\"},{\"authorId\":\"145818206\",\"name\":\"Hao He\"},{\"authorId\":\"71586239\",\"name\":\"G. Sabnis\"},{\"authorId\":\"2264830\",\"name\":\"V. Philip\"},{\"authorId\":\"49533156\",\"name\":\"V. Kumar\"}],\"doi\":\"10.1101/2020.10.08.331017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b63e43d368935fb8657fa0bd800d03b1229485eb\",\"title\":\"Action detection using a neural network elucidates the genetics of mouse grooming behavior\",\"url\":\"https://www.semanticscholar.org/paper/b63e43d368935fb8657fa0bd800d03b1229485eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"1980683\",\"name\":\"Shuchin Aeron\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8c001c449cec20221ba3daa76536a124cddc0e5\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport /Author=Cherian, Anoop; Aeron, Shuchin /CreationDate=July 3, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8c001c449cec20221ba3daa76536a124cddc0e5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"49069045\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/LSP.2019.2923918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"title\":\"Three-Stream Network With Bidirectional Self-Attention for Action Recognition in Extreme Low Resolution Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7360d2f4d84ad6d43090810c9a0a2e0a071027b5\",\"title\":\"MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7360d2f4d84ad6d43090810c9a0a2e0a071027b5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1907.13025\",\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"40603133\",\"name\":\"J. S. Souza\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/AVSS.2019.8909840\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8810ce955198212de0425700285dbe55fc923058\",\"title\":\"SkeleMotion: A New Representation of Skeleton Joint Sequences based on Motion Information for 3D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8810ce955198212de0425700285dbe55fc923058\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216212\",\"name\":\"Vladyslav Sydorov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"32045707a041e18f7afd2b4e7024f9b0dad75890\",\"title\":\"Focused Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32045707a041e18f7afd2b4e7024f9b0dad75890\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145042308\",\"name\":\"U. Iqbal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ea3421243d8edb4fbe8b4962c1566d8b9ce42e1\",\"title\":\"Articulated Human Pose Estimation in Unconstrained Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/6ea3421243d8edb4fbe8b4962c1566d8b9ce42e1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":\"10.1007/s11042-020-08917-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"title\":\"Fine grained sport action recognition with Twin spatio-temporal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327355\",\"name\":\"Trung-Nghia Le\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/WACV.2019.00194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ea69b379c88164d9164ad76c3ce0d148e04ad04\",\"title\":\"Semantic Instance Meets Salient Object: Study on Video Semantic Salient Instance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7ea69b379c88164d9164ad76c3ce0d148e04ad04\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2011.13399\",\"authors\":[{\"authorId\":\"151136071\",\"name\":\"Mattia Segu\"},{\"authorId\":\"1781788981\",\"name\":\"Federico Pirovano\"},{\"authorId\":\"2029237675\",\"name\":\"Gianmario Fumagalli\"},{\"authorId\":\"1557389943\",\"name\":\"Amedeo Fabris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"title\":\"Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal Heatmaps\",\"url\":\"https://www.semanticscholar.org/paper/ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144349170\",\"name\":\"Meet Pandya\"},{\"authorId\":\"1753967\",\"name\":\"A. Pillai\"},{\"authorId\":\"2007484554\",\"name\":\"Himanshu Rupani\"}],\"doi\":\"10.1007/978-981-15-3383-9_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb09c4472916a9385c67c62f82509da877d951b0\",\"title\":\"Segregating and Recognizing Human Actions from Video Footages Using LRCN Technique\",\"url\":\"https://www.semanticscholar.org/paper/fb09c4472916a9385c67c62f82509da877d951b0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40370451\",\"name\":\"H. Kim\"},{\"authorId\":\"10263579\",\"name\":\"Seokmok Park\"},{\"authorId\":\"1820264163\",\"name\":\"Hyeokjin Park\"},{\"authorId\":\"9238090\",\"name\":\"J. Paik\"}],\"doi\":\"10.3390/s20143894\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d76a567188604c227000de1d8e44fe64a176c654\",\"title\":\"Enhanced Action Recognition Using Multiple Stream Deep Learning with Optical Flow and Weighted Sum\",\"url\":\"https://www.semanticscholar.org/paper/d76a567188604c227000de1d8e44fe64a176c654\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47150103\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/WF-IoT48130.2020.9221355\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d69bb85795e1ca9c6354c8537cc96a4361704c87\",\"title\":\"Multipath Event-Based Network for Low-Power Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d69bb85795e1ca9c6354c8537cc96a4361704c87\",\"venue\":\"2020 IEEE 6th World Forum on Internet of Things (WF-IoT)\",\"year\":2020},{\"arxivId\":\"1904.09140\",\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"8045043\",\"name\":\"C. Curio\"}],\"doi\":\"10.1109/ITSC.2019.8917128\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"title\":\"Simple yet efficient real-time pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/978-3-030-49076-8_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c8c96c2395de045227e6c1165bd8f0886b08536\",\"title\":\"What the Appearance Channel from Two-Stream Architectures for Activity Recognition Is Learning?\",\"url\":\"https://www.semanticscholar.org/paper/5c8c96c2395de045227e6c1165bd8f0886b08536\",\"venue\":\"MCPR\",\"year\":2020},{\"arxivId\":\"2010.03497\",\"authors\":[{\"authorId\":\"6917558\",\"name\":\"Daniel Deniz\"},{\"authorId\":\"144484799\",\"name\":\"F. Barranco\"},{\"authorId\":\"103939214\",\"name\":\"J. Isern\"},{\"authorId\":\"32132184\",\"name\":\"E. Ros\"}],\"doi\":\"10.1109/ETFA46521.2020.9211910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92594b024a19bc5cb3e38984c864e1653179db8f\",\"title\":\"Reconfigurable Cyber-Physical System for Lifestyle Video-Monitoring via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/92594b024a19bc5cb3e38984c864e1653179db8f\",\"venue\":\"2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403026588\",\"name\":\"Pau Climent-P\\u00e9rez\"},{\"authorId\":\"1699905\",\"name\":\"S. Spinsante\"},{\"authorId\":\"2338883\",\"name\":\"A. Mihailidis\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.1016/J.ESWA.2019.112847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"title\":\"A review on video-based active and assisted living technologies for automated lifelogging\",\"url\":\"https://www.semanticscholar.org/paper/516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003284138\",\"name\":\"Simkanic Radek\"}],\"doi\":\"10.1109/ICIP40778.2020.9191009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"453e06c572791e18323c111bf95e2175ea4951dd\",\"title\":\"Skeleton Action Recognition Based on Singular Value Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/453e06c572791e18323c111bf95e2175ea4951dd\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"48278763\",\"name\":\"J. Morlier\"}],\"doi\":\"10.1109/ICIP.2019.8803780\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3eb7533610afea095afd443bac0d20565d6a66df\",\"title\":\"Optimal Choice of Motion Estimation Methods for Fine-Grained Action Classification with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3eb7533610afea095afd443bac0d20565d6a66df\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2008.05717\",\"authors\":[{\"authorId\":\"50180715\",\"name\":\"Xixia Xu\"},{\"authorId\":\"1380876608\",\"name\":\"Qi Zou\"},{\"authorId\":\"1662772707\",\"name\":\"Xue Lin\"}],\"doi\":\"10.1145/3394171.3414040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5bf90e79c2b28caf5f9dd2b39af182b385ed74a\",\"title\":\"Alleviating Human-level Shift: A Robust Domain Adaptation Method for Multi-person Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/e5bf90e79c2b28caf5f9dd2b39af182b385ed74a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682261\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e133e8cf792334969365ff7746ebed7b98fce702\",\"title\":\"Boundary Information Matters More: Accurate Temporal Action Detection with Temporal Boundary Network\",\"url\":\"https://www.semanticscholar.org/paper/e133e8cf792334969365ff7746ebed7b98fce702\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1907.09658\",\"authors\":[{\"authorId\":\"145338228\",\"name\":\"Fan Yang\"},{\"authorId\":\"1783949\",\"name\":\"Sakriani Sakti\"},{\"authorId\":\"145175309\",\"name\":\"Y. Wu\"},{\"authorId\":\"145223960\",\"name\":\"S. Nakamura\"}],\"doi\":\"10.1145/3338533.3366569\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a94e1b573836ab358845fea8faf93b15671fdc69\",\"title\":\"Make Skeleton-based Action Recognition Model Smaller, Faster and Better\",\"url\":\"https://www.semanticscholar.org/paper/a94e1b573836ab358845fea8faf93b15671fdc69\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICASSP.2019.8683035\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"52373cd152e2afdc7e8c75025b2c9a02509bb2c1\",\"title\":\"Deep Temporal Pyramid Design for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/52373cd152e2afdc7e8c75025b2c9a02509bb2c1\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1904.04868\",\"authors\":[{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"97f1676e20d232d106d71b6007e4b4284a22699d\",\"title\":\"Back to the Future: Knowledge Distillation for Human Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/97f1676e20d232d106d71b6007e4b4284a22699d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780440\",\"name\":\"Yadong Pan\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"}],\"doi\":\"10.1007/978-3-030-41404-7_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8790fa4fda5c690856462cc96c23d0ad7686862d\",\"title\":\"Multi-person Pose Estimation with Mid-Points for Human Detection under Real-World Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/8790fa4fda5c690856462cc96c23d0ad7686862d\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8702449\",\"name\":\"Wanneng Wang\"},{\"authorId\":\"47009814\",\"name\":\"Yanan Ma\"},{\"authorId\":\"144947764\",\"name\":\"Ke Gao\"},{\"authorId\":\"152813130\",\"name\":\"J. Cao\"}],\"doi\":\"10.1145/3343031.3350884\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0be689463698d92433b4fd343379a32e763c9f2c\",\"title\":\"Cost-free Transfer Learning Mechanism: Deep Digging Relationships of Action Categories\",\"url\":\"https://www.semanticscholar.org/paper/0be689463698d92433b4fd343379a32e763c9f2c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66148232\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":\"10.1109/ICCV.2019.00879\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70660cb3af4e19c74681238c7854e3d341654b2d\",\"title\":\"Hallucinating IDT Descriptors and I3D Optical Flow Features for Action Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/70660cb3af4e19c74681238c7854e3d341654b2d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780440\",\"name\":\"Yadong Pan\"},{\"authorId\":\"49621610\",\"name\":\"Ryo Kawai\"},{\"authorId\":\"1753594859\",\"name\":\"Noboru Yoshida\"},{\"authorId\":\"47969470\",\"name\":\"Hiroo Ikeda\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"}],\"doi\":\"10.1007/s42979-020-00217-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60f65cfa28baec240b3d63e9e88272a768327d64\",\"title\":\"Training Physical and Geometrical Mid-Points for Multi-person Pose Estimation and Human Detection Under Congestion and Low Resolution\",\"url\":\"https://www.semanticscholar.org/paper/60f65cfa28baec240b3d63e9e88272a768327d64\",\"venue\":\"SN Comput. Sci.\",\"year\":2020}],\"corpusId\":21660432,\"doi\":\"10.1109/CVPR.2018.00734\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":19,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"references\":[{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2676982\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"2133988\",\"name\":\"S. Zuffi\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/ICCV.2013.396\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"title\":\"Towards Understanding Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cee43afc7aad6a8f7c4a6d566b60ebc79d57e7a\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1603.06937\",\"authors\":[{\"authorId\":\"31688710\",\"name\":\"Alejandro Newell\"},{\"authorId\":\"34284131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1007/978-3-319-46484-8_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"848938e6199bad08f1db6f3239b260cfa901e95f\",\"title\":\"Stacked Hourglass Networks for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/848938e6199bad08f1db6f3239b260cfa901e95f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34792176\",\"name\":\"Xiaohan Nie\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2015.7298734\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb4291452a25ff2f84f5af6de36b04c1d4d81b12\",\"title\":\"Joint action recognition and pose estimation from video\",\"url\":\"https://www.semanticscholar.org/paper/bb4291452a25ff2f84f5af6de36b04c1d4d81b12\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1812.08008\",\"authors\":[{\"authorId\":\"47060433\",\"name\":\"Zhe Cao\"},{\"authorId\":\"2915997\",\"name\":\"T. \\u0160imon\"},{\"authorId\":\"2797981\",\"name\":\"Shih-En Wei\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1109/CVPR.2017.143\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e8db1519245426f3a78752a3d8360484f4626b1\",\"title\":\"Realtime Multi-person 2D Pose Estimation Using Part Affinity Fields\",\"url\":\"https://www.semanticscholar.org/paper/9e8db1519245426f3a78752a3d8360484f4626b1\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/ICCV.2017.402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a470a81f989d5354239f1044c90e07b78c6beed7\",\"title\":\"RPAN: An End-to-End Recurrent Pose-Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a470a81f989d5354239f1044c90e07b78c6beed7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1701.05384\",\"authors\":[{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2017.228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a76dc85d8c458eebdffa87c64233d1345163478\",\"title\":\"FusionSeg: Learning to Combine Motion and Appearance for Fully Automatic Segmentation of Generic Objects in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a76dc85d8c458eebdffa87c64233d1345163478\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.01861\",\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2017.472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"title\":\"Action Tubelet Detector for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/8dea2081609d838dc5b5a929f2ac19ce0c41c9a0\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.03958\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"143887468\",\"name\":\"Kevin Chen\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/ICCV.2017.236\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"title\":\"Lattice Long Short-Term Memory for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f22d6d59e413ee255e5e0f2104f1e03be1a6722e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121900578\",\"name\":\"Chunyu Wang\"},{\"authorId\":\"1717863\",\"name\":\"Yizhou Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2013.123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21258b55048a5038e3f6167b03e4fa2314ecf628\",\"title\":\"An Approach to Pose-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21258b55048a5038e3f6167b03e4fa2314ecf628\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1604.02808\",\"authors\":[{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"2475944\",\"name\":\"Tian-Tsong Ng\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2016.115\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"title\":\"NTU RGB+D: A Large Scale Dataset for 3D Human Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/091e4d3c85dc0a8212afea875cd3b162d273d46b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1607.07043\",\"authors\":[{\"authorId\":\"40940512\",\"name\":\"Jun Liu\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-319-46487-9_50\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9afbd70a4727df98a0c38c437b94b14eba6577c4\",\"title\":\"Spatio-Temporal LSTM with Trust Gates for 3D Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9afbd70a4727df98a0c38c437b94b14eba6577c4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2017.64\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3142b34fdf09379d231f2d78c85dfa5e6e16b89a\",\"title\":\"Learning Motion Patterns in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3142b34fdf09379d231f2d78c85dfa5e6e16b89a\",\"venue\":\"CVPR\",\"year\":2017},{\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2017.168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"title\":\"Deep Temporal Linear Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3201156\",\"name\":\"Congqi Cao\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"1713887\",\"name\":\"C. Zhang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f66086e4cbb22c5736c836614830489f9594b91\",\"title\":\"Action Recognition with Joints-Pooled 3D Deep Convolutional Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2f66086e4cbb22c5736c836614830489f9594b91\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":\"1704.00616\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"144590074\",\"name\":\"Gabriel L. Oliveira\"},{\"authorId\":\"31656404\",\"name\":\"N. Sedaghat\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2017.316\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eac1b644492c10546a50f3e125a1f790ec46365f\",\"title\":\"Chained Multi-stream Networks Exploiting Pose, Motion, and Appearance for Action Classification and Detection\",\"url\":\"https://www.semanticscholar.org/paper/eac1b644492c10546a50f3e125a1f790ec46365f\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1506.03607\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.368\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4697681079de557cc04e209762b1a4c1eaae709\",\"title\":\"P-CNN: Pose-Based CNN Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c4697681079de557cc04e209762b1a4c1eaae709\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49963740\",\"name\":\"Y. Du\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2015.7298714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1839e17555160bd897b978c48b8ebd13dd21445f\",\"title\":\"Hierarchical recurrent neural network for skeleton based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1839e17555160bd897b978c48b8ebd13dd21445f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"topics\":[{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Heat map\",\"topicId\":\"208268\",\"url\":\"https://www.semanticscholar.org/topic/208268\"},{\"topic\":\"Human Metabolome Database\",\"topicId\":\"214982\",\"url\":\"https://www.semanticscholar.org/topic/214982\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Bootstrap aggregating\",\"topicId\":\"166813\",\"url\":\"https://www.semanticscholar.org/topic/166813\"},{\"topic\":\"Allegro\",\"topicId\":\"876926\",\"url\":\"https://www.semanticscholar.org/topic/876926\"}],\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"