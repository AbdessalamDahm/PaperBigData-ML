"{\"abstract\":\"A key solution to visual question answering (VQA) exists in how to fuse visual and language features extracted from an input image and question. We show that an attention mechanism that enables dense, bi-directional interactions between the two modalities contributes to boost accuracy of prediction of answers. Specifically, we present a simple architecture that is fully symmetric between visual and language representations, in which each question word attends on image regions and each image region attends on question words. It can be stacked to form a hierarchy for multi-step interactions between an image-question pair. We show through experiments that the proposed architecture achieves a new state-of-the-art on VQA and VQA 2.0 despite its small size. We also present qualitative evaluation, demonstrating how the proposed attention mechanism can generate reasonable attention maps on images and questions, which leads to the correct answer prediction.\",\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\",\"url\":\"https://www.semanticscholar.org/author/41022273\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\",\"url\":\"https://www.semanticscholar.org/author/1718872\"}],\"citationVelocity\":33,\"citations\":[{\"arxivId\":\"1904.09073\",\"authors\":[{\"authorId\":\"49869982\",\"name\":\"J. Kruk\"},{\"authorId\":\"104128958\",\"name\":\"Jonah Lubin\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.18653/v1/D19-1469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75e40feb1d09c9bcfe8e6b080f40e6a6ffd03800\",\"title\":\"Integrating Text and Image: Determining Multimodal Document Intent in Instagram Posts\",\"url\":\"https://www.semanticscholar.org/paper/75e40feb1d09c9bcfe8e6b080f40e6a6ffd03800\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"48696362\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894845\",\"name\":\"Fei Wu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3394171.3413745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"title\":\"Photo Stream Question Answer\",\"url\":\"https://www.semanticscholar.org/paper/a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.06581\",\"authors\":[{\"authorId\":\"1826395\",\"name\":\"Bin Duan\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"91913011\",\"name\":\"Wei Wang\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":null,\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"title\":\"Audio-Visual Event Localization via Recursive Fusion by Joint Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.07493\",\"authors\":[{\"authorId\":\"144992211\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"1681799\",\"name\":\"Verena Rieser\"}],\"doi\":\"10.18653/v1/2020.acl-main.728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c3baa99376fac050160c25a9c6d92d9baa5846c\",\"title\":\"History for Visual Dialog: Do we really need it?\",\"url\":\"https://www.semanticscholar.org/paper/8c3baa99376fac050160c25a9c6d92d9baa5846c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1904.03000\",\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"144306299\",\"name\":\"C. Grund\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00779\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7b36024652d99cdf1f75a1daa891729ef0aa0cb\",\"title\":\"What Object Should I Use? - Task Driven Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/e7b36024652d99cdf1f75a1daa891729ef0aa0cb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145764583\",\"name\":\"F. Liu\"},{\"authorId\":\"40628473\",\"name\":\"Jing Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2019/122\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"title\":\"Densely Connected Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99dc8f4c6be75b32a584608cea2c0da0de47db8d\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"153043900\",\"name\":\"Zhi-Ping Zhou\"}],\"doi\":\"10.1145/3366194.3366252\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1b51243d3612e18dd804b727d78b24fc6fb6dc3\",\"title\":\"Visual Question Answering with Dynamic Parameter Prediction using Functional Hashing\",\"url\":\"https://www.semanticscholar.org/paper/a1b51243d3612e18dd804b727d78b24fc6fb6dc3\",\"venue\":\"RICAI 2019\",\"year\":2019},{\"arxivId\":\"2001.06810\",\"authors\":[{\"authorId\":\"50085218\",\"name\":\"Xiankai Lu\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2019.00374\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e54fe27ed18d513e3e9171661bd9b6e1c982b7d5\",\"title\":\"See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/e54fe27ed18d513e3e9171661bd9b6e1c982b7d5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47955591\",\"name\":\"Shuang Liu\"},{\"authorId\":\"9091950\",\"name\":\"Linlin Duan\"},{\"authorId\":\"98457362\",\"name\":\"Zhong Zhang\"},{\"authorId\":\"2393269\",\"name\":\"Xiaozhong Cao\"}],\"doi\":\"10.1109/ACCESS.2019.2926092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"180db7e769401d15d3897b128a4e0c81fb3011fc\",\"title\":\"Hierarchical Multimodal Fusion for Ground-Based Cloud Classification in Weather Station Networks\",\"url\":\"https://www.semanticscholar.org/paper/180db7e769401d15d3897b128a4e0c81fb3011fc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314993\",\"name\":\"Wei-ying Wang\"},{\"authorId\":\"1994473516\",\"name\":\"Jieting Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413890\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b116c8cd44a34f440f260a890e0600b61d92c262\",\"title\":\"VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generation\",\"url\":\"https://www.semanticscholar.org/paper/b116c8cd44a34f440f260a890e0600b61d92c262\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2011.09315\",\"authors\":[{\"authorId\":\"2026322565\",\"name\":\"Minghang Zheng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47866340\",\"name\":\"Hao Dong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7019995948c0a2127501f24ee9632904466d7913\",\"title\":\"End-to-End Object Detection with Adaptive Clustering Transformer\",\"url\":\"https://www.semanticscholar.org/paper/7019995948c0a2127501f24ee9632904466d7913\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144095952\",\"name\":\"H. Li\"},{\"authorId\":\"143914849\",\"name\":\"Y. Xue\"},{\"authorId\":\"1390716980\",\"name\":\"Hongya Zhao\"},{\"authorId\":\"47027378\",\"name\":\"X. Hu\"},{\"authorId\":\"2038469\",\"name\":\"S. Peng\"}],\"doi\":\"10.1007/978-3-030-32236-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1470650f28ccde28a89db89d17addc10b6306338\",\"title\":\"Co-attention Networks for Aspect-Level Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1470650f28ccde28a89db89d17addc10b6306338\",\"venue\":\"NLPCC\",\"year\":2019},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"48079221\",\"name\":\"Sungho Park\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1016/j.neucom.2020.03.098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e48298519b5ff583e585a65eeea3ac10556adf\",\"title\":\"Selective residual learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e48298519b5ff583e585a65eeea3ac10556adf\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1907.00661\",\"authors\":[{\"authorId\":\"32185652\",\"name\":\"Yusuke Yamaura\"},{\"authorId\":\"150246288\",\"name\":\"Nobuya Kanemaki\"},{\"authorId\":\"3184895\",\"name\":\"Yukihiro Tsuboshita\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75952cb7d5945d001d0758a994eb8017ddca3733\",\"title\":\"The Resale Price Prediction of Secondhand Jewelry Items Using a Multi-modal Deep Model with Iterative Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/75952cb7d5945d001d0758a994eb8017ddca3733\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50096204\",\"name\":\"Chunlin Wang\"},{\"authorId\":\"1706546\",\"name\":\"J. Sun\"},{\"authorId\":\"46772675\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3318299.3318305\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f0a08e6485fefab90fc7c56a3ebbf4409c93022\",\"title\":\"Feature Fusion Attention Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7f0a08e6485fefab90fc7c56a3ebbf4409c93022\",\"venue\":\"ICMLC '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8168419\",\"name\":\"Tsun-Yi Yang\"},{\"authorId\":\"73365400\",\"name\":\"Y. Chen\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1109/CVPR.2019.00118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30732c0146c69306a4b62bb0ce6564d7ea4d1c71\",\"title\":\"FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation From a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/30732c0146c69306a4b62bb0ce6564d7ea4d1c71\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.00733\",\"authors\":[{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"40134540\",\"name\":\"X. Liu\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.00925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4e6b18b5573329a5b62f297f6ab9565f841e11b\",\"title\":\"Attention-Based Adaptive Selection of Operations for Image Restoration in the Presence of Unknown Combined Distortions\",\"url\":\"https://www.semanticscholar.org/paper/c4e6b18b5573329a5b62f297f6ab9565f841e11b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11611009\",\"name\":\"Chun-ye Li\"},{\"authorId\":\"8756547\",\"name\":\"Liya Kong\"},{\"authorId\":\"153043900\",\"name\":\"Zhi-Ping Zhou\"}],\"doi\":\"10.1016/j.jvcir.2020.102956\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32a9b74561ee7c7b2d9663248b515168676d9321\",\"title\":\"Improved-StoryGAN for sequential images visualization\",\"url\":\"https://www.semanticscholar.org/paper/32a9b74561ee7c7b2d9663248b515168676d9321\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1908.04107\",\"authors\":[{\"authorId\":\"23165772\",\"name\":\"Z. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"title\":\"Multimodal Unified Attention Networks for Vision-and-Language Interactions\",\"url\":\"https://www.semanticscholar.org/paper/a3d3df29fc98e0d674bf02bab69726795f4c7b78\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.04557\",\"authors\":[{\"authorId\":\"47798280\",\"name\":\"T. Ogura\"},{\"authorId\":\"31428186\",\"name\":\"A. Magassouba\"},{\"authorId\":\"2332462\",\"name\":\"K. Sugiura\"},{\"authorId\":\"134790239\",\"name\":\"Tsubasa Hirakawa\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"1687968\",\"name\":\"H. Fujiyoshi\"},{\"authorId\":\"153476449\",\"name\":\"H. Kawai\"}],\"doi\":\"10.1109/lra.2020.3010735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8665698dd9c9093f03d3d672454ae4db33d381ef\",\"title\":\"Alleviating the Burden of Labeling: Sentence Generation by Attention Branch Encoder\\u2013Decoder Network\",\"url\":\"https://www.semanticscholar.org/paper/8665698dd9c9093f03d3d672454ae4db33d381ef\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2006.14264\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58adf956dfd71a756b8f98b726fdcd8e2552445\",\"title\":\"Self-Segregating and Coordinated-Segregating Transformer for Focused Deep Multi-Modular Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b58adf956dfd71a756b8f98b726fdcd8e2552445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32543309\",\"name\":\"Tianling Jiang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"49046633\",\"name\":\"Chunping Liu\"},{\"authorId\":\"21633777\",\"name\":\"Hailin Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78c2f7520becde5e3bcd9b952791d67c33a48612\",\"title\":\"Visual-Textual Alignment for Graph Inference in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/78c2f7520becde5e3bcd9b952791d67c33a48612\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1910.03230\",\"authors\":[{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"153731335\",\"name\":\"Zhe Gan\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"152876475\",\"name\":\"William W. J. Wang\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0bbae624efbfeee01bd38185c6d754c08417de7\",\"title\":\"Meta Module Network for Compositional Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/d0bbae624efbfeee01bd38185c6d754c08417de7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"48567083\",\"name\":\"Zheng Yu\"},{\"authorId\":\"3116943\",\"name\":\"Jiange Liu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190828\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"316f057e36cf432ece4ba4e2d167a84aef700aee\",\"title\":\"VC-VQA: Visual Calibration Mechanism For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/316f057e36cf432ece4ba4e2d167a84aef700aee\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9254311\",\"name\":\"Yuansheng Song\"},{\"authorId\":\"2110377\",\"name\":\"Ping Jian\"}],\"doi\":\"10.1007/978-3-030-60450-9_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a81751ea4350cd67f9bd1d81b9410c64c22527e\",\"title\":\"Deep Hierarchical Attention Flow for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/5a81751ea4350cd67f9bd1d81b9410c64c22527e\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1808.09648\",\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"title\":\"From VQA to Multimodal CQA: Adapting Visual QA Models for Community QA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.00500\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.01074\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"title\":\"Multi-Task Learning of Hierarchical Vision-Language Representation\",\"url\":\"https://www.semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1508389232\",\"name\":\"Junyi Feng\"},{\"authorId\":\"145197100\",\"name\":\"P. Gong\"},{\"authorId\":\"1508486471\",\"name\":\"Guanghui Qiu\"}],\"doi\":\"10.1145/3376067.3376082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"732af43dac39f3ed15a43ab916eabb80dd67e72a\",\"title\":\"MDAnet: Multiple Fusion Network with Double Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/732af43dac39f3ed15a43ab916eabb80dd67e72a\",\"venue\":\"ICVIP\",\"year\":2019},{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8536519\",\"name\":\"Eunsol Kim\"},{\"authorId\":\"21152168\",\"name\":\"Woo Young Kang\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1888f86aa78a2a538ad68a8bba1dd6b01492c77\",\"title\":\"Hypergraph Attention Networks for Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/d1888f86aa78a2a538ad68a8bba1dd6b01492c77\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1903.00839\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"50218594\",\"name\":\"Z. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/CVPR.2019.00205\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"title\":\"Improving Referring Expression Grounding With Cross-Modal Attention-Guided Erasing\",\"url\":\"https://www.semanticscholar.org/paper/cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103567595\",\"name\":\"Shayan Hassantabar\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"880760777e3671593ba50b7a17b0d30b655fc86d\",\"title\":\"Visual Question Answering : Datasets , Methods , Challenges and Oppurtunities\",\"url\":\"https://www.semanticscholar.org/paper/880760777e3671593ba50b7a17b0d30b655fc86d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49039449\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1703234\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TMM.2020.2972830\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"title\":\"Reasoning on the Relation: Enhancing Visual Representation for Visual Question Answering and Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2009.11118\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"47787551\",\"name\":\"Binh X. Nguyen\"},{\"authorId\":\"1981175\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"31534280\",\"name\":\"Q. D. Tran\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30173e8b551c0655e2036aba7fedf354f1ef5658\",\"title\":\"Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/30173e8b551c0655e2036aba7fedf354f1ef5658\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.10675\",\"authors\":[{\"authorId\":\"31428186\",\"name\":\"A. Magassouba\"},{\"authorId\":\"2332462\",\"name\":\"K. Sugiura\"},{\"authorId\":\"153476449\",\"name\":\"H. Kawai\"}],\"doi\":\"10.1109/LRA.2019.2963649\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a191be5a2d986ed2e1df0e38a6651dee4aa1b0f6\",\"title\":\"A Multimodal Target-Source Classifier With Attention Branches to Understand Ambiguous Instructions for Fetching Daily Objects\",\"url\":\"https://www.semanticscholar.org/paper/a191be5a2d986ed2e1df0e38a6651dee4aa1b0f6\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144454465\",\"name\":\"L. Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"153028349\",\"name\":\"Xiao Wu\"},{\"authorId\":\"83672162\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3343031.3350925\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"title\":\"CRA-Net: Composed Relation Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50031180\",\"name\":\"Xiaofeng Yang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"2753987\",\"name\":\"Fengmao Lv\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"}],\"doi\":\"10.1007/978-3-030-58589-1_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"title\":\"TRRNet: Tiered Relation Reasoning for Compositional Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef765e3e0b7a2a0fc90322c13658480d2b1cb4d9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50580169\",\"name\":\"Y. Chen\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"}],\"doi\":\"10.1109/CVPR42600.2020.00307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78f69364531794550130389342b7bc0ff785b7e9\",\"title\":\"Image Search With Text Feedback by Visiolinguistic Attention Learning\",\"url\":\"https://www.semanticscholar.org/paper/78f69364531794550130389342b7bc0ff785b7e9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.08909\",\"authors\":[{\"authorId\":\"1688272723\",\"name\":\"Guangshuai Gao\"},{\"authorId\":\"2954369\",\"name\":\"W. Zhao\"},{\"authorId\":\"150270468\",\"name\":\"Qingjie Liu\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"}],\"doi\":\"10.1109/tcsvt.2020.2992054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97d45c4f4a24382da56997e1814223777fd02bc3\",\"title\":\"Co-Saliency Detection with Co-Attention Fully Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/97d45c4f4a24382da56997e1814223777fd02bc3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93762952\",\"name\":\"W. Li\"},{\"authorId\":\"1423419337\",\"name\":\"Jianhui Sun\"},{\"authorId\":\"48574046\",\"name\":\"Ge Liu\"},{\"authorId\":\"1657444300\",\"name\":\"Linglan Zhao\"},{\"authorId\":\"35680253\",\"name\":\"Xiangzhong Fang\"}],\"doi\":\"10.1016/j.patrec.2020.02.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"471e503f93c86b9c99e34d0f175b69f1db77f395\",\"title\":\"Visual question answering with attention transfer and a cross-modal gating mechanism\",\"url\":\"https://www.semanticscholar.org/paper/471e503f93c86b9c99e34d0f175b69f1db77f395\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"title\":\"Erasing-based Attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6834deeabfbc3ca5989ca7a3bd76dc5a84c5a346\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1908.04289\",\"authors\":[{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"3152448\",\"name\":\"Zhanpeng Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2019.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"title\":\"Multi-Modality Latent Interaction Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf5a0d3b67cf03c2441f7aa20f0ea499bd02acf6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":\"10.1145/3357384.3358000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"title\":\"Adapting Visual Question Answering Models for Enhancing Multimodal Community Q&A Platforms\",\"url\":\"https://www.semanticscholar.org/paper/6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.09796\",\"authors\":[{\"authorId\":\"145868671\",\"name\":\"M. Crawshaw\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"title\":\"Multi-Task Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/74f23063ca77f5b1caa3770a5957ae5fc565843e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"title\":\"Learnable Aggregating Net with Diversity Learning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47540106\",\"name\":\"J. Zhang\"},{\"authorId\":\"50828249\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1016/j.ipm.2019.102152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ff7b42d8cc37acfc08210cff20983090a968308\",\"title\":\"Multi-Modal fusion with multi-level attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2ff7b42d8cc37acfc08210cff20983090a968308\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144544920\",\"name\":\"Fei Liu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/ICIP.2019.8803670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd71651126f11162d262ff0dcb9ae094f51dcffd\",\"title\":\"Language and Visual Relations Encoding for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cd71651126f11162d262ff0dcb9ae094f51dcffd\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500535053\",\"name\":\"Huiwei Jiang\"},{\"authorId\":\"3213624\",\"name\":\"Xiangyun Hu\"},{\"authorId\":\"50754193\",\"name\":\"K. Li\"},{\"authorId\":\"49050912\",\"name\":\"J. Zhang\"},{\"authorId\":\"107584502\",\"name\":\"Jinqi Gong\"},{\"authorId\":\"1490738742\",\"name\":\"Mi Zhang\"}],\"doi\":\"10.3390/rs12030484\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1ada1c7ef5595d0b044e109a2723c40abd23122\",\"title\":\"PGA-SiamNet: Pyramid Feature-Based Attention-Guided Siamese Network for Remote Sensing Orthoimagery Building Change Detection\",\"url\":\"https://www.semanticscholar.org/paper/f1ada1c7ef5595d0b044e109a2723c40abd23122\",\"venue\":\"Remote. Sens.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1609/AAAI.V33I01.33016391\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"524879e9a072489110e9578cf2689e50c5531f05\",\"title\":\"Structured Two-Stream Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/524879e9a072489110e9578cf2689e50c5531f05\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2002.06800\",\"authors\":[{\"authorId\":\"9208016\",\"name\":\"Aakansha Mishra\"},{\"authorId\":\"47583423\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206913\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"title\":\"CQ-VQA: Visual Question Answering on Categorized Questions\",\"url\":\"https://www.semanticscholar.org/paper/212c2d71f9f404bcbb3cfe8bc35e5e1ea25076c5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2008.09105\",\"authors\":[{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V34I07.6737\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"title\":\"Location-Aware Graph Convolutional Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.01947\",\"authors\":[{\"authorId\":\"15839174\",\"name\":\"G. Sun\"},{\"authorId\":\"2358864\",\"name\":\"W. Wang\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58536-5_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415a1db8bc9a92342c4b0f4ad150692e3766dab2\",\"title\":\"Mining Cross-Image Semantics for Weakly Supervised Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/415a1db8bc9a92342c4b0f4ad150692e3766dab2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6578200\",\"name\":\"Shiling Jiang\"},{\"authorId\":\"1405875318\",\"name\":\"Ming Ma\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"3417894\",\"name\":\"W. Deng\"},{\"authorId\":\"148123516\",\"name\":\"Siyu Ren\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"}],\"doi\":\"10.1007/978-3-030-31654-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87045ac2a065b14a3f6608ac9147fa81b89aa4fb\",\"title\":\"Semantic Reanalysis of Scene Words in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87045ac2a065b14a3f6608ac9147fa81b89aa4fb\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"2008.06914\",\"authors\":[{\"authorId\":\"14488816\",\"name\":\"Libo Qin\"},{\"authorId\":\"2256319\",\"name\":\"W. Che\"},{\"authorId\":\"48514481\",\"name\":\"Yangming Li\"},{\"authorId\":\"1576502392\",\"name\":\"Minheng Ni\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"}],\"doi\":\"10.1609/AAAI.V34I05.6391\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5c7f47daa7013a153a67e90cec6ff01ea4cd8d\",\"title\":\"DCR-Net: A Deep Co-Interactive Relation Network for Joint Dialog Act Recognition and Sentiment Classification\",\"url\":\"https://www.semanticscholar.org/paper/5c5c7f47daa7013a153a67e90cec6ff01ea4cd8d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.11883\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c7faa44bde54f017e164ad8e687bd1963005988\",\"title\":\"Revisiting Modulated Convolutions for Visual Counting and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/6c7faa44bde54f017e164ad8e687bd1963005988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.02164\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1387254703\",\"name\":\"Giuseppe Carenini\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"title\":\"An Improved Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"153028537\",\"name\":\"X. Wu\"},{\"authorId\":\"36263371\",\"name\":\"Shen Ge\"},{\"authorId\":\"93249636\",\"name\":\"W. Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1609/AAAI.V34I07.6824\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"title\":\"Federated Learning for Vision-and-Language Grounding Problems\",\"url\":\"https://www.semanticscholar.org/paper/d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1911.02739\",\"authors\":[{\"authorId\":\"72871419\",\"name\":\"Zhihan Zhang\"},{\"authorId\":\"1770874\",\"name\":\"Zhiyi Yin\"},{\"authorId\":\"1906099\",\"name\":\"Shuhuai Ren\"},{\"authorId\":\"78145275\",\"name\":\"Xinhang Li\"},{\"authorId\":\"50341802\",\"name\":\"S. Li\"}],\"doi\":\"10.1007/978-3-030-60457-8_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"422f098e1e5b6fa34e73ad83557ba793ca3c0403\",\"title\":\"DCA: Diversified Co-Attention towards Informative Live Video Commenting\",\"url\":\"https://www.semanticscholar.org/paper/422f098e1e5b6fa34e73ad83557ba793ca3c0403\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1810.03821\",\"authors\":[{\"authorId\":\"36251013\",\"name\":\"Wei Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09bb33837609afd9f90a9ba418ca3550926e8495\",\"title\":\"Knowing Where to Look? Analysis on Attention of Visual Question Answering System\",\"url\":\"https://www.semanticscholar.org/paper/09bb33837609afd9f90a9ba418ca3550926e8495\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"title\":\"Efficient Attention Mechanism for Handling All the Interactions between Many Inputs with Application to Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144493079\",\"name\":\"Z. Hu\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1904290800\",\"name\":\"Hanyu Liang\"},{\"authorId\":\"1908173213\",\"name\":\"Xingmao Zhang\"},{\"authorId\":\"1901543027\",\"name\":\"Qingguang Liu\"}],\"doi\":\"10.1109/DSC50466.2020.00040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"title\":\"Graph Convolutional Network for Visual Question Answering Based on Fine-grained Question Representation\",\"url\":\"https://www.semanticscholar.org/paper/2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"venue\":\"2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)\",\"year\":2020},{\"arxivId\":\"2007.13135\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"47527626\",\"name\":\"Peng Su\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"title\":\"Contrastive Visual-Linguistic Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/71ff8e0194d1cc4f810f825a569263fea4056ecd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1725408802\",\"name\":\"Meng Cao\"},{\"authorId\":\"48270171\",\"name\":\"Y. Zhu\"},{\"authorId\":\"49896351\",\"name\":\"Wenjing Gao\"},{\"authorId\":\"47629198\",\"name\":\"Mengyao Li\"},{\"authorId\":\"1741081423\",\"name\":\"Shaoxiu Wang\"}],\"doi\":\"10.1002/cpe.5954\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc3b95a6fea7bd7c5c424e60463fbca57dae6a7d\",\"title\":\"Various syncretic co\\u2010attention network for multimodal sentiment analysis\",\"url\":\"https://www.semanticscholar.org/paper/fc3b95a6fea7bd7c5c424e60463fbca57dae6a7d\",\"venue\":\"Concurr. Comput. Pract. Exp.\",\"year\":2020},{\"arxivId\":\"2008.00397\",\"authors\":[{\"authorId\":\"51115516\",\"name\":\"L. Yang\"},{\"authorId\":\"49435166\",\"name\":\"Fanqi Meng\"},{\"authorId\":\"31395194\",\"name\":\"Ming-Kuang Daniel Wu\"},{\"authorId\":\"1850625173\",\"name\":\"Vicent Ying\"},{\"authorId\":\"150345115\",\"name\":\"Xianchao Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c711f0b0f9e214d6ee462cffcac733221bf07026\",\"title\":\"SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space\",\"url\":\"https://www.semanticscholar.org/paper/c711f0b0f9e214d6ee462cffcac733221bf07026\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.11683\",\"authors\":[{\"authorId\":\"145559125\",\"name\":\"H. Akbari\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"1754397\",\"name\":\"Surabhi Bhargava\"},{\"authorId\":\"143852868\",\"name\":\"B. Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.01276\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"title\":\"Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b4702bad26563a4e1d03b33c0af0b29b095438bc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"1752876325\",\"name\":\"Yi Cai\"},{\"authorId\":\"150068355\",\"name\":\"Changmeng Zheng\"},{\"authorId\":\"47740571\",\"name\":\"J. Chen\"},{\"authorId\":\"1701688\",\"name\":\"Ho-fung Leung\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"}],\"doi\":\"10.18653/v1/2020.acl-main.642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ede49ec0dd27849e57152d5116770bcbe3e01874\",\"title\":\"Aligned Dual Channel Graph Convolutional Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ede49ec0dd27849e57152d5116770bcbe3e01874\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2001.05840\",\"authors\":[{\"authorId\":\"36325868\",\"name\":\"L. Shi\"},{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"2198730\",\"name\":\"K. Shuang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"51263928\",\"name\":\"Songxiang Liu\"},{\"authorId\":\"153933134\",\"name\":\"Peng Gao\"},{\"authorId\":\"47374777\",\"name\":\"S. Su\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad6500f4e4548be232e8027cfa648577e8e0ca4b\",\"title\":\"Multi-Layer Content Interaction Through Quaternion Product for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad6500f4e4548be232e8027cfa648577e8e0ca4b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1809.09314\",\"authors\":[{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"145810388\",\"name\":\"Zheng Zhou\"},{\"authorId\":\"145149511\",\"name\":\"J. Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/BigData.2018.8622461\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5138f2cb6de716880cea11df04a2037c5dac6711\",\"title\":\"How to Become Instagram Famous: Post Popularity Prediction with Dual-Attention\",\"url\":\"https://www.semanticscholar.org/paper/5138f2cb6de716880cea11df04a2037c5dac6711\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":\"2004.14025\",\"authors\":[{\"authorId\":\"79778234\",\"name\":\"Sungjin Park\"},{\"authorId\":\"89016637\",\"name\":\"T. Whang\"},{\"authorId\":\"3037023\",\"name\":\"Y. Yoon\"},{\"authorId\":\"1450703435\",\"name\":\"Hueiseok Lim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"title\":\"Multi-View Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52152408\",\"name\":\"Zihan Guo\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20236758\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"title\":\"Multi-Modal Explicit Sparse Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.13262\",\"authors\":[{\"authorId\":\"39209233\",\"name\":\"Siwen Luo\"},{\"authorId\":\"2046142\",\"name\":\"S. Han\"},{\"authorId\":\"33053279\",\"name\":\"Kaiyuan Sun\"},{\"authorId\":\"48422087\",\"name\":\"Josiah Poon\"}],\"doi\":\"10.1007/978-3-030-63830-6_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"title\":\"REXUP: I REason, I EXtract, I UPdate with Structured Compositional Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5225c9ca12387634ad93d6ccc547f5b2347d88a3\",\"venue\":\"ICONIP\",\"year\":2020}],\"corpusId\":4625261,\"doi\":\"10.1109/CVPR.2018.00637\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":10,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"references\":[{\"arxivId\":\"1411.1792\",\"authors\":[{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1747909\",\"name\":\"Hod Lipson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"081651b38ff7533550a3adfc1c00da333a8fe86c\",\"title\":\"How transferable are features in deep neural networks?\",\"url\":\"https://www.semanticscholar.org/paper/081651b38ff7533550a3adfc1c00da333a8fe86c\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1704.05526\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.93\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a396a6febdacb84340d139096455e67049ac1e22\",\"title\":\"Learning to Reason: End-to-End Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a396a6febdacb84340d139096455e67049ac1e22\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.03162\",\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"2544590\",\"name\":\"A. Elqursh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d674b540dcd968bc302ea4360df3f4e85e994b55\",\"title\":\"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d674b540dcd968bc302ea4360df3f4e85e994b55\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.06062\",\"authors\":[{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"3258919\",\"name\":\"Oscar Beijbom\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"title\":\"Compact Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1708.02071\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"49339267\",\"name\":\"Yanpeng Zhao\"},{\"authorId\":\"24027493\",\"name\":\"Shuaiyi Huang\"},{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1109/ICCV.2017.145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5823d18cd378898b12de537862d996443ce9c9e8\",\"title\":\"Structured Attentions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5823d18cd378898b12de537862d996443ce9c9e8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.01604\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3428769\",\"name\":\"Victor Zhong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e978d832a4d86571e1b52aa1685dc32ccb250f50\",\"title\":\"Dynamic Coattention Networks For Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e978d832a4d86571e1b52aa1685dc32ccb250f50\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J.-H. Kim\"},{\"authorId\":null,\"name\":\"K.-W. On\"},{\"authorId\":null,\"name\":\"W. Lim\"},{\"authorId\":null,\"name\":\"J. Kim\"},{\"authorId\":null,\"name\":\"J.-W. Ha\"},{\"authorId\":null,\"name\":\"B.- T. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Hadamard product for low-rank bilinear pooling\",\"url\":\"\",\"venue\":\"In International Conference on Learning Representations (ICLR),\",\"year\":2017},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S.-W. Lee\"},{\"authorId\":null,\"name\":\"D. Kwak\"},{\"authorId\":null,\"name\":\"M.-O. Heo\"},{\"authorId\":null,\"name\":\"J. Kim\"},{\"authorId\":null,\"name\":\"J.-W. Ha\"},{\"authorId\":null,\"name\":\"B.-T. Zhang\"},{\"authorId\":null,\"name\":\"K.-W. On\"},{\"authorId\":null,\"name\":\"W. Lim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hadamard product for low - rank bilinear pool\",\"url\":\"\",\"venue\":\"International Conference on Learning Representations ( ICLR )\",\"year\":null},{\"arxivId\":\"1708.02711\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00444\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"title\":\"Tips and Tricks for Visual Question Answering: Learnings from the 2017 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b14a60a1c3e6bb45baddd754a1cfe83ffc1bbb81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1506.06579\",\"authors\":[{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"151414531\",\"name\":\"Anh M Nguyen\"},{\"authorId\":\"34459632\",\"name\":\"Thomas J. Fuchs\"},{\"authorId\":\"1747909\",\"name\":\"Hod Lipson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b5a24639fa80056d1a17b15f6997d10e76cc731\",\"title\":\"Understanding Neural Networks Through Deep Visualization\",\"url\":\"https://www.semanticscholar.org/paper/1b5a24639fa80056d1a17b15f6997d10e76cc731\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":\"1410.5401\",\"authors\":[{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"89504302\",\"name\":\"G. Wayne\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3823aacea60bc1f2cabb9283144690a3d015db5\",\"title\":\"Neural Turing Machines\",\"url\":\"https://www.semanticscholar.org/paper/c3823aacea60bc1f2cabb9283144690a3d015db5\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944541\",\"name\":\"R. J\\u00f3zefowicz\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b8364c21155d3d2cd38ea4c8b8580beba9a3250\",\"title\":\"An Empirical Exploration of Recurrent Network Architectures\",\"url\":\"https://www.semanticscholar.org/paper/5b8364c21155d3d2cd38ea4c8b8580beba9a3250\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1708.00107\",\"authors\":[{\"authorId\":\"143775536\",\"name\":\"B. McCann\"},{\"authorId\":\"40518045\",\"name\":\"James Bradbury\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc8fa64625d9189f5801837e7b133e7fe3c581f7\",\"title\":\"Learned in Translation: Contextualized Word Vectors\",\"url\":\"https://www.semanticscholar.org/paper/bc8fa64625d9189f5801837e7b133e7fe3c581f7\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}],\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"}],\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"