"{\"abstract\":\"Video captioning is the task of automatically generating a textual description of the actions in a video. Although previous work (e.g. sequence-to-sequence model) has shown promising results in abstracting a coarse description of a short video, it is still very challenging to caption a video containing multiple fine-grained actions with a detailed description. This paper aims to address the challenge by proposing a novel hierarchical reinforcement learning framework for video captioning, where a high-level Manager module learns to design sub-goals and a low-level Worker module recognizes the primitive actions to fulfill the sub-goal. With this compositional framework to reinforce video captioning at different levels, our approach significantly outperforms all the baseline methods on a newly introduced large-scale dataset for fine-grained video captioning. Furthermore, our non-ensemble model has already achieved the state-of-the-art results on the widely-used MSR-VTT dataset.\",\"arxivId\":\"1711.11135\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\",\"url\":\"https://www.semanticscholar.org/author/48631993\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\",\"url\":\"https://www.semanticscholar.org/author/2928777\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\",\"url\":\"https://www.semanticscholar.org/author/46365930\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\",\"url\":\"https://www.semanticscholar.org/author/1706938\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\",\"url\":\"https://www.semanticscholar.org/author/1682479\"}],\"citationVelocity\":34,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"50506129\",\"name\":\"E. Barati\"},{\"authorId\":\"2410994\",\"name\":\"Xue-wen Chen\"}],\"doi\":\"10.1145/3343031.3351037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf8a3f260fbe4ee104380437cd576a556dccd290\",\"title\":\"Critic-based Attention Network for Event-based Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cf8a3f260fbe4ee104380437cd576a556dccd290\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1808.06740\",\"authors\":[{\"authorId\":\"3366595\",\"name\":\"Ziyu Yao\"},{\"authorId\":\"40286474\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1709722\",\"name\":\"Brian M. Sadler\"},{\"authorId\":\"11121990\",\"name\":\"Huan Sun\"}],\"doi\":\"10.1609/aaai.v33i01.33012547\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8761fe4a7dbdc9fb214b7e25096053507aeb9b69\",\"title\":\"Interactive Semantic Parsing for If-Then Recipes via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8761fe4a7dbdc9fb214b7e25096053507aeb9b69\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1804.05448\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/N18-2125\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"title\":\"Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1810.06339\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":\"10.1201/9781351006620-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"title\":\"Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96066534\",\"name\":\"P. Joshi\"},{\"authorId\":\"51497543\",\"name\":\"Chitwan Saharia\"},{\"authorId\":\"1557378944\",\"name\":\"V. Singh\"},{\"authorId\":\"51267359\",\"name\":\"Digvijaysingh Gautam\"},{\"authorId\":\"145799547\",\"name\":\"Ganesh Ramakrishnan\"},{\"authorId\":\"1557645545\",\"name\":\"P. Jyothi\"}],\"doi\":\"10.1109/ICCVW.2019.00459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523e8f226cc75a8fa5597aeb410e9236efc02f5d\",\"title\":\"A Tale of Two Modalities for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/523e8f226cc75a8fa5597aeb410e9236efc02f5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3492481\",\"name\":\"S. Cascianelli\"},{\"authorId\":\"2145503\",\"name\":\"G. Costante\"},{\"authorId\":\"150898549\",\"name\":\"Alessandro Devo\"},{\"authorId\":\"2730000\",\"name\":\"T. A. Ciarfuglia\"},{\"authorId\":\"2634628\",\"name\":\"P. Valigi\"},{\"authorId\":\"2635260\",\"name\":\"M. L. Fravolini\"}],\"doi\":\"10.1109/TMM.2019.2924598\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61a10a61e95ede1064567be38196a2348af3fb6c\",\"title\":\"The Role of the Input in Natural Language Video Description\",\"url\":\"https://www.semanticscholar.org/paper/61a10a61e95ede1064567be38196a2348af3fb6c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1901.03459\",\"authors\":[{\"authorId\":\"1725912\",\"name\":\"Yan Zhao\"},{\"authorId\":\"39263493\",\"name\":\"L. Liu\"},{\"authorId\":\"145160245\",\"name\":\"C. Liu\"},{\"authorId\":\"51176950\",\"name\":\"Ruoyao Yang\"},{\"authorId\":\"144580031\",\"name\":\"Dong Yu\"}],\"doi\":\"10.1007/978-3-319-99495-6_5\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"0bd1fb0a4443999d5f8257d5d737bc33f37713d7\",\"title\":\"From Plots to Endings: A Reinforced Pointer Generator for Story Ending Generation\",\"url\":\"https://www.semanticscholar.org/paper/0bd1fb0a4443999d5f8257d5d737bc33f37713d7\",\"venue\":\"NLPCC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"49728738\",\"name\":\"T. Serre\"}],\"doi\":\"10.1111/nyas.14320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"title\":\"Beyond the feedforward sweep: feedback computations in the visual cortex\",\"url\":\"https://www.semanticscholar.org/paper/83e06eeccfda20ef3025ab5fb311c0fadeca32d8\",\"venue\":\"Annals of the New York Academy of Sciences\",\"year\":2020},{\"arxivId\":\"2009.01067\",\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"title\":\"Video Captioning Using Weak Annotation\",\"url\":\"https://www.semanticscholar.org/paper/aa17f11df851372402a0fa1481fdbc6af36ba2b6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.08292\",\"authors\":[{\"authorId\":\"40902222\",\"name\":\"Santhosh Kelathodi Kumaran\"},{\"authorId\":\"3320759\",\"name\":\"D. P. Dogra\"},{\"authorId\":\"40813600\",\"name\":\"P. Roy\"}],\"doi\":\"10.1145/3417989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88573561d2e662f53201971fab6ecf6beceefe73\",\"title\":\"Anomaly Detection in Road Traffic Using Visual Surveillance: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/88573561d2e662f53201971fab6ecf6beceefe73\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.12905\",\"authors\":[{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":\"10.1145/3343031.3351060\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"5ea12e7ccefa226593a6918ae3100bfcd4b2d284\",\"title\":\"Watch It Twice: Video Captioning with a Refocused Video Encoder\",\"url\":\"https://www.semanticscholar.org/paper/5ea12e7ccefa226593a6918ae3100bfcd4b2d284\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1805.08298\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2a2818ec251d947acd9c74c2040337e656946bc\",\"title\":\"Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/e2a2818ec251d947acd9c74c2040337e656946bc\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"66622154\",\"name\":\"Ray Ptucha\"}],\"doi\":\"10.1007/s10044-018-00770-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"title\":\"Understanding temporal structure for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1799121\",\"name\":\"K. Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/ACCESS.2020.3042484\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"832aafb4989c24211a8377f82228c31f7a90ef81\",\"title\":\"Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap\",\"url\":\"https://www.semanticscholar.org/paper/832aafb4989c24211a8377f82228c31f7a90ef81\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2001.05614\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"38376468\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3233/FAIA200204\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0c33980d7c011a8c657afb825220632e17b1568\",\"title\":\"Delving Deeper into the Decoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f0c33980d7c011a8c657afb825220632e17b1568\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"2002.03740\",\"authors\":[{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1749272\",\"name\":\"Ziyu Guan\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2985868\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"title\":\"Query-Biased Self-Attentive Network for Query-Focused Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108124522\",\"name\":\"T. Fujii\"},{\"authorId\":\"1768926\",\"name\":\"Yuichi Sei\"},{\"authorId\":\"1749328\",\"name\":\"Y. Tahara\"},{\"authorId\":\"1394541524\",\"name\":\"Ryohei Orihara\"},{\"authorId\":\"1740433\",\"name\":\"A. Ohsuga\"}],\"doi\":\"10.1109/BCD.2019.8885222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"347948a756f46d75363ef06ff18bb93f70744420\",\"title\":\"\\u201cNever fry carrots without cutting.\\u201d Cooking Recipe Generation from Videos Using Deep Learning Considering Previous Process\",\"url\":\"https://www.semanticscholar.org/paper/347948a756f46d75363ef06ff18bb93f70744420\",\"venue\":\"2019 IEEE International Conference on Big Data, Cloud Computing, Data Science & Engineering (BCD)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2019.2921655\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"title\":\"Sports Video Captioning via Attentive Motion Representation and Group Relationship Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108124522\",\"name\":\"T. Fujii\"},{\"authorId\":\"1768926\",\"name\":\"Yuichi Sei\"},{\"authorId\":\"1749328\",\"name\":\"Y. Tahara\"},{\"authorId\":\"1394541524\",\"name\":\"Ryohei Orihara\"},{\"authorId\":\"1740433\",\"name\":\"A. Ohsuga\"}],\"doi\":\"10.2991/IJNDC.K.190710.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d85b1543ab836881d3f0992395e8f210b8fc07f4\",\"title\":\"\\\"Never fry carrots without chopping\\\" Generating Cooking Recipes from Cooking Videos Using Deep Learning Considering Previous Process\",\"url\":\"https://www.semanticscholar.org/paper/d85b1543ab836881d3f0992395e8f210b8fc07f4\",\"venue\":\"Int. J. Networked Distributed Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2907739\",\"name\":\"Masoomeh Nabati\"},{\"authorId\":\"30756748\",\"name\":\"A. Behrad\"}],\"doi\":\"10.1016/j.ipm.2020.102302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aca85e733323b2b364ae79fd0934edf2f1544ca1\",\"title\":\"Multi-Sentence Video Captioning using Content-oriented Beam Searching and Multi-stage Refining Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/aca85e733323b2b364ae79fd0934edf2f1544ca1\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"152553911\",\"name\":\"T. Barnes\"},{\"authorId\":\"1423680515\",\"name\":\"Min Chi\"}],\"doi\":\"10.24963/ijcai.2020/647\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a729366768abd5d85a0efd666e6f7ab40ca27d2\",\"title\":\"Hierarchical Reinforcement Learning for Pedagogical Policy Induction (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/6a729366768abd5d85a0efd666e6f7ab40ca27d2\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2005.08271\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d87489d2facf197caafd24d0796523d55d47fb62\",\"title\":\"A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer\",\"url\":\"https://www.semanticscholar.org/paper/d87489d2facf197caafd24d0796523d55d47fb62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46895706\",\"name\":\"Wenfeng Song\"},{\"authorId\":\"1423476966\",\"name\":\"Shuai Li\"},{\"authorId\":\"103054850\",\"name\":\"Tao Chang\"},{\"authorId\":\"2252725\",\"name\":\"Ai-min Hao\"},{\"authorId\":\"20658737\",\"name\":\"Q. Zhao\"},{\"authorId\":\"100787805\",\"name\":\"Hong Qin\"}],\"doi\":\"10.1109/WACV45572.2020.9093382\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60dfaea6c9ad9d6b15941211045f3a476ebc7132\",\"title\":\"Cross-View Contextual Relation Transferred Network for Unsupervised Vehicle Tracking in Drone Videos\",\"url\":\"https://www.semanticscholar.org/paper/60dfaea6c9ad9d6b15941211045f3a476ebc7132\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46895706\",\"name\":\"Wenfeng Song\"},{\"authorId\":\"48830645\",\"name\":\"Shuai Li\"},{\"authorId\":\"103054850\",\"name\":\"Tao Chang\"},{\"authorId\":\"2252725\",\"name\":\"Ai-min Hao\"},{\"authorId\":\"20658737\",\"name\":\"Q. Zhao\"},{\"authorId\":\"100787805\",\"name\":\"Hong Qin\"}],\"doi\":\"10.1109/TIP.2019.2953587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58a06477685794544e34d03a9190ca20a1a8e505\",\"title\":\"Context-Interactive CNN for Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/58a06477685794544e34d03a9190ca20a1a8e505\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2011.07517\",\"authors\":[{\"authorId\":\"49606678\",\"name\":\"Jianan Wang\"},{\"authorId\":\"49730189\",\"name\":\"Boyang Li\"},{\"authorId\":\"46515715\",\"name\":\"Xiangyu Fan\"},{\"authorId\":\"1845592115\",\"name\":\"J. Lin\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f5cbd60f07a19afc3566376e404a490865e5def\",\"title\":\"Data-efficient Alignment of Multimodal Sequences by Aligning Gradient Updates and Internal Feature Distributions\",\"url\":\"https://www.semanticscholar.org/paper/5f5cbd60f07a19afc3566376e404a490865e5def\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669461\",\"name\":\"Kuncheng Fang\"},{\"authorId\":\"144913277\",\"name\":\"Lian Zhou\"},{\"authorId\":\"145020731\",\"name\":\"Cheng Jin\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"35632219\",\"name\":\"Kangnian Weng\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"title\":\"Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention\",\"url\":\"https://www.semanticscholar.org/paper/506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"}],\"doi\":\"10.1145/3347449.3357484\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"989730c00381805543baa470a2d6490cc5354a13\",\"title\":\"L-STAP: Learned Spatio-Temporal Adaptive Pooling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/989730c00381805543baa470a2d6490cc5354a13\",\"venue\":\"AI4TV@MM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"1904053\",\"name\":\"Xiaoguang Zhao\"},{\"authorId\":\"145035830\",\"name\":\"Min Tan\"}],\"doi\":\"10.3390/APP9040750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e00ad164344a7bb92dfea3a71072c24e5fba3b86\",\"title\":\"Deep Reinforcement Learning for Query-Conditioned Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/e00ad164344a7bb92dfea3a71072c24e5fba3b86\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1806.01954\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"9947219\",\"name\":\"Simion-Vlad Bogolin\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c42f427b54ab12a1d89827ee4c6951efae733b55\",\"title\":\"Mining for meaning: from vision to language through multiple networks consensus\",\"url\":\"https://www.semanticscholar.org/paper/c42f427b54ab12a1d89827ee4c6951efae733b55\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2007.02375\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"5891694\",\"name\":\"J. Luo\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"title\":\"Auto-captions on GIF: A Large-scale Video-sentence Dataset for Vision-language Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/ad9d41b29f7b7b35278f466dc2eafedaf7f57db1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.01833\",\"authors\":[{\"authorId\":\"1748036\",\"name\":\"Chen Wu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"17866105\",\"name\":\"Fuli Luo\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.18653/v1/P19-1482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d25f338954a0705616d232cd2ca2c6b975fbeaf\",\"title\":\"A Hierarchical Reinforced Sequence Operation Method for Unsupervised Text Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/6d25f338954a0705616d232cd2ca2c6b975fbeaf\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35548557\",\"name\":\"Konstantinos Gkountakos\"},{\"authorId\":\"47381330\",\"name\":\"A. Dimou\"},{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":\"10.1109/ICE.2019.8792602\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2e3bdb38138a5adbb7b24257780bc3dc6d3a3f3f\",\"title\":\"Incorporating Textual Similarity in Video Captioning Schemes\",\"url\":\"https://www.semanticscholar.org/paper/2e3bdb38138a5adbb7b24257780bc3dc6d3a3f3f\",\"venue\":\"2019 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"145211780\",\"name\":\"Bin Fan\"},{\"authorId\":\"1380311632\",\"name\":\"Shinming Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.18653/v1/D19-1213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"title\":\"Guiding the Flowing of Semantics: Interpretable Video Captioning via POS Tag\",\"url\":\"https://www.semanticscholar.org/paper/ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"51039532\",\"name\":\"Markel Sanz Ausin\"},{\"authorId\":\"1734603\",\"name\":\"T. Barnes\"},{\"authorId\":\"1731937\",\"name\":\"Min Chi\"}],\"doi\":\"10.1007/978-3-030-23204-7_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd7d3becbe36188f22f08609725859c5b72c36df\",\"title\":\"Hierarchical Reinforcement Learning for Pedagogical Policy Induction\",\"url\":\"https://www.semanticscholar.org/paper/bd7d3becbe36188f22f08609725859c5b72c36df\",\"venue\":\"AIED\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349939\",\"name\":\"Guojing Zhou\"},{\"authorId\":\"1696341\",\"name\":\"X. Yang\"},{\"authorId\":\"51216654\",\"name\":\"H. Azizsoltani\"},{\"authorId\":\"152553911\",\"name\":\"T. Barnes\"},{\"authorId\":\"1423680515\",\"name\":\"Min Chi\"}],\"doi\":\"10.1145/3340631.3394848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5c732d58d8f8978eec2b5aea43786b238228191\",\"title\":\"Improving Student-System Interaction Through Data-driven Explanations of Hierarchical Reinforcement Learning Induced Pedagogical Policies\",\"url\":\"https://www.semanticscholar.org/paper/e5c732d58d8f8978eec2b5aea43786b238228191\",\"venue\":\"UMAP\",\"year\":2020},{\"arxivId\":\"2001.06944\",\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86724befacdd9fd8748607f5b025aa59fb7ef010\",\"title\":\"Nested-Wasserstein Self-Imitation Learning for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/86724befacdd9fd8748607f5b025aa59fb7ef010\",\"venue\":\"AISTATS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"},{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"},{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1394465427\",\"name\":\"Qiuyu Cai\"}],\"doi\":\"10.1145/3394171.3416290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93aed487e9b9f51bf05803ef69c92599001358ac\",\"title\":\"XlanV Model with Adaptively Multi-Modality Feature Fusing for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93aed487e9b9f51bf05803ef69c92599001358ac\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413908\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"title\":\"Controllable Video Captioning with an Exemplar Sentence\",\"url\":\"https://www.semanticscholar.org/paper/40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255213\",\"name\":\"Z. Zhang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"47337540\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"2597292\",\"name\":\"Chuanqi Tan\"}],\"doi\":\"10.1109/TCSVT.2019.2936526\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"title\":\"Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/978-3-030-31756-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"title\":\"The Encoder-Decoder Framework and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.02602\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"title\":\"Human Action Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.03966\",\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"49050519\",\"name\":\"Jiyuan Zhang\"},{\"authorId\":\"47119038\",\"name\":\"X. Wang\"},{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/CVPR.2019.00854\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"title\":\"Memory-Attended Recurrent Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.98\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3263b941d0a77bbd2040612ec774ef063ef64c48\",\"title\":\"Semi-Supervised Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3263b941d0a77bbd2040612ec774ef063ef64c48\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1993631009\",\"name\":\"Haizhou Shi\"},{\"authorId\":\"1490931889\",\"name\":\"Haochen Shi\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"49336516\",\"name\":\"W. Wang\"}],\"doi\":\"10.1145/3394171.3413746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa8f78e665c037da28a7e35a98c4d2521e3f12e\",\"title\":\"Relational Graph Learning for Grounded Video Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/9fa8f78e665c037da28a7e35a98c4d2521e3f12e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.09530\",\"authors\":[{\"authorId\":\"153769937\",\"name\":\"H. Akbari\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"120157163\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1845230025\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"37409035\",\"name\":\"R. Fernandez\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"title\":\"Neuro-Symbolic Representations for Video Captioning: A Case for Leveraging Inductive Biases for Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/c2b4d96db34bd472e84c9234838cc4e808eb1ba9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.12255\",\"authors\":[{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"145181836\",\"name\":\"Gabriel Magalh\\u00e3es\"},{\"authorId\":\"31702389\",\"name\":\"Alexander Ku\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"}],\"doi\":\"10.18653/v1/P19-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68ccecb380ecfc0a4b294b84e3d0b6ff6884c4df\",\"title\":\"Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/68ccecb380ecfc0a4b294b84e3d0b6ff6884c4df\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7741774\",\"name\":\"Y. Hu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"51239188\",\"name\":\"Fengcheng Wu\"}],\"doi\":\"10.1145/3343031.3351072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db6035229a71a6c93d4f15c4a4280eb644228da4\",\"title\":\"Hierarchical Global-Local Temporal Modeling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/db6035229a71a6c93d4f15c4a4280eb644228da4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1930287\",\"name\":\"L. Zhang\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1145/3382507.3418886\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c43909efc347aab615a8688e0329d5b3d2cc1b62\",\"title\":\"Temporal Attention and Consistency Measuring for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c43909efc347aab615a8688e0329d5b3d2cc1b62\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":\"1811.02765\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33018965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"title\":\"Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1901.06829\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"1749527\",\"name\":\"Xiang Zhao\"},{\"authorId\":\"2864855\",\"name\":\"Jizhou Huang\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"title\":\"Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.18653/v1/P18-5007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b525bac2438c296e3b627a61908cd37e66ac7115\",\"title\":\"Deep Reinforcement Learning for NLP\",\"url\":\"https://www.semanticscholar.org/paper/b525bac2438c296e3b627a61908cd37e66ac7115\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"102599406\",\"name\":\"Y. Tan\"},{\"authorId\":\"46276803\",\"name\":\"J. Li\"},{\"authorId\":\"46513749\",\"name\":\"Bin Tan\"}],\"doi\":\"10.1016/j.jvcir.2020.102875\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32c722384bdf8ac2ade6d6e4ce3225077b124555\",\"title\":\"Translating video into language by enhancing visual and language representations\",\"url\":\"https://www.semanticscholar.org/paper/32c722384bdf8ac2ade6d6e4ce3225077b124555\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1803.07729\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"22253126\",\"name\":\"Wenhan Xiong\"},{\"authorId\":\"46506498\",\"name\":\"Hongmin Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1007/978-3-030-01270-0_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"368131eaf906d7b29517066e1b2759a44c8105d4\",\"title\":\"Look Before You Leap: Bridging Model-Free and Model-Based Reinforcement Learning for Planned-Ahead Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/368131eaf906d7b29517066e1b2759a44c8105d4\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.08191\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1609/aaai.v33i01.33018465\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"c2b02822cfbc50d17ec5220a19556be9d601c132\",\"title\":\"Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/c2b02822cfbc50d17ec5220a19556be9d601c132\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1908.00169\",\"authors\":[{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"145527564\",\"name\":\"Z. Zhang\"},{\"authorId\":\"31115284\",\"name\":\"Jingjing Li\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"}],\"doi\":\"10.1145/3343031.3350961\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4c8f6c4a2b744fcfd82a7d7c8041d87d2b5c250\",\"title\":\"Curiosity-driven Reinforcement Learning for Diverse Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/d4c8f6c4a2b744fcfd82a7d7c8041d87d2b5c250\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2004.14254\",\"authors\":[{\"authorId\":\"66272304\",\"name\":\"Kangenbei Liao\"},{\"authorId\":\"72999225\",\"name\":\"Q. Liu\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"1780690\",\"name\":\"Baolin Peng\"},{\"authorId\":\"1585496097\",\"name\":\"Qin Chen\"},{\"authorId\":null,\"name\":\"Weijian Sun\"},{\"authorId\":\"144052385\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e014af8ae8d7dbd3c1c908dfba334a6d2181b8e1\",\"title\":\"Task-oriented Dialogue System for Automatic Disease Diagnosis via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e014af8ae8d7dbd3c1c908dfba334a6d2181b8e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50987563\",\"name\":\"Sangmin Park\"},{\"authorId\":\"97243906\",\"name\":\"Young-gab Kim\"}],\"doi\":\"10.1016/j.inffus.2020.10.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65dc69953ef141871f1701d68196aa278566fc16\",\"title\":\"Survey and challenges of story generation models - A multimodal perspective with five steps: Data embedding, topic modeling, storyline generation, draft story generation, and story evaluation\",\"url\":\"https://www.semanticscholar.org/paper/65dc69953ef141871f1701d68196aa278566fc16\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2007.12173\",\"authors\":[{\"authorId\":\"20745881\",\"name\":\"Luca Weihs\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"145704057\",\"name\":\"J. Salvador\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f618d2500477729926ce7d9d311e7e69477dc07\",\"title\":\"Bridging the Imitation Gap by Adaptive Insubordination\",\"url\":\"https://www.semanticscholar.org/paper/3f618d2500477729926ce7d9d311e7e69477dc07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48637710\",\"name\":\"Yongqing Zhu\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3343031.3350932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c3eda8bd5c7b76bc61763948fa0df857052de44\",\"title\":\"Attention-based Densely Connected LSTM for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1c3eda8bd5c7b76bc61763948fa0df857052de44\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144364295\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"title\":\"TVT: Two-View Transformer Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":\"1905.04094\",\"authors\":[{\"authorId\":\"51036717\",\"name\":\"J. Chen\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/TNNLS.2020.3028078\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e237c89c76ebf58085d7066648f7a4291cd9bfce\",\"title\":\"Domain Adversarial Reinforcement Learning for Partial Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/e237c89c76ebf58085d7066648f7a4291cd9bfce\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1901.10623\",\"authors\":[{\"authorId\":\"46265604\",\"name\":\"L. Xu\"},{\"authorId\":\"31506147\",\"name\":\"Q. Zhou\"},{\"authorId\":\"144194066\",\"name\":\"K. Gong\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"66239746\",\"name\":\"Jianheng Tang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1609/AAAI.V33I01.33017346\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e14fdf566f9fe9e605e047e8688c75ad4277bc17\",\"title\":\"End-to-End Knowledge-Routed Relational Dialogue System for Automatic Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/e14fdf566f9fe9e605e047e8688c75ad4277bc17\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47569376\",\"name\":\"Shijie Yang\"},{\"authorId\":\"73596205\",\"name\":\"L. Li\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"49356099\",\"name\":\"Dechao Meng\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3350859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"952a74f839536bd7668acb8d65086b4f4e3a4dee\",\"title\":\"Structured Stochastic Recurrent Network for Linguistic Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/952a74f839536bd7668acb8d65086b4f4e3a4dee\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TMM.2019.2896515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5f79ee6c9b3e5951e4267d4624d2d7669a72cb3\",\"title\":\"Generating Video Descriptions With Latent Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/e5f79ee6c9b3e5951e4267d4624d2d7669a72cb3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/ICCV.2019.00901\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"title\":\"Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.00212\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.18653/v1/D19-1207\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55f546209c01530a7717d4170aa24947c6b92775\",\"title\":\"Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/55f546209c01530a7717d4170aa24947c6b92775\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2011.07635\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"48843025\",\"name\":\"Han Guo\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fb985c6624bede346e05f9ef16aa4505731c330\",\"title\":\"DORB: Dynamically Optimizing Multiple Rewards with Bandits\",\"url\":\"https://www.semanticscholar.org/paper/1fb985c6624bede346e05f9ef16aa4505731c330\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9947219\",\"name\":\"Simion-Vlad Bogolin\"},{\"authorId\":\"50272388\",\"name\":\"Ioana Croitoru\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9348890ecbbfd7bb75667fa2014ebe6f4a5558b1\",\"title\":\"A hierarchical approach to vision-based language generation: from simple sentences to complex natural language\",\"url\":\"https://www.semanticscholar.org/paper/9348890ecbbfd7bb75667fa2014ebe6f4a5558b1\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2012.07098\",\"authors\":[{\"authorId\":\"28282293\",\"name\":\"Begum Citamak\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"51214846\",\"name\":\"Menekse Kuyu\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"152827782\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2557b1a45412e1100d40ec1fe4073c3b00921f6\",\"title\":\"MSVD-Turkish: A Comprehensive Multimodal Dataset for Integrated Vision and Language Research in Turkish\",\"url\":\"https://www.semanticscholar.org/paper/c2557b1a45412e1100d40ec1fe4073c3b00921f6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.02872\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2149345\",\"name\":\"Chenxiao Guan\"},{\"authorId\":\"48616329\",\"name\":\"J. Goodman\"},{\"authorId\":\"50583301\",\"name\":\"Marc Moore\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5328a7024f820fafdab4165777807c2ecb855fe4\",\"title\":\"An Attempt towards Interpretable Audio-Visual Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5328a7024f820fafdab4165777807c2ecb855fe4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.07758\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1109/CVPRW50498.2020.00487\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23e36087637e9d74815eba07990c38c02fecc966\",\"title\":\"Multi-modal Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/23e36087637e9d74815eba07990c38c02fecc966\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2002.02649\",\"authors\":[{\"authorId\":\"9202187\",\"name\":\"Chaoqun Duan\"},{\"authorId\":\"145500846\",\"name\":\"Lei Cui\"},{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2675365\",\"name\":\"Conghui Zhu\"},{\"authorId\":\"1856039\",\"name\":\"T. Zhao\"}],\"doi\":\"10.3233/FAIA200320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bf0bf048b88c2bb5a7d53e34ec912907295be81\",\"title\":\"Multimodal Matching Transformer for Live Commenting\",\"url\":\"https://www.semanticscholar.org/paper/7bf0bf048b88c2bb5a7d53e34ec912907295be81\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"1804.09160\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/P18-1083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0af4274ddc948bb175be7662a699a8270878ced2\",\"title\":\"No Metrics Are Perfect: Adversarial Reward Learning for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/0af4274ddc948bb175be7662a699a8270878ced2\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1908.03409\",\"authors\":[{\"authorId\":\"79953458\",\"name\":\"Haoshuo Huang\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"18138802\",\"name\":\"Harsh Mehta\"},{\"authorId\":\"31702389\",\"name\":\"Alexander Ku\"},{\"authorId\":\"145181836\",\"name\":\"Gabriel Magalh\\u00e3es\"},{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"}],\"doi\":\"10.1109/ICCV.2019.00750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c351e405660f09ded4ba2bd05a2362be292a3da3\",\"title\":\"Transferable Representation Learning in Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c351e405660f09ded4ba2bd05a2362be292a3da3\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108124522\",\"name\":\"T. Fujii\"},{\"authorId\":\"1394541524\",\"name\":\"Ryohei Orihara\"},{\"authorId\":\"1768926\",\"name\":\"Yuichi Sei\"},{\"authorId\":\"1749328\",\"name\":\"Y. Tahara\"},{\"authorId\":\"1740433\",\"name\":\"A. Ohsuga\"}],\"doi\":\"10.1145/3378184.3378217\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a9fabeb62504598488f174f1b354d948d5dfe43\",\"title\":\"Generating Cooking Recipes from Cooking Videos Using Deep Learning Considering Previous Process with Video Encoding\",\"url\":\"https://www.semanticscholar.org/paper/1a9fabeb62504598488f174f1b354d948d5dfe43\",\"venue\":\"APPIS\",\"year\":2020},{\"arxivId\":\"2004.12274\",\"authors\":[{\"authorId\":\"29860450\",\"name\":\"Baoyu Jing\"},{\"authorId\":\"1905077\",\"name\":\"Zeya Wang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/P19-1657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"title\":\"Show, Describe and Conclude: On Exploiting the Structure Information of Chest X-ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632281\",\"name\":\"X. Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/tpami.2020.2972281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"title\":\"Vision-Language Navigation Policy Learning and Adaptation.\",\"url\":\"https://www.semanticscholar.org/paper/2d8a819980ba9413c8c5bea1a078ca8e634d3861\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1907.11117\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b73ff5846772da8575262925aa7709b5e64079a0\",\"title\":\"Learning Visual Actions Using Multiple Verb-Only Labels\",\"url\":\"https://www.semanticscholar.org/paper/b73ff5846772da8575262925aa7709b5e64079a0\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"97799727\",\"name\":\"Chenxiao Guan\"},{\"authorId\":\"32074473\",\"name\":\"J. Goodman\"},{\"authorId\":\"50583301\",\"name\":\"Marc Moore\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d124bd0f0a6f89880844a7da0e8cb79c9f5cd659\",\"title\":\"Audio-Visual Interpretable and Controllable Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d124bd0f0a6f89880844a7da0e8cb79c9f5cd659\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.12633\",\"authors\":[{\"authorId\":\"24339915\",\"name\":\"Davis Gilton\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"145952380\",\"name\":\"R. Willett\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"title\":\"Detection and Description of Change in Visual Streams\",\"url\":\"https://www.semanticscholar.org/paper/dea7e4fdaa5c56a8e1df800149b8d3e8e9950990\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938051940\",\"name\":\"Dylan Flaute\"},{\"authorId\":\"2405109\",\"name\":\"B. Narayanan\"}],\"doi\":\"10.1117/12.2568016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"title\":\"Video captioning using weakly supervised convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"venue\":\"Optical Engineering + Applications\",\"year\":2020},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1807.03089\",\"authors\":[{\"authorId\":\"9368124\",\"name\":\"K. Zhou\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c65232de4ca3809b0765577a1197bd6027f98a39\",\"title\":\"Video Summarisation by Classification with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c65232de4ca3809b0765577a1197bd6027f98a39\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"title\":\"Nested-Wasserstein Distance for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.14752\",\"authors\":[{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"title\":\"A Comprehensive Review on Recent Methods and Challenges of Video Description\",\"url\":\"https://www.semanticscholar.org/paper/baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15484\",\"authors\":[{\"authorId\":\"1491010174\",\"name\":\"Nihar Bendre\"},{\"authorId\":\"1399006252\",\"name\":\"H. Terashima-Mar\\u00edn\"},{\"authorId\":\"71756373\",\"name\":\"Peyman Najafirad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"619571a2be1f0fc03899ce4bff8d6dee40608540\",\"title\":\"Learning from Few Samples: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/619571a2be1f0fc03899ce4bff8d6dee40608540\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10092\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"title\":\"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151478835\",\"name\":\"Chen Xiao-kai\"},{\"authorId\":\"151485756\",\"name\":\"Gao Ke\"},{\"authorId\":\"145515934\",\"name\":\"C. Juan\"}],\"doi\":\"10.1109/ICME.2019.00169\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9fb80b6dc6b636478915382f8de2fb43ee5900d\",\"title\":\"Predictability Analyzing: Deep Reinforcement Learning for Early Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9fb80b6dc6b636478915382f8de2fb43ee5900d\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2003304806\",\"name\":\"Mauricio-Andres Zamora-Hernandez\"},{\"authorId\":\"2003285868\",\"name\":\"Jose Andrez Chaves Ceciliano\"},{\"authorId\":\"145399025\",\"name\":\"Alonso Granados\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"2031782865\",\"name\":\"Jos\\u00ed Garc\\u00eda Rodr\\u00edguez\"},{\"authorId\":\"1754830\",\"name\":\"J. L\\u00f3pez\"}],\"doi\":\"10.1007/978-3-030-57802-2_76\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff70b785887b883f965be3fb93a129ec1dd9c238\",\"title\":\"Manufacturing Description Language for Process Control in Industry 4.0\",\"url\":\"https://www.semanticscholar.org/paper/ff70b785887b883f965be3fb93a129ec1dd9c238\",\"venue\":\"SOCO\",\"year\":2020},{\"arxivId\":\"2008.10966\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"47268124\",\"name\":\"T. Li\"},{\"authorId\":\"46499812\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1007/978-3-030-58536-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"title\":\"In-Home Daily-Life Captioning Using Radio Signals\",\"url\":\"https://www.semanticscholar.org/paper/fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.09791\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-58589-1_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"title\":\"Identity-Aware Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":4433804,\"doi\":\"10.1109/CVPR.2018.00443\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":9,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"74b284a66e75b65f5970d05bac000fe91243ee49\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ecb6b37ed067b2f16dbb6f476d449f113fae534\",\"title\":\"Video Captioning and Retrieval Models with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/1ecb6b37ed067b2f16dbb6f476d449f113fae534\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130333\",\"name\":\"Siqi Liu\"},{\"authorId\":\"39815369\",\"name\":\"Z. Zhu\"},{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/ICCV.2017.100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"title\":\"Improved Image Captioning via Policy Gradient optimization of SPIDEr\",\"url\":\"https://www.semanticscholar.org/paper/163a474747fd63ab62ae586711fa5e5a2ac91bd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.01502\",\"authors\":[{\"authorId\":\"145314568\",\"name\":\"Zhiqiang Shen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"},{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"3700393\",\"name\":\"Minjun Li\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2017.548\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"title\":\"Weakly Supervised Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6979be4e3acbb6a5455946dc332565ccb10cf8de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1505.00521\",\"authors\":[{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f10e071292d593fef939e6ef4a59baf0bb3a6c2b\",\"title\":\"Reinforcement Learning Neural Turing Machines\",\"url\":\"https://www.semanticscholar.org/paper/f10e071292d593fef939e6ef4a59baf0bb3a6c2b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1706.09601\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"title\":\"Actor-Critic Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1506.06863\",\"authors\":[{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"40608686\",\"name\":\"Yangfeng Ji\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2596310\",\"name\":\"Chris Quirk\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":\"10.3115/v1/P15-2073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d0684b19ba46e739e28baa1e180c008226f793a\",\"title\":\"deltaBLEU: A Discriminative Metric for Generation Tasks with Intrinsically Diverse Targets\",\"url\":\"https://www.semanticscholar.org/paper/7d0684b19ba46e739e28baa1e180c008226f793a\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"B. Van Merri\\u00ebnboer\"},{\"authorId\":null,\"name\":\"C. Gulcehre\"},{\"authorId\":null,\"name\":\"D. Bahdanau\"},{\"authorId\":null,\"name\":\"F. Bougares\"},{\"authorId\":null,\"name\":\"H. Schwenk\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hierarchical boundaryaware neural encoder for video captioning Scheduled sampling for sequence prediction with recurrent neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1708.02300\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D17-1103\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53bed2d3d75c4320ad5af4a85e31bf92e3c704ef\",\"title\":\"Reinforced Video Captioning with Entailment Rewards\",\"url\":\"https://www.semanticscholar.org/paper/53bed2d3d75c4320ad5af4a85e31bf92e3c704ef\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1706.01231\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"153757316\",\"name\":\"Zhao Guo\"},{\"authorId\":\"144973314\",\"name\":\"Wu Liu\"},{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.24963/ijcai.2017/381\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"title\":\"Hierarchical LSTM with Adjusted Temporal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"3493516\",\"name\":\"Yifan Xiong\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/2964284.2984065\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7492cac0babe8d514995bcde6456ae00c17325a3\",\"title\":\"Describing Videos using Multi-modal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/7492cac0babe8d514995bcde6456ae00c17325a3\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1604.06057\",\"authors\":[{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"3231182\",\"name\":\"A. Saeedi\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d37620e6f8fe678a43e12930743281cd8cca6a66\",\"title\":\"Hierarchical Deep Reinforcement Learning: Integrating Temporal Abstraction and Intrinsic Motivation\",\"url\":\"https://www.semanticscholar.org/paper/d37620e6f8fe678a43e12930743281cd8cca6a66\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1403.6173\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"113090874\",\"name\":\"W. Qiu\"},{\"authorId\":\"33985877\",\"name\":\"Annemarie Friedrich\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-11752-2_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"889e723cd6d581e120ee6776b231fdf69707ab50\",\"title\":\"Coherent Multi-sentence Video Description with Variable Level of Detail\",\"url\":\"https://www.semanticscholar.org/paper/889e723cd6d581e120ee6776b231fdf69707ab50\",\"venue\":\"GCPR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1145/2964284.2984066\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"61d409b92860480a9188d23ba59b822ddc6331f9\",\"title\":\"Multimodal Video Description\",\"url\":\"https://www.semanticscholar.org/paper/61d409b92860480a9188d23ba59b822ddc6331f9\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5259755f9c100e220ffaa7e08439c5d34be7757a\",\"title\":\"Reinforcement Learning Neural Turing Machines - Revised\",\"url\":\"https://www.semanticscholar.org/paper/5259755f9c100e220ffaa7e08439c5d34be7757a\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12094097\",\"name\":\"Pratik P. Rane\"},{\"authorId\":\"118145941\",\"name\":\"A. M. Sargar\"},{\"authorId\":\"47039181\",\"name\":\"Faiza Shaikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f77a604410d88307ec5c6331c8b6133272fbaa10\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f77a604410d88307ec5c6331c8b6133272fbaa10\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1212.5701\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8729441d734782c3ed532a7d2d9611b438c0a09a\",\"title\":\"ADADELTA: An Adaptive Learning Rate Method\",\"url\":\"https://www.semanticscholar.org/paper/8729441d734782c3ed532a7d2d9611b438c0a09a\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"3276293\",\"name\":\"G. Lever\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1804488\",\"name\":\"T. Degris\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"title\":\"Deterministic Policy Gradient Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/687d0e59d5c35f022ce4638b3e3a6142068efc94\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1608.04959\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1145/2964284.2984062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41eec260e0980f8fd0af46f0dfc043139087a928\",\"title\":\"Frame- and Segment-Level Features and Candidate Pool Evaluation for Video Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/41eec260e0980f8fd0af46f0dfc043139087a928\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1610.02947\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dc37dab102a0465098111b7ccf6f95b736397f2\",\"title\":\"End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3dc37dab102a0465098111b7ccf6f95b736397f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1080/10042857.2004.10677353\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1dad553a004f0f53d18f70349543259b559899a7\",\"title\":\"WATCH\",\"url\":\"https://www.semanticscholar.org/paper/1dad553a004f0f53d18f70349543259b559899a7\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"1704.07489\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P17-1117\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b08d3201af644a638e291755a5e51f6b17a51f3\",\"title\":\"Multi-Task Video Captioning with Video and Entailment Generation\",\"url\":\"https://www.semanticscholar.org/paper/9b08d3201af644a638e291755a5e51f6b17a51f3\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1607.07086\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2616163\",\"name\":\"Philemon Brakel\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d24a0695c9fc669e643bad51d4e14f056329dec\",\"title\":\"An Actor-Critic Algorithm for Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0d24a0695c9fc669e643bad51d4e14f056329dec\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1611.09312\",\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"153925540\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2017.339\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"title\":\"Hierarchical Boundary-Aware Neural Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/726b1ade8b3d0023f0b4a9f86b7c2c3004885e37\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1023/A:1022672621406\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c221cc946425d85f93c86e3be2c31d4feb00faa1\",\"title\":\"Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c221cc946425d85f93c86e3be2c31d4feb00faa1\",\"venue\":\"Machine Learning\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1704.03899\",\"authors\":[{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145779951\",\"name\":\"X. Wang\"},{\"authorId\":\"145002061\",\"name\":\"N. Zhang\"},{\"authorId\":\"2936952\",\"name\":\"Xutao Lv\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"}],\"doi\":\"10.1109/CVPR.2017.128\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"title\":\"Deep Reinforcement Learning-Based Image Captioning with Embedding Reward\",\"url\":\"https://www.semanticscholar.org/paper/c689f73f8ea65c6e81c628f2b37feae09b29e46b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1704.03084\",\"authors\":[{\"authorId\":\"1780690\",\"name\":\"Baolin Peng\"},{\"authorId\":\"40286474\",\"name\":\"Xiujun Li\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1744734\",\"name\":\"Sungjin Lee\"},{\"authorId\":\"1784988\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/D17-1237\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4340bc4c7d1cad07a4f649a148dd6c18d228199\",\"title\":\"Composite Task-Completion Dialogue Policy Learning via Hierarchical Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c4340bc4c7d1cad07a4f649a148dd6c18d228199\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Farhadi\"},{\"authorId\":null,\"name\":\"I. Laptev\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Weakly supervised dense video captioning Frame - and segmentlevel features and candidate pool evaluation for video caption generation\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1705.00754\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"3260219\",\"name\":\"F. Ren\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.83\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"title\":\"Dense-Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/96dd1fc39a368d23291816d57763bc6eb4f7b8d6\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"1760868\",\"name\":\"M. Surdeanu\"},{\"authorId\":\"144661918\",\"name\":\"John Bauer\"},{\"authorId\":\"2784228\",\"name\":\"Jenny Rose Finkel\"},{\"authorId\":\"2105138\",\"name\":\"Steven Bethard\"},{\"authorId\":\"2240597\",\"name\":\"D. McClosky\"}],\"doi\":\"10.3115/v1/P14-5010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"title\":\"The Stanford CoreNLP Natural Language Processing Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/2f5102ec3f70d0dea98c957cc2cab4d15d83a2da\",\"venue\":\"ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"48099761\",\"name\":\"K. Paliwal\"}],\"doi\":\"10.1109/78.650093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"title\":\"Bidirectional recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":1997},{\"arxivId\":\"1511.03476\",\"authors\":[{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2016.117\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e9a66904559011d48245bba01e55f72246927e77\",\"title\":\"Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e9a66904559011d48245bba01e55f72246927e77\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1804.05448\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/N18-2125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"title\":\"Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":\"1703.01161\",\"authors\":[{\"authorId\":\"9948791\",\"name\":\"A. S. Vezhnevets\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"},{\"authorId\":\"1725157\",\"name\":\"T. Schaul\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"049c6e5736313374c6e594c34b9be89a3a09dced\",\"title\":\"FeUdal Networks for Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/049c6e5736313374c6e594c34b9be89a3a09dced\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152784304\",\"name\":\"A. Kumar\"},{\"authorId\":\"151506072\",\"name\":\"A. Sharma\"},{\"authorId\":\"91318330\",\"name\":\"B. Torre\"},{\"authorId\":\"3976878\",\"name\":\"F. Albericio\"}],\"doi\":\"10.5040/9781474284028.0024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f36224042ba7fccb20af534eb8a764f72f3d6d\",\"title\":\"S\",\"url\":\"https://www.semanticscholar.org/paper/02f36224042ba7fccb20af534eb8a764f72f3d6d\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1509.02971\",\"authors\":[{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"2323922\",\"name\":\"J. Hunt\"},{\"authorId\":\"1863250\",\"name\":\"A. Pritzel\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1968210\",\"name\":\"T. Erez\"},{\"authorId\":\"2109481\",\"name\":\"Y. Tassa\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"024006d4c2a89f7acacc6e4438d156525b60a98f\",\"title\":\"Continuous control with deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/024006d4c2a89f7acacc6e4438d156525b60a98f\",\"venue\":\"ICLR\",\"year\":2016}],\"title\":\"Video Captioning via Hierarchical Reinforcement Learning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Automatic summarization\",\"topicId\":\"36919\",\"url\":\"https://www.semanticscholar.org/topic/36919\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Debugging\",\"topicId\":\"8205\",\"url\":\"https://www.semanticscholar.org/topic/8205\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"}],\"url\":\"https://www.semanticscholar.org/paper/74b284a66e75b65f5970d05bac000fe91243ee49\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"