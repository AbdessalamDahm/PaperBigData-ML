"{\"abstract\":\"Deep models are state-of-the-art for many vision tasks including video action recognition and video captioning. Models are trained to caption or classify activity in videos, but little is known about the evidence used to make such decisions. Grounding decisions made by deep networks has been studied in spatial visual content, giving more insight into model predictions for images. However, such studies are relatively lacking for models of spatiotemporal visual content - videos. In this work, we devise a formulation that simultaneously grounds evidence in space and time, in a single pass, using top-down saliency. We visualize the spatiotemporal cues that contribute to a deep model's classification/captioning output using the model's internal representation. Based on these spatiotemporal cues, we are able to localize segments within a video that correspond with a specific action, or phrase from a caption, without explicitly optimizing/training for these tasks.\",\"arxivId\":\"1711.06778\",\"authors\":[{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\",\"url\":\"https://www.semanticscholar.org/author/3298267\"},{\"authorId\":\"144733334\",\"name\":\"A. Zunino\",\"url\":\"https://www.semanticscholar.org/author/144733334\"},{\"authorId\":\"144118620\",\"name\":\"D. Kim\",\"url\":\"https://www.semanticscholar.org/author/144118620\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\",\"url\":\"https://www.semanticscholar.org/author/1701293\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\",\"url\":\"https://www.semanticscholar.org/author/1727204\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\",\"url\":\"https://www.semanticscholar.org/author/1749590\"}],\"citationVelocity\":8,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582477446\",\"name\":\"Yasser Abdelaziz Dahou Djilali\"},{\"authorId\":\"49863790\",\"name\":\"M. Sayah\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.5220/0008875600270036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cdf14f35966eab2d0e3418cea53715342cfce0\",\"title\":\"3DSAL: An Efficient 3D-CNN Architecture for Video Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43cdf14f35966eab2d0e3418cea53715342cfce0\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4786d50855d9685edcd8642fd11e445a6f84b04\",\"title\":\"I NTERPRETING VIDEO FEATURES : A COMPARISON OF 3 D C ONVOLUTIONAL NETWORKS AND C ONVOLU-TIONAL LSTM NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/d4786d50855d9685edcd8642fd11e445a6f84b04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"145905328\",\"name\":\"Kun He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"title\":\"Text-to-Clip Video Retrieval with Early Fusion and Re-Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a50d2245d46ce0595ddbf25ae9acb8513aa70067\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144113066\",\"name\":\"Le Yang\"}],\"doi\":\"10.1109/ACIIW.2019.8925288\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0165027c8badc923dc7fe7aa75f367a354fc8bd1\",\"title\":\"Multi-Modal Depression Detection and Estimation\",\"url\":\"https://www.semanticscholar.org/paper/0165027c8badc923dc7fe7aa75f367a354fc8bd1\",\"venue\":\"2019 8th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos (ACIIW)\",\"year\":2019},{\"arxivId\":\"2003.06498\",\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"39268286\",\"name\":\"Riccardo Volpi\"},{\"authorId\":\"2128305\",\"name\":\"M. Sameki\"},{\"authorId\":\"49051170\",\"name\":\"Jian-ming Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f66d6defa4b6ba3cfb09b410ec5127e3b65a5f66\",\"title\":\"Explainable Deep Classification Models for Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/f66d6defa4b6ba3cfb09b410ec5127e3b65a5f66\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.01869\",\"authors\":[{\"authorId\":\"51244663\",\"name\":\"Panagiotis Linardos\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"144011211\",\"name\":\"J. J. Nieto\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"title\":\"Simple vs complex temporal recurrences for video saliency prediction\",\"url\":\"https://www.semanticscholar.org/paper/d826cd1c9ad907ae1c57a14740eb84a3075f2725\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2006.03204\",\"authors\":[{\"authorId\":\"50980023\",\"name\":\"Vitali Petsiuk\"},{\"authorId\":\"32503437\",\"name\":\"R. Jain\"},{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"3077833\",\"name\":\"Ashutosh Mehra\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6db706ee5a3ff905a34b78189596c833c00124aa\",\"title\":\"Black-box Explanation of Object Detectors via Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/6db706ee5a3ff905a34b78189596c833c00124aa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145515370\",\"name\":\"Qi Feng\"},{\"authorId\":\"83485244\",\"name\":\"Donghyun Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7bf6995f2fb4eee72c7e3d4213b40aa84620bb09\",\"title\":\"Image Identification with Natural Language Specification\",\"url\":\"https://www.semanticscholar.org/paper/7bf6995f2fb4eee72c7e3d4213b40aa84620bb09\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2005.00375\",\"authors\":[{\"authorId\":\"49970148\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"40560502\",\"name\":\"W. Wang\"},{\"authorId\":\"46947534\",\"name\":\"Z. Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1dbcafe488f5b8153d4e43cae3577a590bd62840\",\"title\":\"A Comprehensive Study on Visual Explanations for Spatio-temporal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1dbcafe488f5b8153d4e43cae3577a590bd62840\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.05410\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdff096ae7f7f72a435481e27623ad1a6276900b\",\"title\":\"Attentive Action and Context Factorization\",\"url\":\"https://www.semanticscholar.org/paper/fdff096ae7f7f72a435481e27623ad1a6276900b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.06342\",\"authors\":[{\"authorId\":\"32326200\",\"name\":\"Umang Bhatt\"},{\"authorId\":\"4990825\",\"name\":\"Alice Xiang\"},{\"authorId\":\"150306966\",\"name\":\"S. Sharma\"},{\"authorId\":\"145689461\",\"name\":\"Adrian Weller\"},{\"authorId\":\"40511120\",\"name\":\"Ankur Taly\"},{\"authorId\":\"12488214\",\"name\":\"Yunhan Jia\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"50610150\",\"name\":\"Ruchir Puri\"},{\"authorId\":\"103223218\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2654106\",\"name\":\"P. Eckersley\"}],\"doi\":\"10.1145/3351095.3375624\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b0f4bd3872bb590d457990ac2b26b29f770fc44\",\"title\":\"Explainable machine learning in deployment\",\"url\":\"https://www.semanticscholar.org/paper/1b0f4bd3872bb590d457990ac2b26b29f770fc44\",\"venue\":\"FAT*\",\"year\":2020},{\"arxivId\":\"2005.00375\",\"authors\":[{\"authorId\":\"152985547\",\"name\":\"Z. Li\"},{\"authorId\":\"40560502\",\"name\":\"W. Wang\"},{\"authorId\":\"121544228\",\"name\":\"Z. Li\"},{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"2003804019\",\"name\":\"Yoichi Sato\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"b9338b7de4b849cb094aa4cbd5b85f9935a4ae00\",\"title\":\"Towards Visually Explaining Video Understanding Networks with Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/b9338b7de4b849cb094aa4cbd5b85f9935a4ae00\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83143774\",\"name\":\"Sofia Krasovskaya\"},{\"authorId\":\"48268905\",\"name\":\"W. J. MacInnes\"}],\"doi\":\"10.3390/vision3040056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"title\":\"Salience Models: A Computational Cognitive Neuroscience Review\",\"url\":\"https://www.semanticscholar.org/paper/f5dbdbb939d6b16c380bb930e7a52196f5d0e7a3\",\"venue\":\"Vision\",\"year\":2019},{\"arxivId\":\"1710.11063\",\"authors\":[{\"authorId\":\"26385257\",\"name\":\"A. Chattopadhyay\"},{\"authorId\":\"144341858\",\"name\":\"Anirban Sarkar\"},{\"authorId\":\"9427827\",\"name\":\"Prantik Howlader\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":\"10.1109/WACV.2018.00097\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be012ed29fc4fc366d6b39514679d838eec1f056\",\"title\":\"Grad-CAM++: Generalized Gradient-Based Visual Explanations for Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/be012ed29fc4fc366d6b39514679d838eec1f056\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1902.01078\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICIP.2019.8803153\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a307c21fdd9a3edff092fe0485399714e53fd7a\",\"title\":\"Saliency Tubes: Visual Explanations for Spatio-Temporal Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7a307c21fdd9a3edff092fe0485399714e53fd7a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26385257\",\"name\":\"A. Chattopadhyay\"},{\"authorId\":\"144341858\",\"name\":\"Anirban Sarkar\"},{\"authorId\":\"9427827\",\"name\":\"Prantik Howlader\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1b79a13087a8e9bc2a4446384145e6f85d4820\",\"title\":\"Grad-CAM++: Improved Visual Explanations for Deep Convolutional Networks.\",\"url\":\"https://www.semanticscholar.org/paper/2c1b79a13087a8e9bc2a4446384145e6f85d4820\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394245031\",\"name\":\"G. Santolini\"},{\"authorId\":\"39337007\",\"name\":\"Paolo Rota\"},{\"authorId\":\"4798907\",\"name\":\"D. Gandolfi\"},{\"authorId\":\"3010504\",\"name\":\"P. Bosetti\"}],\"doi\":\"10.1109/CVPRW.2019.00052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a79076fcea549baca1b1b55b69b77e22cab5c001\",\"title\":\"Cut Quality Estimation in Industrial Laser Cutting Machines: A Machine Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/a79076fcea549baca1b1b55b69b77e22cab5c001\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1810.12514\",\"authors\":[{\"authorId\":\"3250084\",\"name\":\"M. Maghoumi\"},{\"authorId\":\"1726039\",\"name\":\"J. LaViola\"}],\"doi\":\"10.1007/978-3-030-33720-9_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d1f1428cef11b3cbbdf3886b9e76e65bd91cb91e\",\"title\":\"DeepGRU: Deep Gesture Recognition Utility\",\"url\":\"https://www.semanticscholar.org/paper/d1f1428cef11b3cbbdf3886b9e76e65bd91cb91e\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"3393678\",\"name\":\"Jacopo Cavazza\"},{\"authorId\":\"134686414\",\"name\":\"Riccardo Volpi\"},{\"authorId\":\"1389596256\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"37783905\",\"name\":\"Andrea Cavallo\"},{\"authorId\":\"1834966\",\"name\":\"C. Becchio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/s11263-019-01234-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2734eeef756657296857068d386521c58228ef5b\",\"title\":\"Predicting Intentions from Motion: The Subject-Adversarial Adaptation Approach\",\"url\":\"https://www.semanticscholar.org/paper/2734eeef756657296857068d386521c58228ef5b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49243413\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"},{\"authorId\":\"2692770\",\"name\":\"K. Peng\"},{\"authorId\":\"39497207\",\"name\":\"J. Ernst\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2019.2921543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d0a810f622a0d753ef41f32cf963254ba9926b8\",\"title\":\"Guided Attention Inference Network\",\"url\":\"https://www.semanticscholar.org/paper/0d0a810f622a0d753ef41f32cf963254ba9926b8\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1812.02626\",\"authors\":[{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"50980023\",\"name\":\"Vitali Petsiuk\"},{\"authorId\":\"51181816\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba6757fece17165acfc1b9856e06f59b138d19e3\",\"title\":\"Guided Zoom: Questioning Network Evidence for Fine-grained Classification\",\"url\":\"https://www.semanticscholar.org/paper/ba6757fece17165acfc1b9856e06f59b138d19e3\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2002.00367\",\"authors\":[{\"authorId\":\"152509251\",\"name\":\"Joonatan M\\u00e4ntt\\u00e4ri\"},{\"authorId\":\"67200092\",\"name\":\"S. Broom\\u00e9\"},{\"authorId\":\"3248522\",\"name\":\"John Folkesson\"},{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab78636736e978b814af4ecbe42d116bbfbbac1f\",\"title\":\"Interpreting video features: a comparison of 3D convolutional networks and convolutional LSTM networks\",\"url\":\"https://www.semanticscholar.org/paper/ab78636736e978b814af4ecbe42d116bbfbbac1f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09542\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"145263742\",\"name\":\"M. S. Kavitha\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"title\":\"Weakly-Supervised Action Localization and Action Recognition using Global-Local Attention of 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"venue\":\"\",\"year\":2020}],\"corpusId\":3754703,\"doi\":\"10.1109/CVPR.2018.00156\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"ad7fc80a2cc26221c077851f44afbd47e3ab6b46\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Karaman\"},{\"authorId\":null,\"name\":\"L. Seidenari\"},{\"authorId\":null,\"name\":\"A. Del Bimbo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fast saliency based pooling of Fisher encoded dense trajectories\",\"url\":\"\",\"venue\":\"In ECCV THUMOS Workshop,\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"G. Toderici\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Fast saliency based pooling of Fisher encoded dense trajectories Visualizing and understanding recurrent networks\",\"url\":\"\",\"venue\":\"32 nd International Conference on Machine Learning ( ICML )\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2016.341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f3e06ddedd4e6ac799679b65a20e9170a8b753e\",\"title\":\"Temporal Action Detection Using a Statistical Language Model\",\"url\":\"https://www.semanticscholar.org/paper/5f3e06ddedd4e6ac799679b65a20e9170a8b753e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.04938\",\"authors\":[{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"1730156\",\"name\":\"Carlos Guestrin\"}],\"doi\":\"10.1145/2939672.2939778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5091316bb1c6db6c6a813f4391911a5c311fdfe0\",\"title\":\"\\\"Why Should I Trust You?\\\": Explaining the Predictions of Any Classifier\",\"url\":\"https://www.semanticscholar.org/paper/5091316bb1c6db6c6a813f4391911a5c311fdfe0\",\"venue\":\"HLT-NAACL Demos\",\"year\":2016},{\"arxivId\":\"1612.07360\",\"authors\":[{\"authorId\":\"2018561\",\"name\":\"Vasili Ramanishka\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.334\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"76f83380fe193ae8475e660c1c6b12b60521a29f\",\"title\":\"Top-Down Visual Saliency Guided by Captions\",\"url\":\"https://www.semanticscholar.org/paper/76f83380fe193ae8475e660c1c6b12b60521a29f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1703.07814\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2017.617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"title\":\"R-C3D: Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/7f8324dda6261ec293e9705c13a0e96b9ab63474\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Das\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Region convolutional 3 d network for temporal activity detection\",\"url\":\"\",\"venue\":\"The IEEE International Conference on Computer Vision ( ICCV )\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1412.4729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.3115/v1/N15-1173\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cef41606f1e1324b683441e694f0e1c96387abf\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cef41606f1e1324b683441e694f0e1c96387abf\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":\"1503.04069\",\"authors\":[{\"authorId\":\"3035541\",\"name\":\"Klaus Greff\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"2865775\",\"name\":\"J. Koutn\\u00edk\"},{\"authorId\":\"71009239\",\"name\":\"Bastiaan Steunebrink\"},{\"authorId\":\"48974230\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1109/tnnls.2016.2582924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7976c2bacfbb194ddbe7fd10c2e50a545cf4081\",\"title\":\"LSTM: A Search Space Odyssey\",\"url\":\"https://www.semanticscholar.org/paper/a7976c2bacfbb194ddbe7fd10c2e50a545cf4081\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143625300\",\"name\":\"J. Yuan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"1731233\",\"name\":\"A. Kassim\"}],\"doi\":\"10.1109/CVPR.2016.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"title\":\"Temporal Action Localization with Pyramid of Score Distribution Features\",\"url\":\"https://www.semanticscholar.org/paper/374a0df2aa63b26737ee89b6c7df01e59b4d8531\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.06984\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.293\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"title\":\"End-to-End Learning of Action Detection from Frame Glimpses in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bbde7946951d770628cf6b6bcd66c63e4fabb4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9499991\",\"name\":\"Chunshui Cao\"},{\"authorId\":\"1958191\",\"name\":\"X. Liu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"2278628\",\"name\":\"Y. Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"},{\"authorId\":\"145501833\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"48908475\",\"name\":\"C. Huang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/ICCV.2015.338\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2260ad2f72b319b6b30569d451026b6290f5ebee\",\"title\":\"Look and Think Twice: Capturing Top-Down Visual Attention with Feedback Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2260ad2f72b319b6b30569d451026b6290f5ebee\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.6806\",\"authors\":[{\"authorId\":\"2060551\",\"name\":\"Jost Tobias Springenberg\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f84a81f431b18a78bd97f59ed4b9d8eda390970\",\"title\":\"Striving for Simplicity: The All Convolutional Net\",\"url\":\"https://www.semanticscholar.org/paper/0f84a81f431b18a78bd97f59ed4b9d8eda390970\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1703.01515\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"2778637\",\"name\":\"Alireza Zareian\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2017.155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"title\":\"CDC: Convolutional-De-Convolutional Networks for Precise Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/bd3a96a94a9ca7fa62f1aec6e868ca03a56c08b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b42f83a720bd4156113ba5350add2df2673daf0\",\"title\":\"Action Recognition and Detection by Combining Motion and Appearance Features\",\"url\":\"https://www.semanticscholar.org/paper/2b42f83a720bd4156113ba5350add2df2673daf0\",\"venue\":\"\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944541\",\"name\":\"R. J\\u00f3zefowicz\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b8364c21155d3d2cd38ea4c8b8580beba9a3250\",\"title\":\"An Empirical Exploration of Recurrent Network Architectures\",\"url\":\"https://www.semanticscholar.org/paper/5b8364c21155d3d2cd38ea4c8b8580beba9a3250\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1506.01066\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.18653/v1/N16-1082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fafa541419b3756968fe5b3156c6f0257cb29c23\",\"title\":\"Visualizing and Understanding Neural Models in NLP\",\"url\":\"https://www.semanticscholar.org/paper/fafa541419b3756968fe5b3156c6f0257cb29c23\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1312.6034\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71\",\"title\":\"Deep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps\",\"url\":\"https://www.semanticscholar.org/paper/dc6ac3437f0a6e64e4404b1b9d188394f8a3bf71\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1506.02078\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"40be3888daa5c2e5af4d36ae22f690bcc8caf600\",\"title\":\"Visualizing and Understanding Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/40be3888daa5c2e5af4d36ae22f690bcc8caf600\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1608.00507\",\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"145527700\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/s11263-017-1059-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7361e42c5eb0d5438c4294cc7ea3f9a53d326309\",\"title\":\"Top-Down Neural Attention by Excitation Backprop\",\"url\":\"https://www.semanticscholar.org/paper/7361e42c5eb0d5438c4294cc7ea3f9a53d326309\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1512.07155\",\"authors\":[{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1016/j.patcog.2017.01.027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"title\":\"Do less and achieve more: Training CNNs for action recognition utilizing action images from the Web\",\"url\":\"https://www.semanticscholar.org/paper/ba29ba8ec180690fca702ad5d516c3e43a7f0bb8\",\"venue\":\"Pattern Recognit.\",\"year\":2017},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"G. Toderici\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"http: //crcv.ucf.edu/THUMOS14/,\",\"year\":2014},{\"arxivId\":\"1704.03296\",\"authors\":[{\"authorId\":\"25576460\",\"name\":\"Ruth C. Fong\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/ICCV.2017.371\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7380e343dd4547e21d5118b16daf03d021d98c4e\",\"title\":\"Interpretable Explanations of Black Boxes by Meaningful Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/7380e343dd4547e21d5118b16daf03d021d98c4e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2093491\",\"name\":\"M. Oquab\"},{\"authorId\":\"119267979\",\"name\":\"L. Bottou\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2015.7298668\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec679c45e88fa25fec32c30bc7c1b7d7fd0facec\",\"title\":\"Is object localization for free? - Weakly-supervised learning with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/ec679c45e88fa25fec32c30bc7c1b7d7fd0facec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48842639\",\"name\":\"Dotan Kaufman\"},{\"authorId\":\"36813724\",\"name\":\"Gil Levi\"},{\"authorId\":\"1756099\",\"name\":\"Tal Hassner\"},{\"authorId\":\"48519520\",\"name\":\"L. Wolf\"}],\"doi\":\"10.1109/ICCV.2017.20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62e6b749ed5825739aa906021c5e613803d5cbe2\",\"title\":\"Temporal Tessellation: A Unified Approach for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/62e6b749ed5825739aa906021c5e613803d5cbe2\",\"venue\":\"ICCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Oneata\"},{\"authorId\":null,\"name\":\"J. Verbeek\"},{\"authorId\":null,\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The lear submission at thumos\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"Excitation Backprop for RNNs\",\"topics\":[{\"topic\":\"Backpropagation\",\"topicId\":\"11998\",\"url\":\"https://www.semanticscholar.org/topic/11998\"},{\"topic\":\"Top-down and bottom-up design\",\"topicId\":\"96387\",\"url\":\"https://www.semanticscholar.org/topic/96387\"},{\"topic\":\"Internationalization and localization\",\"topicId\":\"69706\",\"url\":\"https://www.semanticscholar.org/topic/69706\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Eb/N0\",\"topicId\":\"2259\",\"url\":\"https://www.semanticscholar.org/topic/2259\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"SSI CEB\",\"topicId\":\"4100152\",\"url\":\"https://www.semanticscholar.org/topic/4100152\"}],\"url\":\"https://www.semanticscholar.org/paper/ad7fc80a2cc26221c077851f44afbd47e3ab6b46\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"