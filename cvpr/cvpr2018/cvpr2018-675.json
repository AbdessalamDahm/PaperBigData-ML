"{\"abstract\":\"In this paper we discuss several forms of spatiotemporal convolutions for video analysis and study their effects on action recognition. Our motivation stems from the observation that 2D CNNs applied to individual frames of the video have remained solid performers in action recognition. In this work we empirically demonstrate the accuracy advantages of 3D CNNs over 2D CNNs within the framework of residual learning. Furthermore, we show that factorizing the 3D convolutional filters into separate spatial and temporal components yields significantly gains in accuracy. Our empirical study leads to the design of a new spatiotemporal convolutional block \\\"R(2+1)D\\\" which produces CNNs that achieve results comparable or superior to the state-of-the-art on Sports-1M, Kinetics, UCF101, and HMDB51.\",\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\",\"url\":\"https://www.semanticscholar.org/author/1687325\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\",\"url\":\"https://www.semanticscholar.org/author/46506697\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\",\"url\":\"https://www.semanticscholar.org/author/1732879\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\",\"url\":\"https://www.semanticscholar.org/author/4439383\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\",\"url\":\"https://www.semanticscholar.org/author/1688882\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\",\"url\":\"https://www.semanticscholar.org/author/2210374\"}],\"citationVelocity\":209,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1612977414\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc093ffc4fd928f3e4873fc3c5466b82798b9d6f\",\"title\":\"Supplementary Material for Speech2Action: Cross-modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc093ffc4fd928f3e4873fc3c5466b82798b9d6f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.10066\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"title\":\"A Better Baseline for AVA\",\"url\":\"https://www.semanticscholar.org/paper/6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36751124\",\"name\":\"Amit Nagpal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5668835305efae2697844a053a3451e25f2b8e9\",\"title\":\"Fine grained action recognition in sports videos\",\"url\":\"https://www.semanticscholar.org/paper/d5668835305efae2697844a053a3451e25f2b8e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49616241\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"146441151\",\"name\":\"Carlos Torres\"},{\"authorId\":\"145631625\",\"name\":\"S. Chandrasekaran\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bde073561cd1df85cf546fca443190fc0beb2a53\",\"title\":\"Complex Pairwise Activity Analysis Via Instance Level Evolution Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/bde073561cd1df85cf546fca443190fc0beb2a53\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2001.06769\",\"authors\":[{\"authorId\":\"151080964\",\"name\":\"Kaiyu Shan\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"},{\"authorId\":\"5744018\",\"name\":\"Z. Wang\"},{\"authorId\":\"47715977\",\"name\":\"Ting-Ting Liang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"},{\"authorId\":\"50581109\",\"name\":\"Y. Chen\"},{\"authorId\":\"1920864\",\"name\":\"Yangyan Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"title\":\"MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion\",\"url\":\"https://www.semanticscholar.org/paper/0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"51066371\",\"name\":\"Yuli Chen\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47767769\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"},{\"authorId\":\"144401327\",\"name\":\"Jing Deng\"}],\"doi\":\"10.1007/s11042-020-09137-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"title\":\"XwiseNet: action recognition with Xwise separable convolutions\",\"url\":\"https://www.semanticscholar.org/paper/08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1912.03613\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"144878724\",\"name\":\"J. Bai\"},{\"authorId\":\"48379752\",\"name\":\"Yufu Zhang\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f888f518c79e52debe6646c68049d87d0b0555cd\",\"title\":\"DASZL: Dynamic Action Signatures for Zero-shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/f888f518c79e52debe6646c68049d87d0b0555cd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.08510\",\"authors\":[{\"authorId\":\"144234446\",\"name\":\"Bo He\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b77967866434f46c41f25baf7149d9b027b600b3\",\"title\":\"GTA: Global Temporal Attention for Video Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b77967866434f46c41f25baf7149d9b027b600b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.09930\",\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/cvpr42600.2020.00113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af06120e7883ff969746ab473bfe09e642a90fc3\",\"title\":\"Something-Else: Compositional Action Recognition With Spatial-Temporal Interaction Networks\",\"url\":\"https://www.semanticscholar.org/paper/af06120e7883ff969746ab473bfe09e642a90fc3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1016/J.INFRARED.2019.103014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"title\":\"Deep residual infrared action recognition by integrating local and global spatio-temporal cues\",\"url\":\"https://www.semanticscholar.org/paper/45b4b470fb2f4af1f4dfbea32edd517161b51ad1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.08804\",\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"1840060274\",\"name\":\"Yuhan Cao\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"700233fa6e243a056e4243f89b2f32b2cdcc86b9\",\"title\":\"Temporal Graph Modeling for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/700233fa6e243a056e4243f89b2f32b2cdcc86b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3224057\",\"name\":\"Junhua Liao\"},{\"authorId\":\"1406501395\",\"name\":\"Haihan Duan\"},{\"authorId\":\"50080172\",\"name\":\"X. Li\"},{\"authorId\":\"4986840\",\"name\":\"Hao-ran Xu\"},{\"authorId\":\"9075649\",\"name\":\"Yanbing Yang\"},{\"authorId\":\"1382480464\",\"name\":\"Wei Cai\"},{\"authorId\":\"49069379\",\"name\":\"Y. Chen\"},{\"authorId\":\"150185267\",\"name\":\"Liangyin Chen\"}],\"doi\":\"10.1145/3394171.3413725\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4401b19a38aca534640af392cc797c3e45640ff7\",\"title\":\"Occlusion Detection for Automatic Video Editing\",\"url\":\"https://www.semanticscholar.org/paper/4401b19a38aca534640af392cc797c3e45640ff7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651582\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1916963\",\"name\":\"Y. Shen\"},{\"authorId\":\"89080361\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ICMEW.2019.00034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"title\":\"Deep Key Clips-Video Feature Fusion Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48459568\",\"name\":\"C. Tsai\"},{\"authorId\":\"1718402\",\"name\":\"Ching-Chi Lin\"},{\"authorId\":\"38244340\",\"name\":\"Pangfeng Liu\"},{\"authorId\":\"1726584\",\"name\":\"Jan-Jan Wu\"}],\"doi\":\"10.1109/PADSW.2018.8644593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0440ac3b9fa7b53fe801bad3d8476febd766337\",\"title\":\"Communication Scheduling Optimization for Distributed Deep Learning Systems\",\"url\":\"https://www.semanticscholar.org/paper/f0440ac3b9fa7b53fe801bad3d8476febd766337\",\"venue\":\"2018 IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799396193\",\"name\":\"Zhengying Liu\"},{\"authorId\":\"80334935\",\"name\":\"Adrien Pavao\"},{\"authorId\":\"1819682268\",\"name\":\"Zhen Xu\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1702788\",\"name\":\"F. Ferreira\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"2004160930\",\"name\":\"Sirui Hong\"},{\"authorId\":\"1702307574\",\"name\":\"Frank Hutter\"},{\"authorId\":\"1472906851\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"39140182\",\"name\":\"J. J. Junior\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"},{\"authorId\":\"145963266\",\"name\":\"M. Lindauer\"},{\"authorId\":\"2461112\",\"name\":\"Z. Luo\"},{\"authorId\":\"50161696\",\"name\":\"M. Madadi\"},{\"authorId\":\"3256005\",\"name\":\"Thomas Nierhoff\"},{\"authorId\":\"121870519\",\"name\":\"K. Niu\"},{\"authorId\":\"146411937\",\"name\":\"Chunguang Pan\"},{\"authorId\":\"66406101\",\"name\":\"D. Stoll\"},{\"authorId\":\"9588057\",\"name\":\"S\\u00e9bastien Treguer\"},{\"authorId\":\"46584713\",\"name\":\"J. Wang\"},{\"authorId\":\"145498819\",\"name\":\"P. Wang\"},{\"authorId\":\"2867893\",\"name\":\"Cheng-Lin Wu\"},{\"authorId\":\"2004229421\",\"name\":\"Youcheng Xiong\"},{\"authorId\":\"51109984\",\"name\":\"Arber Zela\"},{\"authorId\":\"40600423\",\"name\":\"Yali Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60ba10c4630fce2e46d64fb915e7a1f827c2d88b\",\"title\":\"Winning solutions and post-challenge analyses of the ChaLearn AutoDL challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/60ba10c4630fce2e46d64fb915e7a1f827c2d88b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13364\",\"authors\":[{\"authorId\":\"37813096\",\"name\":\"Sulaiman Vesal\"},{\"authorId\":\"2041056766\",\"name\":\"Mingxuan Gu\"},{\"authorId\":\"72274494\",\"name\":\"A. Maier\"},{\"authorId\":\"3322489\",\"name\":\"N. Ravikumar\"}],\"doi\":\"10.1109/JBHI.2020.3046449\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83c03ff8913b82d8003b2ebe3d286c72675b72a3\",\"title\":\"Spatio-temporal Multi-task Learning for Cardiac MRI Left Ventricle Quantification.\",\"url\":\"https://www.semanticscholar.org/paper/83c03ff8913b82d8003b2ebe3d286c72675b72a3\",\"venue\":\"IEEE journal of biomedical and health informatics\",\"year\":2020},{\"arxivId\":\"2012.11673\",\"authors\":[{\"authorId\":\"1900466056\",\"name\":\"Sirjan Kafle\"},{\"authorId\":\"1633418058\",\"name\":\"Aman Gupta\"},{\"authorId\":\"1410725735\",\"name\":\"Xue Xia\"},{\"authorId\":\"145630384\",\"name\":\"A. Sankar\"},{\"authorId\":\"46772427\",\"name\":\"X. Chen\"},{\"authorId\":\"144006576\",\"name\":\"D. Wen\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18d91abf683d10837f384c1b4c9a3f9f90cf3e87\",\"title\":\"Smoothed Gaussian Mixture Models for Video Classification and Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/18d91abf683d10837f384c1b4c9a3f9f90cf3e87\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.00753\",\"authors\":[{\"authorId\":\"150308094\",\"name\":\"Samuel Henrique Silva\"},{\"authorId\":\"71756373\",\"name\":\"Peyman Najafirad\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a53dd7f3a7590a2058372410820c8086be109ec8\",\"title\":\"Opportunities and Challenges in Deep Learning Adversarial Robustness: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/a53dd7f3a7590a2058372410820c8086be109ec8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49741227\",\"name\":\"Haifeng Sang\"},{\"authorId\":\"152254334\",\"name\":\"Z. Zhao\"},{\"authorId\":\"3030181\",\"name\":\"Dakuo He\"}],\"doi\":\"10.1109/ACCESS.2019.2936628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"title\":\"Two-Level Attention Model Based Video Action Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"33532407\",\"name\":\"S. Cha\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"},{\"authorId\":\"40656963\",\"name\":\"Soonmin Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.01212\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96c0ba91d650c571d20961f1fae0560f8962afa5\",\"title\":\"Regularization on Spatio-Temporally Smoothed Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96c0ba91d650c571d20961f1fae0560f8962afa5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.06754\",\"authors\":[{\"authorId\":\"2498892\",\"name\":\"Pengxiang Wu\"},{\"authorId\":\"145552439\",\"name\":\"Siheng Chen\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/cvpr42600.2020.01140\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e84232f179034b039bfc4d1dae3c91c1a50bfa2\",\"title\":\"MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Bird\\u2019s Eye View Maps\",\"url\":\"https://www.semanticscholar.org/paper/5e84232f179034b039bfc4d1dae3c91c1a50bfa2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"title\":\"Unseen Action Recognition with Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963124\",\"name\":\"Huanan Dong\"},{\"authorId\":\"48960121\",\"name\":\"Ming Yang Wen\"},{\"authorId\":\"2016529\",\"name\":\"Zhouwang Yang\"}],\"doi\":\"10.3390/FI11060123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df8b25ac1a6cc8777b975bc9f5bee37c0c36de2f\",\"title\":\"Vehicle Speed Estimation Based on 3D ConvNets and Non-Local Blocks\",\"url\":\"https://www.semanticscholar.org/paper/df8b25ac1a6cc8777b975bc9f5bee37c0c36de2f\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"47e1b171fab52368f14f41955cdc7ca7775ded58\",\"title\":\"RGB TVL 1 Flow RGB + TVL 1 FlowMARS MARS + RGB MERS MERS + RGB Accuracy vs Time on MiniKinetics\",\"url\":\"https://www.semanticscholar.org/paper/47e1b171fab52368f14f41955cdc7ca7775ded58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.01725\",\"authors\":[{\"authorId\":\"27555915\",\"name\":\"Tz-Ying Wu\"},{\"authorId\":\"9618379\",\"name\":\"Juan-Ting Lin\"},{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"27538483\",\"name\":\"Chan-Wei Hu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1007/978-3-030-01252-6_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"title\":\"Liquid Pouring Monitoring via Rich Sensory Inputs\",\"url\":\"https://www.semanticscholar.org/paper/e8b3a257a0a44d2859862cdec91c8841dc69144d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33856466\",\"name\":\"C. Sandino\"},{\"authorId\":\"51402390\",\"name\":\"P. Lai\"},{\"authorId\":\"2081096\",\"name\":\"S. Vasanawala\"},{\"authorId\":\"144891194\",\"name\":\"Joseph Y. Cheng\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d8c4e15bc2a6cabd09210477563a62bdf1fe77b\",\"title\":\"Accelerating cardiac cine MRI beyond compressed sensing using DL-ESPIRiT\",\"url\":\"https://www.semanticscholar.org/paper/9d8c4e15bc2a6cabd09210477563a62bdf1fe77b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.03044\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"47120072\",\"name\":\"Xizi Wang\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"41066643\",\"name\":\"Zelin Pu\"},{\"authorId\":\"153499091\",\"name\":\"E. Atkins\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a8be994e7069236d94e30c4c7b481988effc106\",\"title\":\"When, Where, and What? A New Dataset for Anomaly Detection in Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/9a8be994e7069236d94e30c4c7b481988effc106\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.15464\",\"authors\":[{\"authorId\":\"1720851638\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"title\":\"Self-Supervised Video Representation Using Pretext-Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"3190022\",\"name\":\"Danping Liao\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICCVW.2019.00543\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"title\":\"Learning Spatiotemporal Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3351029\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"933f2a39e35018db2442c08f7603a14a70efb06b\",\"title\":\"Fast Non-Local Neural Networks with Spectral Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/933f2a39e35018db2442c08f7603a14a70efb06b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1803.06316\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"title\":\"Temporal Gaussian Mixture Layer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1907.13487\",\"authors\":[{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"title\":\"Use What You Have: Video retrieval using representations from collaborative experts\",\"url\":\"https://www.semanticscholar.org/paper/b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286259\",\"name\":\"JianYu Wang\"},{\"authorId\":\"51235164\",\"name\":\"Jianxin Chen\"},{\"authorId\":\"1768588917\",\"name\":\"Yihao Cai\"}],\"doi\":\"10.1117/12.2574424\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d279c051e5884041e66e1c5411415d74081effa3\",\"title\":\"A framework for multimodal sign language recognition under small sample based on key-frame sampling\",\"url\":\"https://www.semanticscholar.org/paper/d279c051e5884041e66e1c5411415d74081effa3\",\"venue\":\"International Workshop on Pattern Recognition\",\"year\":2020},{\"arxivId\":\"2001.06499\",\"authors\":[{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"152230789\",\"name\":\"Shengju Qian\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6872\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a573c125e85d1230626c8f3cf6193354f753958d\",\"title\":\"Temporal Interlacing Network\",\"url\":\"https://www.semanticscholar.org/paper/a573c125e85d1230626c8f3cf6193354f753958d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81188084\",\"name\":\"Saima Nazir\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"},{\"authorId\":\"145643264\",\"name\":\"E. Izquierdo\"},{\"authorId\":\"30902466\",\"name\":\"Eduard Vazquez\"}],\"doi\":\"10.5220/0007371104200426\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"title\":\"Human Action Recognition using Multi-Kernel Learning for Temporal Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.06576\",\"authors\":[{\"authorId\":\"40133394\",\"name\":\"Hongnian Wang\"},{\"authorId\":\"2518568\",\"name\":\"H. Su\"}],\"doi\":\"10.1109/MDM.2019.00-44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ac4550d9cc6ab47162f3921eaa2d0cca6279ec5\",\"title\":\"STAR: A Concise Deep Learning Framework for Citywide Human Mobility Prediction\",\"url\":\"https://www.semanticscholar.org/paper/8ac4550d9cc6ab47162f3921eaa2d0cca6279ec5\",\"venue\":\"2019 20th IEEE International Conference on Mobile Data Management (MDM)\",\"year\":2019},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596821842\",\"name\":\"Yao Luo\"},{\"authorId\":\"2657905\",\"name\":\"Zhong-Hui Duan\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"}],\"doi\":\"10.1016/j.cviu.2020.103100\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b246717103c240b44b420daf5ff6686f52c557c\",\"title\":\"Bi-branch network for dynamic scene deblurring\",\"url\":\"https://www.semanticscholar.org/paper/6b246717103c240b44b420daf5ff6686f52c557c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152991070\",\"name\":\"Yanyan Song\"},{\"authorId\":\"144539547\",\"name\":\"L. Tan\"},{\"authorId\":\"1691036\",\"name\":\"L. Zhou\"},{\"authorId\":\"153010694\",\"name\":\"Xinyue Lv\"},{\"authorId\":\"1481816621\",\"name\":\"Zihao Ma\"}],\"doi\":\"10.1007/978-3-030-57881-7_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13095711fbcd69d1a9897392b465ab2a25eab81d\",\"title\":\"Video Action Recognition Based on Hybrid Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/13095711fbcd69d1a9897392b465ab2a25eab81d\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":\"2008.12085\",\"authors\":[{\"authorId\":\"2088061\",\"name\":\"Juan Diego Ortega\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"1910490649\",\"name\":\"Paola Canas\"},{\"authorId\":\"3319539\",\"name\":\"Min-An Chao\"},{\"authorId\":\"71814613\",\"name\":\"A. Unnervik\"},{\"authorId\":\"144931363\",\"name\":\"M. Nieto\"},{\"authorId\":\"2353401\",\"name\":\"O. Otaegui\"},{\"authorId\":\"144180623\",\"name\":\"L. Salgado\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"89764b01e004ad39256e0351fef9acea3eecf747\",\"title\":\"DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention and Alertness Analysis\",\"url\":\"https://www.semanticscholar.org/paper/89764b01e004ad39256e0351fef9acea3eecf747\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"38df033adc8b89ad02a638db823be439260113bd\",\"title\":\"Tiny Video Networks: Architecture Search for Efficient Video Models\",\"url\":\"https://www.semanticscholar.org/paper/38df033adc8b89ad02a638db823be439260113bd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"144811736\",\"name\":\"L. Jiang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eb604863b671763de17905ad715a225d9fe43e9\",\"title\":\"Unit Frame 3 : T + 2 Frame 1 : T Frame 2 : T + 1 FrameT + 1 FrameT + 2 FrameT + 3\",\"url\":\"https://www.semanticscholar.org/paper/2eb604863b671763de17905ad715a225d9fe43e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181811\",\"name\":\"J. Zhang\"},{\"authorId\":\"47779342\",\"name\":\"Yutong Xie\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":null,\"name\":\"Hao Chen\"},{\"authorId\":\"49289855\",\"name\":\"Y. Xia\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.24963/ijcai.2019/593\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f07486a42470219d8e08e764a9c988e5eeea7622\",\"title\":\"Light-Weight Hybrid Convolutional Network for Liver Tumor Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f07486a42470219d8e08e764a9c988e5eeea7622\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739631130\",\"name\":\"Fanjia Li\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"50125448\",\"name\":\"Yonggang Xu\"},{\"authorId\":\"8159002\",\"name\":\"Ran Cui\"},{\"authorId\":\"49195402\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ACCESS.2020.2996779\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2580a93582f9a28bf66982cfa51022089a6e337b\",\"title\":\"Multi-Stream and Enhanced Spatial-Temporal Graph Convolution Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2580a93582f9a28bf66982cfa51022089a6e337b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.12004\",\"authors\":[{\"authorId\":\"2028357556\",\"name\":\"Racha Friji\"},{\"authorId\":\"2641251\",\"name\":\"H. Drira\"},{\"authorId\":\"2446036\",\"name\":\"F. Chaieb\"},{\"authorId\":\"145766926\",\"name\":\"S. Kurtek\"},{\"authorId\":\"2028357554\",\"name\":\"Hamza Kchok\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ae03c97b1a6bfa3546646ab654c5bf652c0f12c\",\"title\":\"KShapeNet: Riemannian network on Kendall shape space for Skeleton based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae03c97b1a6bfa3546646ab654c5bf652c0f12c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.08860\",\"authors\":[{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"47172195\",\"name\":\"S. Ramamoorthy\"}],\"doi\":\"10.1016/j.neunet.2020.09.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f313226533edea306c4de79df945cc5a90d153c\",\"title\":\"Lower Dimensional Kernels for Video Discriminators\",\"url\":\"https://www.semanticscholar.org/paper/1f313226533edea306c4de79df945cc5a90d153c\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":\"2006.11476\",\"authors\":[{\"authorId\":\"1390925224\",\"name\":\"Y. Yao\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"}],\"doi\":\"10.1109/cvpr42600.2020.00658\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"title\":\"Video Playback Rate Perception for Self-Supervised Spatio-Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/15e8b0a6366e29c7093ecf844eb40d03d8004abb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27720832\",\"name\":\"T. Long\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"title\":\"Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"101980376\",\"name\":\"F. Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b7214890681dda4ff5e86fa44c900287f3788eb\",\"title\":\"Supplementary Material: Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/8b7214890681dda4ff5e86fa44c900287f3788eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"2020817\",\"name\":\"Ming Zeng\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":\"10.1109/ICCEA50009.2020.00132\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b27c9dc2c2d4ed237d9b0c0605d25e76ff650609\",\"title\":\"Temporal Recursive Propagation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b27c9dc2c2d4ed237d9b0c0605d25e76ff650609\",\"venue\":\"2020 International Conference on Computer Engineering and Application (ICCEA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993657441\",\"name\":\"Beibei Lin\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"39677488\",\"name\":\"F. Bao\"}],\"doi\":\"10.1145/3394171.3413861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7d3b24dd73d35f358da1265709dbcab848593a5\",\"title\":\"Gait Recognition with Multiple-Temporal-Scale 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a7d3b24dd73d35f358da1265709dbcab848593a5\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2002.12177\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/cvpr42600.2020.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cb1b739f32641938485b714a186fb705d0b0215\",\"title\":\"Evolving Losses for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3cb1b739f32641938485b714a186fb705d0b0215\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144575264\",\"name\":\"H. Chen\"},{\"authorId\":\"152141369\",\"name\":\"Yifan Deng\"},{\"authorId\":\"2998493\",\"name\":\"Shiwen Cheng\"},{\"authorId\":null,\"name\":\"Yixuan Wang\"},{\"authorId\":\"48219791\",\"name\":\"Dongmei Jiang\"},{\"authorId\":\"151486921\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1145/3347320.3357690\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d9ff2905896fa52fd9296d75e2de27ffa59f9f1\",\"title\":\"Efficient Spatial Temporal Convolutional Features for Audiovisual Continuous Affect Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d9ff2905896fa52fd9296d75e2de27ffa59f9f1\",\"venue\":\"AVEC@MM\",\"year\":2019},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491085071\",\"name\":\"Xiafei Yu\"},{\"authorId\":\"1728718\",\"name\":\"Jiying Zhao\"}],\"doi\":\"10.1109/GlobalSIP45357.2019.8969481\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefdaec91f85a2bd3d44a5e8189e099d3748e58f\",\"title\":\"Wide Separate 3D Convolution for Video Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/eefdaec91f85a2bd3d44a5e8189e099d3748e58f\",\"venue\":\"2019 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2019},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.03249\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"40897068\",\"name\":\"Xin Chen\"},{\"authorId\":\"23614019\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76db87564c7e6a6f417fca41b9f659a879de5027\",\"title\":\"Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/76db87564c7e6a6f417fca41b9f659a879de5027\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.08711\",\"authors\":[{\"authorId\":\"48085995\",\"name\":\"A. Kozlov\"},{\"authorId\":\"117171023\",\"name\":\"V. Andronov\"},{\"authorId\":\"122388064\",\"name\":\"Y. Gritsenko\"}],\"doi\":\"10.1145/3341105.3373906\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4262413c55cf0319922c42b796c74879a0632a8\",\"title\":\"Lightweight network architecture for real-time action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4262413c55cf0319922c42b796c74879a0632a8\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"2012.14259\",\"authors\":[{\"authorId\":\"3413560\",\"name\":\"C. Palmero\"},{\"authorId\":\"38081877\",\"name\":\"J. Selva\"},{\"authorId\":\"14556193\",\"name\":\"Sorina Smeureanu\"},{\"authorId\":\"39140182\",\"name\":\"J. J. Junior\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"2042751973\",\"name\":\"Alexa Mosegu'i\"},{\"authorId\":\"2437263\",\"name\":\"Z. Zhang\"},{\"authorId\":\"145182692\",\"name\":\"D. Gallardo\"},{\"authorId\":\"6282552\",\"name\":\"G. Guilera\"},{\"authorId\":\"116209576\",\"name\":\"D. Leiva\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55afa75a545cf4949372b264c558c7555551a504\",\"title\":\"Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset\",\"url\":\"https://www.semanticscholar.org/paper/55afa75a545cf4949372b264c558c7555551a504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.08357\",\"authors\":[{\"authorId\":\"1712217403\",\"name\":\"Yinhao Li\"},{\"authorId\":\"3153697\",\"name\":\"Y. Iwamoto\"},{\"authorId\":\"46456175\",\"name\":\"Lanfen Lin\"},{\"authorId\":\"1606128526\",\"name\":\"Rui Xu\"},{\"authorId\":\"123332138\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2878f86c947699f88054d0d342e360ce854504e\",\"title\":\"VolumeNet: A Lightweight Parallel Network for Super-Resolution of Medical Volumetric Data\",\"url\":\"https://www.semanticscholar.org/paper/d2878f86c947699f88054d0d342e360ce854504e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44e8ddac792f35105dd4db176345515f531a0b71\",\"title\":\"Bottom-Up Temporal Action Localization with Mutual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/44e8ddac792f35105dd4db176345515f531a0b71\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.01341\",\"authors\":[{\"authorId\":\"47087136\",\"name\":\"Zhaoyang Yang\"},{\"authorId\":\"113515522\",\"name\":\"Zhenmei Shi\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd712a873ae4eefb6c623c8e605e42c5a0173e3e\",\"title\":\"SF-Net: Structured Feature Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bd712a873ae4eefb6c623c8e605e42c5a0173e3e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.13209\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"title\":\"AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures\",\"url\":\"https://www.semanticscholar.org/paper/a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646959833\",\"name\":\"Yuecong Min\"},{\"authorId\":\"152550038\",\"name\":\"Xiujuan Chai\"},{\"authorId\":\"9055516\",\"name\":\"L. Zhao\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb74477f987459e27bc6b667b4535c378442bd6b\",\"title\":\"FlickerNet: Adaptive 3D Gesture Recognition from Sparse Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/fb74477f987459e27bc6b667b4535c378442bd6b\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1907.01847\",\"authors\":[{\"authorId\":\"73383712\",\"name\":\"W. Li\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"144585903\",\"name\":\"L. Huang\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"title\":\"Deformable Tube Network for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c33e9aaec527dfeb733fc10c1d2bda417f546b37\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121213082\",\"name\":\"Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"title\":\"Few-Shot Video Classification via Temporal Alignment Kaidi\",\"url\":\"https://www.semanticscholar.org/paper/03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39816387\",\"name\":\"C. Li\"},{\"authorId\":\"144916982\",\"name\":\"Zhi Hou\"},{\"authorId\":\"35843399\",\"name\":\"Jiaxu Chen\"},{\"authorId\":\"3272118\",\"name\":\"Yilei Bu\"},{\"authorId\":\"9162532\",\"name\":\"Jiqiang Zhou\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"50322310\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac559873b288f3ac28ee8a38c0f3710ea3f986d9\",\"title\":\"Team DEEP-HRI Moments in Time Challenge 2018 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/ac559873b288f3ac28ee8a38c0f3710ea3f986d9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.07157\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"title\":\"Recurrence to the Rescue: Towards Causal Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92533069\",\"name\":\"L. Chi\"},{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"title\":\"Non-Local Neural Networks With Grouped Bilinear Attentional Transforms\",\"url\":\"https://www.semanticscholar.org/paper/6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"47957191\",\"name\":\"Xiao-yun Zhang\"},{\"authorId\":\"1490938774\",\"name\":\"Haiyan Wu\"}],\"doi\":\"10.1109/VCIP47243.2019.8965768\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5acec6921c4015a3fb252bc18645b33d416b8784\",\"title\":\"Improving Action Recognition with the Graph-Neural-Network-based Interaction Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/5acec6921c4015a3fb252bc18645b33d416b8784\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"88728572\",\"name\":\"Yalong Jia\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"title\":\"Channel-wise Temporal Attention Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121638702\",\"name\":\"Jungin Park\"},{\"authorId\":\"82536700\",\"name\":\"J. Lee\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICCVW.2019.00193\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"title\":\"Video Summarization by Learning Relationships between Action and Scene\",\"url\":\"https://www.semanticscholar.org/paper/62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657366361\",\"name\":\"Hanzao Chen\"},{\"authorId\":\"2667341\",\"name\":\"Xiaofen Xing\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b3e313a139b0f2f9ae09d4137485e8f277732aa\",\"title\":\"Learning Spatio-Temporal Convolutional Network for Real-Time Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/6b3e313a139b0f2f9ae09d4137485e8f277732aa\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2023281907\",\"name\":\"Alberto Calo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"585dcd9a7332583044a77d9489338ab8eaba0fc8\",\"title\":\"Deep neural networks for detection of solar corona mass ejections\",\"url\":\"https://www.semanticscholar.org/paper/585dcd9a7332583044a77d9489338ab8eaba0fc8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1474224022\",\"name\":\"Sun'ao Liu\"},{\"authorId\":\"145802910\",\"name\":\"H. Xu\"},{\"authorId\":\"46399157\",\"name\":\"Yizhi Liu\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"}],\"doi\":\"10.1007/978-3-030-37731-1_59\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85ef1569b2b18212629016f082878b3df04dcc61\",\"title\":\"Improving Brain Tumor Segmentation with Dilated Pseudo-3D Convolution and Multi-direction Fusion\",\"url\":\"https://www.semanticscholar.org/paper/85ef1569b2b18212629016f082878b3df04dcc61\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/WACV45572.2020.9093492\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"title\":\"ImaGINator: Conditional Spatio-Temporal GAN for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"46737456\",\"name\":\"Pu Zhao\"},{\"authorId\":\"32661932\",\"name\":\"M. Gungor\"},{\"authorId\":\"69467609\",\"name\":\"M. Pedram\"},{\"authorId\":\"1710866\",\"name\":\"M. Leeser\"},{\"authorId\":\"145282404\",\"name\":\"X. Lin\"}],\"doi\":\"10.1109/DAC18072.2020.9218571\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8fc582afcb3b81b724ea2af73175ae3c594cef0c\",\"title\":\"3D CNN Acceleration on FPGA using Hardware-Aware Pruning\",\"url\":\"https://www.semanticscholar.org/paper/8fc582afcb3b81b724ea2af73175ae3c594cef0c\",\"venue\":\"2020 57th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2020},{\"arxivId\":\"2001.10953\",\"authors\":[{\"authorId\":\"1491010174\",\"name\":\"Nihar Bendre\"},{\"authorId\":\"51182462\",\"name\":\"Nima Ebadi\"},{\"authorId\":\"39409158\",\"name\":\"John J. Prevost\"},{\"authorId\":\"71756373\",\"name\":\"Peyman Najafirad\"}],\"doi\":\"10.1109/ACCESS.2020.2982364\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6de953ddfb8349de892772edccfcffb0d58dd59\",\"title\":\"Human Action Performance Using Deep Neuro-Fuzzy Recurrent Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/a6de953ddfb8349de892772edccfcffb0d58dd59\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445655\",\"name\":\"C. Zhang\"},{\"authorId\":\"49663261\",\"name\":\"W. Liu\"},{\"authorId\":\"91945776\",\"name\":\"J. Wu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/BigMM.2019.00-27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de265804b8a955308f42fee71d01dfe45fe83f3b\",\"title\":\"Improving Action Recognition with Valued Patches Exploiting\",\"url\":\"https://www.semanticscholar.org/paper/de265804b8a955308f42fee71d01dfe45fe83f3b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752781688\",\"name\":\"Siyuan Yang\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"50345079\",\"name\":\"Shijian Lu\"},{\"authorId\":\"9412318\",\"name\":\"M. Er\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1007/978-3-030-58580-8_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcafbfa5030fe96fb7e39764d72742ccb58dc6a2\",\"title\":\"Collaborative Learning of Gesture Recognition and 3D Hand Pose Estimation with Multi-order Feature Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dcafbfa5030fe96fb7e39764d72742ccb58dc6a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11844\",\"authors\":[{\"authorId\":\"24060014\",\"name\":\"Ipek Ganiyusufoglu\"},{\"authorId\":\"72187685\",\"name\":\"L. M. Ngo\"},{\"authorId\":\"1557601824\",\"name\":\"N. Savov\"},{\"authorId\":\"1968574\",\"name\":\"Sezer Karaoglu\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c6b9e7f0d35690a30a41b090ddba33fd5fe4b8c6\",\"title\":\"Spatio-temporal Features for Generalized Detection of Deepfake Videos\",\"url\":\"https://www.semanticscholar.org/paper/c6b9e7f0d35690a30a41b090ddba33fd5fe4b8c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.13426\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b38e482488359da26a25ed9ef5341cd38a2b6562\",\"title\":\"Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b38e482488359da26a25ed9ef5341cd38a2b6562\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50699209\",\"name\":\"B. Yang\"},{\"authorId\":\"145313443\",\"name\":\"P. Zhou\"}],\"doi\":\"10.1117/12.2540276\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7bcea6e7382735bcac5c5675412003c75550ffac\",\"title\":\"Mixed 3D-(2+1)D convolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7bcea6e7382735bcac5c5675412003c75550ffac\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":\"1908.04121\",\"authors\":[{\"authorId\":\"13380914\",\"name\":\"Z. Zou\"},{\"authorId\":\"114850729\",\"name\":\"Huiliang Shao\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77ec81da5cbef787547a205328cea6f85b921e1d\",\"title\":\"Enhanced 3D convolutional networks for crowd counting\",\"url\":\"https://www.semanticscholar.org/paper/77ec81da5cbef787547a205328cea6f85b921e1d\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674907\",\"name\":\"Lili Meng\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"115284322\",\"name\":\"W. Sun\"},{\"authorId\":\"1402348340\",\"name\":\"Frederich Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCVW.2019.00189\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"title\":\"Interpretable Spatio-Temporal Attention for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1901.09403\",\"authors\":[{\"authorId\":\"41049768\",\"name\":\"Amlaan Bhoi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"title\":\"Spatio-temporal Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.02426\",\"authors\":[{\"authorId\":\"1879292723\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"2029317446\",\"name\":\"Ting Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e84c8a5b818d6c121083550bae9bda257a4df60f\",\"title\":\"Spatial-Temporal Alignment Network for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/e84c8a5b818d6c121083550bae9bda257a4df60f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.02536\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-20870-7_44\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"929c8a73fceb88148847c6abca98a4d413d15415\",\"title\":\"Dynamic Temporal Pyramid Network: A Closer Look at Multi-Scale Modeling for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/929c8a73fceb88148847c6abca98a4d413d15415\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1811.12814\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"}],\"doi\":\"10.1109/CVPR.2019.00052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6\",\"title\":\"Graph-Based Global Reasoning Networks\",\"url\":\"https://www.semanticscholar.org/paper/1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.05907\",\"authors\":[{\"authorId\":\"153108483\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"},{\"authorId\":\"10114692\",\"name\":\"Hong Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"title\":\"A Survey on 3D Skeleton-Based Action Recognition Using Learning Method\",\"url\":\"https://www.semanticscholar.org/paper/0a8196cd5905812dbdfb87096bcb7d2433ede93e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.04714\",\"authors\":[{\"authorId\":\"2008170713\",\"name\":\"Eric Muller-Budack\"},{\"authorId\":\"3430468\",\"name\":\"Matthias Springstein\"},{\"authorId\":\"2079305\",\"name\":\"Sherzod Hakimov\"},{\"authorId\":\"2008172383\",\"name\":\"Kevin Mrutzek\"},{\"authorId\":\"1738703\",\"name\":\"R. Ewerth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"752e0b0cd96083b1469469c087fc88b8aacd8589\",\"title\":\"Ontology-driven Event Type Classification in Images\",\"url\":\"https://www.semanticscholar.org/paper/752e0b0cd96083b1469469c087fc88b8aacd8589\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.07563\",\"authors\":[{\"authorId\":\"74480447\",\"name\":\"Manjot Bilkhu\"},{\"authorId\":\"87779441\",\"name\":\"H. Ayyubi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d29074a0e2dee3d394b51669a9ec5297c008e469\",\"title\":\"Human Activity Recognition for Edge Devices\",\"url\":\"https://www.semanticscholar.org/paper/d29074a0e2dee3d394b51669a9ec5297c008e469\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49454064\",\"name\":\"Kan Huang\"},{\"authorId\":\"1410115257\",\"name\":\"Ge Li\"},{\"authorId\":\"48641357\",\"name\":\"S. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.04.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d62c00232bb1fce188dbe1b2fdb25cf86ef8769b\",\"title\":\"Learning channel-wise spatio-temporal representations for video salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/d62c00232bb1fce188dbe1b2fdb25cf86ef8769b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"Aayush Jung Rana\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4b8626336566f34c7e1d17ddf7b144636812c18\",\"title\":\"An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d4b8626336566f34c7e1d17ddf7b144636812c18\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":\"2008.11516\",\"authors\":[{\"authorId\":\"46196169\",\"name\":\"S. Mahadevan\"},{\"authorId\":\"3488419\",\"name\":\"Ali Athar\"},{\"authorId\":\"3331304\",\"name\":\"Aljosa Osep\"},{\"authorId\":\"1908537619\",\"name\":\"Sebastian Hennen\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc79bd6fb5e674199dfa52a61c819735aed568c5\",\"title\":\"Making a Case for 3D Convolutions for Object Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bc79bd6fb5e674199dfa52a61c819735aed568c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":\"2008.02531\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3394171.3413694\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"title\":\"Self-supervised Video Representation Learning Using Inter-intra Contrastive Framework\",\"url\":\"https://www.semanticscholar.org/paper/de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.01180\",\"authors\":[{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"12732902\",\"name\":\"Xinyue Wei\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"title\":\"RSA: Randomized Simulation as Augmentation for Robust Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923065213\",\"name\":\"Qinghongya Shi\"},{\"authorId\":\"46702837\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"89616898\",\"name\":\"Haotian Ren\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"}],\"doi\":\"10.1186/s13640-020-00519-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"title\":\"Consistent constraint-based video-level learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":\"1909.09422\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"title\":\"Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos\",\"url\":\"https://www.semanticscholar.org/paper/3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.00744\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1614038854\",\"name\":\"Yang Liu\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"47107270\",\"name\":\"E. Coto\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"151352107\",\"name\":\"Valentin Gabeur\"},{\"authorId\":\"1612977414\",\"name\":\"Chen Sun\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"87652983\",\"name\":\"H. Liu\"},{\"authorId\":\"1808091339\",\"name\":\"Chen Wang\"},{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145912650\",\"name\":\"X. Hao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2921b34b99c6150a7625acdbdd99504c2789f7a2\",\"title\":\"The End-of-End-to-End: A Video Understanding Pentathlon Challenge (2020)\",\"url\":\"https://www.semanticscholar.org/paper/2921b34b99c6150a7625acdbdd99504c2789f7a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989516\",\"name\":\"A. L. Georgescu\"},{\"authorId\":\"1721120\",\"name\":\"Jana C K\\u00f6hler\"},{\"authorId\":\"38465931\",\"name\":\"Johanna Weiske\"},{\"authorId\":\"49535508\",\"name\":\"K. Vogeley\"},{\"authorId\":\"1382247440\",\"name\":\"Nikolaos Koutsouleris\"},{\"authorId\":\"1400853302\",\"name\":\"C. Falter-Wagner\"}],\"doi\":\"10.3389/frobt.2019.00132\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f921c99440921581c8741c1bb5332dae4d6f7ced\",\"title\":\"Machine Learning to Study Social Interaction Difficulties in ASD\",\"url\":\"https://www.semanticscholar.org/paper/f921c99440921581c8741c1bb5332dae4d6f7ced\",\"venue\":\"Front. Robot. AI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740612\",\"name\":\"C. Wu\"},{\"authorId\":\"50171534\",\"name\":\"Xiaojun Wu\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/ICCVW.2019.00216\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"title\":\"Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2010.15336\",\"authors\":[{\"authorId\":\"144850780\",\"name\":\"Haoyuan Zhang\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"151502410\",\"name\":\"Zihui Guo\"},{\"authorId\":\"1752792230\",\"name\":\"Wanqing Li\"}],\"doi\":\"10.1016/j.jvcir.2020.102942\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7997b15e6b91fba0f7af6596e12a303ff7de8223\",\"title\":\"SAR-NAS: Skeleton-based Action Recognition via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/7997b15e6b91fba0f7af6596e12a303ff7de8223\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1811.10636\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2019.00188\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"title\":\"Evolving Space-Time Neural Architectures for Videos\",\"url\":\"https://www.semanticscholar.org/paper/793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.00029\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e13ddc782155ed273b8e2c1e92b5130cdd1f3b\",\"title\":\"Chirality Nets for Human Pose Regression\",\"url\":\"https://www.semanticscholar.org/paper/55e13ddc782155ed273b8e2c1e92b5130cdd1f3b\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276931\",\"name\":\"Jiaojiao Li\"},{\"authorId\":\"1379683358\",\"name\":\"Ruxing Cui\"},{\"authorId\":\"46708584\",\"name\":\"B. Li\"},{\"authorId\":\"38785260\",\"name\":\"R. Song\"},{\"authorId\":\"7771261\",\"name\":\"Y. Li\"},{\"authorId\":\"144486974\",\"name\":\"Q. Du\"}],\"doi\":\"10.3390/rs11232859\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a56dc1a3cc8710db614de223c88197e76f7937f3\",\"title\":\"Hyperspectral Image Super-Resolution with 1D-2D Attentional Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a56dc1a3cc8710db614de223c88197e76f7937f3\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"1905.03966\",\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"49050519\",\"name\":\"Jiyuan Zhang\"},{\"authorId\":\"47119038\",\"name\":\"X. Wang\"},{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/CVPR.2019.00854\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"title\":\"Memory-Attended Recurrent Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.1016/j.jneumeth.2019.108536\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40697a874e09a123ed7da97323da27662e0028\",\"title\":\"Deep Learning Improves Automated Rodent Behavior Recognition Within a Specific Experimental Setup\",\"url\":\"https://www.semanticscholar.org/paper/5b40697a874e09a123ed7da97323da27662e0028\",\"venue\":\"Journal of Neuroscience Methods\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"153109159\",\"name\":\"L. Wen\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"},{\"authorId\":\"2020817\",\"name\":\"Ming Zeng\"}],\"doi\":\"10.1109/ICAICA50127.2020.9182498\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b679ccceefd9605661115e6e2391ad3c9076168\",\"title\":\"Spatio-temporal Collaborative Convolution for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b679ccceefd9605661115e6e2391ad3c9076168\",\"venue\":\"2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)\",\"year\":2020},{\"arxivId\":\"1910.13888\",\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCVW.2019.00195\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"title\":\"Comprehensive Video Understanding: Video Summarization with Content-Based Video Recommender Design\",\"url\":\"https://www.semanticscholar.org/paper/126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144486077\",\"name\":\"Xiaoming Peng\"},{\"authorId\":\"51301456\",\"name\":\"A. Bouzerdoum\"}],\"doi\":\"10.1109/DICTA47822.2019.8946036\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fdd19b69b2ddbb770259d8da0223d4edb262f0fe\",\"title\":\"Part-Based Feature Aggregation Method for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fdd19b69b2ddbb770259d8da0223d4edb262f0fe\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.08427\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"343f14319d5e34c37eeb86dea88fa82f56715679\",\"title\":\"Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/343f14319d5e34c37eeb86dea88fa82f56715679\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738590176\",\"name\":\"Alfarabi Imashev\"},{\"authorId\":\"134440762\",\"name\":\"Medet Mukushev\"},{\"authorId\":\"1556952980\",\"name\":\"V. Kimmelman\"},{\"authorId\":\"1913584\",\"name\":\"Anara Sandygulova\"}],\"doi\":\"10.18653/v1/2020.conll-1.51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a7d07bb7d86ed0fd4825ea97ad18f7ba3bc7a60\",\"title\":\"A Dataset for Linguistic Understanding, Visual Evaluation, and Recognition of Sign Languages: The K-RSL\",\"url\":\"https://www.semanticscholar.org/paper/9a7d07bb7d86ed0fd4825ea97ad18f7ba3bc7a60\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":\"1810.08437\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/TPAMI.2019.2929038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67d0a881e0c580acc7770c212396171cc64aa76c\",\"title\":\"Learning with Privileged Information via Adversarial Discriminative Modality Distillation\",\"url\":\"https://www.semanticscholar.org/paper/67d0a881e0c580acc7770c212396171cc64aa76c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.13662\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":null,\"name\":\"Mandela Patrick\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"title\":\"Labelling unlabelled videos from scratch with multi-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.10950\",\"authors\":[{\"authorId\":\"1737817225\",\"name\":\"Zhen Yu\"},{\"authorId\":\"50004409\",\"name\":\"J. Nguyen\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"47623309\",\"name\":\"J. Kelly\"},{\"authorId\":\"143682056\",\"name\":\"C. Mclean\"},{\"authorId\":\"153824047\",\"name\":\"L. Zhang\"},{\"authorId\":\"153804224\",\"name\":\"V. Mar\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bca8cf9045acc94349bafe7d33a7a8aed4e8191\",\"title\":\"Melanoma Diagnosis with Spatio-Temporal Feature Learning on Sequential Dermoscopic Images\",\"url\":\"https://www.semanticscholar.org/paper/2bca8cf9045acc94349bafe7d33a7a8aed4e8191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66933647\",\"name\":\"Debapriya Hazra\"},{\"authorId\":\"1730636\",\"name\":\"Yungcheol Byun\"}],\"doi\":\"10.3390/electronics9081312\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c03f51a33b2ffe479f2995482143207f889f2c9b\",\"title\":\"Upsampling Real-Time, Low-Resolution CCTV Videos Using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c03f51a33b2ffe479f2995482143207f889f2c9b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2005.00375\",\"authors\":[{\"authorId\":\"49970148\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"40560502\",\"name\":\"W. Wang\"},{\"authorId\":\"46947534\",\"name\":\"Z. Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dbcafe488f5b8153d4e43cae3577a590bd62840\",\"title\":\"A Comprehensive Study on Visual Explanations for Spatio-temporal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1dbcafe488f5b8153d4e43cae3577a590bd62840\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.05107\",\"authors\":[{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"46582860\",\"name\":\"W. Mcnally\"},{\"authorId\":\"87975332\",\"name\":\"Chris Dulhanty\"},{\"authorId\":\"47778781\",\"name\":\"Z. Lin\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0868051f7edfd1975980b87f48ace7b5b0d02aee\",\"title\":\"PuckNet: Estimating hockey puck location from broadcast video\",\"url\":\"https://www.semanticscholar.org/paper/0868051f7edfd1975980b87f48ace7b5b0d02aee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-58610-2_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19d574a2238ad11142de1d6f2713315880b2d218\",\"title\":\"Shuffle and Attend: Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/19d574a2238ad11142de1d6f2713315880b2d218\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.12919\",\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"152477216\",\"name\":\"P. Abreu\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"102c5f96b879de46921cfc1f589dbc364310cf54\",\"title\":\"Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/102c5f96b879de46921cfc1f589dbc364310cf54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02753\",\"authors\":[{\"authorId\":\"1612061859\",\"name\":\"Joshua Knights\"},{\"authorId\":\"1612351216\",\"name\":\"Anthony Vanderkop\"},{\"authorId\":\"143679553\",\"name\":\"D. Ward\"},{\"authorId\":\"1612210724\",\"name\":\"Olivia Mackenzie-Ross\"},{\"authorId\":\"145136889\",\"name\":\"P. Moghadam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"195a51f9e4be3537f930d87f5200e63a51b9a226\",\"title\":\"Temporally Coherent Embeddings for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/195a51f9e4be3537f930d87f5200e63a51b9a226\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.09566\",\"authors\":[{\"authorId\":\"3421983\",\"name\":\"Behnaz Rezaei\"},{\"authorId\":\"1388732358\",\"name\":\"Yiorgos Christakis\"},{\"authorId\":\"91252281\",\"name\":\"Bryan Ho\"},{\"authorId\":\"49773841\",\"name\":\"K. Thomas\"},{\"authorId\":\"145859998\",\"name\":\"K. Erb\"},{\"authorId\":\"2225783\",\"name\":\"S. Ostadabbas\"},{\"authorId\":\"50260566\",\"name\":\"S. Patel\"}],\"doi\":\"10.3390/s19194266\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84b5e88e319346385bbedb5d6c8d539693a3397f\",\"title\":\"Target-Specific Action Classification for Automated Assessment of Human Motor Behavior from Video\",\"url\":\"https://www.semanticscholar.org/paper/84b5e88e319346385bbedb5d6c8d539693a3397f\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1910.06961\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"title\":\"Tiny Video Networks\",\"url\":\"https://www.semanticscholar.org/paper/7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9513772\",\"name\":\"L. T\\u00f3th\"},{\"authorId\":\"2003543471\",\"name\":\"Amin Honarmandi Shandiz\"}],\"doi\":\"10.1007/978-3-030-61401-0_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"521c812d686c9a784c4fd6ebceac4078919eda60\",\"title\":\"3D Convolutional Neural Networks for Ultrasound-Based Silent Speech Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/521c812d686c9a784c4fd6ebceac4078919eda60\",\"venue\":\"ICAISC\",\"year\":2020},{\"arxivId\":\"1906.05332\",\"authors\":[{\"authorId\":\"10734287\",\"name\":\"Xiuye Gu\"},{\"authorId\":\"47906704\",\"name\":\"Y. Wang\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"40378636\",\"name\":\"Panqu Wang\"}],\"doi\":\"10.1109/CVPR.2019.00337\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"730666f38edc326439c3250266a7bfe2c6e106ca\",\"title\":\"HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-Scale Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/730666f38edc326439c3250266a7bfe2c6e106ca\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.01449\",\"authors\":[{\"authorId\":\"2177037\",\"name\":\"Andrew Kae\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":\"10.1109/WACV45572.2020.9093645\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e776cc129ed89303af6f2075ccfcea596243ff5d\",\"title\":\"Image to Video Domain Adaptation Using Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e776cc129ed89303af6f2075ccfcea596243ff5d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41019567\",\"name\":\"Lukas Tuggener\"},{\"authorId\":\"1985672\",\"name\":\"M. Amirian\"},{\"authorId\":\"2043513\",\"name\":\"F. Benites\"},{\"authorId\":\"25095856\",\"name\":\"Pius von D\\u00e4niken\"},{\"authorId\":\"1491232062\",\"name\":\"Prakhar Gupta\"},{\"authorId\":\"73681262\",\"name\":\"F. Schilling\"},{\"authorId\":\"1831096656\",\"name\":\"Thilo Stadelmann\"}],\"doi\":\"10.3390/ai1040031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71446ab82087505d7849b1b6f1fce4dcda751c1d\",\"title\":\"Design Patterns for Resource-Constrained Automated Deep-Learning Methods\",\"url\":\"https://www.semanticscholar.org/paper/71446ab82087505d7849b1b6f1fce4dcda751c1d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.11755\",\"authors\":[{\"authorId\":\"1780642035\",\"name\":\"Mohammad Zaki Zadeh\"},{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"47589592\",\"name\":\"Ashish Jaiswal\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f3836b9243086c715f348c9758966c25430b894\",\"title\":\"Self-Supervised Human Activity Recognition by Augmenting Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f3836b9243086c715f348c9758966c25430b894\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"2003.01791\",\"authors\":[{\"authorId\":\"32597970\",\"name\":\"J. Lee\"},{\"authorId\":\"50381441\",\"name\":\"Alexander Wong\"}],\"doi\":\"10.1109/CRV50864.2020.00010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"930b864b2b8515119f2ac4067e7ccbae651098be\",\"title\":\"TimeConvNets: A Deep Time Windowed Convolution Neural Network Design for Real-time Video Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/930b864b2b8515119f2ac4067e7ccbae651098be\",\"venue\":\"2020 17th Conference on Computer and Robot Vision (CRV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0f2fde071939fcd63f7e7ff0b53e781a44e24ca\",\"title\":\"Causal Spatiotemporal Representations Anonymous\",\"url\":\"https://www.semanticscholar.org/paper/b0f2fde071939fcd63f7e7ff0b53e781a44e24ca\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00807\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"title\":\"MARS: Motion-Augmented RGB Stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"title\":\"Resource Efficient 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2004.05054\",\"authors\":[{\"authorId\":\"51000619\",\"name\":\"Evgeny Izutov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"title\":\"ASL Recognition with Metric-Learning based Lightweight Network\",\"url\":\"https://www.semanticscholar.org/paper/f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.07460\",\"authors\":[{\"authorId\":\"47103450\",\"name\":\"Yunlu Xu\"},{\"authorId\":\"1737602\",\"name\":\"C. Zhang\"},{\"authorId\":\"2398015\",\"name\":\"Zhanzhan Cheng\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"143767386\",\"name\":\"Yi Niu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1609/aaai.v33i01.33019070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3934262388cddf2fa6a8af32fbca7e8533ef62df\",\"title\":\"Segregated Temporal Assembly Recurrent Networks for Weakly Supervised Multiple Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/3934262388cddf2fa6a8af32fbca7e8533ef62df\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144577\",\"name\":\"C. Wu\"},{\"authorId\":\"83483083\",\"name\":\"Jiayue Han\"},{\"authorId\":\"1723274\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1bc41a048a30919ba79fa88d9c4a03cb2942b47\",\"title\":\"Time-Asymmetric 3d Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a1bc41a048a30919ba79fa88d9c4a03cb2942b47\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1909.03309\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1007/978-981-15-8697-2_10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"title\":\"Exploring Temporal Differences in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740100\",\"name\":\"M. Kong\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"}],\"doi\":\"10.1007/978-3-030-32456-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"title\":\"Global Features of Fused Frame Relationships Help Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20992076\",\"name\":\"Timothy Callemein\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"74922038\",\"name\":\"Floris De Feyter\"},{\"authorId\":\"73664580\",\"name\":\"Wim Boes\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2003472752\",\"name\":\"Tinne Tuytelaars\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1007/s11042-020-09616-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32921da55d7127169e901c4b3e5d6e2333185561\",\"title\":\"Show me where the action is!: Automatic capturing and timeline generation for reality TV.\",\"url\":\"https://www.semanticscholar.org/paper/32921da55d7127169e901c4b3e5d6e2333185561\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.07217\",\"authors\":[{\"authorId\":\"2595119\",\"name\":\"X. Yang\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af44b51ac01b2599961107a7a76a5892601c5f7c\",\"title\":\"Back to the Future: Cycle Encoding Prediction for Self-supervised Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/af44b51ac01b2599961107a7a76a5892601c5f7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845451\",\"name\":\"Zeng Yan\"},{\"authorId\":\"144736906\",\"name\":\"L. Min\"}],\"doi\":\"10.1145/3433996.3434366\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66b6da456ccec20929a69dadb1e1ebaf17534888\",\"title\":\"The Summarize of Body Behaviour Semantic Computing Key Technology in Video Scene\",\"url\":\"https://www.semanticscholar.org/paper/66b6da456ccec20929a69dadb1e1ebaf17534888\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.00294\",\"authors\":[{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"2187183\",\"name\":\"Y. Zhou\"},{\"authorId\":\"8697322\",\"name\":\"Dongbao Yang\"},{\"authorId\":\"2006302\",\"name\":\"Can Ma\"},{\"authorId\":\"12605536\",\"name\":\"Qixiang Ye\"},{\"authorId\":\"47824616\",\"name\":\"Weiping Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.6840\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"63a8ad8721ae8f15f3ad27b2974aff2f90d10022\",\"title\":\"Video Cloze Procedure for Self-Supervised Spatio-Temporal Learning\",\"url\":\"https://www.semanticscholar.org/paper/63a8ad8721ae8f15f3ad27b2974aff2f90d10022\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1908.04034\",\"authors\":[{\"authorId\":\"32877671\",\"name\":\"Joakim Bruslund Haurum\"},{\"authorId\":\"47926700\",\"name\":\"Chris H. Bahnsen\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfc46198306201da2d00a1e76e80c62b1c6080b\",\"title\":\"Is it Raining Outside? Detection of Rainfall using General-Purpose Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/cbfc46198306201da2d00a1e76e80c62b1c6080b\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1908.04471\",\"authors\":[{\"authorId\":\"2730698\",\"name\":\"K. Hayashi\"},{\"authorId\":\"50169830\",\"name\":\"Taiki Yamaguchi\"},{\"authorId\":\"153589486\",\"name\":\"Y. Sugawara\"},{\"authorId\":\"35647224\",\"name\":\"S. Maeda\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c8832b2a23db816beba564e8e825e3d11ddf6ca\",\"title\":\"Einconv: Exploring Unexplored Tensor Decompositions for Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c8832b2a23db816beba564e8e825e3d11ddf6ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276931\",\"name\":\"Jiaojiao Li\"},{\"authorId\":\"1379683358\",\"name\":\"Ruxing Cui\"},{\"authorId\":\"2485552\",\"name\":\"B. Li\"},{\"authorId\":\"7771261\",\"name\":\"Y. Li\"},{\"authorId\":\"1745727\",\"name\":\"S. Mei\"},{\"authorId\":\"144486980\",\"name\":\"Q. Du\"}],\"doi\":\"10.1109/IGARSS.2019.8898352\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9373941be7391b744ee1ed03576ac5fa46aeccf\",\"title\":\"Dual 1D-2D Spatial-Spectral CNN for Hyperspectral Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/f9373941be7391b744ee1ed03576ac5fa46aeccf\",\"venue\":\"IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium\",\"year\":2019},{\"arxivId\":\"1912.04523\",\"authors\":[{\"authorId\":\"48272026\",\"name\":\"Victoria Lin\"},{\"authorId\":\"36185909\",\"name\":\"J. M. Girard\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"46e546994dbcef1f13c3b63c210127ce0f616540\",\"title\":\"Context-Dependent Models for Predicting and Characterizing Facial Expressiveness\",\"url\":\"https://www.semanticscholar.org/paper/46e546994dbcef1f13c3b63c210127ce0f616540\",\"venue\":\"AffCon@AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423699581\",\"name\":\"A. F. D. Marsiano\"},{\"authorId\":\"9149246\",\"name\":\"I. Soesanti\"},{\"authorId\":\"2969172\",\"name\":\"Igi Ardiyanto\"}],\"doi\":\"10.1109/ICAICTA.2019.8904395\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"title\":\"Deep learning-based Anomaly Detection on Surveillance Videos: Recent Advances\",\"url\":\"https://www.semanticscholar.org/paper/8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.04538\",\"authors\":[{\"authorId\":\"115023832\",\"name\":\"Zhi-Kai Chen\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"51004368\",\"name\":\"Y. He\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9f01b9054517581a675fb919850ad558d4640d7\",\"title\":\"Appending Adversarial Frames for Universal Video Attack\",\"url\":\"https://www.semanticscholar.org/paper/b9f01b9054517581a675fb919850ad558d4640d7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10700\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"144585402\",\"name\":\"Peng Zhang\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3343031.3351040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"title\":\"Explainable Video Action Reasoning via Prior Knowledge and State Transitions\",\"url\":\"https://www.semanticscholar.org/paper/7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2004.12943\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afc91295df19ffc7ab95530dc879ac11126afeee\",\"title\":\"Audio-Visual Instance Discrimination with Cross-Modal Agreement\",\"url\":\"https://www.semanticscholar.org/paper/afc91295df19ffc7ab95530dc879ac11126afeee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49941672\",\"name\":\"Zhiming Hu\"},{\"authorId\":\"50699057\",\"name\":\"Ning Ye\"},{\"authorId\":\"48976987\",\"name\":\"C. Phillips\"},{\"authorId\":\"49772724\",\"name\":\"Tim Capes\"},{\"authorId\":\"1703622\",\"name\":\"I. Mohomed\"}],\"doi\":\"10.1145/3429357.3430518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e2e00fdee406eb9a4f7b341a3be5866c8f99822\",\"title\":\"mmFilter: Language-Guided Video Analytics at the Edge\",\"url\":\"https://www.semanticscholar.org/paper/9e2e00fdee406eb9a4f7b341a3be5866c8f99822\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"2008.03996\",\"authors\":[{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"1382648588\",\"name\":\"Wei Peng\"},{\"authorId\":\"66966514\",\"name\":\"Yoon Lee\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c9d32b48ad0c668e496b7c04c6f49dd87d5c5f5\",\"title\":\"2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors Challenges: An Efficient Optical Flow Stream Guided Framework\",\"url\":\"https://www.semanticscholar.org/paper/6c9d32b48ad0c668e496b7c04c6f49dd87d5c5f5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d51fe8c751b43ffa79feae581d555dfcbced6e3d\",\"title\":\"Supplementary material: SCSampler: Sampling Salient Clips from Video for Efficient Action Recognition 1. Action classification networks\",\"url\":\"https://www.semanticscholar.org/paper/d51fe8c751b43ffa79feae581d555dfcbced6e3d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089882\",\"name\":\"Haiyang Jiang\"},{\"authorId\":\"7303419\",\"name\":\"Yaozong Pan\"},{\"authorId\":\"101594813\",\"name\":\"J. Zhang\"},{\"authorId\":\"145664195\",\"name\":\"H. Yang\"}],\"doi\":\"10.3390/SYM11060761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"title\":\"Battlefield Target Aggregation Behavior Recognition Model Based on Multi-Scale Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1452353179\",\"name\":\"Murilo Varges da Silva\"},{\"authorId\":\"1452350365\",\"name\":\"Aparecido Nilceu Marana\"}],\"doi\":\"10.1109/BRACIS.2019.00134\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab1916435d3cd28d5bcaa13a13e041e6bc0c05a3\",\"title\":\"Human Action Recognition using 2D Poses\",\"url\":\"https://www.semanticscholar.org/paper/ab1916435d3cd28d5bcaa13a13e041e6bc0c05a3\",\"venue\":\"2019 8th Brazilian Conference on Intelligent Systems (BRACIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":\"2004.01283\",\"authors\":[{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"49107065\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d97d2fe18aa00be936fa8492a0c394f3b6791ed4\",\"title\":\"BosphorusSign22k Sign Language Recognition Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d97d2fe18aa00be936fa8492a0c394f3b6791ed4\",\"venue\":\"LREC 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1007/978-3-030-01264-9_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71167cf519940a7373adc221401c396198763ab0\",\"title\":\"Scenes-Objects-Actions: A Multi-task, Multi-label Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71167cf519940a7373adc221401c396198763ab0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1846234260\",\"name\":\"Xiaoyan Meng\"},{\"authorId\":\"1845981156\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"47057083\",\"name\":\"Xiuzhi Li\"},{\"authorId\":\"1846054590\",\"name\":\"Xiangyin Zhang\"}],\"doi\":\"10.1007/s00371-020-01931-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625829da4b74fbcf217615eadd852e5ff4387a17\",\"title\":\"Auxiliary criterion conversion via spatiotemporal semantic encoding and feature entropy for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/625829da4b74fbcf217615eadd852e5ff4387a17\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742445396\",\"name\":\"Lin Wang\"},{\"authorId\":\"1935766044\",\"name\":\"Jingqian Jia\"},{\"authorId\":\"32585571\",\"name\":\"Nan-nan Mao\"}],\"doi\":\"10.23919/CCC50068.2020.9188920\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b23c6d01df6320161e7a34df91435f65fec64ab\",\"title\":\"Micro-Expression Recognition Based on 2D-3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/2b23c6d01df6320161e7a34df91435f65fec64ab\",\"venue\":\"2020 39th Chinese Control Conference (CCC)\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.10850\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58607-2_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"title\":\"Discriminability Distillation in Group Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.01148\",\"authors\":[{\"authorId\":\"2804902\",\"name\":\"M. M. Islam\"},{\"authorId\":\"32229358\",\"name\":\"Tariq Iqbal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab3f612125a13410373c33600abd3fccdf79ce31\",\"title\":\"HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/ab3f612125a13410373c33600abd3fccdf79ce31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2568376\",\"name\":\"Abhimanyu Sahu\"},{\"authorId\":\"40272229\",\"name\":\"A. S. Chowdhury\"}],\"doi\":\"10.1016/j.neucom.2020.02.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57b8133654f03f0b4f74f42bde9133f56aca39b2\",\"title\":\"Summarizing egocentric videos using deep features and optimal clustering\",\"url\":\"https://www.semanticscholar.org/paper/57b8133654f03f0b4f74f42bde9133f56aca39b2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2961531\",\"name\":\"M. Hosseini\"},{\"authorId\":\"145226394\",\"name\":\"F. Ghaderi\"}],\"doi\":\"10.5829/ije.2020.33.05b.29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"title\":\"A Hybrid Deep Learning Architecture Using 3D CNNs and GRUs for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.08206\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"1420126809\",\"name\":\"Haim Barad\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"},{\"authorId\":\"3243137\",\"name\":\"Amit Bleiweiss\"}],\"doi\":\"10.1109/CVPRW50498.2020.00350\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da2934c24a9de690ff399736711b754cc10ae1ec\",\"title\":\"Mimic The Raw Domain: Accelerating Action Recognition in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/da2934c24a9de690ff399736711b754cc10ae1ec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"506ea19145838a035e7dba535519fb40a3a0018c\",\"title\":\"Learning Shared Multimodal Embeddings with Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/506ea19145838a035e7dba535519fb40a3a0018c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.10519\",\"authors\":[{\"authorId\":\"31711745\",\"name\":\"Murilo Varges da Silva\"},{\"authorId\":\"1683019\",\"name\":\"A. N. Marana\"}],\"doi\":\"10.1007/978-3-030-13469-3_64\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0155c2921f060a95c0eca8c64bf62a1eaac591e4\",\"title\":\"Spatiotemporal CNNs for Pornography Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0155c2921f060a95c0eca8c64bf62a1eaac591e4\",\"venue\":\"CIARP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"87046280\",\"name\":\"H. Yang\"},{\"authorId\":\"1560347965\",\"name\":\"Jun Sun\"}],\"doi\":\"10.1109/ICIP40778.2020.9191071\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"title\":\"Multilevel Interaction Reasoning For Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912976\",\"name\":\"W. N. Khotimah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2795743\",\"name\":\"Farid Boussa\\u00efd\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"152660969\",\"name\":\"D. Edwards\"}],\"doi\":\"10.3390/rs12193137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10f9ac6408659b9ecee1df601f4567bce5995e26\",\"title\":\"A High-Performance Spectral-Spatial Residual Network for Hyperspectral Image Classification with Small Training Data\",\"url\":\"https://www.semanticscholar.org/paper/10f9ac6408659b9ecee1df601f4567bce5995e26\",\"venue\":\"Remote. Sens.\",\"year\":2020},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":null,\"name\":\"Zhicheng Yan\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00876\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"title\":\"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153384782\",\"name\":\"Yuhui Wen\"},{\"authorId\":\"144614909\",\"name\":\"L. Gao\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"},{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"},{\"authorId\":\"2314567\",\"name\":\"S. Xia\"}],\"doi\":\"10.1609/AAAI.V33I01.33018989\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2b308ea24adfae53ce655ab7d12b362f647756e\",\"title\":\"Graph CNNs with Motif and Variable Temporal Block for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b2b308ea24adfae53ce655ab7d12b362f647756e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1557269924\",\"name\":\"Tao Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2020.107477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"156fae773062f7ef0d4e9c4bb141cfae46e8ba85\",\"title\":\"Play and rewind: Context-aware video temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/156fae773062f7ef0d4e9c4bb141cfae46e8ba85\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33185308\",\"name\":\"Hong-Cheu Liu\"},{\"authorId\":\"50082191\",\"name\":\"L. Zhang\"},{\"authorId\":\"1657251288\",\"name\":\"Lisi Guan\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053939\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6aa2347064fb6e88d3c233d96c58e07ab7af177c\",\"title\":\"GFNet: A Lightweight Group Frame Network for Efficient Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6aa2347064fb6e88d3c233d96c58e07ab7af177c\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"89674661\",\"name\":\"Runzhong Wang\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8bd415d5c294e4e928f135d19b6b6f978322d28\",\"title\":\"Learning deep graph matching with channel-independent embedding and Hungarian attention\",\"url\":\"https://www.semanticscholar.org/paper/b8bd415d5c294e4e928f135d19b6b6f978322d28\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390770350\",\"name\":\"Liyuan Wang\"},{\"authorId\":\"47539278\",\"name\":\"J. Zhang\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"},{\"authorId\":\"1902835560\",\"name\":\"Jimiao Tian\"},{\"authorId\":\"145210913\",\"name\":\"L. Zhuo\"}],\"doi\":\"10.1016/J.PATREC.2020.09.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c764b579b6c751de978a1da2ff5a9f87c38e4f75\",\"title\":\"Multilevel fusion of multimodal deep features for porn streamer recognition in live video\",\"url\":\"https://www.semanticscholar.org/paper/c764b579b6c751de978a1da2ff5a9f87c38e4f75\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV45572.2020.9093612\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"title\":\"Learning Multimodal Representations for Unseen Activities\",\"url\":\"https://www.semanticscholar.org/paper/dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403026588\",\"name\":\"Pau Climent-P\\u00e9rez\"},{\"authorId\":\"1699905\",\"name\":\"S. Spinsante\"},{\"authorId\":\"2338883\",\"name\":\"A. Mihailidis\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.1016/J.ESWA.2019.112847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"title\":\"A review on video-based active and assisted living technologies for automated lifelogging\",\"url\":\"https://www.semanticscholar.org/paper/516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1908.07625\",\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1109/ICCV.2019.00558\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"title\":\"Action Recognition With Spatial-Temporal Discriminative Filter Banks\",\"url\":\"https://www.semanticscholar.org/paper/d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038426504\",\"name\":\"Zhouning Du\"},{\"authorId\":\"2873178\",\"name\":\"H. Mukaidani\"},{\"authorId\":\"1381799120\",\"name\":\"Ramasamy Saravanakumar\"}],\"doi\":\"10.1109/SMC42975.2020.9283429\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d00445b8d5b6da620056aed4685bf9b766a9700b\",\"title\":\"Action Recognition Based on Linear Dynamical Systems with Deep Features in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d00445b8d5b6da620056aed4685bf9b766a9700b\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.11415\",\"authors\":[{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01063\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ede7829b3f057a874c513919d19307e2b60ead23\",\"title\":\"Few-Shot Video Classification via Temporal Alignment\",\"url\":\"https://www.semanticscholar.org/paper/ede7829b3f057a874c513919d19307e2b60ead23\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064316\",\"name\":\"X. Chen\"},{\"authorId\":\"2021729915\",\"name\":\"Ming Zhou\"},{\"authorId\":\"1810685346\",\"name\":\"Zhengxin Gong\"},{\"authorId\":\"153039925\",\"name\":\"W. Xu\"},{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"3838241\",\"name\":\"Taicheng Huang\"},{\"authorId\":\"50173661\",\"name\":\"Zonglei Zhen\"},{\"authorId\":\"2246399\",\"name\":\"J. Liu\"}],\"doi\":\"10.3389/fncom.2020.580632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2207287564f623d9c976cdf44649c500b615f23d\",\"title\":\"DNNBrain: A Unifying Toolbox for Mapping Deep Neural Networks and Brains\",\"url\":\"https://www.semanticscholar.org/paper/2207287564f623d9c976cdf44649c500b615f23d\",\"venue\":\"Frontiers in Computational Neuroscience\",\"year\":2020},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144393682\",\"name\":\"Q. Ye\"},{\"authorId\":\"1654173355\",\"name\":\"Haoxin Zhong\"},{\"authorId\":\"143640699\",\"name\":\"C. Qu\"},{\"authorId\":\"46866955\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.3390/s20082346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5ab81b36f88067720fc6309b6123983839672bf\",\"title\":\"Human Interaction Recognition Based on Whole-Individual Detection\",\"url\":\"https://www.semanticscholar.org/paper/b5ab81b36f88067720fc6309b6123983839672bf\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2003.02692\",\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"40152520\",\"name\":\"Tae-Hoon Kim\"},{\"authorId\":\"145917158\",\"name\":\"H. J. Chang\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90e185b5011a11fba9dea8db9136e4048b3728ec\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning Using Variable Playback Speed Prediction\",\"url\":\"https://www.semanticscholar.org/paper/90e185b5011a11fba9dea8db9136e4048b3728ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41125198\",\"name\":\"D. Chittajallu\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"3356764\",\"name\":\"Paul Tunison\"},{\"authorId\":\"13060232\",\"name\":\"S. Horvath\"},{\"authorId\":\"32763093\",\"name\":\"K. Wells\"},{\"authorId\":\"2928098\",\"name\":\"Steven G. Leeds\"},{\"authorId\":\"4433600\",\"name\":\"J. Fleshman\"},{\"authorId\":\"144390141\",\"name\":\"G. Sankaranarayanan\"},{\"authorId\":\"1689543\",\"name\":\"A. Enquobahrie\"}],\"doi\":\"10.1117/12.2509985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4458740ba5ac7d0a295481bf7c5b768920166b9\",\"title\":\"Content-based retrieval of video segments from minimally invasive surgery videos using deep convolutional video descriptors and iterative query refinement\",\"url\":\"https://www.semanticscholar.org/paper/c4458740ba5ac7d0a295481bf7c5b768920166b9\",\"venue\":\"Medical Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646487889\",\"name\":\"Bharat Giddwani\"},{\"authorId\":\"1645348665\",\"name\":\"Shruti Pandey\"},{\"authorId\":\"81028011\",\"name\":\"Hitesh Tekchandani\"},{\"authorId\":\"144966373\",\"name\":\"Shrish Verma\"}],\"doi\":\"10.1109/ICCCNT49239.2020.9225546\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b97013fac4b243cc8109eeff834e9356a336485\",\"title\":\"CSTA-2P1D UNet: Consecutive Spatio-Temporal Attention for Multi-Scale 3D Pancreas Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6b97013fac4b243cc8109eeff834e9356a336485\",\"venue\":\"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":\"10.1007/978-3-030-42128-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"title\":\"Unsupervised Learning Towards the Future\",\"url\":\"https://www.semanticscholar.org/paper/1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.03497\",\"authors\":[{\"authorId\":\"6917558\",\"name\":\"Daniel Deniz\"},{\"authorId\":\"144484799\",\"name\":\"F. Barranco\"},{\"authorId\":\"103939214\",\"name\":\"J. Isern\"},{\"authorId\":\"32132184\",\"name\":\"E. Ros\"}],\"doi\":\"10.1109/ETFA46521.2020.9211910\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"92594b024a19bc5cb3e38984c864e1653179db8f\",\"title\":\"Reconfigurable Cyber-Physical System for Lifestyle Video-Monitoring via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/92594b024a19bc5cb3e38984c864e1653179db8f\",\"venue\":\"2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2007.09835\",\"authors\":[{\"authorId\":\"48643324\",\"name\":\"Wei Niu\"},{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"48459506\",\"name\":\"Z. Li\"},{\"authorId\":\"84681008\",\"name\":\"J. Chen\"},{\"authorId\":\"1823636176\",\"name\":\"Jiexiong Guan\"},{\"authorId\":\"47435542\",\"name\":\"Xipeng Shen\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"},{\"authorId\":\"1662772707\",\"name\":\"Xue Lin\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2f44d0cd05ccc1db98af5fabf96e0f4ebd86d9c\",\"title\":\"Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/b2f44d0cd05ccc1db98af5fabf96e0f4ebd86d9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034347747\",\"name\":\"Chang Liu\"},{\"authorId\":\"153690115\",\"name\":\"Yulin Yang\"},{\"authorId\":\"2034348002\",\"name\":\"Xingyan Liu\"},{\"authorId\":\"51310276\",\"name\":\"Linpu Fang\"},{\"authorId\":\"40497356\",\"name\":\"Wenxiong Kang\"}],\"doi\":\"10.1109/TIFS.2020.3036218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a93f6df11436e0f5df09d79c814930430104b75\",\"title\":\"Dynamic-Hand-Gesture Authentication Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4a93f6df11436e0f5df09d79c814930430104b75\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":\"2012.00822\",\"authors\":[{\"authorId\":\"1387720883\",\"name\":\"Haozheng Luo\"},{\"authorId\":\"1443782482\",\"name\":\"Ruiyang Qin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1fe97e5fd1b7151d5ab6565bfe3ca6efe034575\",\"title\":\"Open-Ended Multi-Modal Relational Reason for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b1fe97e5fd1b7151d5ab6565bfe3ca6efe034575\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.10982\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"16040476\",\"name\":\"S. A. Bargal\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"846fca8fa98753223f464b187cb59b02a8a1ccae\",\"title\":\"DMCL: Distillation Multiple Choice Learning for Multimodal Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/846fca8fa98753223f464b187cb59b02a8a1ccae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.04096\",\"authors\":[{\"authorId\":\"49147616\",\"name\":\"Felix Gonda\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3557b92c64d17717253a3a6136fc85cf41ee3036\",\"title\":\"Parallel Separable 3D Convolution for Video and Volumetric Data Understanding\",\"url\":\"https://www.semanticscholar.org/paper/3557b92c64d17717253a3a6136fc85cf41ee3036\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034276230\",\"name\":\"Maxalmina\"},{\"authorId\":\"2034274644\",\"name\":\"Satria Kahfi\"},{\"authorId\":\"9308183\",\"name\":\"K. N. Ramadhani\"},{\"authorId\":\"9347718\",\"name\":\"Anditya Arifianto\"}],\"doi\":\"10.1109/IC2IE50715.2020.9274562\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc3d507bb0926654ad9c3fe38c3edd481bca072c\",\"title\":\"Lip Motion Recognition for Indonesian Vowel Phonemes Using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cc3d507bb0926654ad9c3fe38c3edd481bca072c\",\"venue\":\"2020 3rd International Conference on Computer and Informatics Engineering (IC2IE)\",\"year\":2020},{\"arxivId\":\"2009.08841\",\"authors\":[{\"authorId\":\"144395538\",\"name\":\"J\\u00e1nos V\\u00e9gh\"},{\"authorId\":\"1698035991\",\"name\":\"\\u00c1d\\u00e1m J. Berki\"}],\"doi\":\"10.21203/rs.3.rs-88297/v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ce3076340e9e5c7f24c9e8c2737e1ad2477284e\",\"title\":\"On the spatiotemporal behavior in biology-mimicking computing systems\",\"url\":\"https://www.semanticscholar.org/paper/7ce3076340e9e5c7f24c9e8c2737e1ad2477284e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"145832297\",\"name\":\"Mei Xue\"},{\"authorId\":\"14875040\",\"name\":\"He Yi\"},{\"authorId\":\"1770701\",\"name\":\"Zhang Jin\"}],\"doi\":\"10.1109/ARSO46408.2019.8948745\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48e2cb007411d965b5ed323405e7148ea3fb0bd4\",\"title\":\"Attention alignment by linear space projection for video features extraction\",\"url\":\"https://www.semanticscholar.org/paper/48e2cb007411d965b5ed323405e7148ea3fb0bd4\",\"venue\":\"2019 IEEE International Conference on Advanced Robotics and its Social Impacts (ARSO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"46696307\",\"name\":\"H. Kim\"},{\"authorId\":\"151487048\",\"name\":\"Daekwan Ko\"},{\"authorId\":\"51492435\",\"name\":\"Soo-Chul Lim\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":\"10.1109/RITAPP.2019.8932854\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0263b72d3cea4281a1bf010c041b9a0f4b888bc1\",\"title\":\"Which LSTM Type is Better for Interaction Force Estimation?\",\"url\":\"https://www.semanticscholar.org/paper/0263b72d3cea4281a1bf010c041b9a0f4b888bc1\",\"venue\":\"2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"46728598\",\"name\":\"Xue Mei\"},{\"authorId\":\"46968435\",\"name\":\"Yi He\"},{\"authorId\":\"48180876\",\"name\":\"Jin Zhang\"}],\"doi\":\"10.1007/978-3-030-36189-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f05fa8951324b2f603360a845a610d2596d60aa4\",\"title\":\"Soft Transferring and Progressive Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f05fa8951324b2f603360a845a610d2596d60aa4\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":\"1812.08249\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/WACV45572.2020.9093274\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2766379db5d9907766dab034a52867d7394a265e\",\"title\":\"D3D: Distilled 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2766379db5d9907766dab034a52867d7394a265e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2012.11211\",\"authors\":[{\"authorId\":\"46304750\",\"name\":\"Y. Ding\"},{\"authorId\":\"1563064128\",\"name\":\"Wei Zheng\"},{\"authorId\":\"49553470\",\"name\":\"Guozheng Wu\"},{\"authorId\":\"145824924\",\"name\":\"Ji Geng\"},{\"authorId\":\"1996166035\",\"name\":\"Mingsheng Cao\"},{\"authorId\":\"152179239\",\"name\":\"Zhiquang Qin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96d30788e9634edc37e74e15aebc4e1d16e5d92f\",\"title\":\"A Multi-View Dynamic Fusion Framework: How to Improve the Multimodal Brain Tumor Segmentation from Multi-Views?\",\"url\":\"https://www.semanticscholar.org/paper/96d30788e9634edc37e74e15aebc4e1d16e5d92f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825756610\",\"name\":\"Guodong Zhu\"},{\"authorId\":\"1867643\",\"name\":\"Zhenxue Chen\"},{\"authorId\":\"2402307\",\"name\":\"Chengyun Liu\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"1825761822\",\"name\":\"Weikai He\"}],\"doi\":\"10.1007/s00138-020-01099-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db54cf559cdb2030b7e91d8ec3ab2e8eca98bb8f\",\"title\":\"3D video semantic segmentation for wildfire smoke\",\"url\":\"https://www.semanticscholar.org/paper/db54cf559cdb2030b7e91d8ec3ab2e8eca98bb8f\",\"venue\":\"Machine Vision and Applications\",\"year\":2020},{\"arxivId\":\"1904.05582\",\"authors\":[{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"title\":\"Recurrent Space-time Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50131290\",\"name\":\"M. Yasuda\"},{\"authorId\":\"2991962\",\"name\":\"Y. Ohishi\"},{\"authorId\":\"67318326\",\"name\":\"Y. Koizumi\"},{\"authorId\":\"145752315\",\"name\":\"N. Harada\"}],\"doi\":\"10.21437/interspeech.2020-2445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81da4385a561b48763d140be8bbb30212bbd467d\",\"title\":\"Crossmodal Sound Retrieval Based on Specific Target Co-Occurrence Denoted with Weak Labels\",\"url\":\"https://www.semanticscholar.org/paper/81da4385a561b48763d140be8bbb30212bbd467d\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.03580\",\"authors\":[{\"authorId\":\"66438699\",\"name\":\"Yucai Bai\"},{\"authorId\":\"153740190\",\"name\":\"Giang Dai\"},{\"authorId\":null,\"name\":\"Long Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"title\":\"Extreme Low Resolution Activity Recognition with Spatial-Temporal Attention Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.12667\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"title\":\"Self-Supervised Learning by Cross-Modal Audio-Video Clustering\",\"url\":\"https://www.semanticscholar.org/paper/1ee9df4e96f5021509c438751b48d3de07ae8b75\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2009.14139\",\"authors\":[{\"authorId\":\"1976656211\",\"name\":\"\\u00c7agri G\\u00f6k\\u00e7e\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"title\":\"Score-level Multi Cue Fusion for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10033\",\"authors\":[{\"authorId\":\"38212285\",\"name\":\"N. Gessert\"},{\"authorId\":\"123390466\",\"name\":\"M. Bengs\"},{\"authorId\":\"9540121\",\"name\":\"M. Schl\\u00fcter\"},{\"authorId\":\"3236423\",\"name\":\"A. Schlaefer\"}],\"doi\":\"10.1016/j.media.2020.101730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"title\":\"Deep learning with 4D spatio-temporal data representations for OCT-based force estimation\",\"url\":\"https://www.semanticscholar.org/paper/9c81029be43318d5dc6b8e0eeae5d66d091eb22c\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.01818\",\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"1890165\",\"name\":\"J. Yin\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"102446355\",\"name\":\"Y. Yin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed7ce10f9bde7512236feb67634862dc7dae65f0\",\"title\":\"PISEP^2: Pseudo Image Sequence Evolution based 3D Pose Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ed7ce10f9bde7512236feb67634862dc7dae65f0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151493680\",\"name\":\"Jingjun Chen\"},{\"authorId\":\"1682580\",\"name\":\"Y. Song\"},{\"authorId\":\"1591129121\",\"name\":\"Yuanlin Zhang\"}],\"doi\":\"10.1109/ICME.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"title\":\"Spatial Mask ConvLSTM Network and Intra-Class Joint Training Method for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"68881e3828f18c304189755c5a64979752d4a3eb\",\"title\":\"LP-3 DCNN : Unveiling Local Phase in 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68881e3828f18c304189755c5a64979752d4a3eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":\"10.1109/ISSCC.2019.8662396\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91788beae2cd32b13c9ece1e724fd1988d9d9629\",\"title\":\"1.1 Deep Learning Hardware: Past, Present, and Future\",\"url\":\"https://www.semanticscholar.org/paper/91788beae2cd32b13c9ece1e724fd1988d9d9629\",\"venue\":\"2019 IEEE International Solid- State Circuits Conference - (ISSCC)\",\"year\":2019},{\"arxivId\":\"1904.07933\",\"authors\":[{\"authorId\":\"145343013\",\"name\":\"Andr\\u00e9s F. P\\u00e9rez\"},{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/WACV45572.2020.9093307\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"title\":\"Audio-Visual Model Distillation Using Acoustic Images\",\"url\":\"https://www.semanticscholar.org/paper/f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"title\":\"Dribbling Basketball Shooting Basketball Dribbling Basketball Shooting Basketball Baking Cookies Peeling Potatos Baking Cookies Peeling Potatos Smoking Eating BurgerSmoking Eating\",\"url\":\"https://www.semanticscholar.org/paper/d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758964\",\"name\":\"Jie Yan\"},{\"authorId\":\"1783055\",\"name\":\"Guihe Qin\"},{\"authorId\":\"10431066\",\"name\":\"R. Zhao\"},{\"authorId\":\"46992126\",\"name\":\"Yan-hua Liang\"},{\"authorId\":\"150270946\",\"name\":\"Qianyi Xu\"}],\"doi\":\"10.1109/ACCESS.2019.2961383\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"title\":\"Mixpred: Video Prediction Beyond Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153924558\",\"name\":\"Hsing-Yu Chen\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1007/978-3-030-41299-9_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"title\":\"Group Activity Recognition via Computing Human Pose Motion History and Collective Map from Video\",\"url\":\"https://www.semanticscholar.org/paper/aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739631130\",\"name\":\"Fanjia Li\"},{\"authorId\":\"49298921\",\"name\":\"Juanjuan Li\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"50125448\",\"name\":\"Yonggang Xu\"},{\"authorId\":\"1826167\",\"name\":\"Hongsheng Yin\"},{\"authorId\":\"49195402\",\"name\":\"Gang Hua\"}],\"doi\":\"10.3390/s20185260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"119e639868b3c0e1e9c3c8a1d5456cfbeb516eaa\",\"title\":\"Enhanced Spatial and Extended Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/119e639868b3c0e1e9c3c8a1d5456cfbeb516eaa\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2008.02711\",\"authors\":[{\"authorId\":\"152504322\",\"name\":\"Dezhao Luo\"},{\"authorId\":\"153841261\",\"name\":\"Bo Fang\"},{\"authorId\":\"9113781\",\"name\":\"Yin-qing Zhou\"},{\"authorId\":\"2803189\",\"name\":\"Yucan Zhou\"},{\"authorId\":\"11000953\",\"name\":\"D. Wu\"},{\"authorId\":\"1956868\",\"name\":\"Weiping Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec47ea8667ec60f21ead4e4bd9e286ef28e484f3\",\"title\":\"Exploring Relations in Untrimmed Videos for Self-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/ec47ea8667ec60f21ead4e4bd9e286ef28e484f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be775b7c6c59d40a7437f1ca49f3697b4d2f6d97\",\"title\":\"Inflated Episodic Memory With Region Self-Attention for Long-Tailed Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be775b7c6c59d40a7437f1ca49f3697b4d2f6d97\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1904.03498\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPR.2019.00504\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75544f83d38ef1686d70c763deb43305c5dc8a48\",\"title\":\"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/75544f83d38ef1686d70c763deb43305c5dc8a48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02639\",\"authors\":[{\"authorId\":\"2031911039\",\"name\":\"Edward Fish\"},{\"authorId\":\"2014512338\",\"name\":\"Andrew Gilbert\"},{\"authorId\":\"47371758\",\"name\":\"Jon Weinbren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffe1f5c2d579cc63a785023f4df11207504fbc1c\",\"title\":\"Rethinking movie genre classification with fine-grained semantic clustering\",\"url\":\"https://www.semanticscholar.org/paper/ffe1f5c2d579cc63a785023f4df11207504fbc1c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00134\",\"authors\":[{\"authorId\":\"32601092\",\"name\":\"R. C. Nascimento\"},{\"authorId\":\"81601597\",\"name\":\"Y. M. Souto\"},{\"authorId\":\"49011978\",\"name\":\"Eduardo Ogasawara\"},{\"authorId\":\"145179575\",\"name\":\"F. Porto\"},{\"authorId\":\"31778392\",\"name\":\"E. Bezerra\"}],\"doi\":\"10.1016/j.neucom.2020.09.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27ffc8850d0ffa529b40b324d7f6d74c7be9a54f\",\"title\":\"STConvS2S: Spatiotemporal Convolutional Sequence to Sequence Network for Weather Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/27ffc8850d0ffa529b40b324d7f6d74c7be9a54f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"1409918228\",\"name\":\"Xin Ma\"},{\"authorId\":\"9348561\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/TMM.2019.2953814\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9433095a4a5339815bc0fc000971797e99babdda\",\"title\":\"Convolutional Networks With Channel and STIPs Attention Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9433095a4a5339815bc0fc000971797e99babdda\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491598459\",\"name\":\"Yun-Zhu Song\"},{\"authorId\":\"2028219138\",\"name\":\"Zhi Rui Tam\"},{\"authorId\":\"50688798\",\"name\":\"Hung-Jen Chen\"},{\"authorId\":\"2028221080\",\"name\":\"Huiao-Han Lu\"},{\"authorId\":\"2426757\",\"name\":\"Hong-Han Shuai\"}],\"doi\":\"10.1007/978-3-030-58520-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea35d2594e8f84fb0073893c19903da80914b8c7\",\"title\":\"Character-Preserving Coherent Story Visualization\",\"url\":\"https://www.semanticscholar.org/paper/ea35d2594e8f84fb0073893c19903da80914b8c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.05845\",\"authors\":[{\"authorId\":\"150957405\",\"name\":\"Christopher M. Sandino\"},{\"authorId\":\"51402390\",\"name\":\"P. Lai\"},{\"authorId\":\"2081096\",\"name\":\"S. Vasanawala\"},{\"authorId\":\"144891194\",\"name\":\"Joseph Y. Cheng\"}],\"doi\":\"10.1002/mrm.28420\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d03e553742a65ce9452f3ee539e5dd953c35969\",\"title\":\"Accelerating cardiac cine MRI using a deep learning\\u2010based ESPIRiT reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/0d03e553742a65ce9452f3ee539e5dd953c35969\",\"venue\":\"Magnetic resonance in medicine\",\"year\":2020},{\"arxivId\":\"2011.07231\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00877\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"title\":\"ActBERT: Learning Global-Local Video-Text Representations\",\"url\":\"https://www.semanticscholar.org/paper/8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.10305\",\"authors\":[{\"authorId\":\"1748099\",\"name\":\"Yibo Yang\"},{\"authorId\":\"145505168\",\"name\":\"Jianlong Wu\"},{\"authorId\":\"47892402\",\"name\":\"H. Li\"},{\"authorId\":null,\"name\":\"Xia Li\"},{\"authorId\":\"35925165\",\"name\":\"Tiancheng Shen\"},{\"authorId\":\"33383055\",\"name\":\"Zhouchen Lin\"}],\"doi\":\"10.1609/AAAI.V34I04.6141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5401ce493cafbdfa8c343db207607ac71ecfb263\",\"title\":\"Dynamical System Inspired Adaptive Time Stepping Controller for Residual Network Families\",\"url\":\"https://www.semanticscholar.org/paper/5401ce493cafbdfa8c343db207607ac71ecfb263\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1908.10546\",\"authors\":[{\"authorId\":\"49340538\",\"name\":\"Bowen Shi\"},{\"authorId\":\"51518798\",\"name\":\"Aurora Martinez Del Rio\"},{\"authorId\":\"7185426\",\"name\":\"J. Keane\"},{\"authorId\":\"48718348\",\"name\":\"Diane Brentari\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":\"10.1109/ICCV.2019.00550\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e112053a93beba08a998d71ba7e27620c43a0d4\",\"title\":\"Fingerspelling Recognition in the Wild With Iterative Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/0e112053a93beba08a998d71ba7e27620c43a0d4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490678582\",\"name\":\"David Ouyang\"},{\"authorId\":\"118832513\",\"name\":\"Bryan He\"},{\"authorId\":\"1490678740\",\"name\":\"Amirata Ghorbani\"},{\"authorId\":\"66795291\",\"name\":\"M. Lungren\"},{\"authorId\":\"2668259\",\"name\":\"E. Ashley\"},{\"authorId\":\"31863078\",\"name\":\"D. Liang\"},{\"authorId\":\"145085302\",\"name\":\"James Y. Zou\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"44bfcf2409c0826584c7c409b6a2fcf8c9910c88\",\"title\":\"EchoNet-Dynamic: a Large New Cardiac Motion Video Data Resource for Medical Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/44bfcf2409c0826584c7c409b6a2fcf8c9910c88\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.06196\",\"authors\":[{\"authorId\":\"3125761\",\"name\":\"Jean Kossaifi\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"145245424\",\"name\":\"Adrian Bulat\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"145387779\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/cvpr42600.2020.00610\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"07ea8125d4023993fa3c616242124fede3ed6f77\",\"title\":\"Factorized Higher-Order CNNs With an Application to Spatio-Temporal Emotion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/07ea8125d4023993fa3c616242124fede3ed6f77\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564581635\",\"name\":\"Bassel S. Chawkv\"},{\"authorId\":\"37370786\",\"name\":\"Mohammed Marey\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1109/ICICIS46948.2019.9014841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"title\":\"OA18: A New Office Actions Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"venue\":\"2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS)\",\"year\":2019},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144020384\",\"name\":\"Hoseong Kim\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1145/3265987.3265988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c9f486fcec3c80a41fcecf33b6f4653bac1aaf5\",\"title\":\"Multi-task Joint Learning for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/2c9f486fcec3c80a41fcecf33b6f4653bac1aaf5\",\"venue\":\"CoVieW@MM\",\"year\":2018},{\"arxivId\":\"2012.04983\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"2034015064\",\"name\":\"'Eloi Zablocki\"},{\"authorId\":\"1398301486\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44194713255b6ee890ce1a2d2b727d30e0b71cdb\",\"title\":\"Driving Behavior Explanation with Multi-level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/44194713255b6ee890ce1a2d2b727d30e0b71cdb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6486893\",\"name\":\"Chao Pu\"},{\"authorId\":null,\"name\":\"Hikvision\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"88997434c3dcfe1b9355edae84c78429e423600c\",\"title\":\"Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88997434c3dcfe1b9355edae84c78429e423600c\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1905.00050\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPRW.2019.00302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca721f0db5168097048fa19371ab1bdd92ff15ef\",\"title\":\"Attentive Spatio-Temporal Representation Learning for Diving Classification\",\"url\":\"https://www.semanticscholar.org/paper/ca721f0db5168097048fa19371ab1bdd92ff15ef\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95943271\",\"name\":\"S. Aberkane\"},{\"authorId\":\"66237231\",\"name\":\"M. Elarbi\"}],\"doi\":\"10.1109/ISPA48434.2019.8966795\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7061fd3afa86d4a0f4ef23b95c0503d3271d34af\",\"title\":\"Deep Reinforcement Learning for Real-world Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/7061fd3afa86d4a0f4ef23b95c0503d3271d34af\",\"venue\":\"2019 6th International Conference on Image and Signal Processing and their Applications (ISPA)\",\"year\":2019},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.07203\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"40052301\",\"name\":\"F. Petroni\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"title\":\"Video Understanding as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02422\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"title\":\"Resource Efficient 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2012.07657\",\"authors\":[{\"authorId\":\"1490942098\",\"name\":\"Alexandros Haliassos\"},{\"authorId\":\"2160245\",\"name\":\"Konstantinos Vougioukas\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db7892d6bd1e27f4e65ba8d87fb214d2ba337300\",\"title\":\"Lips Don't Lie: A Generalisable and Robust Approach to Face Forgery Detection\",\"url\":\"https://www.semanticscholar.org/paper/db7892d6bd1e27f4e65ba8d87fb214d2ba337300\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66411323\",\"name\":\"Zhiyang Fu\"},{\"authorId\":\"145435484\",\"name\":\"Hsin Wu Tseng\"},{\"authorId\":\"31573768\",\"name\":\"S. Vedantham\"},{\"authorId\":\"2149933\",\"name\":\"A. Karellas\"},{\"authorId\":\"145728646\",\"name\":\"A. Bilgin\"}],\"doi\":\"10.1038/s41598-020-77923-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfed8b0a06c4f69b8de4d63a961aa0513866485a\",\"title\":\"A residual dense network assisted sparse view reconstruction for breast computed tomography\",\"url\":\"https://www.semanticscholar.org/paper/cfed8b0a06c4f69b8de4d63a961aa0513866485a\",\"venue\":\"Scientific reports\",\"year\":2020},{\"arxivId\":\"2003.06409\",\"authors\":[{\"authorId\":\"1909776\",\"name\":\"Anthony Hu\"},{\"authorId\":\"30467209\",\"name\":\"Fergal Cotter\"},{\"authorId\":\"145536619\",\"name\":\"N. Mohan\"},{\"authorId\":\"31618584\",\"name\":\"C. Gurau\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"}],\"doi\":\"10.1007/978-3-030-58517-4_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79685e5b72e31405ded418abe8af86166313aa0\",\"title\":\"Probabilistic Future Prediction for Video Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a79685e5b72e31405ded418abe8af86166313aa0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.05410\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdff096ae7f7f72a435481e27623ad1a6276900b\",\"title\":\"Attentive Action and Context Factorization\",\"url\":\"https://www.semanticscholar.org/paper/fdff096ae7f7f72a435481e27623ad1a6276900b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.02086\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"title\":\"Self-supervised learning using consistency regularization of spatio-temporal data augmentation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2730698\",\"name\":\"K. Hayashi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"08956893c8bc71d0f4b50ebdd97bc59379d35ab1\",\"title\":\"Einconv: Exploring Unexplored Tensor Network Decompositions for Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/08956893c8bc71d0f4b50ebdd97bc59379d35ab1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.07793\",\"authors\":[{\"authorId\":\"145724888\",\"name\":\"Ashraful Islam\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1109/WACV45572.2020.9093620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145c15e10967f9eb598b62ab547312571ec3ac3c\",\"title\":\"Weakly Supervised Temporal Action Localization Using Deep Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/145c15e10967f9eb598b62ab547312571ec3ac3c\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2006.10734\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"47029037\",\"name\":\"L. Gustafson\"},{\"authorId\":\"37292073\",\"name\":\"A. Adcock\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7aeecf9e5553336e6e49c22efc426f55e2070171\",\"title\":\"Forward Prediction for Physical Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7aeecf9e5553336e6e49c22efc426f55e2070171\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.01549\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"31442858\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018401\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"title\":\"StNet: Local and Global Spatial-Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"1405331439\",\"name\":\"P. Lopez-Meyer\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/ICCV.2019.00640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eca936f462712f3d67ebe564292857144f704f1\",\"title\":\"Uncertainty-Aware Audiovisual Activity Recognition Using Deep Bayesian Variational Inference\",\"url\":\"https://www.semanticscholar.org/paper/8eca936f462712f3d67ebe564292857144f704f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410229972\",\"name\":\"Guy Ben-Yosef\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"113363846\",\"name\":\"Shimon Ullman\"}],\"doi\":\"10.1016/j.cognition.2020.104263\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"340edf9512e543655f7fa27f8498e0ad98ea2521\",\"title\":\"Minimal videos: Trade-off between spatial and temporal information in human and machine vision\",\"url\":\"https://www.semanticscholar.org/paper/340edf9512e543655f7fa27f8498e0ad98ea2521\",\"venue\":\"Cognition\",\"year\":2020},{\"arxivId\":\"2008.12432\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"117595877c1fca610f94c8d07009105092939ecc\",\"title\":\"All About Knowledge Graphs for Actions\",\"url\":\"https://www.semanticscholar.org/paper/117595877c1fca610f94c8d07009105092939ecc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14749\",\"authors\":[{\"authorId\":\"144377735\",\"name\":\"O. Lima\"},{\"authorId\":\"145062167\",\"name\":\"S. Franklin\"},{\"authorId\":\"1768842012\",\"name\":\"Shreshtha Basu\"},{\"authorId\":\"1768848143\",\"name\":\"Blake Karwoski\"},{\"authorId\":\"1768817523\",\"name\":\"Annet George\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54d71afa5ec350958a920b637e37f78e2654563d\",\"title\":\"Deepfake Detection using Spatiotemporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/54d71afa5ec350958a920b637e37f78e2654563d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11261\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"title\":\"Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.02824\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144721617\",\"name\":\"Y. Asano\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"145414740\",\"name\":\"J. Henriques\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"title\":\"Support-set bottlenecks for video-text representation learning\",\"url\":\"https://www.semanticscholar.org/paper/78bc767ebd02c0cc690fdb334c37bf64cfaf0115\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01169\",\"authors\":[{\"authorId\":\"27019040\",\"name\":\"Shang-Hui Yang\"},{\"authorId\":\"144116804\",\"name\":\"Mengxia Zhu\"},{\"authorId\":\"1854302577\",\"name\":\"Jingyang Hou\"},{\"authorId\":\"50085016\",\"name\":\"Xuesong Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5624a9443ed3cb6f468344e3d04d589a485f3c38\",\"title\":\"Deep Knowledge Tracing with Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/5624a9443ed3cb6f468344e3d04d589a485f3c38\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04755\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"title\":\"Generalized Many-Way Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CRV.2019.00032\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"title\":\"Two-Stream Action Recognition in Ice Hockey using Player Pose Sequences and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":\"1912.04462\",\"authors\":[{\"authorId\":\"3264239\",\"name\":\"Shi-Yuan Huang\"},{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"title\":\"Flow-Distilled IP Two-Stream Networks for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050421\",\"name\":\"J. Zhang\"},{\"authorId\":\"145314992\",\"name\":\"Z. Wei\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"143813538\",\"name\":\"L. Liu\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.1145/3343031.3350897\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e2593a896d82b60adf0a982afef27756dcddc6ed\",\"title\":\"Generative Reconstructive Hashing for Incomplete Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e2593a896d82b60adf0a982afef27756dcddc6ed\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bae41b83b1905af1927a11fa2750ba04e785515\",\"title\":\"Chirality Nets: Exploiting Structure in Human Pose Regression\",\"url\":\"https://www.semanticscholar.org/paper/6bae41b83b1905af1927a11fa2750ba04e785515\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92827207\",\"name\":\"Jiayou Chen\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"7661726\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"118150711\",\"name\":\"Junwei Liang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e523ce7431f15cabfefb4aa79fc6642708740948\",\"title\":\"Video to Text Description\",\"url\":\"https://www.semanticscholar.org/paper/e523ce7431f15cabfefb4aa79fc6642708740948\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491085071\",\"name\":\"Xiafei Yu\"}],\"doi\":\"10.20381/RUOR-24213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52b1cfb13c672f06aa6a43133d8b9b071d1f6226\",\"title\":\"Wide Activated Separate 3D Convolution for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/52b1cfb13c672f06aa6a43133d8b9b071d1f6226\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359181\",\"name\":\"Yang Yi\"},{\"authorId\":\"145688138\",\"name\":\"Feng Ni\"},{\"authorId\":\"15470287\",\"name\":\"Yuexin Ma\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"51177968\",\"name\":\"Riming Qiu\"},{\"authorId\":\"2946035\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"143806294\",\"name\":\"Feng Li\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"}],\"doi\":\"10.24963/ijcai.2019/141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"title\":\"High Performance Gesture Recognition via Effective and Efficient Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2004.01278\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"title\":\"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention\",\"url\":\"https://www.semanticscholar.org/paper/8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93768875\",\"name\":\"X. Wang\"},{\"authorId\":\"145824830\",\"name\":\"Yali Du\"},{\"authorId\":\"153823918\",\"name\":\"Leimin Zhang\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"46324827\",\"name\":\"Miao Zhang\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"}],\"doi\":\"10.1145/3343031.3356053\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b0c166759059395262e45681c8a7f15001bbb12\",\"title\":\"Exploring Content-based Video Relevance for Video Click-Through Rate Prediction\",\"url\":\"https://www.semanticscholar.org/paper/2b0c166759059395262e45681c8a7f15001bbb12\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2011.09289\",\"authors\":[{\"authorId\":\"1491321681\",\"name\":\"Alptekin Orbay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bb8bfe4591346e839cc671d09ddb110bed48bff\",\"title\":\"Master Thesis: Neural Sign Language Translation by Learning Tokenization\",\"url\":\"https://www.semanticscholar.org/paper/3bb8bfe4591346e839cc671d09ddb110bed48bff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.06640\",\"authors\":[{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"104382958\",\"name\":\"P. Xu\"},{\"authorId\":\"1401079497\",\"name\":\"David B. D'Ambrosio\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"2574014\",\"name\":\"H. Phan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"title\":\"SPIN: A High Speed, High Resolution Vision Dataset for Tracking and Action Recognition in Ping Pong\",\"url\":\"https://www.semanticscholar.org/paper/6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.12743\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"66370228\",\"name\":\"J. Yoo\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"15460136\",\"name\":\"Jianqiu Zheng\"}],\"doi\":\"10.1109/ICCV.2019.00642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89917e19175eb4f3bca02e0bace8f99d6910b054\",\"title\":\"Temporal Attentive Alignment for Large-Scale Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/89917e19175eb4f3bca02e0bace8f99d6910b054\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.05789\",\"authors\":[{\"authorId\":\"1443743722\",\"name\":\"Ying Cheng\"},{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"48699340\",\"name\":\"Zhihao Pan\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"3067458\",\"name\":\"Yuejie Zhang\"}],\"doi\":\"10.1145/3394171.3413869\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"title\":\"Look, Listen, and Attend: Co-Attention Network for Self-Supervised Audio-Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2002.05123\",\"authors\":[{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ef4549c94e1ee3e2a132c63bde4c2de51396febc\",\"title\":\"Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks.\",\"url\":\"https://www.semanticscholar.org/paper/ef4549c94e1ee3e2a132c63bde4c2de51396febc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"152150149\",\"name\":\"Lin Feng\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"}],\"doi\":\"10.1145/3422844.3423052\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"title\":\"HFNet: A Novel Model for Human Focused Sports Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490678582\",\"name\":\"David Ouyang\"},{\"authorId\":\"118832513\",\"name\":\"Bryan He\"},{\"authorId\":\"1490678740\",\"name\":\"Amirata Ghorbani\"},{\"authorId\":\"1591661317\",\"name\":\"Neal Yuan\"},{\"authorId\":\"13509436\",\"name\":\"Joseph Ebinger\"},{\"authorId\":\"2356307\",\"name\":\"C. Langlotz\"},{\"authorId\":\"47894744\",\"name\":\"Paul A. Heidenreich\"},{\"authorId\":\"1932201\",\"name\":\"R. Harrington\"},{\"authorId\":\"31863078\",\"name\":\"D. Liang\"},{\"authorId\":\"2668259\",\"name\":\"E. Ashley\"},{\"authorId\":\"145085305\",\"name\":\"J. Zou\"}],\"doi\":\"10.1038/s41586-020-2145-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f472cbad2e9aa1d2f365d3a95c2a2f946d11b31\",\"title\":\"Video-based AI for beat-to-beat assessment of cardiac function\",\"url\":\"https://www.semanticscholar.org/paper/6f472cbad2e9aa1d2f365d3a95c2a2f946d11b31\",\"venue\":\"Nature\",\"year\":2020},{\"arxivId\":\"2010.09245\",\"authors\":[{\"authorId\":\"81349355\",\"name\":\"S. Leask\"},{\"authorId\":\"74494428\",\"name\":\"V. Mcdonell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caf28f2f8ca43ad108ea539bb1db419d2657ff03\",\"title\":\"Extraction of Discrete Spectra Modes from Video Data Using a Deep Convolutional Koopman Network\",\"url\":\"https://www.semanticscholar.org/paper/caf28f2f8ca43ad108ea539bb1db419d2657ff03\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.07944\",\"authors\":[{\"authorId\":\"49141069\",\"name\":\"Mingjie Li\"},{\"authorId\":\"2904330\",\"name\":\"Youqian Feng\"},{\"authorId\":\"2903790\",\"name\":\"Zhonghai Yin\"},{\"authorId\":\"1776984\",\"name\":\"Cheng Zhou\"},{\"authorId\":\"146700602\",\"name\":\"Fanghao Dong\"},{\"authorId\":\"71219669\",\"name\":\"Yuan Lin\"},{\"authorId\":\"4864147\",\"name\":\"Yuhao Dong\"}],\"doi\":\"10.1088/1742-6596/1325/1/012073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3920ab70d6a8448a23f1ef621d1be57af8b7579\",\"title\":\"An Action Recognition network for specific target based on rMC and RPN\",\"url\":\"https://www.semanticscholar.org/paper/a3920ab70d6a8448a23f1ef621d1be57af8b7579\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923676563\",\"name\":\"J. Chen\"},{\"authorId\":\"1914657988\",\"name\":\"Jeffrey Mao\"},{\"authorId\":\"4625200\",\"name\":\"C. Thiel\"},{\"authorId\":null,\"name\":\"Yao Wang\"}],\"doi\":\"10.1109/EMBC44109.2020.9175645\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d7621bfc4badc50f24534d6510e179b880aec72\",\"title\":\"iWaste: Video-Based Medical Waste Detection and Classification\",\"url\":\"https://www.semanticscholar.org/paper/8d7621bfc4badc50f24534d6510e179b880aec72\",\"venue\":\"2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143955478\",\"name\":\"Xin He\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":\"72871892\",\"name\":\"S. Shi\"},{\"authorId\":\"152170666\",\"name\":\"X. Chu\"},{\"authorId\":\"71855158\",\"name\":\"J. Tang\"},{\"authorId\":\"103576316\",\"name\":\"X. Liu\"},{\"authorId\":\"102168416\",\"name\":\"C. Yan\"},{\"authorId\":\"153389906\",\"name\":\"J. Zhang\"},{\"authorId\":\"72584201\",\"name\":\"G. Ding\"}],\"doi\":\"10.1101/2020.06.08.20125963\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ca354d24da3f91d6932a4558d946884a96929b5\",\"title\":\"Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans\",\"url\":\"https://www.semanticscholar.org/paper/1ca354d24da3f91d6932a4558d946884a96929b5\",\"venue\":\"medRxiv\",\"year\":2020},{\"arxivId\":\"2002.12886\",\"authors\":[{\"authorId\":\"1965933798\",\"name\":\"Alban Main De Boissiere\"},{\"authorId\":\"2479033\",\"name\":\"Rita Noumeir\"}],\"doi\":\"10.1109/ACCESS.2020.3023599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"title\":\"Infrared and 3D Skeleton Feature Fusion for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.01455\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2019.01018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"title\":\"Representation Flow for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.12708\",\"authors\":[{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"9427217\",\"name\":\"I. Dwivedi\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/ICRA.2019.8794137\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07dd4a2c0c5d783206684eb8977a8a8d9e130a0a\",\"title\":\"Dynamic Traffic Scene Classification with Space-Time Coherence\",\"url\":\"https://www.semanticscholar.org/paper/07dd4a2c0c5d783206684eb8977a8a8d9e130a0a\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1904.07774\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"102575548\",\"name\":\"Cheston Tan Yin Chet\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":\"10.1109/WACV45572.2020.9093263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf8d2362335ffd9706f61e70b65478517ce7f560\",\"title\":\"Weakly Supervised Gaussian Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/cf8d2362335ffd9706f61e70b65478517ce7f560\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1912.03442\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/WACV45572.2020.9093368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afafc4077d9ead2260c6ab12293ada21ee889747\",\"title\":\"Spatio-Temporal Pyramid Graph Convolutions for Human Action Recognition and Postural Assessment\",\"url\":\"https://www.semanticscholar.org/paper/afafc4077d9ead2260c6ab12293ada21ee889747\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1606148625\",\"name\":\"Salma Abdel Magid\"},{\"authorId\":\"72339339\",\"name\":\"Won-Dong Jang\"},{\"authorId\":\"1606093667\",\"name\":\"Denis Schapiro\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"2940596\",\"name\":\"P. Sorger\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1101/2020.03.24.004085\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c5f6ff5cddd7f6ad5ca431b26bbe5e542c46b641\",\"title\":\"Channel Embedding for Informative Protein Identification from Highly Multiplexed Images\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ff5cddd7f6ad5ca431b26bbe5e542c46b641\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153490631\",\"name\":\"Y. Chang\"},{\"authorId\":\"100842298\",\"name\":\"C. S. Chan\"},{\"authorId\":\"1711669\",\"name\":\"Paolo Remagnino\"}],\"doi\":\"10.1007/s00521-020-04982-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7a88c44f85f9ed9ac27de55d1838ba3ce4d05a2\",\"title\":\"Action recognition on continuous video\",\"url\":\"https://www.semanticscholar.org/paper/a7a88c44f85f9ed9ac27de55d1838ba3ce4d05a2\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2006517981\",\"name\":\"Zhenxing Zhou\"},{\"authorId\":\"2007221895\",\"name\":\"Yisiang Neo\"},{\"authorId\":\"49690966\",\"name\":\"K. Lui\"},{\"authorId\":\"48640237\",\"name\":\"V. Tam\"},{\"authorId\":\"1725389\",\"name\":\"E. Lam\"},{\"authorId\":\"145837602\",\"name\":\"N. Wong\"}],\"doi\":\"10.1145/3373625.3418046\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b0d7135c121e4e5a11fbd373628162476a1c975\",\"title\":\"A Portable Hong Kong Sign Language Translation Platform with Deep Learning and Jetson Nano\",\"url\":\"https://www.semanticscholar.org/paper/8b0d7135c121e4e5a11fbd373628162476a1c975\",\"venue\":\"ASSETS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97992296\",\"name\":\"P. Wang\"},{\"authorId\":\"2713305\",\"name\":\"Yunsheng Jiang\"},{\"authorId\":\"114650835\",\"name\":\"Chunxu Xu\"},{\"authorId\":\"100575838\",\"name\":\"Xiaohui Xie\"}],\"doi\":\"10.1145/3343031.3356085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f3a1829f6415d0956a9218e53a598755fab76a8\",\"title\":\"Overview of Content-Based Click-Through Rate Prediction Challenge for Video Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/5f3a1829f6415d0956a9218e53a598755fab76a8\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145309464\",\"name\":\"Min Jiang\"},{\"authorId\":\"51010977\",\"name\":\"N. Pan\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"}],\"doi\":\"10.1016/j.jvcir.2020.102846\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"title\":\"Spatial-temporal saliency action mask attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2006.05091\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f252cf230c32847099908e4eda9a37c3086fcb8a\",\"title\":\"PNL: Efficient Long-Range Dependencies Extraction with Pyramid Non-Local Module for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f252cf230c32847099908e4eda9a37c3086fcb8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"34608228\",\"name\":\"Xu-dong Jiang\"},{\"authorId\":\"3108302\",\"name\":\"Wei-Long Zheng\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/TCSVT.2020.2976789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"title\":\"Early Action Recognition With Category Exclusion Using Policy-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2011.10217\",\"authors\":[{\"authorId\":\"49049926\",\"name\":\"Jianpeng Zhang\"},{\"authorId\":\"1515611919\",\"name\":\"Yutong Xie\"},{\"authorId\":\"1424398780\",\"name\":\"Yong Xia\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e61c4f9f6c10e5c65aa7ab4b6e12e0c7afaf1f16\",\"title\":\"DoDNet: Learning to segment multi-organ and tumors from multiple partially labeled datasets\",\"url\":\"https://www.semanticscholar.org/paper/e61c4f9f6c10e5c65aa7ab4b6e12e0c7afaf1f16\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738178502\",\"name\":\"Matheus Gutoski\"},{\"authorId\":\"3225435\",\"name\":\"A. E. Lazzaretti\"},{\"authorId\":\"1806302\",\"name\":\"H. Lopes\"}],\"doi\":\"10.1007/s00521-020-05009-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f449b6f662a729b045b7bed80254b5bd30505d1\",\"title\":\"Deep metric learning for open-set human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/1f449b6f662a729b045b7bed80254b5bd30505d1\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"2003.14111\",\"authors\":[{\"authorId\":null,\"name\":\"Ziyu Liu\"},{\"authorId\":\"49724467\",\"name\":\"Hongwen Zhang\"},{\"authorId\":\"2075098\",\"name\":\"Zhenghao Chen\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"}],\"doi\":\"10.1109/cvpr42600.2020.00022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f1ae8eea7f9a4a8f894f71a94bb13e26cd65a62\",\"title\":\"Disentangling and Unifying Graph Convolutions for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f1ae8eea7f9a4a8f894f71a94bb13e26cd65a62\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108484451\",\"name\":\"M. Coster\"},{\"authorId\":\"10182287\",\"name\":\"M. V. Herreweghe\"},{\"authorId\":\"2309489\",\"name\":\"J. Dambre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35d9a4812e325eec9a8993e9a8d9e96234f1c323\",\"title\":\"Sign Language Recognition with Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/35d9a4812e325eec9a8993e9a8d9e96234f1c323\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca2c5474491f0a7117e7ca05fc2bdf49deff4b68\",\"title\":\"Symbiotic Attention: UTS-Baidu Submission to the EPIC-Kitchens 2020 Action Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/ca2c5474491f0a7117e7ca05fc2bdf49deff4b68\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1907.04632\",\"authors\":[{\"authorId\":\"145439284\",\"name\":\"Wei Peng\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/ICIP.2019.8802919\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"title\":\"Video Action Recognition Via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"122288178\",\"name\":\"M. Zakizadeh\"},{\"authorId\":\"48328490\",\"name\":\"J. Brady\"},{\"authorId\":\"145674348\",\"name\":\"Diane Calderon\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.1109/COASE.2019.8843199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"beca19ef5b02b4d88008057fc6d4dc6eb8dbaaee\",\"title\":\"An Intelligent Action Recognition System to assess Cognitive Behavior for Executive Function Disorder\",\"url\":\"https://www.semanticscholar.org/paper/beca19ef5b02b4d88008057fc6d4dc6eb8dbaaee\",\"venue\":\"2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)\",\"year\":2019},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"title\":\"Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units\",\"url\":\"https://www.semanticscholar.org/paper/2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.08340\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"title\":\"Only Time Can Tell: Discovering Temporal Data for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"2033687\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"97829466\",\"name\":\"W. Liu\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"}],\"doi\":\"10.1109/ACCESS.2020.2969290\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad5392cff1c693ca07804071b26ad907f3a5ba63\",\"title\":\"A Hybrid-3D Convolutional Network for Video Compressive Sensing\",\"url\":\"https://www.semanticscholar.org/paper/ad5392cff1c693ca07804071b26ad907f3a5ba63\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"}],\"doi\":\"10.1109/IPAS.2018.8708877\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"title\":\"Learning to Represent Spatio-Temporal Features for Fine Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":\"1908.08997\",\"authors\":[{\"authorId\":\"145801577\",\"name\":\"T. Hartley\"},{\"authorId\":\"47703950\",\"name\":\"K. Sidorov\"},{\"authorId\":\"97959395\",\"name\":\"C. Willis\"},{\"authorId\":\"144353457\",\"name\":\"A. D. Marshall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e1919f55a56d02cdffb69d9da6d7919bb359bd6\",\"title\":\"Gradient Weighted Superpixels for Interpretability in CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3e1919f55a56d02cdffb69d9da6d7919bb359bd6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1804.01429\",\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/ICCV.2019.00135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9664f41b8e21125fed01fa3858ca40949fb73e01\",\"title\":\"Layout-Induced Video Representation for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/9664f41b8e21125fed01fa3858ca40949fb73e01\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145268563\",\"name\":\"S. Amini\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2019.2959426\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"title\":\"Spatio-Temporal VLAD Encoding of Visual Events Using Temporal Ordering of the Mid-Level Deep Semantics\",\"url\":\"https://www.semanticscholar.org/paper/fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31711745\",\"name\":\"Murilo Varges da Silva\"},{\"authorId\":\"1683019\",\"name\":\"A. N. Marana\"}],\"doi\":\"10.1109/BRACIS.2019.00134\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35589bdaa822608ac3c9f07731261e51c02fc90f\",\"title\":\"Human Action Recognition using 2D Poses\",\"url\":\"https://www.semanticscholar.org/paper/35589bdaa822608ac3c9f07731261e51c02fc90f\",\"venue\":\"BRACIS\",\"year\":2019},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.00826\",\"authors\":[{\"authorId\":null,\"name\":\"Zihao Wang\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"1999541581\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"316931202b0d02d37672a976f43bb1ed479c6877\",\"title\":\"PV-NAS: Practical Neural Architecture Search for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/316931202b0d02d37672a976f43bb1ed479c6877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.07519\",\"authors\":[{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"title\":\"Higher-order Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.13278\",\"authors\":[{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ea5fe569cd48c588b7fe420965016ed4ddd312\",\"title\":\"Representation Learning with Video Deep InfoMax\",\"url\":\"https://www.semanticscholar.org/paper/04ea5fe569cd48c588b7fe420965016ed4ddd312\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49326834\",\"name\":\"Q. Zuo\"},{\"authorId\":\"11857395\",\"name\":\"Lian Zou\"},{\"authorId\":\"73313375\",\"name\":\"Cien Fan\"},{\"authorId\":\"1657188730\",\"name\":\"Dongqian Li\"},{\"authorId\":\"143891653\",\"name\":\"Hao Jiang\"},{\"authorId\":\"47909275\",\"name\":\"Yifeng Liu\"}],\"doi\":\"10.3390/s20247149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c29f728df66434210f115cba745d6ec63a772e3\",\"title\":\"Whole and Part Adaptive Fusion Graph Convolutional Networks for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c29f728df66434210f115cba745d6ec63a772e3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2011.06219\",\"authors\":[{\"authorId\":\"2008850512\",\"name\":\"Stuart Synakowski\"},{\"authorId\":\"145972081\",\"name\":\"Q. Feng\"},{\"authorId\":\"145358414\",\"name\":\"A. Mart\\u00ednez\"}],\"doi\":\"10.1007/s11263-020-01404-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"461e5c60e3ea892731b59d724d294824c8792649\",\"title\":\"Adding Knowledge to Unsupervised Algorithms for the Recognition of Intent\",\"url\":\"https://www.semanticscholar.org/paper/461e5c60e3ea892731b59d724d294824c8792649\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.13474\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICMLA.2019.00036\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"title\":\"Spatio-Temporal FAST 3D Convolutions for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14547418\",\"name\":\"Shengwei Zhou\"},{\"authorId\":\"153555891\",\"name\":\"L. Bai\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"123580511\",\"name\":\"Zhi-Hong Deng\"},{\"authorId\":\"121330693\",\"name\":\"X. Zhu\"},{\"authorId\":\"143724074\",\"name\":\"C. Gong\"}],\"doi\":\"10.12783/dtcse/cisnrc2019/33302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"title\":\"A Spatial-temporal Attention Module for 3D Convolution Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.08915\",\"authors\":[{\"authorId\":\"1388566371\",\"name\":\"Ling Lo\"},{\"authorId\":\"9572307\",\"name\":\"Hongxia Xie\"},{\"authorId\":\"2426757\",\"name\":\"Hong-Han Shuai\"},{\"authorId\":\"1711298\",\"name\":\"W. Cheng\"}],\"doi\":\"10.1109/MIPR49039.2020.00023\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b807db62c227517eb6ef8fe8de57596f67228173\",\"title\":\"MER-GCN: Micro-Expression Recognition Based on Relation Modeling with Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/b807db62c227517eb6ef8fe8de57596f67228173\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.16367\",\"authors\":[{\"authorId\":\"1901361\",\"name\":\"Pramit Saha\"},{\"authorId\":\"46398931\",\"name\":\"Y. Liu\"},{\"authorId\":\"2160324\",\"name\":\"B. Gick\"},{\"authorId\":\"23111666\",\"name\":\"S. Fels\"}],\"doi\":\"10.1007/978-3-030-59716-0_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11809d6c31e471fb45569c5f40f3f4e7566ee3ce\",\"title\":\"Ultra2Speech - A Deep Learning Framework for Formant Frequency Estimation and Tracking from Ultrasound Tongue Images\",\"url\":\"https://www.semanticscholar.org/paper/11809d6c31e471fb45569c5f40f3f4e7566ee3ce\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2498892\",\"name\":\"Pengxiang Wu\"},{\"authorId\":\"1814286\",\"name\":\"Siheng Chen\"},{\"authorId\":\"1711560\",\"name\":\"Dimitris N. Metaxas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6234435197b5325b0b9caf2f5336c2e41e93a268\",\"title\":\"MotionNet: Joint Perception and Motion Prediction for Autonomous Driving Based on Birda\\u0302\\u2022Z\\u030cs Eye View Maps /Author=Wu, Pengxiang; Chen, Siheng /CreationDate=June 9, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/6234435197b5325b0b9caf2f5336c2e41e93a268\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.00132\",\"authors\":[{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/ICCV.2019.00857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f4b5bfe6b7399797e2048695577eb60253f0bbc\",\"title\":\"CapsuleVOS: Semi-Supervised Video Object Segmentation Using Capsule Routing\",\"url\":\"https://www.semanticscholar.org/paper/2f4b5bfe6b7399797e2048695577eb60253f0bbc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.11102\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1923156\",\"name\":\"Peng Yao\"},{\"authorId\":\"1749850\",\"name\":\"Jing Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shichen Lu\"},{\"authorId\":\"2125223\",\"name\":\"Zheng Gen Yu\"},{\"authorId\":\"46641690\",\"name\":\"Wei Liu\"},{\"authorId\":\"46386029\",\"name\":\"Hanqing Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"title\":\"Multi-View Features and Hybrid Reward Strategies for Vatex Video Captioning Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.03597\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"46398631\",\"name\":\"Yunhui Liu\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00413\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics\",\"url\":\"https://www.semanticscholar.org/paper/eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153652147\",\"name\":\"Jagannath Malik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"title\":\"Test-Time Training for Improved Object Affordance Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9ffc9a0da2a9877ab793b9d0f2f3a9eafd67cc29\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.15983\",\"authors\":[{\"authorId\":\"46933964\",\"name\":\"Gabrielle Ras\"},{\"authorId\":\"2396027\",\"name\":\"L. Ambrogioni\"},{\"authorId\":\"69426785\",\"name\":\"Pim Haselager\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"},{\"authorId\":\"8470000\",\"name\":\"Umut Gucclu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a670bb5caa48964329e482414939c43f3dd6e83\",\"title\":\"Explainable 3D Convolutional Neural Networks by Learning Temporal Transformations\",\"url\":\"https://www.semanticscholar.org/paper/6a670bb5caa48964329e482414939c43f3dd6e83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5104979\",\"name\":\"Mingli Yu\"},{\"authorId\":\"123970125\",\"name\":\"T. Cai\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"65763735\",\"name\":\"K. Wong\"},{\"authorId\":\"66836164\",\"name\":\"John Volpi\"},{\"authorId\":\"1815307\",\"name\":\"J. Wang\"},{\"authorId\":\"49558522\",\"name\":\"S. Wong\"}],\"doi\":\"10.1007/978-3-030-59716-0_59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51e9d30f7100a045d96fbc4bc8dbaca007a8dc82\",\"title\":\"Toward Rapid Stroke Diagnosis with Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/51e9d30f7100a045d96fbc4bc8dbaca007a8dc82\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.05721\",\"authors\":[{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48411936\",\"name\":\"H. Lee\"},{\"authorId\":\"80069330\",\"name\":\"Dong Heon Cho\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24b300420bd814e48b59a3419a22d706da6c4191\",\"title\":\"Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24b300420bd814e48b59a3419a22d706da6c4191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.08670\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"2966051\",\"name\":\"Amirreza Shaban\"},{\"authorId\":\"67294118\",\"name\":\"Michael L. Iuzzolino\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":\"10.1109/cvpr42600.2020.01330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb8304061be88b2452872e12a53b23bc9f6b4925\",\"title\":\"MMTM: Multimodal Transfer Module for CNN Fusion\",\"url\":\"https://www.semanticscholar.org/paper/eb8304061be88b2452872e12a53b23bc9f6b4925\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424365\",\"name\":\"Delaram Behnami\"},{\"authorId\":\"2616139\",\"name\":\"Zhibin Liao\"},{\"authorId\":\"150122252\",\"name\":\"Hany Girgis\"},{\"authorId\":\"48797076\",\"name\":\"Christina Luong\"},{\"authorId\":\"2066272\",\"name\":\"R. Rohling\"},{\"authorId\":\"32521381\",\"name\":\"K. Gin\"},{\"authorId\":\"145172765\",\"name\":\"Teresa Tsang\"},{\"authorId\":\"2427371\",\"name\":\"P. Abolmaesumi\"}],\"doi\":\"10.1007/978-3-030-32245-8_77\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a21c6dfc97813a86132925ae2fe4831bf5122e0\",\"title\":\"Dual-View Joint Estimation of Left Ventricular Ejection Fraction with Uncertainty Modelling in Echocardiograms\",\"url\":\"https://www.semanticscholar.org/paper/0a21c6dfc97813a86132925ae2fe4831bf5122e0\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88762202\",\"name\":\"J. Li\"},{\"authorId\":\"1888867\",\"name\":\"X. Jiang\"},{\"authorId\":\"3307728\",\"name\":\"T. Sun\"},{\"authorId\":\"2876147\",\"name\":\"K. Xu\"}],\"doi\":\"10.1109/AVSS.2019.8909883\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a029b5380133aa2aee82064182683e5db81eeeb\",\"title\":\"Efficient Violence Detection Using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8a029b5380133aa2aee82064182683e5db81eeeb\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1016/j.patcog.2020.107695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e69494bfc8e8156a7f4cc42d9052b57b6e4241\",\"title\":\"Temporal filtering networks for online action detection\",\"url\":\"https://www.semanticscholar.org/paper/86e69494bfc8e8156a7f4cc42d9052b57b6e4241\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.09918\",\"authors\":[{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b8ec500aedc97cc9874a9eb601cef37c5f38e3f\",\"title\":\"Quantitative Survey of the State of the Art in Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b8ec500aedc97cc9874a9eb601cef37c5f38e3f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05769\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01637f04eac8523b6c4887d419bd718f65860982\",\"title\":\"Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/01637f04eac8523b6c4887d419bd718f65860982\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1845915519\",\"name\":\"Eric Kasangu Lubamba\"},{\"authorId\":\"92581630\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3008848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c7c4556126f7219886cd28e4f33c85586f24955\",\"title\":\"Action Prediction Based on Partial Video Observation via Context and Temporal Sequential Network With Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/5c7c4556126f7219886cd28e4f33c85586f24955\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.02129\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"1768574\",\"name\":\"P. Yuen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"title\":\"Self-supervised Temporal Discriminative Learning for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.08648\",\"authors\":[{\"authorId\":\"38092305\",\"name\":\"Sara Moccia\"},{\"authorId\":\"102303915\",\"name\":\"Lucia Migliorelli\"},{\"authorId\":\"153139935\",\"name\":\"V. Carnielli\"},{\"authorId\":\"1721130\",\"name\":\"E. Frontoni\"}],\"doi\":\"10.1109/TBME.2019.2961448\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"680b9c162ae8d1528bb51ec4dcdb48b3033bcf22\",\"title\":\"Preterm Infants\\u2019 Pose Estimation With Spatio-Temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/680b9c162ae8d1528bb51ec4dcdb48b3033bcf22\",\"venue\":\"IEEE Transactions on Biomedical Engineering\",\"year\":2020},{\"arxivId\":\"1908.04353\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"},{\"authorId\":null,\"name\":\"HaiBo Chen\"}],\"doi\":\"10.1007/978-3-030-41299-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2099f70cabf2a8efaa3c84ee4d3c59bcc7d1518f\",\"title\":\"Action Recognition in Untrimmed Videos with Composite Self-Attention Two-Stream Framework\",\"url\":\"https://www.semanticscholar.org/paper/2099f70cabf2a8efaa3c84ee4d3c59bcc7d1518f\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":\"1812.06145\",\"authors\":[{\"authorId\":\"3152993\",\"name\":\"Mahdi Abavisani\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/CVPR.2019.00126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae\",\"title\":\"Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition With Multimodal Training\",\"url\":\"https://www.semanticscholar.org/paper/7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.03857\",\"authors\":[{\"authorId\":null,\"name\":\"Yufei Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"425c33485b32301df75d16cb9cd224763782da8c\",\"title\":\"UniDual: A Unified Model for Image and Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/425c33485b32301df75d16cb9cd224763782da8c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2004.01494\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"title\":\"Two-Stream AMTnet for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48599063\",\"name\":\"Ziqi Yang\"},{\"authorId\":\"46810102\",\"name\":\"X. Gong\"},{\"authorId\":\"46791330\",\"name\":\"Ying Guo\"},{\"authorId\":\"49663403\",\"name\":\"Wenbin Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2990683\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"title\":\"A Temporal Sequence Dual-Branch Network for Classifying Hybrid Ultrasound Data of Breast Cancer\",\"url\":\"https://www.semanticscholar.org/paper/52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.00497\",\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/ICCVW.2019.00552\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5769318fd67d1104e561b7382b305b5ca810d6d2\",\"title\":\"Two-Stream Video Classification with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/5769318fd67d1104e561b7382b305b5ca810d6d2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1812.02707\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94bbc4ea271c918705876b60d98d227a0ab55a43\",\"title\":\"Video Action Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.08895\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"65961eb0380182c32ab3d018c83010aa80969d8a\",\"title\":\"An Efficient 3D CNN for Action/Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/65961eb0380182c32ab3d018c83010aa80969d8a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3234563\",\"name\":\"Qidi Xu\"},{\"authorId\":\"9539022\",\"name\":\"Haocheng Xu\"},{\"authorId\":\"40426833\",\"name\":\"Wei-Long Chen\"},{\"authorId\":\"8004535\",\"name\":\"Chaojun Han\"},{\"authorId\":\"144911687\",\"name\":\"Haoyang Li\"},{\"authorId\":\"26990639\",\"name\":\"Wen-xin Tan\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3343031.3356077\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e2835bb03fad65986f21bb3332f06b661abbe82\",\"title\":\"Time-aware Session Embedding for Click-Through-Rate Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4e2835bb03fad65986f21bb3332f06b661abbe82\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2724075\",\"name\":\"Yiping Tang\"},{\"authorId\":\"51431831\",\"name\":\"Chuang Niu\"},{\"authorId\":\"35182090\",\"name\":\"Minghao Dong\"},{\"authorId\":\"10648494\",\"name\":\"Shenghan Ren\"},{\"authorId\":\"145157018\",\"name\":\"J. Liang\"}],\"doi\":\"10.1007/978-3-030-31723-2_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0603f946c7613af4122ebd9cee6d10885f008501\",\"title\":\"Poleward Moving Aurora Recognition with Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/0603f946c7613af4122ebd9cee6d10885f008501\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024784\",\"name\":\"Ye Li\"},{\"authorId\":\"7188881\",\"name\":\"Guangqiang Yin\"},{\"authorId\":\"145802850\",\"name\":\"S. Hou\"},{\"authorId\":\"16176062\",\"name\":\"Jianhai Cui\"},{\"authorId\":\"2105845\",\"name\":\"Zicheng Huang\"}],\"doi\":\"10.1007/978-3-030-23597-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33e44db6706969ca9f16d81805089c3d05519b75\",\"title\":\"Spatiotemporal Feature Extraction for Pedestrian Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/33e44db6706969ca9f16d81805089c3d05519b75\",\"venue\":\"WASA\",\"year\":2019},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245968\",\"name\":\"Thomas K\\u00fcstner\"},{\"authorId\":\"2610845\",\"name\":\"N. Fuin\"},{\"authorId\":\"1876308218\",\"name\":\"Kerstin Hammernik\"},{\"authorId\":\"1691643\",\"name\":\"A. Bustin\"},{\"authorId\":\"145671101\",\"name\":\"H. Qi\"},{\"authorId\":\"6972313\",\"name\":\"R. Hajhosseiny\"},{\"authorId\":\"40087744\",\"name\":\"P. Masci\"},{\"authorId\":\"34921299\",\"name\":\"R. Neji\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"49848164\",\"name\":\"R. Botnar\"},{\"authorId\":\"2049035\",\"name\":\"C. Prieto\"}],\"doi\":\"10.1038/s41598-020-70551-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcc3d33c0e2a967c51a016c6c1505fcf4265163f\",\"title\":\"CINENet: deep learning-based 3D cardiac CINE MRI reconstruction with multi-coil complex-valued 4D spatio-temporal convolutions\",\"url\":\"https://www.semanticscholar.org/paper/dcc3d33c0e2a967c51a016c6c1505fcf4265163f\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":\"2011.10834\",\"authors\":[{\"authorId\":\"1944615571\",\"name\":\"A. Almeida\"},{\"authorId\":\"145334240\",\"name\":\"J. P. D. Villiers\"},{\"authorId\":\"145515736\",\"name\":\"A. D. Freitas\"},{\"authorId\":\"1944660087\",\"name\":\"M. Velayudan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1d17ac263557f5306e620b431354cc84df14be0\",\"title\":\"Exploring the multimodal information from video content using deep learning features of appearance, audio and action for video recommendation\",\"url\":\"https://www.semanticscholar.org/paper/c1d17ac263557f5306e620b431354cc84df14be0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1606148625\",\"name\":\"Salma Abdel Magid\"},{\"authorId\":\"2472814\",\"name\":\"Won-Dong Jang\"},{\"authorId\":\"1606093667\",\"name\":\"Denis Schapiro\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"2940596\",\"name\":\"P. Sorger\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1007/978-3-030-59722-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fac6f728822a8321bc1110e4b62f51e1fdd7f7b\",\"title\":\"Channel Embedding for Informative Protein Identification from Highly Multiplexed Images\",\"url\":\"https://www.semanticscholar.org/paper/2fac6f728822a8321bc1110e4b62f51e1fdd7f7b\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98026232\",\"name\":\"Zeyuan Chen\"},{\"authorId\":\"153162713\",\"name\":\"K. Xu\"},{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"}],\"doi\":\"10.1145/3343031.3356068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5a32075cda0340a98f2e14157834c17442d81e3\",\"title\":\"Content-Based Video Relevance Prediction with Multi-view Multi-level Deep Interest Network\",\"url\":\"https://www.semanticscholar.org/paper/b5a32075cda0340a98f2e14157834c17442d81e3\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1905.05143\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"title\":\"VideoGraph: Recognizing Minutes-Long Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668321\",\"name\":\"Yuchen Fan\"},{\"authorId\":\"150167366\",\"name\":\"Jiahui Yu\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"},{\"authorId\":\"143750392\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPRW.2019.00269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79d344c5705b3a54fc2af2c6783b0b4c65c706a0\",\"title\":\"An Empirical Investigation of Efficient Spatio-Temporal Modeling in Video Restoration\",\"url\":\"https://www.semanticscholar.org/paper/79d344c5705b3a54fc2af2c6783b0b4c65c706a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629172313\",\"name\":\"Liqing Wan\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"34985619\",\"name\":\"Xiaoping Che\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"title\":\"A Fast Action Recognition Method with Cascaded Networks\",\"url\":\"https://www.semanticscholar.org/paper/bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739109016\",\"name\":\"Dibyadip Chatterjee\"},{\"authorId\":\"1739984148\",\"name\":\"Charu Arora\"},{\"authorId\":\"1739013163\",\"name\":\"Saurajit Chakraborty\"},{\"authorId\":\"2098015\",\"name\":\"S. Saha\"}],\"doi\":\"10.1109/CALCON49167.2020.9106564\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20dc4639fd61e5ab1641f26f20dff0b91f8cabed\",\"title\":\"Human Activity Recognition based on Summarized Semi-detailed Frame Information and Contextual Features\",\"url\":\"https://www.semanticscholar.org/paper/20dc4639fd61e5ab1641f26f20dff0b91f8cabed\",\"venue\":\"2020 IEEE Calcutta Conference (CALCON)\",\"year\":2020},{\"arxivId\":\"2003.11851\",\"authors\":[{\"authorId\":\"143707982\",\"name\":\"Lu Wang\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"39632903\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"65906901\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"867db00148be8bc966a49a15eeb0621310e9e376\",\"title\":\"Coronary Artery Segmentation in Angiographic Videos Using A 3D-2D CE-Net\",\"url\":\"https://www.semanticscholar.org/paper/867db00148be8bc966a49a15eeb0621310e9e376\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"title\":\"Improving gesture recognition through spatial focus of attention\",\"url\":\"https://www.semanticscholar.org/paper/a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47557746\",\"name\":\"Y. Chen\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207404\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2807495123a402bee172b9697f3a98a2351d134\",\"title\":\"Lightweight Action Recognition with Sequence-Specific Global Context\",\"url\":\"https://www.semanticscholar.org/paper/e2807495123a402bee172b9697f3a98a2351d134\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46381810\",\"name\":\"H. Li\"},{\"authorId\":\"102461379\",\"name\":\"J. Wang\"},{\"authorId\":\"3033573\",\"name\":\"Jian-Jun Han\"},{\"authorId\":\"49049946\",\"name\":\"Jinmin Zhang\"},{\"authorId\":\"2808646\",\"name\":\"Yushan Yang\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"}],\"doi\":\"10.1177/0020294020902788\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85810af8b757717d81ab63772d2958445e0818f8\",\"title\":\"A novel multi-stream method for violent interaction detection using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/85810af8b757717d81ab63772d2958445e0818f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.03152\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"50463545\",\"name\":\"Yang Guan\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"49576139\",\"name\":\"Longfei Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f0320cd101ed6426a4330ecb395015c266e976c\",\"title\":\"CTM: Collaborative Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f0320cd101ed6426a4330ecb395015c266e976c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07711\",\"authors\":[{\"authorId\":\"1637242169\",\"name\":\"Guglielmo Camporese\"},{\"authorId\":\"29776698\",\"name\":\"Pasquale Coscia\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc24772bf84d9ff92166d8f228284c4079619ed0\",\"title\":\"Knowledge Distillation for Action Anticipation via Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/dc24772bf84d9ff92166d8f228284c4079619ed0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51471751\",\"name\":\"L. Wang\"},{\"authorId\":\"1750908328\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"1750919212\",\"name\":\"Xiaolei Yin\"},{\"authorId\":\"1749687892\",\"name\":\"Jing Qiu\"},{\"authorId\":\"50109694\",\"name\":\"Z. Yang\"},{\"authorId\":\"8262648\",\"name\":\"Junhui Xing\"},{\"authorId\":\"28094546\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"9249638\",\"name\":\"Zhao-yuan Ma\"}],\"doi\":\"10.1186/s12880-020-00509-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3edbb47db70ec1243530c0efd4257e138a99a959\",\"title\":\"Coronary artery segmentation in angiographic videos utilizing spatial-temporal information\",\"url\":\"https://www.semanticscholar.org/paper/3edbb47db70ec1243530c0efd4257e138a99a959\",\"venue\":\"BMC Medical Imaging\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66980738\",\"name\":\"Kele Belloze\"},{\"authorId\":\"118349635\",\"name\":\"L. Campos\"},{\"authorId\":\"1473660827\",\"name\":\"Ribamar Matias\"},{\"authorId\":\"2019430181\",\"name\":\"Ivair Luques\"},{\"authorId\":\"31778392\",\"name\":\"E. Bezerra\"}],\"doi\":\"10.1007/978-3-030-51862-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bbc119e43ff7fe24ed76f2a7d2e54af385eb05f\",\"title\":\"A Review of Artificial Neural Networks for the Prediction of Essential Proteins\",\"url\":\"https://www.semanticscholar.org/paper/2bbc119e43ff7fe24ed76f2a7d2e54af385eb05f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.02870\",\"authors\":[{\"authorId\":null,\"name\":\"Sheng Li\"},{\"authorId\":\"51209425\",\"name\":\"Fengxiang He\"},{\"authorId\":\"145728792\",\"name\":\"B. Du\"},{\"authorId\":null,\"name\":\"Lefei Zhang\"},{\"authorId\":\"4154180\",\"name\":\"Y. Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01077\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"42c9eaaa70124af1f41a90286db4a009c616d873\",\"title\":\"Fast Spatio-Temporal Residual Network for Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/42c9eaaa70124af1f41a90286db4a009c616d873\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.11954\",\"authors\":[{\"authorId\":\"2117357\",\"name\":\"Chengxu Zhuang\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"40657572\",\"name\":\"D. Yamins\"}],\"doi\":\"10.1109/CVPR42600.2020.00958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02cd7e1a888fedd25337a4598f332c5203091e71\",\"title\":\"Unsupervised Learning From Video With Deep Neural Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/02cd7e1a888fedd25337a4598f332c5203091e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.01311\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"1961370098\",\"name\":\"Francesca Palermo\"},{\"authorId\":\"8290049\",\"name\":\"G. Solak\"},{\"authorId\":\"36686679\",\"name\":\"Claudio Coppola\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"674dd1fa7c67df6b5c68f3b5910790b980ebf413\",\"title\":\"Top-1 CORSMAL Challenge 2020 Submission: Filling Mass Estimation Using Multi-modal Observations of Human-robot Handovers\",\"url\":\"https://www.semanticscholar.org/paper/674dd1fa7c67df6b5c68f3b5910790b980ebf413\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14371\",\"authors\":[{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"145131935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"209b706757048dd8606185bb2ca27c31ff991dd3\",\"title\":\"Tensor Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/209b706757048dd8606185bb2ca27c31ff991dd3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.03330\",\"authors\":[{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/cvpr42600.2020.00654\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4906a09839dcb6ac96a52e06bc7bd613f0482967\",\"title\":\"ClusterFit: Improving Generalization of Visual Representations\",\"url\":\"https://www.semanticscholar.org/paper/4906a09839dcb6ac96a52e06bc7bd613f0482967\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.06288\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"98256637\",\"name\":\"Zhou Yang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46946060\",\"name\":\"M. Jian\"},{\"authorId\":\"49217626\",\"name\":\"Boxuan Zhao\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.07.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50efde486726ae435c28211b6cd123c6b61e3a99\",\"title\":\"Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/50efde486726ae435c28211b6cd123c6b61e3a99\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1907.11921\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"50672766\",\"name\":\"Wei Peng\"},{\"authorId\":\"20868803\",\"name\":\"Xiao-Bai Li\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/ICCV.2019.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97c4a50bb344575705703431ee1114279a717a59\",\"title\":\"Remote Heart Rate Measurement From Highly Compressed Facial Videos: An End-to-End Deep Learning Solution With Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/97c4a50bb344575705703431ee1114279a717a59\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2018.2882805\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02c293bc06c580305c8b62a8ed90f37a75608493\",\"title\":\"Adversarial Action Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/02c293bc06c580305c8b62a8ed90f37a75608493\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1905.00546\",\"authors\":[{\"authorId\":\"3059058\",\"name\":\"I. Z. Yalniz\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88ee291cf1f57fd0f4914a80b986a08a90d887f1\",\"title\":\"Billion-scale semi-supervised learning for image classification\",\"url\":\"https://www.semanticscholar.org/paper/88ee291cf1f57fd0f4914a80b986a08a90d887f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.01197\",\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.1109/CVPR.2019.00806\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"title\":\"Collaborative Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152390773\",\"name\":\"B. Jiang\"},{\"authorId\":\"46696524\",\"name\":\"Lei Zhou\"},{\"authorId\":\"152644243\",\"name\":\"L. Lin\"},{\"authorId\":\"36557488\",\"name\":\"B. Xu\"},{\"authorId\":\"4074288\",\"name\":\"Jiahong Yu\"},{\"authorId\":\"70538826\",\"name\":\"Xu-ping Zheng\"},{\"authorId\":\"119685358\",\"name\":\"K. Wu\"}],\"doi\":\"10.1109/ICIP.2019.8803838\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2283ea00819c199394589af4710e47b36789c297\",\"title\":\"A Real-Time Multi-Label Classification System for Short Videos\",\"url\":\"https://www.semanticscholar.org/paper/2283ea00819c199394589af4710e47b36789c297\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alexandr Lenk\"},{\"authorId\":null,\"name\":\"Matias Cersosimo\"},{\"authorId\":null,\"name\":\"Negin Raoof\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1e0678bc378d505b4b6f04ad1f9b0c6cd7738ea\",\"title\":\"A Novel Approach for Predicting and Understanding Road Danger in the Developing World: Deep Video-Classification of Roads in Nairobi, Kenya\",\"url\":\"https://www.semanticscholar.org/paper/c1e0678bc378d505b4b6f04ad1f9b0c6cd7738ea\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337601\",\"name\":\"Weiqing Huang\"},{\"authorId\":null,\"name\":\"Yi Liu\"},{\"authorId\":\"17121478\",\"name\":\"Shao-yi Zhu\"},{\"authorId\":\"2681852\",\"name\":\"S. Wang\"},{\"authorId\":\"49889061\",\"name\":\"Yanfang Zhang\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207590\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed0fcf2441d42d52d7b81d40a042b4ab8117543b\",\"title\":\"TSCNN: A 3D Convolutional Activity Recognition Network Based on RFID RSSI\",\"url\":\"https://www.semanticscholar.org/paper/ed0fcf2441d42d52d7b81d40a042b4ab8117543b\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Valeo. ai\"},{\"authorId\":null,\"name\":\"Valeo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c8707ffb59b37029942baf4606b415b462de8eb\",\"title\":\"Driving Behavior Explanation with Multi-level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/9c8707ffb59b37029942baf4606b415b462de8eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"48641524\",\"name\":\"Sainan Liu\"},{\"authorId\":\"2010983\",\"name\":\"Zeyu Chen\"},{\"authorId\":\"47744833\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/CVPR.2018.00484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36777066966899fb48c1850d5776af97f1c81942\",\"title\":\"Attentional ShapeContextNet for Point Cloud Recognition\",\"url\":\"https://www.semanticscholar.org/paper/36777066966899fb48c1850d5776af97f1c81942\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.07468\",\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1609/aaai.v33i01.33018618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"title\":\"Multi-scale 3D Convolution Network for Video Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.04075\",\"authors\":[{\"authorId\":\"46933964\",\"name\":\"Gabrielle Ras\"},{\"authorId\":\"2396027\",\"name\":\"L. Ambrogioni\"},{\"authorId\":\"80777440\",\"name\":\"U. G\\u00fc\\u00e7l\\u00fc\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f90ba2a26a7647eb9d3d7936ce596cd138d1dd9\",\"title\":\"Temporal Factorization of 3D Convolutional Kernels\",\"url\":\"https://www.semanticscholar.org/paper/4f90ba2a26a7647eb9d3d7936ce596cd138d1dd9\",\"venue\":\"BNAIC/BENELEARN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968723\",\"name\":\"Zhenyu Mao\"},{\"authorId\":\"145376847\",\"name\":\"Yi Su\"},{\"authorId\":\"7322490\",\"name\":\"Guangquan Xu\"},{\"authorId\":\"145672258\",\"name\":\"X. Wang\"},{\"authorId\":\"72051965\",\"name\":\"Y. Huang\"},{\"authorId\":\"35481850\",\"name\":\"W. Yue\"},{\"authorId\":\"51240979\",\"name\":\"L. Sun\"},{\"authorId\":\"145826495\",\"name\":\"N. Xiong\"}],\"doi\":\"10.1016/J.INS.2019.05.043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2b0383369172e08d91bc60fb70a9a988c317cc\",\"title\":\"Spatio-temporal deep learning method for ADHD fMRI classification\",\"url\":\"https://www.semanticscholar.org/paper/1a2b0383369172e08d91bc60fb70a9a988c317cc\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"102542533\",\"name\":\"M. M. I. Bhuiyan\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd6b78e4b9c50f9783a5d6f4eed09216ece3c508\",\"title\":\"Weight Excitation: Built-in Attention Mechanisms in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dd6b78e4b9c50f9783a5d6f4eed09216ece3c508\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845267\",\"name\":\"Da Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00394\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"daf161f0f763bf19246ad51338764c9f732d11f0\",\"title\":\"METAL: Minimum Effort Temporal Activity Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/daf161f0f763bf19246ad51338764c9f732d11f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70381988\",\"name\":\"A. Specker\"},{\"authorId\":\"2000302663\",\"name\":\"Arne Schumann\"},{\"authorId\":\"9374377\",\"name\":\"J. Beyerer\"}],\"doi\":\"10.1109/ICIP40778.2020.9191264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f1b714526e24196d0a76561c1dffbc13bb8344c\",\"title\":\"An Evaluation Of Design Choices For Pedestrian Attribute Recognition In Video\",\"url\":\"https://www.semanticscholar.org/paper/6f1b714526e24196d0a76561c1dffbc13bb8344c\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490678582\",\"name\":\"David Ouyang\"},{\"authorId\":\"118832513\",\"name\":\"Bryan He\"},{\"authorId\":\"1490678740\",\"name\":\"Amirata Ghorbani\"},{\"authorId\":\"1584627064\",\"name\":\"Curt Langlotz\"},{\"authorId\":\"2931109\",\"name\":\"P. Heidenreich\"},{\"authorId\":\"35450785\",\"name\":\"R. Harrington\"},{\"authorId\":\"1969241\",\"name\":\"D. Liang\"},{\"authorId\":\"2668259\",\"name\":\"E. Ashley\"},{\"authorId\":\"1400311393\",\"name\":\"J. Zou\"}],\"doi\":\"10.1101/19012419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f109bf1a2998664234f63e4e4bfc414ef773e958\",\"title\":\"Interpretable AI for beat-to-beat cardiac function assessment\",\"url\":\"https://www.semanticscholar.org/paper/f109bf1a2998664234f63e4e4bfc414ef773e958\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.08925\",\"authors\":[{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2019.00032\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d4dcd7ed33666e05e28b18f86a693264783749c\",\"title\":\"MAC: Mining Activity Concepts for Language-Based Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/1d4dcd7ed33666e05e28b18f86a693264783749c\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038510026\",\"name\":\"Alam Noor\"},{\"authorId\":\"11042085\",\"name\":\"Bilel Benjdira\"},{\"authorId\":\"36383788\",\"name\":\"A. Ammar\"},{\"authorId\":\"1714415\",\"name\":\"A. Koubaa\"}],\"doi\":\"10.1109/SMART-TECH49988.2020.00056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2ed535be49c0b2df368fa6202bea21e69218ca8\",\"title\":\"DriftNet: Aggressive Driving Behaviour Detection using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2ed535be49c0b2df368fa6202bea21e69218ca8\",\"venue\":\"2020 First International Conference of Smart Systems and Emerging Technologies (SMARTTECH)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978134\",\"name\":\"Y. Su\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"48566545\",\"name\":\"J. Zhu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-58548-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60498bfca85f39068f34d222484dc77b23f62035\",\"title\":\"Human Interaction Learning on 3D Skeleton Point Clouds for Video Violence Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60498bfca85f39068f34d222484dc77b23f62035\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00375\",\"authors\":[{\"authorId\":\"152985547\",\"name\":\"Z. Li\"},{\"authorId\":\"40560502\",\"name\":\"W. Wang\"},{\"authorId\":\"121544228\",\"name\":\"Z. Li\"},{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"2003804019\",\"name\":\"Yoichi Sato\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9338b7de4b849cb094aa4cbd5b85f9935a4ae00\",\"title\":\"Towards Visually Explaining Video Understanding Networks with Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/b9338b7de4b849cb094aa4cbd5b85f9935a4ae00\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.10575\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"153462555\",\"name\":\"Yi Yao\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/WACV45572.2020.9093361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3efc52b9a5190f7f24febb01a969bfdeb804e5fe\",\"title\":\"Stacked Spatio-Temporal Graph Convolutional Networks for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3efc52b9a5190f7f24febb01a969bfdeb804e5fe\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b3fd234bd072706af99100edba037b13d5a0069\",\"title\":\"High Order Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5b3fd234bd072706af99100edba037b13d5a0069\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72557716\",\"name\":\"Song Liu\"},{\"authorId\":\"1709381241\",\"name\":\"Qiaolin He\"},{\"authorId\":\"48708884\",\"name\":\"Z. Wang\"},{\"authorId\":\"153005923\",\"name\":\"Y. Pu\"},{\"authorId\":\"4763857\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICCCBDA49378.2020.9095594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"title\":\"Irregular Action Recognition in Court with 3D Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"venue\":\"2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72613367\",\"name\":\"Xingyu Xu\"},{\"authorId\":\"15626401\",\"name\":\"X. Wu\"},{\"authorId\":\"47227094\",\"name\":\"G. Wang\"},{\"authorId\":\"48017178\",\"name\":\"H. Wang\"}],\"doi\":\"10.1109/ISCID.2018.00079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2465ebbe1d40f289a8db4b0dcaf3dbbb9cdc494b\",\"title\":\"Violent Video Classification Based on Spatial-Temporal Cues Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/2465ebbe1d40f289a8db4b0dcaf3dbbb9cdc494b\",\"venue\":\"2018 11th International Symposium on Computational Intelligence and Design (ISCID)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938051940\",\"name\":\"Dylan Flaute\"},{\"authorId\":\"2405109\",\"name\":\"B. Narayanan\"}],\"doi\":\"10.1117/12.2568016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"title\":\"Video captioning using weakly supervised convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"venue\":\"Optical Engineering + Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2803030\",\"name\":\"Jungchan Cho\"},{\"authorId\":\"2104494\",\"name\":\"Hyoseok Hwang\"}],\"doi\":\"10.3390/s20123491\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a96207034c05387dc84c76de6c5b63795c499809\",\"title\":\"Spatio-Temporal Representation of an Electoencephalogram for Emotion Recognition Using a Three-Dimensional Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a96207034c05387dc84c76de6c5b63795c499809\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143829432\",\"name\":\"Ngoc Nguyen\"},{\"authorId\":\"89558801\",\"name\":\"Dau Phan\"},{\"authorId\":\"70045535\",\"name\":\"F. R. Lumbanraja\"},{\"authorId\":\"145020752\",\"name\":\"M. Faisal\"},{\"authorId\":\"72808308\",\"name\":\"B. Abapihi\"},{\"authorId\":\"34805720\",\"name\":\"Bedy Purnama\"},{\"authorId\":\"2289674\",\"name\":\"Mera Kartika Delimayanti\"},{\"authorId\":\"89895131\",\"name\":\"Kunti Robiatul Mahmudah\"},{\"authorId\":\"2242591\",\"name\":\"M. Kubo\"},{\"authorId\":\"1767800\",\"name\":\"K. Satou\"}],\"doi\":\"10.4236/JBISE.2019.122012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"482feebc7f9f7234abe889a2d2a25118df296413\",\"title\":\"Applying Deep Learning Models to Mouse Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482feebc7f9f7234abe889a2d2a25118df296413\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"Rui Hou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"153317948\",\"name\":\"Shaobo Lin\"},{\"authorId\":\"150048347\",\"name\":\"B. Wang\"},{\"authorId\":\"47058944\",\"name\":\"L. Zhang\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d607aeef85b2fc0b66d7b58da442bd4b4551ded\",\"title\":\"Alibaba-AIC : Submission to Multi-Moments in Time Challenge 2019 \\u2217\",\"url\":\"https://www.semanticscholar.org/paper/4d607aeef85b2fc0b66d7b58da442bd4b4551ded\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1910.06583\",\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"72002635\",\"name\":\"Jianqin Yin\"},{\"authorId\":\"48210845\",\"name\":\"Jinghao Liu\"},{\"authorId\":\"93349641\",\"name\":\"P. Ding\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/tcsvt.2020.3021409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fef6913fe0ed6a5a25162b3502c381adfae56b3c\",\"title\":\"TrajectoryNet: a new spatio-temporal feature learning network for human motion prediction.\",\"url\":\"https://www.semanticscholar.org/paper/fef6913fe0ed6a5a25162b3502c381adfae56b3c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993672539\",\"name\":\"Soumil Kanwal\"},{\"authorId\":\"1993398975\",\"name\":\"Vineet Mehta\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"}],\"doi\":\"10.1145/3394171.3416302\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d51986070dbf6b76db4e553faf7dc301655e3ce4\",\"title\":\"Large Scale Hierarchical Anomaly Detection and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/d51986070dbf6b76db4e553faf7dc301655e3ce4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1910.14303\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1109/tpami.2020.3038993\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613634071acd170fe5c20600f8d49662a8c3b23f\",\"title\":\"Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/613634071acd170fe5c20600f8d49662a8c3b23f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2006.15955\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"88741566\",\"name\":\"No\\u00e9 Tits\"},{\"authorId\":\"71013766\",\"name\":\"Mathilde Brousmiche\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2ed73d5a7fd431b68ddc1b69144df7f44246a9b\",\"title\":\"A Transformer-based joint-encoding for Emotion Recognition and Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/a2ed73d5a7fd431b68ddc1b69144df7f44246a9b\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52089991\",\"name\":\"Mohammad Mahdi Kazemi Esfeh\"},{\"authorId\":\"48797076\",\"name\":\"Christina Luong\"},{\"authorId\":\"3424365\",\"name\":\"Delaram Behnami\"},{\"authorId\":\"145172765\",\"name\":\"Teresa Tsang\"},{\"authorId\":\"2427371\",\"name\":\"P. Abolmaesumi\"}],\"doi\":\"10.1007/978-3-030-59713-9_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a5591526ccb7e1c30dbd9f3146dda6bb048ce2a\",\"title\":\"A Deep Bayesian Video Analysis Framework: Towards a More Robust Estimation of Ejection Fraction\",\"url\":\"https://www.semanticscholar.org/paper/7a5591526ccb7e1c30dbd9f3146dda6bb048ce2a\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1007/978-981-15-1816-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c426717bed63d0afdfb16dd98c8cba915f52853\",\"title\":\"Action Recognition in Videos Using Multi-stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c426717bed63d0afdfb16dd98c8cba915f52853\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.12798\",\"authors\":[{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"10407760\",\"name\":\"Jieru Mei\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3743c3c7c30d700f37bcd00048af007137517a18\",\"title\":\"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network\",\"url\":\"https://www.semanticscholar.org/paper/3743c3c7c30d700f37bcd00048af007137517a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31711745\",\"name\":\"Murilo Varges da Silva\"},{\"authorId\":\"1683019\",\"name\":\"A. N. Marana\"}],\"doi\":\"10.1016/j.asoc.2020.106513\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d644fa83d1a3131c019b2b2f418ba28462a1b43b\",\"title\":\"Human action recognition in videos based on spatiotemporal features and bag-of-poses\",\"url\":\"https://www.semanticscholar.org/paper/d644fa83d1a3131c019b2b2f418ba28462a1b43b\",\"venue\":\"Appl. Soft Comput.\",\"year\":2020},{\"arxivId\":\"2011.07430\",\"authors\":[{\"authorId\":\"47787355\",\"name\":\"J. Li\"},{\"authorId\":\"22244290\",\"name\":\"Kaixin Ma\"},{\"authorId\":\"3188437\",\"name\":\"Shuhui Qu\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1421240600ec3a39310916adbc81ec7394e9a48\",\"title\":\"Audio-Visual Event Recognition through the lens of Adversary\",\"url\":\"https://www.semanticscholar.org/paper/a1421240600ec3a39310916adbc81ec7394e9a48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"48016412\",\"name\":\"H. Wang\"},{\"authorId\":\"145476833\",\"name\":\"Ang Li\"},{\"authorId\":\"7674316\",\"name\":\"Jingxiao Zheng\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"title\":\"Representing Videos based on Scene Layouts for Recognizing Agent-in-Place Actions\",\"url\":\"https://www.semanticscholar.org/paper/4cac9eda716a0addb73bd7ffea2a5fb0e6ec2367\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/cvpr42600.2020.00999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.03579\",\"authors\":[{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2820254\",\"name\":\"Eirina Bourtsoulatze\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3023597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"title\":\"Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing\",\"url\":\"https://www.semanticscholar.org/paper/5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027172024\",\"name\":\"Kavin Ruengprateepsang\"},{\"authorId\":\"2351793\",\"name\":\"S. Wangsiripitak\"},{\"authorId\":\"2056653\",\"name\":\"Kitsuchart Pasupa\"}],\"doi\":\"10.1007/978-3-030-63830-6_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96b28c526b8d6b063d9be5f6916f90ba882c6db1\",\"title\":\"Hybrid Training of Speaker and Sentence Models for One-Shot Lip Password\",\"url\":\"https://www.semanticscholar.org/paper/96b28c526b8d6b063d9be5f6916f90ba882c6db1\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2007.10730\",\"authors\":[{\"authorId\":\"5641221\",\"name\":\"S. Jenni\"},{\"authorId\":\"41016678\",\"name\":\"Givi Meishvili\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1007/978-3-030-58604-1_26\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"title\":\"Video Representation Learning by Recognizing Temporal Transformations\",\"url\":\"https://www.semanticscholar.org/paper/7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31634716\",\"name\":\"Huosheng Xie\"},{\"authorId\":\"2042838335\",\"name\":\"Hongwen Luo\"},{\"authorId\":\"11662913\",\"name\":\"J. Lin\"},{\"authorId\":\"37092569\",\"name\":\"Ning Yang\"}],\"doi\":\"10.1177/1748302620983661\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e170ec3e0ff8a5ccaaacda27f7820df7cd04529\",\"title\":\"A novel algorithm of fast CPR quality evaluation based on kinect\",\"url\":\"https://www.semanticscholar.org/paper/7e170ec3e0ff8a5ccaaacda27f7820df7cd04529\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13720\",\"authors\":[{\"authorId\":\"15665085\",\"name\":\"Y. Cao\"},{\"authorId\":\"152193470\",\"name\":\"Binjie Ding\"},{\"authorId\":\"49938383\",\"name\":\"Zewei He\"},{\"authorId\":\"2491927\",\"name\":\"Jiangxin Yang\"},{\"authorId\":\"9664703\",\"name\":\"Jing-xi Chen\"},{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"1503438566\",\"name\":\"Xin Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2291e83942c513b69e9c6d77adaa292a1915db0\",\"title\":\"Learning Inter- and Intra-frame Representations for Non-Lambertian Photometric Stereo\",\"url\":\"https://www.semanticscholar.org/paper/d2291e83942c513b69e9c6d77adaa292a1915db0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35723063\",\"name\":\"Md. Jamil-Ur Rahman\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CRV50864.2020.00035\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"title\":\"Single-Stage End-to-End Temporal Activity Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"venue\":\"2020 17th Conference on Computer and Robot Vision (CRV)\",\"year\":2020},{\"arxivId\":\"2002.03399\",\"authors\":[{\"authorId\":\"17126804\",\"name\":\"F. Kuhnke\"},{\"authorId\":\"89274230\",\"name\":\"Lars Rumberg\"},{\"authorId\":\"123027238\",\"name\":\"J. Ostermann\"}],\"doi\":\"10.1109/FG47880.2020.00056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9d0935cd0017ab0705d783b985891abed6412f1\",\"title\":\"Two-Stream Aural-Visual Affect Analysis in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/b9d0935cd0017ab0705d783b985891abed6412f1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38896301\",\"name\":\"G. Kundu\"},{\"authorId\":\"152384865\",\"name\":\"Prahal Arora\"},{\"authorId\":\"1818315\",\"name\":\"Ferdi Adeputra\"},{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"48750626\",\"name\":\"D. McKinnon\"},{\"authorId\":\"144038501\",\"name\":\"M. Cheung\"},{\"authorId\":\"123342297\",\"name\":\"Larry K. Anazia\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d087729c4a628ab05b3b68de090e612335de1c38\",\"title\":\"Multi-modal Content Localization in Videos Using Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/d087729c4a628ab05b3b68de090e612335de1c38\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2004.11475\",\"authors\":[{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"27058669\",\"name\":\"I. Dave\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"title\":\"Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Security Videos\",\"url\":\"https://www.semanticscholar.org/paper/beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"50695792\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME.2019.00182\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fdfcaf729fea332fc0a259143c406cee51303854\",\"title\":\"Recognizing Micro Actions in Videos: Learning Motion Details via Segment-Level Temporal Pyramid\",\"url\":\"https://www.semanticscholar.org/paper/fdfcaf729fea332fc0a259143c406cee51303854\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144118590\",\"name\":\"Kangmin Bae\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f69376de7aa59dc7a5050c9d9a5254ea26ca6e\",\"title\":\"Anti-Litter Surveillance based on Person Understanding via Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1f69376de7aa59dc7a5050c9d9a5254ea26ca6e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921887258\",\"name\":\"Tahereh Kamali\"},{\"authorId\":\"51314345\",\"name\":\"K. Hagerman\"},{\"authorId\":\"152194664\",\"name\":\"J. Day\"},{\"authorId\":\"48820601\",\"name\":\"J. Sampson\"},{\"authorId\":\"2753234\",\"name\":\"K. Lim\"},{\"authorId\":\"34285246\",\"name\":\"B. Mueller\"},{\"authorId\":\"37899469\",\"name\":\"Jeffrey R. Wozniak\"}],\"doi\":\"10.1109/EMBC44109.2020.9176455\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ab9670937e08dcb44e2817b06fde82746d6aa6c\",\"title\":\"Diagnosis of Myotonic Dystrophy Based on Resting State fMRI Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ab9670937e08dcb44e2817b06fde82746d6aa6c\",\"venue\":\"2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\",\"year\":2020},{\"arxivId\":\"2008.05924\",\"authors\":[{\"authorId\":\"1387822126\",\"name\":\"Xingxun Jiang\"},{\"authorId\":\"48115912\",\"name\":\"Yuan Zong\"},{\"authorId\":\"153811981\",\"name\":\"Wenming Zheng\"},{\"authorId\":\"2397257\",\"name\":\"Chuangao Tang\"},{\"authorId\":\"1382744618\",\"name\":\"Wanchuang Xia\"},{\"authorId\":\"102517285\",\"name\":\"Cheng Lu\"},{\"authorId\":\"1390977843\",\"name\":\"Jiateng Liu\"}],\"doi\":\"10.1145/3394171.3413620\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"title\":\"DFEW: A Large-Scale Database for Recognizing Dynamic Facial Expressions in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/061d69640ba6b544bbdfa8fa4637fa867fb42d2d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1811.09886\",\"authors\":[{\"authorId\":\"1686843\",\"name\":\"Jongsoo Park\"},{\"authorId\":\"144685269\",\"name\":\"M. Naumov\"},{\"authorId\":\"33071717\",\"name\":\"P. Basu\"},{\"authorId\":\"46193056\",\"name\":\"Summer Deng\"},{\"authorId\":\"2552318\",\"name\":\"A. Kalaiah\"},{\"authorId\":\"1724652\",\"name\":\"D. S. Khudia\"},{\"authorId\":\"144924790\",\"name\":\"J. Law\"},{\"authorId\":\"2398587\",\"name\":\"Parth Malani\"},{\"authorId\":\"143682293\",\"name\":\"A. Malevich\"},{\"authorId\":\"143758120\",\"name\":\"Nadathur Satish\"},{\"authorId\":\"145503806\",\"name\":\"J. Pino\"},{\"authorId\":\"72402417\",\"name\":\"M. Schatz\"},{\"authorId\":\"144452256\",\"name\":\"A. Sidorov\"},{\"authorId\":\"145422368\",\"name\":\"V. Sivakumar\"},{\"authorId\":\"3609856\",\"name\":\"Andrew Tulloch\"},{\"authorId\":\"47119575\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"47096227\",\"name\":\"Y. Wu\"},{\"authorId\":\"30891915\",\"name\":\"H. Yuen\"},{\"authorId\":\"40863835\",\"name\":\"Utku Diril\"},{\"authorId\":\"40858378\",\"name\":\"Dmytro Dzhulgakov\"},{\"authorId\":\"1775500\",\"name\":\"K. Hazelwood\"},{\"authorId\":\"33920592\",\"name\":\"Bill Jia\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"39540215\",\"name\":\"L. Qiao\"},{\"authorId\":\"144632750\",\"name\":\"V. Rao\"},{\"authorId\":\"3121592\",\"name\":\"N. Rotem\"},{\"authorId\":\"1808405\",\"name\":\"Sungjoo Yoo\"},{\"authorId\":\"1711231\",\"name\":\"M. Smelyanskiy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"611e0bd5d466668989df04d642104428d03eaeb6\",\"title\":\"Deep Learning Inference in Facebook Data Centers: Characterization, Performance Optimizations and Hardware Implications\",\"url\":\"https://www.semanticscholar.org/paper/611e0bd5d466668989df04d642104428d03eaeb6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46598954\",\"name\":\"Dan Li\"},{\"authorId\":\"1656176919\",\"name\":\"Kaifeng Zhang\"},{\"authorId\":\"40388829\",\"name\":\"Z. Li\"},{\"authorId\":\"97042247\",\"name\":\"Y. Chen\"}],\"doi\":\"10.3390/s20082381\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"title\":\"A Spatiotemporal Convolutional Network for Multi-Behavior Recognition of Pigs\",\"url\":\"https://www.semanticscholar.org/paper/a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"title\":\"Constraining Temporal Relationship for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05515\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e599d703e358d6e554da859cff116553053d0fa\",\"title\":\"AViD Dataset: Anonymized Videos from Diverse Countries\",\"url\":\"https://www.semanticscholar.org/paper/0e599d703e358d6e554da859cff116553053d0fa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2012.09237\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"21408156\",\"name\":\"U. B\\u00fcchler\"},{\"authorId\":\"2006270114\",\"name\":\"Michael Dorkenwald\"},{\"authorId\":\"1381484612\",\"name\":\"Philipp Reiser\"},{\"authorId\":\"117618945\",\"name\":\"Linard Filli\"},{\"authorId\":\"1879301\",\"name\":\"F. Helmchen\"},{\"authorId\":\"3153305\",\"name\":\"Anna-Sophia Wahl\"},{\"authorId\":\"49207102\",\"name\":\"B. Ommer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c317a8724503b13a9765eb834ba0eb592e2fd59\",\"title\":\"uBAM: Unsupervised Behavior Analysis and Magnification using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1c317a8724503b13a9765eb834ba0eb592e2fd59\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286161\",\"name\":\"Junjie Wang\"},{\"authorId\":\"51311907\",\"name\":\"Xueyan Wen\"}],\"doi\":\"10.1088/1742-6596/1651/1/012193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"title\":\"A Spatio-Temporal Attention Convolution Block for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.11579\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5\",\"title\":\"A2-Nets: Double Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1905.00561\",\"authors\":[{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/CVPR.2019.01232\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"title\":\"Large-Scale Weakly-Supervised Pre-Training for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.06807\",\"authors\":[{\"authorId\":\"145490315\",\"name\":\"Kartik Hegde\"},{\"authorId\":\"50843533\",\"name\":\"R. Agrawal\"},{\"authorId\":\"51463024\",\"name\":\"Yulun Yao\"},{\"authorId\":\"2012099\",\"name\":\"Christopher W. Fletcher\"}],\"doi\":\"10.1109/MICRO.2018.00080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"title\":\"Morph: Flexible Acceleration for 3D CNN-Based Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"venue\":\"2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042569583\",\"name\":\"Kensho Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2042706087\",\"name\":\"Masaki Inaba\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"2042698122\",\"name\":\"Ryusuke Hotta\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ITSC45102.2020.9294443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"title\":\"Predicting Vehicles Appearing from Blind Spots Based on Pedestrian Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.11093\",\"authors\":[{\"authorId\":\"81601597\",\"name\":\"Y. M. Souto\"},{\"authorId\":\"144166255\",\"name\":\"R. Pereira\"},{\"authorId\":\"120802700\",\"name\":\"Roc\\u00edo Zorrilla\"},{\"authorId\":\"145316576\",\"name\":\"Anderson Chaves\"},{\"authorId\":\"1713778652\",\"name\":\"Brian Tsan\"},{\"authorId\":\"27349652\",\"name\":\"F. Rusu\"},{\"authorId\":\"49011978\",\"name\":\"Eduardo Ogasawara\"},{\"authorId\":\"1708380\",\"name\":\"A. Ziviani\"},{\"authorId\":\"145179575\",\"name\":\"F. Porto\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24a571ea9c46eb3930554e348a8e1f1035b7db5c\",\"title\":\"DJEnsemble: On the Selection of a Disjoint Ensemble of Deep Learning Black-Box Spatio-temporal Models\",\"url\":\"https://www.semanticscholar.org/paper/24a571ea9c46eb3930554e348a8e1f1035b7db5c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":206596999,\"doi\":\"10.1109/CVPR.2018.00675\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":112,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"2704179\",\"name\":\"Dongang Wang\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2016.119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"317eaf94573857bec786bbf030605ccdb0fd624d\",\"title\":\"Temporal Action Localization in Untrimmed Videos via Multi-stage CNNs\",\"url\":\"https://www.semanticscholar.org/paper/317eaf94573857bec786bbf030605ccdb0fd624d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948848\",\"name\":\"S. Sadanand\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2012.6247806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"title\":\"Action bank: A high-level representation of activity in video\",\"url\":\"https://www.semanticscholar.org/paper/d90cb88d89408daf4a0fe5ac341a6b9db747a556\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"49436963\",\"name\":\"Shalini Gupta\"},{\"authorId\":\"3736059\",\"name\":\"Kihwan Kim\"},{\"authorId\":\"2342481\",\"name\":\"S. Tyree\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2016.456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b2282ba8b50165f21d42473c22ef89b0224864a\",\"title\":\"Online Detection and Classification of Dynamic Hand Gestures with Recurrent 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0b2282ba8b50165f21d42473c22ef89b0224864a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115901011\",\"name\":\"D. Davies\"}],\"doi\":\"10.1016/S0140-6736(05)61503-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a5985e4e237535df0d1b7fd121e86d25842f0bb\",\"title\":\"T\",\"url\":\"https://www.semanticscholar.org/paper/2a5985e4e237535df0d1b7fd121e86d25842f0bb\",\"venue\":\"The Lancet\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Going deeper with convolutions Convolu - tional learning of spatio - temporal features\",\"url\":\"\",\"venue\":\"\",\"year\":2010},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1706.02677\",\"authors\":[{\"authorId\":\"47316088\",\"name\":\"Priya Goyal\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34837514\",\"name\":\"P. Noordhuis\"},{\"authorId\":\"39033676\",\"name\":\"L. Wesolowski\"},{\"authorId\":\"1717990\",\"name\":\"Aapo Kyrola\"},{\"authorId\":\"3609856\",\"name\":\"Andrew Tulloch\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"title\":\"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\",\"url\":\"https://www.semanticscholar.org/paper/0d57ba12a6d958e178d83be4c84513f7e42b24e5\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1411.4006\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"title\":\"A discriminative CNN video representation for event detection\",\"url\":\"https://www.semanticscholar.org/paper/10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Goyal\"},{\"authorId\":null,\"name\":\"P. Doll\\u00e1r\"},{\"authorId\":null,\"name\":\"R. Girshick\"},{\"authorId\":null,\"name\":\"P. Noordhuis\"},{\"authorId\":null,\"name\":\"L. Wesolowski\"},{\"authorId\":null,\"name\":\"A. Kyrola\"},{\"authorId\":null,\"name\":\"A. Tulloch\"},{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"K. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Accurate\",\"url\":\"\",\"venue\":\"large minibatch sgd: training imagenet in 1 hour. arXiv preprint arXiv:1706.02677\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/CVPR.2017.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048032\",\"name\":\"P. Scovanner\"},{\"authorId\":\"38245610\",\"name\":\"Saad Ali\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1145/1291233.1291311\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"title\":\"A 3-dimensional sift descriptor and its application to action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"venue\":\"ACM Multimedia\",\"year\":2007},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1382424098\",\"name\":\"\\u0422\\u0430\\u0440\\u0430\\u0441\\u0430 \\u0428\\u0435\\u0432\\u0447\\u0435\\u043d\\u043a\\u0430\"},{\"authorId\":\"1397452703\",\"name\":\"\\u0412\\u0430\\u0441\\u0438\\u043b\\u044f \\u041a\\u0430\\u0440\\u0430\\u0437\\u0456\\u043d\\u0430\"},{\"authorId\":\"1397452698\",\"name\":\"\\u041e\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u0430 \\u0411\\u043e\\u0433\\u043e\\u043c\\u043e\\u043b\\u044c\\u0446\\u044f\"}],\"doi\":\"10.1093/clinchem/60.1.283\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"title\":\"Quo vadis?\",\"url\":\"https://www.semanticscholar.org/paper/dedb1eaf13642fec867f4333ed4353f60aa2c38b\",\"venue\":\"Clinical chemistry\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Caffe2-Team\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Caffe2: A new lightweight, modular, and scalable deep learning framework\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"2408697\",\"name\":\"F. Mamalet\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"144723337\",\"name\":\"C. Garcia\"},{\"authorId\":\"1739898\",\"name\":\"A. Baskurt\"}],\"doi\":\"10.1007/978-3-642-25446-8_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12b6551a0f9f5aa62f7d37f03ebc66631e529c4b\",\"title\":\"Sequential Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12b6551a0f9f5aa62f7d37f03ebc66631e529c4b\",\"venue\":\"HBU\",\"year\":2011},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Xiong\"},{\"authorId\":null,\"name\":\"Z. Wang\"},{\"authorId\":null,\"name\":\"Y. Qiao\"},{\"authorId\":null,\"name\":\"D. Lin\"},{\"authorId\":null,\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning spatiotemporal features with 3 d convolutional networks Long - term Temporal Convolutions for Action Recognition Action recognition with improved trajectories\",\"url\":\"\",\"venue\":\"In ICCV\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779050\",\"name\":\"Gunnar Farneb\\u00e4ck\"}],\"doi\":\"10.1007/3-540-45103-X_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"534805683c27accb27d66d9425f759b798df380a\",\"title\":\"Two-Frame Motion Estimation Based on Polynomial Expansion\",\"url\":\"https://www.semanticscholar.org/paper/534805683c27accb27d66d9425f759b798df380a\",\"venue\":\"SCIA\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"2860351\",\"name\":\"Will Y. Zou\"},{\"authorId\":\"32408341\",\"name\":\"Serena Y. Yeung\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1109/CVPR.2011.5995496\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42269d0438c0ae4ca892334946ed779999691074\",\"title\":\"Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis\",\"url\":\"https://www.semanticscholar.org/paper/42269d0438c0ae4ca892334946ed779999691074\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1608.06993\",\"authors\":[{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":\"10.1109/CVPR.2017.243\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"title\":\"Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"N. Srivastava\"},{\"authorId\":null,\"name\":\"E. Mansimov\"},{\"authorId\":null,\"name\":\"R. Salakhudinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Unsupervised learning of video representations using lstms\",\"url\":\"\",\"venue\":\"In International Conference on Machine Learning,\",\"year\":2015},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Kay\"},{\"authorId\":null,\"name\":\"J. Carreira\"},{\"authorId\":null,\"name\":\"K. Simonyan\"},{\"authorId\":null,\"name\":\"B. Zhang\"},{\"authorId\":null,\"name\":\"C. Hillier\"},{\"authorId\":null,\"name\":\"S. Vijayanarasimhan\"},{\"authorId\":null,\"name\":\"F. Viola\"},{\"authorId\":null,\"name\":\"T. Green\"},{\"authorId\":null,\"name\":\"T. Back\"},{\"authorId\":null,\"name\":\"P. Natsev\"},{\"authorId\":null,\"name\":\"M. Suleyman\"},{\"authorId\":null,\"name\":\"A. Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The kinetics human action video\",\"url\":\"\",\"venue\":\"dataset. CoRR,\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"topics\":[{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Habbo\",\"topicId\":\"634492\",\"url\":\"https://www.semanticscholar.org/topic/634492\"},{\"topic\":\"Kinesiology\",\"topicId\":\"113188\",\"url\":\"https://www.semanticscholar.org/topic/113188\"},{\"topic\":\"Video content analysis\",\"topicId\":\"98626\",\"url\":\"https://www.semanticscholar.org/topic/98626\"},{\"topic\":\"Input/output\",\"topicId\":\"8197\",\"url\":\"https://www.semanticscholar.org/topic/8197\"}],\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"