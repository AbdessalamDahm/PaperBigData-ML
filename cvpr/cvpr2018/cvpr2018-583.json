"{\"abstract\":\"Image captioning is an important task, applicable to virtual assistants, editing tools, image indexing, and support of the disabled. In recent years significant progress has been made in image captioning, using Recurrent Neural Networks powered by long-short-term-memory (LSTM) units. Despite mitigating the vanishing gradient problem, and despite their compelling ability to memorize dependencies, LSTM units are complex and inherently sequential across time. To address this issue, recent work has shown benefits of convolutional networks for machine translation and conditional image generation [9, 34, 35]. Inspired by their success, in this paper, we develop a convolutional image captioning technique. We demonstrate its efficacy on the challenging MSCOCO dataset and demonstrate performance on par with the LSTM baseline [16], while having a faster training time per number of parameters. We also perform a detailed analysis, providing compelling reasons in favor of convolutional language generation approaches.\",\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\",\"url\":\"https://www.semanticscholar.org/author/29956361\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\",\"url\":\"https://www.semanticscholar.org/author/113001756\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\",\"url\":\"https://www.semanticscholar.org/author/2068227\"}],\"citationVelocity\":47,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"35986726\",\"name\":\"Anand Bhattad\"},{\"authorId\":\"50615993\",\"name\":\"Min Jin Chong\"},{\"authorId\":\"102461072\",\"name\":\"Kaizhao Liang\"},{\"authorId\":\"2485552\",\"name\":\"B. Li\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"52442339004d1564378cb730f01656600e0819ef\",\"title\":\"Big but Imperceptible Adversarial Perturbations via Semantic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/52442339004d1564378cb730f01656600e0819ef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2001.03340\",\"authors\":[{\"authorId\":\"102942511\",\"name\":\"Matthias Weissenbacher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b78dca52d616602994da95153b8c41745078c5ae\",\"title\":\"Temporally Folded Convolutional Neural Networks for Sequence Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/b78dca52d616602994da95153b8c41745078c5ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9432180\",\"name\":\"R. Kumar\"}],\"doi\":\"10.1007/s42979-020-00135-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b3a8a857467fd389d835f4f6c9fcf5777ed026a\",\"title\":\"Visual Linguistic Model and Its Applications in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9b3a8a857467fd389d835f4f6c9fcf5777ed026a\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1811.10014\",\"authors\":[{\"authorId\":\"50141653\",\"name\":\"Xiao Wang\"},{\"authorId\":\"50876591\",\"name\":\"Chenglong Li\"},{\"authorId\":\"145653641\",\"name\":\"R. Yang\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"144625999\",\"name\":\"B. Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a324234a9bbb4df89b16c8ccede3aada09243dd\",\"title\":\"Describe and Attend to Track: Learning Natural Language guided Structural Representation and Visual Attention for Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/2a324234a9bbb4df89b16c8ccede3aada09243dd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1910.02974\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICRA40945.2020.9196653\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe6f2a08cb8911d52533a413b071638d0463f10a\",\"title\":\"SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability\",\"url\":\"https://www.semanticscholar.org/paper/fe6f2a08cb8911d52533a413b071638d0463f10a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2006.11714\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1491357190\",\"name\":\"Yang Hua\"},{\"authorId\":\"1696052\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f8934f5e17a1e9d7592c641305477fe630a0fbb\",\"title\":\"Off-Policy Self-Critical Training for Transformer in Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/0f8934f5e17a1e9d7592c641305477fe630a0fbb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1438623667\",\"name\":\"Khaled Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"afa8032f794011884be0b06f808540f36b404c0b\",\"title\":\"A Short Review on Image Caption Generation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/afa8032f794011884be0b06f808540f36b404c0b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.02693\",\"authors\":[{\"authorId\":\"8314407\",\"name\":\"X. Yang\"},{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"145657309\",\"name\":\"D. Jin\"},{\"authorId\":\"49421744\",\"name\":\"Yingru Liu\"},{\"authorId\":\"120931191\",\"name\":\"Chi-Hao Wu\"},{\"authorId\":\"34331333\",\"name\":\"Jianchao Tan\"},{\"authorId\":\"47300385\",\"name\":\"Dongliang Xie\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":null,\"name\":\"Xin Wang\"}],\"doi\":\"10.1007/978-3-030-58601-0_1\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf72a4a75b6ecd6dbc4c1af52a9592ec61abcfb5\",\"title\":\"Fashion Captioning: Towards Generating Accurate Descriptions with Semantic Rewards\",\"url\":\"https://www.semanticscholar.org/paper/bf72a4a75b6ecd6dbc4c1af52a9592ec61abcfb5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490502769\",\"name\":\"Jin-Wen Wu\"},{\"authorId\":\"145820431\",\"name\":\"F. Yin\"},{\"authorId\":\"15310310\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"},{\"authorId\":\"117992479\",\"name\":\"Cheng-Lin Liu\"}],\"doi\":\"10.1007/s11263-020-01291-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64b6dafa4bca80af3df7aa82b45ffd6a21e24d4e\",\"title\":\"Handwritten Mathematical Expression Recognition via Paired Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/64b6dafa4bca80af3df7aa82b45ffd6a21e24d4e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2565254\",\"name\":\"Hegui Zhu\"},{\"authorId\":\"144213379\",\"name\":\"Y. Miao\"},{\"authorId\":\"49470457\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1007/s11063-020-10240-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42f3557260dcc817a8d2d590b769c867a0d6018c\",\"title\":\"Semantic Image Segmentation with Improved Position Attention and Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/42f3557260dcc817a8d2d590b769c867a0d6018c\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97636424\",\"name\":\"G. Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144303230\",\"name\":\"Ping Liu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICCV.2019.00902\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"title\":\"Entangled Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1654128868\",\"name\":\"Sruthi K V\"},{\"authorId\":\"1654099368\",\"name\":\"Meharban M S\"}],\"doi\":\"10.1109/ICACCS48705.2020.9074468\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef4c30847b135ee89138126350d8a0c401470559\",\"title\":\"Review on Image Captioning and Speech Synthesis Techniques\",\"url\":\"https://www.semanticscholar.org/paper/ef4c30847b135ee89138126350d8a0c401470559\",\"venue\":\"2020 6th International Conference on Advanced Computing and Communication Systems (ICACCS)\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.06877\",\"authors\":[{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-58452-8_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"title\":\"Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets\",\"url\":\"https://www.semanticscholar.org/paper/e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/ICCV.2019.00901\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"title\":\"Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144060080\",\"name\":\"Giang T. Nguyen\"},{\"authorId\":\"8102722\",\"name\":\"Tae Joon Jun\"},{\"authorId\":\"145178790\",\"name\":\"Trung Tran\"},{\"authorId\":\"1729331675\",\"name\":\"Tolcha Yalew\"},{\"authorId\":\"40513516\",\"name\":\"Daeyoung Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b76f2cba712972f068bfb0fffa9b467761fd273\",\"title\":\"ContCap: A scalable framework for continual image captioning.\",\"url\":\"https://www.semanticscholar.org/paper/7b76f2cba712972f068bfb0fffa9b467761fd273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153083913\",\"name\":\"Qianxia Ma\"},{\"authorId\":\"2034274745\",\"name\":\"Yongfang Nie\"},{\"authorId\":\"2011460\",\"name\":\"J. Song\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.3041447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59c7c7076ece69a4552505f9a3615d4a0c70188d\",\"title\":\"Multimodal Data Processing Framework for Smart City: A Positional-Attention Based Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/59c7c7076ece69a4552505f9a3615d4a0c70188d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2004.10258\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1491357190\",\"name\":\"Yang Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f882bc53ded32b2a32b291078c9454d82f6f108b\",\"title\":\"ParaCNN: Visual Paragraph Generation via Adversarial Twin Contextual CNNs\",\"url\":\"https://www.semanticscholar.org/paper/f882bc53ded32b2a32b291078c9454d82f6f108b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98482977\",\"name\":\"\\u0411\\u043e\\u0440\\u0438\\u0441\\u043e\\u0432 \\u0413\\u0435\\u043e\\u0440\\u0433\\u0438\\u0439 \\u0410\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u043e\\u0432\\u0438\\u0447\"},{\"authorId\":\"97625681\",\"name\":\"\\u0422\\u0438\\u0445\\u043e\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430 \\u0422\\u0430\\u043c\\u0430\\u0440\\u0430 \\u041f\\u0435\\u0442\\u0440\\u043e\\u0432\\u043d\\u0430\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de0cec214cf34d089a9fce9015256b63534cd08\",\"title\":\"\\u0417\\u0430\\u0434\\u0430\\u0447\\u0438 \\u0438 \\u043c\\u0435\\u0442\\u043e\\u0434\\u044b \\u0440\\u0435\\u0441\\u0443\\u0440\\u0441\\u043e\\u0441\\u0431\\u0435\\u0440\\u0435\\u0433\\u0430\\u044e\\u0449\\u0435\\u0439 \\u043e\\u043f\\u0442\\u0438\\u043c\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u0432 \\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u044d\\u043d\\u0435\\u0440\\u0433\\u0435\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0435\",\"url\":\"https://www.semanticscholar.org/paper/0de0cec214cf34d089a9fce9015256b63534cd08\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1908.11310\",\"authors\":[{\"authorId\":\"19444389\",\"name\":\"Koustav Ghosal\"},{\"authorId\":\"36809068\",\"name\":\"Aakanksha Rana\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00556\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5d204156022f65e34706d4211e05bcb578940939\",\"title\":\"Aesthetic Image Captioning From Weakly-Labelled Photographs\",\"url\":\"https://www.semanticscholar.org/paper/5d204156022f65e34706d4211e05bcb578940939\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1910.02029\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/s11263-020-01374-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/28766f2ecfb5dc19addf272bf25301030e8b1af9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144343897\",\"name\":\"R. Guo\"},{\"authorId\":\"22771932\",\"name\":\"Shubo Ma\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1007/s11042-018-7118-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"title\":\"Image captioning: from structural tetrad to translated sentences\",\"url\":\"https://www.semanticscholar.org/paper/ef82141c898442d20c5d9e86e0f5d8940ae12c17\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2907739\",\"name\":\"Masoomeh Nabati\"},{\"authorId\":\"30756748\",\"name\":\"A. Behrad\"}],\"doi\":\"10.1016/j.ipm.2020.102302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aca85e733323b2b364ae79fd0934edf2f1544ca1\",\"title\":\"Multi-Sentence Video Captioning using Content-oriented Beam Searching and Multi-stage Refining Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/aca85e733323b2b364ae79fd0934edf2f1544ca1\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"24952249\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b2c60061ad32e28eb1e20aff42e062c9160786be\",\"title\":\"Diverse and Controllable Image Captioning with Part-of-Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/b2c60061ad32e28eb1e20aff42e062c9160786be\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400258083\",\"name\":\"Chunpu Xu\"},{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"31991405\",\"name\":\"Min Yang\"},{\"authorId\":\"2441161\",\"name\":\"Xiang Ao\"},{\"authorId\":\"1405918472\",\"name\":\"Wangrong Cheng\"},{\"authorId\":\"1936983\",\"name\":\"J. Tian\"}],\"doi\":\"10.1145/3357384.3358105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e81c97c18cb4f4922e4442664350350536a71a13\",\"title\":\"A Unified Generation-Retrieval Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e81c97c18cb4f4922e4442664350350536a71a13\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1904.01410\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"title\":\"Context and Attribute Grounded Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93782401659fe26faef7e5f3b84ff632a12da47f\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Forged Videos\",\"url\":\"https://www.semanticscholar.org/paper/93782401659fe26faef7e5f3b84ff632a12da47f\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.06347\",\"authors\":[{\"authorId\":\"35986726\",\"name\":\"Anand Bhattad\"},{\"authorId\":\"50615993\",\"name\":\"Min Jin Chong\"},{\"authorId\":\"102461072\",\"name\":\"Kaizhao Liang\"},{\"authorId\":\"46708584\",\"name\":\"B. Li\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e01fd005f5f1c2cf1b27c1ac8b014dfd3983da3\",\"title\":\"Unrestricted Adversarial Examples via Semantic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/1e01fd005f5f1c2cf1b27c1ac8b014dfd3983da3\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508437\",\"name\":\"Jiyoun Moon\"},{\"authorId\":\"97166798\",\"name\":\"Beom-Hee Lee\"}],\"doi\":\"10.3390/app9183789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf299851d033ce8245b1c433949dd52219d82742\",\"title\":\"PDDL Planning with Natural Language-Based Scene Understanding for UAV-UGV Cooperation\",\"url\":\"https://www.semanticscholar.org/paper/bf299851d033ce8245b1c433949dd52219d82742\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.05671\",\"authors\":[{\"authorId\":\"46241709\",\"name\":\"Graham Spinks\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1016/j.jbi.2019.103248\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d1d1c06a87f6a40d1e51d8f9554181b6e4f93d6\",\"title\":\"Justifying Diagnosis Decisions by Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4d1d1c06a87f6a40d1e51d8f9554181b6e4f93d6\",\"venue\":\"J. Biomed. Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101726081\",\"name\":\"S. Rawat\"},{\"authorId\":\"1992911636\",\"name\":\"Kartikeyan Singh Rawat\"},{\"authorId\":\"1381574702\",\"name\":\"Rahul Nijhawan\"}],\"doi\":\"10.1109/ICSSIT48917.2020.9214109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c73865aa2634a5e6b0099fe49221d1e56a2b875\",\"title\":\"A Novel Convolutional Neural Network-Gated Recurrent Unit approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0c73865aa2634a5e6b0099fe49221d1e56a2b875\",\"venue\":\"2020 Third International Conference on Smart Systems and Inventive Technology (ICSSIT)\",\"year\":2020},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.08745\",\"authors\":[{\"authorId\":\"144060080\",\"name\":\"Giang T. Nguyen\"},{\"authorId\":\"8102722\",\"name\":\"T. Jun\"},{\"authorId\":\"144256269\",\"name\":\"Trung Tran\"},{\"authorId\":\"72657968\",\"name\":\"Daeyoung Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b428979e3b67f40fc307b5b166f9c97adba6a63f\",\"title\":\"ContCap: A comprehensive framework for continual image captioning\",\"url\":\"https://www.semanticscholar.org/paper/b428979e3b67f40fc307b5b166f9c97adba6a63f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.09108\",\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"2118698\",\"name\":\"Roddy Collins\"},{\"authorId\":\"2754027\",\"name\":\"E. Swears\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":\"10.1109/WACV.2019.00176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d772882cceb083ab053b83615e60c641fc3e7dbb\",\"title\":\"Deep Neural Networks in Fully Connected CRF for Image Labeling with Social Network Metadata\",\"url\":\"https://www.semanticscholar.org/paper/d772882cceb083ab053b83615e60c641fc3e7dbb\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1908.04915\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":null,\"name\":\"Jun Xu\"},{\"authorId\":\"47908497\",\"name\":\"Y. Liu\"},{\"authorId\":\"145556908\",\"name\":\"L. Xu\"}],\"doi\":\"10.24963/ijcai.2019/742\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bbd6c67f6268cd69b1eea02ffb8e018e8e88ce0e\",\"title\":\"HorNet: A Hierarchical Offshoot Recurrent Network for Improving Person Re-ID via Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bbd6c67f6268cd69b1eea02ffb8e018e8e88ce0e\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1905.08110\",\"authors\":[{\"authorId\":\"47904580\",\"name\":\"Yiyu Wang\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"title\":\"Image Captioning based on Deep Learning Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2565254\",\"name\":\"Hegui Zhu\"},{\"authorId\":\"1409765863\",\"name\":\"Min Zhang\"},{\"authorId\":\"3153945\",\"name\":\"Xiangde Zhang\"},{\"authorId\":\"47059353\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s00521-020-05312-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77bb812de43ef3790592e15aa291c4847e421d98\",\"title\":\"Two-branch encoding and iterative attention decoding network for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/77bb812de43ef3790592e15aa291c4847e421d98\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"31126576\",\"name\":\"Zheng Xiong\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"9245443\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.3390/app10010391\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"945ffeb90e538214e3063407db8e094469ec877a\",\"title\":\"Panoptic Segmentation-Based Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/945ffeb90e538214e3063407db8e094469ec877a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1145/3293353.3293391\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"title\":\"A Bottom-Up and Top-Down Approach for Image Captioning using Transformer\",\"url\":\"https://www.semanticscholar.org/paper/acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66230036\",\"name\":\"L. Sun\"},{\"authorId\":\"49337262\",\"name\":\"Weipeng Wang\"},{\"authorId\":\"39682947\",\"name\":\"Jiyun Li\"},{\"authorId\":\"13387006\",\"name\":\"Jingsheng Lin\"}],\"doi\":\"10.1007/978-3-030-26763-6_66\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a7983742d4e9bb354217c42b7aa27f45518916b\",\"title\":\"Study on Medical Image Report Generation Based on Improved Encoding-Decoding Method\",\"url\":\"https://www.semanticscholar.org/paper/4a7983742d4e9bb354217c42b7aa27f45518916b\",\"venue\":\"ICIC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50652001\",\"name\":\"Mingyao Li\"},{\"authorId\":\"67110162\",\"name\":\"S. Kamata\"}],\"doi\":\"10.1109/ICIEV.2018.8641027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"597a9f9aa933c951ea7db14574f16422e175ad1b\",\"title\":\"Deep Neural Networks with Mixture of Experts Layers for Complex Event Recognition from Images\",\"url\":\"https://www.semanticscholar.org/paper/597a9f9aa933c951ea7db14574f16422e175ad1b\",\"venue\":\"2018 Joint 7th International Conference on Informatics, Electronics & Vision (ICIEV) and 2018 2nd International Conference on Imaging, Vision & Pattern Recognition (icIVPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"46867445\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9305704\",\"name\":\"Xiaosheng Yu\"}],\"doi\":\"10.1155/2020/3062706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"title\":\"An Overview of Image Caption Generation Methods\",\"url\":\"https://www.semanticscholar.org/paper/4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144439462\",\"name\":\"Shuang Liu\"},{\"authorId\":\"48499525\",\"name\":\"Liang Richard Bai\"},{\"authorId\":\"46972536\",\"name\":\"Yan-Li Hu\"},{\"authorId\":\"49528408\",\"name\":\"Haoran Wang\"}],\"doi\":\"10.1051/MATECCONF/201823201052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"730083506b1f6064ae12cc7ced6b3b2093d59bfd\",\"title\":\"Image Captioning Based on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/730083506b1f6064ae12cc7ced6b3b2093d59bfd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2873524\",\"name\":\"Z. Ma\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"150347046\",\"name\":\"Yangyang Cheng\"},{\"authorId\":\"51000590\",\"name\":\"Xinrui Zhu\"}],\"doi\":\"10.1109/ICME.2019.00225\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"daad11aee75bcf597602e654c33a12de61343dda\",\"title\":\"Image-to-Tree: A Tree-Structured Decoder for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/daad11aee75bcf597602e654c33a12de61343dda\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34589688\",\"name\":\"Zhenghang Yuan\"},{\"authorId\":\"121856647\",\"name\":\"X. Li\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2962195\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52a221f10ec19fb3b20fda0271184b641c2ccc4b\",\"title\":\"Exploring Multi-Level Attention and Semantic Relationship for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/52a221f10ec19fb3b20fda0271184b641c2ccc4b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.06661\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"title\":\"Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings\",\"url\":\"https://www.semanticscholar.org/paper/87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2010.05796\",\"authors\":[{\"authorId\":\"1994173738\",\"name\":\"Simone Zamboni\"},{\"authorId\":\"32612989\",\"name\":\"Zekarias T. Kefato\"},{\"authorId\":\"69947993\",\"name\":\"Sarunas Girdzijauskas\"},{\"authorId\":\"1994156505\",\"name\":\"Noren Christoffer\"},{\"authorId\":\"3046492\",\"name\":\"L. D. Col\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e72bb6e545c7d4b76c98aa36702fca002c35e3d7\",\"title\":\"Pedestrian Trajectory Prediction with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e72bb6e545c7d4b76c98aa36702fca002c35e3d7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144063214\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"96363850\",\"name\":\"Mohd Fairuz Shiratuddin\"},{\"authorId\":\"48540238\",\"name\":\"Hamid Laga\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/DICTA47822.2019.8946003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"098833985221f9f30d547dadf24ae7b0f1433ef5\",\"title\":\"Bi-SAN-CAP: Bi-Directional Self-Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/098833985221f9f30d547dadf24ae7b0f1433ef5\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"1930660\",\"name\":\"Bo Qu\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/JSTARS.2019.2959208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fbdb53c100005ac890989beb3d78e208ba9acda\",\"title\":\"Retrieval Topic Recurrent Memory Network for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fbdb53c100005ac890989beb3d78e208ba9acda\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1910.12019\",\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"title\":\"Diverse Video Captioning Through Latent Variable Expansion with Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1431726865\",\"name\":\"R. SreelaS.\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.3390/info10110354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"title\":\"Dense Model for Automatic Image Description Generation with Game Theoretic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743434\",\"name\":\"W. Cheng\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fa1076a98a15cec083fb474f238237f1b3a341a\",\"title\":\"Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-based Method\",\"url\":\"https://www.semanticscholar.org/paper/6fa1076a98a15cec083fb474f238237f1b3a341a\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92091076\",\"name\":\"F. Yu\"},{\"authorId\":\"102401998\",\"name\":\"H. Wang\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3394171.3413566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2a0485dca57fd054b1577f9bbda61f40fe0924c\",\"title\":\"Visual Relation of Interest Detection\",\"url\":\"https://www.semanticscholar.org/paper/f2a0485dca57fd054b1577f9bbda61f40fe0924c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2003.00380\",\"authors\":[{\"authorId\":\"1421235702\",\"name\":\"Jieshan Chen\"},{\"authorId\":\"46729152\",\"name\":\"Chunyang Chen\"},{\"authorId\":\"3138980\",\"name\":\"Zhenchang Xing\"},{\"authorId\":\"79988928\",\"name\":\"X. Xu\"},{\"authorId\":\"48324793\",\"name\":\"Liming Zhu\"},{\"authorId\":\"49192734\",\"name\":\"Guoqiang Li\"},{\"authorId\":\"8653150\",\"name\":\"J. Wang\"}],\"doi\":\"10.1145/3377811.3380327\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a32ca8fb3ad34374dfb3ef4967d13b89d7d3ffd2\",\"title\":\"Unblind Your Apps: Predicting Natural-Language Labels for Mobile GUI Components by Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/a32ca8fb3ad34374dfb3ef4967d13b89d7d3ffd2\",\"venue\":\"2020 IEEE/ACM 42nd International Conference on Software Engineering (ICSE)\",\"year\":2020},{\"arxivId\":\"2012.07333\",\"authors\":[{\"authorId\":\"1733071048\",\"name\":\"Chao Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7212df671c50beb567e3d3d608b0c14405c40e3\",\"title\":\"Intrinsic Image Captioning Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7212df671c50beb567e3d3d608b0c14405c40e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"46700004\",\"name\":\"J. Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TMM.2019.2951226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"837a513a43c7bcce903edbacbfc507cba6451e21\",\"title\":\"Show, Tell, and Polish: Ruminant Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/837a513a43c7bcce903edbacbfc507cba6451e21\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1907.11117\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b73ff5846772da8575262925aa7709b5e64079a0\",\"title\":\"Learning Visual Actions Using Multiple Verb-Only Labels\",\"url\":\"https://www.semanticscholar.org/paper/b73ff5846772da8575262925aa7709b5e64079a0\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"2600667\",\"name\":\"W. Diao\"},{\"authorId\":\"2987316\",\"name\":\"W. Zhang\"},{\"authorId\":\"1972876\",\"name\":\"Menglong Yan\"},{\"authorId\":\"97941663\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.3390/rs11202349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c9a104c7b9a76ba03b8f8cf14f7b6b9066d62f0\",\"title\":\"LAM: Remote Sensing Image Captioning with Label-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/4c9a104c7b9a76ba03b8f8cf14f7b6b9066d62f0\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39970828\",\"name\":\"J. Jacob\"},{\"authorId\":\"2457110\",\"name\":\"M. S. Elayidom\"},{\"authorId\":\"3109670\",\"name\":\"V. P. Devassia\"}],\"doi\":\"10.11591/IJECE.V10I6.PP6019-6025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de96c55acc706c4a02307a5e572753ffab6853d2\",\"title\":\"Video content analysis and retrieval system using video storytelling and indexing techniques\",\"url\":\"https://www.semanticscholar.org/paper/de96c55acc706c4a02307a5e572753ffab6853d2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000438408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53e77b526587b3c3bf7bb359590692a081b53260\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation with Dual Attention and Spatial Memory\",\"url\":\"https://www.semanticscholar.org/paper/53e77b526587b3c3bf7bb359590692a081b53260\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72191633\",\"name\":\"A. F. Smeaton\"},{\"authorId\":\"2000709\",\"name\":\"Y. Graham\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"144620851\",\"name\":\"S. Quinn\"},{\"authorId\":\"40063957\",\"name\":\"Eric Arazo Sanchez\"}],\"doi\":\"10.1007/978-3-030-05710-7_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6066f9ab66c10b038f2afffb621b9db8042a4ed\",\"title\":\"Exploring the Impact of Training Data Bias on Automatic Generation of Video Captions\",\"url\":\"https://www.semanticscholar.org/paper/f6066f9ab66c10b038f2afffb621b9db8042a4ed\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"},{\"authorId\":\"145952554\",\"name\":\"Michael Chan\"},{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"31726556\",\"name\":\"Edmund Tong\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.1109/CVPR.2019.00901\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"title\":\"Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e17aac3bbe0aabda715cafad392f31a1e046c17c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.08960\",\"authors\":[{\"authorId\":\"8716902\",\"name\":\"Huiyuan Xie\"},{\"authorId\":\"20662387\",\"name\":\"Tom Sherborne\"},{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"},{\"authorId\":\"15379653\",\"name\":\"A. Copestake\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3afabdc3650ef93c771262f31db8ee144d0ff44\",\"title\":\"Going Beneath the Surface: Evaluating Image Captioning for Grammaticality, Truthfulness and Diversity\",\"url\":\"https://www.semanticscholar.org/paper/a3afabdc3650ef93c771262f31db8ee144d0ff44\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.12377\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e5d203efae1f0838bb59e31026ce3e7511f87\",\"title\":\"Perceive, Transform, and Act: Multi-Modal Attention Networks for Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/bb4e5d203efae1f0838bb59e31026ce3e7511f87\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98831710\",\"name\":\"B. Yang\"},{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"86010b6cb557103eda7e28fa2b497c9a9697fa8d\",\"title\":\"Non-Autoregressive Video Captioning with Iterative Refinement\",\"url\":\"https://www.semanticscholar.org/paper/86010b6cb557103eda7e28fa2b497c9a9697fa8d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.00299\",\"authors\":[{\"authorId\":\"1504364089\",\"name\":\"Mohammed Bany Muhammad\"},{\"authorId\":\"1828610\",\"name\":\"M. Yeasin\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206626\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8541d37973ec4c8a63b9b7b62dd6c1ec2d069d5\",\"title\":\"Eigen-CAM: Class Activation Map using Principal Components\",\"url\":\"https://www.semanticscholar.org/paper/d8541d37973ec4c8a63b9b7b62dd6c1ec2d069d5\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389373080\",\"name\":\"Ruoyu Chen\"},{\"authorId\":\"2607225\",\"name\":\"Zhongnian Li\"},{\"authorId\":\"1772283\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-1398-5_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bab70faa1e36b525766f85b5ff87bff4566d0294\",\"title\":\"Adaptive Joint Attention with Reinforcement Training for Convolutional Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/bab70faa1e36b525766f85b5ff87bff4566d0294\",\"venue\":\"HBAI@IJCAI\",\"year\":2019},{\"arxivId\":\"2005.07787\",\"authors\":[{\"authorId\":\"39367903\",\"name\":\"Mohammad K. Ebrahimpour\"},{\"authorId\":\"82468335\",\"name\":\"J. Falandays\"},{\"authorId\":\"3363025\",\"name\":\"S. Spevack\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"145042542\",\"name\":\"D. Noelle\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207407\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2be092bb21e1ce1e757c4c4158d8cd282c1111d\",\"title\":\"WW-Nets: Dual Neural Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d2be092bb21e1ce1e757c4c4158d8cd282c1111d\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31465302\",\"name\":\"E. Wang\"},{\"authorId\":\"46182609\",\"name\":\"X. Zhang\"},{\"authorId\":\"39907479\",\"name\":\"F. Wang\"},{\"authorId\":\"1682589\",\"name\":\"T. Wu\"},{\"authorId\":\"144404748\",\"name\":\"Chien-Ming Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2917771\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"title\":\"Multilayer Dense Attention Model for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"title\":\"Talk2Nav: Long-Range Vision-and-Language Navigation in Cities\",\"url\":\"https://www.semanticscholar.org/paper/392d258c7c49a8d22bd6b323b2fb67bbca780a5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145143129\",\"name\":\"Sonit Singh\"},{\"authorId\":\"1785901\",\"name\":\"Sarvnaz Karimi\"},{\"authorId\":\"1403196619\",\"name\":\"K. Ho-Shon\"},{\"authorId\":\"1476819159\",\"name\":\"Len Hamey\"}],\"doi\":\"10.1109/DICTA47822.2019.8945819\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e71a487d2a68394a6fd503eb4bf65c7838c6a818\",\"title\":\"From Chest X-Rays to Radiology Reports: A Multimodal Machine Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/e71a487d2a68394a6fd503eb4bf65c7838c6a818\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"}],\"doi\":\"10.1109/TGRS.2019.2951636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a86714cb7ac711054244aeea51a55715e679ebb\",\"title\":\"Sound Active Attention Framework for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2a86714cb7ac711054244aeea51a55715e679ebb\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669461\",\"name\":\"Kuncheng Fang\"},{\"authorId\":\"144913277\",\"name\":\"Lian Zhou\"},{\"authorId\":\"145020731\",\"name\":\"Cheng Jin\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"35632219\",\"name\":\"Kangnian Weng\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018271\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"title\":\"Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention\",\"url\":\"https://www.semanticscholar.org/paper/506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eccfd6174709c285d62b11fb3da9b68d485ca883\",\"title\":\"Integrating Rule-based Entity Masking into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eccfd6174709c285d62b11fb3da9b68d485ca883\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67159407\",\"name\":\"S. Amirian\"},{\"authorId\":\"1799121\",\"name\":\"K. Rasheed\"},{\"authorId\":\"1784399\",\"name\":\"T. Taha\"},{\"authorId\":\"1712033\",\"name\":\"H. Arabnia\"}],\"doi\":\"10.1109/ACCESS.2020.3042484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"832aafb4989c24211a8377f82228c31f7a90ef81\",\"title\":\"Automatic Image and Video Caption Generation With Deep Learning: A Concise Review and Algorithmic Overlap\",\"url\":\"https://www.semanticscholar.org/paper/832aafb4989c24211a8377f82228c31f7a90ef81\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9358850\",\"name\":\"Ruifan Li\"},{\"authorId\":\"4189987\",\"name\":\"Haoyu Liang\"},{\"authorId\":\"46571714\",\"name\":\"Yihui Shi\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1016/j.neucom.2020.02.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f85b7e09e60315d725b316ffc813d20535b21b2\",\"title\":\"Dual-CNN: A Convolutional language decoder for paragraph image captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f85b7e09e60315d725b316ffc813d20535b21b2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"153173208\",\"name\":\"J. Xu\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1016/j.patrec.2019.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eaffb8e5f6f8d11d0c5c012980b25829667f6d1\",\"title\":\"Exploring diverse and fine-grained caption for video by incorporating convolutional architecture into LSTM-based model\",\"url\":\"https://www.semanticscholar.org/paper/2eaffb8e5f6f8d11d0c5c012980b25829667f6d1\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.09408\",\"authors\":[{\"authorId\":\"144125122\",\"name\":\"L. Jiao\"},{\"authorId\":\"70450696\",\"name\":\"Fan Zhang\"},{\"authorId\":\"47185755\",\"name\":\"F. Liu\"},{\"authorId\":\"1702138\",\"name\":\"Shuyuan Yang\"},{\"authorId\":\"47681309\",\"name\":\"L. Li\"},{\"authorId\":\"1897949\",\"name\":\"Zhixi Feng\"},{\"authorId\":\"145036586\",\"name\":\"R. Qu\"}],\"doi\":\"10.1109/ACCESS.2019.2939201\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a\",\"title\":\"A Survey of Deep Learning-Based Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/dfbeb3ca7a01fe80c49b76baa50bf092f71eef4a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3169864\",\"name\":\"Phyu Phyu Khaing\"}],\"doi\":\"10.5815/IJIGSP.2019.06.01\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"10be5e50205809d7ad88d9687c9def7a94b90978\",\"title\":\"Attention-Based Deep Learning Model for Image Captioning: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/10be5e50205809d7ad88d9687c9def7a94b90978\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.00696\",\"authors\":[{\"authorId\":\"143856269\",\"name\":\"N. Nikhil\"},{\"authorId\":\"1737830\",\"name\":\"B. Morris\"}],\"doi\":\"10.1007/978-3-030-11015-4_16\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eedf0edd1384efaaf3214ad581701ffb0004584e\",\"title\":\"Convolutional Neural Network for Trajectory Prediction\",\"url\":\"https://www.semanticscholar.org/paper/eedf0edd1384efaaf3214ad581701ffb0004584e\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"Jinglun Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"title\":\"Describing Video with Multiple Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a17542ca3c7a39470bdbe70a2209c195be6d63df\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-36718-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"title\":\"SACIC: A Semantics-Aware Convolutional Image Captioner Using Multi-level Pervasive Attention\",\"url\":\"https://www.semanticscholar.org/paper/9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380234931\",\"name\":\"K. Prajwal\"},{\"authorId\":\"1380374156\",\"name\":\"C V Jawahar\"},{\"authorId\":\"1734731\",\"name\":\"P. Kumaraguru\"}],\"doi\":\"10.1145/3343031.3350939\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eeacc1da20db16e2a2bcf4a5902bcff556c7a0ed\",\"title\":\"Towards Increased Accessibility of Meme Images with the Help of Rich Face Emotion Captions\",\"url\":\"https://www.semanticscholar.org/paper/eeacc1da20db16e2a2bcf4a5902bcff556c7a0ed\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2002.11886\",\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5dff9ae50c0aadbd99ca59ff70425f63213243e\",\"title\":\"Hierarchical Memory Decoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a5dff9ae50c0aadbd99ca59ff70425f63213243e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.04983\",\"authors\":[{\"authorId\":\"145746402\",\"name\":\"X. Jin\"},{\"authorId\":\"2688093\",\"name\":\"Le Wu\"},{\"authorId\":\"143681906\",\"name\":\"Geng Zhao\"},{\"authorId\":\"47057319\",\"name\":\"X. Li\"},{\"authorId\":\"1391223326\",\"name\":\"Xiaokun Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"145314008\",\"name\":\"Bin Zhou\"},{\"authorId\":\"51197465\",\"name\":\"Xinghui Zhou\"}],\"doi\":\"10.1145/3343031.3350970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e79423b5e216151ce0cdf615a7098666d9d9c07e\",\"title\":\"Aesthetic Attributes Assessment of Images\",\"url\":\"https://www.semanticscholar.org/paper/e79423b5e216151ce0cdf615a7098666d9d9c07e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423665164\",\"name\":\"Wei-Ta Chu\"},{\"authorId\":\"46398585\",\"name\":\"Yu-Hsin Liu\"}],\"doi\":\"10.1109/MMSP.2019.8901741\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9309dbf3b074c1e569c512706a240a1b45d3ac66\",\"title\":\"Spatiotemporal Modeling and Label Distribution Learning for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/9309dbf3b074c1e569c512706a240a1b45d3ac66\",\"venue\":\"2019 IEEE 21st International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2019},{\"arxivId\":\"2005.09727\",\"authors\":[{\"authorId\":\"39367903\",\"name\":\"Mohammad K. Ebrahimpour\"},{\"authorId\":\"3259825\",\"name\":\"Jiayun Li\"},{\"authorId\":\"1915432\",\"name\":\"Yen-Yun Yu\"},{\"authorId\":\"80106900\",\"name\":\"Jackson Reesee\"},{\"authorId\":\"33129821\",\"name\":\"Azadeh Moghtaderi\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"145042542\",\"name\":\"D. Noelle\"}],\"doi\":\"10.1109/WACV.2019.00110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03bc1c0c2877fc87b86f6c0a385c47676c17836e\",\"title\":\"Ventral-Dorsal Neural Networks: Object Detection Via Selective Attention\",\"url\":\"https://www.semanticscholar.org/paper/03bc1c0c2877fc87b86f6c0a385c47676c17836e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1912.00578\",\"authors\":[{\"authorId\":\"50424875\",\"name\":\"Shruti Bhargava\"},{\"authorId\":\"144016260\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d1735a875eb2b3dfd0f281492c9b28b16f72bc9\",\"title\":\"Exposing and Correcting the Gender Bias in Image Captioning Datasets and Models\",\"url\":\"https://www.semanticscholar.org/paper/5d1735a875eb2b3dfd0f281492c9b28b16f72bc9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"119837541\",\"name\":\"Jian-Ming Wu\"},{\"authorId\":\"2000011573\",\"name\":\"Jinfa Huang\"},{\"authorId\":\"31229419\",\"name\":\"G. Hattori\"},{\"authorId\":\"2466117\",\"name\":\"Y. Takishima\"},{\"authorId\":\"2000114316\",\"name\":\"Shinya Wada\"},{\"authorId\":\"1809845071\",\"name\":\"Rui Kimura\"},{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"1610841750\",\"name\":\"Satoshi Kurihara\"}],\"doi\":\"10.1145/3382507.3418830\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1526a7ad07d90f1b53b63299bb1cb9c0ce01925\",\"title\":\"LDNN: Linguistic Knowledge Injectable Deep Neural Network for Group Cohesiveness Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e1526a7ad07d90f1b53b63299bb1cb9c0ce01925\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.00717\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"2802555\",\"name\":\"Xi Meng\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"50078954\",\"name\":\"Xia Li\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"51130683\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36a3cfa6ed48988e23cf68b3abcbe097b29e594a\",\"title\":\"Masked Non-Autoregressive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/36a3cfa6ed48988e23cf68b3abcbe097b29e594a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Arnav Arnav\"},{\"authorId\":\"1488660042\",\"name\":\"Hankyu Jang\"},{\"authorId\":null,\"name\":\"Pulkit Maloo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6270b5a5b43c3233601cb1a4d33855fd818ace47\",\"title\":\"Image Captioning Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/6270b5a5b43c3233601cb1a4d33855fd818ace47\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1900967\",\"name\":\"U. Zia\"},{\"authorId\":\"145759322\",\"name\":\"M. M. Riaz\"},{\"authorId\":\"144683577\",\"name\":\"A. Ghafoor\"},{\"authorId\":\"145602758\",\"name\":\"Seyyed Salehi Seyyed Ali\"}],\"doi\":\"10.1007/s00521-019-04587-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"title\":\"Topic sensitive image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/48473eb93b43e0130fce0d1eabb9b8fa468d8a41\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3055959\",\"name\":\"Veena Thenkanidiyoor\"},{\"authorId\":\"47798961\",\"name\":\"R. Prasath\"},{\"authorId\":\"150255310\",\"name\":\"Odelu Vanga\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-66187-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b326e950ca86368056d2846444c25c61fedbc111\",\"title\":\"Mining Intelligence and Knowledge Exploration: 7th International Conference, MIKE 2019, Goa, India, December 19\\u201322, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/b326e950ca86368056d2846444c25c61fedbc111\",\"venue\":\"MIKE\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40469481\",\"name\":\"T. Nogueira\"},{\"authorId\":\"32535425\",\"name\":\"C. Vinhal\"},{\"authorId\":\"1491425913\",\"name\":\"G\\u00e9lson da Cruz J\\u00fanior\"},{\"authorId\":\"2569769\",\"name\":\"Matheus Rudolfo Diedrich Ullmann\"}],\"doi\":\"10.1007/s11042-020-09539-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48f17b2b08aebd16e711f5c7ca9e773fe6639dc3\",\"title\":\"Reference-based model using multimodal gated recurrent units for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/48f17b2b08aebd16e711f5c7ca9e773fe6639dc3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1811.10762\",\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d82091b1e817be4497fbe11c01ad473d99894c6\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Video Forgery\",\"url\":\"https://www.semanticscholar.org/paper/8d82091b1e817be4497fbe11c01ad473d99894c6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1419474253\",\"name\":\"Md Asifuzzaman Jishan\"},{\"authorId\":\"102857185\",\"name\":\"K. R. Mahmud\"},{\"authorId\":\"48058214\",\"name\":\"A. K. Azad\"},{\"authorId\":\"2868008\",\"name\":\"M. S. Alam\"},{\"authorId\":\"2004453191\",\"name\":\"Anif Minhaz Khan\"}],\"doi\":\"10.26555/ijain.v6i2.499\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"592664a1eb6209c58ab1056ad2e988ad4cd72559\",\"title\":\"Hybrid deep neural network for Bangla automated image descriptor\",\"url\":\"https://www.semanticscholar.org/paper/592664a1eb6209c58ab1056ad2e988ad4cd72559\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"119837541\",\"name\":\"Jian-Ming Wu\"},{\"authorId\":\"47664350\",\"name\":\"Panikos Heracleous\"},{\"authorId\":\"2000114316\",\"name\":\"Shinya Wada\"},{\"authorId\":\"1809845071\",\"name\":\"Rui Kimura\"},{\"authorId\":\"1610841750\",\"name\":\"Satoshi Kurihara\"}],\"doi\":\"10.1145/3382507.3417960\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8e51672cd32ec57536f689165d3030ff63f1e7d\",\"title\":\"Implicit Knowledge Injectable Cross Attention Audiovisual Model for Group Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8e51672cd32ec57536f689165d3030ff63f1e7d\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc8df4ad35282ccf19261e02de87d8e35c956537\",\"title\":\"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fc8df4ad35282ccf19261e02de87d8e35c956537\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2010.02917\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c97dfad7a023fbec97a901dae02b73e2e8e0fff1\",\"title\":\"NCP-VAE: Variational Autoencoders with Noise Contrastive Priors\",\"url\":\"https://www.semanticscholar.org/paper/c97dfad7a023fbec97a901dae02b73e2e8e0fff1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wadalkar Shruti\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"472faa9c5fbc81dac9ee5405446dd8403415ac3a\",\"title\":\"International Journal of Innovative Technology and Exploring Engineering (IJITEE)\",\"url\":\"https://www.semanticscholar.org/paper/472faa9c5fbc81dac9ee5405446dd8403415ac3a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002278\",\"name\":\"Yikuan Li\"},{\"authorId\":\"51464971\",\"name\":\"Hanyin Wang\"},{\"authorId\":\"1830568527\",\"name\":\"Yuan Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"title\":\"A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports\",\"url\":\"https://www.semanticscholar.org/paper/ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.09732\",\"authors\":[{\"authorId\":\"2038261026\",\"name\":\"Daniel Yarnell\"},{\"authorId\":\"101212075\",\"name\":\"Xian Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"952145153f8d7f4adde7e33f9df8b90fbf5ab16c\",\"title\":\"Robust Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/952145153f8d7f4adde7e33f9df8b90fbf5ab16c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39785051\",\"name\":\"A. Jensen\"},{\"authorId\":\"66977188\",\"name\":\"Henrik Marklund\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3694b66e14c35ed1c592a914689f5d45d537896d\",\"title\":\"Turning Equations into Latex : Pipeline vs . End-to-End\",\"url\":\"https://www.semanticscholar.org/paper/3694b66e14c35ed1c592a914689f5d45d537896d\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938051940\",\"name\":\"Dylan Flaute\"},{\"authorId\":\"2405109\",\"name\":\"B. Narayanan\"}],\"doi\":\"10.1117/12.2568016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"title\":\"Video captioning using weakly supervised convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"venue\":\"Optical Engineering + Applications\",\"year\":2020},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47458613\",\"name\":\"A. Tripathi\"},{\"authorId\":\"145305735\",\"name\":\"Siddharth Srivastava\"},{\"authorId\":\"144174561\",\"name\":\"R. Kothari\"}],\"doi\":\"10.1007/978-3-030-04780-1_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"title\":\"Deep Neural Network Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"venue\":\"BDA\",\"year\":2018},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1810.04101\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"2120874\",\"name\":\"Tobias Domhan\"},{\"authorId\":\"2521764\",\"name\":\"F. Hieber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"title\":\"Image Captioning as Neural Machine Translation Task in SOCKEYE\",\"url\":\"https://www.semanticscholar.org/paper/d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134518946\",\"name\":\"Nanxing Li\"},{\"authorId\":\"50678073\",\"name\":\"Bei Liu\"},{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1145/3323873.3325050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"title\":\"Emotion Reinforced Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.03244\",\"authors\":[{\"authorId\":\"1779143\",\"name\":\"Weiyu Guo\"},{\"authorId\":\"1796267433\",\"name\":\"Yidong Ouyang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c98a546daf54264aa35dc13a4fbde38df2d88d6a\",\"title\":\"Robust Learning with Frequency Domain Regularization\",\"url\":\"https://www.semanticscholar.org/paper/c98a546daf54264aa35dc13a4fbde38df2d88d6a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.02517\",\"authors\":[{\"authorId\":\"32583496\",\"name\":\"Y. Fu\"},{\"authorId\":\"46999477\",\"name\":\"Tingting Liu\"},{\"authorId\":\"31933517\",\"name\":\"M. Gao\"},{\"authorId\":\"145031578\",\"name\":\"Aoying Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2395f4b80e54d4b93bf425e207aa6d2236dd5f0b\",\"title\":\"EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for Printed Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2395f4b80e54d4b93bf425e207aa6d2236dd5f0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2565254\",\"name\":\"Hegui Zhu\"},{\"authorId\":\"47780733\",\"name\":\"Baoyu Wang\"},{\"authorId\":\"49470457\",\"name\":\"X. Zhang\"},{\"authorId\":\"2851859\",\"name\":\"J. Liu\"}],\"doi\":\"10.1007/s10489-020-01671-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"160c444f96c7b71304a2f310e88b05944614a5ec\",\"title\":\"Semantic image segmentation with shared decomposition convolution and boundary reinforcement structure\",\"url\":\"https://www.semanticscholar.org/paper/160c444f96c7b71304a2f310e88b05944614a5ec\",\"venue\":\"Applied Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005279478\",\"name\":\"Sreela Sreekumaran Pillai Remadevi Amma\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.25046/aj050447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1226eeb9787b7555e810ee289c4593cb2da04775\",\"title\":\"Keyword Driven Image Description Generation System\",\"url\":\"https://www.semanticscholar.org/paper/1226eeb9787b7555e810ee289c4593cb2da04775\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020}],\"corpusId\":35543299,\"doi\":\"10.1109/CVPR.2018.00583\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":16,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"references\":[{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1506.02640\",\"authors\":[{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2016.91\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"title\":\"You Only Look Once: Unified, Real-Time Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f8e79ac0ea341056ef20f2616628b3e964764cfd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1603.06059\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.18653/v1/P16-1170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"title\":\"Generating Natural Questions About an Image\",\"url\":\"https://www.semanticscholar.org/paper/8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1803.11209\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"143668320\",\"name\":\"W. Hwu\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e81df94c24c08963c7d338d601bb030a8d919720\",\"title\":\"Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/e81df94c24c08963c7d338d601bb030a8d919720\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1610.09038\",\"authors\":[{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"title\":\"Professor Forcing: A New Algorithm for Training Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1211.5063\",\"authors\":[{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84069287da0a6b488b8c933f3cb5be759cb6237e\",\"title\":\"On the difficulty of training recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/84069287da0a6b488b8c933f3cb5be759cb6237e\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1703.06233\",\"authors\":[{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2017.57\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"title\":\"Recurrent Models for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/afc7d76c94c9b73aa28f4aa42407b21aa0572a1b\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.4729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.3115/v1/N15-1173\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cef41606f1e1324b683441e694f0e1c96387abf\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cef41606f1e1324b683441e694f0e1c96387abf\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Agrawal\"},{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"M. Mitchell\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"L. C.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zit - nick , and D . Parikh . VQA : Visual Question Answering\",\"url\":\"\",\"venue\":\"International Conference on Computer Vision ( ICCV )\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1706.03762\",\"authors\":[{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"},{\"authorId\":\"3877127\",\"name\":\"Niki Parmar\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"},{\"authorId\":\"145024664\",\"name\":\"Llion Jones\"},{\"authorId\":\"19177000\",\"name\":\"Aidan N. Gomez\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"3443442\",\"name\":\"Illia Polosukhin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"title\":\"Attention is All you Need\",\"url\":\"https://www.semanticscholar.org/paper/204e3073870fae3d05bcbc2f6a8e263d9b72e776\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2011.6126524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85cb25e88d3b0548a26e7a70b6953e500d27eb9a\",\"title\":\"Learning cross-modality similarity for multinomial data\",\"url\":\"https://www.semanticscholar.org/paper/85cb25e88d3b0548a26e7a70b6953e500d27eb9a\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.05328\",\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"2311318\",\"name\":\"Lasse Espeholt\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0936352b78a52bc5d2b5e3f04233efc56664af51\",\"title\":\"Conditional Image Generation with PixelCNN Decoders\",\"url\":\"https://www.semanticscholar.org/paper/0936352b78a52bc5d2b5e3f04233efc56664af51\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1412.0774\",\"authors\":[{\"authorId\":\"1850973\",\"name\":\"Mohammadreza Mostajabi\"},{\"authorId\":\"2376506\",\"name\":\"Payman Yadollahpour\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/cvpr.2015.7298959\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31622dee41d13f90a099025425dcfb88d0970e60\",\"title\":\"Feedforward semantic segmentation with zoom-out features\",\"url\":\"https://www.semanticscholar.org/paper/31622dee41d13f90a099025425dcfb88d0970e60\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1803.11187\",\"authors\":[{\"authorId\":\"2484223\",\"name\":\"Yuan-Ting Hu\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e2ae4714106a2d5f7e426d640b2f7efa43735e3\",\"title\":\"MaskRNN: Instance Level Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/1e2ae4714106a2d5f7e426d640b2f7efa43735e3\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145704247\",\"name\":\"J. Martens\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"title\":\"Generating Text with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1604.03968\",\"authors\":[{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3139/9783446448100.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927987a48c2a519bbc097d8b6c925b64a85b7d8e\",\"title\":\"Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/927987a48c2a519bbc097d8b6c925b64a85b7d8e\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1705.03122\",\"authors\":[{\"authorId\":\"2401865\",\"name\":\"Jonas Gehring\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2529182\",\"name\":\"David Grangier\"},{\"authorId\":\"13759615\",\"name\":\"Denis Yarats\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43428880d75b3a14257c3ee9bda054e61eb869c0\",\"title\":\"Convolutional Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/43428880d75b3a14257c3ee9bda054e61eb869c0\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1711.04323\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"799537fa855caf53a6a3a7cf20301a81e90da127\",\"title\":\"High-Order Attention Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/799537fa855caf53a6a3a7cf20301a81e90da127\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}],\"title\":\"Convolutional Image Captioning\",\"topics\":[{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Machine translation\",\"topicId\":\"34995\",\"url\":\"https://www.semanticscholar.org/topic/34995\"},{\"topic\":\"Vanishing gradient problem\",\"topicId\":\"178687\",\"url\":\"https://www.semanticscholar.org/topic/178687\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Natural language generation\",\"topicId\":\"6196\",\"url\":\"https://www.semanticscholar.org/topic/6196\"},{\"topic\":\"Glossary of computer graphics\",\"topicId\":\"12790\",\"url\":\"https://www.semanticscholar.org/topic/12790\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Random neural network\",\"topicId\":\"136146\",\"url\":\"https://www.semanticscholar.org/topic/136146\"},{\"topic\":\"Neural Networks\",\"topicId\":\"99954\",\"url\":\"https://www.semanticscholar.org/topic/99954\"}],\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"