"{\"abstract\":\"Visual events are usually accompanied by sounds in our daily lives. We pose the question: Can the machine learn the correspondence between visual scene and the sound, and localize the sound source only by observing sound and visual scene pairs like human? In this paper, we propose a novel unsupervised algorithm to address the problem of localizing the sound source in visual scenes. A two-stream network structure which handles each modality, with attention mechanism is developed for sound source localization. Moreover, although our network is formulated within the unsupervised learning framework, it can be extended to a unified architecture with a simple modification for the supervised and semi-supervised learning settings as well. Meanwhile, a new sound source dataset is developed for performance evaluation. Our empirical evaluation shows that the unsupervised method eventually go through false conclusion in some cases. We also show that even with a few supervision, i.e., semi-supervised setup, false conclusion is able to be corrected effectively.\",\"arxivId\":\"1803.03849\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\",\"url\":\"https://www.semanticscholar.org/author/40895287\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\",\"url\":\"https://www.semanticscholar.org/author/66808667\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\",\"url\":\"https://www.semanticscholar.org/author/3053231\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\",\"url\":\"https://www.semanticscholar.org/author/1715634\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\",\"url\":\"https://www.semanticscholar.org/author/2398271\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405328114\",\"name\":\"Benjamin Cohen-Lhyver\"},{\"authorId\":\"1725528\",\"name\":\"S. Argentieri\"},{\"authorId\":\"144515613\",\"name\":\"Bruno Gas\"}],\"doi\":\"10.3389/fnbot.2018.00060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae3d8ad73472104278b0ef980de6756e326d8a49\",\"title\":\"The Head Turning Modulation System: An Active Multimodal Paradigm for Intrinsically Motivated Exploration of Unknown Environments\",\"url\":\"https://www.semanticscholar.org/paper/ae3d8ad73472104278b0ef980de6756e326d8a49\",\"venue\":\"Front. Neurorobot.\",\"year\":2018},{\"arxivId\":\"2007.01851\",\"authors\":[{\"authorId\":\"3393217\",\"name\":\"Dhiraj Gandhi\"},{\"authorId\":\"50179097\",\"name\":\"Abhinav Gupta\"},{\"authorId\":\"34026610\",\"name\":\"Lerrel Pinto\"}],\"doi\":\"10.15607/RSS.2020.XVI.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f9ee3659c2a855b33ae256e98b05c51b2e30b7\",\"title\":\"Swoosh! Rattle! Thump! - Actions that Sound\",\"url\":\"https://www.semanticscholar.org/paper/c9f9ee3659c2a855b33ae256e98b05c51b2e30b7\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47820818\",\"name\":\"J. Pu\"},{\"authorId\":\"1780393\",\"name\":\"Yannis Panagakis\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/LSP.2020.2996412\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"922ed60c21df0bfff640bec0a3cf48d83f58eb54\",\"title\":\"Active Speaker Detection and Localization in Videos Using Low-Rank and Kernelized Sparsity\",\"url\":\"https://www.semanticscholar.org/paper/922ed60c21df0bfff640bec0a3cf48d83f58eb54\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"1904.07750\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"title\":\"Co-Separating Sounds of Visual Objects\",\"url\":\"https://www.semanticscholar.org/paper/7a88fa82b2032b8234a2005c26de8fbb096aa27a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.05466\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"46332801\",\"name\":\"Minyue Jiang\"},{\"authorId\":\"5424083\",\"name\":\"X. Tan\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"title\":\"Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching\",\"url\":\"https://www.semanticscholar.org/paper/e96b7de5f6366aa1a8b4377d97c3f2464ab198ca\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2002.10981\",\"authors\":[{\"authorId\":\"48359318\",\"name\":\"Sanchita Ghose\"},{\"authorId\":\"2845029\",\"name\":\"John J. Prevost\"}],\"doi\":\"10.1109/TMM.2020.3005033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1337db4d3283e77e959a683ef5cb15949f1d5400\",\"title\":\"AutoFoley: Artificial Synthesis of Synchronized Sound Tracks for Silent Videos with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/1337db4d3283e77e959a683ef5cb15949f1d5400\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.07473\",\"authors\":[{\"authorId\":\"2564871\",\"name\":\"Yan-Bo Lin\"},{\"authorId\":\"3312576\",\"name\":\"Yu-Jhe Li\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"title\":\"Dual-modality Seq2Seq Network for Audio-visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1905.05375\",\"authors\":[{\"authorId\":\"8646392\",\"name\":\"Yu-Ding Lu\"},{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"143963461\",\"name\":\"Hung-Yu Tseng\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICIP.2019.8803494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"038c51491347abe8ff34af421083ad249d4953ac\",\"title\":\"Self-Supervised Audio Spatialization with Correspondence Classifier\",\"url\":\"https://www.semanticscholar.org/paper/038c51491347abe8ff34af421083ad249d4953ac\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1811.10813\",\"authors\":[{\"authorId\":\"2927349\",\"name\":\"S. Shon\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2019.8683477\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac545258eb99e8ee83787903ce74b37cddf00e4e\",\"title\":\"Noise-tolerant Audio-visual Online Person Verification Using an Attention-based Neural Network Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ac545258eb99e8ee83787903ce74b37cddf00e4e\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1911.09649\",\"authors\":[{\"authorId\":\"40895287\",\"name\":\"Arda Senocak\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"3053231\",\"name\":\"J. Kim\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/tpami.2019.2952095\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"title\":\"Learning to Localize Sound Sources in Visual Scenes: Analysis and Applications\",\"url\":\"https://www.semanticscholar.org/paper/edd75cbdad797febb765e2bcaa8653b77138e3a5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50670669\",\"name\":\"T. Konno\"},{\"authorId\":\"1491179155\",\"name\":\"K. Nishida\"},{\"authorId\":\"1491176055\",\"name\":\"K. Itoyama\"},{\"authorId\":\"1764429\",\"name\":\"K. Nakadai\"}],\"doi\":\"10.1109/SII46433.2020.9025812\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee9ed2ac476de9097165db6c7118b7daf9b648cf\",\"title\":\"Audio-Visual 3D Reconstruction Framework for Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/ee9ed2ac476de9097165db6c7118b7daf9b648cf\",\"venue\":\"2020 IEEE/SICE International Symposium on System Integration (SII)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144039832\",\"name\":\"P. Barros\"},{\"authorId\":\"2236890\",\"name\":\"Manfred Eppe\"},{\"authorId\":\"2988592\",\"name\":\"G. Parisi\"},{\"authorId\":\"144227938\",\"name\":\"X. Liu\"},{\"authorId\":\"1736513\",\"name\":\"S. Wermter\"}],\"doi\":\"10.3389/frobt.2019.00137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afbc0881addf58dd82afb2580d0fecd42f65acd6\",\"title\":\"Expectation Learning for Stimulus Prediction Across Modalities Improves Unisensory Classification\",\"url\":\"https://www.semanticscholar.org/paper/afbc0881addf58dd82afb2580d0fecd42f65acd6\",\"venue\":\"Front. Robot. AI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":\"145857587\",\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8f430dbeb164ef96dedfd83bf2583684fab2faa5\",\"title\":\"A Two-Stage Framework for Multiple Sound-Source Localization\",\"url\":\"https://www.semanticscholar.org/paper/8f430dbeb164ef96dedfd83bf2583684fab2faa5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.08606\",\"authors\":[{\"authorId\":\"152848162\",\"name\":\"You Jin Kim\"},{\"authorId\":\"1594024908\",\"name\":\"Hee Soo Heo\"},{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"50643194\",\"name\":\"Bong-Jin Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995fd68acb1ee8c04134be1954cfc4b12f685325\",\"title\":\"End-to-End Lip Synchronisation\",\"url\":\"https://www.semanticscholar.org/paper/995fd68acb1ee8c04134be1954cfc4b12f685325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35399640\",\"name\":\"D\\u00eddac Sur\\u00eds\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"144159726\",\"name\":\"David Bau\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2019.00213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"title\":\"Learning Words by Drawing Images\",\"url\":\"https://www.semanticscholar.org/paper/bbc9cb65aeb814de917fecab31843b95070c3cc1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2008.04237\",\"authors\":[{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58523-5_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0eb79a085e014f129b063199a38fe9945355c137\",\"title\":\"Self-Supervised Learning of Audio-Visual Objects from Video\",\"url\":\"https://www.semanticscholar.org/paper/0eb79a085e014f129b063199a38fe9945355c137\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46429335\",\"name\":\"Feng Wang\"},{\"authorId\":\"144393480\",\"name\":\"D. Guo\"},{\"authorId\":\"31833173\",\"name\":\"H. Liu\"},{\"authorId\":\"51239630\",\"name\":\"Junfeng Zhou\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1109/ICRA.2019.8794166\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"052eb3e2f7015d9f0d138897291b78f2d5b54b32\",\"title\":\"Sound-Indicated Visual Object Detection for Robotic Exploration\",\"url\":\"https://www.semanticscholar.org/paper/052eb3e2f7015d9f0d138897291b78f2d5b54b32\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"2005.01616\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58545-7_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33006edd74d92453903df5a53fa25539047c1850\",\"title\":\"VisualEchoes: Spatial Image Representation Learning through Echolocation\",\"url\":\"https://www.semanticscholar.org/paper/33006edd74d92453903df5a53fa25539047c1850\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.11306\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2019.00583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4892a8ac3e3e3575b17fff393e57b8fd20a08a8\",\"title\":\"Controllable Attention for Structured Layered Video Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/c4892a8ac3e3e3575b17fff393e57b8fd20a08a8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1712.01393\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2018.00374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2d126e02401ec9f3c131eac423620529996df2f\",\"title\":\"Visual to Sound: Generating Natural Sound for Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f2d126e02401ec9f3c131eac423620529996df2f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.07933\",\"authors\":[{\"authorId\":\"145343013\",\"name\":\"Andr\\u00e9s F. P\\u00e9rez\"},{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/WACV45572.2020.9093307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"title\":\"Audio-Visual Model Distillation Using Acoustic Images\",\"url\":\"https://www.semanticscholar.org/paper/f7c6ab8303a03dc9e8454c070030c3e6b0233d40\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1809.08001\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"9299637\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.1109/ICASSP.2019.8682524\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4d66090e0bddb6f751241acd6e59cf25756e57a9\",\"title\":\"Perfect Match: Improved Cross-modal Embeddings for Audio-visual Synchronisation\",\"url\":\"https://www.semanticscholar.org/paper/4d66090e0bddb6f751241acd6e59cf25756e57a9\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"153579825\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.1109/JSTSP.2020.2987720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7431525dd5b821532191c7c078972bc457565d86\",\"title\":\"Perfect Match: Self-Supervised Embeddings for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7431525dd5b821532191c7c078972bc457565d86\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1807.03094\",\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16d4d7ec673b5697776d1c4f229f5a824b891972\",\"title\":\"Deep Co-Clustering for Unsupervised Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/16d4d7ec673b5697776d1c4f229f5a824b891972\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.09013\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICASSP.2019.8682467\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"title\":\"Self-supervised Audio-visual Co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c4a44cd4c6bdd7fe85a1227c5041827ba828e0de\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"27361710\",\"name\":\"K. Dinesh\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"144054465\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"2591822\",\"name\":\"Zhiyan Duan\"}],\"doi\":\"10.5334/TISMIR.25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"67cf2d19d7a2a18d18ad8c0bba7ccd9c8c1e85ad\",\"title\":\"Online Audio-Visual Source Association for Chamber Music Performances\",\"url\":\"https://www.semanticscholar.org/paper/67cf2d19d7a2a18d18ad8c0bba7ccd9c8c1e85ad\",\"venue\":\"Trans. Int. Soc. Music. Inf. Retr.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1600703039\",\"name\":\"Janani Ramaswamy\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"380e7cc65c7be734f2179953bd921630afdee6ec\",\"title\":\"What Makes the Sound?: A Dual-Modality Interacting Network for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/380e7cc65c7be734f2179953bd921630afdee6ec\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b0697bf5bded55d59c58e5d955d49354afbcd95\",\"title\":\"Weakly-Supervised Audio-Visual Video Parsing Toward Unified Multisensory Perception\",\"url\":\"https://www.semanticscholar.org/paper/3b0697bf5bded55d59c58e5d955d49354afbcd95\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.12943\",\"authors\":[{\"authorId\":\"31692099\",\"name\":\"Pedro Morgado\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afc91295df19ffc7ab95530dc879ac11126afeee\",\"title\":\"Audio-Visual Instance Discrimination with Cross-Modal Agreement\",\"url\":\"https://www.semanticscholar.org/paper/afc91295df19ffc7ab95530dc879ac11126afeee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06170\",\"authors\":[{\"authorId\":\"151444035\",\"name\":\"Samyak Jain\"},{\"authorId\":\"34935738\",\"name\":\"Pradeep Yarlagadda\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"},{\"authorId\":\"145091336\",\"name\":\"V. Gandhi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"title\":\"AViNet: Diving Deep into Audio-Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/40a7f20cf6a05a481146bd7f18ba747d17700ebd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113109\",\"name\":\"Valentina Sanguineti\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"2026650249\",\"name\":\"Niccol\\u00f2 Pozzetti\"},{\"authorId\":\"103150889\",\"name\":\"D. Greco\"},{\"authorId\":\"1723008\",\"name\":\"Marco Cristani\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-58542-6_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8728049700f949a4731ca9d6de73dee8940592bc\",\"title\":\"Leveraging Acoustic Images for Effective Self-supervised Audio Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/8728049700f949a4731ca9d6de73dee8940592bc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1712.06651\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01246-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfc504536e8434eb008680343abb77010965169e\",\"title\":\"Objects that Sound\",\"url\":\"https://www.semanticscholar.org/paper/dfc504536e8434eb008680343abb77010965169e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1909.09944\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00900\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a2de516a4e628a30036193d71faac7240d553ef\",\"title\":\"Watch, Listen and Tell: Multi-Modal Weakly Supervised Dense Event Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7a2de516a4e628a30036193d71faac7240d553ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.04210\",\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58548-8_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4d981cc84ee972104eb6d95a2421a42db8a0cf57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.06175\",\"authors\":[{\"authorId\":\"2806097\",\"name\":\"Karren D. Yang\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"1786276\",\"name\":\"Justin Salamon\"}],\"doi\":\"10.1109/cvpr42600.2020.00995\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"title\":\"Telling Left From Right: Learning Spatial Correspondence of Sight and Sound\",\"url\":\"https://www.semanticscholar.org/paper/7555e7a02b23886f1c17049999e4fc66b30c8bf3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.05894\",\"authors\":[{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"37107826\",\"name\":\"R. C. Moore\"},{\"authorId\":\"2114994\",\"name\":\"M. Plakal\"},{\"authorId\":\"2054252\",\"name\":\"A. Popat\"},{\"authorId\":\"2278009\",\"name\":\"R. A. Saurous\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054137\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8db0c9bdc2acf3c3fb25d5474f24472e8372bf8\",\"title\":\"Coincidence, Categorization, and Consolidation: Learning to Recognize Sounds with Minimal Supervision\",\"url\":\"https://www.semanticscholar.org/paper/d8db0c9bdc2acf3c3fb25d5474f24472e8372bf8\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"2841633\",\"name\":\"Hyunmin Lee\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.18653/v1/N19-1011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4798919e74411d87f7745840e45b8bcf61128ff\",\"title\":\"AudioCaps: Generating Captions for Audios in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/c4798919e74411d87f7745840e45b8bcf61128ff\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2001.09414\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"98358780\",\"name\":\"Z. Wang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"04b6568cb7f30c399157e94c30b44c59c00e251d\",\"title\":\"Curriculum Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/04b6568cb7f30c399157e94c30b44c59c00e251d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04758\",\"authors\":[{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"100602595\",\"name\":\"Mandi Luo\"},{\"authorId\":\"77886607\",\"name\":\"Rui Wang\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"title\":\"Deep Audio-Visual Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.11760\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"51333271\",\"name\":\"H. Zhao\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00715\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05c846b122dc64b6900c09b9210912615a3febb6\",\"title\":\"Self-Supervised Moving Vehicle Tracking With Stereo Sound\",\"url\":\"https://www.semanticscholar.org/paper/05c846b122dc64b6900c09b9210912615a3febb6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993602785\",\"name\":\"Ruijian Jia\"},{\"authorId\":\"50142011\",\"name\":\"Xinsheng Wang\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"40689776\",\"name\":\"J. Xue\"}],\"doi\":\"10.1145/3394171.3414023\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4955fda9e96f97e0dcd45c846ec52cb118d89060\",\"title\":\"Look, Listen and Infer\",\"url\":\"https://www.semanticscholar.org/paper/4955fda9e96f97e0dcd45c846ec52cb118d89060\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2007.09902\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"48670507\",\"name\":\"Xudong Xu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1007/978-3-030-58610-2_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73aa926dad010a3f1bb89faa31241f97a89cc461\",\"title\":\"Sep-Stereo: Visually Guided Stereophonic Audio Generation by Associating Source Separation\",\"url\":\"https://www.semanticscholar.org/paper/73aa926dad010a3f1bb89faa31241f97a89cc461\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.06355\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1500378795\",\"name\":\"Di Hu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1007/978-3-030-58565-5_18\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"title\":\"Multiple Sound Sources Localization from Coarse to Fine\",\"url\":\"https://www.semanticscholar.org/paper/53eb4c778e7c2aec2f4c5d2681321b18c06decca\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.04687\",\"authors\":[{\"authorId\":\"2678268\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"9754502\",\"name\":\"Yujia Shi\"},{\"authorId\":\"5264927\",\"name\":\"Yujia Sun\"},{\"authorId\":\"1802542506\",\"name\":\"Fangtao Shao\"},{\"authorId\":\"48551946\",\"name\":\"Zhaoyang Wu\"},{\"authorId\":\"40615725\",\"name\":\"Zhiwei Yang\"}],\"doi\":\"10.1007/978-3-030-58577-8_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f28873be3601c5a2736996eba543cf51950a381\",\"title\":\"Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/8f28873be3601c5a2736996eba543cf51950a381\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2202838\",\"name\":\"David B. Lindell\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":\"10.1109/CVPR.2019.00694\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c5b1bbc49e4be0efd98e0b513e0b41659a32413\",\"title\":\"Acoustic Non-Line-Of-Sight Imaging\",\"url\":\"https://www.semanticscholar.org/paper/7c5b1bbc49e4be0efd98e0b513e0b41659a32413\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.11602\",\"authors\":[{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00097\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"title\":\"Recursive Visual Sound Separation Using Minus-Plus Net\",\"url\":\"https://www.semanticscholar.org/paper/b7a5f074e06cf8d71e26fb5d25b86b4164a5bb54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.04463\",\"authors\":[{\"authorId\":\"151500851\",\"name\":\"K. Deng\"},{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"title\":\"Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04298\",\"authors\":[{\"authorId\":\"1379929116\",\"name\":\"Mandela Patrick\"},{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":\"145891577\",\"name\":\"Ruth Fong\"},{\"authorId\":\"143848064\",\"name\":\"Jo\\u00e3o F. Henriques\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"title\":\"Multi-modal Self-Supervision from Generalized Data Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8ddbaa34c574124a91fa3bc217e232e17668e84c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/CVPR.2019.00947\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8abc9fc312fc6916725ec94816ab26c582cf1a90\",\"title\":\"Deep Multimodal Clustering for Unsupervised Audiovisual Learning\",\"url\":\"https://www.semanticscholar.org/paper/8abc9fc312fc6916725ec94816ab26c582cf1a90\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.07984\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"title\":\"Separating Sounds from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.02001\",\"authors\":[{\"authorId\":\"49923155\",\"name\":\"Hsin-Ying Lee\"},{\"authorId\":\"47008546\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"153699069\",\"name\":\"Mingyu Liu\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"8646392\",\"name\":\"Yu-Ding Lu\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"title\":\"Dancing to Music\",\"url\":\"https://www.semanticscholar.org/paper/12b38ff98d8cb847d735f8fb2b331cdcc30cae91\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.11684\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":\"10.1109/ICRA40945.2020.9197008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a24996f14c194cd125fd69b5af32037d5abee1a\",\"title\":\"Look, Listen, and Act: Towards Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/3a24996f14c194cd125fd69b5af32037d5abee1a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.06581\",\"authors\":[{\"authorId\":\"1826395\",\"name\":\"Bin Duan\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"91913011\",\"name\":\"Wei Wang\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":null,\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"title\":\"Audio-Visual Event Localization via Recursive Fusion by Joint Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01143\",\"authors\":[{\"authorId\":\"18139933\",\"name\":\"Efthymios Tzinis\"},{\"authorId\":\"34654283\",\"name\":\"Scott T. Wisdom\"},{\"authorId\":\"35996413\",\"name\":\"A. Jansen\"},{\"authorId\":\"50781940\",\"name\":\"Shawn Hershey\"},{\"authorId\":\"2211633\",\"name\":\"Tal Remez\"},{\"authorId\":\"1745455\",\"name\":\"D. Ellis\"},{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"title\":\"Into the Wild with AudioScope: Unsupervised Audio-Visual Separation of On-Screen Sounds\",\"url\":\"https://www.semanticscholar.org/paper/8cc141d242387dc9b64124e97896097ddfd6bcf2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.05553\",\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-20873-8_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"title\":\"On Learning Associations of Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1812.02872\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2149345\",\"name\":\"Chenxiao Guan\"},{\"authorId\":\"48616329\",\"name\":\"J. Goodman\"},{\"authorId\":\"50583301\",\"name\":\"Marc Moore\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5328a7024f820fafdab4165777807c2ecb855fe4\",\"title\":\"An Attempt towards Interpretable Audio-Visual Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5328a7024f820fafdab4165777807c2ecb855fe4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990548\",\"name\":\"Go Irie\"},{\"authorId\":\"9211474\",\"name\":\"M. O\\u0161trek\"},{\"authorId\":\"48017277\",\"name\":\"Haochen Wang\"},{\"authorId\":\"1787190\",\"name\":\"H. Kameoka\"},{\"authorId\":\"34454585\",\"name\":\"A. Kimura\"},{\"authorId\":\"1858824\",\"name\":\"Takahito Kawanishi\"},{\"authorId\":\"1718803\",\"name\":\"Kunio Kashino\"}],\"doi\":\"10.1109/ICASSP.2019.8683142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"title\":\"Seeing through Sounds: Predicting Visual Semantic Segmentation Results from Multichannel Audio Signals\",\"url\":\"https://www.semanticscholar.org/paper/36170dadea3e9cdb5b3b422eb0264633e6fd1742\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.14168\",\"authors\":[{\"authorId\":\"51215062\",\"name\":\"Yuanbo Hou\"},{\"authorId\":\"34061637\",\"name\":\"Y. Deng\"},{\"authorId\":\"1842814\",\"name\":\"Bilei Zhu\"},{\"authorId\":\"2919563\",\"name\":\"Zejun Ma\"},{\"authorId\":\"2985587\",\"name\":\"D. Botteldooren\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49f02f3180ea3b0c38c3d78cd1874fd61ce160a7\",\"title\":\"Rule-embedded network for audio-visual voice activity detection in live musical video streams\",\"url\":\"https://www.semanticscholar.org/paper/49f02f3180ea3b0c38c3d78cd1874fd61ce160a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.11264\",\"authors\":[{\"authorId\":\"2957796\",\"name\":\"Wei-Ning Hsu\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2275ab31b4ea01ac6ac3a07855747213d1ed7d0f\",\"title\":\"Disentangling by Partitioning: A Representation Learning Framework for Multimodal Sensory Data\",\"url\":\"https://www.semanticscholar.org/paper/2275ab31b4ea01ac6ac3a07855747213d1ed7d0f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72500859\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yan Yan\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"}],\"doi\":\"10.1109/ICCV.2019.00639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c2b97b0e02d0b7e02fe4303a6c1894e13b27335\",\"title\":\"Dual Attention Matching for Audio-Visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6c2b97b0e02d0b7e02fe4303a6c1894e13b27335\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.07011\",\"authors\":[{\"authorId\":\"144810140\",\"name\":\"J. H. Christensen\"},{\"authorId\":\"3013806\",\"name\":\"Sascha Hornauer\"},{\"authorId\":\"2251428\",\"name\":\"S. Yu\"}],\"doi\":\"10.1109/ICRA40945.2020.9196934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d041600fa596a7d63c633cd976f01b16587fbdb1\",\"title\":\"BatVision: Learning to See 3D Spatial Layout with Two Ears\",\"url\":\"https://www.semanticscholar.org/paper/d041600fa596a7d63c633cd976f01b16587fbdb1\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2011.08612\",\"authors\":[{\"authorId\":\"1519070643\",\"name\":\"Jing Zhang\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/jiot.2020.3039359\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3e3df220673388402b6b114eab68a9c5396210b1\",\"title\":\"Empowering Things with Intelligence: A Survey of the Progress, Challenges, and Opportunities in Artificial Intelligence of Things\",\"url\":\"https://www.semanticscholar.org/paper/3e3df220673388402b6b114eab68a9c5396210b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.10997\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"50487517\",\"name\":\"Xudong Xu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2019.00037\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"title\":\"Vision-Infused Deep Audio Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/82feef7ae3b3d5ea16ce8bfdf9a01d9aadb4b7be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50131290\",\"name\":\"M. Yasuda\"},{\"authorId\":\"2991962\",\"name\":\"Y. Ohishi\"},{\"authorId\":\"67318326\",\"name\":\"Y. Koizumi\"},{\"authorId\":\"145752315\",\"name\":\"N. Harada\"}],\"doi\":\"10.21437/interspeech.2020-2445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81da4385a561b48763d140be8bbb30212bbd467d\",\"title\":\"Crossmodal Sound Retrieval Based on Specific Target Co-Occurrence Denoted with Weak Labels\",\"url\":\"https://www.semanticscholar.org/paper/81da4385a561b48763d140be8bbb30212bbd467d\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"1799463962\",\"name\":\"Feng Wang\"},{\"authorId\":\"1846273678\",\"name\":\"Di Guo\"},{\"authorId\":\"153201597\",\"name\":\"Xinzhu Liu\"},{\"authorId\":\"50812963\",\"name\":\"Xinyu Zhang\"},{\"authorId\":\"2323566\",\"name\":\"Fu-Chun Sun\"}],\"doi\":\"10.1109/TII.2020.3000240\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2e481fdf58e542dbd12d55915379a30c5a02c1b\",\"title\":\"Active Object Discovery and Localization Using Sound-Induced Attention\",\"url\":\"https://www.semanticscholar.org/paper/a2e481fdf58e542dbd12d55915379a30c5a02c1b\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"title\":\"Audio-Visual Embodied Navigation\",\"url\":\"https://www.semanticscholar.org/paper/6090aa8ef7989101e3f18c44a84e3f5a80e905a5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.09622\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"47927907\",\"name\":\"S. Majumder\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3ff7cc35932c5d0ec38f0a8d0a492dc6fede963\",\"title\":\"Learning to Set Waypoints for Audio-Visual Navigation.\",\"url\":\"https://www.semanticscholar.org/paper/e3ff7cc35932c5d0ec38f0a8d0a492dc6fede963\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.05722\",\"authors\":[{\"authorId\":\"31836044\",\"name\":\"Takashi Oya\"},{\"authorId\":\"34279376\",\"name\":\"Shohei Iwase\"},{\"authorId\":\"41015901\",\"name\":\"R. Natsume\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"3117231\",\"name\":\"Shugo Yamaguchi\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"476d71a4cfd1529c4705636041add568853d74b1\",\"title\":\"Do We Need Sound for Sound Source Localization?\",\"url\":\"https://www.semanticscholar.org/paper/476d71a4cfd1529c4705636041add568853d74b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09622\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"47927907\",\"name\":\"S. Majumder\"},{\"authorId\":\"9187007\",\"name\":\"Z. Al-Halah\"},{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"102d3e153bb402a8533af2ee03cb0ba536d09f2f\",\"title\":\"Audio-Visual Waypoints for Navigation\",\"url\":\"https://www.semanticscholar.org/paper/102d3e153bb402a8533af2ee03cb0ba536d09f2f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.04204\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"title\":\"2.5D Visual Sound\",\"url\":\"https://www.semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.14326\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"9299637\",\"name\":\"Hong-Goo Kang\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"}],\"doi\":\"10.21437/Interspeech.2020-1113\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6ec232e30ae03c1f97981fb00c84195f9f9bff3\",\"title\":\"Seeing voices and hearing voices: learning discriminative embeddings using cross-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/d6ec232e30ae03c1f97981fb00c84195f9f9bff3\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2011.01819\",\"authors\":[{\"authorId\":\"143698653\",\"name\":\"P. Morgado\"},{\"authorId\":\"3184077\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"title\":\"Learning Representations from Audio-Visual Spatial Alignment\",\"url\":\"https://www.semanticscholar.org/paper/eeb33ad2ede9944918724978bcbfb08b4c8c50a8\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1912.11474\",\"authors\":[{\"authorId\":\"153246625\",\"name\":\"Chang\\u2019an Chen\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2368282\",\"name\":\"Carl Schissler\"},{\"authorId\":\"80532894\",\"name\":\"S. V. A. Gar\\u00ed\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"2736958\",\"name\":\"Vamsi K. Ithapu\"},{\"authorId\":\"153812886\",\"name\":\"P. Robinson\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-030-58539-6_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c47ef056ac57e83405f9ee63c32c6a185011d187\",\"title\":\"SoundSpaces: Audio-Visual Navigation in 3D Environments\",\"url\":\"https://www.semanticscholar.org/paper/c47ef056ac57e83405f9ee63c32c6a185011d187\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2326243\",\"name\":\"Arun Balajee Vasudevan\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.3929/ETHZ-B-000431943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4867095c19f6c5827943cc74335b370d4bfcab29\",\"title\":\"Semantic Object Prediction and Spatial Sound Super-Resolution with Binaural Sounds\",\"url\":\"https://www.semanticscholar.org/paper/4867095c19f6c5827943cc74335b370d4bfcab29\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":\"1910.08732\",\"authors\":[{\"authorId\":\"50811450\",\"name\":\"Kranti K. Parida\"},{\"authorId\":\"31352334\",\"name\":\"Neeraj Matiyali\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV45572.2020.9093438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a243ee80146ca37fc296bc67043ea2a67222de68\",\"title\":\"Coordinated Joint Multimodal Embeddings for Generalized Audio-Visual Zero-shot Classification and Retrieval of Videos\",\"url\":\"https://www.semanticscholar.org/paper/a243ee80146ca37fc296bc67043ea2a67222de68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16149902\",\"name\":\"Janani Ramaswamy\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/WACV45572.2020.9093616\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c911d81bddb48490a02258e79379b6428246ddc2\",\"title\":\"See the Sound, Hear the Pixels\",\"url\":\"https://www.semanticscholar.org/paper/c911d81bddb48490a02258e79379b6428246ddc2\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.09773\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1109/CVPR.2019.00772\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"title\":\"Speech2Face: Learning the Face Behind a Voice\",\"url\":\"https://www.semanticscholar.org/paper/e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.12867\",\"authors\":[{\"authorId\":\"66066175\",\"name\":\"D. U. Jo\"},{\"authorId\":\"3206837\",\"name\":\"Byeongju Lee\"},{\"authorId\":\"47819455\",\"name\":\"J. Choi\"},{\"authorId\":\"47111186\",\"name\":\"H. Yoo\"},{\"authorId\":\"46174575\",\"name\":\"J. Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3591a27e24c3197512331d8a8cc2f481b36d58fa\",\"title\":\"Cross-modal Variational Auto-encoder with Distributed Latent Spaces and Associators\",\"url\":\"https://www.semanticscholar.org/paper/3591a27e24c3197512331d8a8cc2f481b36d58fa\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.13662\",\"authors\":[{\"authorId\":\"47792365\",\"name\":\"Y. Asano\"},{\"authorId\":null,\"name\":\"Mandela Patrick\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"title\":\"Labelling unlabelled videos from scratch with multi-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/008ba3c574f8e5085dfb1eef0342e8b408565e45\",\"venue\":\"NeurIPS\",\"year\":2020}],\"corpusId\":3841418,\"doi\":\"10.1109/CVPR.2018.00458\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"references\":[{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723344\",\"name\":\"M. Corbetta\"},{\"authorId\":\"39269549\",\"name\":\"G. Shulman\"}],\"doi\":\"10.1038/nrn755\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"53e66b6934516a9859573f4866f81f04bce977ae\",\"title\":\"Control of goal-directed and stimulus-driven attention in the brain\",\"url\":\"https://www.semanticscholar.org/paper/53e66b6934516a9859573f4866f81f04bce977ae\",\"venue\":\"Nature Reviews Neuroscience\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005106\",\"name\":\"P. Majdak\"},{\"authorId\":\"5038090\",\"name\":\"M. Goupell\"},{\"authorId\":\"2219986\",\"name\":\"B. Laback\"}],\"doi\":\"10.3758/APP.72.2.454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c338d7182ed86d56366ae425c131c034dd067a2\",\"title\":\"3-D localization of virtual sound sources: Effects of visual environment, pointing method, and training\",\"url\":\"https://www.semanticscholar.org/paper/4c338d7182ed86d56366ae425c131c034dd067a2\",\"venue\":\"Attention, perception & psychophysics\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2621946\",\"name\":\"B. Schrauwen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeff60867041d2ea92d1b38a20c2031d240d8872\",\"title\":\"Deep content-based music recommendation\",\"url\":\"https://www.semanticscholar.org/paper/eeff60867041d2ea92d1b38a20c2031d240d8872\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389955537\",\"name\":\"S. Shalev-Shwartz\"},{\"authorId\":\"1401829700\",\"name\":\"Shai Ben-David\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ce615ae61d67db8537e981a0a08da7f0f2ff1cee\",\"title\":\"Understanding Machine Learning - From Theory to Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/ce615ae61d67db8537e981a0a08da7f0f2ff1cee\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1706.00932\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"title\":\"See, Hear, and Read: Deep Aligned Representations\",\"url\":\"https://www.semanticscholar.org/paper/52ed3b634c302af93ee2e70b7c28e4b2128a5947\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1505.02206\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2015.166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c426ba865e9158a0f7962a86a50575aa943051b1\",\"title\":\"Learning Image Representations Tied to Ego-Motion\",\"url\":\"https://www.semanticscholar.org/paper/c426ba865e9158a0f7962a86a50575aa943051b1\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2211891\",\"name\":\"Einat Kidron\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"},{\"authorId\":\"1753908\",\"name\":\"Michael Elad\"}],\"doi\":\"10.1109/CVPR.2005.274\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"title\":\"Pixels that sound\",\"url\":\"https://www.semanticscholar.org/paper/91bfc3de8bfa6b9e7ccd685f53db8304a0c114ad\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6622\",\"authors\":[{\"authorId\":\"40555034\",\"name\":\"E. Hoffer\"},{\"authorId\":\"2048494\",\"name\":\"Nir Ailon\"}],\"doi\":\"10.1007/978-3-319-24261-3_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca\",\"title\":\"Deep Metric Learning Using Triplet Network\",\"url\":\"https://www.semanticscholar.org/paper/3ac1a7d6630cd1c7b70c4c2c7bc92c40df1162ca\",\"venue\":\"SIMBAD\",\"year\":2015},{\"arxivId\":\"1503.01817\",\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"118220290\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/2812802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"title\":\"YFCC100M: the new data in multimedia research\",\"url\":\"https://www.semanticscholar.org/paper/354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3169673\",\"name\":\"B. Jones\"},{\"authorId\":\"70510642\",\"name\":\"B. Kabanoff\"}],\"doi\":\"10.3758/BF03203206\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51578811cfbe69772a16bd721dd9d34f1a390b10\",\"title\":\"Eye movements in auditory space perception\",\"url\":\"https://www.semanticscholar.org/paper/51578811cfbe69772a16bd721dd9d34f1a390b10\",\"venue\":\"\",\"year\":1975},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744069\",\"name\":\"Zohar Barzelay\"},{\"authorId\":\"2159538\",\"name\":\"Y. Schechner\"}],\"doi\":\"10.1109/CVPR.2007.383344\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e309dfbae9d123f85223d398d4a400abee3ef393\",\"title\":\"Harmony in Motion\",\"url\":\"https://www.semanticscholar.org/paper/e309dfbae9d123f85223d398d4a400abee3ef393\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113469609\",\"name\":\"B. Skinner\"}],\"doi\":\"10.1037/h0055873\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1412a5dbf3d4d5436cd4c2abcf22809f64aa62ff\",\"title\":\"Superstition in the pigeon.\",\"url\":\"https://www.semanticscholar.org/paper/1412a5dbf3d4d5436cd4c2abcf22809f64aa62ff\",\"venue\":\"Journal of experimental psychology\",\"year\":1948},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3204741\",\"name\":\"R. Bolia\"},{\"authorId\":\"1398436929\",\"name\":\"W. D'Angelo\"},{\"authorId\":\"145374724\",\"name\":\"L. Richard\"}],\"doi\":\"10.1518/001872099779656789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2110b77dc3699580afe2d313b32783d4326a927\",\"title\":\"Aurally Aided Visual Search in Three-Dimensional Space\",\"url\":\"https://www.semanticscholar.org/paper/b2110b77dc3699580afe2d313b32783d4326a927\",\"venue\":\"Hum. Factors\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152823345\",\"name\":\"M. Sol\\u00e8r\"},{\"authorId\":\"31798873\",\"name\":\"J. Bazin\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"153243248\",\"name\":\"A. Krause\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1007/978-3-319-48881-3_59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"title\":\"Suggesting Sounds for Images from Video Collections\",\"url\":\"https://www.semanticscholar.org/paper/333aa36e80f1a7fa29cf069d81d4d2e12679bc67\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2992579\",\"name\":\"Hamid Izadinia\"},{\"authorId\":\"2658133\",\"name\":\"Imran Saleemi\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/TMM.2012.2228476\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3118de593eee760242be45ceac0ae77d0831d31\",\"title\":\"Multimodal Analysis for Identification and Segmentation of Moving-Sounding Objects\",\"url\":\"https://www.semanticscholar.org/paper/e3118de593eee760242be45ceac0ae77d0831d31\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2110979\",\"name\":\"H. V. Trees\"}],\"doi\":\"10.1002/0471221104\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a392bdd3cc161c27d6e2cc9f3a7ec351364103c9\",\"title\":\"Optimum Array Processing: Part IV of Detection, Estimation, and Modulation Theory\",\"url\":\"https://www.semanticscholar.org/paper/a392bdd3cc161c27d6e2cc9f3a7ec351364103c9\",\"venue\":\"\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37280034\",\"name\":\"B. R. Shelton\"},{\"authorId\":\"32780728\",\"name\":\"C. L. Searle\"}],\"doi\":\"10.3758/BF03198830\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"658393ebb59374e74179600e6bd1b81c7e9233fa\",\"title\":\"The influence of vision on the absolute identification of sound-source position\",\"url\":\"https://www.semanticscholar.org/paper/658393ebb59374e74179600e6bd1b81c7e9233fa\",\"venue\":\"Perception & psychophysics\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144733334\",\"name\":\"A. Zunino\"},{\"authorId\":\"1742319\",\"name\":\"M. Crocco\"},{\"authorId\":\"2157339\",\"name\":\"Samuele Martelli\"},{\"authorId\":\"1700022\",\"name\":\"A. Trucco\"},{\"authorId\":\"8955013\",\"name\":\"A. D. Bue\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/ICCVW.2015.95\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"760240945de3fa26c7651b601440ca8749c1b916\",\"title\":\"Seeing the Sound: A New Multimodal Imaging Device for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/760240945de3fa26c7651b601440ca8749c1b916\",\"venue\":\"2015 IEEE International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1940016\",\"name\":\"D. Perrott\"},{\"authorId\":\"46768562\",\"name\":\"J. Cisneros\"},{\"authorId\":\"14203889\",\"name\":\"R. McKinley\"},{\"authorId\":\"1398436929\",\"name\":\"W. D'Angelo\"}],\"doi\":\"10.1518/001872096778827260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"197667c822d665da86ff8d9d63b90539247d9bf0\",\"title\":\"Aurally Aided Visual Search under Virtual and Free-Field Listening Conditions\",\"url\":\"https://www.semanticscholar.org/paper/197667c822d665da86ff8d9d63b90539247d9bf0\",\"venue\":\"Hum. Factors\",\"year\":1996},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31496901\",\"name\":\"John W. Fisher III\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"1731948\",\"name\":\"P. Viola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15674778d14d7f2bf90c323924e8153d5f10fb60\",\"title\":\"Learning Joint Statistical Models for Audio-Visual Fusion and Segregation\",\"url\":\"https://www.semanticscholar.org/paper/15674778d14d7f2bf90c323924e8153d5f10fb60\",\"venue\":\"NIPS\",\"year\":2000},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2487205\",\"name\":\"William W. Gaver\"}],\"doi\":\"10.1207/S15326969ECO0501_1\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0a36667de28f912ba999fe92ae718284012a67be\",\"title\":\"What in the World Do We Hear? An Ecological Approach to Auditory Event Perception\",\"url\":\"https://www.semanticscholar.org/paper/0a36667de28f912ba999fe92ae718284012a67be\",\"venue\":\"\",\"year\":1993},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2387467\",\"name\":\"J. Hershey\"},{\"authorId\":\"1741200\",\"name\":\"J. Movellan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00d1bb817691bb0566bc55fde01d12339625aa1c\",\"title\":\"Audio Vision: Using Audio-Visual Synchrony to Locate Sounds\",\"url\":\"https://www.semanticscholar.org/paper/00d1bb817691bb0566bc55fde01d12339625aa1c\",\"venue\":\"NIPS\",\"year\":1999}],\"title\":\"Learning to Localize Sound Source in Visual Scenes\",\"topics\":[{\"topic\":\"Covox Speech Thing\",\"topicId\":\"181613\",\"url\":\"https://www.semanticscholar.org/topic/181613\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Semi-supervised learning\",\"topicId\":\"254497\",\"url\":\"https://www.semanticscholar.org/topic/254497\"},{\"topic\":\"Semiconductor industry\",\"topicId\":\"76540\",\"url\":\"https://www.semanticscholar.org/topic/76540\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Performance Evaluation\",\"topicId\":\"91975\",\"url\":\"https://www.semanticscholar.org/topic/91975\"},{\"topic\":\"Supervised learning\",\"topicId\":\"8357\",\"url\":\"https://www.semanticscholar.org/topic/8357\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"}],\"url\":\"https://www.semanticscholar.org/paper/b91d738cd1f5d550c5b27f328e55308a0a73b2d2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"