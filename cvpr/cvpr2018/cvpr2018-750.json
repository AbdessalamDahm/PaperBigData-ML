"{\"abstract\":\"Textual-visual cross-modal retrieval has been a hot research topic in both computer vision and natural language processing communities. Learning appropriate representations for multi-modal data is crucial for the cross-modal retrieval performance. Unlike existing image-text retrieval approaches that embed image-text pairs as single feature vectors in a common representational space, we propose to incorporate generative processes into the cross-modal feature embedding, through which we are able to learn not only the global abstract features but also the local grounded features. Extensive experiments show that our framework can well match images and sentences with complex content, and achieve the state-of-the-art cross-modal retrieval results on MSCOCO dataset.\",\"arxivId\":\"1711.06420\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\",\"url\":\"https://www.semanticscholar.org/author/2174964\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\",\"url\":\"https://www.semanticscholar.org/author/1688642\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\",\"url\":\"https://www.semanticscholar.org/author/2708940\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\",\"url\":\"https://www.semanticscholar.org/author/39298199\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\",\"url\":\"https://www.semanticscholar.org/author/2096527\"}],\"citationVelocity\":46,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471463062\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1522102572\",\"name\":\"Zhen Lei\"},{\"authorId\":\"1415720379\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"title\":\"Context-Aware Attention Network for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7314814\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1435766877\",\"name\":\"Gu Xiao-peng\"}],\"doi\":\"10.1145/3362065\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d39fb70393e9a17e5556708852829743380eeed\",\"title\":\"ACMNet: Adaptive Confidence Matching Network for Human Behavior Analysis via Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0d39fb70393e9a17e5556708852829743380eeed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.02354\",\"authors\":[{\"authorId\":\"48598633\",\"name\":\"Zhenguo Yang\"},{\"authorId\":\"26316172\",\"name\":\"Zehang Lin\"},{\"authorId\":\"48201256\",\"name\":\"Min Cheng\"},{\"authorId\":\"145726530\",\"name\":\"Q. Li\"},{\"authorId\":\"1746818\",\"name\":\"W. Liu\"}],\"doi\":\"10.1016/j.ipm.2020.102315\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3be8dc17105e296f871fc269a33c1bc1e18697a7\",\"title\":\"MMED: A Multi-domain and Multi-modality Event Dataset\",\"url\":\"https://www.semanticscholar.org/paper/3be8dc17105e296f871fc269a33c1bc1e18697a7\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"3493789\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1007/978-3-030-31726-3_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fd9462b383033ac1e32964d9219a8636d98be18\",\"title\":\"Deep Voice-Visual Cross-Modal Retrieval with Deep Feature Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/6fd9462b383033ac1e32964d9219a8636d98be18\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"title\":\"Engaging Image Chat: Modeling Personality in Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.05669\",\"authors\":[{\"authorId\":\"1490860633\",\"name\":\"Shuoyao Wang\"},{\"authorId\":\"152867073\",\"name\":\"Diwei Zhu\"}],\"doi\":\"10.24963/ijcai.2020/637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"590da60c5ee04448f4c154f56de59c6ba7ed0e8c\",\"title\":\"Interpretable Multimodal Learning for Intelligent Regulation in Online Payment Systems\",\"url\":\"https://www.semanticscholar.org/paper/590da60c5ee04448f4c154f56de59c6ba7ed0e8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.00945\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"title\":\"Image-Chat: Engaging Grounded Conversations\",\"url\":\"https://www.semanticscholar.org/paper/b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"},{\"authorId\":\"46669153\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054758\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"517efc27e303d408e36bad4d376884ae87fbbf93\",\"title\":\"Exploring Entity-Level Spatial Relationships for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/517efc27e303d408e36bad4d376884ae87fbbf93\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1109/DSAA.2019.00029\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"title\":\"Cross-Media Image-Text Retrieval Combined with Global Similarity and Local Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"venue\":\"2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"},{\"authorId\":\"36061091\",\"name\":\"Jingze Chi\"}],\"doi\":\"10.1109/TCSVT.2019.2953692\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6554f92a57688658c0f3a5cfd7963310e77537d7\",\"title\":\"Unsupervised Cross-Media Retrieval Using Domain Adaptation With Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/6554f92a57688658c0f3a5cfd7963310e77537d7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1909.02701\",\"authors\":[{\"authorId\":\"49243413\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"47003439\",\"name\":\"Yuanyuan Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/ICCV.2019.00475\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"title\":\"Visual Semantic Reasoning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152366931\",\"name\":\"Lei Zhu\"},{\"authorId\":\"153583278\",\"name\":\"Jiayu Song\"},{\"authorId\":\"3351330\",\"name\":\"X. Wei\"},{\"authorId\":\"37629830\",\"name\":\"H. Yu\"},{\"authorId\":\"1390782640\",\"name\":\"Jun Long\"}],\"doi\":\"10.1007/s11042-020-09983-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224aea37455d3d981c7a6f66e1b3f74439a994c7\",\"title\":\"CAESAR: concept augmentation based semantic representation for cross-modal retrieval\",\"url\":\"https://www.semanticscholar.org/paper/224aea37455d3d981c7a6f66e1b3f74439a994c7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3323873.3325043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"title\":\"Improving What Cross-Modal Retrieval Models Learn through Object-Oriented Inter- and Intra-Modal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144560801\",\"name\":\"Wenzhong Guo\"},{\"authorId\":\"120465682\",\"name\":\"J. Wang\"},{\"authorId\":\"49183986\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2916887\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff\",\"title\":\"Deep Multimodal Representation Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999410\",\"name\":\"Zhibin Hu\"},{\"authorId\":\"40132308\",\"name\":\"Yongsheng Luo\"},{\"authorId\":\"46698321\",\"name\":\"Jiong Lin\"},{\"authorId\":\"144761066\",\"name\":\"Yan Yan\"},{\"authorId\":\"5869774\",\"name\":\"J. Chen\"}],\"doi\":\"10.24963/ijcai.2019/111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10012e6a7a0ad10391533326b95bd1291df6f199\",\"title\":\"Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/10012e6a7a0ad10391533326b95bd1291df6f199\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1906.04402\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/CVPR.2019.00208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a39d5919531a56de0e36f6b76142041b5d508213\",\"title\":\"Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1016/j.patcog.2020.107359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"title\":\"Stacked squeeze-and-excitation recurrent residual network for visual-semantic matching\",\"url\":\"https://www.semanticscholar.org/paper/124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461528\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"46458102\",\"name\":\"L. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"title\":\"CycleMatch: A cycle-consistent embedding network for image-text matching\",\"url\":\"https://www.semanticscholar.org/paper/d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152366931\",\"name\":\"Lei Zhu\"},{\"authorId\":\"153583278\",\"name\":\"Jiayu Song\"},{\"authorId\":\"1621039417\",\"name\":\"Xiaofeng Zhu\"},{\"authorId\":\"39978786\",\"name\":\"C. Zhang\"},{\"authorId\":\"48692027\",\"name\":\"Shichao Zhang\"},{\"authorId\":\"72730384\",\"name\":\"Xinpan Yuan\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.20944/preprints202001.0288.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c635a8e009feb9cb099b0822c07eb67f75924edf\",\"title\":\"Adversarial Learning Based Semantic Correlation Representation for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c635a8e009feb9cb099b0822c07eb67f75924edf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143941721\",\"name\":\"Peng Hu\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144152343\",\"name\":\"Xi Peng\"},{\"authorId\":\"66190968\",\"name\":\"Jie Lin\"}],\"doi\":\"10.1609/AAAI.V34I01.5339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9deffcf068af083f1eb1bf064d7c09d7df5178ef\",\"title\":\"Semi-Supervised Multi-Modal Learning with Balanced Spectral Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/9deffcf068af083f1eb1bf064d7c09d7df5178ef\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2001.05876\",\"authors\":[{\"authorId\":\"46659203\",\"name\":\"L. Wang\"},{\"authorId\":\"1486057423\",\"name\":\"Zechen Bai\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1609/aaai.v34i07.6898\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85079d64d6fdd0ba5318fda119d152f2d2946391\",\"title\":\"Show, Recall, and Tell: Image Captioning with Recall Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/85079d64d6fdd0ba5318fda119d152f2d2946391\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.03403\",\"authors\":[{\"authorId\":\"1490652152\",\"name\":\"Jiwei Wei\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1524912498\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":null,\"name\":\"Zheng Wang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/CVPR42600.2020.01302\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd860c3f8a195d06f64ecf36ef6a78397eb883bd\",\"title\":\"Universal Weighting Metric Learning for Cross-Modal Matching\",\"url\":\"https://www.semanticscholar.org/paper/dd860c3f8a195d06f64ecf36ef6a78397eb883bd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1906.06892\",\"authors\":[{\"authorId\":\"49289638\",\"name\":\"Yaxian Xia\"},{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"},{\"authorId\":\"40445654\",\"name\":\"Jie Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80a56c659dd1ab8675f01560ac5757a7f872ffa2\",\"title\":\"ParNet: Position-aware Aggregated Relation Network for Image-Text matching\",\"url\":\"https://www.semanticscholar.org/paper/80a56c659dd1ab8675f01560ac5757a7f872ffa2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"title\":\"ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2004.09144\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8185538174d9f751125407cad3687994ff08fadb\",\"title\":\"Transformer Reasoning Network for Image-Text Matching and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8185538174d9f751125407cad3687994ff08fadb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Asi Sheffer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"99de392582d3bd6d1e55cdafcd362ef8d57575d9\",\"title\":\"Natural Language Object Retrieval with Cross Domain Normalization\",\"url\":\"https://www.semanticscholar.org/paper/99de392582d3bd6d1e55cdafcd362ef8d57575d9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145281166\",\"name\":\"G. Song\"},{\"authorId\":\"2248421\",\"name\":\"Xiaoyang Tan\"}],\"doi\":\"10.1109/ICCVW.2019.00554\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95016f65fdc03d2dc976588a5a1230abfa0efd5b\",\"title\":\"Sequential Learning for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/95016f65fdc03d2dc976588a5a1230abfa0efd5b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"145093507\",\"name\":\"Yao Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3300939\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70e80065c4db089c3792245535ecacdca3770577\",\"title\":\"Modality-Invariant Image-Text Embedding for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/70e80065c4db089c3792245535ecacdca3770577\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1908.10534\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"93809632\",\"name\":\"Xiang Xu\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCV.2019.00591\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"title\":\"Adversarial Representation Learning for Text-to-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.11416\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3343031.3350869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d149507610400ddc2f2b29d9a39f7688b613039\",\"title\":\"Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2d149507610400ddc2f2b29d9a39f7688b613039\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.00560\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2059515\",\"name\":\"Mingyang Ling\"}],\"doi\":\"10.1109/CVPR.2019.00207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"740db108d536a8b6f53111407898f4ecaecf80ea\",\"title\":\"Scene Graph Generation With External Knowledge and Image Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/740db108d536a8b6f53111407898f4ecaecf80ea\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143751553\",\"name\":\"B. Zhu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40663515\",\"name\":\"J. Chen\"},{\"authorId\":\"48387349\",\"name\":\"Yanbin Hao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c32c5eb31c1c02651618b9a12610e0d6b8dcc82\",\"title\":\"R 2 GAN : Cross-modal Recipe Retrieval with Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/3c32c5eb31c1c02651618b9a12610e0d6b8dcc82\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"46764518\",\"name\":\"Zhendong Niu\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.24963/ijcai.2019/720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad748d1772f893b3c8a3857a19292375be259daf\",\"title\":\"Knowledge Aware Semantic Concept Expansion for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/ad748d1772f893b3c8a3857a19292375be259daf\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429704\",\"name\":\"D. Zhang\"},{\"authorId\":\"46721598\",\"name\":\"Bo Ni\"},{\"authorId\":\"40552330\",\"name\":\"Qiyu Zhi\"},{\"authorId\":\"34780317\",\"name\":\"T. Plummer\"},{\"authorId\":\"144836952\",\"name\":\"Q. Li\"},{\"authorId\":\"152514378\",\"name\":\"Hao Zheng\"},{\"authorId\":\"1694209\",\"name\":\"Qingkai Zeng\"},{\"authorId\":\"49890108\",\"name\":\"Y. Zhang\"},{\"authorId\":\"46314882\",\"name\":\"Dong Wang\"}],\"doi\":\"10.1145/3341161.3342885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1535fbc22dbe34edb1078e0447f5d664c26878df\",\"title\":\"Through The Eyes of A Poet: Classical Poetry Recommendation with Visual Input on Social Media\",\"url\":\"https://www.semanticscholar.org/paper/1535fbc22dbe34edb1078e0447f5d664c26878df\",\"venue\":\"2019 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM)\",\"year\":2019},{\"arxivId\":\"1903.10658\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICCV.2019.01042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"title\":\"Unpaired Image Captioning via Scene Graph Alignments\",\"url\":\"https://www.semanticscholar.org/paper/f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380008340\",\"name\":\"Wei Xiong\"},{\"authorId\":\"2013031\",\"name\":\"Y. Lv\"},{\"authorId\":\"1391223556\",\"name\":\"Xiaohan Zhang\"},{\"authorId\":\"14113358\",\"name\":\"Yaqi Cui\"}],\"doi\":\"10.1109/TGRS.2020.2968096\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7014b755c8d335b5551c59ed5b071aa9f4b53f12\",\"title\":\"Learning to Translate for Cross-Source Remote Sensing Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7014b755c8d335b5551c59ed5b071aa9f4b53f12\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47012336\",\"name\":\"Xin Fu\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"49339608\",\"name\":\"Yufeng Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/TMM.2019.2957948\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c2195652dddf015880ceacefd811a3df7cae30c\",\"title\":\"Rich Features Embedding for Cross-Modal Retrieval: A Simple Baseline\",\"url\":\"https://www.semanticscholar.org/paper/7c2195652dddf015880ceacefd811a3df7cae30c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"},{\"authorId\":\"1686820\",\"name\":\"B. M\\u00e9rialdo\"}],\"doi\":\"10.1109/CBMI.2018.8516480\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"174812bf1d4718cdf0b5432d9df290153046afe7\",\"title\":\"Embedding Images and Sentences in a Common Space with a Recurrent Capsule Network\",\"url\":\"https://www.semanticscholar.org/paper/174812bf1d4718cdf0b5432d9df290153046afe7\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":\"1904.09471\",\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/ICCV.2019.00585\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d2d1f64a11ca9234716a777dedc962586930a9\",\"title\":\"Saliency-Guided Attention Network for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/a3d2d1f64a11ca9234716a777dedc962586930a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.04272\",\"authors\":[{\"authorId\":\"35376394\",\"name\":\"Martin Engilberge\"},{\"authorId\":\"39255836\",\"name\":\"Louis Chevallier\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR.2019.01105\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23b27ae9af6ccff4faa04f18c9024fc49f57b4a2\",\"title\":\"SoDeep: A Sorting Deep Net to Learn Ranking Loss Surrogates\",\"url\":\"https://www.semanticscholar.org/paper/23b27ae9af6ccff4faa04f18c9024fc49f57b4a2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"},{\"authorId\":\"1686820\",\"name\":\"B. M\\u00e9rialdo\"}],\"doi\":\"10.1007/978-3-030-05716-9_23\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"edafa697ba68874d608015b521c43d04e3584992\",\"title\":\"Gated Recurrent Capsules for Visual Word Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/edafa697ba68874d608015b521c43d04e3584992\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":\"2006.08159\",\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9eefd969deebe48439efef3dc2cd9fa914ec4ac\",\"title\":\"Survey on Deep Multi-modal Data Analytics: Collaboration, Rivalry and Fusion\",\"url\":\"https://www.semanticscholar.org/paper/e9eefd969deebe48439efef3dc2cd9fa914ec4ac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06976\",\"authors\":[{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"},{\"authorId\":\"117992479\",\"name\":\"Cheng-Lin Liu\"},{\"authorId\":\"21266300\",\"name\":\"C. Y. Suen\"}],\"doi\":\"10.1109/JPROC.2020.2989782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a53aaf97203d3f8a89d9d8e0d39ca568c0896d4\",\"title\":\"Towards Robust Pattern Recognition: A Review\",\"url\":\"https://www.semanticscholar.org/paper/6a53aaf97203d3f8a89d9d8e0d39ca568c0896d4\",\"venue\":\"Proceedings of the IEEE\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121789307\",\"name\":\"W. Guo\"},{\"authorId\":\"143932869\",\"name\":\"Jian Liang\"},{\"authorId\":\"144496860\",\"name\":\"Xiangwei Kong\"},{\"authorId\":\"3051419\",\"name\":\"Lingxiao Song\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"}],\"doi\":\"10.1007/978-3-030-20873-8_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"19cac7075675992baefe308300be4e69a9080d2e\",\"title\":\"X-GACMN: An X-Shaped Generative Adversarial Cross-Modal Network with Hypersphere Embedding\",\"url\":\"https://www.semanticscholar.org/paper/19cac7075675992baefe308300be4e69a9080d2e\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"46911598\",\"name\":\"Lin Zuo\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2020.2967597\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"title\":\"Cross-Modal Attention With Semantic Consistence for Image\\u2013Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wenhui Li\"},{\"authorId\":null,\"name\":\"Song Yang\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":null,\"name\":\"Dan Song\"},{\"authorId\":null,\"name\":\"Xuanya Li\"}],\"doi\":\"10.1016/j.ipm.2020.102432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"title\":\"Multi-level similarity learning for image-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72445881\",\"name\":\"Xinhong Ma\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/TMM.2020.2969792\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d68c359a76b9efb3bedf85cdc915bcf49dbd55db\",\"title\":\"Multi-Level Correlation Adversarial Hashing for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d68c359a76b9efb3bedf85cdc915bcf49dbd55db\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2011.04305\",\"authors\":[{\"authorId\":\"1918424\",\"name\":\"Jiacheng Chen\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"1906061249\",\"name\":\"Changhu Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"title\":\"Learning the Best Pooling Strategy for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"2285442\",\"name\":\"M. Xu\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":\"10.1145/3383184\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"title\":\"Dual-path Convolutional Image-Text Embeddings with Instance Loss\",\"url\":\"https://www.semanticscholar.org/paper/58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2003.08027\",\"authors\":[{\"authorId\":\"39024831\",\"name\":\"Shuai Wang\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40912079\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b65ffe7ada51e34a0a8e3e46b90d71099141a8e\",\"title\":\"Mutatt: Visual-Textual Mutual Guidance For Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3b65ffe7ada51e34a0a8e3e46b90d71099141a8e\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1909.02072\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00921\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"title\":\"Large-Scale Tag-Based Font Retrieval With Generative Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"145720713\",\"name\":\"Shuai Wang\"}],\"doi\":\"10.1109/TGRS.2020.2979273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e27873bd45b8b3206127fce377c62576068963b2\",\"title\":\"Deep Cross-Modal Image\\u2013Voice Retrieval in Remote Sensing\",\"url\":\"https://www.semanticscholar.org/paper/e27873bd45b8b3206127fce377c62576068963b2\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47172737\",\"name\":\"A. Sain\"},{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86d0e140dafbf112a8884b195a335a61585ea01e\",\"title\":\"SAIN, BHUNIA, SONG: CROSS-MODAL HIERARCHICAL MODELLING FOR FG-SBIR 1 Cross-Modal Hierarchical Modelling for Fine-Grained Sketch Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/86d0e140dafbf112a8884b195a335a61585ea01e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.13339\",\"authors\":[{\"authorId\":\"30141435\",\"name\":\"Pranav Aggarwal\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"133701193\",\"name\":\"Baldo Faieta\"},{\"authorId\":\"2897426\",\"name\":\"Saeid Motiian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb5da53c969f4e94b58f3ebbfab177e4e625564\",\"title\":\"Multitask Text-to-Visual Embedding with Titles and Clickthrough Data\",\"url\":\"https://www.semanticscholar.org/paper/9fb5da53c969f4e94b58f3ebbfab177e4e625564\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"46389488\",\"name\":\"H. Ma\"}],\"doi\":\"10.1109/ACCESS.2020.2969808\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"title\":\"Combining Global and Local Similarity for Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1380065125\",\"name\":\"Narges Honarvar Nazari\"},{\"authorId\":\"90323489\",\"name\":\"J. Hahn\"},{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/tpami.2019.2947440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86df22f8dbec3489432063ef569a4793dc232c70\",\"title\":\"Interpreting the Rhetoric of Visual Advertisements.\",\"url\":\"https://www.semanticscholar.org/paper/86df22f8dbec3489432063ef569a4793dc232c70\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"2010.15075\",\"authors\":[{\"authorId\":\"11016722\",\"name\":\"Noushin Hajarolasvadi\"},{\"authorId\":\"32286131\",\"name\":\"M. Ram\\u00edrez\"},{\"authorId\":\"40986317\",\"name\":\"Wesley Beccaro\"},{\"authorId\":\"2128977\",\"name\":\"H. Demirel\"}],\"doi\":\"10.1109/ACCESS.2020.3042328\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5122bc767bcbdde57761c64973c72e945ba7bd22\",\"title\":\"Generative Adversarial Networks in Human Emotion Synthesis: A Review\",\"url\":\"https://www.semanticscholar.org/paper/5122bc767bcbdde57761c64973c72e945ba7bd22\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123959265\",\"name\":\"Qian-Fang Zou\"},{\"authorId\":\"1724542\",\"name\":\"Ligang Liu\"},{\"authorId\":\"1704131\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/s00371-020-01935-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"293e3bf9f8cd49b67662fd7ad92a6e187ac05c4b\",\"title\":\"Instance-level 3D shape retrieval from a single image by hybrid-representation-assisted joint embedding\",\"url\":\"https://www.semanticscholar.org/paper/293e3bf9f8cd49b67662fd7ad92a6e187ac05c4b\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500406374\",\"name\":\"Shaily Malik\"},{\"authorId\":\"33044192\",\"name\":\"P. Bansal\"}],\"doi\":\"10.1007/978-981-15-5148-2_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cad3386d53bd717052503fe9d394795b927fff6c\",\"title\":\"Semantic Space Autoencoder for Cross-Modal Data Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/cad3386d53bd717052503fe9d394795b927fff6c\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1903.02149\",\"authors\":[{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"40585259\",\"name\":\"L. Wang\"},{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"}],\"doi\":\"10.1609/AAAI.V33I01.3301176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"806ba6c5340b66ce7d5150d82b2b094ef32dc734\",\"title\":\"Coupled CycleGAN: Unsupervised Hashing Network for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/806ba6c5340b66ce7d5150d82b2b094ef32dc734\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"145987795\",\"name\":\"M. A. Lopes\"},{\"authorId\":\"145877010\",\"name\":\"Douglas M. Souza\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/ICCV.2019.00590\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84010f883e9a7283666a6628226016ca4f8d28f1\",\"title\":\"Language-Agnostic Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/84010f883e9a7283666a6628226016ca4f8d28f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41017837\",\"name\":\"Zhuobin Zheng\"},{\"authorId\":\"80414744\",\"name\":\"Youcheng Ben\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"title\":\"Multi-Scale Visual Semantics Aggregation with Self-Attention for End-to-End Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"venue\":\"ACML\",\"year\":2019},{\"arxivId\":\"2002.10016\",\"authors\":[{\"authorId\":\"52200777\",\"name\":\"Hadi Abdi Khojasteh\"},{\"authorId\":\"31459942\",\"name\":\"Ebrahim Ansari\"},{\"authorId\":\"2671497\",\"name\":\"Parvin Razzaghi\"},{\"authorId\":\"2369481\",\"name\":\"Akbar Karimi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61ee052718bdeae8ab352359bf2828bf7b2b0e45\",\"title\":\"Deep Multimodal Image-Text Embeddings for Automatic Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/61ee052718bdeae8ab352359bf2828bf7b2b0e45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14700\",\"authors\":[{\"authorId\":\"7748443\",\"name\":\"Sangwoong Yoon\"},{\"authorId\":\"21152168\",\"name\":\"Woo Young Kang\"},{\"authorId\":\"97519074\",\"name\":\"Sungwook Jeon\"},{\"authorId\":\"50112156\",\"name\":\"Seong-Eun Lee\"},{\"authorId\":\"118727697\",\"name\":\"Changjin Han\"},{\"authorId\":\"30664924\",\"name\":\"Jonghun Park\"},{\"authorId\":\"1845794808\",\"name\":\"Eun-Sol Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e0570df4e56d51be58b53166e853d848ef767af\",\"title\":\"Image-to-Image Retrieval by Learning Similarity between Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/2e0570df4e56d51be58b53166e853d848ef767af\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15281603\",\"name\":\"Zerui Chen\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2019.8802975\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"title\":\"Augmented Visual-Semantic Embeddings for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1911.05978\",\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"},{\"authorId\":\"1406355360\",\"name\":\"Aniket Pednekar\"},{\"authorId\":\"1406355394\",\"name\":\"A. Krishnamoorthy\"},{\"authorId\":\"113477341\",\"name\":\"Kazoo Sone\"},{\"authorId\":\"40632403\",\"name\":\"S. Basu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ea46e70da5e0882ac6e08afd8a9f6285abfb12a\",\"title\":\"HUSE: Hierarchical Universal Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/0ea46e70da5e0882ac6e08afd8a9f6285abfb12a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.05106\",\"authors\":[{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"},{\"authorId\":\"3431037\",\"name\":\"J. Qi\"},{\"authorId\":\"10667704\",\"name\":\"Yuxin Yuan\"}],\"doi\":\"10.1145/3284750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b4d3aa2a4559660bc3be2f38865d463601ff1d2\",\"title\":\"CM-GANs\",\"url\":\"https://www.semanticscholar.org/paper/3b4d3aa2a4559660bc3be2f38865d463601ff1d2\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"9355577\",\"name\":\"Shangqian Gao\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6784007c4433274b6d04b88c7fe626c25924b5ec\",\"title\":\"Cross-Modal Learning with Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/6784007c4433274b6d04b88c7fe626c25924b5ec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66227056\",\"name\":\"M. Guo\"},{\"authorId\":\"2035796\",\"name\":\"C. Zhou\"},{\"authorId\":\"49721726\",\"name\":\"Jiahang Liu\"}],\"doi\":\"10.1109/JSTARS.2019.2949220\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db38673271d01e83d915053f64eb058b94141c9f\",\"title\":\"Jointly Learning of Visual and Auditory: A New Approach for RS Image and Audio Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/db38673271d01e83d915053f64eb058b94141c9f\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336997\",\"name\":\"W. Wang\"},{\"authorId\":\"12287885\",\"name\":\"R. Liu\"},{\"authorId\":\"4820214\",\"name\":\"Mingle Wang\"},{\"authorId\":\"49184528\",\"name\":\"Sen Wang\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1145/3394171.3413507\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00075d654178c2641b779d28235c85877f475858\",\"title\":\"Memory-Based Network for Scene Graph with Unbalanced Relations\",\"url\":\"https://www.semanticscholar.org/paper/00075d654178c2641b779d28235c85877f475858\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1910.06514\",\"authors\":[{\"authorId\":\"144872058\",\"name\":\"Takashi Matsubara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"743164e8d89d7d6138ce32ee069489d9097bb816\",\"title\":\"Target-Oriented Deformation of Visual-Semantic Embedding Space\",\"url\":\"https://www.semanticscholar.org/paper/743164e8d89d7d6138ce32ee069489d9097bb816\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2004.00277\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01093\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"title\":\"Graph Structured Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.09953\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b488019592d8e0c08e6cd011ae0543a6ac451357\",\"title\":\"Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators\",\"url\":\"https://www.semanticscholar.org/paper/b488019592d8e0c08e6cd011ae0543a6ac451357\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50025815\",\"name\":\"Yongzhi Li\"},{\"authorId\":\"47845273\",\"name\":\"D. Zhang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/cvpr42600.2020.01280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"title\":\"Visual-Semantic Matching by Exploring High-Order Attention and Distraction\",\"url\":\"https://www.semanticscholar.org/paper/a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"101084939\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/ACCESS.2020.2975594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"284cd0512ecd5d7cec335b0038444085398ebaf5\",\"title\":\"Multi-Modal Memory Enhancement Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/284cd0512ecd5d7cec335b0038444085398ebaf5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69025802\",\"name\":\"F. A. Ruambo\"},{\"authorId\":\"1491246934\",\"name\":\"Mrindoko R. Nicholaus\"}],\"doi\":\"10.1109/ICUMT48472.2019.8970954\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84f57b1a016cbb2470ee400c25108129ecc5ff24\",\"title\":\"Towards Enhancing Information Retrieval Systems: A Brief Survey of Strategies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/84f57b1a016cbb2470ee400c25108129ecc5ff24\",\"venue\":\"2019 11th International Congress on Ultra Modern Telecommunications and Control Systems and Workshops (ICUMT)\",\"year\":2019},{\"arxivId\":\"2007.15103\",\"authors\":[{\"authorId\":\"47172737\",\"name\":\"A. Sain\"},{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78094362d566c3411dc7b7dcbd70b4527bcc974\",\"title\":\"Cross-Modal Hierarchical Modelling for Fine-Grained Sketch Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c78094362d566c3411dc7b7dcbd70b4527bcc974\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"98608166\",\"name\":\"M. Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/TIP.2020.3038354\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"title\":\"Deep Relation Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2010.12126\",\"authors\":[{\"authorId\":\"35432059\",\"name\":\"L. Ren\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"1730455\",\"name\":\"K. Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065af7ecb52354be79f538dac3ca210bf57e7739\",\"title\":\"Beyond the Deep Metric Learning: Enhance the Cross-Modal Matching with Adversarial Discriminative Domain Regularization\",\"url\":\"https://www.semanticscholar.org/paper/065af7ecb52354be79f538dac3ca210bf57e7739\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-030-30645-8_66\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f378be13df9e97e15ca240b60a0a0aa16d5eb64\",\"title\":\"Artpedia: A New Visual-Semantic Dataset with Visual and Contextual Sentences in the Artistic Domain\",\"url\":\"https://www.semanticscholar.org/paper/6f378be13df9e97e15ca240b60a0a0aa16d5eb64\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46511118\",\"name\":\"Bin Zhu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"47739915\",\"name\":\"J. Chen\"},{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"}],\"doi\":\"10.1109/CVPR.2019.01174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db30fce2fec76c17dfd7a65f8b739855d033255e\",\"title\":\"R\\u00b2GAN: Cross-Modal Recipe Retrieval With Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/db30fce2fec76c17dfd7a65f8b739855d033255e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98498116\",\"name\":\"S. Chen\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/ICCV.2019.00127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45b967283dd8e3732284387b36ed5e38a3aed0ff\",\"title\":\"Attention-Based Autism Spectrum Disorder Screening With Privileged Modality\",\"url\":\"https://www.semanticscholar.org/paper/45b967283dd8e3732284387b36ed5e38a3aed0ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2005.09183\",\"authors\":[{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"40495154\",\"name\":\"M. Hayashi\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1109/ICIP40778.2020.9190820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63a5b2f09fd2b217fa5a3792b84a78397fc10be4\",\"title\":\"Retrieving and Highlighting Action with Spatiotemporal Reference\",\"url\":\"https://www.semanticscholar.org/paper/63a5b2f09fd2b217fa5a3792b84a78397fc10be4\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2002.06661\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"title\":\"Latent Normalizing Flows for Many-to-Many Cross-Domain Mappings\",\"url\":\"https://www.semanticscholar.org/paper/87415957ec3aa3ae6756e3e7d22873cd9fc74c51\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732300163\",\"name\":\"Y. Guo\"},{\"authorId\":\"12564022\",\"name\":\"J. Chen\"},{\"authorId\":\"7214794\",\"name\":\"H. Zhang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3372278.3390709\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d1ac5e2f4d70b26ee7e79ee30a38f64676b404a\",\"title\":\"Visual Relations Augmented Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3d1ac5e2f4d70b26ee7e79ee30a38f64676b404a\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145094975\",\"name\":\"N. Zhou\"},{\"authorId\":\"67296711\",\"name\":\"J. Du\"},{\"authorId\":\"46705098\",\"name\":\"Zhe Xue\"},{\"authorId\":null,\"name\":\"Chong Liu\"},{\"authorId\":\"1844305587\",\"name\":\"Jinxuan Li\"}],\"doi\":\"10.1155/2020/7834953\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"330075e7b74c083608118a029e1f559ae8fcfb70\",\"title\":\"Cross-Modal Search for Social Networks via Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/330075e7b74c083608118a029e1f559ae8fcfb70\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2020.2995815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"title\":\"Enhancing Cross-Modal Retrieval Based on Modality-Specific and Embedding Spaces\",\"url\":\"https://www.semanticscholar.org/paper/5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2012.02206\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"47621053\",\"name\":\"A. Gholami\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"title\":\"Scan2Cap: Context-aware Dense Captioning in RGB-D Scans\",\"url\":\"https://www.semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121789307\",\"name\":\"W. Guo\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"144496860\",\"name\":\"Xiangwei Kong\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":\"10.1145/3343031.3351053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"title\":\"Learning Disentangled Representation for Cross-Modal Retrieval with Deep Mutual Information Estimation\",\"url\":\"https://www.semanticscholar.org/paper/52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491401385\",\"name\":\"P. Hu\"},{\"authorId\":\"1491401385\",\"name\":\"P. Hu\"},{\"authorId\":\"8249791\",\"name\":\"Xi Peng\"},{\"authorId\":\"47297550\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"66190968\",\"name\":\"Jie Lin\"},{\"authorId\":\"1786516\",\"name\":\"Liangli Zhen\"},{\"authorId\":\"70116510\",\"name\":\"W. Wang\"},{\"authorId\":\"1800117\",\"name\":\"Dezhong Peng\"},{\"authorId\":\"1800117\",\"name\":\"Dezhong Peng\"}],\"doi\":\"10.1016/j.patcog.2020.107734\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52ac2c9cad84cd70b7552a1f19741ac2b0b2536d\",\"title\":\"Cross-modal discriminant adversarial network\",\"url\":\"https://www.semanticscholar.org/paper/52ac2c9cad84cd70b7552a1f19741ac2b0b2536d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.04476\",\"authors\":[{\"authorId\":\"153003087\",\"name\":\"Xiangteng He\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"49352711\",\"name\":\"L. Xi-e\"}],\"doi\":\"10.1145/3343031.3350974\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9afd2d5d6ad193787a175124d1940ec21188342\",\"title\":\"A New Benchmark and Approach for Fine-grained Cross-media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/e9afd2d5d6ad193787a175124d1940ec21188342\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1863856\",\"name\":\"Kaimin Wei\"},{\"authorId\":\"2392310\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2996407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"title\":\"Adversarial Attentive Multi-Modal Embedding Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"title\":\"ENGAGING IMAGE CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.08504\",\"authors\":[{\"authorId\":\"51279767\",\"name\":\"Kenta Hama\"},{\"authorId\":\"144872058\",\"name\":\"Takashi Matsubara\"},{\"authorId\":\"1711781\",\"name\":\"K. Uehara\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c110fd348139a55fb37da1f44d4a2141c137f1a4\",\"title\":\"Exploring Uncertainty Measures for Image-Caption Embedding-and-Retrieval Task\",\"url\":\"https://www.semanticscholar.org/paper/c110fd348139a55fb37da1f44d4a2141c137f1a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"1914578421\",\"name\":\"Sabarish Gopalakrishnan\"},{\"authorId\":\"1404315481\",\"name\":\"Raymond Ptucha\"}],\"doi\":\"10.1117/1.JEI.29.2.023013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"360d84f0649d80d3b96846c1cd958b6c54332835\",\"title\":\"Aligned attention for common multimodal embeddings\",\"url\":\"https://www.semanticscholar.org/paper/360d84f0649d80d3b96846c1cd958b6c54332835\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.11550\",\"authors\":[{\"authorId\":\"1453661830\",\"name\":\"Keyu Wen\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"},{\"authorId\":\"48561436\",\"name\":\"Q. Cheng\"}],\"doi\":\"10.1109/TCSVT.2020.3030656\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2740a2308d9f9b867cd54cdf04da82c82c417481\",\"title\":\"Learning Dual Semantic Relations with Graph Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2740a2308d9f9b867cd54cdf04da82c82c417481\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"153051449\",\"name\":\"Tianyou Lu\"},{\"authorId\":\"1500393994\",\"name\":\"W. Huang\"},{\"authorId\":\"7998512\",\"name\":\"Jingling Yuan\"},{\"authorId\":\"8133750\",\"name\":\"W. Liu\"},{\"authorId\":\"1685088\",\"name\":\"Chia-Wen Lin\"}],\"doi\":\"10.1145/3372278.3390696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0f3bfe3ffcfd1983af3ac717cf07ff1be856e24\",\"title\":\"Visible-infrared Person Re-identification via Colorization-based Siamese Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/d0f3bfe3ffcfd1983af3ac717cf07ff1be856e24\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47012336\",\"name\":\"Xin Fu\"},{\"authorId\":\"152621482\",\"name\":\"Y. Zhao\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecc77dbc9388afac79388ab2aa986d9ffa6c2204\",\"title\":\"Adversarial task-specific learning\",\"url\":\"https://www.semanticscholar.org/paper/ecc77dbc9388afac79388ab2aa986d9ffa6c2204\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2010.02949\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.60\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73068d13d6e53876c374ebd4c862ec01351c9f39\",\"title\":\"Learning to Represent Image and Text with Denotation Graph\",\"url\":\"https://www.semanticscholar.org/paper/73068d13d6e53876c374ebd4c862ec01351c9f39\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a26d15d75febf100209cd5d198e8046be9c51f9\",\"title\":\"Re-ranking image-text matching by adaptive metric fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a26d15d75febf100209cd5d198e8046be9c51f9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1910.00058\",\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/D19-1154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b3b563f6611f60af8ca96624191ff66b27a8f9\",\"title\":\"Multi-Head Attention with Diversity for Learning Grounded Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/99b3b563f6611f60af8ca96624191ff66b27a8f9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/tcyb.2020.2985716\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"758890bef9a1a85a25a1f6831a58f00a462476af\",\"title\":\"SMAN: Stacked Multimodal Attention Network for Cross-Modal Image-Text Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/758890bef9a1a85a25a1f6831a58f00a462476af\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145215117\",\"name\":\"S. S. Rao\"},{\"authorId\":\"144426990\",\"name\":\"S. Ikram\"},{\"authorId\":\"1924754968\",\"name\":\"Parashara Ramesh\"}],\"doi\":\"10.1109/Indo-TaiwanICAN48429.2020.9181344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d72a89114da174dc2c8df1b785d014a7dc8f3192\",\"title\":\"Deep Learning System for Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d72a89114da174dc2c8df1b785d014a7dc8f3192\",\"venue\":\"2020 Indo \\u2013 Taiwan 2nd International Conference on Computing, Analytics and Networks (Indo-Taiwan ICAN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118023258\",\"name\":\"X. Wei\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"2694924\",\"name\":\"Y. Li\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"1684705122\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPR42600.2020.01095\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"caabcf61499e00c78d8ee692b8939caf98544a9c\",\"title\":\"Multi-Modality Cross Attention Network for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/caabcf61499e00c78d8ee692b8939caf98544a9c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1371af87f6d5e22ef6d8c5f9977f5e924f176f6\",\"title\":\"Bidirectional Retrieval Made Simple J\\u00f4natas Wehrmann\",\"url\":\"https://www.semanticscholar.org/paper/e1371af87f6d5e22ef6d8c5f9977f5e924f176f6\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3044372\",\"name\":\"M. Bastan\"},{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"50455411\",\"name\":\"Z. Heng\"},{\"authorId\":\"1404186585\",\"name\":\"Chen Zhuo\"},{\"authorId\":\"2785432\",\"name\":\"D. Sng\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e84df2f3ef0430c464c3c2bc169dfba8fca8c1bd\",\"title\":\"NTU ROSE Lab at TRECVID 2018: Ad-hoc Video Search and Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e84df2f3ef0430c464c3c2bc169dfba8fca8c1bd\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1990265392\",\"name\":\"Leigang Qu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413961\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"922d677867e1aa2a7cca05241af4746a0be04dd0\",\"title\":\"Context-Aware Multi-View Summarization Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/922d677867e1aa2a7cca05241af4746a0be04dd0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00280\",\"authors\":[{\"authorId\":\"11274858\",\"name\":\"Hengtong Hu\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00319\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f669a973d3ac83f9dea52b8a629a2ae48be4532f\",\"title\":\"Creating Something From Nothing: Unsupervised Knowledge Distillation for Cross-Modal Hashing\",\"url\":\"https://www.semanticscholar.org/paper/f669a973d3ac83f9dea52b8a629a2ae48be4532f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.18653/v1/P18-1085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"title\":\"Illustrative Language Understanding: Large-Scale Visual Grounding with Image Search\",\"url\":\"https://www.semanticscholar.org/paper/35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"3444569\",\"name\":\"Petar Velickovic\"},{\"authorId\":\"144269589\",\"name\":\"P. Li\\u00f2\"}],\"doi\":\"10.1109/TNNLS.2019.2945992\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e10055d62462c4112c2fbd4d8ba929e9eb769b58\",\"title\":\"XFlow: Cross-Modal Deep Neural Networks for Audiovisual Classification\",\"url\":\"https://www.semanticscholar.org/paper/e10055d62462c4112c2fbd4d8ba929e9eb769b58\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152998700\",\"name\":\"Y. Li\"},{\"authorId\":\"9918971\",\"name\":\"H. Hu\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"}],\"doi\":\"10.1109/ICIP.2019.8803515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b4d21bc1d24cd7f36d02f431aae0ad699563251\",\"title\":\"Learning Visually Aligned Semantic Graph for Cross-Modal Manifold Matching\",\"url\":\"https://www.semanticscholar.org/paper/0b4d21bc1d24cd7f36d02f431aae0ad699563251\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.06635\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"25080314\",\"name\":\"Teresa Botschen\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/ICCVW.2019.00557\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f81c842e37eb0c22528f1bf569514b379cf489ea\",\"title\":\"Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/f81c842e37eb0c22528f1bf569514b379cf489ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2003.00392\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"title\":\"Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2185781\",\"name\":\"Junyang Qian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b2cc9293d545e32b6ed514226d891639d54e34d\",\"title\":\"NEURAL CAPTION-IMAGE RETRIEVAL\",\"url\":\"https://www.semanticscholar.org/paper/8b2cc9293d545e32b6ed514226d891639d54e34d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112305\",\"name\":\"Chunxiao Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"3181822\",\"name\":\"Wenyu Zang\"},{\"authorId\":null,\"name\":\"Bin Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"title\":\"A Neighbor-aware Approach for Image-text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2001.03712\",\"authors\":[{\"authorId\":\"1435907961\",\"name\":\"Geondo Park\"},{\"authorId\":\"3472799\",\"name\":\"Chihye Han\"},{\"authorId\":\"2570901\",\"name\":\"W. Yoon\"},{\"authorId\":\"30595492\",\"name\":\"Dae-Shik Kim\"}],\"doi\":\"10.1109/WACV45572.2020.9093548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af60c7ea01a5fc0ff48bfbf3dd8b3bf69f86ff48\",\"title\":\"MHSAN: Multi-Head Self-Attention Network for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/af60c7ea01a5fc0ff48bfbf3dd8b3bf69f86ff48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.13073\",\"authors\":[{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8d117d098ac59d90bf7814d889e814b52637f22\",\"title\":\"A Novel Attention-based Aggregation Function to Combine Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/e8d117d098ac59d90bf7814d889e814b52637f22\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"1915664\",\"name\":\"Di Chen\"},{\"authorId\":\"1521935487\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/TMM.2020.2972168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1016eb1f2517418e48727417e14590f04eb8a96\",\"title\":\"Adversarial Attribute-Text Embedding for Person Search With Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/c1016eb1f2517418e48727417e14590f04eb8a96\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2010.01082\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"title\":\"Multi-Modal Open-Domain Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.05134\",\"authors\":[{\"authorId\":\"49184936\",\"name\":\"S. Wang\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"12977859\",\"name\":\"Z. Yao\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/WACV45572.2020.9093614\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f1b9e51c1d16c346e1ef679c243d61702a8a80\",\"title\":\"Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c9f1b9e51c1d16c346e1ef679c243d61702a8a80\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145952478\",\"name\":\"S. Huang\"},{\"authorId\":\"2027156493\",\"name\":\"Liang Sun\"},{\"authorId\":\"3161063\",\"name\":\"Muhammad Yousefnezhad\"},{\"authorId\":\"152808646\",\"name\":\"M. Wang\"},{\"authorId\":\"1772283\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-3-030-63823-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2d1d976a651b33a80e0ef0fad160d57c89de835\",\"title\":\"Perceived Image Reconstruction from Human Brain Activity via Time-Series Information Guided Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2d1d976a651b33a80e0ef0fad160d57c89de835\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1387712541\",\"name\":\"Zijin Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1145/3343031.3351055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42001225313e0f5376a8f4b1759e687225cd9d00\",\"title\":\"Cross-Modal Image-Text Retrieval with Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/42001225313e0f5376a8f4b1759e687225cd9d00\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151490323\",\"name\":\"Mengmeng Jing\"},{\"authorId\":\"49297739\",\"name\":\"Jingjing Li\"},{\"authorId\":\"145081293\",\"name\":\"Lei Zhu\"},{\"authorId\":\"1655484744\",\"name\":\"Ke Lu\"},{\"authorId\":\"49307823\",\"name\":\"Yang Yang\"},{\"authorId\":\"144794676\",\"name\":\"Z. Huang\"}],\"doi\":\"10.1145/3394171.3413676\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"032ae655e6be115923bf3facab40e16cf896441c\",\"title\":\"Incomplete Cross-modal Retrieval with Dual-Aligned Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/032ae655e6be115923bf3facab40e16cf896441c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.04011\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"title\":\"Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9733883\",\"name\":\"Qingrong Cheng\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1007/s11042-020-09450-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f473ada1bad964dc701f9fd19e53a05db8f3b4e6\",\"title\":\"Deep attentional fine-grained similarity network with adversarial learning for cross-modal retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f473ada1bad964dc701f9fd19e53a05db8f3b4e6\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2002.12489\",\"authors\":[{\"authorId\":\"1500380529\",\"name\":\"Y. Lu\"},{\"authorId\":\"89971337\",\"name\":\"Yue Wu\"},{\"authorId\":\"48265485\",\"name\":\"B. Liu\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"3735710\",\"name\":\"Baopu Li\"},{\"authorId\":\"3127351\",\"name\":\"Q. Chu\"},{\"authorId\":\"14514752\",\"name\":\"N. Yu\"}],\"doi\":\"10.1109/cvpr42600.2020.01339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52ee037195398c596e7548a5f6c224250be55b40\",\"title\":\"Cross-Modality Person Re-Identification With Shared-Specific Feature Transfer\",\"url\":\"https://www.semanticscholar.org/paper/52ee037195398c596e7548a5f6c224250be55b40\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.00808\",\"authors\":[{\"authorId\":\"32824146\",\"name\":\"Ammarah Farooq\"},{\"authorId\":\"144987296\",\"name\":\"M. Awais\"},{\"authorId\":\"144535339\",\"name\":\"Fei Yan\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"},{\"authorId\":\"144595173\",\"name\":\"A. Akbari\"},{\"authorId\":\"2610118\",\"name\":\"Syed Safwan Khalid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73d3b9d649923f87b18882232f68682a941b213a\",\"title\":\"A Convolutional Baseline for Person Re-Identification Using Vision and Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/73d3b9d649923f87b18882232f68682a941b213a\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":3031042,\"doi\":\"10.1109/CVPR.2018.00750\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":4,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"724b253a55e86ad230ba05c7eb78f249e09258d9\",\"references\":[{\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\"}],\"doi\":\"10.1109/CVPR.2017.131\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"3344005\",\"name\":\"C. Dance\"}],\"doi\":\"10.1109/CVPR.2007.383266\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23694b6d61668e62bb11f17c1d75dde3b4951948\",\"title\":\"Fisher Kernels on Visual Vocabularies for Image Categorization\",\"url\":\"https://www.semanticscholar.org/paper/23694b6d61668e62bb11f17c1d75dde3b4951948\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Salakhutdinov\"},{\"authorId\":null,\"name\":\"R. S. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A method for stochastic optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1511.07067\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.539\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06599d41a3256245aa0cb2e9e56b29459c2e2c69\",\"title\":\"VisualWord2Vec (Vis-W2V): Learning Visually Grounded Word Embeddings Using Abstract Scenes\",\"url\":\"https://www.semanticscholar.org/paper/06599d41a3256245aa0cb2e9e56b29459c2e2c69\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1710.05106\",\"authors\":[{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"},{\"authorId\":\"3431037\",\"name\":\"J. Qi\"},{\"authorId\":\"10667704\",\"name\":\"Yuxin Yuan\"}],\"doi\":\"10.1145/3284750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b4d3aa2a4559660bc3be2f38865d463601ff1d2\",\"title\":\"CM-GANs\",\"url\":\"https://www.semanticscholar.org/paper/3b4d3aa2a4559660bc3be2f38865d463601ff1d2\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1612.03242\",\"authors\":[{\"authorId\":\"120811666\",\"name\":\"Han Zhang\"},{\"authorId\":\"145017761\",\"name\":\"Tao Xu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/ICCV.2017.629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"title\":\"StackGAN: Text to Photo-Realistic Image Synthesis with Stacked Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/ea67d2d5f2a7d5760ec6b67ea93d11dd5affa921\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1705.04304\",\"authors\":[{\"authorId\":\"2896063\",\"name\":\"Romain Paulus\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"032274e57f7d8b456bd255fe76b909b2c1d7458e\",\"title\":\"A Deep Reinforced Model for Abstractive Summarization\",\"url\":\"https://www.semanticscholar.org/paper/032274e57f7d8b456bd255fe76b909b2c1d7458e\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144426057\",\"name\":\"M. Zhou\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"10699750\",\"name\":\"X. Gao\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2017.208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad5dc94b28bee087a34f52114c52bd09d2acd8cb\",\"title\":\"Hierarchical Multimodal LSTM for Dense Visual-Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/ad5dc94b28bee087a34f52114c52bd09d2acd8cb\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2017.767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1605.05396\",\"authors\":[{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"3084614\",\"name\":\"Xinchen Yan\"},{\"authorId\":\"2876316\",\"name\":\"L. Logeswaran\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"title\":\"Generative Adversarial Text to Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/6c7f040a150abf21dbcefe1f22e0f98fa184f41a\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"38979129\",\"name\":\"Xi Li\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1776903\",\"name\":\"Weiming Lu\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/2733373.2806240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bf935268af764654ec3212569d2f76ed4ff58f7\",\"title\":\"Deep Compositional Cross-modal Learning to Rank via Local-Global Alignment\",\"url\":\"https://www.semanticscholar.org/paper/5bf935268af764654ec3212569d2f76ed4ff58f7\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1607.02748\",\"authors\":[{\"authorId\":\"3433026\",\"name\":\"Antonia Creswell\"},{\"authorId\":\"2815535\",\"name\":\"A. Bharath\"}],\"doi\":\"10.1007/978-3-319-46604-0_55\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"344e8d09cd6144e84a92273d2b5be6c885ce2c22\",\"title\":\"Adversarial Training for Sketch Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/344e8d09cd6144e84a92273d2b5be6c885ce2c22\",\"venue\":\"ECCV Workshops\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1512.07108\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"1859486\",\"name\":\"Jason Kuen\"},{\"authorId\":\"2139431\",\"name\":\"Lianyang Ma\"},{\"authorId\":\"3000984\",\"name\":\"Amir Shahroudy\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"66506222\",\"name\":\"T. Liu\"},{\"authorId\":\"50141018\",\"name\":\"X. Wang\"},{\"authorId\":\"50248285\",\"name\":\"Gang Wang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"6955999\",\"name\":\"T. Chen\"}],\"doi\":\"10.1016/j.patcog.2017.10.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1193317829bfcc9b9dffa5ae85a2e2114254b37e\",\"title\":\"Recent advances in convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/1193317829bfcc9b9dffa5ae85a2e2114254b37e\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49441320\",\"name\":\"H. Ding\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"32824694\",\"name\":\"A. Q. Liu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea743597a5f48babef1982259566d76a9bf66bf2\",\"title\":\"Context Contrasted Feature and Gated Multi-scale Aggregation for Scene Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ea743597a5f48babef1982259566d76a9bf66bf2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014}],\"title\":\"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Document retrieval\",\"topicId\":\"14824\",\"url\":\"https://www.semanticscholar.org/topic/14824\"},{\"topic\":\"Word embedding\",\"topicId\":\"286696\",\"url\":\"https://www.semanticscholar.org/topic/286696\"},{\"topic\":\"Learning to rank\",\"topicId\":\"135827\",\"url\":\"https://www.semanticscholar.org/topic/135827\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Test set\",\"topicId\":\"24168\",\"url\":\"https://www.semanticscholar.org/topic/24168\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Emoticon\",\"topicId\":\"55238\",\"url\":\"https://www.semanticscholar.org/topic/55238\"}],\"url\":\"https://www.semanticscholar.org/paper/724b253a55e86ad230ba05c7eb78f249e09258d9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"