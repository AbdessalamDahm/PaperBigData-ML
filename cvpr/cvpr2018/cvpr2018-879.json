"{\"abstract\":\"We introduce a seemingly impossible task: given only an audio clip of someone speaking, decide which of two face images is the speaker. In this paper we study this, and a number of related cross-modal tasks, aimed at answering the question: how much can we infer from the voice about the face and vice versa? We study this task \\\"in the wild\\\", employing the datasets that are now publicly available for face recognition from static images (VGGFace) and speaker identification from audio (VoxCeleb). These provide training and testing scenarios for both static and dynamic testing of cross-modal matching. We make the following contributions: (i) we introduce CNN architectures for both binary and multi-way cross-modal face and audio matching: (ii) we compare dynamic testing (where video information is available, but the audio is not from the same video) with static testing (where only a single still image is available): and (iii) we use human testing as a baseline to calibrate the difficulty of the task. We show that a CNN can indeed be trained to solve this task in both the static and dynamic scenarios, and is even well above chance on 10-way classification of the face given the voice. The CNN matches human performance on easy examples (e.g. different gender across faces) but exceeds human performance on more challenging examples (e.g. faces with the same gender, age and nationality).\",\"arxivId\":\"1804.00326\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\",\"url\":\"https://www.semanticscholar.org/author/19263506\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\",\"url\":\"https://www.semanticscholar.org/author/7641268\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\",\"url\":\"https://www.semanticscholar.org/author/1688869\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":\"1904.00150\",\"authors\":[{\"authorId\":\"145816931\",\"name\":\"Gaurav Verma\"},{\"authorId\":\"76954832\",\"name\":\"E. Dhekane\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"}],\"doi\":\"10.1109/ICASSP.2019.8683133\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed9941b21b26f9396eed2c6b0d9c5b0cf6e5f118\",\"title\":\"Learning Affective Correspondence between Music and Image\",\"url\":\"https://www.semanticscholar.org/paper/ed9941b21b26f9396eed2c6b0d9c5b0cf6e5f118\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"153915824\",\"name\":\"Rita Singh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d97a12a443d1238ac2f02b3e47619fff33c8430f\",\"title\":\"Face Reconstruction from Voice using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d97a12a443d1238ac2f02b3e47619fff33c8430f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88631934\",\"name\":\"Sujata M Huestegge\"}],\"doi\":\"10.3389/fpsyg.2019.01957\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a73c58e23f1ce88c0376e4f1feb99525e01dcf21\",\"title\":\"Matching Unfamiliar Voices to Static and Dynamic Faces: No Evidence for a Dynamic Face Advantage in a Simultaneous Presentation Paradigm\",\"url\":\"https://www.semanticscholar.org/paper/a73c58e23f1ce88c0376e4f1feb99525e01dcf21\",\"venue\":\"Front. Psychol.\",\"year\":2019},{\"arxivId\":\"2003.11136\",\"authors\":[{\"authorId\":\"144129240\",\"name\":\"D. Nguyen\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"1779016\",\"name\":\"D. Nguyen\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1930235\",\"name\":\"S. Tran\"},{\"authorId\":\"47689605\",\"name\":\"Rui Zeng\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"393d4d4b6fd9774ead6ff4a59d9249b6f5c2775f\",\"title\":\"Joint Deep Cross-Domain Transfer Learning for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/393d4d4b6fd9774ead6ff4a59d9249b6f5c2775f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.07074\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"46239142\",\"name\":\"Soyeon Choe\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"153579825\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.21437/Interspeech.2020-1065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7abd42a3f9319873384138283ed71279044601b7\",\"title\":\"FaceFilter: Audio-visual speech separation using still images\",\"url\":\"https://www.semanticscholar.org/paper/7abd42a3f9319873384138283ed71279044601b7\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"2006.05888\",\"authors\":[{\"authorId\":\"115358722\",\"name\":\"Yeqi Bai\"},{\"authorId\":\"145855564\",\"name\":\"Tao Ma\"},{\"authorId\":\"48169625\",\"name\":\"L. Wang\"},{\"authorId\":\"1723364\",\"name\":\"Z. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7a27c9aca97915feb61a189d7a351083a7336b1\",\"title\":\"Speech Fusion to Face: Bridging the Gap Between Human's Vocal Characteristics and Facial Imaging\",\"url\":\"https://www.semanticscholar.org/paper/c7a27c9aca97915feb61a189d7a351083a7336b1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08742\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edcd367fd429a013a1a777ebfa42528e37aa821\",\"title\":\"Disentangled Speech Embeddings Using Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/6edcd367fd429a013a1a777ebfa42528e37aa821\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"cb4eefb45ee5143da44be376396c85b6ab2d7a2e\",\"title\":\"Re-rendering Reality Research Statement\",\"url\":\"https://www.semanticscholar.org/paper/cb4eefb45ee5143da44be376396c85b6ab2d7a2e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.10604\",\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"1798727\",\"name\":\"R. Singh\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b412102130e3b9e8eeb73b29cace8c800f29f83b\",\"title\":\"Reconstructing faces from voices\",\"url\":\"https://www.semanticscholar.org/paper/b412102130e3b9e8eeb73b29cace8c800f29f83b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"3419368\",\"name\":\"Jiaxing Tan\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e304622f51f30f281cd8cc09a992b7519f135d2d\",\"title\":\"Cross-modal Center Loss\",\"url\":\"https://www.semanticscholar.org/paper/e304622f51f30f281cd8cc09a992b7519f135d2d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46885959\",\"name\":\"R. Wang\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"1391221164\",\"name\":\"Xufeng Zhang\"},{\"authorId\":\"35043641\",\"name\":\"Jixin Ma\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"}],\"doi\":\"10.1109/ICMEW.2019.00-70\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"a2a8ca7fbb86dc0b8f4d9c4c44e7bffb186c585a\",\"title\":\"A Novel Distance Learning for Elastic Cross-Modal Audio-Visual Matching\",\"url\":\"https://www.semanticscholar.org/paper/a2a8ca7fbb86dc0b8f4d9c4c44e7bffb186c585a\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1798727\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/978-981-13-8403-5_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8f052ba476ba781a2ecd64f18cad3999cd98d01\",\"title\":\"Reconstruction of the Human Persona in 3D from Voice, and its Reverse\",\"url\":\"https://www.semanticscholar.org/paper/d8f052ba476ba781a2ecd64f18cad3999cd98d01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.02863\",\"authors\":[{\"authorId\":\"7523247\",\"name\":\"S. Zhou\"},{\"authorId\":\"144396601\",\"name\":\"H. Beigi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35d5e7c09d4b2d5356bc19027a85e2329f7434c0\",\"title\":\"A Transfer Learning Method for Speech Emotion Recognition from Automatic Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/35d5e7c09d4b2d5356bc19027a85e2329f7434c0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.00833\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-01261-8_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"title\":\"Learnable PINs: Cross-Modal Embeddings for Person Identity\",\"url\":\"https://www.semanticscholar.org/paper/a2344004f0e1409c0c9473d071a5cfd74bff0a5d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123026381\",\"name\":\"Wang Hanyan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02191cf3238c7c0013522e88b5b8eb6af826bd7c\",\"title\":\"COMP4801 Interim Report Facial Expression Synthesis using Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/02191cf3238c7c0013522e88b5b8eb6af826bd7c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.04758\",\"authors\":[{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"100602595\",\"name\":\"Mandi Luo\"},{\"authorId\":\"77886607\",\"name\":\"Rui Wang\"},{\"authorId\":\"4520695\",\"name\":\"A. Zheng\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"title\":\"Deep Audio-Visual Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/7cabfa7362ebb57c77380caa57aa17fd7195605c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48355030\",\"name\":\"Zhengyang Chen\"},{\"authorId\":\"145720713\",\"name\":\"Shuai Wang\"},{\"authorId\":\"2480051\",\"name\":\"Yanmin Qian\"}],\"doi\":\"10.21437/interspeech.2020-2229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29aad3d6ae4018381ab90bda636ff8475c584003\",\"title\":\"Multi-Modality Matters: A Performance Leap on VoxCeleb\",\"url\":\"https://www.semanticscholar.org/paper/29aad3d6ae4018381ab90bda636ff8475c584003\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9273364\",\"name\":\"S. Banerjee\"},{\"authorId\":\"2613438\",\"name\":\"W. Scheirer\"},{\"authorId\":\"39782629\",\"name\":\"L. Li\"}],\"doi\":\"10.3389/fncom.2019.00003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abafe96c4ef0605b181f6dade35175c0baaa90f9\",\"title\":\"An Extreme Value Theory Model of Cross-Modal Sensory Information Integration in Modulation of Vertebrate Visual System Functions\",\"url\":\"https://www.semanticscholar.org/paper/abafe96c4ef0605b181f6dade35175c0baaa90f9\",\"venue\":\"Front. Comput. Neurosci.\",\"year\":2019},{\"arxivId\":\"2004.14326\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"9299637\",\"name\":\"Hong-Goo Kang\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"}],\"doi\":\"10.21437/Interspeech.2020-1113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6ec232e30ae03c1f97981fb00c84195f9f9bff3\",\"title\":\"Seeing voices and hearing voices: learning discriminative embeddings using cross-modal self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/d6ec232e30ae03c1f97981fb00c84195f9f9bff3\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"1905.09773\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1109/CVPR.2019.00772\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"title\":\"Speech2Face: Learning the Face Behind a Voice\",\"url\":\"https://www.semanticscholar.org/paper/e4b54f2e0ebbe450e2c527cf5a00d4816980a913\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"153579825\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.1109/JSTSP.2020.2987720\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7431525dd5b821532191c7c078972bc457565d86\",\"title\":\"Perfect Match: Self-Supervised Embeddings for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7431525dd5b821532191c7c078972bc457565d86\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1805.05553\",\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-20873-8_18\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"title\":\"On Learning Associations of Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/1bdd7ed61a38b61399340c04cd478a96b67a51e5\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39726017\",\"name\":\"Rui Wang\"},{\"authorId\":\"48032873\",\"name\":\"X. Liu\"},{\"authorId\":\"120082097\",\"name\":\"Yiu-ming Cheung\"},{\"authorId\":\"48694127\",\"name\":\"K. Cheng\"},{\"authorId\":\"151488319\",\"name\":\"N. Wang\"},{\"authorId\":\"2038786\",\"name\":\"Wentao Fan\"}],\"doi\":\"10.1145/3397271.3401302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d25d53b24ae9bea15f92576cc152c63f562344f\",\"title\":\"Learning Discriminative Joint Embeddings for Efficient Face and Voice Association\",\"url\":\"https://www.semanticscholar.org/paper/6d25d53b24ae9bea15f92576cc152c63f562344f\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"2007.13729\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144220896\",\"name\":\"Xiaoyu Chen\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"title\":\"Noisy Agents: Self-supervised Exploration by Predicting Auditory Events\",\"url\":\"https://www.semanticscholar.org/paper/5f978b3829acad6ac8b3372d2fa8d38a45b96d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145743106\",\"name\":\"A. Ross\"},{\"authorId\":\"47041759\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1751335\",\"name\":\"Cunjian Chen\"},{\"authorId\":\"39617163\",\"name\":\"A. Chowdhury\"},{\"authorId\":\"5456235\",\"name\":\"V. Mirjalili\"},{\"authorId\":\"49620396\",\"name\":\"R. Sharma\"},{\"authorId\":\"3153117\",\"name\":\"Thomas Swearingen\"},{\"authorId\":\"3382857\",\"name\":\"S. Yadav\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06084d91b5a92a1dfd37b4dc7c54d4ef6043d209\",\"title\":\"Problems in Biometrics : The Future\",\"url\":\"https://www.semanticscholar.org/paper/06084d91b5a92a1dfd37b4dc7c54d4ef6043d209\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.04463\",\"authors\":[{\"authorId\":\"151500851\",\"name\":\"K. Deng\"},{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"title\":\"Unsupervised Any-to-Many Audiovisual Synthesis via Exemplar Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/1dcee6a820b9d23c9cca11b1de96dd14f97e9f2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.03160\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_35\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe018f22600d07cbd0452a070e03708886470015\",\"title\":\"The Sound of Pixels\",\"url\":\"https://www.semanticscholar.org/paper/fe018f22600d07cbd0452a070e03708886470015\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.09002\",\"authors\":[{\"authorId\":\"11614724\",\"name\":\"Chris Xiaoxuan Lu\"},{\"authorId\":\"4720253\",\"name\":\"Xuan Kan\"},{\"authorId\":\"2525530\",\"name\":\"B. Du\"},{\"authorId\":\"48240322\",\"name\":\"Changhao Chen\"},{\"authorId\":\"144169294\",\"name\":\"Hongkai Wen\"},{\"authorId\":\"34401562\",\"name\":\"A. Markham\"},{\"authorId\":\"3641238\",\"name\":\"A. Trigoni\"},{\"authorId\":\"144075655\",\"name\":\"J. S. Stankovic\"}],\"doi\":\"10.1145/3308558.3313398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41b3c74c1be988ead54ea124b7ea63255655a4c4\",\"title\":\"Autonomous Learning for Face Recognition in the Wild via Ambient Wireless Cues\",\"url\":\"https://www.semanticscholar.org/paper/41b3c74c1be988ead54ea124b7ea63255655a4c4\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":\"2006.06976\",\"authors\":[{\"authorId\":\"2870877\",\"name\":\"Xu-Yao Zhang\"},{\"authorId\":\"117992479\",\"name\":\"Cheng-Lin Liu\"},{\"authorId\":\"21266300\",\"name\":\"C. Y. Suen\"}],\"doi\":\"10.1109/JPROC.2020.2989782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a53aaf97203d3f8a89d9d8e0d39ca568c0896d4\",\"title\":\"Towards Robust Pattern Recognition: A Review\",\"url\":\"https://www.semanticscholar.org/paper/6a53aaf97203d3f8a89d9d8e0d39ca568c0896d4\",\"venue\":\"Proceedings of the IEEE\",\"year\":2020},{\"arxivId\":\"1910.08732\",\"authors\":[{\"authorId\":\"50811450\",\"name\":\"Kranti K. Parida\"},{\"authorId\":\"31352334\",\"name\":\"Neeraj Matiyali\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV45572.2020.9093438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a243ee80146ca37fc296bc67043ea2a67222de68\",\"title\":\"Coordinated Joint Multimodal Embeddings for Generalized Audio-Visual Zero-shot Classification and Retrieval of Videos\",\"url\":\"https://www.semanticscholar.org/paper/a243ee80146ca37fc296bc67043ea2a67222de68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88470948\",\"name\":\"Y. Kim\"},{\"authorId\":\"2487892\",\"name\":\"Sungeun Hong\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"121416659\",\"name\":\"H. Park\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7170952d0d6ded78708be7aca86e630089dcdb88\",\"title\":\"Domain Adaptation without Source Data\",\"url\":\"https://www.semanticscholar.org/paper/7170952d0d6ded78708be7aca86e630089dcdb88\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1852936248\",\"name\":\"Kai Cheng\"},{\"authorId\":\"48032873\",\"name\":\"X. Liu\"},{\"authorId\":\"120082097\",\"name\":\"Yiu-ming Cheung\"},{\"authorId\":\"39726017\",\"name\":\"Rui Wang\"},{\"authorId\":\"12186775\",\"name\":\"Xing Xu\"},{\"authorId\":\"122246162\",\"name\":\"Bineng Zhong\"}],\"doi\":\"10.1145/3394171.3413710\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"6b8fbb89065eb64004635490ef3a591b55cad530\",\"title\":\"Hearing like Seeing: Improving Voice-Face Interactions and Associations via Adversarial Deep Semantic Matching Network\",\"url\":\"https://www.semanticscholar.org/paper/6b8fbb89065eb64004635490ef3a591b55cad530\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491233100\",\"name\":\"Pranav Agarwal\"},{\"authorId\":\"119831613\",\"name\":\"Soumyajit Poddar\"},{\"authorId\":\"120454702\",\"name\":\"A. Hazarika\"},{\"authorId\":\"9116680\",\"name\":\"H. Rahaman\"}],\"doi\":\"10.1109/TENSYMP46218.2019.8971330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8761a0f1fce4a49282acb1db542e740005a038ea\",\"title\":\"Learning to synthesize faces using voice clips for Cross-Modal biometric matching\",\"url\":\"https://www.semanticscholar.org/paper/8761a0f1fce4a49282acb1db542e740005a038ea\",\"venue\":\"2019 IEEE Region 10 Symposium (TENSYMP)\",\"year\":2019},{\"arxivId\":\"2003.12957\",\"authors\":[{\"authorId\":\"22248940\",\"name\":\"X. Zeng\"},{\"authorId\":\"122568788\",\"name\":\"Yusu Pan\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"},{\"authorId\":\"93006732\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6970\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d12eae6644c366023e746906bcb8fd0758a8223e\",\"title\":\"Realistic Face Reenactment via Self-Supervised Disentangling of Identity and Pose\",\"url\":\"https://www.semanticscholar.org/paper/d12eae6644c366023e746906bcb8fd0758a8223e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1652995353\",\"name\":\"Gurlove Singh\"},{\"authorId\":\"46623875\",\"name\":\"Amit Kumar Goel\"}],\"doi\":\"10.1109/ICIMIA48430.2020.9074838\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b053a15dcdeb1d89d271c03d6b1bc3d30d8ec00e\",\"title\":\"Face Detection and Recognition System using Digital Image Processing\",\"url\":\"https://www.semanticscholar.org/paper/b053a15dcdeb1d89d271c03d6b1bc3d30d8ec00e\",\"venue\":\"2020 2nd International Conference on Innovative Mechanisms for Industry Applications (ICIMIA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"3493789\",\"name\":\"Y. Feng\"}],\"doi\":\"10.1007/978-3-030-31726-3_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fd9462b383033ac1e32964d9219a8636d98be18\",\"title\":\"Deep Voice-Visual Cross-Modal Retrieval with Deep Feature Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/6fd9462b383033ac1e32964d9219a8636d98be18\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"2005.09812\",\"authors\":[{\"authorId\":\"107979102\",\"name\":\"Juan Leon Alcazar\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPR42600.2020.01248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34c8161a352bce60b64b6382b1ff7280433ad654\",\"title\":\"Active Speakers in Context\",\"url\":\"https://www.semanticscholar.org/paper/34c8161a352bce60b64b6382b1ff7280433ad654\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2727313\",\"name\":\"A. Jamaludin\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01150-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"title\":\"You Said That?: Synthesising Talking Faces from Audio\",\"url\":\"https://www.semanticscholar.org/paper/0e8cd058ae29c6f60a8750c1df3caa5dc0e99543\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1909.01976\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"}],\"doi\":\"10.1109/ICCVW.2019.00551\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"title\":\"Do Cross Modal Systems Leverage Semantic Relationships?\",\"url\":\"https://www.semanticscholar.org/paper/5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"1486416823\",\"name\":\"Moreno Caraffini\"},{\"authorId\":\"1387994112\",\"name\":\"Nicola Landro\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"}],\"doi\":\"10.1109/IVCNZ48456.2019.8960960\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e69953361ce959aa85ff795bee593e589c1fd867\",\"title\":\"Are These Birds Similar: Learning Branched Networks for Fine-grained Representations\",\"url\":\"https://www.semanticscholar.org/paper/e69953361ce959aa85ff795bee593e589c1fd867\",\"venue\":\"2019 International Conference on Image and Vision Computing New Zealand (IVCNZ)\",\"year\":2019},{\"arxivId\":\"2004.11838\",\"authors\":[{\"authorId\":\"1727159\",\"name\":\"Ferda Ofli\"},{\"authorId\":\"37784060\",\"name\":\"Firoj Alam\"},{\"authorId\":\"153338028\",\"name\":\"M. Imran\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4a888afd8fb93e9d294acdc7022ee20a5db8d617\",\"title\":\"Analysis of Social Media Data using Multimodal Deep Learning for Disaster Response\",\"url\":\"https://www.semanticscholar.org/paper/4a888afd8fb93e9d294acdc7022ee20a5db8d617\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.03591\",\"authors\":[{\"authorId\":\"48208484\",\"name\":\"Justin Lin\"},{\"authorId\":\"35159852\",\"name\":\"R. Calandra\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":\"10.1109/ICRA.2019.8793885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b474d390d434b4a156a38ad1062f8a7ccd25ef5\",\"title\":\"Learning to Identify Object Instances by Touch: Tactile Recognition via Multimodal Matching\",\"url\":\"https://www.semanticscholar.org/paper/5b474d390d434b4a156a38ad1062f8a7ccd25ef5\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":\"1810.02001\",\"authors\":[{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"153756236\",\"name\":\"S. Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"}],\"doi\":\"10.1109/DICTA.2018.8615789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b11f0b0cd3b2ab859d46142242b972711702a81\",\"title\":\"Image and Encoded Text Fusion for Multi-Modal Classification\",\"url\":\"https://www.semanticscholar.org/paper/1b11f0b0cd3b2ab859d46142242b972711702a81\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1016/j.csl.2019.101027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f94a09614d0b6f5c7ac6ab4b0f6df21480f0c7a5\",\"title\":\"Voxceleb: Large-scale speaker verification in the wild\",\"url\":\"https://www.semanticscholar.org/paper/f94a09614d0b6f5c7ac6ab4b0f6df21480f0c7a5\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":\"2004.02205\",\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e908719ae2a09e3726300df65bcd31dfddea5a86\",\"title\":\"Deep Multimodal Feature Encoding for Video Ordering\",\"url\":\"https://www.semanticscholar.org/paper/e908719ae2a09e3726300df65bcd31dfddea5a86\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83601757\",\"name\":\"Gou Mao\"},{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"40231966\",\"name\":\"Lu Xiao-qiang\"}],\"doi\":\"10.1109/PRRS.2018.8486338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54d97faabb67c99afb5ab8c16feee7658ea8533f\",\"title\":\"Deep Cross-Modal Retrieval for Remote Sensing Image and Audio\",\"url\":\"https://www.semanticscholar.org/paper/54d97faabb67c99afb5ab8c16feee7658ea8533f\",\"venue\":\"2018 10th IAPR Workshop on Pattern Recognition in Remote Sensing (PRRS)\",\"year\":2018},{\"arxivId\":\"2005.08606\",\"authors\":[{\"authorId\":\"152848162\",\"name\":\"You Jin Kim\"},{\"authorId\":\"1594024908\",\"name\":\"Hee Soo Heo\"},{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"50643194\",\"name\":\"Bong-Jin Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"995fd68acb1ee8c04134be1954cfc4b12f685325\",\"title\":\"End-to-End Lip Synchronisation\",\"url\":\"https://www.semanticscholar.org/paper/995fd68acb1ee8c04134be1954cfc4b12f685325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30691613\",\"name\":\"X. Wang\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"153426241\",\"name\":\"J. Chen\"},{\"authorId\":\"1519969356\",\"name\":\"Xiaobo Wang\"},{\"authorId\":\"7590116\",\"name\":\"C. Yan\"},{\"authorId\":\"153040576\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3380549\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"410d362eaa55c93b6772d1158b1522e6d6846e22\",\"title\":\"Listen, Look, and Find the One\",\"url\":\"https://www.semanticscholar.org/paper/410d362eaa55c93b6772d1158b1522e6d6846e22\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1807.04836\",\"authors\":[{\"authorId\":\"145357606\",\"name\":\"Y. Wen\"},{\"authorId\":\"144727980\",\"name\":\"M. Ismail\"},{\"authorId\":\"36326884\",\"name\":\"Weiyang Liu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"},{\"authorId\":\"1798727\",\"name\":\"R. Singh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"4188f289eb85bb047dbbc15acbd79fae6abe25f5\",\"title\":\"Disjoint Mapping Network for Cross-modal Matching of Voices and Faces\",\"url\":\"https://www.semanticscholar.org/paper/4188f289eb85bb047dbbc15acbd79fae6abe25f5\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1904.04540\",\"authors\":[{\"authorId\":\"1787190\",\"name\":\"Hirokazu Kameoka\"},{\"authorId\":\"2007195\",\"name\":\"Kou Tanaka\"},{\"authorId\":\"96646484\",\"name\":\"Aaron Valero Puche\"},{\"authorId\":\"2991962\",\"name\":\"Yasunori Ohishi\"},{\"authorId\":\"50509323\",\"name\":\"Takuhiro Kaneko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a354cd50fa34379b79c951c165d9c7238780fe8\",\"title\":\"Crossmodal Voice Conversion\",\"url\":\"https://www.semanticscholar.org/paper/5a354cd50fa34379b79c951c165d9c7238780fe8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.08001\",\"authors\":[{\"authorId\":\"10437962\",\"name\":\"Soo-Whan Chung\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"9299637\",\"name\":\"Hong-Goo Kang\"}],\"doi\":\"10.1109/ICASSP.2019.8682524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d66090e0bddb6f751241acd6e59cf25756e57a9\",\"title\":\"Perfect Match: Improved Cross-modal Embeddings for Audio-visual Synchronisation\",\"url\":\"https://www.semanticscholar.org/paper/4d66090e0bddb6f751241acd6e59cf25756e57a9\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48514386\",\"name\":\"Yansheng Li\"},{\"authorId\":\"1471663596\",\"name\":\"Jiayi Ma\"},{\"authorId\":\"46867114\",\"name\":\"Yong-jun Zhang\"}],\"doi\":\"10.1016/j.inffus.2020.10.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"63e83149acdef797c8fe8b2fcb32ff20dff15b92\",\"title\":\"Image retrieval from remote sensing big data: A survey\",\"url\":\"https://www.semanticscholar.org/paper/63e83149acdef797c8fe8b2fcb32ff20dff15b92\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2007.07984\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"title\":\"Separating Sounds from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/7b2cf1d0538f3ad0d5fae1af4d97571b9291eabc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.02522\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"47107270\",\"name\":\"E. Coto\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"3282778\",\"name\":\"Mitchell McLaren\"},{\"authorId\":\"3127386\",\"name\":\"D. Reynolds\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30b6eca9585286cc011a56f3c8adbab3bcd33a0b\",\"title\":\"VoxSRC 2019: The first VoxCeleb Speaker Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/30b6eca9585286cc011a56f3c8adbab3bcd33a0b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1905988623\",\"name\":\"Han Xue\"},{\"authorId\":\"1406041324\",\"name\":\"Jun Ling\"},{\"authorId\":\"144157729\",\"name\":\"L. Song\"},{\"authorId\":\"144509678\",\"name\":\"Rong Xie\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9190699\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d103f9e2d8e4e440fe1127270cba0fe6fdb5554\",\"title\":\"Realistic Talking Face Synthesis With Geometry-Aware Feature Transformation\",\"url\":\"https://www.semanticscholar.org/paper/1d103f9e2d8e4e440fe1127270cba0fe6fdb5554\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1806.05622\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2018-1929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8875ae233bc074f5cd6c4ebba447b536a7e847a5\",\"title\":\"VoxCeleb2: Deep Speaker Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8875ae233bc074f5cd6c4ebba447b536a7e847a5\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9273364\",\"name\":\"S. Banerjee\"},{\"authorId\":\"2613438\",\"name\":\"W. Scheirer\"},{\"authorId\":\"39782629\",\"name\":\"L. Li\"}],\"doi\":\"10.1101/423038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee6f3f410332792d4b7890e53315448b459eae00\",\"title\":\"An Extreme Value Theory Model of Cross-Modal Sensory Information Integration in Modulation of Vertebrate Visual System Functions\",\"url\":\"https://www.semanticscholar.org/paper/ee6f3f410332792d4b7890e53315448b459eae00\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.05937\",\"authors\":[{\"authorId\":null,\"name\":\"Lin Wang\"},{\"authorId\":\"51182421\",\"name\":\"Kuk-Jin Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2528a82dd2266600d4ee2b54165556a984de94d4\",\"title\":\"Knowledge Distillation and Student-Teacher Learning for Visual Intelligence: A Review and New Outlooks\",\"url\":\"https://www.semanticscholar.org/paper/2528a82dd2266600d4ee2b54165556a984de94d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.07364\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"title\":\"Revisiting Cross Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.08685\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"}],\"doi\":\"10.1109/DICTA47822.2019.8945863\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d0e10059e473f57a0a89b61a0d15a09bb2624641\",\"title\":\"Deep Latent Space Learning for Cross-Modal Mapping of Audio and Visual Signals\",\"url\":\"https://www.semanticscholar.org/paper/d0e10059e473f57a0a89b61a0d15a09bb2624641\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1904.01909\",\"authors\":[{\"authorId\":\"9181429\",\"name\":\"Soumya Tripathy\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1109/WACV45572.2020.9093474\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14927abbd16abbf1c1dbed1a2f70dd0a9bea8120\",\"title\":\"ICface: Interpretable and Controllable Face Reenactment Using GANs\",\"url\":\"https://www.semanticscholar.org/paper/14927abbd16abbf1c1dbed1a2f70dd0a9bea8120\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"2596714\",\"name\":\"H. Shin\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2694281\",\"name\":\"Alexandre Kaspar\"},{\"authorId\":\"48857539\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"912fd5d2d83d149707559db832606b91ed912821\",\"title\":\"On Learning Associations of Faces and Voices Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/912fd5d2d83d149707559db832606b91ed912821\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.05830\",\"authors\":[{\"authorId\":\"81678900\",\"name\":\"Hyeong-Seok Choi\"},{\"authorId\":\"24100383\",\"name\":\"Chang-Dae Park\"},{\"authorId\":\"34674393\",\"name\":\"K. Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"b44c4d94d2b1ce39ccf94677d69085a3bf5b2ff3\",\"title\":\"From Inference to Generation: End-to-end Fully Self-supervised Generation of Human Face from Speech\",\"url\":\"https://www.semanticscholar.org/paper/b44c4d94d2b1ce39ccf94677d69085a3bf5b2ff3\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2004.13780\",\"authors\":[{\"authorId\":\"49590274\",\"name\":\"M. Saeed\"},{\"authorId\":\"153756236\",\"name\":\"S. Nawaz\"},{\"authorId\":\"1389596256\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"8955013\",\"name\":\"A. D. Bue\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"98ae5913e9b5de1225076bbdf27bb7173cd3a07e\",\"title\":\"Cross-modal Speaker Verification and Recognition: A Multilingual Perspective\",\"url\":\"https://www.semanticscholar.org/paper/98ae5913e9b5de1225076bbdf27bb7173cd3a07e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143712386\",\"name\":\"Nam Le\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1007/s11042-018-6992-3\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"8bd417c5806eeb071c4e480283c618da2f6f49d7\",\"title\":\"Improving speech embedding using crossmodal transfer learning with audio-visual data\",\"url\":\"https://www.semanticscholar.org/paper/8bd417c5806eeb071c4e480283c618da2f6f49d7\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"2004.09476\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"47940821\",\"name\":\"Hang Zhao\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR42600.2020.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b643a7186c08db9f13d7204f6e5e739f97902e71\",\"title\":\"Music Gesture for Visual Sound Separation\",\"url\":\"https://www.semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.03894\",\"authors\":[{\"authorId\":\"1866636284\",\"name\":\"Ruijie Tao\"},{\"authorId\":\"2127436\",\"name\":\"Rohan Kumar Das\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.21437/interspeech.2020-1814\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7232c88607067648ec726caaa4c02f58a9808424\",\"title\":\"Audio-Visual Speaker Recognition with a Cross-Modal Discriminative Network\",\"url\":\"https://www.semanticscholar.org/paper/7232c88607067648ec726caaa4c02f58a9808424\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9407523\",\"name\":\"Yaxiong Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"},{\"authorId\":\"145720713\",\"name\":\"Shuai Wang\"}],\"doi\":\"10.1109/TGRS.2020.2979273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e27873bd45b8b3206127fce377c62576068963b2\",\"title\":\"Deep Cross-Modal Image\\u2013Voice Retrieval in Remote Sensing\",\"url\":\"https://www.semanticscholar.org/paper/e27873bd45b8b3206127fce377c62576068963b2\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11614724\",\"name\":\"Chris Xiaoxuan Lu\"},{\"authorId\":\"3466717\",\"name\":\"Yuanbo Xiangli\"},{\"authorId\":\"2828083\",\"name\":\"P. Zhao\"},{\"authorId\":\"48240322\",\"name\":\"Changhao Chen\"},{\"authorId\":\"112852965\",\"name\":\"N. Trigoni\"},{\"authorId\":\"34401562\",\"name\":\"A. Markham\"}],\"doi\":\"10.1109/JIOT.2019.2926645\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7eb2f9ddbc238bcae13a90162cd92b6a6c88dcd2\",\"title\":\"Autonomous Learning of Speaker Identity and WiFi Geofence From Noisy Sensor Data\",\"url\":\"https://www.semanticscholar.org/paper/7eb2f9ddbc238bcae13a90162cd92b6a6c88dcd2\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7180730\",\"name\":\"Shota Horiguchi\"},{\"authorId\":\"1833359\",\"name\":\"N. Kanda\"},{\"authorId\":\"2694044\",\"name\":\"K. Nagamatsu\"}],\"doi\":\"10.1145/3240508.3240601\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b4da93fbdf7ae520fa00d39ffa694e850b85162\",\"title\":\"Face-Voice Matching using Cross-modal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/3b4da93fbdf7ae520fa00d39ffa694e850b85162\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1379495741\",\"name\":\"Do Hoang Nam Le\"}],\"doi\":\"10.5075/EPFL-THESIS-9442\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"925fca48b3db9bdc770835e8389b4ee2be383c0c\",\"title\":\"Multimodal person recognition in audio-visual streams\",\"url\":\"https://www.semanticscholar.org/paper/925fca48b3db9bdc770835e8389b4ee2be383c0c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98498116\",\"name\":\"S. Chen\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1109/ICCV.2019.00127\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45b967283dd8e3732284387b36ed5e38a3aed0ff\",\"title\":\"Attention-Based Autism Spectrum Disorder Screening With Privileged Modality\",\"url\":\"https://www.semanticscholar.org/paper/45b967283dd8e3732284387b36ed5e38a3aed0ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1905.04717\",\"authors\":[{\"authorId\":\"145743106\",\"name\":\"A. Ross\"},{\"authorId\":\"9273341\",\"name\":\"Sudipta Banerjee\"},{\"authorId\":\"1751335\",\"name\":\"Cunjian Chen\"},{\"authorId\":\"39617163\",\"name\":\"A. Chowdhury\"},{\"authorId\":\"5456235\",\"name\":\"V. Mirjalili\"},{\"authorId\":\"49620396\",\"name\":\"R. Sharma\"},{\"authorId\":\"3153117\",\"name\":\"Thomas Swearingen\"},{\"authorId\":\"3382857\",\"name\":\"S. Yadav\"}],\"doi\":\"10.1109/ICB45273.2019.8987307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc6ef43c8b806f0777822e2a6989f8807d347e35\",\"title\":\"Some Research Problems in Biometrics: The Future Beckons\",\"url\":\"https://www.semanticscholar.org/paper/fc6ef43c8b806f0777822e2a6989f8807d347e35\",\"venue\":\"2019 International Conference on Biometrics (ICB)\",\"year\":2019},{\"arxivId\":\"1807.07860\",\"authors\":[{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"40457380\",\"name\":\"Y. Liu\"},{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1816f98e2a4dd54690c2689cf529699d8843e847\",\"title\":\"Talking Face Generation by Adversarially Disentangled Audio-Visual Representation\",\"url\":\"https://www.semanticscholar.org/paper/1816f98e2a4dd54690c2689cf529699d8843e847\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2005.13291\",\"authors\":[{\"authorId\":\"153940581\",\"name\":\"Andrew Allan Port\"},{\"authorId\":\"39432093\",\"name\":\"Chelhwon Kim\"},{\"authorId\":\"143794743\",\"name\":\"M. Patel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed446fcbfc1d70a987aeb8020be48163e0fb05b7\",\"title\":\"Earballs: Neural Transmodal Translation\",\"url\":\"https://www.semanticscholar.org/paper/ed446fcbfc1d70a987aeb8020be48163e0fb05b7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66227056\",\"name\":\"M. Guo\"},{\"authorId\":\"2035796\",\"name\":\"C. Zhou\"},{\"authorId\":\"49721726\",\"name\":\"Jiahang Liu\"}],\"doi\":\"10.1109/JSTARS.2019.2949220\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db38673271d01e83d915053f64eb058b94141c9f\",\"title\":\"Jointly Learning of Visual and Auditory: A New Approach for RS Image and Audio Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/db38673271d01e83d915053f64eb058b94141c9f\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2019},{\"arxivId\":\"1911.09338\",\"authors\":[{\"authorId\":\"1422036044\",\"name\":\"Chuyuan Xiong\"},{\"authorId\":\"14701544\",\"name\":\"De-yuan Zhang\"},{\"authorId\":\"144018867\",\"name\":\"Tao Liu\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"19fdaeff329c54bcffaf2e858d5a2584c229cb64\",\"title\":\"Voice-Face Cross-modal Matching and Retrieval: A Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/19fdaeff329c54bcffaf2e858d5a2584c229cb64\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40035527\",\"name\":\"C. McGinn\"},{\"authorId\":\"144317088\",\"name\":\"I. Torre\"}],\"doi\":\"10.1109/HRI.2019.8673305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7819a33496cb315dd32d720fcaa3499fde05efb8\",\"title\":\"Can you Tell the Robot by the Voice? An Exploratory Study on the Role of Voice in the Perception of Robots\",\"url\":\"https://www.semanticscholar.org/paper/7819a33496cb315dd32d720fcaa3499fde05efb8\",\"venue\":\"2019 14th ACM/IEEE International Conference on Human-Robot Interaction (HRI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26300682\",\"name\":\"N. Pokhriyal\"},{\"authorId\":\"1723877\",\"name\":\"V. Govindaraju\"}],\"doi\":\"10.1109/ACCESS.2020.3014188\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d88daa04d950b174da19fe210170a5ac6117df51\",\"title\":\"Learning Discriminative Factorized Subspaces With Application to Touchscreen Biometrics\",\"url\":\"https://www.semanticscholar.org/paper/d88daa04d950b174da19fe210170a5ac6117df51\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1811.10813\",\"authors\":[{\"authorId\":\"2927349\",\"name\":\"S. Shon\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.1109/ICASSP.2019.8683477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac545258eb99e8ee83787903ce74b37cddf00e4e\",\"title\":\"Noise-tolerant Audio-visual Online Person Verification Using an Attention-based Neural Network Fusion\",\"url\":\"https://www.semanticscholar.org/paper/ac545258eb99e8ee83787903ce74b37cddf00e4e\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798291\",\"name\":\"Hang Zhou\"},{\"authorId\":\"40457380\",\"name\":\"Yu Liu\"},{\"authorId\":\"3243969\",\"name\":\"Ziwei Liu\"},{\"authorId\":\"144389949\",\"name\":\"Ping Luo\"},{\"authorId\":\"31843833\",\"name\":\"Xiaogang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c79a853f7beb5726506c358b5fd1a1b7ce12aac\",\"title\":\"Word ID Person ID pid information audio wid information visual wid information wid information wid adversarial against pid pid adversarial against wid wid\",\"url\":\"https://www.semanticscholar.org/paper/9c79a853f7beb5726506c358b5fd1a1b7ce12aac\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"48380309\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"36217631\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67e733b987eb508fdaa60746bf0f5ed4ad192dbe\",\"title\":\"Grounding Spoken Words in Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/67e733b987eb508fdaa60746bf0f5ed4ad192dbe\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.05561\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1145/3240508.3240578\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"540831094fd9b80469c8dacb9320b7e342b50e03\",\"title\":\"Emotion Recognition in Speech using Cross-Modal Transfer in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/540831094fd9b80469c8dacb9320b7e342b50e03\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2007.14509\",\"authors\":[{\"authorId\":\"4056993\",\"name\":\"J. P. Robinson\"},{\"authorId\":\"29693602\",\"name\":\"Z. Khan\"},{\"authorId\":\"49546023\",\"name\":\"Yu Yin\"},{\"authorId\":\"14580705\",\"name\":\"M. Shao\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7d70e168bc43e3df1d625068b60a10779f5f7fe\",\"title\":\"Families In Wild Multimedia (FIW-MM): A Multi-Modal Database for Recognizing Kinship\",\"url\":\"https://www.semanticscholar.org/paper/c7d70e168bc43e3df1d625068b60a10779f5f7fe\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":4559198,\"doi\":\"10.1109/CVPR.2018.00879\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":12,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"2c75658b080a9baaac20db39af86016ffa36f6f0\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3188342\",\"name\":\"Omkar M. Parkhi\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.29.41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"162ea969d1929ed180cc6de9f0bf116993ff6e06\",\"title\":\"Deep Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/162ea969d1929ed180cc6de9f0bf116993ff6e06\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"Andrej Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2867206\",\"name\":\"H. E. \\u00c7eting\\u00fcl\"},{\"authorId\":\"1696666\",\"name\":\"Y. Yemez\"},{\"authorId\":\"1749677\",\"name\":\"E. Erzin\"},{\"authorId\":\"1747853\",\"name\":\"A. Tekalp\"}],\"doi\":\"10.1109/ICASSP.2005.1415162\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a09b054bfa90dfc636bd9830317ad33c6bde29d8\",\"title\":\"Robust lip-motion features for speaker identification\",\"url\":\"https://www.semanticscholar.org/paper/a09b054bfa90dfc636bd9830317ad33c6bde29d8\",\"venue\":\"Proceedings. (ICASSP '05). IEEE International Conference on Acoustics, Speech, and Signal Processing, 2005.\",\"year\":2005},{\"arxivId\":\"1502.06108\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"title\":\"Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks\",\"url\":\"https://www.semanticscholar.org/paper/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1764761\",\"name\":\"K. Chatfield\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.5244/C.25.76\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b7908f71188b89adf62ce9126a0466e1a34338f\",\"title\":\"The devil is in the details: an evaluation of recent feature encoding methods\",\"url\":\"https://www.semanticscholar.org/paper/7b7908f71188b89adf62ce9126a0466e1a34338f\",\"venue\":\"BMVC\",\"year\":2011},{\"arxivId\":\"1406.4773\",\"authors\":[{\"authorId\":\"46675428\",\"name\":\"Y. Sun\"},{\"authorId\":\"123331603\",\"name\":\"Y. Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91bdaf3f1226e4065c4296d5c362906ceadfc631\",\"title\":\"Deep Learning Face Representation by Joint Identification-Verification\",\"url\":\"https://www.semanticscholar.org/paper/91bdaf3f1226e4065c4296d5c362906ceadfc631\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144155856\",\"name\":\"T. Wells\"},{\"authorId\":\"46285232\",\"name\":\"Thom Baguley\"},{\"authorId\":\"47315932\",\"name\":\"M. Sergeant\"},{\"authorId\":\"144309635\",\"name\":\"Andrew Dunn\"}],\"doi\":\"10.1007/s10508-012-0054-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef6c9da395415b0e227ec93dbbc6b1bb4f1bdc78\",\"title\":\"Perceptions of Human Attractiveness Comprising Face and Voice Cues\",\"url\":\"https://www.semanticscholar.org/paper/ef6c9da395415b0e227ec93dbbc6b1bb4f1bdc78\",\"venue\":\"Archives of sexual behavior\",\"year\":2013},{\"arxivId\":\"1706.08612\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.21437/Interspeech.2017-950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a26431833b0ea8659ef1d24bff3ac9e56dcfcd0\",\"title\":\"VoxCeleb: A Large-Scale Speaker Identification Dataset\",\"url\":\"https://www.semanticscholar.org/paper/8a26431833b0ea8659ef1d24bff3ac9e56dcfcd0\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3013966\",\"name\":\"L. Lachs\"},{\"authorId\":\"1859196\",\"name\":\"D. Pisoni\"}],\"doi\":\"10.1121/1.1757454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35d94717aa759ef1734ecfd92918e878ede6de35\",\"title\":\"Specification of cross-modal source information in isolated kinematic displays of speech.\",\"url\":\"https://www.semanticscholar.org/paper/35d94717aa759ef1734ecfd92918e878ede6de35\",\"venue\":\"The Journal of the Acoustical Society of America\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143959913\",\"name\":\"E. Khoury\"},{\"authorId\":\"2121764\",\"name\":\"Laurent El Shafey\"},{\"authorId\":\"49872143\",\"name\":\"C. McCool\"},{\"authorId\":\"38636666\",\"name\":\"M. G\\u00fcnther\"},{\"authorId\":\"145607451\",\"name\":\"S. Marcel\"}],\"doi\":\"10.1016/j.imavis.2013.10.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3cc38699c402c3cd14a928834a37a9f01b0afd6\",\"title\":\"Bi-modal biometric authentication on mobile phones in challenging conditions\",\"url\":\"https://www.semanticscholar.org/paper/f3cc38699c402c3cd14a928834a37a9f01b0afd6\",\"venue\":\"Image Vis. Comput.\",\"year\":2014},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50473499\",\"name\":\"M. Kamachi\"},{\"authorId\":\"144240600\",\"name\":\"H. Hill\"},{\"authorId\":\"2283386\",\"name\":\"K. Lander\"},{\"authorId\":\"1404217694\",\"name\":\"E. Vatikiotis-Bateson\"}],\"doi\":\"10.1016/j.cub.2003.09.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4d6ee3aed9f5e3f63b1bce29e8706c3c5917dd\",\"title\":\"`Putting the Face to the Voice' Matching Identity across Modality\",\"url\":\"https://www.semanticscholar.org/paper/fd4d6ee3aed9f5e3f63b1bce29e8706c3c5917dd\",\"venue\":\"Current Biology\",\"year\":2003},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153144262\",\"name\":\"H. M. Smith\"}],\"doi\":\"10.3758/s13414-015-1045-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a22c71a446e37283007139a9da366cb1ddb4550\",\"title\":\"Matching novel face and voice identity using static and dynamic facial images\",\"url\":\"https://www.semanticscholar.org/paper/8a22c71a446e37283007139a9da366cb1ddb4550\",\"venue\":\"Attention, perception & psychophysics\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1686341\",\"name\":\"K. Markert\"},{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"}],\"doi\":\"10.5244/C.23.2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a251dac6589a83e0bbcf9bef9a80c21222aeecbb\",\"title\":\"Learning Models for Object Recognition from Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a251dac6589a83e0bbcf9bef9a80c21222aeecbb\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":\"1611.06646\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2017.607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b53a308a41507a2ef2faed78eb48812633e75fb\",\"title\":\"Self-Supervised Video Representation Learning with Odd-One-Out Networks\",\"url\":\"https://www.semanticscholar.org/paper/7b53a308a41507a2ef2faed78eb48812633e75fb\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":\"1512.00596\",\"authors\":[{\"authorId\":\"1397689071\",\"name\":\"Ira Kemelmacher-Shlizerman\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"},{\"authorId\":\"1390583389\",\"name\":\"Daniel Miller\"},{\"authorId\":\"1409192503\",\"name\":\"Evan Brossard\"}],\"doi\":\"10.1109/CVPR.2016.527\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"b3078aac6d5ee5e9edaab58b180360b45f22f436\",\"title\":\"The MegaFace Benchmark: 1 Million Faces for Recognition at Scale\",\"url\":\"https://www.semanticscholar.org/paper/b3078aac6d5ee5e9edaab58b180360b45f22f436\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1707.02749\",\"authors\":[{\"authorId\":\"143712386\",\"name\":\"Nam Le\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1109/ICCVW.2017.58\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"45a7c02c88b6434761f87df01ae71a3db18191b7\",\"title\":\"Improving Speaker Turn Embedding by Crossmodal Transfer Learning from Face Embedding\",\"url\":\"https://www.semanticscholar.org/paper/45a7c02c88b6434761f87df01ae71a3db18191b7\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.1109/ICCV.2013.211\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"title\":\"Learning the Visual Interpretation of Sentences\",\"url\":\"https://www.semanticscholar.org/paper/6c39f56c3c21c3972c362f8e752be57a50c41f4f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2867206\",\"name\":\"H. E. \\u00c7eting\\u00fcl\"},{\"authorId\":\"1749677\",\"name\":\"E. Erzin\"},{\"authorId\":\"1696666\",\"name\":\"Y. Yemez\"},{\"authorId\":\"1747853\",\"name\":\"A. Tekalp\"}],\"doi\":\"10.1016/j.sigpro.2006.02.045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd58aec0285795fc465c34a65640c679760b13d1\",\"title\":\"Multimodal speaker/speech recognition using lip motion, lip texture and audio\",\"url\":\"https://www.semanticscholar.org/paper/fd58aec0285795fc465c34a65640c679760b13d1\",\"venue\":\"Signal Process.\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-319-54427-4_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87defac1045bfa9af0162cd248d193e9be6eb25b\",\"title\":\"Out of Time: Automated Lip Sync in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/87defac1045bfa9af0162cd248d193e9be6eb25b\",\"venue\":\"ACCV Workshops\",\"year\":2016},{\"arxivId\":\"1610.09003\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/TPAMI.2017.2753232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4162e328aacba376ea95a7654378423e504ca3d\",\"title\":\"Cross-Modal Scene Networks\",\"url\":\"https://www.semanticscholar.org/paper/a4162e328aacba376ea95a7654378423e504ca3d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1705.08168\",\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2017.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"title\":\"Look, Listen and Learn\",\"url\":\"https://www.semanticscholar.org/paper/9b5f696f73c1264ccb8e97d3b738a2342ecd6bee\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283386\",\"name\":\"K. Lander\"},{\"authorId\":\"144240600\",\"name\":\"H. Hill\"},{\"authorId\":\"50473499\",\"name\":\"M. Kamachi\"},{\"authorId\":\"1404217694\",\"name\":\"E. Vatikiotis-Bateson\"}],\"doi\":\"10.1037/0096-1523.33.4.905\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32d1d6b7888cd8d2093a76b11cf1f2355118d455\",\"title\":\"It's not what you say but the way you say it: matching faces and voices.\",\"url\":\"https://www.semanticscholar.org/paper/32d1d6b7888cd8d2093a76b11cf1f2355118d455\",\"venue\":\"Journal of experimental psychology. Human perception and performance\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00507\",\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"145527700\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145561604\",\"name\":\"Jonathan Brandt\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1007/s11263-017-1059-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7361e42c5eb0d5438c4294cc7ea3f9a53d326309\",\"title\":\"Top-Down Neural Attention by Excitation Backprop\",\"url\":\"https://www.semanticscholar.org/paper/7361e42c5eb0d5438c4294cc7ea3f9a53d326309\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Rubin\"},{\"authorId\":null,\"name\":\"E. Vatikiotis-Bateson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ceptions of human attractiveness comprising face and voice cues\",\"url\":\"\",\"venue\":\"Archives of sexual behavior\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48637456\",\"name\":\"H. Yehia\"},{\"authorId\":\"145669976\",\"name\":\"P. Rubin\"},{\"authorId\":\"1402154966\",\"name\":\"E. Vatikiotis-Bateson\"}],\"doi\":\"10.1016/S0167-6393(98)00048-X\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f98d08ac726957c934769993511f26cfa32652e7\",\"title\":\"Quantitative association of vocal-tract and facial behavior\",\"url\":\"https://www.semanticscholar.org/paper/f98d08ac726957c934769993511f26cfa32652e7\",\"venue\":\"Speech Commun.\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48486321\",\"name\":\"David Snyder\"},{\"authorId\":\"1403025001\",\"name\":\"D. Garcia-Romero\"},{\"authorId\":\"47652202\",\"name\":\"D. Povey\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.21437/INTERSPEECH.2017-620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"369728d7576683a25de8890e4bc02fae6132fccb\",\"title\":\"Deep Neural Network Embeddings for Text-Independent Speaker Verification\",\"url\":\"https://www.semanticscholar.org/paper/369728d7576683a25de8890e4bc02fae6132fccb\",\"venue\":\"INTERSPEECH\",\"year\":2017},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346353\",\"name\":\"H. Ouyang\"},{\"authorId\":\"144911707\",\"name\":\"T. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc9188c5ea84a2e881bee9e1832759026b218396\",\"title\":\"A new lip feature representation method for video-based bimodal authentication\",\"url\":\"https://www.semanticscholar.org/paper/bc9188c5ea84a2e881bee9e1832759026b218396\",\"venue\":\"\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143710848\",\"name\":\"A. Roy\"},{\"authorId\":\"145607451\",\"name\":\"S. Marcel\"}],\"doi\":\"10.1109/BTAS.2010.5634477\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8490e01de6272b77c62b82c1af77ad35c82ab0b5\",\"title\":\"Introducing crossmodal biometrics: Person identification from distinct audio & visual streams\",\"url\":\"https://www.semanticscholar.org/paper/8490e01de6272b77c62b82c1af77ad35c82ab0b5\",\"venue\":\"2010 Fourth IEEE International Conference on Biometrics: Theory, Applications and Systems (BTAS)\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6433526\",\"name\":\"H. Hollien\"},{\"authorId\":\"144939125\",\"name\":\"G. Moore\"}],\"doi\":\"10.1044/JSHR.0302.157\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f4bd9fbfa9dd2efc79c2b65e10ea083f7d0bbee\",\"title\":\"Measurements of the Vocal Folds during Changes in Pitch\",\"url\":\"https://www.semanticscholar.org/paper/6f4bd9fbfa9dd2efc79c2b65e10ea083f7d0bbee\",\"venue\":\"\",\"year\":1960},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36160563\",\"name\":\"R. Krauss\"},{\"authorId\":\"32288220\",\"name\":\"R. Freyberg\"},{\"authorId\":\"2313269\",\"name\":\"Ezequiel Morsella\"}],\"doi\":\"10.1016/S0022-1031(02)00510-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6c74f4ceddc27789a6f1c7f0c97e1df095e77e7\",\"title\":\"Inferring speakers\\u2019 physical attributes from their voices\",\"url\":\"https://www.semanticscholar.org/paper/e6c74f4ceddc27789a6f1c7f0c97e1df095e77e7\",\"venue\":\"\",\"year\":2002},{\"arxivId\":\"1601.04920\",\"authors\":[{\"authorId\":\"1746242\",\"name\":\"S. Mallat\"}],\"doi\":\"10.1098/rsta.2015.0203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a0c5a8dcb526350d880fb46629295c9a51f163d\",\"title\":\"Understanding deep convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/1a0c5a8dcb526350d880fb46629295c9a51f163d\",\"venue\":\"Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698208\",\"name\":\"G. Saon\"},{\"authorId\":\"38940652\",\"name\":\"H. Soltau\"},{\"authorId\":\"1713978\",\"name\":\"D. Nahamoo\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"}],\"doi\":\"10.1109/ASRU.2013.6707705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e46a2e57ce37b846bef48d776aeafa16c411681\",\"title\":\"Speaker adaptation of neural network acoustic models using i-vectors\",\"url\":\"https://www.semanticscholar.org/paper/8e46a2e57ce37b846bef48d776aeafa16c411681\",\"venue\":\"2013 IEEE Workshop on Automatic Speech Recognition and Understanding\",\"year\":2013},{\"arxivId\":\"1412.0035\",\"authors\":[{\"authorId\":\"32694028\",\"name\":\"Aravindh Mahendran\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPR.2015.7299155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d790c8fae40357d24813d085fa74a436847fb49\",\"title\":\"Understanding deep image representations by inverting them\",\"url\":\"https://www.semanticscholar.org/paper/4d790c8fae40357d24813d085fa74a436847fb49\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.05358\",\"authors\":[{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"33666044\",\"name\":\"A. Senior\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.367\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"title\":\"Lip Reading Sentences in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/bed6d0097df1e9ac82f789f6da268cdb3dd65bc3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3135554\",\"name\":\"Najim Dehak\"},{\"authorId\":\"143632131\",\"name\":\"P. Kenny\"},{\"authorId\":\"2998680\",\"name\":\"R. Dehak\"},{\"authorId\":\"144712062\",\"name\":\"P. Dumouchel\"},{\"authorId\":\"1739502\",\"name\":\"P. Ouellet\"}],\"doi\":\"10.1109/TASL.2010.2064307\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40e8d23231469e6495d3e06086e64df93e9dcfa0\",\"title\":\"Front-End Factor Analysis for Speaker Verification\",\"url\":\"https://www.semanticscholar.org/paper/40e8d23231469e6495d3e06086e64df93e9dcfa0\",\"venue\":\"IEEE Transactions on Audio, Speech, and Language Processing\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2554769\",\"name\":\"E. Cvejic\"},{\"authorId\":\"1734469\",\"name\":\"Jeesun Kim\"},{\"authorId\":\"46427362\",\"name\":\"C. Davis\"}],\"doi\":\"10.1016/j.cognition.2011.11.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"38a0223f58b159c337445f81544518e00b82bdfe\",\"title\":\"Recognizing prosody across modalities, face areas and speakers: Examining perceivers\\u2019 sensitivity to variable realizations of visual prosody\",\"url\":\"https://www.semanticscholar.org/paper/38a0223f58b159c337445f81544518e00b82bdfe\",\"venue\":\"Cognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47246616\",\"name\":\"R. Brunelli\"},{\"authorId\":\"1723503\",\"name\":\"D. Falavigna\"}],\"doi\":\"10.1109/34.464560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34d605dabf6c2935f0d3001b9dd8c3ec36f95138\",\"title\":\"Person identification using multiple cues\",\"url\":\"https://www.semanticscholar.org/paper/34d605dabf6c2935f0d3001b9dd8c3ec36f95138\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":1995},{\"arxivId\":\"1610.09001\",\"authors\":[{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"title\":\"SoundNet: Learning Sound Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/7ab8d3af6f78f9c9f64a2f2d38471401ad0988a9\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153144262\",\"name\":\"H. M. Smith\"},{\"authorId\":\"82812708\",\"name\":\"Andrew K. Dunn\"},{\"authorId\":\"46285232\",\"name\":\"Thom Baguley\"},{\"authorId\":\"4067849\",\"name\":\"Paula C. Stacey\"}],\"doi\":\"10.1177/1474704916630317\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4678611caa2c0fdcacbcb8ddc2f574e29126afbf\",\"title\":\"Concordant Cues in Faces and Voices\",\"url\":\"https://www.semanticscholar.org/paper/4678611caa2c0fdcacbcb8ddc2f574e29126afbf\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152517923\",\"name\":\"L. Rosenblum\"},{\"authorId\":\"152406351\",\"name\":\"Nicolas M. Smith\"},{\"authorId\":\"153848761\",\"name\":\"Sarah M. Nichols\"},{\"authorId\":\"46939562\",\"name\":\"S. Hale\"},{\"authorId\":\"102523461\",\"name\":\"J. Lee\"}],\"doi\":\"10.3758/BF03193658\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcb03d7bb50966d6d26143094f0d27edf18df1e6\",\"title\":\"Hearing a face: Cross-modal speaker matching using isolated visible speech\",\"url\":\"https://www.semanticscholar.org/paper/bcb03d7bb50966d6d26143094f0d27edf18df1e6\",\"venue\":\"Perception & psychophysics\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11538011\",\"name\":\"Randy Thornhill\"},{\"authorId\":\"1932721391\",\"name\":\"ANDERS PAPE M\\u00f8ller\"}],\"doi\":\"10.1111/j.1469-185X.1997.tb00022.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f08f71e936d530b3bcd52d0ba7a267f125d52267\",\"title\":\"DEVELOPMENTAL STABILITY, DISEASE AND MEDICINE\",\"url\":\"https://www.semanticscholar.org/paper/f08f71e936d530b3bcd52d0ba7a267f125d52267\",\"venue\":\"Biological reviews of the Cambridge Philosophical Society\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"},{\"authorId\":\"145962204\",\"name\":\"M. Pietik\\u00e4inen\"}],\"doi\":\"10.1007/978-3-642-39094-4_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6b352f861eab170c22d7d9e7d2b876e1b94d67a\",\"title\":\"Visual Speaker Identification with Spatiotemporal Directional Features\",\"url\":\"https://www.semanticscholar.org/paper/a6b352f861eab170c22d7d9e7d2b876e1b94d67a\",\"venue\":\"ICIAR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3329542\",\"name\":\"S. M. Sheffert\"},{\"authorId\":\"39569469\",\"name\":\"E. Olson\"}],\"doi\":\"10.3758/BF03194884\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b916110c0440d49289b733cc9526213dd6e5fee\",\"title\":\"Audiovisual speech facilitates voice learning\",\"url\":\"https://www.semanticscholar.org/paper/3b916110c0440d49289b733cc9526213dd6e5fee\",\"venue\":\"Perception & psychophysics\",\"year\":2004},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Seeing Voices and Hearing Faces: Cross-Modal Biometric Matching\",\"topics\":[{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Biometrics\",\"topicId\":\"3710\",\"url\":\"https://www.semanticscholar.org/topic/3710\"},{\"topic\":\"Dynamic testing\",\"topicId\":\"521162\",\"url\":\"https://www.semanticscholar.org/topic/521162\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Eclipse\",\"topicId\":\"91965\",\"url\":\"https://www.semanticscholar.org/topic/91965\"},{\"topic\":\"Facial recognition system\",\"topicId\":\"30847\",\"url\":\"https://www.semanticscholar.org/topic/30847\"},{\"topic\":\"Speaker recognition\",\"topicId\":\"3974\",\"url\":\"https://www.semanticscholar.org/topic/3974\"},{\"topic\":\"Static program analysis\",\"topicId\":\"31857\",\"url\":\"https://www.semanticscholar.org/topic/31857\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Bitwise operation\",\"topicId\":\"296233\",\"url\":\"https://www.semanticscholar.org/topic/296233\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"ERIKA Enterprise\",\"topicId\":\"1810688\",\"url\":\"https://www.semanticscholar.org/topic/1810688\"},{\"topic\":\"LU decomposition\",\"topicId\":\"112169\",\"url\":\"https://www.semanticscholar.org/topic/112169\"},{\"topic\":\"Expectation propagation\",\"topicId\":\"527411\",\"url\":\"https://www.semanticscholar.org/topic/527411\"}],\"url\":\"https://www.semanticscholar.org/paper/2c75658b080a9baaac20db39af86016ffa36f6f0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"