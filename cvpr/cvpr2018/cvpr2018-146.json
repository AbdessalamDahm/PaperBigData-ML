"{\"abstract\":\"Most image captioning models focus on one-line (single image) captioning, where the correlations like relevance and diversity among group images (e.g., within the same album or event) are simply neglected, resulting in less accurate and diverse captions. Recent works mainly consider imposing the diversity during the online inference only, which neglect the correlation among visual structures in offline training. In this paper, we propose a novel group-based image captioning scheme (termed GroupCap), which jointly models the structured relevance and diversity among group images towards an optimal collaborative captioning. In particular, we first propose a visual tree parser (VP-Tree) to construct the structured semantic correlations within individual images. Then, the relevance and diversity among images are well modeled by exploiting the correlations among their tree structures. Finally, such correlations are modeled as constraints and sent into the LSTM-based captioning generator. We adopt an end-to-end formulation to train the visual tree parser, the structured relevance and diversity constraints, as well as the LSTM based captioning model jointly. To facilitate quantitative evaluation, we further release two group captioning datasets derived from the MS-COCO benchmark, serving as the first of their kind. Quantitative results show that the proposed GroupCap model outperforms the state-of-the-art and alternative approaches.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\",\"url\":\"https://www.semanticscholar.org/author/2642638\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\",\"url\":\"https://www.semanticscholar.org/author/145592290\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\",\"url\":\"https://www.semanticscholar.org/author/1759841\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\",\"url\":\"https://www.semanticscholar.org/author/47096329\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\",\"url\":\"https://www.semanticscholar.org/author/34739384\"}],\"citationVelocity\":11,\"citations\":[{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.09727\",\"authors\":[{\"authorId\":\"39367903\",\"name\":\"Mohammad K. Ebrahimpour\"},{\"authorId\":\"3259825\",\"name\":\"Jiayun Li\"},{\"authorId\":\"1915432\",\"name\":\"Yen-Yun Yu\"},{\"authorId\":\"80106900\",\"name\":\"Jackson Reesee\"},{\"authorId\":\"33129821\",\"name\":\"Azadeh Moghtaderi\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"145042542\",\"name\":\"D. Noelle\"}],\"doi\":\"10.1109/WACV.2019.00110\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03bc1c0c2877fc87b86f6c0a385c47676c17836e\",\"title\":\"Ventral-Dorsal Neural Networks: Object Detection Via Selective Attention\",\"url\":\"https://www.semanticscholar.org/paper/03bc1c0c2877fc87b86f6c0a385c47676c17836e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.05942\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"title\":\"Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning\",\"url\":\"https://www.semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"153017460\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":null,\"name\":\"Yan Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"title\":\"Variational Structured Semantic Inference for Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1903.05854\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"49050705\",\"name\":\"J. Zhang\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.00160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb\",\"title\":\"MirrorGAN: Learning Text-To-Image Generation by Redescription\",\"url\":\"https://www.semanticscholar.org/paper/5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1431726865\",\"name\":\"R. SreelaS.\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.3390/info10110354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"title\":\"Dense Model for Automatic Image Description Generation with Game Theoretic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":\"2005.07787\",\"authors\":[{\"authorId\":\"39367903\",\"name\":\"Mohammad K. Ebrahimpour\"},{\"authorId\":\"82468335\",\"name\":\"J. Falandays\"},{\"authorId\":\"3363025\",\"name\":\"S. Spevack\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"145042542\",\"name\":\"D. Noelle\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207407\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2be092bb21e1ce1e757c4c4158d8cd282c1111d\",\"title\":\"WW-Nets: Dual Neural Networks for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/d2be092bb21e1ce1e757c4c4158d8cd282c1111d\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134518946\",\"name\":\"Nanxing Li\"},{\"authorId\":\"50678073\",\"name\":\"Bei Liu\"},{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"}],\"doi\":\"10.1145/3323873.3325050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"title\":\"Emotion Reinforced Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/426ce52b0c4ac73e6226c532d4d8a2171f12e9fb\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145441561\",\"name\":\"W. Cui\"},{\"authorId\":\"49451360\",\"name\":\"Fei Wang\"},{\"authorId\":\"144258396\",\"name\":\"X. He\"},{\"authorId\":\"29090447\",\"name\":\"D. Zhang\"},{\"authorId\":\"122135929\",\"name\":\"Xuxiang Xu\"},{\"authorId\":\"144817588\",\"name\":\"Meng Yao\"},{\"authorId\":\"72682876\",\"name\":\"Z. Wang\"},{\"authorId\":\"1955707\",\"name\":\"Jiejun Huang\"}],\"doi\":\"10.3390/RS11091044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75b0a1264b5ba0202ee3e81b89d7e9f0042c3744\",\"title\":\"Multi-Scale Semantic Segmentation and Spatial Relationship Recognition of Remote Sensing Images Based on an Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/75b0a1264b5ba0202ee3e81b89d7e9f0042c3744\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"1908.04919\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"58a77455b1c38afe1eab4bec664bd866eba1573d\",\"title\":\"Towards Diverse and Accurate Image Captions via Reinforcing Determinantal Point Process\",\"url\":\"https://www.semanticscholar.org/paper/58a77455b1c38afe1eab4bec664bd866eba1573d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"143648909\",\"name\":\"C. Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/ICME.2019.00069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"title\":\"Colloquial Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400258083\",\"name\":\"Chunpu Xu\"},{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"31991405\",\"name\":\"Min Yang\"},{\"authorId\":\"2441161\",\"name\":\"Xiang Ao\"},{\"authorId\":\"1405918472\",\"name\":\"Wangrong Cheng\"},{\"authorId\":\"1936983\",\"name\":\"J. Tian\"}],\"doi\":\"10.1145/3357384.3358105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e81c97c18cb4f4922e4442664350350536a71a13\",\"title\":\"A Unified Generation-Retrieval Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e81c97c18cb4f4922e4442664350350536a71a13\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013546\",\"name\":\"B. Wang\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"1930660\",\"name\":\"Bo Qu\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/JSTARS.2019.2959208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fbdb53c100005ac890989beb3d78e208ba9acda\",\"title\":\"Retrieval Topic Recurrent Memory Network for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fbdb53c100005ac890989beb3d78e208ba9acda\",\"venue\":\"IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing\",\"year\":2020},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2010.14551\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"25576460\",\"name\":\"Ruth C. Fong\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b796497f350d15bd47d06cb4794bad15a149a72\",\"title\":\"Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b796497f350d15bd47d06cb4794bad15a149a72\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510776185\",\"name\":\"Bingning Li\"},{\"authorId\":\"145657495\",\"name\":\"Chi Zhang\"},{\"authorId\":\"1787856\",\"name\":\"Wei Pei\"},{\"authorId\":\"48491394\",\"name\":\"Liang Shen\"}],\"doi\":\"10.1007/978-981-15-8462-6_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f930a604e75b0a0dc49dd801bb775a76c8b57216\",\"title\":\"Design of ISAR Image Annotation System Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/f930a604e75b0a0dc49dd801bb775a76c8b57216\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2010.03855\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"title\":\"Dense Relational Image Captioning via Multi-task Triple-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.04983\",\"authors\":[{\"authorId\":\"145746402\",\"name\":\"X. Jin\"},{\"authorId\":\"2688093\",\"name\":\"Le Wu\"},{\"authorId\":\"143681906\",\"name\":\"Geng Zhao\"},{\"authorId\":\"47057319\",\"name\":\"X. Li\"},{\"authorId\":\"1391223326\",\"name\":\"Xiaokun Zhang\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":\"145314008\",\"name\":\"Bin Zhou\"},{\"authorId\":\"51197465\",\"name\":\"Xinghui Zhou\"}],\"doi\":\"10.1145/3343031.3350970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e79423b5e216151ce0cdf615a7098666d9d9c07e\",\"title\":\"Aesthetic Attributes Assessment of Images\",\"url\":\"https://www.semanticscholar.org/paper/e79423b5e216151ce0cdf615a7098666d9d9c07e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2012.07333\",\"authors\":[{\"authorId\":\"1733071048\",\"name\":\"Chao Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7212df671c50beb567e3d3d608b0c14405c40e3\",\"title\":\"Intrinsic Image Captioning Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7212df671c50beb567e3d3d608b0c14405c40e3\",\"venue\":\"\",\"year\":2020}],\"corpusId\":52830169,\"doi\":\"10.1109/CVPR.2018.00146\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"2115fe369b3a6b859c6992ba023d5c11b1689801\",\"references\":[{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.00525\",\"authors\":[{\"authorId\":\"3081378\",\"name\":\"Varun K. Nagaraja\"},{\"authorId\":\"2852035\",\"name\":\"V. Morariu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1007/978-3-319-46493-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"title\":\"Modeling Context Between Objects for Referring Expression Understanding\",\"url\":\"https://www.semanticscholar.org/paper/86eef3a1dff2bd2808847358cdb7f5ba2b7e0214\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803066\",\"name\":\"A. Sadovnik\"},{\"authorId\":\"3437467\",\"name\":\"Yi-I Chiu\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"2331213\",\"name\":\"S. Edelman\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/CVPR.2012.6248003\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d632b8ca64f804a02e9bcf4b3bd9cf3caba0fa9\",\"title\":\"Image description with a goal: Building efficient discriminating expressions for images\",\"url\":\"https://www.semanticscholar.org/paper/9d632b8ca64f804a02e9bcf4b3bd9cf3caba0fa9\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1504.06692\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"144287022\",\"name\":\"Xu Wei\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"152924551\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb847564774394c484e701437dbcffbf040ff3cc\",\"title\":\"Learning Like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images\",\"url\":\"https://www.semanticscholar.org/paper/eb847564774394c484e701437dbcffbf040ff3cc\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2585821\",\"name\":\"Cliff Chiung-Yu Lin\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c0ddf74f87d154db88d79c640578c1610451eec\",\"title\":\"Parsing Natural Scenes and Natural Language with Recursive Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c0ddf74f87d154db88d79c640578c1610451eec\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"cs/0205028\",\"authors\":[{\"authorId\":\"21308992\",\"name\":\"Steven Bird\"}],\"doi\":\"10.3115/1225403.1225421\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01a660ec8aa995a88a00bfb41cb86c022047a9db\",\"title\":\"NLTK: The Natural Language Toolkit\",\"url\":\"https://www.semanticscholar.org/paper/01a660ec8aa995a88a00bfb41cb86c022047a9db\",\"venue\":\"ACL\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"10609538\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1145/3123266.3123275\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"159d16cdc48135632c2d5790e5baaf8d0631f510\",\"title\":\"StructCap: Structured Semantic Embedding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/159d16cdc48135632c2d5790e5baaf8d0631f510\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1612.09542\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2017.375\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5b64709c677c131ec8b7846d3493df53987fa6f\",\"title\":\"A Joint Speaker-Listener-Reinforcer Model for Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/a5b64709c677c131ec8b7846d3493df53987fa6f\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/CVPR.2017.345\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3006072\",\"name\":\"Sahar Kazemzadeh\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"32215032\",\"name\":\"Mark Matten\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3115/v1/D14-1086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c141447f51b6732242376164ff961e464731c8\",\"title\":\"ReferItGame: Referring to Objects in Photographs of Natural Scenes\",\"url\":\"https://www.semanticscholar.org/paper/92c141447f51b6732242376164ff961e464731c8\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.05490\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2017.443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"title\":\"Semantic Regularisation for Recurrent Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/12f523745a3605314e8ea1dc03f29c5a20a2549e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1701.03439\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2017.333\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b45e9a40313096abf530df3b98a1dfa1553f17b\",\"title\":\"Comprehension-Guided Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/9b45e9a40313096abf530df3b98a1dfa1553f17b\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1701.02870\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1109/CVPR.2017.120\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e782437503f2a24fd1a836a434da395bf15c88c2\",\"title\":\"Context-Aware Captions from Context-Agnostic Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e782437503f2a24fd1a836a434da395bf15c88c2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1704.06485\",\"authors\":[{\"authorId\":\"47465525\",\"name\":\"Cesc Chunseong Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"title\":\"Attend to You: Personalized Image Captioning with Context Sequence Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/9d842c2fb5a0c54f15bc4e45c7c93bdb8b0c44de\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.05594\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1406012647\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"104757141\",\"name\":\"Jian Shao\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/CVPR.2017.667\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88513e738a95840de05a62f0e43d30a67b3c542e\",\"title\":\"SCA-CNN: Spatial and Channel-Wise Attention in Convolutional Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88513e738a95840de05a62f0e43d30a67b3c542e\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Rongrong Ji\"},{\"authorId\":null,\"name\":\"Jinsong Su\"},{\"authorId\":null,\"name\":\"Yongjian Wu\"},{\"authorId\":null,\"name\":\"Yunsheng Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Berg . A joint speaker - listener - reinforcer model for referring expressions Comprehension - guided referring expressions\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.02283\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"3317152\",\"name\":\"Oana-Maria Camburu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1109/CVPR.2016.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e65142010431ffc089b272a1174214e00693e503\",\"title\":\"Generation and Comprehension of Unambiguous Object Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/e65142010431ffc089b272a1174214e00693e503\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3090304\",\"name\":\"Zhuhao Wang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"1776903\",\"name\":\"Weiming Lu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"38979129\",\"name\":\"Xi Li\"},{\"authorId\":\"3431212\",\"name\":\"Zitong Zhang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e55283e6eb3f0f9db07cf1b20e0de8d5aac10e\",\"title\":\"Diverse Image Captioning via GroupTalk\",\"url\":\"https://www.semanticscholar.org/paper/39e55283e6eb3f0f9db07cf1b20e0de8d5aac10e\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803066\",\"name\":\"A. Sadovnik\"},{\"authorId\":\"50716462\",\"name\":\"A. Gallagher\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/CVPRW.2013.47\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a12539c70600fcce83ba3709cb27cf7701ff09b\",\"title\":\"Not Everybody's Special: Using Neighbors in Referring Expressions with Uncertain Attributes\",\"url\":\"https://www.semanticscholar.org/paper/9a12539c70600fcce83ba3709cb27cf7701ff09b\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2013},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.09978\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/CVPR.2017.470\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"title\":\"Modeling Relationships in Referential Expressions with Compositional Modular Networks\",\"url\":\"https://www.semanticscholar.org/paper/ce264a4e1490e959d84ddd60edbb0edcbfb3af38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}],\"title\":\"GroupCap: Group-Based Image Captioning with Structured Relevance and Diversity Constraints\",\"topics\":[{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Parsing\",\"topicId\":\"1910\",\"url\":\"https://www.semanticscholar.org/topic/1910\"},{\"topic\":\"Tree structure\",\"topicId\":\"1356\",\"url\":\"https://www.semanticscholar.org/topic/1356\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Online and offline\",\"topicId\":\"12094\",\"url\":\"https://www.semanticscholar.org/topic/12094\"},{\"topic\":\"Discriminative model\",\"topicId\":\"39987\",\"url\":\"https://www.semanticscholar.org/topic/39987\"},{\"topic\":\"Autostereogram\",\"topicId\":\"99453\",\"url\":\"https://www.semanticscholar.org/topic/99453\"},{\"topic\":\"Entity\",\"topicId\":\"6664\",\"url\":\"https://www.semanticscholar.org/topic/6664\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Vantage-point tree\",\"topicId\":\"1263771\",\"url\":\"https://www.semanticscholar.org/topic/1263771\"}],\"url\":\"https://www.semanticscholar.org/paper/2115fe369b3a6b859c6992ba023d5c11b1689801\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"