"{\"abstract\":\"A number of studies have found that today's Visual Question Answering (VQA) models are heavily driven by superficial correlations in the training data and lack sufficient image grounding. To encourage development of models geared towards the latter, we propose a new setting for VQA where for every question type, train and test sets have different prior distributions of answers. Specifically, we present new splits of the VQA v1 and VQA v2 datasets, which we call Visual Question Answering under Changing Priors (VQA-CP v1 and VQA-CP v2 respectively). First, we evaluate several existing VQA models under this new setting and show that their performance degrades significantly compared to the original VQA setting. Second, we propose a novel Grounded Visual Question Answering model (GVQA) that contains inductive biases and restrictions in the architecture specifically designed to prevent the model from 'cheating' by primarily relying on priors in the training data. Specifically, GVQA explicitly disentangles the recognition of visual concepts present in the image from the identification of plausible answer space for a given question, enabling the model to more robustly generalize across different distributions of answers. GVQA is built off an existing VQA model - Stacked Attention Networks (SAN). Our experiments demonstrate that GVQA significantly outperforms SAN on both VQA-CP v1 and VQA-CP v2 datasets. Interestingly, it also outperforms more powerful VQA models such as Multimodal Compact Bilinear Pooling (MCB) in several cases. GVQA offers strengths complementary to SAN when trained and evaluated on the original VQA v1 and VQA v2 datasets. Finally, GVQA is more transparent and interpretable than existing VQA models.\",\"arxivId\":\"1712.00377\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\",\"url\":\"https://www.semanticscholar.org/author/2801949\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/1746610\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\",\"url\":\"https://www.semanticscholar.org/author/2684226\"}],\"citationVelocity\":56,\"citations\":[{\"arxivId\":\"2012.09392\",\"authors\":[{\"authorId\":\"13816392\",\"name\":\"S. J. Moon\"},{\"authorId\":\"9962692\",\"name\":\"Sangwoo Mo\"},{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"48173961\",\"name\":\"Jaeho Lee\"},{\"authorId\":\"143720148\",\"name\":\"Jinwoo Shin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdfe6051558414589f8b8b2e0fea596833e845bb\",\"title\":\"MASKER: Masked Keyword Regularization for Reliable Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/bdfe6051558414589f8b8b2e0fea596833e845bb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1908.02660\",\"authors\":[{\"authorId\":\"150180131\",\"name\":\"Kaiyu Yang\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"145124903\",\"name\":\"J. Deng\"}],\"doi\":\"10.1109/ICCV.2019.00214\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"title\":\"SpatialSense: An Adversarially Crowdsourced Benchmark for Spatial Relation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d738fa77de08592d9b77754e48cc63e276e5c0d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.02806\",\"authors\":[{\"authorId\":\"41019737\",\"name\":\"Hyojin Bahng\"},{\"authorId\":\"2647582\",\"name\":\"Sanghyuk Chun\"},{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4f3f946498e8af471596f89dde2168f87cc9861\",\"title\":\"Learning De-biased Representations with Biased Representations\",\"url\":\"https://www.semanticscholar.org/paper/f4f3f946498e8af471596f89dde2168f87cc9861\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1809.03707\",\"authors\":[{\"authorId\":\"51929143\",\"name\":\"M. Wagner\"},{\"authorId\":\"7005920\",\"name\":\"H. Basevi\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"39956342\",\"name\":\"Wenbin Li\"},{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"1732672\",\"name\":\"A. Leonardis\"}],\"doi\":\"10.1007/978-3-030-11009-3_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"918f122b385c5de709d076063527e850c2666c78\",\"title\":\"Answering Visual What-If Questions: From Actions to Predicted Scene Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/918f122b385c5de709d076063527e850c2666c78\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034270322\",\"name\":\"Liyana Sahir Kallooriyakath\"},{\"authorId\":\"2034269084\",\"name\":\"Jithin M V\"},{\"authorId\":\"81431088\",\"name\":\"B. V\"},{\"authorId\":\"2034269088\",\"name\":\"Adith P P\"}],\"doi\":\"10.1109/ICSTCEE49637.2020.9277374\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea0ab46474037363b0a52b758538e61ccb90ecec\",\"title\":\"Visual Question Answering: Methodologies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/ea0ab46474037363b0a52b758538e61ccb90ecec\",\"venue\":\"2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)\",\"year\":2020},{\"arxivId\":\"1810.10656\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86553974fabf38bbe022dc44794f345339b45c0b\",\"title\":\"Understand, Compose and Respond - Answering Visual Questions by a Composition of Abstract Procedures\",\"url\":\"https://www.semanticscholar.org/paper/86553974fabf38bbe022dc44794f345339b45c0b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.08315\",\"authors\":[{\"authorId\":\"151195783\",\"name\":\"Ruixiang Tang\"},{\"authorId\":\"3432460\",\"name\":\"Mengnan Du\"},{\"authorId\":\"48513905\",\"name\":\"Yuening Li\"},{\"authorId\":\"47781070\",\"name\":\"Zirui Liu\"},{\"authorId\":\"1490483806\",\"name\":\"X. Hu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b239fe63de5de0a1e0c08af97a30f79b5a2bdbc\",\"title\":\"Mitigating Gender Bias in Captioning Systems\",\"url\":\"https://www.semanticscholar.org/paper/0b239fe63de5de0a1e0c08af97a30f79b5a2bdbc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.04166\",\"authors\":[{\"authorId\":\"1887625\",\"name\":\"Yuehua Wu\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TIP.2020.2967584\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866908141e1db5d6b278984072303a0e14423bcc\",\"title\":\"Revisiting EmbodiedQA: A Simple Baseline and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/866908141e1db5d6b278984072303a0e14423bcc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1809.04482\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86e5f81bde496549e9df2b1abdef0879a3135adb\",\"title\":\"The Visual QA Devil in the Details: The Impact of Early Fusion and Batch Norm on CLEVR\",\"url\":\"https://www.semanticscholar.org/paper/86e5f81bde496549e9df2b1abdef0879a3135adb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48289232\",\"name\":\"Mohit Bajaj\"},{\"authorId\":\"49680751\",\"name\":\"Lanjun Wang\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2019.00438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a7bb3c251498a7c700c5f0563a53aea54345653\",\"title\":\"G3raphGround: Graph-Based Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/0a7bb3c251498a7c700c5f0563a53aea54345653\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02962\",\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"title\":\"From Two Graphs to N Questions: A VQA Dataset for Compositional Reasoning on Vision and Commonsense\",\"url\":\"https://www.semanticscholar.org/paper/06b3ecff93bc79a1242b06702f160ffc43c487b9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420608\",\"name\":\"Difei Gao\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"51069511\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/JSTSP.2020.2989701\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b3478e680e957672c4fbc8e1da559588997b325\",\"title\":\"Learning to Recognize Visual Concepts for Visual Question Answering With Structural Label Space\",\"url\":\"https://www.semanticscholar.org/paper/5b3478e680e957672c4fbc8e1da559588997b325\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1905.09998\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7336b10298798985eaa842da38609a3fd0700be3\",\"title\":\"Self-Critical Reasoning for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7336b10298798985eaa842da38609a3fd0700be3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2012.13693\",\"authors\":[{\"authorId\":\"2042334827\",\"name\":\"Sagar Gubbi Venkatesh\"},{\"authorId\":\"152417262\",\"name\":\"A. Biswas\"},{\"authorId\":\"2440327\",\"name\":\"Raviteja Upadrashta\"},{\"authorId\":\"123282453\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"2408872\",\"name\":\"P. Talukdar\"},{\"authorId\":\"1756622\",\"name\":\"B. Amrutur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1bc4e722f1b67d02a1a54ba222258f36062e050\",\"title\":\"Spatial Reasoning from Natural Language Instructions for Robot Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/f1bc4e722f1b67d02a1a54ba222258f36062e050\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35318567\",\"name\":\"Rohan Jha\"},{\"authorId\":\"10727711\",\"name\":\"Charles Lovering\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"237992be146743e9858f8035dbbe92421ff9a889\",\"title\":\"When does data augmentation help generalization in NLP?\",\"url\":\"https://www.semanticscholar.org/paper/237992be146743e9858f8035dbbe92421ff9a889\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04422\",\"authors\":[{\"authorId\":\"1802508687\",\"name\":\"Vatsal Goel\"},{\"authorId\":\"1802505447\",\"name\":\"Mohit Chandak\"},{\"authorId\":\"47583481\",\"name\":\"A. Anand\"},{\"authorId\":\"46401518\",\"name\":\"Prithwijit Guha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"title\":\"IQ-VQA: Intelligent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9adb9a076ae1817fbac0dd258bb4a72027456e6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.06936\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/TPAMI.2018.2880185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8927117cba0d82d59a35f099b47acb291c6567e3\",\"title\":\"Inverse Visual Question Answering: A New Benchmark and VQA Diagnosis Tool\",\"url\":\"https://www.semanticscholar.org/paper/8927117cba0d82d59a35f099b47acb291c6567e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.05726\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7454abbee8f92dd0fd893c8039c03d66e9a5f032\",\"title\":\"Estimating semantic structure for the VQA answer space\",\"url\":\"https://www.semanticscholar.org/paper/7454abbee8f92dd0fd893c8039c03d66e9a5f032\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4009206\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"33201965\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"1410148565\",\"name\":\"Karina Kanjaria\"},{\"authorId\":\"40346984\",\"name\":\"Joy T. Wu\"},{\"authorId\":\"13403287\",\"name\":\"D. Ballah\"},{\"authorId\":\"1388126424\",\"name\":\"Adam Coy\"},{\"authorId\":\"2308391\",\"name\":\"Alexandros Karargyris\"},{\"authorId\":\"2230103\",\"name\":\"Yufan Guo\"},{\"authorId\":\"1768272818\",\"name\":\"David James Beymer\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"},{\"authorId\":\"80257800\",\"name\":\"Vandana Mukherjee\"}],\"doi\":\"10.18653/v1/2020.bionlp-1.6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"title\":\"Towards Visual Dialog for Radiology\",\"url\":\"https://www.semanticscholar.org/paper/6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"venue\":\"BioNLP\",\"year\":2020},{\"arxivId\":\"1904.09067\",\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b42c1eb6a8eadc8d734acd4c1ff1ff0f6b164500\",\"title\":\"Emergence of Compositional Language with Deep Generational Transmission\",\"url\":\"https://www.semanticscholar.org/paper/b42c1eb6a8eadc8d734acd4c1ff1ff0f6b164500\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.07789\",\"authors\":[{\"authorId\":\"1977256\",\"name\":\"V. Manjunatha\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00979\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"title\":\"Explicit Bias Discovery in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/c5d15ab9b3d541e53d0b7743bce99a074698394b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66935500\",\"name\":\"P. Deshmukh\"},{\"authorId\":\"51502239\",\"name\":\"Rani S. Lande\"}],\"doi\":\"10.1109/ICICT48043.2020.9112454\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"title\":\"Convolutional Neural Network based Review System for Automatic Past Event Search using Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":\"1909.03683\",\"authors\":[{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/D19-1418\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba783d92d0eaf6a7bff6ced7660150ce38016bbc\",\"title\":\"Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases\",\"url\":\"https://www.semanticscholar.org/paper/ba783d92d0eaf6a7bff6ced7660150ce38016bbc\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2012.08673\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c8f6878dac0c5c99c192ded715d2e864eed7302\",\"title\":\"A Closer Look at the Robustness of Vision-and-Language Pre-trained Models\",\"url\":\"https://www.semanticscholar.org/paper/3c8f6878dac0c5c99c192ded715d2e864eed7302\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1909.13471\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"title\":\"On Incorporating Semantic Prior Knowlegde in Deep Learning Through Embedding-Space Constraints\",\"url\":\"https://www.semanticscholar.org/paper/1c01573c08b364018fb2f3b5e69a7238b0afd66f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145296409\",\"name\":\"A. Potapov\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"48649198\",\"name\":\"V. Bogdanov\"},{\"authorId\":\"150031580\",\"name\":\"Alexander Scherbatiy\"}],\"doi\":\"10.1007/978-3-030-27005-6_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34b5098b5fc6021059f89247d03ef7e84969b752\",\"title\":\"Cognitive Module Networks for Grounded Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/34b5098b5fc6021059f89247d03ef7e84969b752\",\"venue\":\"AGI\",\"year\":2019},{\"arxivId\":\"1901.03035\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29e13746fa5aed13e51558a521a39aaeaa99c1b1\",\"title\":\"Self-Monitoring Navigation Agent via Auxiliary Progress Estimation\",\"url\":\"https://www.semanticscholar.org/paper/29e13746fa5aed13e51558a521a39aaeaa99c1b1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.07790\",\"authors\":[{\"authorId\":\"1637185408\",\"name\":\"Joe Stacey\"},{\"authorId\":\"3051815\",\"name\":\"Pasquale Minervini\"},{\"authorId\":\"2026652\",\"name\":\"Haim Dubossarsky\"},{\"authorId\":\"48662861\",\"name\":\"Sebastian Riedel\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1def7b029df7d37962fd684ea5ae7a7d7e99491\",\"title\":\"There is Strength in Numbers: Avoiding the Hypothesis-Only Bias in Natural Language Inference via Ensemble Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/a1def7b029df7d37962fd684ea5ae7a7d7e99491\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1912.07538\",\"authors\":[{\"authorId\":\"48189355\",\"name\":\"V. Agarwal\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/cvpr42600.2020.00971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"title\":\"Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing\",\"url\":\"https://www.semanticscholar.org/paper/d9cf8fc0bca131be5aeba5fb64a7393f53cb7e60\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.11059\",\"authors\":[{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I07.7005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"title\":\"Unified Vision-Language Pre-Training for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/088ef8f1bdd733673672a055017ee3dd0e70f2cf\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3449429\",\"name\":\"Alexander Kuhnle\"}],\"doi\":\"10.17863/CAM.49177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04262cb3f76ff769af32afad05263bd47ebef18\",\"title\":\"Evaluating visually grounded language capabilities using microworlds\",\"url\":\"https://www.semanticscholar.org/paper/c04262cb3f76ff769af32afad05263bd47ebef18\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410010039\",\"name\":\"Hao Zhao\"},{\"authorId\":\"123554573\",\"name\":\"M. Lu\"},{\"authorId\":\"1405606408\",\"name\":\"Anbang Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"48571207\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1007/s11263-019-01263-4\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"title\":\"Learning to Draw Sight Lines\",\"url\":\"https://www.semanticscholar.org/paper/5b153c7410571339ff11b3b8d1fdbc54cc832d86\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2002.10215\",\"authors\":[{\"authorId\":\"48631626\",\"name\":\"Xinyu Wang\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"46668045\",\"name\":\"Chun Chet Ng\"},{\"authorId\":\"30099960\",\"name\":\"Canjie Luo\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"46699480\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"35462302\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"title\":\"On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395925001\",\"name\":\"Bj\\u00f6rn Wahle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"title\":\"Grounding semantics in robots for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/79223360b86ed9c8fd64e579be4828fe44b1ce4a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143912737\",\"name\":\"Heather Riley\"},{\"authorId\":\"1714890\",\"name\":\"M. Sridharan\"}],\"doi\":\"10.1145/3284432.3284456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a53ba48dba8dfb2d49e75e1160cee5b3201e020\",\"title\":\"Non-monotonic Logical Reasoning and Deep Learning for Explainable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4a53ba48dba8dfb2d49e75e1160cee5b3201e020\",\"venue\":\"HAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48079662\",\"name\":\"Sungho Park\"},{\"authorId\":\"145864562\",\"name\":\"Sunhee Hwang\"},{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1109/ACCESS.2020.3041503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"title\":\"Fair-VQA: Fairness-Aware Visual Question Answering Through Sensitive Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/958284df0d0eca1b9cb234411aa15940c99e7ce6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.11949\",\"authors\":[{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"1508668394\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"49887423\",\"name\":\"Jiaxin Shi\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00377\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10874b307d89f1ff9e049f2464afa6d91237ce4c\",\"title\":\"Unbiased Scene Graph Generation From Biased Training\",\"url\":\"https://www.semanticscholar.org/paper/10874b307d89f1ff9e049f2464afa6d91237ce4c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.16010\",\"authors\":[{\"authorId\":\"1390575046\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"title\":\"Loss-rescaling VQA: Revisiting Language Prior Problem from a Class-imbalance View\",\"url\":\"https://www.semanticscholar.org/paper/9b9e35875ad771961ad2d35f7b9cd645b96afd04\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.05917\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1007/s11263-020-01295-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e50c32f7244e3556eb879f24b7de8410f3177f6\",\"title\":\"Visual Social Relationship Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e50c32f7244e3556eb879f24b7de8410f3177f6\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2596437\",\"name\":\"S. W. Kim\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffe11e74e99e152964fc64f7387b5a944a76983b\",\"title\":\"Progressive Reasoning by Module Composition\",\"url\":\"https://www.semanticscholar.org/paper/ffe11e74e99e152964fc64f7387b5a944a76983b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.07059\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"title\":\"Accuracy vs. Complexity: A Trade-off in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.08430\",\"authors\":[{\"authorId\":\"35748708\",\"name\":\"Gabriel Grand\"},{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"}],\"doi\":\"10.18653/v1/W19-1801\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"title\":\"Adversarial Regularization for Visual Question Answering: Strengths, Shortcomings, and Side Effects\",\"url\":\"https://www.semanticscholar.org/paper/a25800880aa6905f9cf2fb4e6aef54164f999cbd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.12772\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":\"10.1016/j.imavis.2020.103985\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a678b68abd4047d5342f64725f57a04647a47711\",\"title\":\"From Known to the Unknown: Transferring Knowledge to Answer Questions about Novel Visual and Semantic Concepts\",\"url\":\"https://www.semanticscholar.org/paper/a678b68abd4047d5342f64725f57a04647a47711\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"2010.02855\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"1729762\",\"name\":\"M. Nickel\"},{\"authorId\":\"4690624\",\"name\":\"Ari S. Morcos\"},{\"authorId\":\"2373318\",\"name\":\"B. Lake\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ffed50c5a14012145ee4d87855ae23deee44be5\",\"title\":\"CURI: A Benchmark for Productive Concept Learning Under Uncertainty\",\"url\":\"https://www.semanticscholar.org/paper/1ffed50c5a14012145ee4d87855ae23deee44be5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3146073\",\"name\":\"Ilke Demir\"},{\"authorId\":\"2644209\",\"name\":\"Dena Bazazian\"},{\"authorId\":\"144290131\",\"name\":\"A. Romero\"},{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"26917145\",\"name\":\"Lyne P. Tchapmi\"}],\"doi\":\"10.1109/CVPRW.2018.00240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e94dae42730a26ca232bc42ea66092d28dfcedc1\",\"title\":\"WiCV 2018: The Fourth Women in Computer Vision Workshop\",\"url\":\"https://www.semanticscholar.org/paper/e94dae42730a26ca232bc42ea66092d28dfcedc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2010.10802\",\"authors\":[{\"authorId\":\"2239880\",\"name\":\"I. Gat\"},{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da5dde64865d7620079e0f50ef27b32bbebef7af\",\"title\":\"Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies\",\"url\":\"https://www.semanticscholar.org/paper/da5dde64865d7620079e0f50ef27b32bbebef7af\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152297151\",\"name\":\"Mengnan Du\"},{\"authorId\":\"47717322\",\"name\":\"Ninghao Liu\"},{\"authorId\":\"145338259\",\"name\":\"F. Yang\"},{\"authorId\":\"48539382\",\"name\":\"Xia Hu\"}],\"doi\":\"10.1007/s10115-020-01517-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f3017e2bfba3ddf5df1ea5798bea479ee755fc6\",\"title\":\"Learning credible DNNs via incorporating prior knowledge and model local explanation\",\"url\":\"https://www.semanticscholar.org/paper/1f3017e2bfba3ddf5df1ea5798bea479ee755fc6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.04998\",\"authors\":[{\"authorId\":null,\"name\":\"Yitong Li\"},{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"28612243\",\"name\":\"S. Prakash\"},{\"authorId\":\"49161455\",\"name\":\"P. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0fa920ea66b7642eb97df389b7e32faa9744b3e\",\"title\":\"Toward Interpretability of Dual-Encoder Models for Dialogue Response Suggestions\",\"url\":\"https://www.semanticscholar.org/paper/f0fa920ea66b7642eb97df389b7e32faa9744b3e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dzmitry Bahdanau\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eb710b446570f48377b25eb279295648d05f65d\",\"title\":\"On sample efficiency and systematic generalization of grounded language understanding with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/2eb710b446570f48377b25eb279295648d05f65d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.11310\",\"authors\":[{\"authorId\":\"19444389\",\"name\":\"Koustav Ghosal\"},{\"authorId\":\"36809068\",\"name\":\"Aakanksha Rana\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/ICCVW.2019.00556\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d204156022f65e34706d4211e05bcb578940939\",\"title\":\"Aesthetic Image Captioning From Weakly-Labelled Photographs\",\"url\":\"https://www.semanticscholar.org/paper/5d204156022f65e34706d4211e05bcb578940939\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/s11263-018-1116-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7e232313a59d735ef7c8a9f4cc7bc980a29deb5e\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"3055431\",\"name\":\"Marco T\\u00falio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":\"10.1109/CVPR42600.2020.01002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27cea494961a45d6a0687c75248fd078999d9a43\",\"title\":\"SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/27cea494961a45d6a0687c75248fd078999d9a43\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.02453\",\"authors\":[{\"authorId\":\"28458352\",\"name\":\"S. Kim\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f27b833c4a0dcb809215b185e8e2601aef6e7fb8\",\"title\":\"Visual Reasoning by Progressive Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/f27b833c4a0dcb809215b185e8e2601aef6e7fb8\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49303626\",\"name\":\"K. Su\"},{\"authorId\":\"144904233\",\"name\":\"Hang Su\"},{\"authorId\":\"104545113\",\"name\":\"J. Li\"},{\"authorId\":\"1557387379\",\"name\":\"Jun Zhu\"}],\"doi\":\"10.3389/frobt.2020.00109\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e2a19bef88c30a37402da5b54fac34655d77ea\",\"title\":\"Toward Accurate Visual Reasoning With Dual-Path Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/22e2a19bef88c30a37402da5b54fac34655d77ea\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"1810.02358\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"1837923\",\"name\":\"Taehoon Kim\"},{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b80f128830114896df94999b4104cb75408e657e\",\"title\":\"Transfer Learning via Unsupervised Task Discovery for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b80f128830114896df94999b4104cb75408e657e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1907.00490\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICDAR.2019.00251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"title\":\"ICDAR 2019 Competition on Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":\"1912.09713\",\"authors\":[{\"authorId\":\"51027911\",\"name\":\"Daniel Keysers\"},{\"authorId\":\"1474228495\",\"name\":\"Nathanael Sch\\u00e4rli\"},{\"authorId\":\"1471909492\",\"name\":\"Nathan Scales\"},{\"authorId\":\"2836674\",\"name\":\"H. Buisman\"},{\"authorId\":\"2362932\",\"name\":\"Daniel Furrer\"},{\"authorId\":\"1471005695\",\"name\":\"Sergii Kashubin\"},{\"authorId\":\"1470531643\",\"name\":\"Nikola Momchev\"},{\"authorId\":\"1470524352\",\"name\":\"Danila Sinopalnikov\"},{\"authorId\":\"3140227\",\"name\":\"Lukasz Stafiniak\"},{\"authorId\":\"1470473803\",\"name\":\"Tibor Tihon\"},{\"authorId\":\"3045792\",\"name\":\"D. Tsarkov\"},{\"authorId\":null,\"name\":\"Xiao Wang\"},{\"authorId\":\"2807540\",\"name\":\"Marc van Zee\"},{\"authorId\":\"49513540\",\"name\":\"O. Bousquet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b\",\"title\":\"Measuring Compositional Generalization: A Comprehensive Method on Realistic Data\",\"url\":\"https://www.semanticscholar.org/paper/5cdab78acc4f3aab429a0dd41c3ec7e605d42e7b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2004.11546\",\"authors\":[{\"authorId\":\"79327062\",\"name\":\"Yiben Yang\"},{\"authorId\":\"8805254\",\"name\":\"Chaitanya Malaviya\"},{\"authorId\":\"152793333\",\"name\":\"Jared Fernandez\"},{\"authorId\":\"2705113\",\"name\":\"Swabha Swayamdipta\"},{\"authorId\":\"39227408\",\"name\":\"Ronan Le Bras\"},{\"authorId\":\"48094797\",\"name\":\"Jiping Wang\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"145612610\",\"name\":\"Doug Downey\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd6f3b6d92ae9448a2000d9690b921f545f00256\",\"title\":\"Generative Data Augmentation for Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/dd6f3b6d92ae9448a2000d9690b921f545f00256\",\"venue\":\"EMNLP 2020\",\"year\":2020},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.13681\",\"authors\":[{\"authorId\":\"20657367\",\"name\":\"A. Mani\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"},{\"authorId\":\"2029244392\",\"name\":\"Nobline Yoo\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"title\":\"Point and Ask: Incorporating Pointing into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412806873\",\"name\":\"Mandar Bhalerao\"},{\"authorId\":\"1491238382\",\"name\":\"Shlok Gujar\"},{\"authorId\":\"144555055\",\"name\":\"A. Bhave\"},{\"authorId\":\"2702152\",\"name\":\"Anant V. Nimkar\"}],\"doi\":\"10.1109/IBSSC47189.2019.8973090\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"title\":\"Visual Question Answering Using Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/0fd778bd56bfda44297c72633b2ef2988d10bc76\",\"venue\":\"2019 IEEE Bombay Section Signature Conference (IBSSC)\",\"year\":2019},{\"arxivId\":\"2003.11844\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"145491338\",\"name\":\"S. Palacio\"},{\"authorId\":\"144553243\",\"name\":\"J. Folz\"},{\"authorId\":\"48258541\",\"name\":\"Federico Raue\"},{\"authorId\":\"120996558\",\"name\":\"J. Hees\"},{\"authorId\":\"1384499125\",\"name\":\"Andreas Dengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"title\":\"P $\\\\approx$ NP, at least in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/625ec4698251cd181818bfd12f1cd5e63c7bcef0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11134\",\"authors\":[{\"authorId\":\"2018700866\",\"name\":\"Chao Yang\"},{\"authorId\":\"145030306\",\"name\":\"S. Feng\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"2476503\",\"name\":\"H. Shen\"},{\"authorId\":\"50248868\",\"name\":\"Guoqing Wang\"},{\"authorId\":\"1796274181\",\"name\":\"Bin Jiang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e30790690231e7730eb6f903a722a54091fc4967\",\"title\":\"Learning content and context with language bias for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e30790690231e7730eb6f903a722a54091fc4967\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.15012\",\"authors\":[{\"authorId\":\"35318567\",\"name\":\"Rohan Jha\"},{\"authorId\":\"10727711\",\"name\":\"Charles Lovering\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f8cad3cdb1c4b75d145105887a61fca55852d6c\",\"title\":\"Does Data Augmentation Improve Generalization in NLP\",\"url\":\"https://www.semanticscholar.org/paper/2f8cad3cdb1c4b75d145105887a61fca55852d6c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.05601\",\"authors\":[{\"authorId\":\"3432460\",\"name\":\"Mengnan Du\"},{\"authorId\":\"47717322\",\"name\":\"Ninghao Liu\"},{\"authorId\":\"91915492\",\"name\":\"Fan Yang\"},{\"authorId\":\"48539382\",\"name\":\"Xia Hu\"}],\"doi\":\"10.1109/ICDM.2019.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f23b2e41bab791db094de4a3de302bef790c5e7\",\"title\":\"Learning Credible Deep Neural Networks with Rationale Regularization\",\"url\":\"https://www.semanticscholar.org/paper/2f23b2e41bab791db094de4a3de302bef790c5e7\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"1752876325\",\"name\":\"Yi Cai\"},{\"authorId\":\"150068355\",\"name\":\"Changmeng Zheng\"},{\"authorId\":\"47740571\",\"name\":\"J. Chen\"},{\"authorId\":\"1701688\",\"name\":\"Ho-fung Leung\"},{\"authorId\":\"145138436\",\"name\":\"Qing Li\"}],\"doi\":\"10.18653/v1/2020.acl-main.642\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ede49ec0dd27849e57152d5116770bcbe3e01874\",\"title\":\"Aligned Dual Channel Graph Convolutional Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ede49ec0dd27849e57152d5116770bcbe3e01874\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"144914662\",\"name\":\"F. Xiao\"},{\"authorId\":\"143728443\",\"name\":\"Le An\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"48305363\",\"name\":\"Xiaochuan Sun\"}],\"doi\":\"10.1145/3300938\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"title\":\"Semantic Concept Network and Deep Walk-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f49c6c3b864a3e66c7f0d70b43ab76176a8aeb44\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2003.10065\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"title\":\"Linguistically Driven Graph Capsule Network for Visual Question Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/e4e90d80721fc24ac40f4711f8692aba08dc14e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79327062\",\"name\":\"Yiben Yang\"},{\"authorId\":\"8805254\",\"name\":\"Chaitanya Malaviya\"},{\"authorId\":\"152793333\",\"name\":\"Jared Fernandez\"},{\"authorId\":\"2705113\",\"name\":\"Swabha Swayamdipta\"},{\"authorId\":\"39227408\",\"name\":\"Ronan Le Bras\"},{\"authorId\":\"46583890\",\"name\":\"J. Wang\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"145612610\",\"name\":\"Doug Downey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"509a275d2563e08a193d4b032f43dd9eb9e6c575\",\"title\":\"G-DAUG: Generative Data Augmentation for Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/509a275d2563e08a193d4b032f43dd9eb9e6c575\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":\"48567083\",\"name\":\"Zheng Yu\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/icme46284.2020.9102814\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fef6c56e474fa99e907b478f17f1becd50900f21\",\"title\":\"Rankvqa: Answer Re-Ranking For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fef6c56e474fa99e907b478f17f1becd50900f21\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2004.14602\",\"authors\":[{\"authorId\":\"22670284\",\"name\":\"Miyoung Ko\"},{\"authorId\":\"65798870\",\"name\":\"Jinhyuk Lee\"},{\"authorId\":\"153761147\",\"name\":\"Hyunjae Kim\"},{\"authorId\":\"1390543205\",\"name\":\"Gangwoo Kim\"},{\"authorId\":\"144323862\",\"name\":\"Jaewoo Kang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.84\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e14aad3423e454254c4d90c5de0ad7d965f328ee\",\"title\":\"Look at the First Sentence: Position Bias in Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e14aad3423e454254c4d90c5de0ad7d965f328ee\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.02865\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00204\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51932dc1148566040fdb0df6ed66d8d2a0712933\",\"title\":\"Actively Seeking and Learning From Live Data\",\"url\":\"https://www.semanticscholar.org/paper/51932dc1148566040fdb0df6ed66d8d2a0712933\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.06927\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145479841\",\"name\":\"E. Horvitz\"},{\"authorId\":\"78846919\",\"name\":\"Marco Tulio Ribeiro\"},{\"authorId\":\"2571049\",\"name\":\"Besmira Nushi\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"title\":\"SQuINTing at VQA Models: Interrogating VQA Models with Sub-Questions\",\"url\":\"https://www.semanticscholar.org/paper/92c3db650f0eecbdf6e9ff2e2e75338bd3752a05\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.01725\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1859082176\",\"name\":\"Salman Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"title\":\"Attention Guided Semantic Relationship Parsing for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2625271\",\"name\":\"Mengfei Li\"},{\"authorId\":\"143628183\",\"name\":\"Li Gu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"title\":\"Text-Guided Dual-Branch Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87f208c3716a80f5251d35196b8ac5c42fa791ea\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e3bb5773205477ae4711524a9d4ae739bee40349\",\"title\":\"Visual semantic role labeling requires recognizing activities and semantic context in images\",\"url\":\"https://www.semanticscholar.org/paper/e3bb5773205477ae4711524a9d4ae739bee40349\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49530191\",\"name\":\"S. Bhattacharya\"},{\"authorId\":\"2757153\",\"name\":\"Rajeev Agrawal\"},{\"authorId\":\"1812598\",\"name\":\"Neal Wagner\"}],\"doi\":\"10.1145/3281375.3281405\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a84b972b385109fc9eb76522de8344a5d495763\",\"title\":\"Application of deep learning and geo-knowledge bases to scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/7a84b972b385109fc9eb76522de8344a5d495763\",\"venue\":\"MEDES\",\"year\":2018},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.04380\",\"authors\":[{\"authorId\":\"2083259\",\"name\":\"Yonatan Belinkov\"},{\"authorId\":\"48926630\",\"name\":\"Adam Poliak\"},{\"authorId\":\"1692491\",\"name\":\"S. Shieber\"},{\"authorId\":\"7536576\",\"name\":\"Benjamin Van Durme\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":\"10.18653/v1/P19-1084\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6540ee01a87c3b3435da73f4e3297489d525c151\",\"title\":\"Don't Take the Premise for Granted: Mitigating Artifacts in Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/6540ee01a87c3b3435da73f4e3297489d525c151\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2003.06576\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/cvpr42600.2020.01081\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dc08d90005b12f66a12798fd79959a8f7f8c4885\",\"title\":\"Counterfactual Samples Synthesizing for Robust Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/dc08d90005b12f66a12798fd79959a8f7f8c4885\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.01801\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"46328947\",\"name\":\"B. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/WACV45572.2020.9093494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"title\":\"Answering Questions about Data Visualizations using Efficient Bimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152303308\",\"name\":\"Mengfei Li\"},{\"authorId\":\"152553572\",\"name\":\"Huan Shao\"},{\"authorId\":\"144911521\",\"name\":\"Y. Ji\"},{\"authorId\":\"49308130\",\"name\":\"Yang Yang\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1109/ICMEW.2019.00045\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"054b5c14785494d4c991155592b95928d7e9d14a\",\"title\":\"Question Splitting and Unbalanced Multi-modal Pooling for VQA\",\"url\":\"https://www.semanticscholar.org/paper/054b5c14785494d4c991155592b95928d7e9d14a\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":\"10.18653/v1/2020.acl-main.643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e600553fe2f21630f2a272c80de4ce0e0363cb9c\",\"title\":\"Multimodal Neural Graph Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e600553fe2f21630f2a272c80de4ce0e0363cb9c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47963068\",\"name\":\"N. Vyas\"},{\"authorId\":\"3167650\",\"name\":\"Sai Krishna Rallabandi\"},{\"authorId\":\"117576986\",\"name\":\"Lalitesh Morishetti\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.1109/ICASSP.2019.8683370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39bb2e79980f70cdbeb3d1d06c6329700ea00c9d\",\"title\":\"Learning Disentangled Representation in Latent Stochastic Models: A Case Study with Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39bb2e79980f70cdbeb3d1d06c6329700ea00c9d\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"title\":\"When an Image Tells a Story: The Role of Visual and Semantic Information for Generating Paragraph Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1109/CVPR.2019.00686\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"title\":\"GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.11528\",\"authors\":[{\"authorId\":\"46875376\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"9228892\",\"name\":\"P. Zhang\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2020/151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0714f88deda344c87bf78569de68d9e1f0b377a7\",\"title\":\"Overcoming Language Priors with Self-supervised Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0714f88deda344c87bf78569de68d9e1f0b377a7\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2012.07192\",\"authors\":[{\"authorId\":\"2826839\",\"name\":\"Qingxing Cao\"},{\"authorId\":\"51473867\",\"name\":\"Bailin Li\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"3170394\",\"name\":\"Keze Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"title\":\"Knowledge-Routed Visual Question Reasoning: Challenges for Deep Representation Embedding\",\"url\":\"https://www.semanticscholar.org/paper/e452c1aa68173d6a1d3aefd9f08f70e43b0c59f4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"title\":\"Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cfc9ef5c7ef8056cff7bf1f1cfdd75e120f28231\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740656238\",\"name\":\"Am\\u00e9lie Royer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5924bfeb91ff47e5f01d7307ccae3869834db79d\",\"title\":\"Leveraging structure in Computer Vision tasks for flexible Deep Learning models\",\"url\":\"https://www.semanticscholar.org/paper/5924bfeb91ff47e5f01d7307ccae3869834db79d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.10210\",\"authors\":[{\"authorId\":\"108630954\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"2455565\",\"name\":\"S. Xiao\"},{\"authorId\":\"115718758\",\"name\":\"A. Mclean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"title\":\"On modality bias in the TVQA dataset.\",\"url\":\"https://www.semanticscholar.org/paper/6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06087\",\"authors\":[{\"authorId\":\"66536530\",\"name\":\"Yash Kant\"},{\"authorId\":\"32587693\",\"name\":\"A. Moudgil\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ead5088bc1922526be9a503dd42b15d467b962\",\"title\":\"Contrast and Classify: Alternate Training for Robust VQA\",\"url\":\"https://www.semanticscholar.org/paper/35ead5088bc1922526be9a503dd42b15d467b962\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"},{\"authorId\":\"145380213\",\"name\":\"B. He\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207058\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99a01a687f7959de4c86102342d4bcfec6382aa8\",\"title\":\"Multi-Channel Co-Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99a01a687f7959de4c86102342d4bcfec6382aa8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ad97e877f55f7ce631fbce30d194c1912c22362\",\"title\":\"IARY PROGRESS ESTIMATION\",\"url\":\"https://www.semanticscholar.org/paper/8ad97e877f55f7ce631fbce30d194c1912c22362\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143912737\",\"name\":\"Heather Riley\"},{\"authorId\":\"1714890\",\"name\":\"M. Sridharan\"}],\"doi\":\"10.3389/frobt.2019.00125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9ae2f99dd2ae29f4bfd220446175bb854db2008\",\"title\":\"Integrating Non-monotonic Logical Reasoning and Inductive Learning With Deep Learning for Explainable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9ae2f99dd2ae29f4bfd220446175bb854db2008\",\"venue\":\"Front. Robot. AI\",\"year\":2019},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2933400\",\"name\":\"Jurgis Skilters\"},{\"authorId\":\"1798058\",\"name\":\"N. Newcombe\"},{\"authorId\":\"70514916\",\"name\":\"David Uttal\"}],\"doi\":\"10.1007/978-3-030-57983-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"267c6cf5e0e2952ac74b5df4ad58266392fd9e1e\",\"title\":\"Spatial Cognition XII: 12th International Conference, Spatial Cognition 2020, Riga, Latvia, August 26\\u201328, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/267c6cf5e0e2952ac74b5df4ad58266392fd9e1e\",\"venue\":\"Spatial Cognition\",\"year\":2020},{\"arxivId\":\"2009.08566\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.63\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cf4e64566252b3a342ba344e8a123c2b209766f2\",\"title\":\"MUTANT: A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cf4e64566252b3a342ba344e8a123c2b209766f2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"113720743\",\"name\":\"Amin Parvaneh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR42600.2020.01006\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"title\":\"Counterfactual Vision and Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145296409\",\"name\":\"A. Potapov\"},{\"authorId\":\"6374907\",\"name\":\"O. Scherbakov\"},{\"authorId\":\"48649198\",\"name\":\"V. Bogdanov\"},{\"authorId\":\"39086684\",\"name\":\"V. Potapova\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"143860556\",\"name\":\"S. Rodionov\"},{\"authorId\":\"1804542874\",\"name\":\"Artem Yashenko\"}],\"doi\":\"10.1007/978-3-030-52152-3_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b375748f0abbf56154615568d7cefb7fd404dd6f\",\"title\":\"Analyzing Elementary School Olympiad Math Tasks as a Benchmark for AGI\",\"url\":\"https://www.semanticscholar.org/paper/b375748f0abbf56154615568d7cefb7fd404dd6f\",\"venue\":\"AGI\",\"year\":2020},{\"arxivId\":\"2009.11118\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"47787551\",\"name\":\"Binh X. Nguyen\"},{\"authorId\":\"1981175\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"31534280\",\"name\":\"Q. D. Tran\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"30173e8b551c0655e2036aba7fedf354f1ef5658\",\"title\":\"Multiple interaction learning with question-type prior knowledge for constraining answer search space in visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/30173e8b551c0655e2036aba7fedf354f1ef5658\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35318567\",\"name\":\"Rohan Jha\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"},{\"authorId\":\"144885169\",\"name\":\"M. Littman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46dfd46fb41d56bc77055e436dc969de8df0e76b\",\"title\":\"Data augmentation and the role of hardness for feature learning in NLP\",\"url\":\"https://www.semanticscholar.org/paper/46dfd46fb41d56bc77055e436dc969de8df0e76b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":\"10.1007/978-3-030-11018-5_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ae89d6027c6b45c7b2b95ebc01a1054966da133\",\"title\":\"Knowing When to Look for What and Where: Evaluating Generation of Spatial Descriptions with Adaptive Attention\",\"url\":\"https://www.semanticscholar.org/paper/8ae89d6027c6b45c7b2b95ebc01a1054966da133\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2006.10079\",\"authors\":[{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"title\":\"Overcoming Statistical Shortcuts for Open-ended Visual Counting\",\"url\":\"https://www.semanticscholar.org/paper/b5cb23c3c09bcd9f0e12a864b9f4ac3fa0f2dfbd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10038\",\"authors\":[{\"authorId\":\"31340289\",\"name\":\"Sameer Dharur\"},{\"authorId\":\"87994165\",\"name\":\"Purva Tendulkar\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"title\":\"SOrT-ing VQA Models : Contrastive Gradient Learning for Improved Consistency\",\"url\":\"https://www.semanticscholar.org/paper/997cec8026c9904e18ced7ce02e3f7a8e8bf0846\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.02265\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"title\":\"ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/65a9c7b0800c86a196bc14e7621ff895cc6ab287\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2006.05121\",\"authors\":[{\"authorId\":\"51149482\",\"name\":\"Corentin Kervadec\"},{\"authorId\":\"145664204\",\"name\":\"G. Antipov\"},{\"authorId\":\"2341854\",\"name\":\"M. Baccouche\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221\",\"title\":\"Roses Are Red, Violets Are Blue... but Should Vqa Expect Them To?\",\"url\":\"https://www.semanticscholar.org/paper/95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.12271\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145498821\",\"name\":\"P. Wang\"},{\"authorId\":\"39767248\",\"name\":\"Jiewei Cao\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1609/AAAI.V34I07.6885\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed1dcc516162297bbab37aa64d920c87fcc77ca8\",\"title\":\"V-PROM: A Benchmark for Visual Reasoning Using Visual Progressive Matrices\",\"url\":\"https://www.semanticscholar.org/paper/ed1dcc516162297bbab37aa64d920c87fcc77ca8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46791594\",\"name\":\"Yangyang Guo\"}],\"doi\":\"10.1145/3338533.3372212\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5dcf0102f968510d4626a387affa74c008c470e0\",\"title\":\"Multimedia Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5dcf0102f968510d4626a387affa74c008c470e0\",\"venue\":\"MMAsia\",\"year\":2019},{\"arxivId\":\"1912.01452\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"9951160\",\"name\":\"Modar Alfadly\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01aa5668a618fbb376b6ab6608defc074ed355ac\",\"title\":\"Assessing the Robustness of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01aa5668a618fbb376b6ab6608defc074ed355ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"153183862\",\"name\":\"Raquel Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/D19-6403\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dc75988a53b86c1e36539daa0d8ac003b234502\",\"title\":\"Big Generalizations with Small Data: Exploring the Role of Training Samples in Learning Adjectives of Size\",\"url\":\"https://www.semanticscholar.org/paper/9dc75988a53b86c1e36539daa0d8ac003b234502\",\"venue\":\"LANTERN@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"2002.11894\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"title\":\"Unshuffling Data for Improved Generalization\",\"url\":\"https://www.semanticscholar.org/paper/fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.04964\",\"authors\":[{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"}],\"doi\":\"10.1109/TCSVT.2019.2940647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"title\":\"Multi-Modal Deep Analysis for Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"},{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"}],\"doi\":\"10.1007/978-3-030-57983-8_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d8cbeae59ec7d54eabe34b2c143541d1fd7e7fe\",\"title\":\"Spatial Descriptions on a Functional-Geometric Spectrum: the Location of Objects\",\"url\":\"https://www.semanticscholar.org/paper/7d8cbeae59ec7d54eabe34b2c143541d1fd7e7fe\",\"venue\":\"Spatial Cognition\",\"year\":2020},{\"arxivId\":\"1905.04877\",\"authors\":[{\"authorId\":\"30921555\",\"name\":\"Yangyang Guo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"35435925\",\"name\":\"Y. Liu\"},{\"authorId\":\"49417788\",\"name\":\"Yinglong Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3331184.3331186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"title\":\"Quantifying and Alleviating the Language Prior Problem in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d00fe8d117a3849d3085d4301d91c56b775ee8b1\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"2003.09772\",\"authors\":[{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"49889726\",\"name\":\"Y. Zhang\"},{\"authorId\":\"50753116\",\"name\":\"M. Yu\"},{\"authorId\":\"35132120\",\"name\":\"T. Jaakkola\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60d7279168e1e1c9e151b68a3a9fc94ad5137ce5\",\"title\":\"Invariant Rationalization\",\"url\":\"https://www.semanticscholar.org/paper/60d7279168e1e1c9e151b68a3a9fc94ad5137ce5\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1808.00300\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"2019153\",\"name\":\"P. Battaglia\"}],\"doi\":\"10.1007/978-3-030-01231-1_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"afe3a0d463e2f099305c745ddbf943844583795d\",\"title\":\"Learning Visual Question Answering by Bootstrapping Hard Attention\",\"url\":\"https://www.semanticscholar.org/paper/afe3a0d463e2f099305c745ddbf943844583795d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1902.09506\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c122fa378a774ba202d418cf71c5c356cf2f902f\",\"title\":\"GQA: a new dataset for compositional question answering over real-world images\",\"url\":\"https://www.semanticscholar.org/paper/c122fa378a774ba202d418cf71c5c356cf2f902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"title\":\"Research Statement Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/d115b0e8ba14641c26d5e38fd2b5f4c226888729\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48289232\",\"name\":\"Mohit Bajaj\"}],\"doi\":\"10.14288/1.0380482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef8832a4cc4d1838763df8dc7580e14706547f5a\",\"title\":\"Graph-based language grounding\",\"url\":\"https://www.semanticscholar.org/paper/ef8832a4cc4d1838763df8dc7580e14706547f5a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.02088\",\"authors\":[{\"authorId\":\"145659406\",\"name\":\"Y. Shi\"},{\"authorId\":\"2426872\",\"name\":\"T. Furlanello\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":\"10.1007/978-3-030-01225-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"title\":\"Question Type Guided Attention in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.09241\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"1692540612\",\"name\":\"Christopher Kanan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad322ec0617a9bdf1dabd2a51e626a9c474ed9e3\",\"title\":\"On the Value of Out-of-Distribution Testing: An Example of Goodhart's Law\",\"url\":\"https://www.semanticscholar.org/paper/ad322ec0617a9bdf1dabd2a51e626a9c474ed9e3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.03856\",\"authors\":[{\"authorId\":\"143997772\",\"name\":\"Christopher Clark\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.272\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55188532ea9ea4d4a4872ebe79fc3add14cd34dd\",\"title\":\"Learning to Model and Ignore Dataset Bias with Mixed Capacity Ensembles\",\"url\":\"https://www.semanticscholar.org/paper/55188532ea9ea4d4a4872ebe79fc3add14cd34dd\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2006.04315\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"112957699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"title\":\"Counterfactual VQA: A Cause-Effect Look at Language Bias\",\"url\":\"https://www.semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13406\",\"authors\":[{\"authorId\":\"153188991\",\"name\":\"Spencer Whitehead\"},{\"authorId\":\"97671685\",\"name\":\"H. Wu\"},{\"authorId\":\"51135899\",\"name\":\"Yi Ren Fung\"},{\"authorId\":\"153172090\",\"name\":\"Huai-zhong Ji\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1904c5389a70a905019d5429f09bc7f669bdc898\",\"title\":\"Learning from Lexical Perturbations for Consistent Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1904c5389a70a905019d5429f09bc7f669bdc898\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.11524\",\"authors\":[{\"authorId\":\"1961237\",\"name\":\"S. Amizadeh\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"2636739\",\"name\":\"Oleksandr Polozov\"},{\"authorId\":\"153268415\",\"name\":\"Y. Huang\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb62c82e469a265d986a164ba56d96d130937fd7\",\"title\":\"Neuro-Symbolic Visual Reasoning: Disentangling \\\"Visual\\\" from \\\"Reasoning\\\"\",\"url\":\"https://www.semanticscholar.org/paper/fb62c82e469a265d986a164ba56d96d130937fd7\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88240975\",\"name\":\"B. Goertzel\"},{\"authorId\":\"35234816\",\"name\":\"A. Panov\"},{\"authorId\":\"145296409\",\"name\":\"A. Potapov\"},{\"authorId\":\"1976753\",\"name\":\"Roman V Yampolskiy\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-52152-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1de88fd6bdaac4afe6dd3b7ca80923e1dbff40e1\",\"title\":\"Artificial General Intelligence: 13th International Conference, AGI 2020, St. Petersburg, Russia, September 16\\u201319, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/1de88fd6bdaac4afe6dd3b7ca80923e1dbff40e1\",\"venue\":\"AGI\",\"year\":2020},{\"arxivId\":\"1909.10650\",\"authors\":[{\"authorId\":\"143912737\",\"name\":\"Heather Riley\"},{\"authorId\":\"1714890\",\"name\":\"M. Sridharan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb2fb0462a1e8cf01e2ddf4ff7029d1edb3a8d58\",\"title\":\"Non-monotonic Logical Reasoning Guiding Deep Learning for Explainable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bb2fb0462a1e8cf01e2ddf4ff7029d1edb3a8d58\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1801.08163\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2018.00592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"title\":\"DVQA: Understanding Data Visualizations via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7289a240c9425bc7cad87b3b835e5f0cac22f488\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shivam Garg\"},{\"authorId\":\"144681901\",\"name\":\"R. Srivastava\"}],\"doi\":\"10.1049/iet-cvi.2018.5226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4bb5303fd5e26f411bdfa3db063acd6cff90a1\",\"title\":\"Object sequences: encoding categorical and spatial information for a yes/no visual question answering task\",\"url\":\"https://www.semanticscholar.org/paper/9a4bb5303fd5e26f411bdfa3db063acd6cff90a1\",\"venue\":\"IET Comput. Vis.\",\"year\":2018},{\"arxivId\":\"1906.09635\",\"authors\":[{\"authorId\":\"145511547\",\"name\":\"Shawn Tan\"},{\"authorId\":\"2305979\",\"name\":\"Yikang Shen\"},{\"authorId\":\"48908331\",\"name\":\"C. Huang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7a21d9359a4e1e4e9ce6063f6110c00593bcad3\",\"title\":\"Investigating Biases in Textual Entailment Datasets\",\"url\":\"https://www.semanticscholar.org/paper/a7a21d9359a4e1e4e9ce6063f6110c00593bcad3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48322149\",\"name\":\"Roma Patel\"},{\"authorId\":\"2949185\",\"name\":\"Ellie Pavlick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59d7737f8ee098d880ec69cd344a581cb47e5e63\",\"title\":\"Learning Visually Grounded Representations with Sketches\",\"url\":\"https://www.semanticscholar.org/paper/59d7737f8ee098d880ec69cd344a581cb47e5e63\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09034\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-58607-2_34\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"29121a31e4d684839cfd0bb358f33ea1266cece5\",\"title\":\"Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision\",\"url\":\"https://www.semanticscholar.org/paper/29121a31e4d684839cfd0bb358f33ea1266cece5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.15631\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"title\":\"Improving VQA and its Explanations by Comparing Competing Explanations\",\"url\":\"https://www.semanticscholar.org/paper/f336b80e3f78615fbb414d4c4aed7545024dc4bf\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":19298149,\"doi\":\"10.1109/CVPR.2018.00522\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":47,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1511.05960\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"36650957\",\"name\":\"Jiang Wang\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"title\":\"ABC-CNN: An Attention Based Convolutional Neural Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b196bc11ad516c8e6ff96f83acfc443fd7161730\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1611.05546\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a8224266b8ab1483f6548307ab96227147f34da\",\"title\":\"Zero-Shot Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a8224266b8ab1483f6548307ab96227147f34da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Kezami\"},{\"authorId\":null,\"name\":\"A. Globerson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"an attention based convolutional neural network for visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"J. Yang\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Hierarchical questionimage co-attention for visual question answering\",\"url\":\"\",\"venue\":\"NIPS,\",\"year\":2016},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1704.08243\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"title\":\"C-VQA: A Compositional Split of the Visual Question Answering (VQA) v1.0 Dataset\",\"url\":\"https://www.semanticscholar.org/paper/a3d071d2a5c11329aa324b2cae6b7b6ca7800213\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. H. Park\"},{\"authorId\":null,\"name\":\"D. Yang\"},{\"authorId\":null,\"name\":\"A. Rohrbach\"},{\"authorId\":null,\"name\":\"T. Darrell\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VQA : Visual Question Answering Being negative but constructively : Lessons learnt from creating better visual question answering datasets Cross - dataset adaptation for visual question answering\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"},{\"authorId\":\"1748758\",\"name\":\"H. Nickisch\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPRW.2009.5206594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"title\":\"Learning to detect unseen object classes by between-class attribute transfer\",\"url\":\"https://www.semanticscholar.org/paper/0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1704.02516\",\"authors\":[{\"authorId\":\"21810992\",\"name\":\"Santhosh K. Ramakrishnan\"},{\"authorId\":\"2311107\",\"name\":\"Ambar Pal\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1109/CVPR.2017.773\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"title\":\"An Empirical Evaluation of Visual Question Answering for Novel Objects\",\"url\":\"https://www.semanticscholar.org/paper/6e77e651f44a11c7c3a459c7dfcdfabba0fb6891\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2016.538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"title\":\"Answer-Type Prediction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ebe5081b8a24b4740db929b6eae75f28f8edbc58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.05676\",\"authors\":[{\"authorId\":\"3335651\",\"name\":\"Aiwen Jiang\"},{\"authorId\":\"7572514\",\"name\":\"Fang Wang\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"47001807\",\"name\":\"Y. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1382fa43c31e594ed2d84dda9984b1db047b0e\",\"title\":\"Compositional Memory for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3d1382fa43c31e594ed2d84dda9984b1db047b0e\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2014.211\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fad544edfc2cd2a127436a2126bab7ad31ec333\",\"title\":\"Decorrelating Semantic Visual Attributes by Resisting the Urge to Share\",\"url\":\"https://www.semanticscholar.org/paper/0fad544edfc2cd2a127436a2126bab7ad31ec333\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"X. Lin\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deeper lstm and normalized cnn visual question answering model\",\"url\":\"\",\"venue\":\"https://github.com/VT-vision-lab/ VQA_LSTM_CNN,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"title\":\"Deep Compositional Question Answering with Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.06108\",\"authors\":[{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICME.2017.8019436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"121a9a160f1f2819a01edbe522024b58dbfee798\",\"title\":\"DualNet: Domain-invariant network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/121a9a160f1f2819a01edbe522024b58dbfee798\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40403107\",\"name\":\"X. Zhou\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/s00530-002-0070-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62cec1ef9f1d9135884c2a61919d20fbb8eda589\",\"title\":\"Relevance feedback in image retrieval: A comprehensive review\",\"url\":\"https://www.semanticscholar.org/paper/62cec1ef9f1d9135884c2a61919d20fbb8eda589\",\"venue\":\"Multimedia Systems\",\"year\":2003},{\"arxivId\":\"1608.07639\",\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"3451674\",\"name\":\"Vahid Kezami\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"936227f7483938097cc1cdd3032016df54dbd5b6\",\"title\":\"Learning to generalize to new compositions in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/936227f7483938097cc1cdd3032016df54dbd5b6\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3449b65008b27f6e60a73d80c1fd990f0481126b\",\"title\":\"Torch7: A Matlab-like Environment for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/3449b65008b27f6e60a73d80c1fd990f0481126b\",\"venue\":\"NIPS 2011\",\"year\":2011}],\"title\":\"Don't Just Assume; Look and Answer: Overcoming Priors for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"SOCKS\",\"topicId\":\"879399\",\"url\":\"https://www.semanticscholar.org/topic/879399\"},{\"topic\":\"Virtual collective consciousness\",\"topicId\":\"3715367\",\"url\":\"https://www.semanticscholar.org/topic/3715367\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"The Superficial\",\"topicId\":\"708686\",\"url\":\"https://www.semanticscholar.org/topic/708686\"},{\"topic\":\"don't take it personally, babe, it just ain't your story\",\"topicId\":\"4042523\",\"url\":\"https://www.semanticscholar.org/topic/4042523\"},{\"topic\":\"Storage area network\",\"topicId\":\"36411\",\"url\":\"https://www.semanticscholar.org/topic/36411\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Bilinear transform\",\"topicId\":\"397622\",\"url\":\"https://www.semanticscholar.org/topic/397622\"}],\"url\":\"https://www.semanticscholar.org/paper/90873a97aa9a43775e5aeea01b03aea54b28bfbd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"