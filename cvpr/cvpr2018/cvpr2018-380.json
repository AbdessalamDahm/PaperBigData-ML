"{\"abstract\":\"The study of algorithms to automatically answer visual questions currently is motivated by visual question answering (VQA) datasets constructed in artificial VQA settings. We propose VizWiz, the first goal-oriented VQA dataset arising from a natural VQA setting. VizWiz consists of over 31,000 visual questions originating from blind people who each took a picture using a mobile phone and recorded a spoken question about it, together with 10 crowdsourced answers per visual question. VizWiz differs from the many existing VQA datasets because (1) images are captured by blind photographers and so are often poor quality, (2) questions are spoken and so are more conversational, and (3) often visual questions cannot be answered. Evaluation of modern algorithms for answering visual questions and deciding if a visual question is answerable reveals that VizWiz is a challenging dataset. We introduce this dataset to encourage a larger community to develop more generalized algorithms that can assist blind people.\",\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\",\"url\":\"https://www.semanticscholar.org/author/2028946\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\",\"url\":\"https://www.semanticscholar.org/author/48933900\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\",\"url\":\"https://www.semanticscholar.org/author/32027456\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\",\"url\":\"https://www.semanticscholar.org/author/2582404\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\",\"url\":\"https://www.semanticscholar.org/author/47532530\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\",\"url\":\"https://www.semanticscholar.org/author/1794409\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\",\"url\":\"https://www.semanticscholar.org/author/1744846\"}],\"citationVelocity\":38,\"citations\":[{\"arxivId\":\"1808.00171\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1007/978-3-030-01258-8_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8164ebc07f51c9e0db4902980b5ac3f5a8d8d48c\",\"title\":\"Shuffle-Then-Assemble: Learning Object-Agnostic Visual Relationship Features\",\"url\":\"https://www.semanticscholar.org/paper/8164ebc07f51c9e0db4902980b5ac3f5a8d8d48c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144883814\",\"name\":\"E. Davis\"}],\"doi\":\"10.3389/frai.2020.00051\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"18bf0bb3da3cab55e3d187347bfe0fe071fa92d6\",\"title\":\"Unanswerable Questions About Images and Texts\",\"url\":\"https://www.semanticscholar.org/paper/18bf0bb3da3cab55e3d187347bfe0fe071fa92d6\",\"venue\":\"Frontiers in Artificial Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"101489041\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"title\":\"Reason Label Description Issues with the Question-Image ( QI ) pair Low Quality\",\"url\":\"https://www.semanticscholar.org/paper/6a9293145a9a3a7ca42b18a437e0bce67a359127\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.11743\",\"authors\":[{\"authorId\":\"1491233100\",\"name\":\"Pranav Agarwal\"},{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"1594025086\",\"name\":\"V. Panagiotou\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b430a5384c82beb6102106fbea0a134425a08c23\",\"title\":\"Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models\",\"url\":\"https://www.semanticscholar.org/paper/b430a5384c82beb6102106fbea0a134425a08c23\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"1811.10120\",\"authors\":[{\"authorId\":\"144069571\",\"name\":\"Martin Weiss\"},{\"authorId\":\"39175553\",\"name\":\"Margaux Luck\"},{\"authorId\":\"31773740\",\"name\":\"Roger Girgis\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"40061310\",\"name\":\"Joseph Paul Cohen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7593df056b1700d7ea9872ff299a903bdc7d2533\",\"title\":\"A Survey of Mobile Computing for the Visually Impaired\",\"url\":\"https://www.semanticscholar.org/paper/7593df056b1700d7ea9872ff299a903bdc7d2533\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"title\":\"ENGAGING IMAGE CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2012.04638\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"46583994\",\"name\":\"Jianfeng Wang\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1882479\",\"name\":\"D. Flor\\u00eancio\"},{\"authorId\":\"30602591\",\"name\":\"Lijuan Wang\"},{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"145637095\",\"name\":\"Lei Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"title\":\"TAP: Text-Aware Pre-training for Text-VQA and Text-Caption\",\"url\":\"https://www.semanticscholar.org/paper/8deceb13cb3afcfbaab06a2c655f1935445635fe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.10215\",\"authors\":[{\"authorId\":\"48631626\",\"name\":\"Xinyu Wang\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"46668045\",\"name\":\"Chun Chet Ng\"},{\"authorId\":\"30099960\",\"name\":\"Canjie Luo\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"46699480\",\"name\":\"Chee Seng Chan\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"35462302\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"title\":\"On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29c3242cce0c78f96d7d90e0123b95cb0840f21a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"49146706\",\"name\":\"Y. Choi\"},{\"authorId\":\"2487892\",\"name\":\"Sungeun Hong\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d111dc672d48823c22594d28d9742c0b707959c6\",\"title\":\"Bilinear attention networks for VizWiz challenge\",\"url\":\"https://www.semanticscholar.org/paper/d111dc672d48823c22594d28d9742c0b707959c6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.06198\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":\"10.1007/978-3-030-58601-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06b869a92a22db711e4fbe8b141c83523c7c4604\",\"title\":\"Reducing Language Biases in Visual Question Answering with Visually-Grounded Question Encoder\",\"url\":\"https://www.semanticscholar.org/paper/06b869a92a22db711e4fbe8b141c83523c7c4604\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.06258\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/cvpr42600.2020.01001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"title\":\"Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/4fc2eb1b494a29c7cb39da3b180a302521e459a0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1145/3290605.3300566\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de6562e7c3736b7e0c94f62f26ea1f77d44e4eff\",\"title\":\"Hands Holding Clues for Object Recognition in Teachable Machines\",\"url\":\"https://www.semanticscholar.org/paper/de6562e7c3736b7e0c94f62f26ea1f77d44e4eff\",\"venue\":\"CHI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"144760828\",\"name\":\"C. Rodriguez\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7a406da5e069e37fe780d679a7140ecf46454bc3\",\"title\":\"ACL 2020 The 58th Annual Meeting of the Association for Computational Linguistics Proceedings of the Second Grand Challenge and Workshop on Multimodal Language (Challenge-HML)\",\"url\":\"https://www.semanticscholar.org/paper/7a406da5e069e37fe780d679a7140ecf46454bc3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.04342\",\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"48933740\",\"name\":\"Q. Li\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/ICCV.2019.00437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cae43b28757e0c37a05156ed063dcc3bb652809\",\"title\":\"Why Does a Visual Question Have Different Answers?\",\"url\":\"https://www.semanticscholar.org/paper/4cae43b28757e0c37a05156ed063dcc3bb652809\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"292d6cbab27ba35c825d75130311a4b27f291af2\",\"title\":\"Visual Question Answering with Annotation-Efficient Zero Shot Learning under Linguistic Domain Shift\",\"url\":\"https://www.semanticscholar.org/paper/292d6cbab27ba35c825d75130311a4b27f291af2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48712213\",\"name\":\"Harmanpreet Kaur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc47b075dcbb2a170740d5da1d51d954efb62748\",\"title\":\"Building Shared Mental Models between Humans and AI for Effective Collaboration\",\"url\":\"https://www.semanticscholar.org/paper/bc47b075dcbb2a170740d5da1d51d954efb62748\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"81500724\",\"name\":\"Anuraag Jain\"},{\"authorId\":\"80235179\",\"name\":\"Shomiron Ghose\"},{\"authorId\":\"1727999\",\"name\":\"Gierad Laput\"},{\"authorId\":\"145078227\",\"name\":\"C. Harrison\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/3264921\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bc8fda7ea6451b39a447fe2e31fb05868df8b91\",\"title\":\"Crowd-AI Camera Sensing in the Real World\",\"url\":\"https://www.semanticscholar.org/paper/9bc8fda7ea6451b39a447fe2e31fb05868df8b91\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"50444302\",\"name\":\"Q. Li\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"46317592\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2019.00103\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"title\":\"VizWiz-Priv: A Dataset for Recognizing the Presence and Purpose of Private Visual Information in Images Taken by Blind People\",\"url\":\"https://www.semanticscholar.org/paper/8dba803240e2cf00d143d4b0a82b95933b5883eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2004.02673\",\"authors\":[{\"authorId\":\"72825141\",\"name\":\"M. Nazarczuk\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/ICRA40945.2020.9197332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bea5f30c145a0675418d04941b2eee77f4e9008\",\"title\":\"SHOP-VRB: A Visual Reasoning Benchmark for Object Perception\",\"url\":\"https://www.semanticscholar.org/paper/1bea5f30c145a0675418d04941b2eee77f4e9008\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2019.00203\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bb60b737b53b23f5eb1f56cd145153d4581330\",\"title\":\"It's Not About the Journey; It's About the Destination: Following Soft Paths Under Question-Guidance for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/80bb60b737b53b23f5eb1f56cd145153d4581330\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.00490\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICDAR.2019.00251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"title\":\"ICDAR 2019 Competition on Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4b3b0d8d5a24630c940049442a8d824534faf8b9\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"},{\"authorId\":\"2007213005\",\"name\":\"Kristina Shiroma\"},{\"authorId\":\"40430520\",\"name\":\"B. Xie\"},{\"authorId\":\"3079031\",\"name\":\"Kenneth R. Fleischmann\"},{\"authorId\":\"1420431848\",\"name\":\"Danna Gurari\"}],\"doi\":\"10.1145/3373625.3417014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f392b88ac5d7af7ae2abfec48f7f10e137708ccf\",\"title\":\"Visual Content Considered Private by People Who are Blind\",\"url\":\"https://www.semanticscholar.org/paper/f392b88ac5d7af7ae2abfec48f7f10e137708ccf\",\"venue\":\"ASSETS\",\"year\":2020},{\"arxivId\":\"2001.03615\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01028\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"title\":\"In Defense of Grid Features for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e4e57e0f7030f2c71ff7e9e3583d8ec908ca16e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47240387\",\"name\":\"Y. Zhong\"},{\"authorId\":\"35268094\",\"name\":\"Masaki Matsubara\"},{\"authorId\":\"34573158\",\"name\":\"A. Morishima\"}],\"doi\":\"10.1109/BigData.2018.8621911\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"048e4fa6dc6a2ce0092b638de62ed58ec0a265a4\",\"title\":\"Identification of Important Images for Understanding Web Pages\",\"url\":\"https://www.semanticscholar.org/paper/048e4fa6dc6a2ce0092b638de62ed58ec0a265a4\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":\"1904.01375\",\"authors\":[{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":\"48064335\",\"name\":\"L. Yang\"},{\"authorId\":\"46382824\",\"name\":\"Hui Li\"},{\"authorId\":\"9223063\",\"name\":\"Yuyan Deng\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5bf577d7f378138d37a165cf764cb1967392cb65\",\"title\":\"A Simple and Robust Convolutional-Attention Network for Irregular Text Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5bf577d7f378138d37a165cf764cb1967392cb65\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582890834\",\"name\":\"Zekun Yang\"},{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1748743\",\"name\":\"H. Takemura\"}],\"doi\":\"10.1109/WACV45572.2020.9093596\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39b2d8b8233a53dc7eadb819c52213369dff8648\",\"title\":\"BERT Representations for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/39b2d8b8233a53dc7eadb819c52213369dff8648\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39290858e39fb6e2a7d8b9685cbb854fa7da222f\",\"title\":\"Combining NLP and Computer Vision to Help Blind People\",\"url\":\"https://www.semanticscholar.org/paper/39290858e39fb6e2a7d8b9685cbb854fa7da222f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.01119\",\"authors\":[{\"authorId\":\"97634546\",\"name\":\"Khaled Jedoui\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e23a129f49fcd52258c14da28311cce3190d271f\",\"title\":\"Deep Bayesian Active Learning for Multiple Correct Outputs\",\"url\":\"https://www.semanticscholar.org/paper/e23a129f49fcd52258c14da28311cce3190d271f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2697719\",\"name\":\"Sooyeon Lee\"},{\"authorId\":\"52214543\",\"name\":\"Madison Reddie\"},{\"authorId\":\"40166850\",\"name\":\"Chun-Hua Tsai\"},{\"authorId\":\"145040474\",\"name\":\"Jordan Beck\"},{\"authorId\":\"1715072\",\"name\":\"M. Rosson\"},{\"authorId\":\"145066246\",\"name\":\"J. Carroll\"}],\"doi\":\"10.1145/3313831.3376591\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66456698050f87b0adfc54c42d2c7e4b821593e1\",\"title\":\"The Emerging Professional Practice of Remote Sighted Assistance for People with Visual Impairments\",\"url\":\"https://www.semanticscholar.org/paper/66456698050f87b0adfc54c42d2c7e4b821593e1\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":\"2003.07333\",\"authors\":[{\"authorId\":\"7754251\",\"name\":\"Sylvain Lobry\"},{\"authorId\":\"144173388\",\"name\":\"D. Marcos\"},{\"authorId\":\"1409495574\",\"name\":\"J. Murray\"},{\"authorId\":\"1404577763\",\"name\":\"D. Tuia\"}],\"doi\":\"10.1109/TGRS.2020.2988782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b3ddddefee26c686da2e1088d21e69c594f1c3d\",\"title\":\"RSVQA: Visual Question Answering for Remote Sensing Data\",\"url\":\"https://www.semanticscholar.org/paper/0b3ddddefee26c686da2e1088d21e69c594f1c3d\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1904.01375\",\"authors\":[{\"authorId\":\"152538521\",\"name\":\"L. Yang\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"49969637\",\"name\":\"Zhuguo Li\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1016/j.neucom.2020.07.010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"605ceaafca25b5501a21a5899979cfee19758d57\",\"title\":\"A holistic representation guided attention network for scene text recognition\",\"url\":\"https://www.semanticscholar.org/paper/605ceaafca25b5501a21a5899979cfee19758d57\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2012.12975\",\"authors\":[{\"authorId\":\"1410423255\",\"name\":\"R\\u0131za Velio\\u011flu\"},{\"authorId\":\"38444971\",\"name\":\"Jewgeni Rose\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d952d45eb6e7c0c564974e2caf1d86db36750b20\",\"title\":\"Detecting Hate Speech in Memes Using Multimodal Deep Learning Approaches: Prize-winning solution to Hateful Memes Challenge\",\"url\":\"https://www.semanticscholar.org/paper/d952d45eb6e7c0c564974e2caf1d86db36750b20\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.12917\",\"authors\":[{\"authorId\":\"3442255\",\"name\":\"Zan-Xia Jin\"},{\"authorId\":\"2003456770\",\"name\":\"Heran Wu\"},{\"authorId\":\"46962194\",\"name\":\"C. Yang\"},{\"authorId\":\"31679477\",\"name\":\"Fang Zhou\"},{\"authorId\":\"2005306\",\"name\":\"Jingyan Qin\"},{\"authorId\":\"145628818\",\"name\":\"Lei Xiao\"},{\"authorId\":\"120644708\",\"name\":\"XuCheng Yin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d209f0d94492447713541b28373d9b6cad5edeb9\",\"title\":\"RUArt: A Novel Text-Centered Solution for Text-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d209f0d94492447713541b28373d9b6cad5edeb9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14435\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bdabd8bc1009e3ef2764a4e1dde20938aecad84\",\"title\":\"Towards Ecologically Valid Research on Language User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/6bdabd8bc1009e3ef2764a4e1dde20938aecad84\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.13648\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"2864362\",\"name\":\"Ernest Valveny\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/ICCV.2019.00439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0033346700dc450ac22c9b704eab0e906d868662\",\"title\":\"Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0033346700dc450ac22c9b704eab0e906d868662\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.06637\",\"authors\":[{\"authorId\":\"1742328079\",\"name\":\"Shaunak Halbe\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"title\":\"Exploring Weaknesses of VQA Models through Attribution Driven Insights\",\"url\":\"https://www.semanticscholar.org/paper/274fffd96aa6c20931ccdf5e1ce6677dcc9fbe75\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"},{\"authorId\":\"2007214491\",\"name\":\"Utkarsh Dwivedi\"},{\"authorId\":\"1393356238\",\"name\":\"Sravya Amancherla\"},{\"authorId\":\"35684404\",\"name\":\"Mayanka Jha\"},{\"authorId\":\"41124627\",\"name\":\"Riya Chanduka\"}],\"doi\":\"10.1145/3373625.3418026\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f6ec17a76e1173c96824e9a0d367b95c9f421dd\",\"title\":\"IncluSet: A Data Surfacing Repository for Accessibility Datasets\",\"url\":\"https://www.semanticscholar.org/paper/7f6ec17a76e1173c96824e9a0d367b95c9f421dd\",\"venue\":\"ASSETS\",\"year\":2020},{\"arxivId\":\"1909.02097\",\"authors\":[{\"authorId\":\"2059199\",\"name\":\"Soravit Changpinyo\"},{\"authorId\":\"144865339\",\"name\":\"Bo Pang\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.18653/v1/D19-1155\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3b6e6822eabe2f64192a1965c23e38043866319c\",\"title\":\"Decoupled Box Proposal and Featurization with Ultrafine-Grained Semantic Labels Improve Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3b6e6822eabe2f64192a1965c23e38043866319c\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7754251\",\"name\":\"Sylvain Lobry\"},{\"authorId\":\"1409495574\",\"name\":\"J. Murray\"},{\"authorId\":\"144173388\",\"name\":\"D. Marcos\"},{\"authorId\":\"2977931\",\"name\":\"D. Tuia\"}],\"doi\":\"10.1109/IGARSS.2019.8898891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3b13f3e7bff346c6116cdd9158dd81cb489dafc\",\"title\":\"Visual Question Answering From Remote Sensing Images\",\"url\":\"https://www.semanticscholar.org/paper/b3b13f3e7bff346c6116cdd9158dd81cb489dafc\",\"venue\":\"IGARSS 2019 - 2019 IEEE International Geoscience and Remote Sensing Symposium\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46500210\",\"name\":\"Abigale Stangl\"}],\"doi\":\"10.1145/3313831.3376404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4501c700e6aefb261efa50a46e1b9091e175cad2\",\"title\":\"\\\"Person, Shoes, Tree. Is the Person Naked?\\\" What People with Vision Impairments Want in Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4501c700e6aefb261efa50a46e1b9091e175cad2\",\"venue\":\"CHI\",\"year\":2020},{\"arxivId\":\"1904.08920\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00851\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"af1f7739283bdbd2b7a94903041f6d6afd991907\",\"title\":\"Towards VQA Models That Can Read\",\"url\":\"https://www.semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48357919\",\"name\":\"L. Guo\"},{\"authorId\":\"3451534\",\"name\":\"Kate K. Mays\"},{\"authorId\":\"1998921\",\"name\":\"Sha Lai\"},{\"authorId\":\"47801182\",\"name\":\"Mona Jalal\"},{\"authorId\":\"1756038\",\"name\":\"P. Ishwar\"},{\"authorId\":\"1723703\",\"name\":\"Margrit Betke\"}],\"doi\":\"10.1177/1077699019891437\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9105ca6940f765bc3865c6b4ebd074e1c5bb006d\",\"title\":\"Accurate, Fast, But Not Always Cheap: Evaluating \\u201cCrowdcoding\\u201d as an Alternative Approach to Analyze Social Media Data\",\"url\":\"https://www.semanticscholar.org/paper/9105ca6940f765bc3865c6b4ebd074e1c5bb006d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.08939\",\"authors\":[{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.1145/3356727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78bf80ce212a5fc0bb0851a12b7f32ea5c85c48d\",\"title\":\"AI and accessibility\",\"url\":\"https://www.semanticscholar.org/paper/78bf80ce212a5fc0bb0851a12b7f32ea5c85c48d\",\"venue\":\"Commun. ACM\",\"year\":2020},{\"arxivId\":\"1811.08481\",\"authors\":[{\"authorId\":\"2909186\",\"name\":\"Ben Zion Vatashsky\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1109/CVPR42600.2020.01039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66ccd32be901da217799c78af229676418c7a882\",\"title\":\"VQA With No Questions-Answers Training\",\"url\":\"https://www.semanticscholar.org/paper/66ccd32be901da217799c78af229676418c7a882\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738647655\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"1438547118\",\"name\":\"Wei-Ting Lu\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"48390820\",\"name\":\"Guanyi Chen\"},{\"authorId\":\"51421297\",\"name\":\"L. Li\"},{\"authorId\":\"1399599427\",\"name\":\"Kees van Deemter\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"775d54f3cb71b066ab8959bee9a282a58a286483\",\"title\":\"Gradations of Error Severity in Automatic Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/775d54f3cb71b066ab8959bee9a282a58a286483\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152538521\",\"name\":\"L. Yang\"},{\"authorId\":\"40156219\",\"name\":\"P. Wang\"},{\"authorId\":\"71200795\",\"name\":\"H. Li\"},{\"authorId\":\"152673839\",\"name\":\"Ye Gao\"},{\"authorId\":\"30973429\",\"name\":\"Linjiang Zhang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ac5713ce2cae2f81dcaa232838b2b552d8965ba\",\"title\":\"A Simple and Strong Convolutional-Attention Network for Irregular Text Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ac5713ce2cae2f81dcaa232838b2b552d8965ba\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"547253984732d770bcb95627048ba3733df62e47\",\"title\":\"Grounded and Ungrounded Referring Expressions in Human Dialogues: Language Mirrors Different Grounding Conditions\",\"url\":\"https://www.semanticscholar.org/paper/547253984732d770bcb95627048ba3733df62e47\",\"venue\":\"CLiC-it\",\"year\":2020},{\"arxivId\":\"2004.08744\",\"authors\":[{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"title\":\"Are we pretraining it right? Digging deeper into visio-linguistic pretraining\",\"url\":\"https://www.semanticscholar.org/paper/43d77f0547f4a1bf4faf29e5e7548564b70e758a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.03160\",\"authors\":[{\"authorId\":\"1557299630\",\"name\":\"Xiaoyu Zeng\"},{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"3428457\",\"name\":\"Tai-Yin Chiu\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1145/3415220\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"72f5a58ac11e98a15e96c413178198b6f1b6e736\",\"title\":\"Vision Skills Needed to Answer Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/72f5a58ac11e98a15e96c413178198b6f1b6e736\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782578\",\"name\":\"Chun-Ju Yang\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"title\":\"Visual Question Answer Diversity\",\"url\":\"https://www.semanticscholar.org/paper/91c184e7fb0c7cce5319b8db85c1488b3861976f\",\"venue\":\"HCOMP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1380065125\",\"name\":\"Narges Honarvar Nazari\"},{\"authorId\":\"90323489\",\"name\":\"J. Hahn\"},{\"authorId\":\"1996796\",\"name\":\"Zaeem Hussain\"},{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/tpami.2019.2947440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86df22f8dbec3489432063ef569a4793dc232c70\",\"title\":\"Interpreting the Rhetoric of Visual Advertisements.\",\"url\":\"https://www.semanticscholar.org/paper/86df22f8dbec3489432063ef569a4793dc232c70\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4222f4a553bd46b2bf61490cb0f99b2719a1bf3\",\"title\":\"Accessibility : A Discussion of Ethical Considerations\",\"url\":\"https://www.semanticscholar.org/paper/e4222f4a553bd46b2bf61490cb0f99b2719a1bf3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.12557\",\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1109/WACV45572.2020.9093353\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb634ac5f4d8166e7ba56bfd089cc0809ac6d71f\",\"title\":\"Hand-Priming in Object Localization for Assistive Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/fb634ac5f4d8166e7ba56bfd089cc0809ac6d71f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2002.08565\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"150353841\",\"name\":\"Yinan Zhao\"},{\"authorId\":\"1409765557\",\"name\":\"Meng Zhang\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"}],\"doi\":\"10.1007/978-3-030-58520-4_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c936d878003254cdab662a966cecd29e8be652d0\",\"title\":\"Captioning Images Taken by People Who Are Blind\",\"url\":\"https://www.semanticscholar.org/paper/c936d878003254cdab662a966cecd29e8be652d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.00753\",\"authors\":[{\"authorId\":\"2429278\",\"name\":\"Chenyu Gao\"},{\"authorId\":\"1476704317\",\"name\":\"Qi Zhu\"},{\"authorId\":\"1585288737\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Hui Li\"},{\"authorId\":\"46398380\",\"name\":\"Y. Liu\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"title\":\"Structured Multimodal Attentions for TextVQA\",\"url\":\"https://www.semanticscholar.org/paper/eeab710608359ec5ada5fe6fe36da134291dd5cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"32113652\",\"name\":\"G. Gandolfi\"},{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"title\":\"Be Different to Be Better! A Benchmark to Leverage the Complementarity of Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48941288\",\"name\":\"T. Akter\"},{\"authorId\":\"1909948\",\"name\":\"Bryan Dosono\"},{\"authorId\":\"1927977\",\"name\":\"T. Ahmed\"},{\"authorId\":\"145728136\",\"name\":\"Apu Kapadia\"},{\"authorId\":\"1403688897\",\"name\":\"Bryan Semaan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0eb4ecdbbf691e9827d5452ae1cd524ba1d017dd\",\"title\":\"\\\"I am uncomfortable sharing what I can't see\\\": Privacy Concerns of the Visually Impaired with Camera Based Assistive Applications\",\"url\":\"https://www.semanticscholar.org/paper/0eb4ecdbbf691e9827d5452ae1cd524ba1d017dd\",\"venue\":\"USENIX Security Symposium\",\"year\":2020},{\"arxivId\":\"2003.12511\",\"authors\":[{\"authorId\":\"3428457\",\"name\":\"Tai-Yin Chiu\"},{\"authorId\":\"31812669\",\"name\":\"Y. Zhao\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1109/cvpr42600.2020.00370\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"795435da0de2cb9772e8ebec9a4242de7e677b30\",\"title\":\"Assessing Image Quality Issues for Real-World Problems\",\"url\":\"https://www.semanticscholar.org/paper/795435da0de2cb9772e8ebec9a4242de7e677b30\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80285408\",\"name\":\"Reeti Mathur\"},{\"authorId\":\"145521690\",\"name\":\"E. Brady\"}],\"doi\":\"10.1145/3234695.3240994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"132b44b95cd0bfe4b6a2d4dfeba1858411f0271d\",\"title\":\"Mixed-Ability Collaboration for Accessible Photo Sharing\",\"url\":\"https://www.semanticscholar.org/paper/132b44b95cd0bfe4b6a2d4dfeba1858411f0271d\",\"venue\":\"ASSETS\",\"year\":2018},{\"arxivId\":\"2007.12750\",\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1410551459\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1005e3d5584fc25d1aa42922d78033c50719bfa\",\"title\":\"Dialog without Dialog Data: Learning Visual Dialog Agents from VQA Data\",\"url\":\"https://www.semanticscholar.org/paper/d1005e3d5584fc25d1aa42922d78033c50719bfa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2005.04790\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"152422011\",\"name\":\"Aravind Mohan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"1389630028\",\"name\":\"Davide Testuggine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51b461040c381cb1489e55ea4b9686c709818b10\",\"title\":\"The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes\",\"url\":\"https://www.semanticscholar.org/paper/51b461040c381cb1489e55ea4b9686c709818b10\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.08899\",\"authors\":[{\"authorId\":\"34317896\",\"name\":\"M. Mathew\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f71a7744fa383a2dbfad5959e78c56220d725eb\",\"title\":\"Document Visual Question Answering Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/1f71a7744fa383a2dbfad5959e78c56220d725eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153673249\",\"name\":\"Guy Meyer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cf4eee5b64bf2c4590cc83bdd2f54ed5a7864ffd\",\"title\":\"Development of a Search Engine Tool for Visually Impaired Web Users\",\"url\":\"https://www.semanticscholar.org/paper/cf4eee5b64bf2c4590cc83bdd2f54ed5a7864ffd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.03607\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"14487640\",\"name\":\"Ari Holtzman\"},{\"authorId\":\"144354055\",\"name\":\"Elizabeth Clark\"},{\"authorId\":\"3444092\",\"name\":\"Lianhui Qin\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2061fa43759830136dc158250c6e20ffcbd5e9b\",\"title\":\"Evaluating Machines by their Real-World Language Use\",\"url\":\"https://www.semanticscholar.org/paper/a2061fa43759830136dc158250c6e20ffcbd5e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143647292\",\"name\":\"F. Liu\"},{\"authorId\":\"49560222\",\"name\":\"Guanghui Xu\"},{\"authorId\":\"1720738301\",\"name\":\"Qi Wu\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"145229535\",\"name\":\"W. Jia\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1145/3394171.3413924\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"title\":\"Cascade Reasoning Network for Text-based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/29df8ed16d3787c710e0128dc1948a95990cc9fb\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"},{\"authorId\":\"1585231765\",\"name\":\"Galena Pisoni\"}],\"doi\":\"10.1145/3386392.3399276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e217f502687c0af8ebe1fe70088e3e94a0db6830\",\"title\":\"Accessible Cultural Heritage through Explainable Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/e217f502687c0af8ebe1fe70088e3e94a0db6830\",\"venue\":\"UMAP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121415349\",\"name\":\"N. Davis\"},{\"authorId\":\"40430520\",\"name\":\"B. Xie\"},{\"authorId\":\"1420431848\",\"name\":\"Danna Gurari\"}],\"doi\":\"10.1002/pra2.251\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"41b8a8de855e43e7b007f851f1be91b4fc29c018\",\"title\":\"Quality of images showing medication packaging from individuals with vision impairments: Implications for the design of visual question answering applications\",\"url\":\"https://www.semanticscholar.org/paper/41b8a8de855e43e7b007f851f1be91b4fc29c018\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"80993542\",\"name\":\"Esha Kothari\"},{\"authorId\":\"3347530\",\"name\":\"S. Jain\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1145/3234695.3236337\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4715303bdb871e57cbb597b7e936a6ef4aa2f71a\",\"title\":\"BrowseWithMe: An Online Clothes Shopping Assistant for People with Visual Impairments\",\"url\":\"https://www.semanticscholar.org/paper/4715303bdb871e57cbb597b7e936a6ef4aa2f71a\",\"venue\":\"ASSETS\",\"year\":2018},{\"arxivId\":\"1812.00148\",\"authors\":[{\"authorId\":\"50111671\",\"name\":\"S. Lee\"},{\"authorId\":\"52214543\",\"name\":\"Madison Reddie\"},{\"authorId\":\"52214205\",\"name\":\"Krish Gurdasani\"},{\"authorId\":\"8415711\",\"name\":\"Xiying Wang\"},{\"authorId\":\"145040474\",\"name\":\"Jordan Beck\"},{\"authorId\":\"1715072\",\"name\":\"M. Rosson\"},{\"authorId\":\"145066246\",\"name\":\"J. Carroll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a8ea9350d84a8ff0d1b7066bee5dac7bea5092f\",\"title\":\"Conversations for Vision: Remote Sighted Assistants Helping People with Visual Impairments\",\"url\":\"https://www.semanticscholar.org/paper/8a8ea9350d84a8ff0d1b7066bee5dac7bea5092f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1912.09336\",\"authors\":[{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd121ca598c0603fdfac1863c4cb16ea1650fc66\",\"title\":\"VizWiz Dataset Browser: A Tool for Visualizing Machine Learning Datasets\",\"url\":\"https://www.semanticscholar.org/paper/bd121ca598c0603fdfac1863c4cb16ea1650fc66\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35613969\",\"name\":\"M. Iwamura\"},{\"authorId\":\"1666706133\",\"name\":\"Naoki Hirabayashi\"},{\"authorId\":\"152910779\",\"name\":\"Z. Cheng\"},{\"authorId\":\"3139154\",\"name\":\"Kazunori Minatani\"},{\"authorId\":\"32027013\",\"name\":\"K. Kise\"}],\"doi\":\"10.1145/3334480.3382983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6818458bbc3fc85f17564d7438b45e3c347f7f7\",\"title\":\"VisPhoto: Photography for People with Visual Impairment as Post-Production of Omni-Directional Camera Image\",\"url\":\"https://www.semanticscholar.org/paper/f6818458bbc3fc85f17564d7438b45e3c347f7f7\",\"venue\":\"CHI Extended Abstracts\",\"year\":2020},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.02227\",\"authors\":[{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"1783184\",\"name\":\"Ece Kamar\"},{\"authorId\":\"4006636\",\"name\":\"Jennifer Wortman Vaughan\"},{\"authorId\":\"1831395\",\"name\":\"H. Wallach\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"}],\"doi\":\"10.1145/3386296.3386298\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74eb6147977d94ac5db4ff779e6d4e53feeed75\",\"title\":\"Toward fairness in AI for people with disabilities SBG@a research roadmap\",\"url\":\"https://www.semanticscholar.org/paper/e74eb6147977d94ac5db4ff779e6d4e53feeed75\",\"venue\":\"ACM SIGACCESS Access. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40474403\",\"name\":\"J. J. Lau\"},{\"authorId\":\"29948554\",\"name\":\"Soumya Gayen\"},{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":\"10.1038/sdata.2018.251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"title\":\"A dataset of clinically generated visual questions and answers about radiology images\",\"url\":\"https://www.semanticscholar.org/paper/18f9a6045ba01cb079c4fa49a630d71bbd27cd92\",\"venue\":\"Scientific Data\",\"year\":2018},{\"arxivId\":\"2010.11163\",\"authors\":[{\"authorId\":\"153673249\",\"name\":\"Guy Meyer\"},{\"authorId\":\"2369906\",\"name\":\"Alan Wassyng\"},{\"authorId\":\"1766205\",\"name\":\"M. Lawford\"},{\"authorId\":\"6833251\",\"name\":\"Kourosh Sabri\"},{\"authorId\":\"144337170\",\"name\":\"S. Shirani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67742a86e695cd3e79e4c211fdeda8d6fe339f66\",\"title\":\"Literature Review of Computer Tools for the Visually Impaired: a focus on Search Engines\",\"url\":\"https://www.semanticscholar.org/paper/67742a86e695cd3e79e4c211fdeda8d6fe339f66\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02659\",\"authors\":[{\"authorId\":\"32097919\",\"name\":\"Terrance Devries\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"20132361\",\"name\":\"Changhan Wang\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a86bdaf401943e36fe34f4461c7761a3e9b99e9\",\"title\":\"Does Object Recognition Work for Everyone?\",\"url\":\"https://www.semanticscholar.org/paper/7a86bdaf401943e36fe34f4461c7761a3e9b99e9\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1911.04058\",\"authors\":[{\"authorId\":\"48615049\",\"name\":\"Y. Xu\"},{\"authorId\":\"46308159\",\"name\":\"L. Chen\"},{\"authorId\":\"120235436\",\"name\":\"Zhongwei Cheng\"},{\"authorId\":\"71138167\",\"name\":\"Lixin Duan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.34\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"title\":\"Open-Ended Visual Question Answering by Multi-Modal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2fdcc61d9a02412f5eb5d596ee41c8504a83c20a\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3701069\",\"name\":\"Saya Takada\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ICIP40778.2020.9191015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f028e95d1d3f1e8a67917713bc03f2655d817b16\",\"title\":\"Estimation Of Visual Contents Based On Question Answering From Human Brain Activity\",\"url\":\"https://www.semanticscholar.org/paper/f028e95d1d3f1e8a67917713bc03f2655d817b16\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2205800\",\"name\":\"Asma Ben Abacha\"},{\"authorId\":\"29948554\",\"name\":\"Soumya Gayen\"},{\"authorId\":\"40474403\",\"name\":\"J. J. Lau\"},{\"authorId\":\"38935013\",\"name\":\"Sivaramakrishnan Rajaraman\"},{\"authorId\":\"1398175407\",\"name\":\"Dina Demner-Fushman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4634bf44a0c994e2bed89686225f8cef601a0224\",\"title\":\"NLM at ImageCLEF 2018 Visual Question Answering in the Medical Domain\",\"url\":\"https://www.semanticscholar.org/paper/4634bf44a0c994e2bed89686225f8cef601a0224\",\"venue\":\"CLEF\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"}],\"doi\":\"10.1145/3266037.3266133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9495905b62cd9e72293b336e3e83c066404cadc\",\"title\":\"Crowd-AI Systems for Non-Visual Information Access in the Real World\",\"url\":\"https://www.semanticscholar.org/paper/c9495905b62cd9e72293b336e3e83c066404cadc\",\"venue\":\"UIST\",\"year\":2018},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2150647\",\"name\":\"Kyungjun Lee\"},{\"authorId\":\"101767253\",\"name\":\"J. Hong\"},{\"authorId\":\"1389222222\",\"name\":\"Simone Pimento\"},{\"authorId\":\"1389222220\",\"name\":\"Ebrima Jarjue\"},{\"authorId\":\"1745229\",\"name\":\"Hernisa Kacorri\"}],\"doi\":\"10.1145/3308561.3353799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"854f7ee708fdb78943c7b67dcf8f3b786d94b9b0\",\"title\":\"Revisiting Blind Photography in the Context of Teachable Object Recognizers\",\"url\":\"https://www.semanticscholar.org/paper/854f7ee708fdb78943c7b67dcf8f3b786d94b9b0\",\"venue\":\"ASSETS\",\"year\":2019},{\"arxivId\":\"2004.04963\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1587/transinf.2020EDP7089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"title\":\"Rephrasing visual questions by specifying the entropy of the answer distribution\",\"url\":\"https://www.semanticscholar.org/paper/d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1908.07144\",\"authors\":[{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"34233160\",\"name\":\"J. Kong\"},{\"authorId\":\"145102182\",\"name\":\"M. Rivera\"},{\"authorId\":\"40027632\",\"name\":\"F. F. Xu\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/3332165.3347873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"933b03a81110676f4c61c449f1926ebd58bc47f7\",\"title\":\"StateLens: A Reverse Engineering Solution for Making Existing Dynamic Touchscreens Accessible\",\"url\":\"https://www.semanticscholar.org/paper/933b03a81110676f4c61c449f1926ebd58bc47f7\",\"venue\":\"UIST\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295297\",\"name\":\"Anubrata Das\"},{\"authorId\":\"3019097\",\"name\":\"Samreen Anjum\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"}],\"doi\":\"10.1002/pra2.7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dfd466f46e6e63368444c1adc95e258a9ff67a3\",\"title\":\"Dataset bias: A case study for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/4dfd466f46e6e63368444c1adc95e258a9ff67a3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.02088\",\"authors\":[{\"authorId\":\"145659406\",\"name\":\"Y. Shi\"},{\"authorId\":\"2426872\",\"name\":\"T. Furlanello\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":\"2047844\",\"name\":\"Anima Anandkumar\"}],\"doi\":\"10.1007/978-3-030-01225-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"title\":\"Question Type Guided Attention in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/80fc9efde5bb28550d17363d882fd5bc6d805c26\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144079770\",\"name\":\"Yingying Zhu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"1661045088\",\"name\":\"Jiong Wang\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"}],\"doi\":\"10.1145/3397271.3401176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"101ff7312884afa4ed62f7ef2ef591f50a0e0183\",\"title\":\"Regional Relation Modeling for Visual Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/101ff7312884afa4ed62f7ef2ef591f50a0e0183\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"2007.01780\",\"authors\":[{\"authorId\":\"31926869\",\"name\":\"A. Pollard\"},{\"authorId\":\"2113093\",\"name\":\"J. Shapiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1b8ffe938f706a9416c319a34793a2389866773\",\"title\":\"Visual Question Answering as a Multi-Task Problem\",\"url\":\"https://www.semanticscholar.org/paper/b1b8ffe938f706a9416c319a34793a2389866773\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1911.09655\",\"authors\":[{\"authorId\":\"1822214\",\"name\":\"Haytham M. Fayek\"},{\"authorId\":\"31039758\",\"name\":\"J. Johnson\"}],\"doi\":\"10.1109/TASLP.2020.3010650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfa437129daef8533708924c395c3fd0c5c3bf81\",\"title\":\"Temporal Reasoning via Audio Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bfa437129daef8533708924c395c3fd0c5c3bf81\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":\"2012.02356\",\"authors\":[{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"72be4e0750cf5591d527d7792aa861353526e311\",\"title\":\"Self-Supervised VQA: Answering Visual Questions using Images and Captions\",\"url\":\"https://www.semanticscholar.org/paper/72be4e0750cf5591d527d7792aa861353526e311\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":3831582,\"doi\":\"10.1109/CVPR.2018.00380\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":14,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"references\":[{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31732712\",\"name\":\"H. MacLeod\"},{\"authorId\":\"2803724\",\"name\":\"C. Bennett\"},{\"authorId\":\"144844426\",\"name\":\"M. Morris\"},{\"authorId\":\"1722375\",\"name\":\"E. Cutrell\"}],\"doi\":\"10.1145/3025453.3025814\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4d7780cff87334906ede9036ed6aafc837997e2\",\"title\":\"Understanding Blind People's Experiences with Computer-Generated Captions of Social Media Images\",\"url\":\"https://www.semanticscholar.org/paper/e4d7780cff87334906ede9036ed6aafc837997e2\",\"venue\":\"CHI\",\"year\":2017},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144168587\",\"name\":\"M. V\\u00e1zquez\"},{\"authorId\":\"1792714\",\"name\":\"A. Steinfeld\"}],\"doi\":\"10.1145/2651380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47bb34b894beb095a31d1ae2526be27926c35954\",\"title\":\"An Assisted Photography Framework to Help Visually Impaired Users Properly Aim a Camera\",\"url\":\"https://www.semanticscholar.org/paper/47bb34b894beb095a31d1ae2526be27926c35954\",\"venue\":\"TCHI\",\"year\":2014},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1704.03162\",\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"2544590\",\"name\":\"A. Elqursh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d674b540dcd968bc302ea4360df3f4e85e994b55\",\"title\":\"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d674b540dcd968bc302ea4360df3f4e85e994b55\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"2925245\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1866029.1866080\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"venue\":\"UIST '10\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Patterson\"},{\"authorId\":null,\"name\":\"J. Hays\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Sun attribute database: Discovering\",\"url\":\"\",\"venue\":\"annotating, and recognizing scene attributes. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 2751\\u20132758. IEEE\",\"year\":2012},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"III -Analyzing the VizWiz dataset (supplements Section 4)\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1968133\",\"name\":\"Shaomei Wu\"},{\"authorId\":\"40558385\",\"name\":\"J. Wieland\"},{\"authorId\":\"9043088\",\"name\":\"Omid Farivar\"},{\"authorId\":\"2930003\",\"name\":\"Julie Schiller\"}],\"doi\":\"10.1145/2998181.2998364\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f56b1043c59727ebac5b6f7c31b5c30a0b84a6f\",\"title\":\"Automatic Alt-text: Computer-generated Image Descriptions for Blind Users on a Social Network Service\",\"url\":\"https://www.semanticscholar.org/paper/5f56b1043c59727ebac5b6f7c31b5c30a0b84a6f\",\"venue\":\"CSCW\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"143694777\",\"name\":\"Frank Keller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f6a4556769e819242d669d073b895f1e45a706f\",\"title\":\"Image Description using Visual Dependency Representations\",\"url\":\"https://www.semanticscholar.org/paper/3f6a4556769e819242d669d073b895f1e45a706f\",\"venue\":\"EMNLP\",\"year\":2013},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144281893\",\"name\":\"Y. Zhong\"},{\"authorId\":\"34071791\",\"name\":\"Pierre J. Garrigues\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/2513383.2513443\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcb297c2daed971d3cb1f7c2e18f049da3182822\",\"title\":\"Real time object scanning using a mobile phone and cloud-based visual search engine\",\"url\":\"https://www.semanticscholar.org/paper/dcb297c2daed971d3cb1f7c2e18f049da3182822\",\"venue\":\"ASSETS\",\"year\":2013},{\"arxivId\":\"1606.06622\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1090\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"0eb859d4184476bd80d5f2090b3401c702f66135\",\"title\":\"Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions\",\"url\":\"https://www.semanticscholar.org/paper/0eb859d4184476bd80d5f2090b3401c702f66135\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1511.02570\",\"authors\":[{\"authorId\":\"71984337\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.24963/ijcai.2017/179\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"title\":\"Explicit Knowledge-based Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0b0a1cd432413978e4ef3d0418ebf3bb07af6c7a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927977\",\"name\":\"T. Ahmed\"},{\"authorId\":\"39179135\",\"name\":\"R. Hoyle\"},{\"authorId\":\"31963703\",\"name\":\"K. Connelly\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145728136\",\"name\":\"Apu Kapadia\"}],\"doi\":\"10.1145/2702123.2702334\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"96140aad50a2b32a61ce922813dd1e620c1cee6d\",\"title\":\"Privacy Concerns and Behaviors of People with Visual Impairments\",\"url\":\"https://www.semanticscholar.org/paper/96140aad50a2b32a61ce922813dd1e620c1cee6d\",\"venue\":\"CHI\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152816925\",\"name\":\"Michele A. Burton\"},{\"authorId\":\"145521691\",\"name\":\"E. Brady\"},{\"authorId\":\"145664318\",\"name\":\"Robin Brewer\"},{\"authorId\":\"35779187\",\"name\":\"Callie Neylan\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"47505369\",\"name\":\"A. Hurst\"}],\"doi\":\"10.1145/2384916.2384941\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6539bd0b923c54c7c79281ab1821d09c65c92c6e\",\"title\":\"Crowdsourcing subjective fashion advice using VizWiz: challenges and opportunities\",\"url\":\"https://www.semanticscholar.org/paper/6539bd0b923c54c7c79281ab1821d09c65c92c6e\",\"venue\":\"ASSETS '12\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/2049536.2049573\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7035e6dde6ac203d7f884faffeaa2066278b4b8a\",\"title\":\"Supporting blind photography\",\"url\":\"https://www.semanticscholar.org/paper/7035e6dde6ac203d7f884faffeaa2066278b4b8a\",\"venue\":\"ASSETS '11\",\"year\":2011},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286640\",\"name\":\"N. Silberman\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-642-33715-4_54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1994ba5946456fc70948c549daf62363f13fa2d\",\"title\":\"Indoor Segmentation and Support Inference from RGBD Images\",\"url\":\"https://www.semanticscholar.org/paper/c1994ba5946456fc70948c549daf62363f13fa2d\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1703.09684\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/ICCV.2017.217\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"915b5b12f9bdebc321e970ecd713458c3479d70e\",\"title\":\"An Analysis of Visual Question Answering Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/915b5b12f9bdebc321e970ecd713458c3479d70e\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39771170\",\"name\":\"Andeep S. Toor\"},{\"authorId\":\"143979395\",\"name\":\"H. Wechsler\"},{\"authorId\":\"144759484\",\"name\":\"M. Nappi\"}],\"doi\":\"10.1145/3095713.3095718\",\"intent\":[\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"a1eb455fa852fb3ee14eb0907a7db9081a42b3a7\",\"title\":\"Question Part Relevance and Editing for Cooperative and Context-Aware VQA (C2VQA)\",\"url\":\"https://www.semanticscholar.org/paper/a1eb455fa852fb3ee14eb0907a7db9081a42b3a7\",\"venue\":\"CBMI\",\"year\":2017},{\"arxivId\":\"1606.05433\",\"authors\":[{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"121177698\",\"name\":\"A. Dick\"},{\"authorId\":\"133678193\",\"name\":\"A. van den Hengel\"}],\"doi\":\"10.1109/TPAMI.2017.2754246\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"title\":\"FVQA: Fact-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b60630911d7746fba06de7c34abe98c9a61c6bcc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30871693\",\"name\":\"D. Adams\"},{\"authorId\":\"1690455\",\"name\":\"L. M. Villaverde\"},{\"authorId\":\"1777424\",\"name\":\"S. Kurniawan\"}],\"doi\":\"10.1145/2504335.2504360\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3578f858be503acb2b5ea3b102b33a0f3cf355ca\",\"title\":\"A qualitative study to support a blind photography mobile application\",\"url\":\"https://www.semanticscholar.org/paper/3578f858be503acb2b5ea3b102b33a0f3cf355ca\",\"venue\":\"PETRA '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Be my eyes\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Wu\"},{\"authorId\":null,\"name\":\"J. Wieland\"},{\"authorId\":null,\"name\":\"O. Farivar\"},{\"authorId\":null,\"name\":\"J. Schiller\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Automatic alttext: Computer-generated image descriptions for blind users on a social network service\",\"url\":\"\",\"venue\":\"CSCW, pages 1180\\u20131992\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1109/CVPRW.2010.5543821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4742fbc64c7b51bba9f29a8f328af3b85e5a2e6\",\"title\":\"VizWiz::LocateIt - enabling blind people to locate objects in their environment\",\"url\":\"https://www.semanticscholar.org/paper/f4742fbc64c7b51bba9f29a8f328af3b85e5a2e6\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops\",\"year\":2010},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145521690\",\"name\":\"E. Brady\"},{\"authorId\":\"1392238578\",\"name\":\"M. Morris\"},{\"authorId\":\"144281893\",\"name\":\"Y. Zhong\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1397284386\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/2470654.2481291\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ad8eacf71dda8fcfbf5ed0e1b86f5bd3b3d0ca0\",\"title\":\"Visual challenges in the everyday lives of blind people\",\"url\":\"https://www.semanticscholar.org/paper/1ad8eacf71dda8fcfbf5ed0e1b86f5bd3b3d0ca0\",\"venue\":\"CHI\",\"year\":2013},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"I -Filtering visual questions (supplements Section 3.2)\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24492532\",\"name\":\"Jian-xiong Xiao\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2010.5539970\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"title\":\"SUN database: Large-scale scene recognition from abbey to zoo\",\"url\":\"https://www.semanticscholar.org/paper/908091b4a8757c3b2f7d9cfa2c4f616ee12c5157\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1503.01817\",\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"118220290\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/2812802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"title\":\"YFCC100M: the new data in multimedia research\",\"url\":\"https://www.semanticscholar.org/paper/354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2598433\",\"name\":\"Walter S. Lasecki\"},{\"authorId\":\"1928967\",\"name\":\"Phyo Thiha\"},{\"authorId\":\"144281893\",\"name\":\"Y. Zhong\"},{\"authorId\":\"145521691\",\"name\":\"E. Brady\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/2513383.2517033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2be456d47795df387b4ca9273e17a785ee184e67\",\"title\":\"Answering visual questions with conversational crowd assistants\",\"url\":\"https://www.semanticscholar.org/paper/2be456d47795df387b4ca9273e17a785ee184e67\",\"venue\":\"ASSETS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50827772\",\"name\":\"G. Patterson\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2012.6247998\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"add89dbbd15b82d8275d712f7f969f1b511f96fd\",\"title\":\"SUN attribute database: Discovering, annotating, and recognizing scene attributes\",\"url\":\"https://www.semanticscholar.org/paper/add89dbbd15b82d8275d712f7f969f1b511f96fd\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014}],\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Crowdsourcing\",\"topicId\":\"85\",\"url\":\"https://www.semanticscholar.org/topic/85\"},{\"topic\":\"Mobile phone\",\"topicId\":\"2623\",\"url\":\"https://www.semanticscholar.org/topic/2623\"},{\"topic\":\"Window blind\",\"topicId\":\"547163\",\"url\":\"https://www.semanticscholar.org/topic/547163\"}],\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"