"{\"abstract\":\"Image and sentence matching has made great progress recently, but it remains challenging due to the large visual-semantic discrepancy. This mainly arises from that the representation of pixel-level image usually lacks of high-level semantic information as in its matched sentence. In this work, we propose a semantic-enhanced image and sentence matching model, which can improve the image representation by learning semantic concepts and then organizing them in a correct semantic order. Given an image, we first use a multi-regional multi-label CNN to predict its semantic concepts, including objects, properties, actions, etc. Then, considering that different orders of semantic concepts lead to diverse semantic meanings, we use a context-gated sentence generation scheme for semantic order learning. It simultaneously uses the image global context containing concept relations as reference and the groundtruth semantic order in the matched sentence as supervision. After obtaining the improved image representation, we learn the sentence representation with a conventional LSTM, and then jointly perform image and sentence matching and sentence generation for model learning. Extensive experiments demonstrate the effectiveness of our learned semantic concepts and order, by achieving the state-of-the-art results on two public benchmark datasets.\",\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\",\"url\":\"https://www.semanticscholar.org/author/144368930\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\",\"url\":\"https://www.semanticscholar.org/author/34902783\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\",\"url\":\"https://www.semanticscholar.org/author/144143336\"}],\"citationVelocity\":34,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"144368926\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fa68cde4db12779adacb70a24961cf09b1adf73\",\"title\":\"Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/0fa68cde4db12779adacb70a24961cf09b1adf73\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00587\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"title\":\"ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1947015\",\"name\":\"Zhaowei Qu\"},{\"authorId\":\"2148442\",\"name\":\"Bingyu Cao\"},{\"authorId\":\"38435706\",\"name\":\"X. Wang\"},{\"authorId\":\"145987554\",\"name\":\"F. Li\"},{\"authorId\":\"47568790\",\"name\":\"Peirong Xu\"},{\"authorId\":\"121860468\",\"name\":\"Luhan Zhang\"}],\"doi\":\"10.3970/cmc.2018.903.694\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f267f73a84deacf93e4761622f84a06c91d977a\",\"title\":\"Feedback LSTM network based on attention for image description generator\",\"url\":\"https://www.semanticscholar.org/paper/1f267f73a84deacf93e4761622f84a06c91d977a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120082097\",\"name\":\"Yiu-ming Cheung\"},{\"authorId\":\"32807533\",\"name\":\"Sheung Wai Chan\"}],\"doi\":\"10.36227/techrxiv.12334688\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"100537744c2039f3a33e0faee255304fe0c69eb6\",\"title\":\"Multiple User Behavior Learning for Enhancing Interactive Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/100537744c2039f3a33e0faee255304fe0c69eb6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021057\",\"name\":\"Chunyan Shao\"},{\"authorId\":\"50445803\",\"name\":\"Chi Zhang\"},{\"authorId\":\"3159484\",\"name\":\"Zaojun Fang\"},{\"authorId\":\"9295205\",\"name\":\"G. Yang\"}],\"doi\":\"10.1109/ACCESS.2019.2962268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ea496f9be2b0bcd9e1df6057fb44210feb80a2b\",\"title\":\"A Deep Learning-Based Semantic Filter for RANSAC-Based Fundamental Matrix Calculation and the ORB-SLAM System\",\"url\":\"https://www.semanticscholar.org/paper/8ea496f9be2b0bcd9e1df6057fb44210feb80a2b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50025815\",\"name\":\"Yongzhi Li\"},{\"authorId\":\"47845273\",\"name\":\"D. Zhang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/cvpr42600.2020.01280\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"title\":\"Visual-Semantic Matching by Exploring High-Order Attention and Distraction\",\"url\":\"https://www.semanticscholar.org/paper/a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15281603\",\"name\":\"Zerui Chen\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2019.8802975\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"title\":\"Augmented Visual-Semantic Embeddings for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1863856\",\"name\":\"Kaimin Wei\"},{\"authorId\":\"2392310\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2996407\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"title\":\"Adversarial Attentive Multi-Modal Embedding Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2003.00392\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01065\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"title\":\"Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"9355577\",\"name\":\"Shangqian Gao\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6784007c4433274b6d04b88c7fe626c25924b5ec\",\"title\":\"Cross-Modal Learning with Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/6784007c4433274b6d04b88c7fe626c25924b5ec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1911.10460\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143672098\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"35119829\",\"name\":\"R. Song\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"7474269\",\"name\":\"Ping-Ping Lin\"},{\"authorId\":\"47099153\",\"name\":\"Xiaoyu Qi\"},{\"authorId\":\"50096056\",\"name\":\"C. Wang\"},{\"authorId\":\"97807965\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1145/3343031.3350571\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0779bca8faec33918338f98c0014e387993d388\",\"title\":\"Neural Storyboard Artist: Visualizing Stories with Coherent Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/e0779bca8faec33918338f98c0014e387993d388\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805478\",\"name\":\"Dheeraj Kumar Peri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"214679a3a2a6a2325a9d168006e58c6150b4eae0\",\"title\":\"Multi-modal learning using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/214679a3a2a6a2325a9d168006e58c6150b4eae0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47012336\",\"name\":\"Xin Fu\"},{\"authorId\":\"152621482\",\"name\":\"Y. Zhao\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecc77dbc9388afac79388ab2aa986d9ffa6c2204\",\"title\":\"Adversarial task-specific learning\",\"url\":\"https://www.semanticscholar.org/paper/ecc77dbc9388afac79388ab2aa986d9ffa6c2204\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118023258\",\"name\":\"X. Wei\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"2694924\",\"name\":\"Y. Li\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"1684705122\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPR42600.2020.01095\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"caabcf61499e00c78d8ee692b8939caf98544a9c\",\"title\":\"Multi-Modality Cross Attention Network for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/caabcf61499e00c78d8ee692b8939caf98544a9c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"},{\"authorId\":\"46669153\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054758\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"517efc27e303d408e36bad4d376884ae87fbbf93\",\"title\":\"Exploring Entity-Level Spatial Relationships for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/517efc27e303d408e36bad4d376884ae87fbbf93\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"1914578421\",\"name\":\"Sabarish Gopalakrishnan\"},{\"authorId\":\"1404315481\",\"name\":\"Raymond Ptucha\"}],\"doi\":\"10.1117/1.JEI.29.2.023013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"360d84f0649d80d3b96846c1cd958b6c54332835\",\"title\":\"Aligned attention for common multimodal embeddings\",\"url\":\"https://www.semanticscholar.org/paper/360d84f0649d80d3b96846c1cd958b6c54332835\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461528\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"46458102\",\"name\":\"L. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"title\":\"CycleMatch: A cycle-consistent embedding network for image-text matching\",\"url\":\"https://www.semanticscholar.org/paper/d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1908.10534\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"93809632\",\"name\":\"Xiang Xu\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCV.2019.00591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"title\":\"Adversarial Representation Learning for Text-to-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"144333684\",\"name\":\"William Chan\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.18653/v1/P18-1085\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"title\":\"Illustrative Language Understanding: Large-Scale Visual Grounding with Image Search\",\"url\":\"https://www.semanticscholar.org/paper/35ebe95db7ab148e25904604d3b06a9412f6b4a4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112305\",\"name\":\"Chunxiao Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"3181822\",\"name\":\"Wenyu Zang\"},{\"authorId\":null,\"name\":\"Bin Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"title\":\"A Neighbor-aware Approach for Image-text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"46764518\",\"name\":\"Zhendong Niu\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.24963/ijcai.2019/720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad748d1772f893b3c8a3857a19292375be259daf\",\"title\":\"Knowledge Aware Semantic Concept Expansion for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/ad748d1772f893b3c8a3857a19292375be259daf\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2001.03712\",\"authors\":[{\"authorId\":\"1435907961\",\"name\":\"Geondo Park\"},{\"authorId\":\"3472799\",\"name\":\"Chihye Han\"},{\"authorId\":\"2570901\",\"name\":\"W. Yoon\"},{\"authorId\":\"30595492\",\"name\":\"Dae-Shik Kim\"}],\"doi\":\"10.1109/WACV45572.2020.9093548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af60c7ea01a5fc0ff48bfbf3dd8b3bf69f86ff48\",\"title\":\"MHSAN: Multi-Head Self-Attention Network for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/af60c7ea01a5fc0ff48bfbf3dd8b3bf69f86ff48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wenhui Li\"},{\"authorId\":null,\"name\":\"Song Yang\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":null,\"name\":\"Dan Song\"},{\"authorId\":null,\"name\":\"Xuanya Li\"}],\"doi\":\"10.1016/j.ipm.2020.102432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"title\":\"Multi-level similarity learning for image-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2010.12126\",\"authors\":[{\"authorId\":\"35432059\",\"name\":\"L. Ren\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"1730455\",\"name\":\"K. Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065af7ecb52354be79f538dac3ca210bf57e7739\",\"title\":\"Beyond the Deep Metric Learning: Enhance the Cross-Modal Matching with Adversarial Discriminative Domain Regularization\",\"url\":\"https://www.semanticscholar.org/paper/065af7ecb52354be79f538dac3ca210bf57e7739\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.06514\",\"authors\":[{\"authorId\":\"144872058\",\"name\":\"Takashi Matsubara\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"743164e8d89d7d6138ce32ee069489d9097bb816\",\"title\":\"Target-Oriented Deformation of Visual-Semantic Embedding Space\",\"url\":\"https://www.semanticscholar.org/paper/743164e8d89d7d6138ce32ee069489d9097bb816\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1387712541\",\"name\":\"Zijin Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1145/3343031.3351055\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42001225313e0f5376a8f4b1759e687225cd9d00\",\"title\":\"Cross-Modal Image-Text Retrieval with Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/42001225313e0f5376a8f4b1759e687225cd9d00\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/tcyb.2020.2985716\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"758890bef9a1a85a25a1f6831a58f00a462476af\",\"title\":\"SMAN: Stacked Multimodal Attention Network for Cross-Modal Image-Text Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/758890bef9a1a85a25a1f6831a58f00a462476af\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2020},{\"arxivId\":\"2010.03403\",\"authors\":[{\"authorId\":\"1490652152\",\"name\":\"Jiwei Wei\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1524912498\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":null,\"name\":\"Zheng Wang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/CVPR42600.2020.01302\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd860c3f8a195d06f64ecf36ef6a78397eb883bd\",\"title\":\"Universal Weighting Metric Learning for Cross-Modal Matching\",\"url\":\"https://www.semanticscholar.org/paper/dd860c3f8a195d06f64ecf36ef6a78397eb883bd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.07459\",\"authors\":[{\"authorId\":\"103393695\",\"name\":\"C. Jiang\"},{\"authorId\":\"3560734\",\"name\":\"Steven Weikai Lu\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3467c9977b875544221abbd8153facf2cb176759\",\"title\":\"Constructing Dynamic Knowledge Graph for Visual Semantic Understanding and Applications in Autonomous Robotics\",\"url\":\"https://www.semanticscholar.org/paper/3467c9977b875544221abbd8153facf2cb176759\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"101084939\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/ACCESS.2020.2975594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"284cd0512ecd5d7cec335b0038444085398ebaf5\",\"title\":\"Multi-Modal Memory Enhancement Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/284cd0512ecd5d7cec335b0038444085398ebaf5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1908.04011\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350875\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"title\":\"Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"2285442\",\"name\":\"M. Xu\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":\"10.1145/3383184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"title\":\"Dual-path Convolutional Image-Text Embeddings with Instance Loss\",\"url\":\"https://www.semanticscholar.org/paper/58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2004.00277\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01093\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"title\":\"Graph Structured Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"39937384\",\"name\":\"Yan Huang\"},{\"authorId\":\"145769446\",\"name\":\"L. Wang\"}],\"doi\":\"10.1145/3394171.3413895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98b354ddfa46ccf9fc604c751eb9deebf4c909f8\",\"title\":\"Textual Dependency Embedding for Person Search by Language\",\"url\":\"https://www.semanticscholar.org/paper/98b354ddfa46ccf9fc604c751eb9deebf4c909f8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"145987795\",\"name\":\"M. A. Lopes\"},{\"authorId\":\"145877010\",\"name\":\"Douglas M. Souza\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/ICCV.2019.00590\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84010f883e9a7283666a6628226016ca4f8d28f1\",\"title\":\"Language-Agnostic Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/84010f883e9a7283666a6628226016ca4f8d28f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2004.09144\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8185538174d9f751125407cad3687994ff08fadb\",\"title\":\"Transformer Reasoning Network for Image-Text Matching and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8185538174d9f751125407cad3687994ff08fadb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.1145/3372278.3390674\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"title\":\"Forward and Backward Multimodal NMT for Improved Monolingual and Multilingual Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8a5e6f4fb5ed60d43e2dd51944456440eff28fb\",\"title\":\"*OH, Weon Geun and *KO, Jong-Gook\",\"url\":\"https://www.semanticscholar.org/paper/c8a5e6f4fb5ed60d43e2dd51944456440eff28fb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.05134\",\"authors\":[{\"authorId\":\"49184936\",\"name\":\"S. Wang\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"12977859\",\"name\":\"Z. Yao\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/WACV45572.2020.9093614\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c9f1b9e51c1d16c346e1ef679c243d61702a8a80\",\"title\":\"Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c9f1b9e51c1d16c346e1ef679c243d61702a8a80\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732300163\",\"name\":\"Y. Guo\"},{\"authorId\":\"12564022\",\"name\":\"J. Chen\"},{\"authorId\":\"7214794\",\"name\":\"H. Zhang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3372278.3390709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1ac5e2f4d70b26ee7e79ee30a38f64676b404a\",\"title\":\"Visual Relations Augmented Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3d1ac5e2f4d70b26ee7e79ee30a38f64676b404a\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999410\",\"name\":\"Zhibin Hu\"},{\"authorId\":\"40132308\",\"name\":\"Yongsheng Luo\"},{\"authorId\":\"46698321\",\"name\":\"Jiong Lin\"},{\"authorId\":\"144761066\",\"name\":\"Yan Yan\"},{\"authorId\":\"5869774\",\"name\":\"J. Chen\"}],\"doi\":\"10.24963/ijcai.2019/111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10012e6a7a0ad10391533326b95bd1291df6f199\",\"title\":\"Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/10012e6a7a0ad10391533326b95bd1291df6f199\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79647482\",\"name\":\"Letitia Parcalabescu\"},{\"authorId\":\"143876555\",\"name\":\"A. Frank\"}],\"doi\":\"10.1109/CVPRW50498.2020.00489\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c18dcb2b99cb50ff8dc485fee41cd3c39a5e2089\",\"title\":\"Exploring Phrase Grounding without Training: Contextualisation and Extension to Text-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c18dcb2b99cb50ff8dc485fee41cd3c39a5e2089\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47987162\",\"name\":\"Hao Wu\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"51437593\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"143872729\",\"name\":\"Weiwei Sun\"},{\"authorId\":\"1712167\",\"name\":\"W. Ma\"}],\"doi\":\"10.1109/CVPR.2019.00677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"title\":\"Unified Visual-Semantic Embeddings: Bridging Vision and Language With Structured Meaning Representations\",\"url\":\"https://www.semanticscholar.org/paper/08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2041284719\",\"name\":\"Tao Zhi\"},{\"authorId\":\"1768459301\",\"name\":\"Yingchun Fan\"},{\"authorId\":\"145062063\",\"name\":\"Hong Han\"}],\"doi\":\"10.1109/ACCESS.2020.3044169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"072ed263dd4b98569173b41e846020f0cc737e15\",\"title\":\"Cross-Modal Retrieval via Similarity-Preserving Learning and Semantic Average Embedding\",\"url\":\"https://www.semanticscholar.org/paper/072ed263dd4b98569173b41e846020f0cc737e15\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1911.05978\",\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"},{\"authorId\":\"1406355360\",\"name\":\"Aniket Pednekar\"},{\"authorId\":\"1406355394\",\"name\":\"A. Krishnamoorthy\"},{\"authorId\":\"113477341\",\"name\":\"Kazoo Sone\"},{\"authorId\":\"40632403\",\"name\":\"S. Basu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ea46e70da5e0882ac6e08afd8a9f6285abfb12a\",\"title\":\"HUSE: Hierarchical Universal Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/0ea46e70da5e0882ac6e08afd8a9f6285abfb12a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.04402\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/CVPR.2019.00208\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a39d5919531a56de0e36f6b76142041b5d508213\",\"title\":\"Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961512\",\"name\":\"Yi-Ling Wu\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"2847159\",\"name\":\"Guoli Song\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3343031.3350940\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1830b5c741aa93b417e15ca1e26e56dfe83d3ce9\",\"title\":\"Learning Fragment Self-Attention Embeddings for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1830b5c741aa93b417e15ca1e26e56dfe83d3ce9\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1109/DSAA.2019.00029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"title\":\"Cross-Media Image-Text Retrieval Combined with Global Similarity and Local Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"venue\":\"2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743434\",\"name\":\"W. Cheng\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fa1076a98a15cec083fb474f238237f1b3a341a\",\"title\":\"Towards Unconstrained Pointing Problem of Visual Question Answering: A Retrieval-based Method\",\"url\":\"https://www.semanticscholar.org/paper/6fa1076a98a15cec083fb474f238237f1b3a341a\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2002.10016\",\"authors\":[{\"authorId\":\"52200777\",\"name\":\"Hadi Abdi Khojasteh\"},{\"authorId\":\"31459942\",\"name\":\"Ebrahim Ansari\"},{\"authorId\":\"2671497\",\"name\":\"Parvin Razzaghi\"},{\"authorId\":\"2369481\",\"name\":\"Akbar Karimi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61ee052718bdeae8ab352359bf2828bf7b2b0e45\",\"title\":\"Deep Multimodal Image-Text Embeddings for Automatic Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/61ee052718bdeae8ab352359bf2828bf7b2b0e45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-030-30645-8_66\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f378be13df9e97e15ca240b60a0a0aa16d5eb64\",\"title\":\"Artpedia: A New Visual-Semantic Dataset with Visual and Contextual Sentences in the Artistic Domain\",\"url\":\"https://www.semanticscholar.org/paper/6f378be13df9e97e15ca240b60a0a0aa16d5eb64\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1016/j.patcog.2020.107359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"title\":\"Stacked squeeze-and-excitation recurrent residual network for visual-semantic matching\",\"url\":\"https://www.semanticscholar.org/paper/124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"145093507\",\"name\":\"Yao Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3300939\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70e80065c4db089c3792245535ecacdca3770577\",\"title\":\"Modality-Invariant Image-Text Embedding for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/70e80065c4db089c3792245535ecacdca3770577\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453661830\",\"name\":\"Keyu Wen\"},{\"authorId\":\"27698074\",\"name\":\"X. Gu\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1a5d86ff2012a868a23c0defb83c90400e30706\",\"title\":\"Dual Semantic Relationship Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/b1a5d86ff2012a868a23c0defb83c90400e30706\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1807.08381\",\"authors\":[{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1007/978-3-030-10925-7_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e05f4e761aded7f9feefafc802bbd28b15a4690d\",\"title\":\"Pedestrian Trajectory Prediction with Structured Memory Hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/e05f4e761aded7f9feefafc802bbd28b15a4690d\",\"venue\":\"ECML/PKDD\",\"year\":2018},{\"arxivId\":\"1909.09953\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b488019592d8e0c08e6cd011ae0543a6ac451357\",\"title\":\"Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators\",\"url\":\"https://www.semanticscholar.org/paper/b488019592d8e0c08e6cd011ae0543a6ac451357\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"},{\"authorId\":\"3431037\",\"name\":\"J. Qi\"},{\"authorId\":\"79633139\",\"name\":\"Yunkan Zhuo\"}],\"doi\":\"10.1109/TIP.2019.2952085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f03ed79925004dcc28b3c7af33759463d08884e\",\"title\":\"MAVA: Multi-Level Adaptive Visual-Textual Alignment by Cross-Media Bi-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/3f03ed79925004dcc28b3c7af33759463d08884e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2020.2995815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"title\":\"Enhancing Cross-Modal Retrieval Based on Modality-Specific and Embedding Spaces\",\"url\":\"https://www.semanticscholar.org/paper/5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1904.09471\",\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/ICCV.2019.00585\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3d2d1f64a11ca9234716a777dedc962586930a9\",\"title\":\"Saliency-Guided Attention Network for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/a3d2d1f64a11ca9234716a777dedc962586930a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.00500\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.01074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"title\":\"Multi-Task Learning of Hierarchical Vision-Language Representation\",\"url\":\"https://www.semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47012336\",\"name\":\"Xin Fu\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"49339608\",\"name\":\"Yufeng Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/TMM.2019.2957948\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c2195652dddf015880ceacefd811a3df7cae30c\",\"title\":\"Rich Features Embedding for Cross-Modal Retrieval: A Simple Baseline\",\"url\":\"https://www.semanticscholar.org/paper/7c2195652dddf015880ceacefd811a3df7cae30c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1909.02701\",\"authors\":[{\"authorId\":\"49243413\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"47003439\",\"name\":\"Yuanyuan Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/ICCV.2019.00475\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"title\":\"Visual Semantic Reasoning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"46389488\",\"name\":\"H. Ma\"}],\"doi\":\"10.1109/ACCESS.2020.2969808\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"title\":\"Combining Global and Local Similarity for Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.08883\",\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"72095125\",\"name\":\"Y. Zhang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"}],\"doi\":\"10.1007/978-3-030-58586-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe573437cbd4069556348ad28dfeae2df46e22a0\",\"title\":\"Consensus-Aware Visual-Semantic Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/fe573437cbd4069556348ad28dfeae2df46e22a0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47166189\",\"name\":\"Xiaojing Yu\"},{\"authorId\":\"2648459\",\"name\":\"Tianlong Chen\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1516504563\",\"name\":\"M. Mugo\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/ICCVW.2019.00223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5522c0d74d37ee5e0bca6aae9026cb5994bf7a7d\",\"title\":\"Cross-Modal Person Search: A Coarse-to-Fine Framework using Bi-Directional Text-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/5522c0d74d37ee5e0bca6aae9026cb5994bf7a7d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430216\",\"name\":\"Y. Tamaazousti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"619404bf9fd0f55eeabb94f0cebf190399c57f0a\",\"title\":\"Vers l\\u2019universalit\\u00e9 des repr\\u00e9sentations visuelle et multimodales\",\"url\":\"https://www.semanticscholar.org/paper/619404bf9fd0f55eeabb94f0cebf190399c57f0a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.06892\",\"authors\":[{\"authorId\":\"49289638\",\"name\":\"Yaxian Xia\"},{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"},{\"authorId\":\"40445654\",\"name\":\"Jie Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80a56c659dd1ab8675f01560ac5757a7f872ffa2\",\"title\":\"ParNet: Position-aware Aggregated Relation Network for Image-Text matching\",\"url\":\"https://www.semanticscholar.org/paper/80a56c659dd1ab8675f01560ac5757a7f872ffa2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143629526\",\"name\":\"Longzheng Cai\"},{\"authorId\":\"1563801223\",\"name\":\"Shuyun Lim\"},{\"authorId\":\"50142418\",\"name\":\"X. Wang\"},{\"authorId\":\"11799720\",\"name\":\"L. Tang\"}],\"doi\":\"10.1007/978-981-15-3308-2_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d13f332ccdfc00a915d8434a9263c57771aa012\",\"title\":\"Can Deep Neural Networks Learn Broad Semantic Concepts of Images?\",\"url\":\"https://www.semanticscholar.org/paper/9d13f332ccdfc00a915d8434a9263c57771aa012\",\"venue\":\"ICGEC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a26d15d75febf100209cd5d198e8046be9c51f9\",\"title\":\"Re-ranking image-text matching by adaptive metric fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a26d15d75febf100209cd5d198e8046be9c51f9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1909.11416\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3343031.3350869\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"2d149507610400ddc2f2b29d9a39f7688b613039\",\"title\":\"Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2d149507610400ddc2f2b29d9a39f7688b613039\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.03493\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1609/AAAI.V34I07.6785\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77802591c3f5b3f654bb5b68ad62ed056769320f\",\"title\":\"MULE: Multimodal Universal Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/77802591c3f5b3f654bb5b68ad62ed056769320f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3323873.3325043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"title\":\"Improving What Cross-Modal Retrieval Models Learn through Object-Oriented Inter- and Intra-Modal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41017837\",\"name\":\"Zhuobin Zheng\"},{\"authorId\":\"80414744\",\"name\":\"Youcheng Ben\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"title\":\"Multi-Scale Visual Semantics Aggregation with Self-Attention for End-to-End Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"venue\":\"ACML\",\"year\":2019},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03772\",\"authors\":[{\"authorId\":\"67228310\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"46522306\",\"name\":\"Xudong Liu\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"102551205\",\"name\":\"J. Liu\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/cvpr42600.2020.01267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a\",\"title\":\"IMRAM: Iterative Matching With Recurrent Attention Memory for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805478\",\"name\":\"Dheeraj Kumar Peri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71f67d2c184e6557a0a3ca1635979ac7b7227e28\",\"title\":\"Multi-modal learning using deep neural networks by Dheeraj Kumar Peri November 2018\",\"url\":\"https://www.semanticscholar.org/paper/71f67d2c184e6557a0a3ca1635979ac7b7227e28\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.06066\",\"authors\":[{\"authorId\":\"150112700\",\"name\":\"Gen Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"143795948\",\"name\":\"Yuejian Fang\"},{\"authorId\":\"71790825\",\"name\":\"Daxin Jiang\"},{\"authorId\":\"143849622\",\"name\":\"M. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I07.6795\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bc1c8bd00bbf7401afcb5460277840fd8bab029\",\"title\":\"Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/2bc1c8bd00bbf7401afcb5460277840fd8bab029\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30814238\",\"name\":\"W. Wei\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"49958606\",\"name\":\"Heng Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ACCESS.2020.2992187\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7bdfb3fde985493fc53c379cb79ef4a5da2977a3\",\"title\":\"Boosting Cross-Modal Retrieval With MVSE++ and Reciprocal Neighbors\",\"url\":\"https://www.semanticscholar.org/paper/7bdfb3fde985493fc53c379cb79ef4a5da2977a3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"98608166\",\"name\":\"M. Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/TIP.2020.3038354\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"title\":\"Deep Relation Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"3374688\",\"name\":\"M. Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":null,\"name\":\"Heng Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"}],\"doi\":\"10.1016/J.PATREC.2019.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749f376d0addb83569fcc7536e46308abbb232d4\",\"title\":\"How much do cross-modal related semantics benefit image captioning by weighting attributes and re-ranking sentences?\",\"url\":\"https://www.semanticscholar.org/paper/749f376d0addb83569fcc7536e46308abbb232d4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"46911598\",\"name\":\"Lin Zuo\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2020.2967597\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"title\":\"Cross-Modal Attention With Semantic Consistence for Image\\u2013Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3343031.3350894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"title\":\"Annotation Efficient Cross-Modal Retrieval with Adversarial Attentive Alignment\",\"url\":\"https://www.semanticscholar.org/paper/b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1903.06275\",\"authors\":[{\"authorId\":\"38916638\",\"name\":\"Dheeraj Peri\"},{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"1749833\",\"name\":\"R. Ptucha\"}],\"doi\":\"10.1109/ICIP.2019.8802922\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95a467d6522baf373034820f5c097fc414d73d1e\",\"title\":\"Show, Translate and Tell\",\"url\":\"https://www.semanticscholar.org/paper/95a467d6522baf373034820f5c097fc414d73d1e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2010.02949\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.60\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"73068d13d6e53876c374ebd4c862ec01351c9f39\",\"title\":\"Learning to Represent Image and Text with Denotation Graph\",\"url\":\"https://www.semanticscholar.org/paper/73068d13d6e53876c374ebd4c862ec01351c9f39\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.04305\",\"authors\":[{\"authorId\":\"1918424\",\"name\":\"Jiacheng Chen\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"1906061249\",\"name\":\"Changhu Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"title\":\"Learning the Best Pooling Strategy for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471463062\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1522102572\",\"name\":\"Zhen Lei\"},{\"authorId\":\"1415720379\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"title\":\"Context-Aware Attention Network for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"83a6fd8eadd36c22bdac861bd2b20aba87968c3d\",\"title\":\"Material for \\u201c Multitask Learning of Hierarchical Vision-Language Representation \\u201d\",\"url\":\"https://www.semanticscholar.org/paper/83a6fd8eadd36c22bdac861bd2b20aba87968c3d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7314814\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1435766877\",\"name\":\"Gu Xiao-peng\"}],\"doi\":\"10.1145/3362065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d39fb70393e9a17e5556708852829743380eeed\",\"title\":\"ACMNet: Adaptive Confidence Matching Network for Human Behavior Analysis via Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0d39fb70393e9a17e5556708852829743380eeed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1909.06635\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"25080314\",\"name\":\"Teresa Botschen\"},{\"authorId\":\"1730400\",\"name\":\"Iryna Gurevych\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"}],\"doi\":\"10.1109/ICCVW.2019.00557\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f81c842e37eb0c22528f1bf569514b379cf489ea\",\"title\":\"Joint Wasserstein Autoencoders for Aligning Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/f81c842e37eb0c22528f1bf569514b379cf489ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020}],\"corpusId\":4519459,\"doi\":\"10.1109/CVPR.2018.00645\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":18,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"references\":[{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/ICIP.2013.6738596\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca52604845b36d61be6b30f9b481f9136f202932\",\"title\":\"Multi-task deep neural network for multi-label learning\",\"url\":\"https://www.semanticscholar.org/paper/ca52604845b36d61be6b30f9b481f9136f202932\",\"venue\":\"2013 IEEE International Conference on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1605.01379\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1007/978-3-319-46475-6_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c94217efec8773ef947df2772f92df8c5726f855\",\"title\":\"Leveraging Visual Question Answering for Image-Caption Ranking\",\"url\":\"https://www.semanticscholar.org/paper/c94217efec8773ef947df2772f92df8c5726f855\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TMM.2015.2476658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e7702f8992572dcfabc9262b9d15b82236a0d47\",\"title\":\"Unconstrained Multimodal Multi-Label Learning\",\"url\":\"https://www.semanticscholar.org/paper/8e7702f8992572dcfabc9262b9d15b82236a0d47\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"3344005\",\"name\":\"C. Dance\"}],\"doi\":\"10.1109/CVPR.2007.383266\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23694b6d61668e62bb11f17c1d75dde3b4951948\",\"title\":\"Fisher Kernels on Visual Vocabularies for Image Categorization\",\"url\":\"https://www.semanticscholar.org/paper/23694b6d61668e62bb11f17c1d75dde3b4951948\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2017.767\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1604.04573\",\"authors\":[{\"authorId\":\"152924487\",\"name\":\"Jiang Wang\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"48908475\",\"name\":\"C. Huang\"},{\"authorId\":\"40515617\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f321e268990e3e1a792d4bcf829600caab41e1e\",\"title\":\"CNN-RNN: A Unified Framework for Multi-label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/6f321e268990e3e1a792d4bcf829600caab41e1e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1608.07973\",\"authors\":[{\"authorId\":\"3451681\",\"name\":\"Aviv Eisenschtat\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2017.201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2616e0fbce43362a338acedcbb5cd80db7bbb7e5\",\"title\":\"Linking Image and Text with 2-Way Nets\",\"url\":\"https://www.semanticscholar.org/paper/2616e0fbce43362a338acedcbb5cd80db7bbb7e5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"144529354\",\"name\":\"Wei Xia\"},{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"1753492\",\"name\":\"Junshi Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145550812\",\"name\":\"J. Dong\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TPAMI.2015.2491929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32d850e556f39f6bbedcdef0e38f5cd295a6144f\",\"title\":\"HCP: A Flexible CNN Framework for Multi-Label Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/32d850e556f39f6bbedcdef0e38f5cd295a6144f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/CVPR.2015.7298966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"title\":\"Deep correlation for matching images and text\",\"url\":\"https://www.semanticscholar.org/paper/efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2278628\",\"name\":\"Y. Yu\"},{\"authorId\":\"48908475\",\"name\":\"C. Huang\"},{\"authorId\":\"144887704\",\"name\":\"K. Yu\"}],\"doi\":\"10.1109/CVPR.2015.7298968\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ebb4ded00ac91538460e8c06e5733cc00ba44e\",\"title\":\"Deep multiple instance learning for image classification and auto-annotation\",\"url\":\"https://www.semanticscholar.org/paper/29ebb4ded00ac91538460e8c06e5733cc00ba44e\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.5726\",\"authors\":[{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"144529354\",\"name\":\"Wei Xia\"},{\"authorId\":\"1753492\",\"name\":\"Junshi Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"145550812\",\"name\":\"J. Dong\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":\"10.1109/TPAMI.2015.2491929\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67bb920c40b161a543f29943e7d945789ef208cd\",\"title\":\"CNN: Single-label to Multi-label\",\"url\":\"https://www.semanticscholar.org/paper/67bb920c40b161a543f29943e7d945789ef208cd\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1312.4894\",\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"145266091\",\"name\":\"Thomas Leung\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b049d8cfea6c3bed377090e0e7fa677d282a361\",\"title\":\"Deep Convolutional Ranking for Multilabel Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/3b049d8cfea6c3bed377090e0e7fa677d282a361\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1109/ICCV.2017.442\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"90208e8cbda1f39f3d06e41d97898408b13192a7\",\"title\":\"Learning a Recurrent Residual Fusion Network for Multimodal Matching\",\"url\":\"https://www.semanticscholar.org/paper/90208e8cbda1f39f3d06e41d97898408b13192a7\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017}],\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"topics\":[{\"topic\":\"Supercomputer\",\"topicId\":\"9282\",\"url\":\"https://www.semanticscholar.org/topic/9282\"},{\"topic\":\"Multi-label classification\",\"topicId\":\"31117\",\"url\":\"https://www.semanticscholar.org/topic/31117\"},{\"topic\":\"Nvidia DGX-1\",\"topicId\":\"2516702\",\"url\":\"https://www.semanticscholar.org/topic/2516702\"},{\"topic\":\"Organizing (structure)\",\"topicId\":\"7824\",\"url\":\"https://www.semanticscholar.org/topic/7824\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Sion's minimax theorem\",\"topicId\":\"860227\",\"url\":\"https://www.semanticscholar.org/topic/860227\"},{\"topic\":\"Gated community\",\"topicId\":\"916892\",\"url\":\"https://www.semanticscholar.org/topic/916892\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Discrepancy function\",\"topicId\":\"1146712\",\"url\":\"https://www.semanticscholar.org/topic/1146712\"}],\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"