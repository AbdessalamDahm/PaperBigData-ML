"{\"abstract\":\"Human conversation is a complex mechanism with subtle nuances. It is hence an ambitious goal to develop artificial intelligence agents that can participate fluently in a conversation. While we are still far from achieving this goal, recent progress in visual question answering, image captioning, and visual question generation shows that dialog systems may be realizable in the not too distant future. To this end, a novel dataset was introduced recently and encouraging results were demonstrated, particularly for question answering. In this paper, we demonstrate a simple symmetric discriminative baseline, that can be applied to both predicting an answer as well as predicting a question. We show that this method performs on par with the state of the art, even memory net based methods. In addition, for the first time on the visual dialog dataset, we assess the performance of a system asking questions, and demonstrate how visual dialog can be generated from discriminative question generation and question answering.\",\"arxivId\":\"1803.11186\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\",\"url\":\"https://www.semanticscholar.org/author/10680632\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\",\"url\":\"https://www.semanticscholar.org/author/1749609\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\",\"url\":\"https://www.semanticscholar.org/author/2068227\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.06196\",\"authors\":[{\"authorId\":\"89840297\",\"name\":\"T. Liu\"},{\"authorId\":\"153293827\",\"name\":\"Q. Fang\"},{\"authorId\":\"3068001\",\"name\":\"Wenbiao Ding\"},{\"authorId\":\"4574975\",\"name\":\"Zhongqin Wu\"},{\"authorId\":\"14631164\",\"name\":\"Zhiwei Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28080d9b0307fe6ba754d44047b8f2fb55b77bcc\",\"title\":\"Mathematical Word Problem Generation from Commonsense Knowledge Graph and Equations\",\"url\":\"https://www.semanticscholar.org/paper/28080d9b0307fe6ba754d44047b8f2fb55b77bcc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47540106\",\"name\":\"J. Zhang\"},{\"authorId\":\"50828249\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1016/j.ipm.2019.102152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ff7b42d8cc37acfc08210cff20983090a968308\",\"title\":\"Multi-Modal fusion with multi-level attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2ff7b42d8cc37acfc08210cff20983090a968308\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.01124\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01237-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"title\":\"Straight to the Facts: Learning Knowledge Base Retrieval for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d88eb94d7054d2668b1a8dfa311721f37ae1f059\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582059215\",\"name\":\"Austin Kershaw\"},{\"authorId\":\"144048413\",\"name\":\"M. Bober\"}],\"doi\":\"10.18653/v1/W19-0603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25cf62b795a84896f2d2dc2e4f770ed8edc874a6\",\"title\":\"The Lexical Gap: An Improved Measure of Automated Image Description Quality\",\"url\":\"https://www.semanticscholar.org/paper/25cf62b795a84896f2d2dc2e4f770ed8edc874a6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.02379\",\"authors\":[{\"authorId\":\"46258988\",\"name\":\"Vishvak S. Murahari\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"}],\"doi\":\"10.1007/978-3-030-58523-5_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"604d7678235f5bb6039794e382d12058cecf8070\",\"title\":\"Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline\",\"url\":\"https://www.semanticscholar.org/paper/604d7678235f5bb6039794e382d12058cecf8070\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1906.02622\",\"authors\":[{\"authorId\":\"26161085\",\"name\":\"Kalpesh Krishna\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"}],\"doi\":\"10.18653/v1/P19-1224\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8da992b611df508b1803f66ffa53bd1fb741a76c\",\"title\":\"Generating Question-Answer Hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/8da992b611df508b1803f66ffa53bd1fb741a76c\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2008.04858\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"1643931890\",\"name\":\"Siyi Du\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"}],\"doi\":\"10.1145/3394171.3413826\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"title\":\"KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.05728\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"152264213\",\"name\":\"Shivansh Patel\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"title\":\"Granular Multimodal Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2cdd7267c95f00728e214439d41ad3efb6457ab6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.03322\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"9072379\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"336cad600d15832243f4228b351c638630d64cb7\",\"title\":\"Learning to Respond with Your Favorite Stickers: A Framework of Unifying Multi-Modality and User Preference in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/336cad600d15832243f4228b351c638630d64cb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.10496\",\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"title\":\"Two Causal Principles for Improving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TIP.2020.3034494\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"title\":\"Learning Dual Encoding Model for Adaptive Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1785405226\",\"name\":\"Xiaofan Chen\"},{\"authorId\":\"1716428\",\"name\":\"Songyang Lao\"},{\"authorId\":\"1789237897\",\"name\":\"Ting Duan\"}],\"doi\":\"10.1145/3438872.3439098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0867cec490d447b02c25abaa00363606f205b9c9\",\"title\":\"Multimodal Fusion of Visual Dialog: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/0867cec490d447b02c25abaa00363606f205b9c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.10802\",\"authors\":[{\"authorId\":\"2239880\",\"name\":\"I. Gat\"},{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5dde64865d7620079e0f50ef27b32bbebef7af\",\"title\":\"Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies\",\"url\":\"https://www.semanticscholar.org/paper/da5dde64865d7620079e0f50ef27b32bbebef7af\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1902.08355\",\"authors\":[{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"144231469\",\"name\":\"T. Gao\"},{\"authorId\":\"16110760\",\"name\":\"Sohee Yang\"},{\"authorId\":\"8351571\",\"name\":\"Jaejun Yoo\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dde473b9280b115ae4405e5dc936a6e913aa573\",\"title\":\"Large-Scale Answerer in Questioner's Mind for Visual Dialog Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/0dde473b9280b115ae4405e5dc936a6e913aa573\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.18653/v1/D19-1217\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"title\":\"Video Dialog via Progressive Inference and Cross-Transformer\",\"url\":\"https://www.semanticscholar.org/paper/142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"title\":\"Efficient Attention Mechanism for Handling All the Interactions between Many Inputs with Application to Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fe05479dc4bf2698fcc4e29f09743f8eb1b0f9ec\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126416\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ICME.2019.00270\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"title\":\"Visual Dialog with Targeted Objects\",\"url\":\"https://www.semanticscholar.org/paper/16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.00579\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P19-1648\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"title\":\"Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1809.00681\",\"authors\":[{\"authorId\":\"2479187\",\"name\":\"Moitreya Chatterjee\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1007/978-3-030-01216-8_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27973d90c1427369cb10aa0202d671f0422e21e\",\"title\":\"Diverse and Coherent Paragraph Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/a27973d90c1427369cb10aa0202d671f0422e21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1811.00538\",\"authors\":[{\"authorId\":\"153137839\",\"name\":\"M. Narasimhan\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad08da5951437c117551a63c2f8b943bee2029ce\",\"title\":\"Out of the Box: Reasoning with Graph Convolution Nets for Factual Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad08da5951437c117551a63c2f8b943bee2029ce\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04679\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"}],\"doi\":\"10.1145/3366423.3380191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab771b7431f5d3dce4372a18555f4216528ace7\",\"title\":\"Learning to Respond with Stickers: A Framework of Unifying Multi-Modality in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/3ab771b7431f5d3dce4372a18555f4216528ace7\",\"venue\":\"WWW\",\"year\":2020}],\"corpusId\":4454615,\"doi\":\"10.1109/CVPR.2018.00603\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":1,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"references\":[{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1610.02424\",\"authors\":[{\"authorId\":\"3358971\",\"name\":\"Ashwin K. Vijayakumar\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e4dd95c4341ec7d14317a3d97022773a0822906c\",\"title\":\"Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/e4dd95c4341ec7d14317a3d97022773a0822906c\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1803.11209\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"143668320\",\"name\":\"W. Hwu\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e81df94c24c08963c7d338d601bb030a8d919720\",\"title\":\"Interpretable and Globally Optimal Prediction for Textual Grounding using Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/e81df94c24c08963c7d338d601bb030a8d919720\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1506.02075\",\"authors\":[{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e565308c8081e807709cb4a917443b737e6cdb4\",\"title\":\"Large-scale Simple Question Answering with Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/6e565308c8081e807709cb4a917443b737e6cdb4\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65911798\",\"name\":\"A. Spring\"},{\"authorId\":\"7753714\",\"name\":\"M. Lewerentz\"},{\"authorId\":\"32009199\",\"name\":\"T. Bluhm\"},{\"authorId\":\"144508212\",\"name\":\"P. Heimann\"},{\"authorId\":\"24269814\",\"name\":\"C. Hennig\"},{\"authorId\":\"92119326\",\"name\":\"G. K\\u00fchner\"},{\"authorId\":\"153933286\",\"name\":\"H. Kroiss\"},{\"authorId\":\"40378213\",\"name\":\"J. Krom\"},{\"authorId\":\"152933601\",\"name\":\"H. Laqua\"},{\"authorId\":\"46816398\",\"name\":\"J. Maier\"},{\"authorId\":\"40588319\",\"name\":\"H. Riemann\"},{\"authorId\":\"46356567\",\"name\":\"J. Schacht\"},{\"authorId\":\"49058670\",\"name\":\"A. Werner\"},{\"authorId\":\"7411314\",\"name\":\"M. Zilker\"}],\"doi\":\"10.1007/3-540-26367-5_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"70fd66e78add02052f0883363e1d80dcd3f6baab\",\"title\":\"A\",\"url\":\"https://www.semanticscholar.org/paper/70fd66e78add02052f0883363e1d80dcd3f6baab\",\"venue\":\"Therapielexikon Neurologie\",\"year\":2005},{\"arxivId\":\"1711.04323\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799537fa855caf53a6a3a7cf20301a81e90da127\",\"title\":\"High-Order Attention Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/799537fa855caf53a6a3a7cf20301a81e90da127\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"},{\"authorId\":\"1630291637\",\"name\":\"Delle Scienze Umane\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630390134\",\"name\":\"Progetto BiologiaAmbiente\"},{\"authorId\":\"1630311779\",\"name\":\"Profilo IN Uscita\"},{\"authorId\":\"1630291648\",\"name\":\"Il Liceo\"}],\"doi\":\"10.1515/9783111413426-013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"title\":\"L\",\"url\":\"https://www.semanticscholar.org/paper/5385b3c2cef5138d2f4f9127ec7565eb8043a1c4\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1611.01144\",\"authors\":[{\"authorId\":\"145116380\",\"name\":\"Eric Jang\"},{\"authorId\":\"2046135\",\"name\":\"Shixiang Gu\"},{\"authorId\":\"16443937\",\"name\":\"Ben Poole\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29e944711a354c396fad71936f536e83025b6ce0\",\"title\":\"Categorical Reparameterization with Gumbel-Softmax\",\"url\":\"https://www.semanticscholar.org/paper/29e944711a354c396fad71936f536e83025b6ce0\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1709.07192\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"47353404\",\"name\":\"X. Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47aff6477f05ec32fc163e1943fe9464a8379552\",\"title\":\"Visual Question Generation as Dual Task of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47aff6477f05ec32fc163e1943fe9464a8379552\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Xu\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Ask\",\"url\":\"\",\"venue\":\"attend and answer: Exploring question-guided spatial attention for visual question answering. In ECCV\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1603.08023\",\"authors\":[{\"authorId\":\"50557647\",\"name\":\"C. Liu\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"35224828\",\"name\":\"I. Serban\"},{\"authorId\":\"38107789\",\"name\":\"Michael Noseworthy\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"}],\"doi\":\"10.18653/v1/D16-1230\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"129cbad01be98ee88a930e31898cb76be79c41c1\",\"title\":\"How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/129cbad01be98ee88a930e31898cb76be79c41c1\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.00333\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"title\":\"Learning to Answer Questions from Image Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/98bd5dd1740f585bf25320ba504e2c1ae57f2e5f\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1502.01852\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/ICCV.2015.123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"title\":\"Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification\",\"url\":\"https://www.semanticscholar.org/paper/d6f2f611da110b5b5061731be3fc4c7f45d8ee23\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Jabri\"},{\"authorId\":null,\"name\":\"A. Joulin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"van der Maaten. Revisiting visual question answering baselines. In ECCV\",\"year\":2016},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1704.03493\",\"authors\":[{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"3095572\",\"name\":\"Ziyu Zhang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2017.575\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"title\":\"Creativity: Generating Diverse Questions Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/390cac0a7e2f90c8efb12a1a9ff850ef386e5db6\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"title\":\"Deep Compositional Question Answering with Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/0ac8f1a3c679b90d22c1f840cdc8d61ffef750ac\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1711.07068\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"82247c9e74ddebb4dce65560ee69620579358f2d\",\"title\":\"Diverse and Accurate Image Description Using a Variational Auto-Encoder with an Additive Gaussian Encoding Space\",\"url\":\"https://www.semanticscholar.org/paper/82247c9e74ddebb4dce65560ee69620579358f2d\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Das\"},{\"authorId\":null,\"name\":\"H. Agrawal\"},{\"authorId\":null,\"name\":\"C. L. Zitnick\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and D\",\"url\":\"\",\"venue\":\"Batra. Human attention in visual question answering: Do humans and deep networks look at the same regions? In EMNLP\",\"year\":2016},{\"arxivId\":\"1803.11185\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"021b08b823700f8053afc54356e8d0ce57a3df71\",\"title\":\"Unsupervised Textual Grounding: Linking Words to Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/021b08b823700f8053afc54356e8d0ce57a3df71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1603.06059\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":\"10.18653/v1/P16-1170\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"title\":\"Generating Natural Questions About an Image\",\"url\":\"https://www.semanticscholar.org/paper/8ae09bb88506aa667ac01642f0cbc9dbb30a628d\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":\"1705.06676\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/ICCV.2017.285\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"title\":\"MUTAN: Multimodal Tucker Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fe466e84fa2e838adc3c37ee327cd68004ae08fe\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Xu\"},{\"authorId\":null,\"name\":\"J. Ba\"},{\"authorId\":null,\"name\":\"R. Kiros\"},{\"authorId\":null,\"name\":\"K. Cho\"},{\"authorId\":null,\"name\":\"A. Courville\"},{\"authorId\":null,\"name\":\"R. Salakhudinov\"},{\"authorId\":null,\"name\":\"R. Zemel\"},{\"authorId\":null,\"name\":\"Y. Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Show\",\"url\":\"\",\"venue\":\"attend and tell: Neural image caption generation with visual attention. In ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1092\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"venue\":\"EMNLP 2016\",\"year\":2016}],\"title\":\"Two Can Play This Game: Visual Dialog with Discriminative Question Generation and Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Dialog system\",\"topicId\":\"83260\",\"url\":\"https://www.semanticscholar.org/topic/83260\"},{\"topic\":\"Discriminative model\",\"topicId\":\"39987\",\"url\":\"https://www.semanticscholar.org/topic/39987\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Statistical classification\",\"topicId\":\"715\",\"url\":\"https://www.semanticscholar.org/topic/715\"}],\"url\":\"https://www.semanticscholar.org/paper/36bb1983dceb84f33d9adcf4ef032c9b0aeed1e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"