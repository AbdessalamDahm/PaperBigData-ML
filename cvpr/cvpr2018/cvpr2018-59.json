"{\"abstract\":\"Most approaches for video frame interpolation require accurate dense correspondences to synthesize an in-between frame. Therefore, they do not perform well in challenging scenarios with e.g. lighting changes or motion blur. Recent deep learning approaches that rely on kernels to represent motion can only alleviate these problems to some extent. In those cases, methods that use a per-pixel phase-based motion representation have been shown to work well. However, they are only applicable for a limited amount of motion. We propose a new approach, PhaseNet, that is designed to robustly handle challenging scenarios while also coping with larger motion. Our approach consists of a neural network decoder that directly estimates the phase decomposition of the intermediate frame. We show that this is superior to the hand-crafted heuristics previously used in phase-based methods and also compares favorably to recent deep learning based approaches for video frame interpolation on challenging datasets.\",\"arxivId\":\"1804.00884\",\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\",\"url\":\"https://www.semanticscholar.org/author/50113176\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\",\"url\":\"https://www.semanticscholar.org/author/1763523\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\",\"url\":\"https://www.semanticscholar.org/author/46936952\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\",\"url\":\"https://www.semanticscholar.org/author/1388791172\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\",\"url\":\"https://www.semanticscholar.org/author/144877478\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\",\"url\":\"https://www.semanticscholar.org/author/2604867\"}],\"citationVelocity\":19,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"32764534\",\"name\":\"Songnan Lin\"},{\"authorId\":\"1519062623\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"1625349614\",\"name\":\"Zhe Jiang\"},{\"authorId\":\"2780914\",\"name\":\"Dongqing Zou\"},{\"authorId\":null,\"name\":\"Yongtian Wang\"},{\"authorId\":\"47739910\",\"name\":\"J. Chen\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"}],\"doi\":\"10.1007/978-3-030-58598-3_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b949d975aac0d5864b9f27ecc517f198571b4ccf\",\"title\":\"Learning Event-Driven Video Deblurring and Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b949d975aac0d5864b9f27ecc517f198571b4ccf\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144796690\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"title\":\"High-speed Video from Asynchronous Camera Array Si\",\"url\":\"https://www.semanticscholar.org/paper/1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"},{\"authorId\":\"92733026\",\"name\":\"Soon-chul Kwon\"},{\"authorId\":\"1773696\",\"name\":\"Ji-Sang Yoo\"}],\"doi\":\"10.3390/sym11101251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"title\":\"A Fast 4K Video Frame Interpolation Using a Multi-Scale Optical Flow Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739216152\",\"name\":\"Zhuojun Cai\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"1629984773\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1117/1.JEI.29.3.033005\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0bf0db08152f35e9b9ab65e3e7ba7e6cd305c75\",\"title\":\"Video super-resolution with phase-aided deformable alignment network\",\"url\":\"https://www.semanticscholar.org/paper/d0bf0db08152f35e9b9ab65e3e7ba7e6cd305c75\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150258541\",\"name\":\"Paulino Cristovao\"},{\"authorId\":\"1754192\",\"name\":\"H. Nakada\"},{\"authorId\":\"144739206\",\"name\":\"Yusuke Tanimura\"},{\"authorId\":\"7142317\",\"name\":\"Hideki Asoh\"}],\"doi\":\"10.1109/ACCESS.2020.3016313\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb617a6b46c8f3b6bccaf8974853143d161221ed\",\"title\":\"Generating In-Between Images Through Learned Latent Space Representation Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/bb617a6b46c8f3b6bccaf8974853143d161221ed\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145567286\",\"name\":\"Hoang Le\"},{\"authorId\":\"50208066\",\"name\":\"F. Liu\"}],\"doi\":\"10.1111/cgf.13860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26d8da3d2f67e914aa564942d2721e89e221ef52\",\"title\":\"Appearance Flow Completion for Novel View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/26d8da3d2f67e914aa564942d2721e89e221ef52\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"2002.12259\",\"authors\":[{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.00516\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"title\":\"Blurry Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98080420\",\"name\":\"Hyeongmin Lee\"},{\"authorId\":\"48271129\",\"name\":\"Taeoh Kim\"},{\"authorId\":\"3305074\",\"name\":\"Tae-Young Chung\"},{\"authorId\":\"48322708\",\"name\":\"Daehyun Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"3055035\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"946a9a5d18a423de9c109087ecae818809276b9c\",\"title\":\"Learning Spatial Transform for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/946a9a5d18a423de9c109087ecae818809276b9c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.12622\",\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"51268282\",\"name\":\"Keunsoo Ko\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1007/978-3-030-58568-6_7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"title\":\"BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"151270904\",\"name\":\"Zhaojing Wen\"},{\"authorId\":\"151483658\",\"name\":\"Wenxue Cui\"},{\"authorId\":\"39618906\",\"name\":\"Rui Wang\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"}],\"doi\":\"10.1109/ICME.2019.00304\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"title\":\"Continuous Bidirectional Optical Flow for Video Frame Sequence Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/614abce0a5e2dcade4c34e903e3bb67329d7c3d8\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1904.10898\",\"authors\":[{\"authorId\":\"89952912\",\"name\":\"M. Claus\"},{\"authorId\":\"21225169\",\"name\":\"J. V. Gemert\"}],\"doi\":\"10.1109/CVPRW.2019.00235\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b42fd2d5e4167a5b4c29b71e086ce2487032a6e\",\"title\":\"ViDeNN: Deep Blind Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/0b42fd2d5e4167a5b4c29b71e086ce2487032a6e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626101034\",\"name\":\"Nguyen Van Thang\"},{\"authorId\":\"1390764531\",\"name\":\"Kyujoong Lee\"},{\"authorId\":\"3090069\",\"name\":\"Hyuk-Jae Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2982039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"title\":\"A Stacked Deep MEMC Network for Frame Rate Up Conversion and its Application to HEVC\",\"url\":\"https://www.semanticscholar.org/paper/1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.05193\",\"authors\":[{\"authorId\":\"102580872\",\"name\":\"Andr\\u00e9 Nortje\"},{\"authorId\":\"40021784\",\"name\":\"Herman A. Engelbrecht\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1012d2e369d1bc0b49f201fad95fd851bc654467\",\"title\":\"Deep motion estimation for parallel inter-frame prediction in video compression\",\"url\":\"https://www.semanticscholar.org/paper/1012d2e369d1bc0b49f201fad95fd851bc654467\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.00263\",\"authors\":[{\"authorId\":\"12601304\",\"name\":\"Qiangeng Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Weiyue Wang\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1109/WACV45572.2020.9093530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"title\":\"Stochastic Dynamics for Video Infilling\",\"url\":\"https://www.semanticscholar.org/paper/56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.04642\",\"authors\":[{\"authorId\":\"49422053\",\"name\":\"Yihao Liu\"},{\"authorId\":\"1604613100\",\"name\":\"Liangbin Xie\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"title\":\"Enhanced Quadratic Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153690347\",\"name\":\"Yoonmo Yang\"},{\"authorId\":\"1831183\",\"name\":\"Byung Tae Oh\"}],\"doi\":\"10.1016/j.image.2020.115982\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"title\":\"Video frame interpolation using deep cascaded network structure\",\"url\":\"https://www.semanticscholar.org/paper/a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"1907.10244\",\"authors\":[{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"3191728\",\"name\":\"T. Chung\"},{\"authorId\":\"48322708\",\"name\":\"D. Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00536\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"title\":\"AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"49521471\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2936549\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"title\":\"FI-Net: A Lightweight Video Frame Interpolation Network Using Feature-Level Flow\",\"url\":\"https://www.semanticscholar.org/paper/00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66152807\",\"name\":\"J. Lee\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"34273166\",\"name\":\"Hoang M. Le\"},{\"authorId\":\"153035663\",\"name\":\"F. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"title\":\"/ Appearance Flow Completion for Novel View Synthesis Dense Flow Estimator Sparse Flow Estimator Sparse Flow Estimator Sparse Flow Estimator\",\"url\":\"https://www.semanticscholar.org/paper/55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1901.06034\",\"authors\":[{\"authorId\":\"144796690\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/WACV.2019.00237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9ed892e7787805e2202d006687ac69fea6bab0a5\",\"title\":\"High-Speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/9ed892e7787805e2202d006687ac69fea6bab0a5\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123797012\",\"name\":\"Christopher May\"},{\"authorId\":\"145869839\",\"name\":\"M. Oliveira\"},{\"authorId\":\"1698910\",\"name\":\"D. Aliaga\"}],\"doi\":\"10.1109/TVCG.2020.2992670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"title\":\"Video Folding: Increased Framerate for Semi-Repetitive Sequences.\",\"url\":\"https://www.semanticscholar.org/paper/e37d7a35e7bf448f027e5e33d1a91143d18b7ad2\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2020},{\"arxivId\":\"1905.10240\",\"authors\":[{\"authorId\":\"2469811\",\"name\":\"Yunpeng Li\"},{\"authorId\":\"3181733\",\"name\":\"Dominik Roblek\"},{\"authorId\":\"1749128\",\"name\":\"M. Tagliasacchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"063700c45e10362f5642c08849348c41ee5b08a3\",\"title\":\"From Here to There: Video Inbetweening Using Direct 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/063700c45e10362f5642c08849348c41ee5b08a3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47690278\",\"name\":\"Zhe Ren\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"48739844\",\"name\":\"Wenlong Liao\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1109/TIP.2020.3024015\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9479abb2673e847e88ee8c8a06bcf18aab4338b4\",\"title\":\"STFlow: Self-Taught Optical Flow Estimation Using Pseudo Labels\",\"url\":\"https://www.semanticscholar.org/paper/9479abb2673e847e88ee8c8a06bcf18aab4338b4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.02909\",\"authors\":[{\"authorId\":\"9757384\",\"name\":\"Woon-Sung Park\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b87df69011057c700f581798e8c13667f5205b8e\",\"title\":\"Deep Predictive Video Compression with Bi-directional Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b87df69011057c700f581798e8c13667f5205b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471436975\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"2257525\",\"name\":\"W. Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"},{\"authorId\":\"104009756\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/ACCESS.2019.2959019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"title\":\"Video Frame Synthesis via Plug-and-Play Deep Locally Temporal Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\"}],\"doi\":\"10.1109/CVPR.2019.00250\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9508145\",\"name\":\"Morten Hannemose\"},{\"authorId\":\"144454181\",\"name\":\"Janus N\\u00f8rtoft Jensen\"},{\"authorId\":\"48660142\",\"name\":\"G. Einarsson\"},{\"authorId\":\"2579225\",\"name\":\"J. Wilm\"},{\"authorId\":\"2253200\",\"name\":\"A. Dahl\"},{\"authorId\":\"2661305\",\"name\":\"J. Frisvad\"}],\"doi\":\"10.1007/978-3-030-20205-7_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"title\":\"Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow\",\"url\":\"https://www.semanticscholar.org/paper/7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"venue\":\"SCIA\",\"year\":2019},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"144816141\",\"name\":\"J. Campos\"},{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/ICCV.2019.00652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"title\":\"Neural Inter-Frame Compression for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/f587e6b59d4c5ff21efa076ac9349b3b6d777a34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2005.01233\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"48206011\",\"name\":\"Hee-won Kim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152283843\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"1585142097\",\"name\":\"Zhiyong Gaon\"},{\"authorId\":\"2812984\",\"name\":\"G. Chen\"},{\"authorId\":\"7774660\",\"name\":\"Yunhua Lu\"},{\"authorId\":\"46585842\",\"name\":\"R. Duan\"},{\"authorId\":\"150321531\",\"name\":\"Tong Liu\"},{\"authorId\":\"47059427\",\"name\":\"L. Zhang\"},{\"authorId\":\"120878650\",\"name\":\"Woonsung Park\"},{\"authorId\":\"47596916\",\"name\":\"M. Kim\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"104101992\",\"name\":\"L. Aloni\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"116295634\",\"name\":\"Ze Pan\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00421\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3247a8640db63c638a1386493a87202aa2a0b15b\",\"title\":\"AIM 2019 Challenge on Video Temporal Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/3247a8640db63c638a1386493a87202aa2a0b15b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91926911\",\"name\":\"Minho Park\"},{\"authorId\":\"2909533\",\"name\":\"Sangmin Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054744\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"title\":\"Video Frame Interpolation Via Exceptional Motion-Aware Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2002.12680\",\"authors\":[{\"authorId\":\"7000208\",\"name\":\"Yu-yu Guo\"},{\"authorId\":\"49117537\",\"name\":\"Lei Bi\"},{\"authorId\":\"2130901\",\"name\":\"Euijoon Ahn\"},{\"authorId\":\"11675891\",\"name\":\"D. Feng\"},{\"authorId\":\"49110419\",\"name\":\"Q. Wang\"},{\"authorId\":\"46454386\",\"name\":\"Jinman Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.00478\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57561a45ccde67ea6e3db870e4994106e4d61a69\",\"title\":\"A Spatiotemporal Volumetric Interpolation Network for 4D Dynamic Medical Image\",\"url\":\"https://www.semanticscholar.org/paper/57561a45ccde67ea6e3db870e4994106e4d61a69\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1809.07759\",\"authors\":[{\"authorId\":\"84509959\",\"name\":\"Mart Kartasev\"},{\"authorId\":\"84650046\",\"name\":\"Carlo Rapisarda\"},{\"authorId\":\"47414172\",\"name\":\"Dominik Fay\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"f1aed5cd540275f86b7019e494be57437c604715\",\"title\":\"Implementing Adaptive Separable Convolution for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f1aed5cd540275f86b7019e494be57437c604715\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.13170\",\"authors\":[{\"authorId\":\"145879931\",\"name\":\"M. Haris\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.1109/CVPR42600.2020.00293\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"title\":\"Space-Time-Aware Multi-Resolution Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c54199e6f1f9553ab32148f60c7e49af55cc1d6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102510752\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"153731442\",\"name\":\"Zhiyong Gao\"}],\"doi\":\"10.1109/TIP.2020.3033617\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"title\":\"Video Frame Interpolation and Enhancement via Pyramid Recurrent Framework\",\"url\":\"https://www.semanticscholar.org/paper/a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yiding Wang\"},{\"authorId\":\"2601624\",\"name\":\"Weiyan Wang\"},{\"authorId\":\"1908497\",\"name\":\"Junxue Zhang\"},{\"authorId\":\"1727978\",\"name\":\"J. Jiang\"},{\"authorId\":\"40611817\",\"name\":\"K. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ba6bb6915df9b352ed8be591f50ed3d00244670\",\"title\":\"Bridging the Edge-Cloud Barrier for Real-time Advanced Vision Analytics\",\"url\":\"https://www.semanticscholar.org/paper/7ba6bb6915df9b352ed8be591f50ed3d00244670\",\"venue\":\"HotCloud\",\"year\":2019},{\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/CVPR42600.2020.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.08872\",\"authors\":[{\"authorId\":\"1573986321\",\"name\":\"Liad Pollak Zuckerman\"},{\"authorId\":\"1944189\",\"name\":\"S. Bagon\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"}],\"doi\":\"10.1007/978-3-030-58571-6_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02772404c8c6e1903a00798ce01492bc6820f665\",\"title\":\"Across Scales \\\\& Across Dimensions: Temporal Super-Resolution using Deep Internal Learning\",\"url\":\"https://www.semanticscholar.org/paper/02772404c8c6e1903a00798ce01492bc6820f665\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98485019\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"title\":\"High-speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.12106\",\"authors\":[{\"authorId\":\"51308376\",\"name\":\"A. Paliwal\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"}],\"doi\":\"10.1109/TPAMI.2020.2987316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c82944c88e0be99857a280d8246593842c515a0\",\"title\":\"Deep Slow Motion Video Reconstruction With Hybrid Imaging System\",\"url\":\"https://www.semanticscholar.org/paper/5c82944c88e0be99857a280d8246593842c515a0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2141bb1226997c49123731d97b484ca19696485a\",\"title\":\"Robust Temporal Super-Resolution for Dynamic Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/2141bb1226997c49123731d97b484ca19696485a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.23919/EUSIPCO.2019.8903168\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"title\":\"IEST: Interpolation-Enhanced Shearlet Transform for Light Field Reconstruction Using Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"145037825\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1109/ICIP.2019.8803678\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a3078e39137a59af12f49a985c3b1e1765d51eba\",\"title\":\"Frame Interpolation Using Phase and Amplitude Feature Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/a3078e39137a59af12f49a985c3b1e1765d51eba\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1456030258\",\"name\":\"Wei Xue\"},{\"authorId\":\"119636186\",\"name\":\"H. Ai\"},{\"authorId\":\"48789454\",\"name\":\"Tianyu Sun\"},{\"authorId\":\"3358591\",\"name\":\"Chunfeng Song\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.neucom.2019.11.015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f2ec817c142710d6f53e90c1ff25327b823eddb\",\"title\":\"Frame-GAN: Increasing the frame rate of gait videos with generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/4f2ec817c142710d6f53e90c1ff25327b823eddb\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753738047\",\"name\":\"Kshitija Pandya\"},{\"authorId\":\"1753737879\",\"name\":\"Disha Varshney\"},{\"authorId\":\"1753607722\",\"name\":\"Ashray Aggarwal\"},{\"authorId\":\"115827410\",\"name\":\"Anil Singh Parihar\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"682e288a5870f182e0f92bb4735f5659dff8b94c\",\"title\":\"An Analytical Study of CNN-based Video Frame Interpolation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/682e288a5870f182e0f92bb4735f5659dff8b94c\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":\"1912.08776\",\"authors\":[{\"authorId\":\"1469278809\",\"name\":\"Simon Biland\"},{\"authorId\":\"40331104\",\"name\":\"V. C. Azevedo\"},{\"authorId\":\"48925478\",\"name\":\"Byungsoo Kim\"},{\"authorId\":\"1789549\",\"name\":\"B. Solenthaler\"}],\"doi\":\"10.2312/egs.20201019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de6c4f79355b51267be1e2f9a59fe0005f09323d\",\"title\":\"Frequency-Aware Reconstruction of Fluid Simulations with Generative Networks\",\"url\":\"https://www.semanticscholar.org/paper/de6c4f79355b51267be1e2f9a59fe0005f09323d\",\"venue\":\"Eurographics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48915513\",\"name\":\"P. Johnston\"},{\"authorId\":\"1807106\",\"name\":\"Eyad Elyan\"}],\"doi\":\"10.1016/J.DIIN.2019.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"title\":\"A review of digital video tampering: From simple editing to full synthesis\",\"url\":\"https://www.semanticscholar.org/paper/cd5080bc7bc45a40ed55b3f3c809dbba44698a5d\",\"venue\":\"Digit. Investig.\",\"year\":2019},{\"arxivId\":\"2004.11566\",\"authors\":[{\"authorId\":\"102460658\",\"name\":\"Kai Fukami\"},{\"authorId\":\"151486054\",\"name\":\"K. Fukagata\"},{\"authorId\":\"51093147\",\"name\":\"Kunihiko Taira\"}],\"doi\":\"10.1017/jfm.2020.948\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5722e8069a2ef43338455c514e4b3e8910ee8326\",\"title\":\"Machine learning based spatio-temporal super resolution reconstruction of turbulent flows\",\"url\":\"https://www.semanticscholar.org/paper/5722e8069a2ef43338455c514e4b3e8910ee8326\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10755743\",\"name\":\"Takayuki Nakatsuka\"},{\"authorId\":\"2844427\",\"name\":\"M. Hamanaka\"},{\"authorId\":\"1490867805\",\"name\":\"Shigeo Morishima\"}],\"doi\":\"10.5220/0008876600270035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"title\":\"Audio-guided Video Interpolation via Human Pose Features\",\"url\":\"https://www.semanticscholar.org/paper/6c1de74772253f4b9ebb4ea86b1602fa1445786f\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486417554\",\"name\":\"Ren-Yu Tseng\"},{\"authorId\":\"1604961801\",\"name\":\"Yao-Kai Liu\"},{\"authorId\":\"37284667\",\"name\":\"Ju-Chin Chen\"},{\"authorId\":\"21754565\",\"name\":\"Kawuu W. Lin\"}],\"doi\":\"10.1109/TAAI48200.2019.8959822\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"title\":\"Adaptive Frame Interpolation using an End-to-End Deep Net with High Quality Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"venue\":\"2019 International Conference on Technologies and Applications of Arti\\ufb01cial Intelligence (TAAI)\",\"year\":2019},{\"arxivId\":\"1809.03258\",\"authors\":[{\"authorId\":\"9179750\",\"name\":\"Omar Hommos\"},{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-030-11024-6_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23dbada22825613e7c616eb60af0c8a812372f3b\",\"title\":\"Using phase instead of optical flow for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/23dbada22825613e7c616eb60af0c8a812372f3b\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2004.00779\",\"authors\":[{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"},{\"authorId\":\"9535762\",\"name\":\"Janghoon Choi\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"title\":\"Scene-Adaptive Video Frame Interpolation via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2939143\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"title\":\"A Multi-Scale Position Feature Transform Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019}],\"corpusId\":4565517,\"doi\":\"10.1109/CVPR.2018.00059\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"references\":[{\"arxivId\":\"1609.02974\",\"authors\":[{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1145/2980179.2980251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"title\":\"Learning-based view synthesis for light field cameras\",\"url\":\"https://www.semanticscholar.org/paper/8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49121996\",\"name\":\"William M. Marsden\"}],\"doi\":\"10.1017/CBO9781139207249.009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3d2218b17e7898a222e5fc2079a3f1531990708f\",\"title\":\"I and J\",\"url\":\"https://www.semanticscholar.org/paper/3d2218b17e7898a222e5fc2079a3f1531990708f\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1704.04186\",\"authors\":[{\"authorId\":\"1761777\",\"name\":\"Y. Zhang\"},{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1109/CVPR.2017.61\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c673908b8bc0ebc24fd11e2420c76affd366b826\",\"title\":\"Video Acceleration Magnification\",\"url\":\"https://www.semanticscholar.org/paper/c673908b8bc0ebc24fd11e2420c76affd366b826\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1601.07532\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-54193-8_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3788cb8e73e1c0a62b762731da7769288a9098c9\",\"title\":\"Learning to Extract Motion from Videos in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3788cb8e73e1c0a62b762731da7769288a9098c9\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2017.244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00016-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"title\":\"P\",\"url\":\"https://www.semanticscholar.org/paper/db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2717546\",\"name\":\"Zhoutong Zhang\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"}],\"doi\":\"10.1109/CVPR.2015.7299004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0403cfef558374856bc412ad7f8b5b51b23e4f4d\",\"title\":\"Light field from micro-baseline image pair\",\"url\":\"https://www.semanticscholar.org/paper/0403cfef558374856bc412ad7f8b5b51b23e4f4d\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8de174ab5419b9d3127695405efd079808e956e8\",\"title\":\"Curriculum learning\",\"url\":\"https://www.semanticscholar.org/paper/8de174ab5419b9d3127695405efd079808e956e8\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1612.01925\",\"authors\":[{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"153200643\",\"name\":\"N. Mayer\"},{\"authorId\":\"2872102\",\"name\":\"Tonmoy Saikia\"},{\"authorId\":\"3316866\",\"name\":\"Margret Keuper\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2017.179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"title\":\"FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/edd846e76cacfba5be37da99c006e3ccc9b861b0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"37021642\",\"name\":\"F. Huang\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"}],\"doi\":\"10.1145/1576246.1531348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"title\":\"Moving gradients: a path-based method for plausible image interpolation\",\"url\":\"https://www.semanticscholar.org/paper/d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"venue\":\"SIGGRAPH '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620868474\",\"name\":\"E. M. S. J. xviii\"},{\"authorId\":\"1620865685\",\"name\":\"Pere Labat\"}],\"doi\":\"10.1515/9783050077338-026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04ca08a80bcd972baa3ef89441f3749f99e8e0b2\",\"title\":\"Y\",\"url\":\"https://www.semanticscholar.org/paper/04ca08a80bcd972baa3ef89441f3749f99e8e0b2\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/ICIP.1995.537667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89b6a5a136bc0a938b792df6bdde134def28335e\",\"title\":\"The steerable pyramid: a flexible architecture for multi-scale derivative computation\",\"url\":\"https://www.semanticscholar.org/paper/89b6a5a136bc0a938b792df6bdde134def28335e\",\"venue\":\"Proceedings., International Conference on Image Processing\",\"year\":1995},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143794407\",\"name\":\"X. Hao\"},{\"authorId\":\"8273966\",\"name\":\"Guigang Zhang\"},{\"authorId\":\"144153753\",\"name\":\"Shang Ma\"}],\"doi\":\"10.1142/S1793351X16500045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f8d648c52edf74e41b0996128aa536e13cc7e82\",\"title\":\"Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4f8d648c52edf74e41b0996128aa536e13cc7e82\",\"venue\":\"Int. J. Semantic Comput.\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25158111\",\"name\":\"Ekta Prashnani\"},{\"authorId\":\"1716245\",\"name\":\"M. Noorkami\"},{\"authorId\":\"144839435\",\"name\":\"D. Vaquero\"},{\"authorId\":\"143881938\",\"name\":\"P. Sen\"}],\"doi\":\"10.1111/cgf.12940\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7034d165c73c19cbdfe116fd1c4463f61958c20a\",\"title\":\"A Phase\\u2010Based Approach for Animating Images Using Video Examples\",\"url\":\"https://www.semanticscholar.org/paper/7034d165c73c19cbdfe116fd1c4463f61958c20a\",\"venue\":\"Comput. Graph. Forum\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"E. Ilg\"},{\"authorId\":null,\"name\":\"N. Mayer\"},{\"authorId\":null,\"name\":\"T. Saikia\"},{\"authorId\":null,\"name\":\"M. Keuper\"},{\"authorId\":null,\"name\":\"A. Dosovitskiy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and T\",\"url\":\"\",\"venue\":\"Brox. Flownet 2.0: Evolution of optical flow estimation with deep networks. In Computer Vision and Pattern Recognition, pages 1647\\u20131655. IEEE Computer Society\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1403920739\",\"name\":\"A. Rav-Acha\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1109/CVPR.2010.5540159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f66fff6ee972d6096337aeb6cd16c26c27137af\",\"title\":\"Regenerative morphing\",\"url\":\"https://www.semanticscholar.org/paper/3f66fff6ee972d6096337aeb6cd16c26c27137af\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1506.06825\",\"authors\":[{\"authorId\":\"48001135\",\"name\":\"J. Flynn\"},{\"authorId\":\"1725327\",\"name\":\"Ivan Neulander\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2016.595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"title\":\"Deep Stereo: Learning to Predict New Views from the World's Imagery\",\"url\":\"https://www.semanticscholar.org/paper/73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1206.5538\",\"authors\":[{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145467703\",\"name\":\"P. Vincent\"}],\"doi\":\"10.1109/TPAMI.2013.50\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"184ac0766262312ba76bbdece4e7ffad0aa8180b\",\"title\":\"Representation Learning: A Review and New Perspectives\",\"url\":\"https://www.semanticscholar.org/paper/184ac0766262312ba76bbdece4e7ffad0aa8180b\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2016.85\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05e9e85b5137016c93d042170e82f77bb551a108\",\"title\":\"A Benchmark Dataset and Evaluation Methodology for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/05e9e85b5137016c93d042170e82f77bb551a108\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1704.00090\",\"authors\":[{\"authorId\":\"143961654\",\"name\":\"M. Gardner\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"1824052\",\"name\":\"Emiliano Gambaretto\"},{\"authorId\":\"11146706\",\"name\":\"Christian Gagn\\u00e9\"},{\"authorId\":\"144430305\",\"name\":\"Jean-Fran\\u00e7ois Lalonde\"}],\"doi\":\"10.1145/3130800.3130891\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f319959bdc1ea61c23153bda3c1f974ae8e10e8\",\"title\":\"Learning to predict indoor illumination from a single image\",\"url\":\"https://www.semanticscholar.org/paper/3f319959bdc1ea61c23153bda3c1f974ae8e10e8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"}],\"doi\":\"10.1007/978-3-319-46487-9_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a6a98a31eb6bfb3471a22063356ea50c442c488\",\"title\":\"Phase-Based Modification Transfer for Video\",\"url\":\"https://www.semanticscholar.org/paper/7a6a98a31eb6bfb3471a22063356ea50c442c488\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1702.02463\",\"authors\":[{\"authorId\":\"3243969\",\"name\":\"Z. Liu\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"36966089\",\"name\":\"Y. Liu\"},{\"authorId\":\"1696487\",\"name\":\"A. Agarwala\"}],\"doi\":\"10.1109/ICCV.2017.478\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"title\":\"Video Frame Synthesis Using Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/8970e9caed1fca960ead644e6453a1a7321a7e6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.00675\",\"authors\":[{\"authorId\":\"1403171438\",\"name\":\"J. Pont-Tuset\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"1413064976\",\"name\":\"S. Caelles\"},{\"authorId\":\"1778133\",\"name\":\"Pablo Arbel\\u00e1ez\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"title\":\"The 2017 DAVIS Challenge on Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/49e8fec24cce8b73706bc5fcd2c3f681addb9982\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34004812\",\"name\":\"N. Wadhwa\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/2461912.2461966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f835cbad5cf09601493df7fdfc0f310b4c1a5ed\",\"title\":\"Phase-based video motion processing\",\"url\":\"https://www.semanticscholar.org/paper/8f835cbad5cf09601493df7fdfc0f310b4c1a5ed\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33523605\",\"name\":\"J. Portilla\"},{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"}],\"doi\":\"10.1023/A:1026553619983\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37afeac49518877dc96a3ca2ec3ebdfc5305e0a9\",\"title\":\"A Parametric Texture Model Based on Joint Statistics of Complex Wavelet Coefficients\",\"url\":\"https://www.semanticscholar.org/paper/37afeac49518877dc96a3ca2ec3ebdfc5305e0a9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/s11263-013-0644-x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1850a106fad32010e2fae2f3c34d47e3237bb3f4\",\"title\":\"A Quantitative Analysis of Current Practices in Optical Flow Estimation and the Principles Behind Them\",\"url\":\"https://www.semanticscholar.org/paper/1850a106fad32010e2fae2f3c34d47e3237bb3f4\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689350\",\"name\":\"Eero P. Simoncelli\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"2360881\",\"name\":\"D. Heeger\"}],\"doi\":\"10.1109/18.119725\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8515604037444b3f079a9d328b0c560f33da0a19\",\"title\":\"Shiftable multiscale transforms\",\"url\":\"https://www.semanticscholar.org/paper/8515604037444b3f079a9d328b0c560f33da0a19\",\"venue\":\"IEEE Trans. Inf. Theory\",\"year\":1992},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Baker\"},{\"authorId\":null,\"name\":\"D. Scharstein\"},{\"authorId\":null,\"name\":\"J. P. Lewis\"},{\"authorId\":null,\"name\":\"S. Roth\"},{\"authorId\":null,\"name\":\"M. J. Black\"},{\"authorId\":null,\"name\":\"R. Szeliski\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A database and evaluation methodology for opti- 505  cal flow\",\"url\":\"\",\"venue\":\"International Journal of Computer Vision, 92(1):1\\u2013 31\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"1711116\",\"name\":\"M. Hefeeda\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2015.7299039\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"192f17853cf7a5ecf4353ea67fa541b89b7f0fc4\",\"title\":\"Video magnification in presence of large motions\",\"url\":\"https://www.semanticscholar.org/paper/192f17853cf7a5ecf4353ea67fa541b89b7f0fc4\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47113027\",\"name\":\"Wenbin Li\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"38549616\",\"name\":\"J. Starck\"},{\"authorId\":\"3309893\",\"name\":\"G. Brostow\"},{\"authorId\":\"2036351\",\"name\":\"N. D. F. Campbell\"}],\"doi\":\"10.1145/2897824.2925973\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bb4a30d0e57e57a1cccba0916a638738ceb7b75\",\"title\":\"Roto++\",\"url\":\"https://www.semanticscholar.org/paper/8bb4a30d0e57e57a1cccba0916a638738ceb7b75\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"}],\"doi\":\"10.1109/TPAMI.2011.236\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"title\":\"Motion Detail Preserving Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3307078\",\"name\":\"P. Didyk\"},{\"authorId\":\"1402956544\",\"name\":\"Pitchaya Sitthi-amorn\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1145/2508363.2508376\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83e20d726ac829907082629b6fa1d60b378eaa83\",\"title\":\"Joint view expansion and filtering for automultiscopic 3D displays\",\"url\":\"https://www.semanticscholar.org/paper/83e20d726ac829907082629b6fa1d60b378eaa83\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"1723930\",\"name\":\"A. Jepson\"}],\"doi\":\"10.1007/BF00056772\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e91e17ee1135bcdfc03a0c56fae3affe7812d8b\",\"title\":\"Computation of component image velocity from local phase information\",\"url\":\"https://www.semanticscholar.org/paper/1e91e17ee1135bcdfc03a0c56fae3affe7812d8b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2004}],\"title\":\"PhaseNet for Video Frame Interpolation\",\"topics\":[{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Heuristic (computer science)\",\"topicId\":\"927\",\"url\":\"https://www.semanticscholar.org/topic/927\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Network architecture\",\"topicId\":\"58473\",\"url\":\"https://www.semanticscholar.org/topic/58473\"},{\"topic\":\"In-phase and quadrature components\",\"topicId\":\"18192\",\"url\":\"https://www.semanticscholar.org/topic/18192\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Gaussian blur\",\"topicId\":\"384913\",\"url\":\"https://www.semanticscholar.org/topic/384913\"}],\"url\":\"https://www.semanticscholar.org/paper/b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"