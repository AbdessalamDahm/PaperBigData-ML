"{\"abstract\":\"The purpose of this study is to determine whether current video datasets have sufficient data for training very deep convolutional neural networks (CNNs) with spatio-temporal three-dimensional (3D) kernels. Recently, the performance levels of 3D CNNs in the field of action recognition have improved significantly. However, to date, conventional research has only explored relatively shallow 3D architectures. We examine the architectures of various 3D CNNs from relatively shallow to very deep ones on current video datasets. Based on the results of those experiments, the following conclusions could be obtained: (i) ResNet-18 training resulted in significant overfitting for UCF-101, HMDB-51, and ActivityNet but not for Kinetics. (ii) The Kinetics dataset has sufficient data for training of deep 3D CNNs, and enables training of up to 152 ResNets layers, interestingly similar to 2D ResNets on ImageNet. ResNeXt-101 achieved 78.4% average accuracy on the Kinetics test set. (iii) Kinetics pretrained simple 3D architectures outperforms complex 2D architectures, and the pretrained ResNeXt-101 achieved 94.5% and 70.2% on UCF-101 and HMDB-51, respectively. The use of 2D CNNs trained on ImageNet has produced significant progress in various tasks in image. We believe that using deep 3D CNNs together with Kinetics will retrace the successful history of 2D CNNs and ImageNet, and stimulate advances in computer vision for videos. The codes and pretrained models used in this study are publicly available1.\",\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\",\"url\":\"https://www.semanticscholar.org/author/2199251\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\",\"url\":\"https://www.semanticscholar.org/author/1730200\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\",\"url\":\"https://www.semanticscholar.org/author/1732705\"}],\"citationVelocity\":195,\"citations\":[{\"arxivId\":\"1811.10811\",\"authors\":[{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"1409219085\",\"name\":\"Paulo Lopez-Meyer\"},{\"authorId\":\"1798616\",\"name\":\"Omesh Tickoo\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"1cca57d2532a4085fb357c10237bdded69541310\",\"title\":\"Uncertainty aware multimodal activity recognition with Bayesian inference\",\"url\":\"https://www.semanticscholar.org/paper/1cca57d2532a4085fb357c10237bdded69541310\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"Rui Hou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.13215\",\"authors\":[{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"3456894\",\"name\":\"J. Ive\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f58e6646e04a6e96280d2ce8ea196a0ffc39ebd\",\"title\":\"Transformer-based Cascaded Multimodal Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/0f58e6646e04a6e96280d2ce8ea196a0ffc39ebd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405030052\",\"name\":\"Gibran Benitez-Garcia\"},{\"authorId\":\"153735678\",\"name\":\"Muhammad Haris\"},{\"authorId\":\"1490667000\",\"name\":\"Yoshiyuki Tsuda\"},{\"authorId\":\"3081689\",\"name\":\"N. Ukita\"}],\"doi\":\"10.3390/s20020528\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d56868869c29540998eb04e50614f20eeb1575c\",\"title\":\"Finger Gesture Spotting from Long Sequences Based on Multi-Stream Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2d56868869c29540998eb04e50614f20eeb1575c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780642035\",\"name\":\"Mohammad Zaki Zadeh\"},{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"1780399270\",\"name\":\"Jason Bernard Lim\"},{\"authorId\":\"1603672934\",\"name\":\"Maria Kyrarini\"},{\"authorId\":\"1780642436\",\"name\":\"Glenn Wylie\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.1145/3389189.3397648\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea9c77e2434c878ca92167d2a3b287573187375\",\"title\":\"Towards cognitive fatigue detection from functional magnetic resonance imaging data\",\"url\":\"https://www.semanticscholar.org/paper/2ea9c77e2434c878ca92167d2a3b287573187375\",\"venue\":\"PETRA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2749153\",\"name\":\"Xiangguo Zhao\"},{\"authorId\":\"48486326\",\"name\":\"Xin Bi\"},{\"authorId\":\"49435444\",\"name\":\"Xiangyu Zeng\"},{\"authorId\":\"51192933\",\"name\":\"Y. Zhang\"},{\"authorId\":\"91427811\",\"name\":\"Qiu-Sheng Fang\"}],\"doi\":\"10.1007/s00521-020-05181-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acf12142932dfbe7fc1fbe661052d9bdb0e1d10e\",\"title\":\"EDense: a convolutional neural network with ELM-based dense connections\",\"url\":\"https://www.semanticscholar.org/paper/acf12142932dfbe7fc1fbe661052d9bdb0e1d10e\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2069936\",\"name\":\"H. Lamba\"}],\"doi\":\"10.1184/R1/11591301.V1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"343ef9087aee0a553d44c9444ef285884a906e49\",\"title\":\"Modeling User Behavior on Socio-Technical Systems: Patterns and Anomalies\",\"url\":\"https://www.semanticscholar.org/paper/343ef9087aee0a553d44c9444ef285884a906e49\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12457708\",\"name\":\"Zhipeng Wei\"},{\"authorId\":\"1742506579\",\"name\":\"J. Chen\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"108526754\",\"name\":\"Linxi Jiang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"40242610\",\"name\":\"F. Zhou\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V34I07.6918\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b490ba0965fa45445eca4715f46166c76e88988\",\"title\":\"Heuristic Black-Box Adversarial Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/7b490ba0965fa45445eca4715f46166c76e88988\",\"venue\":\"AAAI 2020\",\"year\":2019},{\"arxivId\":\"1811.00347\",\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f56cb5dc32b5b280546998418fda7769d0858629\",\"title\":\"How2: A Large-scale Dataset for Multimodal Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f56cb5dc32b5b280546998418fda7769d0858629\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.01059\",\"authors\":[{\"authorId\":\"145081300\",\"name\":\"L. Zhu\"},{\"authorId\":\"1891221\",\"name\":\"Qi She\"},{\"authorId\":\"152569618\",\"name\":\"Lidan Zhang\"},{\"authorId\":\"113192074\",\"name\":\"Ping Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"28a62b2cf1ec46ca16c6a76431759c43d086ca1b\",\"title\":\"A Spectral Nonlocal Block for Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/28a62b2cf1ec46ca16c6a76431759c43d086ca1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.04656\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCVW.2019.00186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"title\":\"Video Representation Learning by Dense Predictive Coding\",\"url\":\"https://www.semanticscholar.org/paper/0174d263d3a77bf03fce831a9a5ce2678e1959f0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1908.04034\",\"authors\":[{\"authorId\":\"32877671\",\"name\":\"Joakim Bruslund Haurum\"},{\"authorId\":\"47926700\",\"name\":\"Chris H. Bahnsen\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbfc46198306201da2d00a1e76e80c62b1c6080b\",\"title\":\"Is it Raining Outside? Detection of Rainfall using General-Purpose Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/cbfc46198306201da2d00a1e76e80c62b1c6080b\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097122\",\"name\":\"Y. Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"9359893\",\"name\":\"Shengrong Gong\"}],\"doi\":\"10.1145/3378026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e075864cdf19117f6b5f78db877347e2bca4f\",\"title\":\"Spatio-temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/083e075864cdf19117f6b5f78db877347e2bca4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.14742\",\"authors\":[{\"authorId\":\"51115810\",\"name\":\"Hochul Hwang\"},{\"authorId\":\"1831882\",\"name\":\"C. Jang\"},{\"authorId\":\"51311609\",\"name\":\"Geonwoo Park\"},{\"authorId\":\"1679356768\",\"name\":\"Junghyun Cho\"},{\"authorId\":\"49596689\",\"name\":\"Ig-Jae Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"title\":\"ElderSim: A Synthetic Data Generation Platform for Human Action Recognition in Eldercare Applications\",\"url\":\"https://www.semanticscholar.org/paper/06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.12085\",\"authors\":[{\"authorId\":\"2088061\",\"name\":\"Juan Diego Ortega\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"1910490649\",\"name\":\"Paola Canas\"},{\"authorId\":\"3319539\",\"name\":\"Min-An Chao\"},{\"authorId\":\"71814613\",\"name\":\"A. Unnervik\"},{\"authorId\":\"144931363\",\"name\":\"M. Nieto\"},{\"authorId\":\"2353401\",\"name\":\"O. Otaegui\"},{\"authorId\":\"144180623\",\"name\":\"L. Salgado\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"89764b01e004ad39256e0351fef9acea3eecf747\",\"title\":\"DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention and Alertness Analysis\",\"url\":\"https://www.semanticscholar.org/paper/89764b01e004ad39256e0351fef9acea3eecf747\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93108271\",\"name\":\"Mohammad Almasi\"},{\"authorId\":\"5570375\",\"name\":\"H. Fathi\"},{\"authorId\":\"1581789684\",\"name\":\"Sayed Adel Ghaeinian\"},{\"authorId\":\"1580485424\",\"name\":\"S. Samiee\"},{\"authorId\":\"145625558\",\"name\":\"Chuankun Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"90862862\",\"name\":\"S. Wang\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"}],\"doi\":\"10.5120/ijca2019919703\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3b87a4b6e42b89d80e5a496c64f0ae7c16b064a\",\"title\":\"Human Action Recognition through the First-Person Point of view, Case Study Two Basic Task\",\"url\":\"https://www.semanticscholar.org/paper/b3b87a4b6e42b89d80e5a496c64f0ae7c16b064a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.05674\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":\"10.1007/978-981-15-3651-9_2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f99d62a02d91de622dbf5208ef859938980c16d6\",\"title\":\"Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/f99d62a02d91de622dbf5208ef859938980c16d6\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1910.09505\",\"authors\":[{\"authorId\":\"82449565\",\"name\":\"F. Sala\"},{\"authorId\":\"1782486\",\"name\":\"P. Varma\"},{\"authorId\":\"144428045\",\"name\":\"Jason A. Fries\"},{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"2389237\",\"name\":\"Shiori Sagawa\"},{\"authorId\":\"122333481\",\"name\":\"Saelig Khattar\"},{\"authorId\":\"98536774\",\"name\":\"Ashwini Ramamoorthy\"},{\"authorId\":\"144293517\",\"name\":\"Ke Xiao\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"},{\"authorId\":\"153670513\",\"name\":\"J. Priest\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2effb581419f8eb6701e88c8cd8bad15f57b9fa\",\"title\":\"Multi-Resolution Weak Supervision for Sequential Data\",\"url\":\"https://www.semanticscholar.org/paper/f2effb581419f8eb6701e88c8cd8bad15f57b9fa\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1811.03865\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/ICASSP.2019.8682750\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"101b39c530834a8063d033c38d3c6d80dfcfced0\",\"title\":\"Multimodal Grounding for Sequence-to-sequence Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/101b39c530834a8063d033c38d3c6d80dfcfced0\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2001.11091\",\"authors\":[{\"authorId\":\"1491169373\",\"name\":\"Mohamad Ballout\"},{\"authorId\":\"1381681564\",\"name\":\"Mohammad Tuqan\"},{\"authorId\":\"1790873\",\"name\":\"Daniel C. Asmar\"},{\"authorId\":\"48810394\",\"name\":\"Elie Shammas\"},{\"authorId\":\"1768700\",\"name\":\"George E. Sakr\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207337\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"title\":\"The benefits of synthetic data for action categorization\",\"url\":\"https://www.semanticscholar.org/paper/7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2002.01132\",\"authors\":[{\"authorId\":\"152199971\",\"name\":\"Shikha Dubey\"},{\"authorId\":\"26955202\",\"name\":\"Abhijeet Boragule\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/ICCAIS46528.2019.9074586\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20bc30e6787e92e4e91f7016c2d4465d7d45c22c\",\"title\":\"3D ResNet with Ranking Loss Function for Abnormal Activity Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/20bc30e6787e92e4e91f7016c2d4465d7d45c22c\",\"venue\":\"2019 International Conference on Control, Automation and Information Sciences (ICCAIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144095614\",\"name\":\"A. Jalal\"},{\"authorId\":\"2042123418\",\"name\":\"Israr Akhtar\"},{\"authorId\":\"7826090\",\"name\":\"Kyoungmin Kim\"}],\"doi\":\"10.3390/su12239814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30d438a0564359d1343c49d826f0d04870ce2847\",\"title\":\"Human Posture Estimation and Sustainable Events Classification via Pseudo-2D Stick Model and K-ary Tree Hashing\",\"url\":\"https://www.semanticscholar.org/paper/30d438a0564359d1343c49d826f0d04870ce2847\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6624871\",\"name\":\"Dmytro Tkachenko\"}],\"doi\":\"10.29007/WJ5T\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e7f320bb31be1f41d7d33d2eccdd4a96a526ca8\",\"title\":\"Human Action Recognition Using Fusion of Modern Deep Convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8e7f320bb31be1f41d7d33d2eccdd4a96a526ca8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2002.06353\",\"authors\":[{\"authorId\":\"35347136\",\"name\":\"Huaishao Luo\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"15086992\",\"name\":\"H. Huang\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"66782928\",\"name\":\"Tianrui Li\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"},{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4243555758433880a67b15b50f752b1e2a8c4609\",\"title\":\"UniViLM: A Unified Video and Language Pre-Training Model for Multimodal Understanding and Generation\",\"url\":\"https://www.semanticscholar.org/paper/4243555758433880a67b15b50f752b1e2a8c4609\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390412671\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"46223195\",\"name\":\"Shuchen Weng\"},{\"authorId\":\"49889486\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35580784\",\"name\":\"Boxin Shi\"},{\"authorId\":\"80266964\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2968054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"title\":\"Context-Aware Cross-Attention for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.15657\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0\",\"title\":\"Video Representations of Goals Emerge from Watching Failure\",\"url\":\"https://www.semanticscholar.org/paper/9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06961\",\"authors\":[{\"authorId\":\"1483595780\",\"name\":\"Parul Gupta\"},{\"authorId\":\"1729516889\",\"name\":\"Komal Chugh\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"}],\"doi\":\"10.1145/3382507.3418857\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e7f37f4336f08a2f4b172c3f9e36f49c83c6359\",\"title\":\"The eyes know it: FakeET- An Eye-tracking Database to Understand Deepfake Perception\",\"url\":\"https://www.semanticscholar.org/paper/9e7f37f4336f08a2f4b172c3f9e36f49c83c6359\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978134\",\"name\":\"Y. Su\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"48566545\",\"name\":\"J. Zhu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-58548-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60498bfca85f39068f34d222484dc77b23f62035\",\"title\":\"Human Interaction Learning on 3D Skeleton Point Clouds for Video Violence Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60498bfca85f39068f34d222484dc77b23f62035\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09833\",\"authors\":[{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"1823519002\",\"name\":\"Xuanteng Huang\"},{\"authorId\":\"50135134\",\"name\":\"Weihong Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1007/978-3-030-58601-0_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4079558004efd97ddb20ea160909f7fa97d689c2\",\"title\":\"MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection\",\"url\":\"https://www.semanticscholar.org/paper/4079558004efd97ddb20ea160909f7fa97d689c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40647545\",\"name\":\"A. Saveliev\"},{\"authorId\":\"1654173982\",\"name\":\"Mikhail Uzdiaev\"},{\"authorId\":\"1654160653\",\"name\":\"Malov Dmitrii\"}],\"doi\":\"10.1109/DeSE.2019.00165\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"51c790640bb74eeb0af7187ec93e3af80905a53d\",\"title\":\"Aggressive Action Recognition Using 3D CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/51c790640bb74eeb0af7187ec93e3af80905a53d\",\"venue\":\"2019 12th International Conference on Developments in eSystems Engineering (DeSE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50322696\",\"name\":\"Haoliang Tan\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8715474732e8d024078d482b8d0f7cae88a31bcc\",\"title\":\"Object Affordances Graph Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8715474732e8d024078d482b8d0f7cae88a31bcc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"}],\"doi\":\"10.1007/978-3-030-58520-4_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e8a596261cfd846538811edf7db7d5f754b1159\",\"title\":\"Is Sharing of Egocentric Video Giving Away Your Biometric Signature?\",\"url\":\"https://www.semanticscholar.org/paper/5e8a596261cfd846538811edf7db7d5f754b1159\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"153142893\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCV.2019.00767\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"title\":\"View-LSTM: Novel-View Video Synthesis Through View Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2004.10998\",\"authors\":[{\"authorId\":\"144701473\",\"name\":\"Ajian Liu\"},{\"authorId\":\"3167960\",\"name\":\"X. Li\"},{\"authorId\":\"145121526\",\"name\":\"J. Wan\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"50161696\",\"name\":\"M. Madadi\"},{\"authorId\":\"1735319\",\"name\":\"Yi Jin\"},{\"authorId\":\"102814533\",\"name\":\"Z. Wu\"},{\"authorId\":\"48678111\",\"name\":\"Xiao-gang Yu\"},{\"authorId\":\"9645431\",\"name\":\"Zichang Tan\"},{\"authorId\":\"145964227\",\"name\":\"Qi Yuan\"},{\"authorId\":\"51241560\",\"name\":\"Ruikun Yang\"},{\"authorId\":\"73819368\",\"name\":\"Benjia Zhou\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"39756350\",\"name\":\"S. Li\"}],\"doi\":\"10.1049/bme2.12002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9da03ba515f90596fee79da032874d3d5e82da21\",\"title\":\"Cross-ethnicity Face Anti-spoofing Recognition Challenge: A Review\",\"url\":\"https://www.semanticscholar.org/paper/9da03ba515f90596fee79da032874d3d5e82da21\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49717917\",\"name\":\"Hyunsung Kim\"},{\"authorId\":\"153188536\",\"name\":\"J. Kim\"},{\"authorId\":\"32058260\",\"name\":\"Youngseok Kim\"},{\"authorId\":\"40214639\",\"name\":\"M. Kim\"},{\"authorId\":\"10089945\",\"name\":\"Yongsung Lee\"}],\"doi\":\"10.3390/s20216004\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93d8143b1951022b458a959d53156ab87861b059\",\"title\":\"Energy-Efficient Wearable EPTS Device Using On-Device DCNN Processing for Football Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/93d8143b1951022b458a959d53156ab87861b059\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1911.11206\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1109/cvpr42600.2020.00100\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"title\":\"Oops! Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"144350546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1007/978-3-030-00776-8_57\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"title\":\"DT-3DResNet-LSTM: An Architecture for Temporal Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153924558\",\"name\":\"Hsing-Yu Chen\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1007/978-3-030-41299-9_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"title\":\"Group Activity Recognition via Computing Human Pose Motion History and Collective Map from Video\",\"url\":\"https://www.semanticscholar.org/paper/aa2b2a6ce78eb79952408d426ba1b48efdb81dca\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1846234260\",\"name\":\"Xiaoyan Meng\"},{\"authorId\":\"1845981156\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"47057083\",\"name\":\"Xiuzhi Li\"},{\"authorId\":\"1846054590\",\"name\":\"Xiangyin Zhang\"}],\"doi\":\"10.1007/s00371-020-01931-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625829da4b74fbcf217615eadd852e5ff4387a17\",\"title\":\"Auxiliary criterion conversion via spatiotemporal semantic encoding and feature entropy for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/625829da4b74fbcf217615eadd852e5ff4387a17\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1904.04346\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"1737830\",\"name\":\"B. Morris\"}],\"doi\":\"10.1109/CVPR.2019.00039\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3183228a83b1daffeb458f9041d51612589a5b3\",\"title\":\"What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/f3183228a83b1daffeb458f9041d51612589a5b3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.12919\",\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"152477216\",\"name\":\"P. Abreu\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"102c5f96b879de46921cfc1f589dbc364310cf54\",\"title\":\"Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/102c5f96b879de46921cfc1f589dbc364310cf54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40340011\",\"name\":\"S. Chandra\"},{\"authorId\":\"1893915\",\"name\":\"M. Vakalopoulou\"},{\"authorId\":\"15610878\",\"name\":\"Lucas Fidon\"},{\"authorId\":\"40799943\",\"name\":\"E. Battistella\"},{\"authorId\":\"69330195\",\"name\":\"Th\\u00e9o Estienne\"},{\"authorId\":\"143755376\",\"name\":\"Roger Sun\"},{\"authorId\":\"6639401\",\"name\":\"C. Robert\"},{\"authorId\":\"51071151\",\"name\":\"E. Deutsch\"},{\"authorId\":\"1680727\",\"name\":\"N. Paragios\"}],\"doi\":\"10.1007/978-3-030-11726-9_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0eb2c64e328ddc47541bd8734263dea02950e19\",\"title\":\"Context Aware 3D CNNs for Brain Tumor Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/c0eb2c64e328ddc47541bd8734263dea02950e19\",\"venue\":\"BrainLes@MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101279813\",\"name\":\"Zhuo Wang\"},{\"authorId\":\"1713578\",\"name\":\"Zhezhou Yu\"},{\"authorId\":null,\"name\":\"Yao Wang\"},{\"authorId\":\"2267157\",\"name\":\"H. Zhang\"},{\"authorId\":\"10219698\",\"name\":\"Yishan Luo\"},{\"authorId\":\"1865445259\",\"name\":\"Lin Shi\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":\"49444621\",\"name\":\"Chunjie Guo\"}],\"doi\":\"10.3389/fphys.2020.612928\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1dbe2ad3ba5f9f1e19e4d1d4c723d3b33a7f7b1c\",\"title\":\"3D Compressed Convolutional Neural Network Differentiates Neuromyelitis Optical Spectrum Disorders From Multiple Sclerosis Using Automated White Matter Hyperintensities Segmentations\",\"url\":\"https://www.semanticscholar.org/paper/1dbe2ad3ba5f9f1e19e4d1d4c723d3b33a7f7b1c\",\"venue\":\"Frontiers in Physiology\",\"year\":2020},{\"arxivId\":\"2007.03056\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1007/978-3-030-58545-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"title\":\"VPN: Learning Video-Pose Embedding for Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410229972\",\"name\":\"Guy Ben-Yosef\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"113363846\",\"name\":\"Shimon Ullman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5eb2dd6b1abb9329a09b9c11d78389d6e4229b5a\",\"title\":\"WHAT CAN HUMAN MINIMAL VIDEOS TELL US ABOUT DYNAMIC RECOGNITION MODELS?\",\"url\":\"https://www.semanticscholar.org/paper/5eb2dd6b1abb9329a09b9c11d78389d6e4229b5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/cvpr42600.2020.00999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"1912.04538\",\"authors\":[{\"authorId\":\"115023832\",\"name\":\"Zhi-Kai Chen\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"51004368\",\"name\":\"Y. He\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b9f01b9054517581a675fb919850ad558d4640d7\",\"title\":\"Appending Adversarial Frames for Universal Video Attack\",\"url\":\"https://www.semanticscholar.org/paper/b9f01b9054517581a675fb919850ad558d4640d7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2016399\",\"name\":\"H. Xu\"},{\"authorId\":\"144033007\",\"name\":\"Xuemei Sun\"}],\"doi\":\"10.1109/ICSESS47205.2019.9040764\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b08552c44b47349b4c1d66de1788ca3f987f475\",\"title\":\"Jointly Temporal Pooling Networks and Multi-loss Fusion for Video-based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/4b08552c44b47349b4c1d66de1788ca3f987f475\",\"venue\":\"2019 IEEE 10th International Conference on Software Engineering and Service Science (ICSESS)\",\"year\":2019},{\"arxivId\":\"1910.10027\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a9a80cbddaa54002fce1345523960a0f02550e86\",\"title\":\"Human Action Recognition in Drone Videos using a Few Aerial Training Examples\",\"url\":\"https://www.semanticscholar.org/paper/a9a80cbddaa54002fce1345523960a0f02550e86\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"1405331439\",\"name\":\"P. Lopez-Meyer\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/ICCV.2019.00640\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"8eca936f462712f3d67ebe564292857144f704f1\",\"title\":\"Uncertainty-Aware Audiovisual Activity Recognition Using Deep Bayesian Variational Inference\",\"url\":\"https://www.semanticscholar.org/paper/8eca936f462712f3d67ebe564292857144f704f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1808.04234\",\"authors\":[{\"authorId\":\"22246693\",\"name\":\"Shitao Tang\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"9407393\",\"name\":\"Y. Chen\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1007/978-3-030-20887-5_36\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c5a784d96aaf6cd41f1460d58259480503df7270\",\"title\":\"Fast Video Shot Transition Localization with Deep Structured Models\",\"url\":\"https://www.semanticscholar.org/paper/c5a784d96aaf6cd41f1460d58259480503df7270\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.05523\",\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/CVPR42600.2020.00531\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33392bb15145ba1c7681061ce891f2e49354ca17\",\"title\":\"G3AN: Disentangling Appearance and Motion for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/33392bb15145ba1c7681061ce891f2e49354ca17\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1380212680\",\"name\":\"A. K. Qin\"},{\"authorId\":\"150325884\",\"name\":\"T. Wu\"},{\"authorId\":\"1390585158\",\"name\":\"Chi Harold Liu\"}],\"doi\":\"10.1145/3343031.3350916\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"554d3d5cdffa7e2aa292504d4d4507af498e30d2\",\"title\":\"Action Recognition with Bootstrapping based Long-range Temporal Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/554d3d5cdffa7e2aa292504d4d4507af498e30d2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2009.13019\",\"authors\":[{\"authorId\":\"81185314\",\"name\":\"Panwen Hu\"},{\"authorId\":\"151488129\",\"name\":\"Jiazhen Liu\"},{\"authorId\":\"1516136186\",\"name\":\"Rui Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ced52cf176a96dee39f774bb225cb7e0e2d4f92\",\"title\":\"Concentrated Multi-Grained Multi-Attention Network for Video Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/7ced52cf176a96dee39f774bb225cb7e0e2d4f92\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2020.2984904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"title\":\"STA-CNN: Convolutional Spatial-Temporal Attention Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2009.08058\",\"authors\":[{\"authorId\":\"80977068\",\"name\":\"Shao-Yuan Lo\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b98a1dd74ec445e8128798c5b4072a7a48b0591\",\"title\":\"MultAV: Multiplicative Adversarial Videos\",\"url\":\"https://www.semanticscholar.org/paper/4b98a1dd74ec445e8128798c5b4072a7a48b0591\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12392\",\"authors\":[{\"authorId\":\"1958036\",\"name\":\"Gongbo Liang\"},{\"authorId\":\"48631827\",\"name\":\"Xiaoqin Wang\"},{\"authorId\":\"46867976\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1491631303\",\"name\":\"Xin Xing\"},{\"authorId\":\"1491643960\",\"name\":\"Hunter Blanton\"},{\"authorId\":\"1491644479\",\"name\":\"Tawfiq Salem\"},{\"authorId\":\"47259377\",\"name\":\"Nathan B. Jacobs\"}],\"doi\":\"10.1109/BIBM47256.2019.8983048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d0e1914fb9df12cf42d1f8621d0de024276b735\",\"title\":\"Joint 2D-3D Breast Cancer Classification\",\"url\":\"https://www.semanticscholar.org/paper/7d0e1914fb9df12cf42d1f8621d0de024276b735\",\"venue\":\"2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"122288178\",\"name\":\"M. Zakizadeh\"},{\"authorId\":\"48328490\",\"name\":\"J. Brady\"},{\"authorId\":\"145674348\",\"name\":\"Diane Calderon\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.1109/COASE.2019.8843199\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"beca19ef5b02b4d88008057fc6d4dc6eb8dbaaee\",\"title\":\"An Intelligent Action Recognition System to assess Cognitive Behavior for Executive Function Disorder\",\"url\":\"https://www.semanticscholar.org/paper/beca19ef5b02b4d88008057fc6d4dc6eb8dbaaee\",\"venue\":\"2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390818869\",\"name\":\"Jinlei Xu\"},{\"authorId\":\"144546140\",\"name\":\"T. Xu\"},{\"authorId\":\"123432231\",\"name\":\"Xin Tian\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144911521\",\"name\":\"Y. Ji\"}],\"doi\":\"10.1109/IJCNN.2019.8851897\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf7b38dd24c20223e006066be4202d1da700af37\",\"title\":\"Context Gating with Short Temporal Information for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf7b38dd24c20223e006066be4202d1da700af37\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71712589\",\"name\":\"L. Courtney\"},{\"authorId\":\"40568918\",\"name\":\"R. Sreenivas\"}],\"doi\":\"10.1007/978-3-030-41299-9_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7db0bb6ed3630373be94e678dbc397d619473e90\",\"title\":\"Using Deep Convolutional LSTM Networks for Learning Spatiotemporal Features\",\"url\":\"https://www.semanticscholar.org/paper/7db0bb6ed3630373be94e678dbc397d619473e90\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":\"1904.04817\",\"authors\":[{\"authorId\":\"71712589\",\"name\":\"L. Courtney\"},{\"authorId\":\"40568918\",\"name\":\"R. Sreenivas\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"3034c12a9c5b27592a123216a0cfd79f955b0a0f\",\"title\":\"Learning from Videos with Deep Convolutional LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/3034c12a9c5b27592a123216a0cfd79f955b0a0f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.07725\",\"authors\":[{\"authorId\":\"40809222\",\"name\":\"Luxuan Li\"},{\"authorId\":\"145868988\",\"name\":\"Tao Kong\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-36718-3_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f27170bf174d81e646492173ba9e9c97753853c\",\"title\":\"Deep Point-wise Prediction for Action Temporal Proposal\",\"url\":\"https://www.semanticscholar.org/paper/8f27170bf174d81e646492173ba9e9c97753853c\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038499155\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"144184407\",\"name\":\"Jun Liao\"},{\"authorId\":\"52201470\",\"name\":\"Mengyuan Ran\"},{\"authorId\":\"50080172\",\"name\":\"X. Li\"},{\"authorId\":\"118188869\",\"name\":\"S. Wang\"},{\"authorId\":\"120095706\",\"name\":\"Li Liu\"}],\"doi\":\"10.1109/SMC42975.2020.9283407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e188653c8638298f83cbadf4c92ac4d439407640\",\"title\":\"ST-Xception: A Depthwise Separable Convolution Network for Military Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e188653c8638298f83cbadf4c92ac4d439407640\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81333974\",\"name\":\"J. Pessoa\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4ec25a47f6bcf0b19d6cd5103b16b10900284b90\",\"title\":\"VIDEO COMPRESSION USING (END-TO-END) DEEP LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/4ec25a47f6bcf0b19d6cd5103b16b10900284b90\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.11204\",\"authors\":[{\"authorId\":\"37302154\",\"name\":\"J. Yang\"},{\"authorId\":\"143923374\",\"name\":\"S. Liu\"},{\"authorId\":\"1764071\",\"name\":\"S. Grbic\"},{\"authorId\":\"145101451\",\"name\":\"A. A. A. Setio\"},{\"authorId\":\"2510540\",\"name\":\"Zhoubing Xu\"},{\"authorId\":\"145720674\",\"name\":\"E. Gibson\"},{\"authorId\":\"49844235\",\"name\":\"Guillaume Chabin\"},{\"authorId\":\"1747498\",\"name\":\"B. Georgescu\"},{\"authorId\":\"1742373\",\"name\":\"A. Laine\"},{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"}],\"doi\":\"10.1109/ISBI.2019.8759493\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22af5979064ae772e3bf1c6f40b95255e51abf5e\",\"title\":\"Class-Aware Adversarial Lung Nodule Synthesis In CT Images\",\"url\":\"https://www.semanticscholar.org/paper/22af5979064ae772e3bf1c6f40b95255e51abf5e\",\"venue\":\"2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)\",\"year\":2019},{\"arxivId\":\"1810.11731\",\"authors\":[{\"authorId\":\"1412518183\",\"name\":\"Marian K. Y. Boktor\"},{\"authorId\":\"1410429737\",\"name\":\"A. Al-Kabbany\"},{\"authorId\":\"46318863\",\"name\":\"Radwa Khalil\"},{\"authorId\":\"1398644693\",\"name\":\"S. El-Khamy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6044b30751c19b3231782fb0475c9ca438940690\",\"title\":\"Real-time Action Recognition with Dissimilarity-based Training of Specialized Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/6044b30751c19b3231782fb0475c9ca438940690\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2012.09542\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"145263742\",\"name\":\"M. S. Kavitha\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"title\":\"Weakly-Supervised Action Localization and Action Recognition using Global-Local Attention of 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06762\",\"authors\":[{\"authorId\":\"11455132\",\"name\":\"Lianmin Zheng\"},{\"authorId\":\"51195858\",\"name\":\"Chengfan Jia\"},{\"authorId\":\"15013196\",\"name\":\"Min-min Sun\"},{\"authorId\":\"51125084\",\"name\":\"Z. Wu\"},{\"authorId\":\"17813719\",\"name\":\"C. H. Yu\"},{\"authorId\":\"1411406011\",\"name\":\"Ameer Haj-Ali\"},{\"authorId\":null,\"name\":\"Yida Wang\"},{\"authorId\":\"1724199\",\"name\":\"Jun Yang\"},{\"authorId\":\"2720913\",\"name\":\"D. Zhuo\"},{\"authorId\":\"145741786\",\"name\":\"K. Sen\"},{\"authorId\":\"49988044\",\"name\":\"Joseph E. Gonzalez\"},{\"authorId\":\"1484048577\",\"name\":\"I. Stoica\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ebbdc79a3553e8ad2996d6d03987bfaeb448e82\",\"title\":\"Ansor : Generating High-Performance Tensor Programs for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/6ebbdc79a3553e8ad2996d6d03987bfaeb448e82\",\"venue\":\"OSDI 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1516118831\",\"name\":\"Kaito Hirasawa\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/icmew46912.2020.9106025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2daa199f17048175bc3bfff3dabc451175a166f\",\"title\":\"Mvgan Maximizing Time-Lag Aware Canonical Correlation for Baseball Highlight Generation\",\"url\":\"https://www.semanticscholar.org/paper/d2daa199f17048175bc3bfff3dabc451175a166f\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73416563\",\"name\":\"Guoliang Pang\"},{\"authorId\":\"50141950\",\"name\":\"Xionghui Wang\"},{\"authorId\":\"8520539\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"47539770\",\"name\":\"Q. Zhang\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.24963/ijcai.2019/126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e6a5cbcd6788a75586807e6c14a164ffca9907f\",\"title\":\"DBDNet: Learning Bi-directional Dynamics for Early Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1e6a5cbcd6788a75586807e6c14a164ffca9907f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1901.10323\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/FG.2019.8756576\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d22729721f211c9244eaa91f94432325d6f3320a\",\"title\":\"Real-time Hand Gesture Detection and Classification Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d22729721f211c9244eaa91f94432325d6f3320a\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sang Keun Choe\"},{\"authorId\":null,\"name\":\"Quanyang Lu\"},{\"authorId\":null,\"name\":\"Vikas Raunak\"},{\"authorId\":null,\"name\":\"Yi Xu\"},{\"authorId\":null,\"name\":\"Florian Metze\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de107f4c68d87c2e680f10b7ee4c92fa6a929f28\",\"title\":\"On Leveraging Visual Modality for Speech Recognition Error Correction\",\"url\":\"https://www.semanticscholar.org/paper/de107f4c68d87c2e680f10b7ee4c92fa6a929f28\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9328269\",\"name\":\"Ngoc-Dung T. Tieu\"},{\"authorId\":\"40415016\",\"name\":\"Huy H. Nguyen\"},{\"authorId\":\"2912817\",\"name\":\"Hoang-Quoc Nguyen-Son\"},{\"authorId\":\"1716857\",\"name\":\"J. Yamagishi\"},{\"authorId\":\"1678602\",\"name\":\"I. Echizen\"}],\"doi\":\"10.1016/J.JISA.2019.03.002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a15a3813040ee1a5a181ed781290a6a18d953777\",\"title\":\"Spatio-temporal generative adversarial network for gait anonymization\",\"url\":\"https://www.semanticscholar.org/paper/a15a3813040ee1a5a181ed781290a6a18d953777\",\"venue\":\"J. Inf. Secur. Appl.\",\"year\":2019},{\"arxivId\":\"1911.11306\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"50112704\",\"name\":\"Sumin Lee\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2019.2953187\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13aa627f35de78af64d1861fceb97c834a769b05\",\"title\":\"SRG: Snippet Relatedness-Based Temporal Action Proposal Generator\",\"url\":\"https://www.semanticscholar.org/paper/13aa627f35de78af64d1861fceb97c834a769b05\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2006.13608\",\"authors\":[{\"authorId\":\"1739188006\",\"name\":\"Sheng-Yu Zhang\"},{\"authorId\":\"3856602\",\"name\":\"Ziqi Tan\"},{\"authorId\":\"145919748\",\"name\":\"Jin Yu\"},{\"authorId\":\"50144812\",\"name\":\"Z. Zhao\"},{\"authorId\":\"33870528\",\"name\":\"Kun Kuang\"},{\"authorId\":\"71328060\",\"name\":\"T. Jiang\"},{\"authorId\":\"1709595\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"38385080\",\"name\":\"Hongxia Yang\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3394486.3403325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d271e93c7566b231e560c48b4cc4942077d762f9\",\"title\":\"Comprehensive Information Integration Modeling Framework for Video Titling\",\"url\":\"https://www.semanticscholar.org/paper/d271e93c7566b231e560c48b4cc4942077d762f9\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4158401\",\"name\":\"Yeguang Li\"},{\"authorId\":\"48985434\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"1384843518\",\"name\":\"L. Hu\"},{\"authorId\":\"49298479\",\"name\":\"J. Li\"},{\"authorId\":\"1792722\",\"name\":\"Deqing Wang\"}],\"doi\":\"10.1016/j.jvcir.2020.102818\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5392fc56f99ab7f9fc01ca2bca94a13acd8cf280\",\"title\":\"Candidate region correlation for video action detection\",\"url\":\"https://www.semanticscholar.org/paper/5392fc56f99ab7f9fc01ca2bca94a13acd8cf280\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"5342346\",\"name\":\"H. Li\"},{\"authorId\":\"32676626\",\"name\":\"Yan-tao Yu\"},{\"authorId\":\"144143222\",\"name\":\"C. Zhou\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"}],\"doi\":\"10.1111/mice.12538\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"452fa24781dfbed3de50a0a5af416a4e5bc0de93\",\"title\":\"Combining deep features and activity context to improve recognition of activities of workers in groups\",\"url\":\"https://www.semanticscholar.org/paper/452fa24781dfbed3de50a0a5af416a4e5bc0de93\",\"venue\":\"Comput. Aided Civ. Infrastructure Eng.\",\"year\":2020},{\"arxivId\":\"1812.01973\",\"authors\":[{\"authorId\":\"3420998\",\"name\":\"Romain Cohendet\"},{\"authorId\":\"1996351\",\"name\":\"Claire-H\\u00e9l\\u00e8ne Demarty\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"},{\"authorId\":\"35376394\",\"name\":\"Martin Engilberge\"}],\"doi\":\"10.1109/ICCV.2019.00262\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a958610752f934032a0fa2db1ecb3a5acaca396a\",\"title\":\"VideoMem: Constructing, Analyzing, Predicting Short-Term and Long-Term Video Memorability\",\"url\":\"https://www.semanticscholar.org/paper/a958610752f934032a0fa2db1ecb3a5acaca396a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"Li Yao\"},{\"authorId\":\"144350546\",\"name\":\"Ying Qian\"}],\"doi\":\"10.1109/WACVW.2019.00009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f9a9031fdff486aac00815f83cf5a9cc5d7a392\",\"title\":\"Novel Activities Detection Algorithm in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/9f9a9031fdff486aac00815f83cf5a9cc5d7a392\",\"venue\":\"2019 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2019},{\"arxivId\":\"1909.01106\",\"authors\":[{\"authorId\":null,\"name\":\"Yida Wang\"},{\"authorId\":\"1822708\",\"name\":\"D. J. Tan\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1109/ICCV.2019.00870\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"65fa71111d1dc5f56589f65202f0342e3402b26b\",\"title\":\"ForkNet: Multi-Branch Volumetric Semantic Completion From a Single Depth Image\",\"url\":\"https://www.semanticscholar.org/paper/65fa71111d1dc5f56589f65202f0342e3402b26b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2007.12519\",\"authors\":[{\"authorId\":\"49251781\",\"name\":\"J. Chen\"},{\"authorId\":\"47073875\",\"name\":\"Chenhui Wang\"},{\"authorId\":\"2607007\",\"name\":\"K. Wang\"},{\"authorId\":\"5836425\",\"name\":\"Chaoqun Yin\"},{\"authorId\":\"143955103\",\"name\":\"Cong Zhao\"},{\"authorId\":\"143706446\",\"name\":\"Tao Xu\"},{\"authorId\":\"152899469\",\"name\":\"X. Zhang\"},{\"authorId\":\"50293860\",\"name\":\"Ziqiang Huang\"},{\"authorId\":\"1423648972\",\"name\":\"Meichen Liu\"},{\"authorId\":\"8168228\",\"name\":\"T. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b39b7b510ef2fc04e99aa9ba7d2ec344a0bb2017\",\"title\":\"HEU Emotion: A Large-scale Database for Multi-modal Emotion Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/b39b7b510ef2fc04e99aa9ba7d2ec344a0bb2017\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3397911\",\"name\":\"Georgios Paraskevopoulos\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":\"10.18653/v1/2020.acl-main.216\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9399c7d21a579001a4951bf462843633483af367\",\"title\":\"Multimodal and Multiresolution Speech Recognition with Transformers\",\"url\":\"https://www.semanticscholar.org/paper/9399c7d21a579001a4951bf462843633483af367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2007.03198\",\"authors\":[{\"authorId\":\"51963928\",\"name\":\"Utku Ozbulak\"},{\"authorId\":\"151059683\",\"name\":\"Jonathan Peck\"},{\"authorId\":\"7627712\",\"name\":\"W. D. Neve\"},{\"authorId\":\"2602726\",\"name\":\"Bart Goossens\"},{\"authorId\":\"1989271\",\"name\":\"Y. Saeys\"},{\"authorId\":\"2579326\",\"name\":\"Arnout Van Messem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"126ccc111e09138a28c40fb23c9bfa3838532dcb\",\"title\":\"Regional Image Perturbation Reduces Lp Norms of Adversarial Examples While Maintaining Model-to-model Transferability\",\"url\":\"https://www.semanticscholar.org/paper/126ccc111e09138a28c40fb23c9bfa3838532dcb\",\"venue\":\"ICML 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82957042\",\"name\":\"K. Abe\"},{\"authorId\":\"40984574\",\"name\":\"Chikara Nakamura\"},{\"authorId\":\"3177909\",\"name\":\"Yosuke Otsubo\"},{\"authorId\":\"31432119\",\"name\":\"T. Koike\"},{\"authorId\":\"6611386\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1145/3347318.3355521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74f4225b1303d4c491f76556787a5250d9ed2710\",\"title\":\"Spectator Excitement Detection in Small-scale Sports Events\",\"url\":\"https://www.semanticscholar.org/paper/74f4225b1303d4c491f76556787a5250d9ed2710\",\"venue\":\"MMSports '19\",\"year\":2019},{\"arxivId\":\"2010.08021\",\"authors\":[{\"authorId\":\"146103583\",\"name\":\"Aman Khullar\"},{\"authorId\":\"46368735\",\"name\":\"Udit Arora\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"80b7bf7e35fa1a4aff4410d2b1b767c4eb2833d8\",\"title\":\"MAST: Multimodal Abstractive Summarization with Trimodal Hierarchical Attention\",\"url\":\"https://www.semanticscholar.org/paper/80b7bf7e35fa1a4aff4410d2b1b767c4eb2833d8\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2011.11261\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"title\":\"Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11647\",\"authors\":[{\"authorId\":\"119913594\",\"name\":\"J. Lorenzo\"},{\"authorId\":\"144471901\",\"name\":\"I. Parra\"},{\"authorId\":\"38000929\",\"name\":\"F. Wirth\"},{\"authorId\":\"48049213\",\"name\":\"C. Stiller\"},{\"authorId\":\"1729433\",\"name\":\"D. Llorca\"},{\"authorId\":\"152795656\",\"name\":\"M. A. Sotelo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caa90323363228030e53fd8e734bfd3ddd04ebca\",\"title\":\"RNN-based Pedestrian Crossing Prediction using Activity and Pose-related Features\",\"url\":\"https://www.semanticscholar.org/paper/caa90323363228030e53fd8e734bfd3ddd04ebca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47557746\",\"name\":\"Y. Chen\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207404\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2807495123a402bee172b9697f3a98a2351d134\",\"title\":\"Lightweight Action Recognition with Sequence-Specific Global Context\",\"url\":\"https://www.semanticscholar.org/paper/e2807495123a402bee172b9697f3a98a2351d134\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2010.13662\",\"authors\":[{\"authorId\":\"150310958\",\"name\":\"Shun-cheng Wu\"},{\"authorId\":\"2656323\",\"name\":\"Keisuke Tateno\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa0ab60fa9d7cfe32f3e6ada1639641c178ecdf8\",\"title\":\"SCFusion: Real-time Incremental Scene Reconstruction with Semantic Completion\",\"url\":\"https://www.semanticscholar.org/paper/aa0ab60fa9d7cfe32f3e6ada1639641c178ecdf8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09245\",\"authors\":[{\"authorId\":\"144648787\",\"name\":\"M. Saito\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef29d5c85b70fd9dbe04a7b839fbc7d413b161e6\",\"title\":\"TGANv2: Efficient Training of Large Models for Video Generation with Multiple Subsampling Layers\",\"url\":\"https://www.semanticscholar.org/paper/ef29d5c85b70fd9dbe04a7b839fbc7d413b161e6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1911.08206\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"1420126809\",\"name\":\"Haim Barad\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"},{\"authorId\":\"3243137\",\"name\":\"Amit Bleiweiss\"}],\"doi\":\"10.1109/CVPRW50498.2020.00350\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"da2934c24a9de690ff399736711b754cc10ae1ec\",\"title\":\"Mimic The Raw Domain: Accelerating Action Recognition in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/da2934c24a9de690ff399736711b754cc10ae1ec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1810.12494\",\"authors\":[{\"authorId\":\"51300425\",\"name\":\"Yi-Ling Qiao\"},{\"authorId\":\"144614914\",\"name\":\"Lin Gao\"},{\"authorId\":\"152879056\",\"name\":\"Yu-Kun Lai\"},{\"authorId\":\"36572049\",\"name\":\"ShiHong Xia\"}],\"doi\":\"10.1016/j.media.2019.101628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bce61a182c7a1028eed0c0f67e779753a86503c2\",\"title\":\"2019 Formatting Instructions for Authors Using LaTeX\",\"url\":\"https://www.semanticscholar.org/paper/bce61a182c7a1028eed0c0f67e779753a86503c2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1907.05013\",\"authors\":[{\"authorId\":\"152776651\",\"name\":\"Y. Ito\"},{\"authorId\":\"8157092\",\"name\":\"H. Imai\"},{\"authorId\":\"34306980\",\"name\":\"Tung D. Le\"},{\"authorId\":\"1724292\",\"name\":\"Yasushi Negishi\"},{\"authorId\":\"1697424\",\"name\":\"Kiyokuni Kawachiya\"},{\"authorId\":\"1964107\",\"name\":\"Ryo Matsumiya\"},{\"authorId\":\"152531938\",\"name\":\"Toshio Endo\"}],\"doi\":\"10.1145/3293883.3298790\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"810f1f5b1aec0a513271a7222a9b4ee5ea71e28f\",\"title\":\"Profiling based out-of-core hybrid method for large neural networks: poster\",\"url\":\"https://www.semanticscholar.org/paper/810f1f5b1aec0a513271a7222a9b4ee5ea71e28f\",\"venue\":\"PPoPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151471179\",\"name\":\"Nasim Khani\"},{\"authorId\":\"1917506\",\"name\":\"M. Rezaeian\"}],\"doi\":\"10.1109/PRIA.2019.8785989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"615f2ff53e297c753b323df4a1550a68953c0260\",\"title\":\"Three-stream Very Deep Neural Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/615f2ff53e297c753b323df4a1550a68953c0260\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3137286\",\"name\":\"Ujjwal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71e6fa3bfa9f05a459760ce947d6b1cf2f81205f\",\"title\":\"Handling the speed-accuracy trade-off in deep-learning based pedestrian detection systems. (Gestion du compromis vitesse- pr\\u00e9cision dans les syst\\u00e8mes de d\\u00e9tection de pi\\u00e9tons bas\\u00e9s sur apprentissage profond)\",\"url\":\"https://www.semanticscholar.org/paper/71e6fa3bfa9f05a459760ce947d6b1cf2f81205f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1806.08482\",\"authors\":[{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"1763245\",\"name\":\"Xiaoguang Han\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"}],\"doi\":\"10.1609/AAAI.V33I01.33015232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f8c851b73ccb36a88bea0392d1ace84a79f3d97\",\"title\":\"Video Inpainting by Jointly Learning Temporal Structure and Spatial Details\",\"url\":\"https://www.semanticscholar.org/paper/1f8c851b73ccb36a88bea0392d1ace84a79f3d97\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.04579\",\"authors\":[{\"authorId\":\"2069936\",\"name\":\"H. Lamba\"},{\"authorId\":\"114379842\",\"name\":\"Shashank Srikanth\"},{\"authorId\":\"1388051395\",\"name\":\"Dheeraj Reddy Pailla\"},{\"authorId\":\"9139178\",\"name\":\"Shwetanshu Singh\"},{\"authorId\":\"1453888285\",\"name\":\"Karandeep Juneja\"},{\"authorId\":\"1734731\",\"name\":\"P. Kumaraguru\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43d0875ba83bea726ac4533b0e60e0acfbbaac5c\",\"title\":\"Driving The Last Mile: Characterizing and Understanding Distracted Driving Posts on Social Networks\",\"url\":\"https://www.semanticscholar.org/paper/43d0875ba83bea726ac4533b0e60e0acfbbaac5c\",\"venue\":\"ICWSM\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.06232\",\"authors\":[{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"1782475\",\"name\":\"G. Swirszcz\"},{\"authorId\":\"153062108\",\"name\":\"J. Carreira\"},{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"}],\"doi\":\"10.1109/cvpr42600.2020.01185\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"title\":\"Sideways: Depth-Parallel Training of Video Models\",\"url\":\"https://www.semanticscholar.org/paper/21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.07776\",\"authors\":[{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"2964822\",\"name\":\"Adam P. Harrison\"},{\"authorId\":\"6643700\",\"name\":\"Youjing Zheng\"},{\"authorId\":\"145829312\",\"name\":\"Ke Yan\"},{\"authorId\":\"9271225\",\"name\":\"Yuankai Huo\"},{\"authorId\":\"91353860\",\"name\":\"Jing Xiao\"},{\"authorId\":\"29163569\",\"name\":\"Lin Yang\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"}],\"doi\":\"10.1109/TMI.2020.3022034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"698d02144ad64a51a27a169af39a3056f9873dd8\",\"title\":\"Lesion Harvester: Iteratively Mining Unlabeled Lesions and Hard-Negative Examples at Scale\",\"url\":\"https://www.semanticscholar.org/paper/698d02144ad64a51a27a169af39a3056f9873dd8\",\"venue\":\"IEEE transactions on medical imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1749395\",\"name\":\"Xianghua Xu\"}],\"doi\":\"10.1109/ACCESS.2020.3003939\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f99d0990c255c635f731cefa434912b09598e8cd\",\"title\":\"Recurrent Compressed Convolutional Networks for Short Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/f99d0990c255c635f731cefa434912b09598e8cd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"title\":\"Resource Efficient 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51940549\",\"name\":\"Pablo Andres Millan Arias\"},{\"authorId\":\"51927098\",\"name\":\"Julian Armando Quiroga Sepulveda\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"316824a4535ceb0eba8842c774605b7cc1614c5d\",\"title\":\"Deep Learned vs. Hand-Crafted Features for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/316824a4535ceb0eba8842c774605b7cc1614c5d\",\"venue\":\"2018 IEEE First International Conference on Artificial Intelligence and Knowledge Engineering (AIKE)\",\"year\":2018},{\"arxivId\":\"1812.01737\",\"authors\":[{\"authorId\":\"143923374\",\"name\":\"S. Liu\"},{\"authorId\":\"145720674\",\"name\":\"E. Gibson\"},{\"authorId\":\"1764071\",\"name\":\"S. Grbic\"},{\"authorId\":\"2510540\",\"name\":\"Zhoubing Xu\"},{\"authorId\":\"145101451\",\"name\":\"A. A. A. Setio\"},{\"authorId\":\"37302154\",\"name\":\"J. Yang\"},{\"authorId\":\"1747498\",\"name\":\"B. Georgescu\"},{\"authorId\":\"1685020\",\"name\":\"D. Comaniciu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5a3b8aad2ac60d34b79b2f1ba21d14755d81daf\",\"title\":\"Decompose to manipulate: Manipulable Object Synthesis in 3D Medical Images with Structured Image Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/c5a3b8aad2ac60d34b79b2f1ba21d14755d81daf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10001427\",\"name\":\"H. Fan\"},{\"authorId\":\"152604028\",\"name\":\"Cheng Luo\"},{\"authorId\":\"31902430\",\"name\":\"Chenglong Zeng\"},{\"authorId\":\"100998451\",\"name\":\"M. Ferianc\"},{\"authorId\":\"144514893\",\"name\":\"Zhiqiang Que\"},{\"authorId\":\"6287360\",\"name\":\"S. Liu\"},{\"authorId\":\"143825108\",\"name\":\"Xinyu Niu\"},{\"authorId\":\"144708627\",\"name\":\"W. Luk\"}],\"doi\":\"10.1109/ASAP.2019.00-44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe692ad45181356472e507ec6cf78667e652f182\",\"title\":\"F-E3D: FPGA-based Acceleration of an Efficient 3D Convolutional Neural Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe692ad45181356472e507ec6cf78667e652f182\",\"venue\":\"2019 IEEE 30th International Conference on Application-specific Systems, Architectures and Processors (ASAP)\",\"year\":2019},{\"arxivId\":\"1904.04964\",\"authors\":[{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"2819862\",\"name\":\"J. Feng\"},{\"authorId\":\"35213482\",\"name\":\"Yinliang Zhao\"},{\"authorId\":\"13102785\",\"name\":\"X. Zhang\"},{\"authorId\":\"12211820\",\"name\":\"Shiyuan Zhang\"},{\"authorId\":\"1783892\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/ACCESS.2019.2923743\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75020f90bc2e65d069458dca79b4bfaa28ac1826\",\"title\":\"Joint Activity Recognition and Indoor Localization With WiFi Fingerprints\",\"url\":\"https://www.semanticscholar.org/paper/75020f90bc2e65d069458dca79b4bfaa28ac1826\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"Aayush Jung Rana\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b8626336566f34c7e1d17ddf7b144636812c18\",\"title\":\"An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d4b8626336566f34c7e1d17ddf7b144636812c18\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":\"10.1145/3343031.3350998\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1e5fbf1440850bdea40aeee99956cb6e01e2e22\",\"title\":\"Exploring Background-bias for Anomaly Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/e1e5fbf1440850bdea40aeee99956cb6e01e2e22\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8702449\",\"name\":\"Wanneng Wang\"},{\"authorId\":\"47009814\",\"name\":\"Yanan Ma\"},{\"authorId\":\"144947764\",\"name\":\"Ke Gao\"},{\"authorId\":\"152813130\",\"name\":\"J. Cao\"}],\"doi\":\"10.1145/3343031.3350884\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0be689463698d92433b4fd343379a32e763c9f2c\",\"title\":\"Cost-free Transfer Learning Mechanism: Deep Digging Relationships of Action Categories\",\"url\":\"https://www.semanticscholar.org/paper/0be689463698d92433b4fd343379a32e763c9f2c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144577\",\"name\":\"C. Wu\"},{\"authorId\":\"83483083\",\"name\":\"Jiayue Han\"},{\"authorId\":\"1723274\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802910\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a1bc41a048a30919ba79fa88d9c4a03cb2942b47\",\"title\":\"Time-Asymmetric 3d Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a1bc41a048a30919ba79fa88d9c4a03cb2942b47\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50021838\",\"name\":\"Tingting Liu\"},{\"authorId\":\"72050817\",\"name\":\"Zengzhao Chen\"},{\"authorId\":\"1907530\",\"name\":\"Xiangwei Wang\"}],\"doi\":\"10.1145/3338147.3338163\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1322930a4e062793f127e7e685e78375090adfbd\",\"title\":\"Automatic Instructional Pointing Gesture Recognition by Machine Learning in the Intelligent Learning Environment\",\"url\":\"https://www.semanticscholar.org/paper/1322930a4e062793f127e7e685e78375090adfbd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1516118831\",\"name\":\"Kaito Hirasawa\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/GCCE46687.2019.9015527\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9f812169b6b0793818746eacc40e0a7d1c47575\",\"title\":\"Semantic Shot Classification in Baseball Videos Based on Similarities of Visual Features\",\"url\":\"https://www.semanticscholar.org/paper/f9f812169b6b0793818746eacc40e0a7d1c47575\",\"venue\":\"2019 IEEE 8th Global Conference on Consumer Electronics (GCCE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144433\",\"name\":\"Baptist Vandersmissen\"},{\"authorId\":\"31042607\",\"name\":\"Nicolas Knudde\"},{\"authorId\":\"49812011\",\"name\":\"Azarakhsh Jalalvand\"},{\"authorId\":\"2426172\",\"name\":\"I. Couckuyt\"},{\"authorId\":\"1806487\",\"name\":\"T. Dhaene\"},{\"authorId\":\"134860754\",\"name\":\"W. De Neve\"}],\"doi\":\"10.1007/s00521-019-04408-1\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"9173cf7ca2576621d8e7dbc4c49f2cbd6cd46a51\",\"title\":\"Indoor human activity recognition using high-dimensional sensors and deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/9173cf7ca2576621d8e7dbc4c49f2cbd6cd46a51\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.06807\",\"authors\":[{\"authorId\":\"145490315\",\"name\":\"Kartik Hegde\"},{\"authorId\":\"50843533\",\"name\":\"R. Agrawal\"},{\"authorId\":\"51463024\",\"name\":\"Yulun Yao\"},{\"authorId\":\"2012099\",\"name\":\"Christopher W. Fletcher\"}],\"doi\":\"10.1109/MICRO.2018.00080\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"title\":\"Morph: Flexible Acceleration for 3D CNN-Based Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"venue\":\"2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036617777\",\"name\":\"Dersu Giritlio\\u011flu\"},{\"authorId\":\"66178017\",\"name\":\"Burak Mandira\"},{\"authorId\":\"66431479\",\"name\":\"Selim F. Yilmaz\"},{\"authorId\":\"2036617571\",\"name\":\"Can Ufuk Ertenli\"},{\"authorId\":\"2036604806\",\"name\":\"Berhan Faruk Akg\\u00fcr\"},{\"authorId\":\"72438439\",\"name\":\"Merve Kiniklioglu\"},{\"authorId\":\"2036244890\",\"name\":\"Asl\\u0131 G\\u00fcl Kurt\"},{\"authorId\":\"2036618924\",\"name\":\"Emre Mutlu\"},{\"authorId\":\"8290492\",\"name\":\"\\u015e. C. G\\u00fcrel\"},{\"authorId\":\"8290492\",\"name\":\"\\u015e. C. G\\u00fcrel\"},{\"authorId\":\"1471439035\",\"name\":\"Hamdi Dibeklioglu\"}],\"doi\":\"10.1007/s12193-020-00347-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2cb5347a1d56940d77964d6e07f3e4be2ae321c\",\"title\":\"Multimodal analysis of personality traits on videos of self-presentation and induced behavior\",\"url\":\"https://www.semanticscholar.org/paper/c2cb5347a1d56940d77964d6e07f3e4be2ae321c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1965909970\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"1755773\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"143930562\",\"name\":\"G. Chen\"},{\"authorId\":\"153016830\",\"name\":\"J. Guo\"}],\"doi\":\"10.1109/ACCESS.2020.3021857\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3a02eab3df6ec8bfaf0711cd1d87ab837fe437b\",\"title\":\"Understanding Objects in Video: Object-Oriented Video Captioning via Structured Trajectory and Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/e3a02eab3df6ec8bfaf0711cd1d87ab837fe437b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.09461\",\"authors\":[{\"authorId\":\"1405834398\",\"name\":\"Peng Xu\"},{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"79456794\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"145886114\",\"name\":\"Jun Guo\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":\"10.1109/tcsvt.2020.3014491\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5c8c79a9a943ababce9bd6892da97d297d0b3e1\",\"title\":\"Fine-Grained Instance-Level Sketch-Based Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b5c8c79a9a943ababce9bd6892da97d297d0b3e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35548557\",\"name\":\"Konstantinos Gkountakos\"},{\"authorId\":\"48764738\",\"name\":\"K. Ioannidis\"},{\"authorId\":\"1774233\",\"name\":\"T. Tsikrika\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1145/3372278.3390725\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"080c7eeabecc13cb49026e39e8e82d2a6ee9926a\",\"title\":\"A Crowd Analysis Framework for Detecting Violence Scenes\",\"url\":\"https://www.semanticscholar.org/paper/080c7eeabecc13cb49026e39e8e82d2a6ee9926a\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27213742\",\"name\":\"W. Zhao\"},{\"authorId\":\"152905258\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"51350339\",\"name\":\"Yingli Sun\"},{\"authorId\":\"50991066\",\"name\":\"Cheng Li\"},{\"authorId\":\"7970336\",\"name\":\"Wei-lan Wu\"},{\"authorId\":\"103154524\",\"name\":\"L. Jin\"},{\"authorId\":\"1390867136\",\"name\":\"Zhiming Yang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"50735393\",\"name\":\"P. Gao\"},{\"authorId\":\"48319637\",\"name\":\"P. Wang\"},{\"authorId\":\"40284404\",\"name\":\"Yanqing Hua\"},{\"authorId\":\"50651607\",\"name\":\"Maoxing Li\"}],\"doi\":\"10.1158/0008-5472.CAN-18-0696\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dae87cbcd7475b0775287c4c3223e4d6089a13f\",\"title\":\"3D Deep Learning from CT Scans Predicts Tumor Invasiveness of Subcentimeter Pulmonary Adenocarcinomas.\",\"url\":\"https://www.semanticscholar.org/paper/3dae87cbcd7475b0775287c4c3223e4d6089a13f\",\"venue\":\"Cancer research\",\"year\":2018},{\"arxivId\":\"1812.01263\",\"authors\":[{\"authorId\":\"2551640\",\"name\":\"Atsushi Kanehira\"},{\"authorId\":\"3124509\",\"name\":\"Kentaro Takemoto\"},{\"authorId\":\"52176168\",\"name\":\"Sho Inayoshi\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2019.00879\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b016ff1148e8bf8ffa1beb5c8cd89c644825edf2\",\"title\":\"Multimodal Explanations by Predicting Counterfactuality in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b016ff1148e8bf8ffa1beb5c8cd89c644825edf2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.11954\",\"authors\":[{\"authorId\":\"2117357\",\"name\":\"Chengxu Zhuang\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"40657572\",\"name\":\"D. Yamins\"}],\"doi\":\"10.1109/CVPR42600.2020.00958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02cd7e1a888fedd25337a4598f332c5203091e71\",\"title\":\"Unsupervised Learning From Video With Deep Neural Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/02cd7e1a888fedd25337a4598f332c5203091e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.11557\",\"authors\":[{\"authorId\":\"145872624\",\"name\":\"Yao Rong\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1884159\",\"name\":\"Enkelejda Kasneci\"}],\"doi\":\"10.1109/ITSC45102.2020.9294181\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"318c74a024b39897b927e462a0ff15c8d2f97415\",\"title\":\"Driver Intention Anticipation Based on In-Cabin and Driving Scene Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/318c74a024b39897b927e462a0ff15c8d2f97415\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1959406969\",\"name\":\"Teppei Suzuki\"},{\"authorId\":\"1484094470\",\"name\":\"Kodai Nakashima\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.1109/ICRA40945.2020.9197399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7422c29fc16151913940b0dad2eb5baec0e2dfa9\",\"title\":\"Joint Pedestrian Detection and Risk-level Prediction with Motion-Representation-by-Detection\",\"url\":\"https://www.semanticscholar.org/paper/7422c29fc16151913940b0dad2eb5baec0e2dfa9\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2008.00141\",\"authors\":[{\"authorId\":\"1739277022\",\"name\":\"Jing Shi\"},{\"authorId\":\"3580276\",\"name\":\"Zhiheng Li\"},{\"authorId\":\"2743695\",\"name\":\"Haitian Zheng\"},{\"authorId\":\"47103309\",\"name\":\"Yihang Xu\"},{\"authorId\":\"39965348\",\"name\":\"Tianyou Xiao\"},{\"authorId\":\"1850457615\",\"name\":\"Weitao Tan\"},{\"authorId\":\"46909942\",\"name\":\"Xiaoning Guo\"},{\"authorId\":\"40523619\",\"name\":\"Sizhe Li\"},{\"authorId\":\"1492121866\",\"name\":\"Bin Yang\"},{\"authorId\":\"48559634\",\"name\":\"Z. Xu\"},{\"authorId\":\"3454330\",\"name\":\"R. Lin\"},{\"authorId\":\"1850415250\",\"name\":\"Zhongkai Shangguan\"},{\"authorId\":\"1418468111\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1739383876\",\"name\":\"Jingwen Wang\"},{\"authorId\":\"24734526\",\"name\":\"Rohan Sharma\"},{\"authorId\":\"1850615551\",\"name\":\"Surya Iyer\"},{\"authorId\":\"2565521\",\"name\":\"A. Deshmukh\"},{\"authorId\":\"1850414878\",\"name\":\"Raunak Mahalik\"},{\"authorId\":\"46529788\",\"name\":\"S. Singh\"},{\"authorId\":\"72042607\",\"name\":\"Jayant G. Rohra\"},{\"authorId\":\"2760404\",\"name\":\"Yipeng Zhang\"},{\"authorId\":\"9572971\",\"name\":\"Tongyu Yang\"},{\"authorId\":\"50654041\",\"name\":\"X. Wen\"},{\"authorId\":\"151431506\",\"name\":\"E. Fahnestock\"},{\"authorId\":\"1850643473\",\"name\":\"Bryce Ikeda\"},{\"authorId\":\"34896307\",\"name\":\"I. Lawson\"},{\"authorId\":\"36096161\",\"name\":\"A. Finkelstein\"},{\"authorId\":\"1850705323\",\"name\":\"Kehao Guo\"},{\"authorId\":\"84421169\",\"name\":\"R. Magnotti\"},{\"authorId\":\"144616805\",\"name\":\"A. Sexton\"},{\"authorId\":\"1850690827\",\"name\":\"Jeet Ketan Thaker\"},{\"authorId\":\"1850602178\",\"name\":\"Oscar Su\"},{\"authorId\":\"100887531\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"31ffab4f9db78b74115a66080451789d209deb24\",\"title\":\"Actor-Action Video Classification CSC 249/449 Spring 2020 Challenge Report\",\"url\":\"https://www.semanticscholar.org/paper/31ffab4f9db78b74115a66080451789d209deb24\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.00859\",\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"title\":\"Less Is More: Learning Highlight Detection From Video Duration\",\"url\":\"https://www.semanticscholar.org/paper/85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1926536\",\"name\":\"Chengcheng Wei\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/BigMM.2019.00027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be5b602bfbc6488f8ef633db1292f70138b5751b\",\"title\":\"Deep Grammatical Multi-classifier for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be5b602bfbc6488f8ef633db1292f70138b5751b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"Reinier Oves Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"Eduardo F. Morales\"},{\"authorId\":\"144763689\",\"name\":\"Luis Enrique Sucar\"}],\"doi\":\"10.1007/978-3-030-33904-3_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3497d8a0438bd69e857690ed1d60ce32ce8546f8\",\"title\":\"A Novel Scheme for Training Two-Stream CNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3497d8a0438bd69e857690ed1d60ce32ce8546f8\",\"venue\":\"CIARP\",\"year\":2019},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2010.01824\",\"authors\":[{\"authorId\":\"144943440\",\"name\":\"Saptarshi Sinha\"},{\"authorId\":\"1743276\",\"name\":\"H. Ohashi\"},{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1516fe9eeca6e8bd3d26723f725d222107cb2551\",\"title\":\"Class-Wise Difficulty-Balanced Loss for Solving Class-Imbalance\",\"url\":\"https://www.semanticscholar.org/paper/1516fe9eeca6e8bd3d26723f725d222107cb2551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.02993\",\"authors\":[{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"41156945\",\"name\":\"W. Crichton\"},{\"authorId\":\"2651173\",\"name\":\"J. Hong\"},{\"authorId\":\"153742294\",\"name\":\"Xinwei Yao\"},{\"authorId\":\"9184695\",\"name\":\"Haotian Zhang\"},{\"authorId\":\"48289103\",\"name\":\"Anh Truong\"},{\"authorId\":\"1381444249\",\"name\":\"Avanika Narayan\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9eb31de07bd0cd684a46785020f08633e4331e05\",\"title\":\"Rekall: Specifying Video Events using Compositions of Spatiotemporal Labels\",\"url\":\"https://www.semanticscholar.org/paper/9eb31de07bd0cd684a46785020f08633e4331e05\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.09412\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"73819368\",\"name\":\"Benjia Zhou\"},{\"authorId\":\"1785406293\",\"name\":\"Jun Wan\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"title\":\"Searching Multi-Rate and Multi-Modal Temporal Enhanced Networks for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40290798\",\"name\":\"T. Suzuki\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1007/978-3-030-11012-3_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72446b34abdd68469eb6045b3958bb10d8b2cfd4\",\"title\":\"Learning Spatiotemporal 3D Convolution with Video Order Self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/72446b34abdd68469eb6045b3958bb10d8b2cfd4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394415540\",\"name\":\"Xiankun Pei\"},{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"97522088\",\"name\":\"Ye Zhao\"}],\"doi\":\"10.1145/3347319.3356837\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91ef86ef55d7e70bdcc4e5ac20d798055f845736\",\"title\":\"Continuous Sign Language Recognition Based on Pseudo-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/91ef86ef55d7e70bdcc4e5ac20d798055f845736\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.07882\",\"authors\":[{\"authorId\":\"2198519\",\"name\":\"Zongwei Zhou\"},{\"authorId\":\"1388013239\",\"name\":\"Vatsal Sodha\"},{\"authorId\":\"72238162\",\"name\":\"Jiaxuan Pang\"},{\"authorId\":\"143751204\",\"name\":\"Michael B. Gotway\"},{\"authorId\":\"1485304039\",\"name\":\"Jianming Liang\"}],\"doi\":\"10.1016/j.media.2020.101840\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"837ac3f4a638b1ae9f424e51f0e7bfa8cb05298d\",\"title\":\"Models Genesis\",\"url\":\"https://www.semanticscholar.org/paper/837ac3f4a638b1ae9f424e51f0e7bfa8cb05298d\",\"venue\":\"Medical Image Anal.\",\"year\":2021},{\"arxivId\":\"2003.07064\",\"authors\":[{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1109/cvpr42600.2020.01428\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"title\":\"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location\",\"url\":\"https://www.semanticscholar.org/paper/e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"venue\":\"CVPR\",\"year\":2020},{\"arxivId\":\"1905.08711\",\"authors\":[{\"authorId\":\"48085995\",\"name\":\"A. Kozlov\"},{\"authorId\":\"117171023\",\"name\":\"V. Andronov\"},{\"authorId\":\"122388064\",\"name\":\"Y. Gritsenko\"}],\"doi\":\"10.1145/3341105.3373906\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"d4262413c55cf0319922c42b796c74879a0632a8\",\"title\":\"Lightweight network architecture for real-time action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4262413c55cf0319922c42b796c74879a0632a8\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"1909.05667\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"title\":\"Explainable Deep Learning for Video Recognition Tasks: A Framework & Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.12494\",\"authors\":[{\"authorId\":\"34494191\",\"name\":\"YiMing Lei\"},{\"authorId\":\"102691580\",\"name\":\"Yukun Tian\"},{\"authorId\":\"3449207\",\"name\":\"Hongming Shan\"},{\"authorId\":\"2247926\",\"name\":\"Junping Zhang\"},{\"authorId\":\"47227094\",\"name\":\"G. Wang\"},{\"authorId\":\"152618536\",\"name\":\"M. Kalra\"}],\"doi\":\"10.1016/j.media.2019.101628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bce61a182c7a1028eed0c0f67e779753a86503c2\",\"title\":\"Shape and margin-aware lung nodule classification in low-dose CT images via soft activation mapping\",\"url\":\"https://www.semanticscholar.org/paper/bce61a182c7a1028eed0c0f67e779753a86503c2\",\"venue\":\"Medical Image Anal.\",\"year\":2020},{\"arxivId\":\"2008.02129\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"1768574\",\"name\":\"P. Yuen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"title\":\"Self-supervised Temporal Discriminative Learning for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46399735\",\"name\":\"Y. Liu\"}],\"doi\":\"10.3390/s20071979\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b4a909ffff2aea9f9ec904c7a997c5e8118bfc52\",\"title\":\"Multi-Scale Spatio-Temporal Feature Extraction and Depth Estimation from Sequences by Ordinal Classification\",\"url\":\"https://www.semanticscholar.org/paper/b4a909ffff2aea9f9ec904c7a997c5e8118bfc52\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6624871\",\"name\":\"Dmytro Tkachenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b305ba8ae5ae48c86a3ba93073151f21382ccd39\",\"title\":\"EasyChair Preprint No 336 Human action recognition using fusion of modern deep convolutional and recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b305ba8ae5ae48c86a3ba93073151f21382ccd39\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20f900237f789fb860e32cc823a103755e02d87e\",\"title\":\"Activity Recognition with Still Images and Video\",\"url\":\"https://www.semanticscholar.org/paper/20f900237f789fb860e32cc823a103755e02d87e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9055516\",\"name\":\"L. Zhao\"},{\"authorId\":\"9313823\",\"name\":\"Z. Wang\"},{\"authorId\":\"46266049\",\"name\":\"G. Zhang\"},{\"authorId\":\"1965609\",\"name\":\"H. Gao\"}],\"doi\":\"10.1007/s11042-020-09259-w\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d7579bef38cf04542b2b0cfffb51c58fb26b629\",\"title\":\"Driver drowsiness recognition via transferred deep 3D convolutional network and state probability vector\",\"url\":\"https://www.semanticscholar.org/paper/4d7579bef38cf04542b2b0cfffb51c58fb26b629\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"51066371\",\"name\":\"Yuli Chen\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47767769\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"},{\"authorId\":\"144401327\",\"name\":\"Jing Deng\"}],\"doi\":\"10.1007/s11042-020-09137-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"title\":\"XwiseNet: action recognition with Xwise separable convolutions\",\"url\":\"https://www.semanticscholar.org/paper/08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151478835\",\"name\":\"Chen Xiao-kai\"},{\"authorId\":\"151485756\",\"name\":\"Gao Ke\"},{\"authorId\":\"145515934\",\"name\":\"C. Juan\"}],\"doi\":\"10.1109/ICME.2019.00169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9fb80b6dc6b636478915382f8de2fb43ee5900d\",\"title\":\"Predictability Analyzing: Deep Reinforcement Learning for Early Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9fb80b6dc6b636478915382f8de2fb43ee5900d\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"title\":\"ops Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.06902\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"1605763279\",\"name\":\"Dongliang Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"title\":\"Collaborative Distillation in the Parameter and Spectrum Domains for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09508\",\"authors\":[{\"authorId\":\"20727815\",\"name\":\"V. Veerabadran\"},{\"authorId\":\"2300332\",\"name\":\"R. Pourreza\"},{\"authorId\":\"3000952\",\"name\":\"A. Habibian\"},{\"authorId\":\"1619853435\",\"name\":\"Taco Cohen\"}],\"doi\":\"10.1109/cvprw50498.2020.00092\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9de002992c790e022abb59746e7cd27447df8fb\",\"title\":\"Adversarial Distortion for Learned Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/f9de002992c790e022abb59746e7cd27447df8fb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2012.08097\",\"authors\":[{\"authorId\":\"51445222\",\"name\":\"Shentong Mo\"},{\"authorId\":\"37874701\",\"name\":\"Xiaoqing Tan\"},{\"authorId\":\"2037452190\",\"name\":\"Jingfei Xia\"},{\"authorId\":\"2037420729\",\"name\":\"Pinxu Ren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c10f951f731274f088333a43ba57e416612c8e3\",\"title\":\"Towards Improving Spatiotemporal Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c10f951f731274f088333a43ba57e416612c8e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.03498\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1109/CVPR.2019.00504\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"75544f83d38ef1686d70c763deb43305c5dc8a48\",\"title\":\"LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/75544f83d38ef1686d70c763deb43305c5dc8a48\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2205770\",\"name\":\"Tackgeun You\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1007/978-3-030-58571-6_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39fad4820b9a1d5186c915e171e8ef307f6ef98d\",\"title\":\"Traffic Accident Benchmark for Causality Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39fad4820b9a1d5186c915e171e8ef307f6ef98d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.01843\",\"authors\":[{\"authorId\":\"90070363\",\"name\":\"Amir Ziai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"46d062fe61e9a1bdd328bc600a87353958312c8a\",\"title\":\"Detecting Kissing Scenes in a Database of Hollywood Films\",\"url\":\"https://www.semanticscholar.org/paper/46d062fe61e9a1bdd328bc600a87353958312c8a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008034295\",\"name\":\"Nayu Liu\"},{\"authorId\":\"2946890\",\"name\":\"Xian Sun\"},{\"authorId\":\"150129463\",\"name\":\"Hongfeng Yu\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"3287827\",\"name\":\"Guangluan Xu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.144\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e993f052fc1a860011e34e7043af9b3b1a2c8897\",\"title\":\"Multistage Fusion with Forget Gate for Multimodal Summarization in Open-Domain Videos\",\"url\":\"https://www.semanticscholar.org/paper/e993f052fc1a860011e34e7043af9b3b1a2c8897\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.08826\",\"authors\":[{\"authorId\":\"48904692\",\"name\":\"Shijie Sun\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"49195830\",\"name\":\"X. Song\"},{\"authorId\":\"66589145\",\"name\":\"H. Song\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-58586-0_37\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c9f448bfb87e9a3db4f2c73a93be271cca0c932\",\"title\":\"Simultaneous Detection and Tracking with Motion Modelling for Multiple Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/5c9f448bfb87e9a3db4f2c73a93be271cca0c932\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12089020\",\"name\":\"Yuki Hiroi\"},{\"authorId\":\"3020419\",\"name\":\"W. Kameyama\"}],\"doi\":\"10.1109/GCCE50665.2020.9291887\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba37ce2c0611f12b0d51b7b61cf0e78b32ba40d6\",\"title\":\"Person Re-identification by Two-stream Feature-fusion Architecture Utilizing a Partial Body Image\",\"url\":\"https://www.semanticscholar.org/paper/ba37ce2c0611f12b0d51b7b61cf0e78b32ba40d6\",\"venue\":\"2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)\",\"year\":2020},{\"arxivId\":\"1903.01197\",\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.1109/CVPR.2019.00806\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"title\":\"Collaborative Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.08740\",\"authors\":[{\"authorId\":\"145653036\",\"name\":\"Xin Tang\"},{\"authorId\":\"3456696\",\"name\":\"Shanbo Cheng\"},{\"authorId\":\"144919491\",\"name\":\"L. Do\"},{\"authorId\":\"3436926\",\"name\":\"Zhiyu Min\"},{\"authorId\":\"144642000\",\"name\":\"Feng Ji\"},{\"authorId\":null,\"name\":\"Heng Yu\"},{\"authorId\":\"47540131\",\"name\":\"Ji Zhang\"},{\"authorId\":\"49177776\",\"name\":\"Haiqin Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fee6c3d72455584d4e50a55e7a6adb5e6b604667\",\"title\":\"Improving Multilingual Semantic Textual Similarity with Shared Sentence Encoder for Low-resource Languages\",\"url\":\"https://www.semanticscholar.org/paper/fee6c3d72455584d4e50a55e7a6adb5e6b604667\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49010385\",\"name\":\"Yuan Jing\"},{\"authorId\":\"1384219309\",\"name\":\"Jinshan Hao\"},{\"authorId\":\"143666997\",\"name\":\"P. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2946870\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4d47dfb02ef1787d51a8eab65969a4e18d70920\",\"title\":\"Learning Spatiotemporal Features of CSI for Indoor Localization With Dual-Stream 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c4d47dfb02ef1787d51a8eab65969a4e18d70920\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024784\",\"name\":\"Ye Li\"},{\"authorId\":\"7188881\",\"name\":\"Guangqiang Yin\"},{\"authorId\":\"145802850\",\"name\":\"S. Hou\"},{\"authorId\":\"16176062\",\"name\":\"Jianhai Cui\"},{\"authorId\":\"2105845\",\"name\":\"Zicheng Huang\"}],\"doi\":\"10.1007/978-3-030-23597-0_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33e44db6706969ca9f16d81805089c3d05519b75\",\"title\":\"Spatiotemporal Feature Extraction for Pedestrian Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/33e44db6706969ca9f16d81805089c3d05519b75\",\"venue\":\"WASA\",\"year\":2019},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491185305\",\"name\":\"Chikako Takasaki\"},{\"authorId\":\"1785227\",\"name\":\"A. Takefusa\"},{\"authorId\":\"1754192\",\"name\":\"H. Nakada\"},{\"authorId\":\"35187302\",\"name\":\"Masato Oguchi\"}],\"doi\":\"10.1109/CloudCom.2019.00027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d97893e11d4519457160a53373216a285d40b14e\",\"title\":\"A Study of Action Recognition Using Pose Data Toward Distributed Processing Over Edge and Cloud\",\"url\":\"https://www.semanticscholar.org/paper/d97893e11d4519457160a53373216a285d40b14e\",\"venue\":\"2019 IEEE International Conference on Cloud Computing Technology and Science (CloudCom)\",\"year\":2019},{\"arxivId\":\"1909.05165\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"title\":\"Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1958291\",\"name\":\"A. Singh\"},{\"authorId\":\"50333206\",\"name\":\"Aman Kumar\"},{\"authorId\":\"70626177\",\"name\":\"A. Jain\"}],\"doi\":\"10.1109/ICCVW.2019.00227\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"16f76c782224f1171044b8a92875376c950232cf\",\"title\":\"Bayesian Gait-Based Gender Identification (BGGI) Network on Individuals Wearing Loosely Fitted Clothing\",\"url\":\"https://www.semanticscholar.org/paper/16f76c782224f1171044b8a92875376c950232cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49301794\",\"name\":\"Junyu Lu\"},{\"authorId\":\"2254851\",\"name\":\"Chenbin Zhang\"},{\"authorId\":\"50683578\",\"name\":\"Z. Xie\"},{\"authorId\":\"38189652\",\"name\":\"Guang Ling\"},{\"authorId\":\"10733510\",\"name\":\"T. Zhou\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":\"10.18653/v1/P19-1006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8139f574111db4a35574eba97f50d443ed3fb6fe\",\"title\":\"Constructing Interpretive Spatio-Temporal Features for Multi-Turn Responses Selection\",\"url\":\"https://www.semanticscholar.org/paper/8139f574111db4a35574eba97f50d443ed3fb6fe\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79993756\",\"name\":\"Haruya Ishikawa\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"48589121\",\"name\":\"Shuichi Akizuki\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.23919/MVA.2019.8757896\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a019ef99567561824c50196f013eb73657b96232\",\"title\":\"Human-Object Maps for Daily Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a019ef99567561824c50196f013eb73657b96232\",\"venue\":\"2019 16th International Conference on Machine Vision Applications (MVA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/TBIOM.2020.2968216\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c485bd63692f4aa68e54137ad237a431849017b9\",\"title\":\"Online Dynamic Hand Gesture Recognition Including Efficiency Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c485bd63692f4aa68e54137ad237a431849017b9\",\"venue\":\"IEEE Transactions on Biometrics, Behavior, and Identity Science\",\"year\":2020},{\"arxivId\":\"1806.01954\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"9947219\",\"name\":\"Simion-Vlad Bogolin\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c42f427b54ab12a1d89827ee4c6951efae733b55\",\"title\":\"Mining for meaning: from vision to language through multiple networks consensus\",\"url\":\"https://www.semanticscholar.org/paper/c42f427b54ab12a1d89827ee4c6951efae733b55\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05782\",\"authors\":[{\"authorId\":\"49902274\",\"name\":\"Y. Tian\"},{\"authorId\":\"2574958\",\"name\":\"Gaofeng Pan\"},{\"authorId\":\"144789580\",\"name\":\"Mohamed-Slim Alouini\"}],\"doi\":\"10.36227/techrxiv.12458267\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"08f659d873d70d61d86b894bb0c16d7172a7644b\",\"title\":\"Applying Deep-Learning-Based Computer Vision to Wireless Communications: Methodologies, Opportunities, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/08f659d873d70d61d86b894bb0c16d7172a7644b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.04262\",\"authors\":[{\"authorId\":\"80977068\",\"name\":\"Shao-Yuan Lo\"},{\"authorId\":\"1986468743\",\"name\":\"Jeya Maria Jose Valanarasu\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"41fdb4e109cf1895e78694e2716db5729fdd0a2a\",\"title\":\"Overcomplete Representations Against Adversarial Videos\",\"url\":\"https://www.semanticscholar.org/paper/41fdb4e109cf1895e78694e2716db5729fdd0a2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143955478\",\"name\":\"Xin He\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":\"72871892\",\"name\":\"S. Shi\"},{\"authorId\":\"152170666\",\"name\":\"X. Chu\"},{\"authorId\":\"71855158\",\"name\":\"J. Tang\"},{\"authorId\":\"103576316\",\"name\":\"X. Liu\"},{\"authorId\":\"102168416\",\"name\":\"C. Yan\"},{\"authorId\":\"153389906\",\"name\":\"J. Zhang\"},{\"authorId\":\"72584201\",\"name\":\"G. Ding\"}],\"doi\":\"10.1101/2020.06.08.20125963\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ca354d24da3f91d6932a4558d946884a96929b5\",\"title\":\"Benchmarking Deep Learning Models and Automated Model Design for COVID-19 Detection with Chest CT Scans\",\"url\":\"https://www.semanticscholar.org/paper/1ca354d24da3f91d6932a4558d946884a96929b5\",\"venue\":\"medRxiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581759118\",\"name\":\"Ashkan Shakarami\"},{\"authorId\":\"70265572\",\"name\":\"Hadis Tarrah\"},{\"authorId\":\"1583990875\",\"name\":\"Ali Mahdavi-Hormat\"}],\"doi\":\"10.1016/j.ijleo.2020.164237\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8529896993a8bda9dfb46e3213cc981246bd5c0\",\"title\":\"A CAD system for diagnosing Alzheimer\\u2019s disease using 2D slices and an improved AlexNet-SVM method\",\"url\":\"https://www.semanticscholar.org/paper/d8529896993a8bda9dfb46e3213cc981246bd5c0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.08895\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65961eb0380182c32ab3d018c83010aa80969d8a\",\"title\":\"An Efficient 3D CNN for Action/Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/65961eb0380182c32ab3d018c83010aa80969d8a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.03266\",\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":\"10.1109/WACV45572.2020.9093283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7286873\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"36906906\",\"name\":\"Yi Wu\"},{\"authorId\":\"1750931828\",\"name\":\"Ke Cheng\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"},{\"authorId\":\"1694235\",\"name\":\"Hanqing Lu\"}],\"doi\":\"10.1016/j.patcog.2020.107416\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7cbc6ef1599bff31816c003d18821fcf6d1bde\",\"title\":\"Gesture recognition based on deep deformable 3D convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7cbc6ef1599bff31816c003d18821fcf6d1bde\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6486893\",\"name\":\"Chao Pu\"},{\"authorId\":null,\"name\":\"Hikvision\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"88997434c3dcfe1b9355edae84c78429e423600c\",\"title\":\"Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88997434c3dcfe1b9355edae84c78429e423600c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412211187\",\"name\":\"Houssam El-Hariri\"}],\"doi\":\"10.14288/1.0389533\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e6b237994d443564e206a6a256f645d1584511\",\"title\":\"Reliable and robust hip dysplasia measurement with three-dimensional ultrasound and convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/a6e6b237994d443564e206a6a256f645d1584511\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885339245\",\"name\":\"Ana-Cosmina Popescu\"},{\"authorId\":\"2595036\",\"name\":\"I. Mocanu\"},{\"authorId\":\"143623623\",\"name\":\"B. Cramariuc\"}],\"doi\":\"10.1109/ACCESS.2020.3013406\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"444cebeebce47adec38e43a0789d6cf2610c1fc9\",\"title\":\"Fusion Mechanisms for Human Activity Recognition Using Automated Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/444cebeebce47adec38e43a0789d6cf2610c1fc9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2300332\",\"name\":\"R. Pourreza\"},{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3000952\",\"name\":\"A. Habibian\"}],\"doi\":\"10.1109/ICCVW.2019.00129\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"607b8b660c4a60cca358ab7583a3ee24d76c27b2\",\"title\":\"Recognizing Compressed Videos: Challenges and Promises\",\"url\":\"https://www.semanticscholar.org/paper/607b8b660c4a60cca358ab7583a3ee24d76c27b2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2011.04084\",\"authors\":[{\"authorId\":\"48414237\",\"name\":\"S. Ghorbani\"},{\"authorId\":\"2334648\",\"name\":\"Y. Gaur\"},{\"authorId\":\"145814853\",\"name\":\"Y. Shi\"},{\"authorId\":\"152319568\",\"name\":\"Jinyu Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"913ad51defbde43f6147d8b79244a5dc4d0a2071\",\"title\":\"Listen, Look and Deliberate: Visual context-aware speech recognition using pre-trained text-video representations\",\"url\":\"https://www.semanticscholar.org/paper/913ad51defbde43f6147d8b79244a5dc4d0a2071\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d281b07ee152f6c1312297b71791d358f4dc88cb\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360$^{\\\\circ}$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/d281b07ee152f6c1312297b71791d358f4dc88cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.05721\",\"authors\":[{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48411936\",\"name\":\"H. Lee\"},{\"authorId\":\"80069330\",\"name\":\"Dong Heon Cho\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"24b300420bd814e48b59a3419a22d706da6c4191\",\"title\":\"Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24b300420bd814e48b59a3419a22d706da6c4191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410229972\",\"name\":\"Guy Ben-Yosef\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"113363846\",\"name\":\"Shimon Ullman\"}],\"doi\":\"10.1016/j.cognition.2020.104263\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"340edf9512e543655f7fa27f8498e0ad98ea2521\",\"title\":\"Minimal videos: Trade-off between spatial and temporal information in human and machine vision\",\"url\":\"https://www.semanticscholar.org/paper/340edf9512e543655f7fa27f8498e0ad98ea2521\",\"venue\":\"Cognition\",\"year\":2020},{\"arxivId\":\"1905.03966\",\"authors\":[{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"49050519\",\"name\":\"Jiyuan Zhang\"},{\"authorId\":\"47119038\",\"name\":\"X. Wang\"},{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/CVPR.2019.00854\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"title\":\"Memory-Attended Recurrent Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b12124f7bbdd3a99d6b392024806d0f3124380ac\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"}],\"doi\":\"10.1007/978-3-030-12177-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7f93e107e81125397652c5d2ae4535c5344612\",\"title\":\"Three-Stream Convolution Networks After Background Subtraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d7f93e107e81125397652c5d2ae4535c5344612\",\"venue\":\"FFER/DLPR@ICPR\",\"year\":2018},{\"arxivId\":\"1908.01536\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144353457\",\"name\":\"A. D. Marshall\"},{\"authorId\":\"113727107\",\"name\":\"Harrison B Taylor\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e7242dfc1d8124cf8c91bcc7d8c62fee7d274198\",\"title\":\"Discriminating Spatial and Temporal Relevance in Deep Taylor Decompositions for Explainable Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e7242dfc1d8124cf8c91bcc7d8c62fee7d274198\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40987711\",\"name\":\"G. Hahm\"},{\"authorId\":\"31232920\",\"name\":\"Chang-Uk Kwak\"},{\"authorId\":null,\"name\":\"Sun-Joong Kim\"}],\"doi\":\"10.1109/ICTC49870.2020.9289342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c08aca9e9f2785d5713acc48ee40eb5ca0d9ee50\",\"title\":\"Learning a Video-Text Joint Embedding using Korean Tagged Movie Clips\",\"url\":\"https://www.semanticscholar.org/paper/c08aca9e9f2785d5713acc48ee40eb5ca0d9ee50\",\"venue\":\"2020 International Conference on Information and Communication Technology Convergence (ICTC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"145144215\",\"name\":\"L. Zhang\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/TMM.2018.2869278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7029cf09ef4a8fb6b53123314e540113fc8ab6a\",\"title\":\"Continuous Gesture Segmentation and Recognition Using 3DCNN and Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/f7029cf09ef4a8fb6b53123314e540113fc8ab6a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134665127\",\"name\":\"Roberto S\\u00e1nchez P\\u00e1manes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c03323dc648d7739aa230ea2d65eb02a0558c6a\",\"title\":\"Learning temporal features of facial action units using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/4c03323dc648d7739aa230ea2d65eb02a0558c6a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48411946\",\"name\":\"Hyunhoon Lee\"},{\"authorId\":\"38124188\",\"name\":\"Y. Byun\"},{\"authorId\":\"7547486\",\"name\":\"Seokha Hwang\"},{\"authorId\":\"1915813\",\"name\":\"Sunggu Lee\"},{\"authorId\":\"40234594\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/ISOCC.2018.8649987\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"452681cdc6f54ccbafc8d1e6414c3e672084ad0a\",\"title\":\"Fixed-Point Quantization of 3D Convolutional Neural Networks for Energy-Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/452681cdc6f54ccbafc8d1e6414c3e672084ad0a\",\"venue\":\"2018 International SoC Design Conference (ISOCC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98831710\",\"name\":\"B. Yang\"},{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86010b6cb557103eda7e28fa2b497c9a9697fa8d\",\"title\":\"Non-Autoregressive Video Captioning with Iterative Refinement\",\"url\":\"https://www.semanticscholar.org/paper/86010b6cb557103eda7e28fa2b497c9a9697fa8d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"2011.05227\",\"authors\":[{\"authorId\":\"2008155399\",\"name\":\"Th'eo Ayral\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"3477862\",\"name\":\"S. Bacon\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9080a9f5464b37572202e4a4061997428993fe50\",\"title\":\"Temporal Stochastic Softmax for 3D CNNs: An Application in Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9080a9f5464b37572202e4a4061997428993fe50\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"}],\"doi\":\"10.1109/ICIP40778.2020.9190958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"title\":\"Grouped Temporal Enhancement Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944615571\",\"name\":\"A. Almeida\"},{\"authorId\":\"145334240\",\"name\":\"J. P. D. Villiers\"},{\"authorId\":\"143985011\",\"name\":\"A. Freitas\"},{\"authorId\":\"1944660087\",\"name\":\"M. Velayudan\"}],\"doi\":\"10.23919/FUSION45008.2020.9190331\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b558a0a74a96f0d08c57ea3c78c2e11335c76aa8\",\"title\":\"Visual comparison of statistical feature aggregation methods for video-based similarity applications\",\"url\":\"https://www.semanticscholar.org/paper/b558a0a74a96f0d08c57ea3c78c2e11335c76aa8\",\"venue\":\"2020 IEEE 23rd International Conference on Information Fusion (FUSION)\",\"year\":2020},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10839\",\"authors\":[{\"authorId\":\"7878341\",\"name\":\"Wubo Li\"},{\"authorId\":\"46197764\",\"name\":\"D. Jiang\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"}],\"doi\":\"10.21437/interspeech.2020-2359\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"title\":\"TMT: A Transformer-based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8207793\",\"name\":\"James P. Bohnslav\"},{\"authorId\":\"8419711\",\"name\":\"Nivanthika K Wimalasena\"},{\"authorId\":\"1945164690\",\"name\":\"Kelsey J Clausing\"},{\"authorId\":\"1976696822\",\"name\":\"David Yarmolinksy\"},{\"authorId\":\"144998880\",\"name\":\"T. Cruz\"},{\"authorId\":\"71489902\",\"name\":\"Eugenia Chiappe\"},{\"authorId\":\"48926043\",\"name\":\"Lauren L. Orefice\"},{\"authorId\":\"3824034\",\"name\":\"C. Woolf\"},{\"authorId\":\"3966889\",\"name\":\"C. Harvey\"}],\"doi\":\"10.1101/2020.09.24.312504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ddfc8674186fdf356ccc2bd030e187ba5232682\",\"title\":\"DeepEthogram: a machine learning pipeline for supervised behavior classification from raw pixels\",\"url\":\"https://www.semanticscholar.org/paper/5ddfc8674186fdf356ccc2bd030e187ba5232682\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.11516\",\"authors\":[{\"authorId\":\"46196169\",\"name\":\"S. Mahadevan\"},{\"authorId\":\"3488419\",\"name\":\"Ali Athar\"},{\"authorId\":\"3331304\",\"name\":\"Aljosa Osep\"},{\"authorId\":\"1908537619\",\"name\":\"Sebastian Hennen\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc79bd6fb5e674199dfa52a61c819735aed568c5\",\"title\":\"Making a Case for 3D Convolutions for Object Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bc79bd6fb5e674199dfa52a61c819735aed568c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894435\",\"name\":\"M. Almasi\"}],\"doi\":\"10.1109/icesc48915.2020.9155757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bf3d672e77b0b87f8dd79efd0cdf26752bb1bd5\",\"title\":\"Human Movement Analysis from the Egocentric Camera View\",\"url\":\"https://www.semanticscholar.org/paper/2bf3d672e77b0b87f8dd79efd0cdf26752bb1bd5\",\"venue\":\"2020 International Conference on Electronics and Sustainable Communication Systems (ICESC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7ae93062fdaa6054a2a44bf7b0352c5a5bf97eba\",\"title\":\"3 Dataset Construction and Task Description\",\"url\":\"https://www.semanticscholar.org/paper/7ae93062fdaa6054a2a44bf7b0352c5a5bf97eba\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"},{\"authorId\":\"146066583\",\"name\":\"Angelos Filos\"},{\"authorId\":\"2681954\",\"name\":\"Yarin Gal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0bf0cdf3dbc9de25978f741749e5cf5243072fd\",\"title\":\"Improving MFVI in Bayesian Neural Networks with Empirical Bayes: a Study with Diabetic Retinopathy Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/f0bf0cdf3dbc9de25978f741749e5cf5243072fd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1653150921\",\"name\":\"Shih-Cheng Huang\"},{\"authorId\":\"30324920\",\"name\":\"Tanay Kothari\"},{\"authorId\":\"2080947\",\"name\":\"I. Banerjee\"},{\"authorId\":\"1517032702\",\"name\":\"Chris Chute\"},{\"authorId\":\"20445908\",\"name\":\"R. Ball\"},{\"authorId\":\"1651818563\",\"name\":\"N. Borus\"},{\"authorId\":\"1650441341\",\"name\":\"Andrew Huang\"},{\"authorId\":\"5485740\",\"name\":\"B. Patel\"},{\"authorId\":\"1453104568\",\"name\":\"P. Rajpurkar\"},{\"authorId\":\"1453116587\",\"name\":\"Jeremy A. Irvin\"},{\"authorId\":\"1642480684\",\"name\":\"Jared Dunnmon\"},{\"authorId\":\"1651818183\",\"name\":\"Joseph Bledsoe\"},{\"authorId\":\"1651828856\",\"name\":\"Katie Shpanskaya\"},{\"authorId\":\"32252424\",\"name\":\"Abhay Dhaliwal\"},{\"authorId\":\"144036839\",\"name\":\"R. Zamanian\"},{\"authorId\":\"144110208\",\"name\":\"A. C. Ng\"},{\"authorId\":\"4204731\",\"name\":\"M. Lungren\"}],\"doi\":\"10.1038/s41746-020-0266-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7a4240dfde5d9e00eab9a0ba4ed30dcb3eadd1d4\",\"title\":\"PENet\\u2014a scalable deep-learning model for automated diagnosis of pulmonary embolism using volumetric CT imaging\",\"url\":\"https://www.semanticscholar.org/paper/7a4240dfde5d9e00eab9a0ba4ed30dcb3eadd1d4\",\"venue\":\"npj Digital Medicine\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740100\",\"name\":\"M. Kong\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"}],\"doi\":\"10.1007/978-3-030-32456-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"title\":\"Global Features of Fused Frame Relationships Help Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923065213\",\"name\":\"Qinghongya Shi\"},{\"authorId\":\"46702837\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"89616898\",\"name\":\"Haotian Ren\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"}],\"doi\":\"10.1186/s13640-020-00519-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"title\":\"Consistent constraint-based video-level learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"33532407\",\"name\":\"S. Cha\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"},{\"authorId\":\"40656963\",\"name\":\"Soonmin Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.01212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96c0ba91d650c571d20961f1fae0560f8962afa5\",\"title\":\"Regularization on Spatio-Temporally Smoothed Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96c0ba91d650c571d20961f1fae0560f8962afa5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"2008.11149\",\"authors\":[{\"authorId\":\"1390483392\",\"name\":\"Akshat Gupta\"},{\"authorId\":\"66496106\",\"name\":\"Milan Desai\"},{\"authorId\":\"24832454\",\"name\":\"Wusheng Liang\"},{\"authorId\":\"144566321\",\"name\":\"M. Kannan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18c0b6e5a7ac62788d61eab4f888dddc75a88db2\",\"title\":\"Spatiotemporal Action Recognition in Restaurant Videos\",\"url\":\"https://www.semanticscholar.org/paper/18c0b6e5a7ac62788d61eab4f888dddc75a88db2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48851752\",\"name\":\"K. Ono\"},{\"authorId\":\"134888836\",\"name\":\"Yutaro Iwamoto\"},{\"authorId\":\"92709317\",\"name\":\"Yen-Wei Chen\"},{\"authorId\":\"50299655\",\"name\":\"M. Nonaka\"}],\"doi\":\"10.18178/joig.8.2.42-46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"070c1e40f1bc7f9192d7e95de319ca4b01ade7b6\",\"title\":\"Automatic Segmentation of Infant Brain Ventricles with Hydrocephalus in MRI Based on 2.5D U-Net and Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/070c1e40f1bc7f9192d7e95de319ca4b01ade7b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/IPAS.2018.8708895\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"title\":\"Analysis on Temporal Dimension of Inputs for 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48274587\",\"name\":\"B. Su\"},{\"authorId\":\"1736695\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2919303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69946fbd310a60e3fe938654e8571a92ef4ffa67\",\"title\":\"Learning Low-Dimensional Temporal Representations with Latent Alignments\",\"url\":\"https://www.semanticscholar.org/paper/69946fbd310a60e3fe938654e8571a92ef4ffa67\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.11475\",\"authors\":[{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"27058669\",\"name\":\"I. Dave\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"title\":\"Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Security Videos\",\"url\":\"https://www.semanticscholar.org/paper/beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.01693\",\"authors\":[{\"authorId\":\"2027022082\",\"name\":\"Mohit Sharma\"},{\"authorId\":\"1785853\",\"name\":\"Oliver Kroemer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51c2b1b0e4465217cf3611726bb7161c4a71b50d\",\"title\":\"Relational Learning for Skill Preconditions\",\"url\":\"https://www.semanticscholar.org/paper/51c2b1b0e4465217cf3611726bb7161c4a71b50d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.06644\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"50652944\",\"name\":\"Xiangyu Wei\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"title\":\"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.07355\",\"authors\":[{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"title\":\"TinyVIRAT: Low-resolution Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11566\",\"authors\":[{\"authorId\":\"36811682\",\"name\":\"Z. Zhang\"},{\"authorId\":\"37198550\",\"name\":\"Yaya Shi\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"39397292\",\"name\":\"Peijin Wang\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1109/cvpr42600.2020.01329\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1dd557a8839733a5ee06d19989a265e61f603c1\",\"title\":\"Object Relational Graph With Teacher-Recommended Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1dd557a8839733a5ee06d19989a265e61f603c1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13491\",\"authors\":[{\"authorId\":\"1753876893\",\"name\":\"Muhamedrahimov Raouf\"},{\"authorId\":\"1753867861\",\"name\":\"Bar Amir\"},{\"authorId\":\"1753875994\",\"name\":\"Akselrod-Ballin Ayelet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe5236425b47196c5cf1b6157863f00a74431481\",\"title\":\"Learning Interclass Relations for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/fe5236425b47196c5cf1b6157863f00a74431481\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2009.05244\",\"authors\":[{\"authorId\":\"80977068\",\"name\":\"Shao-Yuan Lo\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b4aca8d9185be9c52157400f887987872eddd1ba\",\"title\":\"Defending Against Multiple and Unforeseen Adversarial Videos\",\"url\":\"https://www.semanticscholar.org/paper/b4aca8d9185be9c52157400f887987872eddd1ba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93782401659fe26faef7e5f3b84ff632a12da47f\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Forged Videos\",\"url\":\"https://www.semanticscholar.org/paper/93782401659fe26faef7e5f3b84ff632a12da47f\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629172313\",\"name\":\"Liqing Wan\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"34985619\",\"name\":\"Xiaoping Che\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"title\":\"A Fast Action Recognition Method with Cascaded Networks\",\"url\":\"https://www.semanticscholar.org/paper/bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"46728598\",\"name\":\"Xue Mei\"},{\"authorId\":\"46968435\",\"name\":\"Yi He\"},{\"authorId\":\"48180876\",\"name\":\"Jin Zhang\"}],\"doi\":\"10.1007/978-3-030-36189-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f05fa8951324b2f603360a845a610d2596d60aa4\",\"title\":\"Soft Transferring and Progressive Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f05fa8951324b2f603360a845a610d2596d60aa4\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":\"1811.07157\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"title\":\"Recurrence to the Rescue: Towards Causal Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134659275\",\"name\":\"Ryo Miyoshi\"},{\"authorId\":\"40168195\",\"name\":\"N. Nagata\"},{\"authorId\":\"48338800\",\"name\":\"M. Hashimoto\"}],\"doi\":\"10.1109/DICTA47822.2019.8946025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50ee97a344f08aa4241434940d676cc18d55ff91\",\"title\":\"Facial-Expression Recognition from Video using Enhanced Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/50ee97a344f08aa4241434940d676cc18d55ff91\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1811.03305\",\"authors\":[{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2da82a8deec0d5e72919c7139d467089334d63d\",\"title\":\"BAR: Bayesian Activity Recognition using variational inference\",\"url\":\"https://www.semanticscholar.org/paper/a2da82a8deec0d5e72919c7139d467089334d63d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82801208\",\"name\":\"S. Gurev\"},{\"authorId\":\"1446958517\",\"name\":\"N. Manoj\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2e62224832ab6b7c21587bbab5e70cff29cb0a8\",\"title\":\"Predicting Correctness of Protein Complex Binding Orientations\",\"url\":\"https://www.semanticscholar.org/paper/b2e62224832ab6b7c21587bbab5e70cff29cb0a8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144130711\",\"name\":\"C. Lin\"},{\"authorId\":\"2003807524\",\"name\":\"Mengxiang Lin\"},{\"authorId\":\"2003808280\",\"name\":\"Suhui Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3032430\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"25db1ba302821f83040021e164e34d323354b154\",\"title\":\"SOPNet Method for the Fine-Grained Measurement and Prediction of Precipitation Intensity Using Outdoor Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/25db1ba302821f83040021e164e34d323354b154\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740811711\",\"name\":\"Shinya Michibata\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"},{\"authorId\":\"1733070603\",\"name\":\"Atsushi Hashimoto\"}],\"doi\":\"10.1145/3379175.3391712\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66bead45f2fff3f9175658eb036f1a38031f2ba7\",\"title\":\"Cooking Activity Recognition in Egocentric Videos with a Hand Mask Image Branch in the Multi-stream CNN\",\"url\":\"https://www.semanticscholar.org/paper/66bead45f2fff3f9175658eb036f1a38031f2ba7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.04865\",\"authors\":[{\"authorId\":\"3087214\",\"name\":\"Yutaro Shigeto\"},{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"2996464\",\"name\":\"Jiaqing Lin\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46cff2f107f0f9c84aa0d70c64a6d1acc5e766fe\",\"title\":\"Video Caption Dataset for Describing Human Actions in Japanese\",\"url\":\"https://www.semanticscholar.org/paper/46cff2f107f0f9c84aa0d70c64a6d1acc5e766fe\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2019.00248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26994223\",\"name\":\"Yunbin Tu\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"2011768695\",\"name\":\"Junjun Guo\"},{\"authorId\":\"2409659\",\"name\":\"Shengxiang Gao\"},{\"authorId\":\"121854326\",\"name\":\"Zhengtao Yu\"}],\"doi\":\"10.1016/j.patcog.2020.107702\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6686fadf7f7ef2283cc9286095db281f8520ec04\",\"title\":\"Enhancing the alignment between target words and corresponding frames for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/6686fadf7f7ef2283cc9286095db281f8520ec04\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50980197\",\"name\":\"Yongchen Wang\"},{\"authorId\":\"94751361\",\"name\":\"Y. Wang\"},{\"authorId\":\"46382709\",\"name\":\"H. Li\"},{\"authorId\":\"144724152\",\"name\":\"Cong Shi\"},{\"authorId\":\"40613624\",\"name\":\"Xiaowei Li\"}],\"doi\":\"10.1145/3316781.3317919\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e1b8ff4a2e1a7a9f29ebc07df978c7cf9d75f1ff\",\"title\":\"Systolic Cube: A Spatial 3D CNN Accelerator Architecture for Low Power Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e1b8ff4a2e1a7a9f29ebc07df978c7cf9d75f1ff\",\"venue\":\"2019 56th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6135447\",\"name\":\"Jiawei Sun\"},{\"authorId\":\"47151943\",\"name\":\"W. Chen\"},{\"authorId\":\"46244742\",\"name\":\"Suting Peng\"},{\"authorId\":\"2952027\",\"name\":\"Boqiang Liu\"}],\"doi\":\"10.1007/s10916-019-1358-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7b44e9c242301867d88b42c5111d573ae091da2e\",\"title\":\"DRRNet: Dense Residual Refine Networks for Automatic Brain Tumor Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7b44e9c242301867d88b42c5111d573ae091da2e\",\"venue\":\"Journal of Medical Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2803030\",\"name\":\"Jungchan Cho\"},{\"authorId\":\"2104494\",\"name\":\"Hyoseok Hwang\"}],\"doi\":\"10.3390/s20123491\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a96207034c05387dc84c76de6c5b63795c499809\",\"title\":\"Spatio-Temporal Representation of an Electoencephalogram for Emotion Recognition Using a Three-Dimensional Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a96207034c05387dc84c76de6c5b63795c499809\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1904.09288\",\"authors\":[{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"145879186\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2019.00035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"title\":\"STEP: Spatio-Temporal Progressive Learning for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2112794\",\"name\":\"M. Inaba\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1007/978-3-030-11012-3_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9b97dd5fc8d79a9e18f283bf9a5644eaf6676ea\",\"title\":\"Recognizing People in Blind Spots Based on Surrounding Behavior\",\"url\":\"https://www.semanticscholar.org/paper/a9b97dd5fc8d79a9e18f283bf9a5644eaf6676ea\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1909.11786\",\"authors\":[{\"authorId\":\"48172949\",\"name\":\"N. Ahuja\"},{\"authorId\":\"3269525\",\"name\":\"I. Ndiour\"},{\"authorId\":\"1388721949\",\"name\":\"Trushant Kalyanpur\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c948ab13b9ecfa35374913710f849e806297e18\",\"title\":\"Probabilistic Modeling of Deep Features for Out-of-Distribution and Adversarial Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c948ab13b9ecfa35374913710f849e806297e18\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.00597\",\"authors\":[{\"authorId\":\"2007582232\",\"name\":\"Simon Ging\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80089ad641bae28b0e57771afef181b60011069e\",\"title\":\"COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/80089ad641bae28b0e57771afef181b60011069e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70147929\",\"name\":\"H. Yang\"},{\"authorId\":\"18997752\",\"name\":\"Jun Zhang\"},{\"authorId\":\"2721485\",\"name\":\"Shuohao Li\"},{\"authorId\":\"3249639\",\"name\":\"Tingjin Luo\"}],\"doi\":\"10.3233/JIFS-18209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"title\":\"Bi-direction hierarchical LSTM with spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1912.03647\",\"authors\":[{\"authorId\":\"1452735766\",\"name\":\"Dingheng Wang\"},{\"authorId\":\"8278873\",\"name\":\"Guang-She Zhao\"},{\"authorId\":\"47949360\",\"name\":\"Guoqi Li\"},{\"authorId\":\"143895325\",\"name\":\"L. Deng\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"}],\"doi\":\"10.1016/j.neunet.2020.07.028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64b889ae5e703e1a89590288b0292eec8e5b7f83\",\"title\":\"Lossless Compression for 3DCNNs Based on Tensor Train Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/64b889ae5e703e1a89590288b0292eec8e5b7f83\",\"venue\":\"Neural networks : the official journal of the International Neural Network Society\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993656259\",\"name\":\"Xutong Jin\"},{\"authorId\":\"66841398\",\"name\":\"S. Li\"},{\"authorId\":\"48821625\",\"name\":\"T. Qu\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"},{\"authorId\":\"50248637\",\"name\":\"Guoping Wang\"}],\"doi\":\"10.1145/3394171.3413572\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc316c6c3f2f55f03e486536a5850752df49bb84\",\"title\":\"Deep-Modal: Real-Time Impact Sound Synthesis for Arbitrary Shapes\",\"url\":\"https://www.semanticscholar.org/paper/dc316c6c3f2f55f03e486536a5850752df49bb84\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993657441\",\"name\":\"Beibei Lin\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"39677488\",\"name\":\"F. Bao\"}],\"doi\":\"10.1145/3394171.3413861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7d3b24dd73d35f358da1265709dbcab848593a5\",\"title\":\"Gait Recognition with Multiple-Temporal-Scale 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/a7d3b24dd73d35f358da1265709dbcab848593a5\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/978-3-030-49076-8_24\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c8c96c2395de045227e6c1165bd8f0886b08536\",\"title\":\"What the Appearance Channel from Two-Stream Architectures for Activity Recognition Is Learning?\",\"url\":\"https://www.semanticscholar.org/paper/5c8c96c2395de045227e6c1165bd8f0886b08536\",\"venue\":\"MCPR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51320503\",\"name\":\"Marios Krestenitis\"},{\"authorId\":\"3200630\",\"name\":\"N. Passalis\"},{\"authorId\":\"3074923\",\"name\":\"Alexandros Iosifidis\"},{\"authorId\":\"9219875\",\"name\":\"M. Gabbouj\"},{\"authorId\":\"1737071\",\"name\":\"A. Tefas\"}],\"doi\":\"10.1016/j.patcog.2020.107380\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf4fc35ab9e17fc2219687f9951cf441861e0c06\",\"title\":\"Recurrent bag-of-features for visual information analysis\",\"url\":\"https://www.semanticscholar.org/paper/bf4fc35ab9e17fc2219687f9951cf441861e0c06\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2008.04999\",\"authors\":[{\"authorId\":\"13930770\",\"name\":\"Faegheh Sardari\"},{\"authorId\":\"2657085\",\"name\":\"A. Paiement\"},{\"authorId\":\"1751117\",\"name\":\"S. Hannuna\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.3390/s20185258\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"title\":\"VI-Net\\u2014View-Invariant Quality of Human Movement Assessment\",\"url\":\"https://www.semanticscholar.org/paper/eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.04632\",\"authors\":[{\"authorId\":\"145439284\",\"name\":\"Wei Peng\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/ICIP.2019.8802919\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"title\":\"Video Action Recognition Via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1905.13607\",\"authors\":[{\"authorId\":\"119413444\",\"name\":\"G. Storey\"},{\"authorId\":\"144725605\",\"name\":\"R. Jiang\"},{\"authorId\":\"32676664\",\"name\":\"Shelagh Keogh\"},{\"authorId\":\"1690116\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/ACCESS.2019.2937285\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"title\":\"3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework Using Fully 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669427929\",\"name\":\"Lichao Yang\"},{\"authorId\":\"48365715\",\"name\":\"Ting-Yu Yang\"},{\"authorId\":null,\"name\":\"Haochen Liu\"},{\"authorId\":\"145409056\",\"name\":\"Xiaocai Shan\"},{\"authorId\":\"13275978\",\"name\":\"J. Brighton\"},{\"authorId\":\"2540001\",\"name\":\"L. Skrypchuk\"},{\"authorId\":\"78767836\",\"name\":\"Alexandros\"},{\"authorId\":\"2006650326\",\"name\":\"Mouzakitis\"},{\"authorId\":\"151469503\",\"name\":\"Yifan Zhao\"}],\"doi\":\"10.1109/jsen.2020.3005810\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b61bf86f7267f547896db1e3e42ba71e4796b919\",\"title\":\"A refined non-driving activity classification using a two-stream convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/b61bf86f7267f547896db1e3e42ba71e4796b919\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1016/j.csl.2020.101093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"title\":\"Transfer learning for multimodal dialog\",\"url\":\"https://www.semanticscholar.org/paper/9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":\"2008.08502\",\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"76e71fe84643b72ffb61afe54c9034be824604e3\",\"title\":\"Learning Trailer Moments in Full-Length Movies\",\"url\":\"https://www.semanticscholar.org/paper/76e71fe84643b72ffb61afe54c9034be824604e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50055874\",\"name\":\"Pablo Andres Millan Arias\"},{\"authorId\":\"23176854\",\"name\":\"Julian Armando Quiroga Sepulveda\"}],\"doi\":\"10.1109/AIKE.2018.00039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b49675484d598c57b1d9237538a0e7a7e3ed3b5\",\"title\":\"Deep Learned vs. Hand-Crafted Features for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/1b49675484d598c57b1d9237538a0e7a7e3ed3b5\",\"venue\":\"AIKE\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148336006\",\"name\":\"Weisong Che\"},{\"authorId\":\"9391708\",\"name\":\"Shuhua Peng\"}],\"doi\":\"10.1109/IAEAC47372.2019.8997745\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d67b6135393720b4629c0eca95a16bf67e3f0364\",\"title\":\"3D Dual Path Networks and Multi-scale Feature Fusion for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d67b6135393720b4629c0eca95a16bf67e3f0364\",\"venue\":\"2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10025937\",\"name\":\"Z. Xu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"46868155\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICMEW.2018.8551529\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"title\":\"S2L: Single-Streamline For Complex Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79755154\",\"name\":\"Hongje Seong\"},{\"authorId\":\"2246939\",\"name\":\"Junhyuk Hyun\"},{\"authorId\":\"70400973\",\"name\":\"Euntai Kim\"}],\"doi\":\"10.1109/ICCVW.2019.00194\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"title\":\"Video Multitask Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8cfb522acca27ee7b0cdd1e4a8f5af492ac5c87d\",\"title\":\"G3AN: This video does not exist. Disentangling motion and appearance for video generation\",\"url\":\"https://www.semanticscholar.org/paper/8cfb522acca27ee7b0cdd1e4a8f5af492ac5c87d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14547418\",\"name\":\"Shengwei Zhou\"},{\"authorId\":\"153555891\",\"name\":\"L. Bai\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"123580511\",\"name\":\"Zhi-Hong Deng\"},{\"authorId\":\"121330693\",\"name\":\"X. Zhu\"},{\"authorId\":\"143724074\",\"name\":\"C. Gong\"}],\"doi\":\"10.12783/dtcse/cisnrc2019/33302\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"title\":\"A Spatial-temporal Attention Module for 3D Convolution Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48321132\",\"name\":\"Y. Zou\"},{\"authorId\":\"9641665\",\"name\":\"X. Ren\"}],\"doi\":\"10.1007/978-981-15-8458-9_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"title\":\"An Efficient Action Recognition Framework Based on ELM and 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35548557\",\"name\":\"Konstantinos Gkountakos\"},{\"authorId\":\"2378908\",\"name\":\"K. Ioannidis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fa40ad7b87549ad2f2fa39b1d421a4ff50aaf99\",\"title\":\"ITI-CERTH participation in TRECVID 2018\",\"url\":\"https://www.semanticscholar.org/paper/2fa40ad7b87549ad2f2fa39b1d421a4ff50aaf99\",\"venue\":\"TRECVID\",\"year\":2017},{\"arxivId\":\"2010.15464\",\"authors\":[{\"authorId\":\"1720851638\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"title\":\"Self-Supervised Video Representation Using Pretext-Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09524\",\"authors\":[{\"authorId\":\"51218228\",\"name\":\"H. Saribas\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"152438412\",\"name\":\"Bedirhan Uzun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fa30736fb132c3a021b1e4227d212d4b8f6bc79\",\"title\":\"TRAT: Tracking by Attention Using Spatio-Temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/5fa30736fb132c3a021b1e4227d212d4b8f6bc79\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88762202\",\"name\":\"J. Li\"},{\"authorId\":\"1888867\",\"name\":\"X. Jiang\"},{\"authorId\":\"3307728\",\"name\":\"T. Sun\"},{\"authorId\":\"2876147\",\"name\":\"K. Xu\"}],\"doi\":\"10.1109/AVSS.2019.8909883\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8a029b5380133aa2aee82064182683e5db81eeeb\",\"title\":\"Efficient Violence Detection Using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8a029b5380133aa2aee82064182683e5db81eeeb\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"E. Morales\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/s10044-020-00924-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b3d22fad864939a5e630fda197e8584fef793e0\",\"title\":\"Second-order motion descriptors for efficient action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b3d22fad864939a5e630fda197e8584fef793e0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042569583\",\"name\":\"Kensho Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2042706087\",\"name\":\"Masaki Inaba\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"2042698122\",\"name\":\"Ryusuke Hotta\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ITSC45102.2020.9294443\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"title\":\"Predicting Vehicles Appearing from Blind Spots Based on Pedestrian Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115113072\",\"name\":\"S. Kondratiuk\"},{\"authorId\":\"9368047\",\"name\":\"I. Krak\"},{\"authorId\":\"1933321065\",\"name\":\"Anatolii Kylias\"},{\"authorId\":\"81418873\",\"name\":\"V. Kasianiuk\"}],\"doi\":\"10.1007/978-3-030-54215-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ded59719c96e05ffe1d39bb73d0ff73de74bb8fd\",\"title\":\"Fingerspelling Alphabet Recognition Using CNNs with 3D Convolutions for Cross Platform Applications\",\"url\":\"https://www.semanticscholar.org/paper/ded59719c96e05ffe1d39bb73d0ff73de74bb8fd\",\"venue\":\"ISDMCI\",\"year\":2020},{\"arxivId\":\"1811.08890\",\"authors\":[{\"authorId\":\"51261844\",\"name\":\"N. Holzenberger\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"}],\"doi\":\"10.1109/ICASSP.2019.8683540\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a01ae256dfe7bd10734fec8a66549fb7ea876a05\",\"title\":\"Learning from Multiview Correlations in Open-domain Videos\",\"url\":\"https://www.semanticscholar.org/paper/a01ae256dfe7bd10734fec8a66549fb7ea876a05\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1906.07052\",\"authors\":[{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"49543907\",\"name\":\"Xin-Xin Liu\"},{\"authorId\":\"49388002\",\"name\":\"Jianxin Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"title\":\"Towards Real-Time Action Recognition on Mobile Devices Using Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6624871\",\"name\":\"Dmytro Tkachenko\"}],\"doi\":\"10.1109/saic.2018.8516860\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355cea44e2d40409a7a5be72b12511e43d259cb9\",\"title\":\"Human Action Recognition Using Fusion of Modern Deep Convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/355cea44e2d40409a7a5be72b12511e43d259cb9\",\"venue\":\"2018 IEEE First International Conference on System Analysis & Intelligent Computing (SAIC)\",\"year\":2018},{\"arxivId\":\"1907.10837\",\"authors\":[{\"authorId\":\"2447769\",\"name\":\"Chunfei Ma\"},{\"authorId\":\"32407457\",\"name\":\"Joonhyang Choi\"},{\"authorId\":\"150936578\",\"name\":\"Byeongwon Lee\"},{\"authorId\":\"3246975\",\"name\":\"Seungji Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"title\":\"Submission to ActivityNet Challenge 2019: Task B Spatio-temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e089531c9e2ad7852b374e9f0e1a5a29c477f0b\",\"title\":\"Probing the Role of Video Context in Multimodal Machine Translation with Source Corruption\",\"url\":\"https://www.semanticscholar.org/paper/7e089531c9e2ad7852b374e9f0e1a5a29c477f0b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153920582\",\"name\":\"Luk\\u00e1s Neumann\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPRW.2019.00354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"title\":\"Future Event Prediction: If and When\",\"url\":\"https://www.semanticscholar.org/paper/4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1804.02555\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"5014206\",\"name\":\"T. Suzuki\"},{\"authorId\":\"6881850\",\"name\":\"S. Oikawa\"},{\"authorId\":\"1720770\",\"name\":\"Y. Matsui\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICRA.2018.8460812\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b13f8c8733503ddfee6a140e62b7e280d70f48d\",\"title\":\"Drive Video Analysis for the Detection of Traffic Near-Miss Incidents\",\"url\":\"https://www.semanticscholar.org/paper/8b13f8c8733503ddfee6a140e62b7e280d70f48d\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":\"2004.10299\",\"authors\":[{\"authorId\":\"35663637\",\"name\":\"R. Sanford\"},{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"2429097\",\"name\":\"Luiz G. Hafemann\"},{\"authorId\":\"2116752\",\"name\":\"B. Pourbabaee\"},{\"authorId\":\"145556010\",\"name\":\"M. Javan\"}],\"doi\":\"10.1109/CVPRW50498.2020.00457\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a8f1403dab1116dd841e42fc09212201512d177\",\"title\":\"Group Activity Detection from Trajectory and Video Data in Soccer\",\"url\":\"https://www.semanticscholar.org/paper/9a8f1403dab1116dd841e42fc09212201512d177\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1911.12509\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"title\":\"Action Recognition via Pose-Based Graph Convolutional Networks with Intermediate Dense Supervision\",\"url\":\"https://www.semanticscholar.org/paper/9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":\"2009.14661\",\"authors\":[{\"authorId\":\"1500399016\",\"name\":\"Tong Yu\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"title\":\"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.02172\",\"authors\":[{\"authorId\":\"51224607\",\"name\":\"Yi-Chieh Liu\"},{\"authorId\":\"15809720\",\"name\":\"Yung-An Hsieh\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"46962482\",\"name\":\"C. H. Yang\"},{\"authorId\":\"1687483\",\"name\":\"J. Tegn\\u00e9r\"},{\"authorId\":\"49291215\",\"name\":\"Y. Tsai\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053783\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7151072c07431b5e65aed6bd86e6894e43b1c7be\",\"title\":\"Interpretable Self-Attention Temporal Reasoning for Driving Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/7151072c07431b5e65aed6bd86e6894e43b1c7be\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1910.00932\",\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840270\",\"name\":\"S. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9739f39feacca0550eff8ac42a92445efdce31c8\",\"title\":\"Training Kinetics in 15 Minutes: Large-scale Distributed Training on Videos\",\"url\":\"https://www.semanticscholar.org/paper/9739f39feacca0550eff8ac42a92445efdce31c8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"51458977\",\"name\":\"J. Xu\"},{\"authorId\":\"1429834069\",\"name\":\"Canqian Yang\"},{\"authorId\":\"7314697\",\"name\":\"Guozheng Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1881b72a1d5abc9d016e88203e8bb04b831a4586\",\"title\":\"Reinventing 2D Convolutions for 3D Medical Images\",\"url\":\"https://www.semanticscholar.org/paper/1881b72a1d5abc9d016e88203e8bb04b831a4586\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92530521\",\"name\":\"O. Beaumont\"},{\"authorId\":\"1395576412\",\"name\":\"Lionel Eyraud-Dubois\"},{\"authorId\":\"80222318\",\"name\":\"A. Shilova\"}],\"doi\":\"10.1007/978-3-030-57675-2_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d491b204c0f7b9dadce9b6f29cb8e407dd107dff\",\"title\":\"Optimal GPU-CPU Offloading Strategies for Deep Neural Network Training\",\"url\":\"https://www.semanticscholar.org/paper/d491b204c0f7b9dadce9b6f29cb8e407dd107dff\",\"venue\":\"Euro-Par\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"},{\"authorId\":\"2817677\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"152299623\",\"name\":\"C. Yan\"},{\"authorId\":\"46518251\",\"name\":\"L. Yao\"}],\"doi\":\"10.1016/j.knosys.2020.106432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6072b5407daf1db4871fa27bdac7f63407019091\",\"title\":\"Memory transformation networks for weakly supervised visual classification\",\"url\":\"https://www.semanticscholar.org/paper/6072b5407daf1db4871fa27bdac7f63407019091\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.02531\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3394171.3413694\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"title\":\"Self-supervised Video Representation Learning Using Inter-intra Contrastive Framework\",\"url\":\"https://www.semanticscholar.org/paper/de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50504570\",\"name\":\"Weiwen Chen\"},{\"authorId\":null,\"name\":\"Yaohua Wang\"},{\"authorId\":\"143702938\",\"name\":\"C. Yang\"},{\"authorId\":\"98177810\",\"name\":\"Y. Li\"}],\"doi\":\"10.1109/ICRAS49812.2020.9135062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c3253800e8b1d00d0a7b877ee7feb0822ec57bd\",\"title\":\"Hardware Acceleration Implementation of Three-Dimensional Convolutional Neural Network on Vector Digital Signal Processors\",\"url\":\"https://www.semanticscholar.org/paper/0c3253800e8b1d00d0a7b877ee7feb0822ec57bd\",\"venue\":\"2020 4th International Conference on Robotics and Automation Sciences (ICRAS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e77a31a2ddadb878764bbe5bc860d6b24cdaf9f8\",\"title\":\"ResNeXt action prediction Vocabulary Bidirectional RNN Text Encoder ResNeXt action prediction Multimodal Decoder Vocabulary Decoder\",\"url\":\"https://www.semanticscholar.org/paper/e77a31a2ddadb878764bbe5bc860d6b24cdaf9f8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147627782\",\"name\":\"Marc Roig Vilamala\"},{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"1721540\",\"name\":\"F. Cerutti\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a21755ee535c52a1759149c7159987e9d2ba939\",\"title\":\"A Pilot Study on Detecting Violence in Videos Fusing Proxy Models\",\"url\":\"https://www.semanticscholar.org/paper/2a21755ee535c52a1759149c7159987e9d2ba939\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1874862797\",\"name\":\"Boge Wen\"},{\"authorId\":\"122665402\",\"name\":\"Siyuan Chen\"},{\"authorId\":\"3090858\",\"name\":\"Chenhui Shao\"}],\"doi\":\"10.1016/j.compind.2020.103255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"title\":\"Temporal action proposal for online driver action monitoring using Dilated Convolutional Temporal Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"venue\":\"Comput. Ind.\",\"year\":2020},{\"arxivId\":\"1809.00241\",\"authors\":[{\"authorId\":\"47287745\",\"name\":\"Ankit Shah\"},{\"authorId\":\"51434736\",\"name\":\"Harini Kesavamoorthy\"},{\"authorId\":\"51441023\",\"name\":\"Poorva Rane\"},{\"authorId\":\"1989712\",\"name\":\"Pramati Kalwad\"},{\"authorId\":\"7661726\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"1740721\",\"name\":\"Florian Metze\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"72f4c415b5f3ecf63380b6985c95c5af2ba72632\",\"title\":\"Activity Recognition on a Large Scale in Short Videos - Moments in Time Dataset\",\"url\":\"https://www.semanticscholar.org/paper/72f4c415b5f3ecf63380b6985c95c5af2ba72632\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"title\":\"Self-supervised Spatiotemporal Feature Learning by Video Geometric Transformations\",\"url\":\"https://www.semanticscholar.org/paper/3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390937493\",\"name\":\"Alaaeldin Ali\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"title\":\"Spatiotemporal Representation Learning For Human Action Recognition And Localization\",\"url\":\"https://www.semanticscholar.org/paper/54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00807\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"title\":\"MARS: Motion-Augmented RGB Stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.00625\",\"authors\":[{\"authorId\":\"48847709\",\"name\":\"S. Chen\"},{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"35086032\",\"name\":\"Y. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5bcda431e0b615e094562bf038f1ef4df1865088\",\"title\":\"Med3D: Transfer Learning for 3D Medical Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5bcda431e0b615e094562bf038f1ef4df1865088\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b02dba59a087f16d8286aec5e6481d5952a37df5\",\"title\":\"CMU Sinbad\\u2019s Submission for the DSTC7 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b02dba59a087f16d8286aec5e6481d5952a37df5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.11623\",\"authors\":[{\"authorId\":\"10792639\",\"name\":\"Maarten Vandersteegen\"},{\"authorId\":\"1656709277\",\"name\":\"Wouter Reusen\"},{\"authorId\":\"2321568\",\"name\":\"Kristof Van Beeck\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1109/CVPRW50498.2020.00057\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"db922731bf1469a525f72bbc71eb229a853b0c93\",\"title\":\"Low-latency hand gesture recognition with a low resolution thermal imager\",\"url\":\"https://www.semanticscholar.org/paper/db922731bf1469a525f72bbc71eb229a853b0c93\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"82619398\",\"name\":\"P. D'Oro\"},{\"authorId\":\"1390194542\",\"name\":\"D. Giordano\"},{\"authorId\":\"147598837\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s11263-019-01246-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d50b45969bef86bf29bcaf9052beade2282fa094\",\"title\":\"Adversarial Framework for Unsupervised Learning of Motion Dynamics in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d50b45969bef86bf29bcaf9052beade2282fa094\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40214720\",\"name\":\"L. Long\"},{\"authorId\":\"5278544\",\"name\":\"Z. V. Johnson\"},{\"authorId\":\"1600243424\",\"name\":\"Junyu Li\"},{\"authorId\":\"1600853953\",\"name\":\"Tucker J Lancaster\"},{\"authorId\":\"1601570335\",\"name\":\"Vineeth Aljapur\"},{\"authorId\":\"145914793\",\"name\":\"J. T. Streelman\"},{\"authorId\":\"4984693\",\"name\":\"P. T. McGrath\"}],\"doi\":\"10.1016/j.isci.2020.101591\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2da83837d144ff1060c2e7bf030496284d874ddc\",\"title\":\"Automatic Classification of Cichlid Behaviors Using 3D Convolutional Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/2da83837d144ff1060c2e7bf030496284d874ddc\",\"venue\":\"iScience\",\"year\":2020},{\"arxivId\":\"2003.00832\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"50031872\",\"name\":\"Yunsheng Ma\"},{\"authorId\":\"37989322\",\"name\":\"Y. Gu\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"151185822\",\"name\":\"Runbo Hu\"},{\"authorId\":\"144626314\",\"name\":\"Hua Chai\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1609/AAAI.V34I01.5364\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"title\":\"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.09087\",\"authors\":[{\"authorId\":\"50619476\",\"name\":\"Minjee Kim\"},{\"authorId\":\"7629657\",\"name\":\"Joonmyeong Choi\"},{\"authorId\":\"145979407\",\"name\":\"N. Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b324999ef8d4ff5977ae02f145b7257b1638071a\",\"title\":\"Fully Automated Hand Hygiene Monitoring\\\\\\\\in Operating Room using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b324999ef8d4ff5977ae02f145b7257b1638071a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1145/3240508.3240675\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f888a870545af2735118bbd6358ffa68f1e386f\",\"title\":\"A Large-scale RGB-D Database for Arbitrary-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f888a870545af2735118bbd6358ffa68f1e386f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66425285\",\"name\":\"Akash Panchal\"},{\"authorId\":\"48756948\",\"name\":\"H. Trivedi\"},{\"authorId\":\"101106680\",\"name\":\"M. Rajput\"},{\"authorId\":\"144027193\",\"name\":\"D. Trivedi\"}],\"doi\":\"10.1007/978-981-15-3369-3_65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3eb1ee19f1312c0a7e4cf8459ff260039968342\",\"title\":\"Activity Recognition Using Temporal Features and Deep Bottleneck 3D-ResNeXt\",\"url\":\"https://www.semanticscholar.org/paper/a3eb1ee19f1312c0a7e4cf8459ff260039968342\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.04599\",\"authors\":[{\"authorId\":\"39619930\",\"name\":\"M. Zajac\"},{\"authorId\":\"7912420\",\"name\":\"Konrad Zolna\"},{\"authorId\":\"2599281\",\"name\":\"N. Rostamzadeh\"},{\"authorId\":\"2708655\",\"name\":\"Pedro H. O. Pinheiro\"}],\"doi\":\"10.1609/aaai.v33i01.330110077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9b2972e261f279b2d770d3236ae0a32970d6cc2\",\"title\":\"Adversarial Framing for Image and Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9b2972e261f279b2d770d3236ae0a32970d6cc2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2006.15731\",\"authors\":[{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"33615817\",\"name\":\"M. Hebert\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"99b33c3b1a38aa4c2569abb98ca21759951849d5\",\"title\":\"Unsupervised Learning of Video Representations via Dense Trajectory Clustering\",\"url\":\"https://www.semanticscholar.org/paper/99b33c3b1a38aa4c2569abb98ca21759951849d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.09163\",\"authors\":[{\"authorId\":\"103483742\",\"name\":\"Yuang Liu\"},{\"authorId\":\"144333217\",\"name\":\"W. Zhang\"},{\"authorId\":\"71563028\",\"name\":\"Jijie Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c599bb8e3b98eec9e4d90f3ade68932afe11aa35\",\"title\":\"Learning from a Lightweight Teacher for Efficient Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/c599bb8e3b98eec9e4d90f3ade68932afe11aa35\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03186\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"title\":\"Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.01665\",\"authors\":[{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"3456894\",\"name\":\"J. Ive\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d29d6a96af4843aeaef71f717a98e66014656624\",\"title\":\"Predicting Actions to Help Predict Translations\",\"url\":\"https://www.semanticscholar.org/paper/d29d6a96af4843aeaef71f717a98e66014656624\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICPR.2018.8546325\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d45f7abeca184533ee0f0670c4946bcd34edda81\",\"title\":\"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/d45f7abeca184533ee0f0670c4946bcd34edda81\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1911.10477\",\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"2007540200\",\"name\":\"Yi He\"},{\"authorId\":\"51458977\",\"name\":\"J. Xu\"},{\"authorId\":\"1429834069\",\"name\":\"Canqian Yang\"},{\"authorId\":\"7314697\",\"name\":\"Guozheng Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7384a5a54c6bc376e4bde319e5a3fe3e935407b2\",\"title\":\"Reinventing 2D Convolutions for 3D Images\",\"url\":\"https://www.semanticscholar.org/paper/7384a5a54c6bc376e4bde319e5a3fe3e935407b2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651582\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1916963\",\"name\":\"Y. Shen\"},{\"authorId\":\"89080361\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ICMEW.2019.00034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"title\":\"Deep Key Clips-Video Feature Fusion Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1903.09616\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"title\":\"On the Importance of Video Action Recognition for Visual Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48375740\",\"name\":\"Junyong You\"},{\"authorId\":\"1719045\",\"name\":\"Jari Korhonen\"}],\"doi\":\"10.1109/ICIP.2019.8803395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae684616c88d4af719d77cad77df314b0cac97e5\",\"title\":\"Deep Neural Networks for No-Reference Video Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/ae684616c88d4af719d77cad77df314b0cac97e5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1804.06057\",\"authors\":[{\"authorId\":\"3401864\",\"name\":\"Ryota Hinami\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"81f63e7344cc242416e37d791f7eb83ec2c07681\",\"title\":\"Multimodal Co-Training for Selecting Good Examples from Webly Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/81f63e7344cc242416e37d791f7eb83ec2c07681\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"36251013\",\"name\":\"Wei Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"48480250\",\"name\":\"Jianhui Sun\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"}],\"doi\":\"10.1109/ICME.2019.00272\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ab93deeb3894ceb65d8837764e54110f22c5b7d\",\"title\":\"Refining Proposals with Neighboring Contexts for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/3ab93deeb3894ceb65d8837764e54110f22c5b7d\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1905.10693\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"title\":\"DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.10695\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f771b7514664d2b5e4f7dc12400897db95b0e136\",\"title\":\"Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/f771b7514664d2b5e4f7dc12400897db95b0e136\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7868673\",\"name\":\"Yi-Kun Tang\"},{\"authorId\":\"4590286\",\"name\":\"Heyan Huang\"},{\"authorId\":\"71764998\",\"name\":\"Xuewen Shi\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"}],\"doi\":\"10.1007/978-3-030-34223-4_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce818ac56b8fd52165f00e9251efcf078d0fe39f\",\"title\":\"Picture News Collection: A Dataset for Automatic Picture News Thumbnail Selection\",\"url\":\"https://www.semanticscholar.org/paper/ce818ac56b8fd52165f00e9251efcf078d0fe39f\",\"venue\":\"WISE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2006.03876\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e30fd64c9659c8cc6b28d37d19395752aae89130\",\"title\":\"ARID: A New Dataset for Recognizing Action in the Dark\",\"url\":\"https://www.semanticscholar.org/paper/e30fd64c9659c8cc6b28d37d19395752aae89130\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.12018\",\"authors\":[{\"authorId\":\"98831710\",\"name\":\"B. Yang\"},{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9191773630826b15a86148453365aae7703aec6b\",\"title\":\"Non-Autoregressive Coarse-to-Fine Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9191773630826b15a86148453365aae7703aec6b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2912976\",\"name\":\"W. N. Khotimah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2795743\",\"name\":\"Farid Boussa\\u00efd\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"152660969\",\"name\":\"D. Edwards\"}],\"doi\":\"10.3390/rs12193137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10f9ac6408659b9ecee1df601f4567bce5995e26\",\"title\":\"A High-Performance Spectral-Spatial Residual Network for Hyperspectral Image Classification with Small Training Data\",\"url\":\"https://www.semanticscholar.org/paper/10f9ac6408659b9ecee1df601f4567bce5995e26\",\"venue\":\"Remote. Sens.\",\"year\":2020},{\"arxivId\":\"1807.07203\",\"authors\":[{\"authorId\":\"1718406\",\"name\":\"N. Inoue\"},{\"authorId\":\"1704408\",\"name\":\"Koichi Shinoda\"}],\"doi\":\"10.1145/3240508.3240592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb285efdb73d57ab425fbbffc4327c4f1f441c85\",\"title\":\"Few-Shot Adaptation for Multimedia Semantic Indexing\",\"url\":\"https://www.semanticscholar.org/paper/eb285efdb73d57ab425fbbffc4327c4f1f441c85\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"27ff341652fff45d545f68c6e00b0b07627dccc1\",\"title\":\"Training Kinetics in 15 Minutes: Large-scale Distributed Training on Videos\",\"url\":\"https://www.semanticscholar.org/paper/27ff341652fff45d545f68c6e00b0b07627dccc1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.03457\",\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"3086596\",\"name\":\"Byeongho Heo\"},{\"authorId\":\"2086576\",\"name\":\"Dongyoon Han\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"title\":\"VideoMix: Rethinking Data Augmentation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152991070\",\"name\":\"Yanyan Song\"},{\"authorId\":\"144539547\",\"name\":\"L. Tan\"},{\"authorId\":\"1691036\",\"name\":\"L. Zhou\"},{\"authorId\":\"153010694\",\"name\":\"Xinyue Lv\"},{\"authorId\":\"1481816621\",\"name\":\"Zihao Ma\"}],\"doi\":\"10.1007/978-3-030-57881-7_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13095711fbcd69d1a9897392b465ab2a25eab81d\",\"title\":\"Video Action Recognition Based on Hybrid Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/13095711fbcd69d1a9897392b465ab2a25eab81d\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":\"1904.03249\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"40897068\",\"name\":\"Xin Chen\"},{\"authorId\":\"23614019\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"76db87564c7e6a6f417fca41b9f659a879de5027\",\"title\":\"Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/76db87564c7e6a6f417fca41b9f659a879de5027\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6dd3595637c470f7f008b80a4db131da929e35e\",\"title\":\"We don't Need Thousand Proposals: Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f6dd3595637c470f7f008b80a4db131da929e35e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.00179\",\"authors\":[{\"authorId\":\"1708502\",\"name\":\"R. Tolosana\"},{\"authorId\":\"1402712530\",\"name\":\"R. Vera-Rodr\\u00edguez\"},{\"authorId\":\"1701431\",\"name\":\"Julian Fierrez\"},{\"authorId\":\"144083995\",\"name\":\"A. Morales\"},{\"authorId\":\"1397258551\",\"name\":\"J. Ortega-Garcia\"}],\"doi\":\"10.1016/j.inffus.2020.06.014\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96bcd003424aa4b2f9d6e8ade013a3a4293fecf5\",\"title\":\"DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection\",\"url\":\"https://www.semanticscholar.org/paper/96bcd003424aa4b2f9d6e8ade013a3a4293fecf5\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738178502\",\"name\":\"Matheus Gutoski\"},{\"authorId\":\"3225435\",\"name\":\"A. E. Lazzaretti\"},{\"authorId\":\"1806302\",\"name\":\"H. Lopes\"}],\"doi\":\"10.1007/s00521-020-05009-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f449b6f662a729b045b7bed80254b5bd30505d1\",\"title\":\"Deep metric learning for open-set human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/1f449b6f662a729b045b7bed80254b5bd30505d1\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":\"2008.10850\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58607-2_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"title\":\"Discriminability Distillation in Group Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"122200401\",\"name\":\"Shan-shan Zhang\"},{\"authorId\":\"152721770\",\"name\":\"Liang Xiao\"},{\"authorId\":\"51460259\",\"name\":\"Jian Yang\"}],\"doi\":\"10.1007/978-3-030-36189-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75adc8c65f82dfdb3c843972833a89e86f7f4bee\",\"title\":\"Intelligence Science and Big Data Engineering. Visual Data Engineering: 9th International Conference, IScIDE 2019, Nanjing, China, October 17\\u201320, 2019, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/75adc8c65f82dfdb3c843972833a89e86f7f4bee\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":\"2005.02134\",\"authors\":[{\"authorId\":\"1405030052\",\"name\":\"Gibran Benitez-Garcia\"},{\"authorId\":\"1398632145\",\"name\":\"J. Olivares-Mercado\"},{\"authorId\":\"1398632169\",\"name\":\"G. Sanchez-Perez\"},{\"authorId\":\"1681659\",\"name\":\"K. Yanai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fdb6a34f12ca6a16c4932001c2866ea68ccb2a3\",\"title\":\"IPN Hand: A Video Dataset and Benchmark for Real-Time Continuous Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2fdb6a34f12ca6a16c4932001c2866ea68ccb2a3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49868702\",\"name\":\"Ran Wei\"},{\"authorId\":\"144065286\",\"name\":\"Li Mi\"},{\"authorId\":\"7741774\",\"name\":\"Y. Hu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.jvcir.2020.102751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b43ca6f4615d5e384a9b404964a49ed21a14805\",\"title\":\"Exploiting the local temporal information for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4b43ca6f4615d5e384a9b404964a49ed21a14805\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2003.14285\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"1762890\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144387904\",\"name\":\"S. Chakraborty\"},{\"authorId\":\"1804334\",\"name\":\"Prudhvi Gurram\"},{\"authorId\":\"151479420\",\"name\":\"Richard Tomsett\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab170d55c661bf7cf5868ca82b67a3d6fed758d2\",\"title\":\"Explaining Motion Relevance for Activity Recognition in Video Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/ab170d55c661bf7cf5868ca82b67a3d6fed758d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.09383\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"48607331\",\"name\":\"Yu Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"title\":\"Baidu-UTS Submission to the EPIC-Kitchens Action Recognition Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"68881e3828f18c304189755c5a64979752d4a3eb\",\"title\":\"LP-3 DCNN : Unveiling Local Phase in 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68881e3828f18c304189755c5a64979752d4a3eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2019.00429\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"714df3e97817ec56b8dbc7217155adadf2a0487f\",\"title\":\"Iterative Alignment Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/714df3e97817ec56b8dbc7217155adadf2a0487f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05410\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdff096ae7f7f72a435481e27623ad1a6276900b\",\"title\":\"Attentive Action and Context Factorization\",\"url\":\"https://www.semanticscholar.org/paper/fdff096ae7f7f72a435481e27623ad1a6276900b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.12770\",\"authors\":[{\"authorId\":\"1388811741\",\"name\":\"Alaaeldin El-Nouby\"},{\"authorId\":\"2443456\",\"name\":\"Shuangfei Zhai\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"49158771\",\"name\":\"J. Susskind\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6ab402a45266620d4c41218242be5d5ddf1f63ca\",\"title\":\"Skip-Clip: Self-Supervised Spatiotemporal Representation Learning by Future Clip Order Ranking\",\"url\":\"https://www.semanticscholar.org/paper/6ab402a45266620d4c41218242be5d5ddf1f63ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144044733\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"15179633\",\"name\":\"F. Shen\"}],\"doi\":\"10.1109/TNNLS.2019.2933554\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"355b4e74774798c177c82943eef925d66a2bb2ce\",\"title\":\"A Deep One-Class Neural Network for Anomalous Event Detection in Complex Scenes\",\"url\":\"https://www.semanticscholar.org/paper/355b4e74774798c177c82943eef925d66a2bb2ce\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144059150\",\"name\":\"H. Itoh\"},{\"authorId\":\"48700146\",\"name\":\"Holger R Roth\"},{\"authorId\":\"2764676\",\"name\":\"Masahiro Oda\"},{\"authorId\":\"3656984\",\"name\":\"M. Misawa\"},{\"authorId\":\"48833252\",\"name\":\"Y. Mori\"},{\"authorId\":\"153562544\",\"name\":\"S. Kudo\"},{\"authorId\":\"1390079492\",\"name\":\"Kensaku Mori\"}],\"doi\":\"10.1049/htl.2019.0079\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94e62c2728adbb235b0998c6feae6ca0345ebcc7\",\"title\":\"Stable polyp-scene classification via subsampling and residual learning from an imbalanced large dataset\",\"url\":\"https://www.semanticscholar.org/paper/94e62c2728adbb235b0998c6feae6ca0345ebcc7\",\"venue\":\"Healthcare technology letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681325\",\"name\":\"Yifan Zhao\"},{\"authorId\":\"26329506\",\"name\":\"Jingchun Cheng\"},{\"authorId\":\"119796890\",\"name\":\"W. Zhou\"},{\"authorId\":\"47423664\",\"name\":\"C. Zhang\"},{\"authorId\":\"134880988\",\"name\":\"Xiong Pan\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a382a97e4cf243f02a5a3ef648bc86f66d6bc1e8\",\"title\":\"Infrared Pedestrian Detection with Converted Temperature Map\",\"url\":\"https://www.semanticscholar.org/paper/a382a97e4cf243f02a5a3ef648bc86f66d6bc1e8\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66185025\",\"name\":\"Hyun-woo Kim\"},{\"authorId\":\"10263579\",\"name\":\"Seokmok Park\"},{\"authorId\":\"9238090\",\"name\":\"J. Paik\"}],\"doi\":\"10.1109/ICCE46568.2020.9043125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b33e3ea9a39e06223c5e92d77e2490864b862d2d\",\"title\":\"Pre-Activated 3D CNN and Feature Pyramid Network for Traffic Accident Detection\",\"url\":\"https://www.semanticscholar.org/paper/b33e3ea9a39e06223c5e92d77e2490864b862d2d\",\"venue\":\"2020 IEEE International Conference on Consumer Electronics (ICCE)\",\"year\":2020},{\"arxivId\":\"1909.03309\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1007/978-981-15-8697-2_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"title\":\"Exploring Temporal Differences in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804033\",\"name\":\"K. Ueki\"},{\"authorId\":\"34711903\",\"name\":\"Y. Nakagome\"},{\"authorId\":\"14410793\",\"name\":\"Koji Hirakawa\"},{\"authorId\":\"144177702\",\"name\":\"K. Kikuchi\"},{\"authorId\":\"32639661\",\"name\":\"Yoshihiko Hayashi\"},{\"authorId\":\"3279652\",\"name\":\"T. Ogawa\"},{\"authorId\":\"1709528\",\"name\":\"T. Kobayashi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fdd5f7170128769904cf49d7f0f7836f5005629\",\"title\":\"Waseda_Meisei at TRECVID 2018: Ad-hoc Video Search\",\"url\":\"https://www.semanticscholar.org/paper/0fdd5f7170128769904cf49d7f0f7836f5005629\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58523-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b26d5d20b073828898087f99b81736c0629c1798\",\"title\":\"Learning Trailer Moments in Full-Length Movies with Co-Contrastive Attention\",\"url\":\"https://www.semanticscholar.org/paper/b26d5d20b073828898087f99b81736c0629c1798\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.10834\",\"authors\":[{\"authorId\":\"1944615571\",\"name\":\"A. Almeida\"},{\"authorId\":\"145334240\",\"name\":\"J. P. D. Villiers\"},{\"authorId\":\"145515736\",\"name\":\"A. D. Freitas\"},{\"authorId\":\"1944660087\",\"name\":\"M. Velayudan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1d17ac263557f5306e620b431354cc84df14be0\",\"title\":\"Exploring the multimodal information from video content using deep learning features of appearance, audio and action for video recommendation\",\"url\":\"https://www.semanticscholar.org/paper/c1d17ac263557f5306e620b431354cc84df14be0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05769\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01637f04eac8523b6c4887d419bd718f65860982\",\"title\":\"Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/01637f04eac8523b6c4887d419bd718f65860982\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.12334\",\"authors\":[{\"authorId\":\"152998393\",\"name\":\"Yunqiang Li\"},{\"authorId\":\"21225169\",\"name\":\"J. V. Gemert\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f33710063f1cdf74abe298245e4cd3834800c9\",\"title\":\"Deep Unsupervised Image Hashing by Maximizing Bit Entropy\",\"url\":\"https://www.semanticscholar.org/paper/48f33710063f1cdf74abe298245e4cd3834800c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca2c5474491f0a7117e7ca05fc2bdf49deff4b68\",\"title\":\"Symbiotic Attention: UTS-Baidu Submission to the EPIC-Kitchens 2020 Action Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/ca2c5474491f0a7117e7ca05fc2bdf49deff4b68\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47e1b171fab52368f14f41955cdc7ca7775ded58\",\"title\":\"RGB TVL 1 Flow RGB + TVL 1 FlowMARS MARS + RGB MERS MERS + RGB Accuracy vs Time on MiniKinetics\",\"url\":\"https://www.semanticscholar.org/paper/47e1b171fab52368f14f41955cdc7ca7775ded58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27720832\",\"name\":\"T. Long\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00122\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"title\":\"Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"145395437\",\"name\":\"F. Doctor\"},{\"authorId\":\"2031669\",\"name\":\"A. Herrera\"},{\"authorId\":\"1959195375\",\"name\":\"Sohail Sahab\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a50e6b64d5351cd3d4780c232fc3f7512a72aec4\",\"title\":\"Multimodal Deep Features Fusion for Video Memorability Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a50e6b64d5351cd3d4780c232fc3f7512a72aec4\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49577833\",\"name\":\"Daniel Y. Fu\"},{\"authorId\":\"41156945\",\"name\":\"W. Crichton\"},{\"authorId\":\"1692370\",\"name\":\"J. Hong\"},{\"authorId\":\"8073409\",\"name\":\"Xin-Wei Yao\"},{\"authorId\":\"9184695\",\"name\":\"Haotian Zhang\"},{\"authorId\":\"4543607\",\"name\":\"Anh Truong\"},{\"authorId\":null,\"name\":\"Avanika\"},{\"authorId\":\"90731789\",\"name\":\"Narayan\"},{\"authorId\":\"1820412\",\"name\":\"M. Agrawala\"},{\"authorId\":\"1803218\",\"name\":\"Christopher R\\u00e9\"},{\"authorId\":\"2789576\",\"name\":\"K. Fatahalian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c02fbd897258cdc75b007a7d161c43a7d42e28e4\",\"title\":\"Video Event Speciication using Programmatic Composition\",\"url\":\"https://www.semanticscholar.org/paper/c02fbd897258cdc75b007a7d161c43a7d42e28e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906550\",\"name\":\"Yanfeng Gu\"},{\"authorId\":\"102736009\",\"name\":\"H. Liu\"},{\"authorId\":\"1563987327\",\"name\":\"Tengfei Wang\"},{\"authorId\":\"2973521\",\"name\":\"Shengyang Li\"},{\"authorId\":\"1910913\",\"name\":\"Guoming Gao\"}],\"doi\":\"10.1007/s11432-019-2784-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f0f9790533d0585a60d1cf53b03985357371a11\",\"title\":\"Deep feature extraction and motion representation for satellite video scene classification\",\"url\":\"https://www.semanticscholar.org/paper/0f0f9790533d0585a60d1cf53b03985357371a11\",\"venue\":\"Science China Information Sciences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1109/ICSP.2018.8652359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"494f3f390442c622fd47d3c75316c3f9737bfa97\",\"title\":\"Temporal Pyramid Pooling Based Relation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/494f3f390442c622fd47d3c75316c3f9737bfa97\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557485864\",\"name\":\"Martin de la Riva\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1109/ICCVW.2019.00169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b1de275b44a65c04a67c78a2251887a461a7e42\",\"title\":\"Bayesian 3D ConvNets for Action Recognition from Few Examples\",\"url\":\"https://www.semanticscholar.org/paper/8b1de275b44a65c04a67c78a2251887a461a7e42\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":\"10.1109/ICCVW.2019.00102\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f21daf4c6ad986905e4bdf4b6a9652d671c8bac\",\"title\":\"Efficient Priors for Scalable Variational Inference in Bayesian Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0f21daf4c6ad986905e4bdf4b6a9652d671c8bac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1516118831\",\"name\":\"Kaito Hirasawa\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ICIP40778.2020.9191070\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17fe0a86f0c7d8ae2632d774d22dee6f38114100\",\"title\":\"Important Scene Detection Of Baseball Videos Via Time-Lag Aware Deep Multiset Canonical Correlation Maximization\",\"url\":\"https://www.semanticscholar.org/paper/17fe0a86f0c7d8ae2632d774d22dee6f38114100\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034347747\",\"name\":\"Chang Liu\"},{\"authorId\":\"153690115\",\"name\":\"Yulin Yang\"},{\"authorId\":\"2034348002\",\"name\":\"Xingyan Liu\"},{\"authorId\":\"51310276\",\"name\":\"Linpu Fang\"},{\"authorId\":\"40497356\",\"name\":\"Wenxiong Kang\"}],\"doi\":\"10.1109/TIFS.2020.3036218\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a93f6df11436e0f5df09d79c814930430104b75\",\"title\":\"Dynamic-Hand-Gesture Authentication Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4a93f6df11436e0f5df09d79c814930430104b75\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33185308\",\"name\":\"Hong-Cheu Liu\"},{\"authorId\":\"50082191\",\"name\":\"L. Zhang\"},{\"authorId\":\"1657251288\",\"name\":\"Lisi Guan\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053939\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6aa2347064fb6e88d3c233d96c58e07ab7af177c\",\"title\":\"GFNet: A Lightweight Group Frame Network for Efficient Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6aa2347064fb6e88d3c233d96c58e07ab7af177c\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9947219\",\"name\":\"Simion-Vlad Bogolin\"},{\"authorId\":\"50272388\",\"name\":\"Ioana Croitoru\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9348890ecbbfd7bb75667fa2014ebe6f4a5558b1\",\"title\":\"A hierarchical approach to vision-based language generation: from simple sentences to complex natural language\",\"url\":\"https://www.semanticscholar.org/paper/9348890ecbbfd7bb75667fa2014ebe6f4a5558b1\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2011.10927\",\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"title\":\"We don't Need Thousand Proposals$\\\\colon$ Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.03439\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"31669239\",\"name\":\"Y. Li\"},{\"authorId\":\"5541349\",\"name\":\"Y. Jiang\"},{\"authorId\":\"40486942\",\"name\":\"P. Wang\"},{\"authorId\":\"46417172\",\"name\":\"Q. Shen\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.1109/TGRS.2019.2902568\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c2416c4b8e46ef14e17b3293ba98ac8a9a9294e\",\"title\":\"Hyperspectral Classification Based on Lightweight 3-D-CNN With Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/4c2416c4b8e46ef14e17b3293ba98ac8a9a9294e\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"34608228\",\"name\":\"Xu-dong Jiang\"},{\"authorId\":\"3108302\",\"name\":\"Wei-Long Zheng\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/TCSVT.2020.2976789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"title\":\"Early Action Recognition With Category Exclusion Using Policy-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1804.09235\",\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"143673251\",\"name\":\"D. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"title\":\"ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.10056\",\"authors\":[{\"authorId\":\"1750502\",\"name\":\"X. Huang\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"}],\"doi\":\"10.1109/ICIP40778.2020.9190781\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"title\":\"Predictive Coding Networks Meet Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2621181\",\"name\":\"Haoye Dong\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"152365288\",\"name\":\"B. Wu\"},{\"authorId\":\"8567485\",\"name\":\"Bing-cheng Chen\"},{\"authorId\":\"144926874\",\"name\":\"J. Yin\"}],\"doi\":\"10.1109/ICCV.2019.00125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69a1e9a45eff33105a5f236e36876c917b278a0e\",\"title\":\"FW-GAN: Flow-Navigated Warping GAN for Video Virtual Try-On\",\"url\":\"https://www.semanticscholar.org/paper/69a1e9a45eff33105a5f236e36876c917b278a0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.11953\",\"authors\":[{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"8280915\",\"name\":\"Yunpeng Song\"},{\"authorId\":\"27899522\",\"name\":\"J. Zhang\"},{\"authorId\":\"1783892\",\"name\":\"J. Han\"},{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"61367718a07bafbd696871be25e11815f1dd85c4\",\"title\":\"Temporal Unet: Sample Level Human Action Recognition using WiFi\",\"url\":\"https://www.semanticscholar.org/paper/61367718a07bafbd696871be25e11815f1dd85c4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.10730\",\"authors\":[{\"authorId\":\"5641221\",\"name\":\"S. Jenni\"},{\"authorId\":\"41016678\",\"name\":\"Givi Meishvili\"},{\"authorId\":\"144707901\",\"name\":\"P. Favaro\"}],\"doi\":\"10.1007/978-3-030-58604-1_26\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"title\":\"Video Representation Learning by Recognizing Temporal Transformations\",\"url\":\"https://www.semanticscholar.org/paper/7657ceea5001eb500b4aa2f5e0a440828cde4764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.03754\",\"authors\":[{\"authorId\":\"27066021\",\"name\":\"Huanqian Yan\"},{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"46708584\",\"name\":\"B. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af1400f1cfbca05fe4b30c972e793bdd36da955b\",\"title\":\"Sparse Black-box Video Attack with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/af1400f1cfbca05fe4b30c972e793bdd36da955b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2004.02205\",\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e908719ae2a09e3726300df65bcd31dfddea5a86\",\"title\":\"Deep Multimodal Feature Encoding for Video Ordering\",\"url\":\"https://www.semanticscholar.org/paper/e908719ae2a09e3726300df65bcd31dfddea5a86\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b71d3f30238cb6621021a95543cce3aab96a21b\",\"title\":\"Fine-grained Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1b71d3f30238cb6621021a95543cce3aab96a21b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50141950\",\"name\":\"Xionghui Wang\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00367\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"48c601d0029c25ba02480c473d1bd31960acb2e2\",\"title\":\"Progressive Teacher-Student Learning for Early Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/48c601d0029c25ba02480c473d1bd31960acb2e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.02851\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"39fc7acf294739c27078c337706376a1c03dfa06\",\"title\":\"Recognizing American Sign Language Manual Signs from RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/39fc7acf294739c27078c337706376a1c03dfa06\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"Omesh Tickoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9c5781cef6611294d1746bcfca9c0e48b285edc\",\"title\":\"MOPED: Efficient priors for scalable variational inference in Bayesian deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/f9c5781cef6611294d1746bcfca9c0e48b285edc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47677047\",\"name\":\"Biao Yang\"},{\"authorId\":\"143767230\",\"name\":\"Rongrong Ni\"}],\"doi\":\"10.1109/CYBER46603.2019.9066706\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1750dd991c3cc85bc3675ab707fd956e0d83c849\",\"title\":\"Vision-based recognition of pedestrian crossing intention in an urban environment\",\"url\":\"https://www.semanticscholar.org/paper/1750dd991c3cc85bc3675ab707fd956e0d83c849\",\"venue\":\"2019 IEEE 9th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)\",\"year\":2019},{\"arxivId\":\"1804.04326\",\"authors\":[{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"2996464\",\"name\":\"Jiaqing Lin\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"title\":\"STAIR Actions: A Video Dataset of Everyday Home Actions\",\"url\":\"https://www.semanticscholar.org/paper/d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"146992883\",\"name\":\"I. Participants\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae4d06143a6b46ffaf5d228b1fa464dc322ddc18\",\"title\":\"R4-A.3: Human Detection & Re-Identification for Mass Transit Environments\",\"url\":\"https://www.semanticscholar.org/paper/ae4d06143a6b46ffaf5d228b1fa464dc322ddc18\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.10681\",\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"14990294\",\"name\":\"Feixiang Xu\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21029564f3072ab3ff2368069001ba7cb2bd6a3f\",\"title\":\"A Large-scale Varying-view RGB-D Action Dataset for Arbitrary-view Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21029564f3072ab3ff2368069001ba7cb2bd6a3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2011.08900\",\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90e9702ca01ebda8d131e1ec7c46506fc4959f2e\",\"title\":\"Whose hand is this? Person Identification from Egocentric Hand Gestures\",\"url\":\"https://www.semanticscholar.org/paper/90e9702ca01ebda8d131e1ec7c46506fc4959f2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51487791\",\"name\":\"L. C. Valeriano\"},{\"authorId\":\"1705089\",\"name\":\"P. Napoletano\"},{\"authorId\":\"143940718\",\"name\":\"R. Schettini\"}],\"doi\":\"10.1109/ICCE-Berlin.2018.8576183\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"566d09c45ff60abe62e4e3dcac13f0f6747688e5\",\"title\":\"Recognition of driver distractions using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/566d09c45ff60abe62e4e3dcac13f0f6747688e5\",\"venue\":\"2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.10591\",\"authors\":[{\"authorId\":\"40916221\",\"name\":\"Aniket A. Tolpadi\"},{\"authorId\":\"2287883\",\"name\":\"J. Lee\"},{\"authorId\":\"2319990\",\"name\":\"V. Pedoia\"},{\"authorId\":\"2417009\",\"name\":\"S. Majumdar\"}],\"doi\":\"10.1038/s41598-020-63395-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"485bda5bf4aec210fe7bad30a0185d443801444e\",\"title\":\"Deep Learning Predicts Total Knee Replacement from Magnetic Resonance Images\",\"url\":\"https://www.semanticscholar.org/paper/485bda5bf4aec210fe7bad30a0185d443801444e\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46293528\",\"name\":\"M. K. Lee\"},{\"authorId\":\"2866383\",\"name\":\"Dong-Yoon Choi\"},{\"authorId\":\"3835816\",\"name\":\"D. Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.1109/FG.2019.8756551\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"0fbda098fb938dc61e6e3815242bd0f4c46bd731\",\"title\":\"Visual Scene-aware Hybrid Neural Network Architecture for Video-based Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0fbda098fb938dc61e6e3815242bd0f4c46bd731\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"1905.04430\",\"authors\":[{\"authorId\":\"119352476\",\"name\":\"M. M. K. Moghaddam\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"title\":\"Follow the Attention: Combining Partial Pose and Object Motion for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.03064\",\"authors\":[{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"1783892\",\"name\":\"J. Han\"},{\"authorId\":\"12211820\",\"name\":\"Shiyuan Zhang\"},{\"authorId\":\"153003059\",\"name\":\"Xu He\"},{\"authorId\":\"107613350\",\"name\":\"D. Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d1fcd222721829a8c6e46cdad0e444972726543\",\"title\":\"CSI-Net: Unified Human Body Characterization and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d1fcd222721829a8c6e46cdad0e444972726543\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145476300\",\"name\":\"P. Zhdanov\"},{\"authorId\":\"143636123\",\"name\":\"A. Khan\"},{\"authorId\":\"2525887\",\"name\":\"A. R. Rivera\"},{\"authorId\":\"1803086\",\"name\":\"A. Khattak\"}],\"doi\":\"10.1109/IJCNN.2018.8489663\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c54fe61181045865d6834e2fe4376aeea1f9884\",\"title\":\"Improving Human Action Recognition through Hierarchical Neural Network Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/4c54fe61181045865d6834e2fe4376aeea1f9884\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1811.09245\",\"authors\":[{\"authorId\":\"1725418556\",\"name\":\"Masaki Saito\"},{\"authorId\":\"3083107\",\"name\":\"Shunta Saito\"},{\"authorId\":\"152400765\",\"name\":\"Masanori Koyama\"},{\"authorId\":\"3456592\",\"name\":\"S. Kobayashi\"}],\"doi\":\"10.1007/s11263-020-01333-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14b175654024c6b57653239674305fe91bca89a1\",\"title\":\"Train Sparsely, Generate Densely: Memory-Efficient Unsupervised Training of High-Resolution Temporal GAN\",\"url\":\"https://www.semanticscholar.org/paper/14b175654024c6b57653239674305fe91bca89a1\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2005.02690\",\"authors\":[{\"authorId\":\"145836706\",\"name\":\"Xi Ouyang\"},{\"authorId\":\"1807819\",\"name\":\"Jiayu Huo\"},{\"authorId\":\"144056421\",\"name\":\"Liming Xia\"},{\"authorId\":\"145355172\",\"name\":\"F. Shan\"},{\"authorId\":\"48211558\",\"name\":\"J. Liu\"},{\"authorId\":\"30148169\",\"name\":\"Zhanhao Mo\"},{\"authorId\":\"2118089\",\"name\":\"Fuhua Yan\"},{\"authorId\":\"2213445\",\"name\":\"Z. Ding\"},{\"authorId\":\"144286903\",\"name\":\"Q. Yang\"},{\"authorId\":\"144977494\",\"name\":\"Bin Song\"},{\"authorId\":\"122710522\",\"name\":\"F. Shi\"},{\"authorId\":\"48118809\",\"name\":\"Huan Yuan\"},{\"authorId\":\"1471738497\",\"name\":\"Ying Wei\"},{\"authorId\":\"3379159\",\"name\":\"Xiaohuan Cao\"},{\"authorId\":\"2018041\",\"name\":\"Yaozong Gao\"},{\"authorId\":\"2371632\",\"name\":\"Dijia Wu\"},{\"authorId\":\"29516249\",\"name\":\"Qian Wang\"},{\"authorId\":\"146549267\",\"name\":\"D. Shen\"}],\"doi\":\"10.1109/TMI.2020.2995508\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"601c4188ef2a0155c9e894abdc86b77776ad3192\",\"title\":\"Dual-Sampling Attention Network for Diagnosis of COVID-19 From Community Acquired Pneumonia\",\"url\":\"https://www.semanticscholar.org/paper/601c4188ef2a0155c9e894abdc86b77776ad3192\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":\"2008.09037\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"2331418\",\"name\":\"S. Samsi\"},{\"authorId\":\"3302251\",\"name\":\"W. Arcand\"},{\"authorId\":\"2159806\",\"name\":\"David Bestor\"},{\"authorId\":\"34001612\",\"name\":\"Bill Bergeron\"},{\"authorId\":\"2098646\",\"name\":\"C. Byun\"},{\"authorId\":\"1850501832\",\"name\":\"Micheal Houle\"},{\"authorId\":\"145238688\",\"name\":\"M. Hubbell\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"3257323\",\"name\":\"J. Kepner\"},{\"authorId\":\"1983355\",\"name\":\"A. Kirby\"},{\"authorId\":\"1684116\",\"name\":\"P. Michaleas\"},{\"authorId\":\"3385550\",\"name\":\"Lauren Milechin\"},{\"authorId\":\"143913450\",\"name\":\"J. Mullen\"},{\"authorId\":\"2417672\",\"name\":\"A. Prout\"},{\"authorId\":\"144557576\",\"name\":\"A. Rosa\"},{\"authorId\":\"2097629\",\"name\":\"Albert Reuther\"},{\"authorId\":\"145378881\",\"name\":\"C. Yee\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":\"10.1109/HPEC43674.2020.9286249\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"title\":\"Accuracy and Performance Comparison of Video Action Recognition Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"venue\":\"2020 IEEE High Performance Extreme Computing Conference (HPEC)\",\"year\":2020},{\"arxivId\":\"2003.13886\",\"authors\":[{\"authorId\":\"51128743\",\"name\":\"Srikanth Malla\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"}],\"doi\":\"10.1109/cvpr42600.2020.01120\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"title\":\"TITAN: Future Forecast Using Action Priors\",\"url\":\"https://www.semanticscholar.org/paper/55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.03715\",\"authors\":[{\"authorId\":\"4492316\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"145505204\",\"name\":\"J. Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d507f3088e5c8411bc06e274958cbe263169a39d\",\"title\":\"OVC-Net: Object-Oriented Video Captioning with Temporal Graph and Detail Enhancement.\",\"url\":\"https://www.semanticscholar.org/paper/d507f3088e5c8411bc06e274958cbe263169a39d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"title\":\"Iterative Alignment Network for Continuous Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1906.07901\",\"authors\":[{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":\"10.18653/v1/P19-1659\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37cc2c54cc60ee1301baca2d95bf003c76dd07d5\",\"title\":\"Multimodal Abstractive Summarization for How2 Videos\",\"url\":\"https://www.semanticscholar.org/paper/37cc2c54cc60ee1301baca2d95bf003c76dd07d5\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1807.05073\",\"authors\":[{\"authorId\":\"71425456\",\"name\":\"Xingyu Liao\"},{\"authorId\":\"144486617\",\"name\":\"Lingxiao He\"},{\"authorId\":\"2016529\",\"name\":\"Zhouwang Yang\"}],\"doi\":\"10.1007/978-3-030-20876-9_39\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bff271886a64964a0a3f4ccdb6e0abb85abfbea0\",\"title\":\"Video-based Person Re-identification via 3D Convolutional Networks and Non-local Attention\",\"url\":\"https://www.semanticscholar.org/paper/bff271886a64964a0a3f4ccdb6e0abb85abfbea0\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2012.04701\",\"authors\":[{\"authorId\":\"48399108\",\"name\":\"Tianyi Zhao\"},{\"authorId\":\"39758810\",\"name\":\"Kai Cao\"},{\"authorId\":\"8248199\",\"name\":\"Jiawen Yao\"},{\"authorId\":\"37754137\",\"name\":\"Isabella Nogues\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"1820909720\",\"name\":\"Lingyun Huang\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"1993660364\",\"name\":\"Zhaozheng Yin\"},{\"authorId\":\"145981199\",\"name\":\"Ling Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7acf9355deb04f63d51aa0905418ee2ab092d0f\",\"title\":\"3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management\",\"url\":\"https://www.semanticscholar.org/paper/f7acf9355deb04f63d51aa0905418ee2ab092d0f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46294028\",\"name\":\"M. Lee\"},{\"authorId\":\"72657988\",\"name\":\"Dae Yu Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.3390/s20185184\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99e5cbf00e3bf5e31b0d08980a059ed6310e4b21\",\"title\":\"Visual Scene-Aware Hybrid and Multi-Modal Feature Aggregation for Facial Expression Recognition \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/99e5cbf00e3bf5e31b0d08980a059ed6310e4b21\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46895706\",\"name\":\"Wenfeng Song\"},{\"authorId\":\"48830645\",\"name\":\"Shuai Li\"},{\"authorId\":\"103054850\",\"name\":\"Tao Chang\"},{\"authorId\":\"2252725\",\"name\":\"Ai-min Hao\"},{\"authorId\":\"20658737\",\"name\":\"Q. Zhao\"},{\"authorId\":\"100787805\",\"name\":\"Hong Qin\"}],\"doi\":\"10.1109/TIP.2019.2953587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58a06477685794544e34d03a9190ca20a1a8e505\",\"title\":\"Context-Interactive CNN for Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/58a06477685794544e34d03a9190ca20a1a8e505\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796221456\",\"name\":\"Bin Liu\"},{\"authorId\":\"144347268\",\"name\":\"M. Wu\"},{\"authorId\":\"1796272603\",\"name\":\"Minze Tao\"},{\"authorId\":\"30148287\",\"name\":\"Qin Wang\"},{\"authorId\":\"1796267563\",\"name\":\"Luye He\"},{\"authorId\":\"47544023\",\"name\":\"G. Shen\"},{\"authorId\":\"31262025\",\"name\":\"Ke-Han Chen\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"}],\"doi\":\"10.1109/ACCESS.2020.3005825\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27e43e35ce810d8aca341034e544bd398ca6491c\",\"title\":\"Video Content Analysis for Compliance Audit in Finance and Security Industry\",\"url\":\"https://www.semanticscholar.org/paper/27e43e35ce810d8aca341034e544bd398ca6491c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2005.00253\",\"authors\":[{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"145587605\",\"name\":\"Y. Tian\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"206beeef56a1cb5409d5b5a4395255ffe9c38bbe\",\"title\":\"Recognizing American Sign Language Nonmanual Signal Grammar Errors in Continuous Videos\",\"url\":\"https://www.semanticscholar.org/paper/206beeef56a1cb5409d5b5a4395255ffe9c38bbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14499178\",\"name\":\"H. Chen\"},{\"authorId\":null,\"name\":\"Yunhe Wang\"},{\"authorId\":\"144305248\",\"name\":\"H. Shu\"},{\"authorId\":\"103603255\",\"name\":\"Yehui Tang\"},{\"authorId\":\"1691522\",\"name\":\"Chunjing Xu\"},{\"authorId\":\"151485124\",\"name\":\"Boxin Shi\"},{\"authorId\":\"1517686064\",\"name\":\"Chao Xu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"144962249\",\"name\":\"Chang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00171\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b3a8c5bf6e2b966f482c11705601da060d8dd361\",\"title\":\"Frequency Domain Compact 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b3a8c5bf6e2b966f482c11705601da060d8dd361\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.06189\",\"authors\":[{\"authorId\":\"1739538\",\"name\":\"L. Wang\"},{\"authorId\":\"21072153\",\"name\":\"Zixun Sun\"},{\"authorId\":\"3315113\",\"name\":\"Wentao Yao\"},{\"authorId\":\"47940636\",\"name\":\"Hui Zhan\"},{\"authorId\":\"3252265\",\"name\":\"Chengwei Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d760fc5d63705bd33d33b759fe727149f8e47e67\",\"title\":\"Unsupervised Multi-stream Highlight detection for the Game \\\"Honor of Kings\\\"\",\"url\":\"https://www.semanticscholar.org/paper/d760fc5d63705bd33d33b759fe727149f8e47e67\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.08465\",\"authors\":[{\"authorId\":\"71777904\",\"name\":\"H. Zhang\"},{\"authorId\":\"2884662\",\"name\":\"Xuemiao Xu\"},{\"authorId\":\"2823769\",\"name\":\"G. Han\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"}],\"doi\":\"10.1109/cvpr42600.2020.00075\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d29fc735af090ac33d986d129daf022268839096\",\"title\":\"Context-Aware and Scale-Insensitive Temporal Repetition Counting\",\"url\":\"https://www.semanticscholar.org/paper/d29fc735af090ac33d986d129daf022268839096\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388870641\",\"name\":\"Patrick Gebert\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/IVS.2019.8814249\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4901f667458a3a2144fe42e965ed43b7dbe995a\",\"title\":\"End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d4901f667458a3a2144fe42e965ed43b7dbe995a\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423676696\",\"name\":\"Andrei Fr\\u0103\\u0163il\\u0103\"},{\"authorId\":\"144535468\",\"name\":\"C. Florea\"},{\"authorId\":\"2905899\",\"name\":\"C. Vertan\"},{\"authorId\":\"13577989\",\"name\":\"M. Badea\"}],\"doi\":\"10.1109/SPED.2019.8906591\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0e9c0d9cbea8b4237fe9137bb0f3b0485b3a0c2\",\"title\":\"Genuine vs Posed Expressions: A Juxtaposing of Man and Machine Performance\",\"url\":\"https://www.semanticscholar.org/paper/d0e9c0d9cbea8b4237fe9137bb0f3b0485b3a0c2\",\"venue\":\"2019 International Conference on Speech Technology and Human-Computer Dialogue (SpeD)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49865403\",\"name\":\"Zhiyu Chen\"},{\"authorId\":\"1668787617\",\"name\":\"Yangwei Gu\"},{\"authorId\":\"50542782\",\"name\":\"Chunhua Deng\"},{\"authorId\":\"34611435\",\"name\":\"Ziqi Zhu\"}],\"doi\":\"10.1109/SPAC49953.2019.237869\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"747cd60482560cc92a254eccc516cf8f230845d8\",\"title\":\"Adaptive Temporal Segmentation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/747cd60482560cc92a254eccc516cf8f230845d8\",\"venue\":\"2019 International Conference on Security, Pattern Analysis, and Cybernetics (SPAC)\",\"year\":2019},{\"arxivId\":\"1905.04225\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145872624\",\"name\":\"Yao Rong\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a4787b4123d0928e08ec79412e2626d9e3adbea\",\"title\":\"Talking With Your Hands: Scaling Hand Gestures and Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3a4787b4123d0928e08ec79412e2626d9e3adbea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1712247436\",\"name\":\"Felix Hertlein\"},{\"authorId\":\"153443035\",\"name\":\"D. M\\u00fcnch\"},{\"authorId\":\"144006867\",\"name\":\"M. Arens\"}],\"doi\":\"10.1109/WACVW50321.2020.9096934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"title\":\"Context Sensitivity of Spatio-Temporal Activity Detection using Hierarchical Deep Neural Networks in Extended Videos\",\"url\":\"https://www.semanticscholar.org/paper/f2da22aa90be9036b60ac7dbe0683c09e7f30a03\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096937\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b39d9873e95553406923f0bbd492ba70f6db7d83\",\"title\":\"Real-time Detection of Activities in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/b39d9873e95553406923f0bbd492ba70f6db7d83\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145268563\",\"name\":\"S. Amini\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2019.2959426\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"title\":\"Spatio-Temporal VLAD Encoding of Visual Events Using Temporal Ordering of the Mid-Level Deep Semantics\",\"url\":\"https://www.semanticscholar.org/paper/fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2002.01646\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ea6919c7e1633693b9ee4a53ca79db8b3d990e6\",\"title\":\"Solving Raven's Progressive Matrices with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3ea6919c7e1633693b9ee4a53ca79db8b3d990e6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143996556\",\"name\":\"H. Ye\"},{\"authorId\":\"2043501\",\"name\":\"Xilong Qu\"},{\"authorId\":\"27739837\",\"name\":\"Shengzong Liu\"},{\"authorId\":\"153184972\",\"name\":\"G. Li\"}],\"doi\":\"10.1080/17517575.2020.1762245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c742897f5892c6a181772651c7ff8ad034fb4a1\",\"title\":\"Hybrid sampling method for autoregressive classification trees under density-weighted curvature distance\",\"url\":\"https://www.semanticscholar.org/paper/9c742897f5892c6a181772651c7ff8ad034fb4a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1145/3379156.3391337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117877a5d29a6e3d0ad6f7520e6ff8b114d5670b\",\"title\":\"Deep Audio-Visual Saliency: Baseline Model and Data\",\"url\":\"https://www.semanticscholar.org/paper/117877a5d29a6e3d0ad6f7520e6ff8b114d5670b\",\"venue\":\"ETRA Short Papers\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720950078\",\"name\":\"Yingguo Jiang\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"50728655\",\"name\":\"Tong Zhang\"}],\"doi\":\"10.1007/s13042-020-01132-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e8bfe9b80cb41a2f9e83bed1b20bd2afd563271\",\"title\":\"View-independent representation with frame interpolation method for skeleton-based human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7e8bfe9b80cb41a2f9e83bed1b20bd2afd563271\",\"venue\":\"Int. J. Mach. Learn. Cybern.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2581044\",\"name\":\"Cemil Zalluhoglu\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"}],\"doi\":\"10.1016/j.imavis.2020.103870\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cd8441db0c344897d728c013dd600baf918113a\",\"title\":\"Collective Sports: A multi-task dataset for collective activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/2cd8441db0c344897d728c013dd600baf918113a\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":\"1904.08505\",\"authors\":[{\"authorId\":\"65914312\",\"name\":\"Clebeson Canuto dos Santos\"},{\"authorId\":\"143622442\",\"name\":\"J. A. Samatelo\"},{\"authorId\":\"21859276\",\"name\":\"Raquel Frizera Vassallo\"}],\"doi\":\"10.1016/j.neucom.2020.03.038\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0b763e684aa26436efb8da8dad15d4fd555866e\",\"title\":\"Dynamic Gesture Recognition by Using CNNs and Star RGB: a Temporal Information Condensation\",\"url\":\"https://www.semanticscholar.org/paper/d0b763e684aa26436efb8da8dad15d4fd555866e\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993691002\",\"name\":\"Raksha Ramesh\"},{\"authorId\":\"144578530\",\"name\":\"Vishal Anand\"},{\"authorId\":\"1993659768\",\"name\":\"Ziyin Wang\"},{\"authorId\":\"1993695801\",\"name\":\"Tianle Zhu\"},{\"authorId\":\"1993695696\",\"name\":\"Wenfeng Lyu\"},{\"authorId\":\"1993660605\",\"name\":\"Serena Yuan\"},{\"authorId\":\"153903099\",\"name\":\"Ching-Yung Lin\"}],\"doi\":\"10.1145/3395035.3425641\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2667528b8e8301bfc095e9d51fb823125b6af62b\",\"title\":\"Kinetics and Scene Features for Intent Detection\",\"url\":\"https://www.semanticscholar.org/paper/2667528b8e8301bfc095e9d51fb823125b6af62b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.05683\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"48513370\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"2692368\",\"name\":\"Muchen Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00634\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d92827d0c62ce499e199caadb83e5ba457bc8869\",\"title\":\"TubeTK: Adopting Tubes to Track Multi-Object in a One-Step Training Model\",\"url\":\"https://www.semanticscholar.org/paper/d92827d0c62ce499e199caadb83e5ba457bc8869\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.13426\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b38e482488359da26a25ed9ef5341cd38a2b6562\",\"title\":\"Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b38e482488359da26a25ed9ef5341cd38a2b6562\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1007/978-3-030-01264-9_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71167cf519940a7373adc221401c396198763ab0\",\"title\":\"Scenes-Objects-Actions: A Multi-task, Multi-label Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71167cf519940a7373adc221401c396198763ab0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19120180\",\"name\":\"L. Song\"},{\"authorId\":\"1810660380\",\"name\":\"X. Guo\"},{\"authorId\":\"1965900016\",\"name\":\"Yiqi Fan\"}],\"doi\":\"10.1109/ICCSE49874.2020.9201857\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7469bdeb3ecabc3eead628789467173b86b6970\",\"title\":\"Action Recognition in Video Using Human Keypoint Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7469bdeb3ecabc3eead628789467173b86b6970\",\"venue\":\"2020 15th International Conference on Computer Science & Education (ICCSE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3281413\",\"name\":\"Diangang Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1993699405\",\"name\":\"Yuka Hayashi\"},{\"authorId\":\"144042991\",\"name\":\"Jun Suzuki\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"}],\"doi\":\"10.1145/3394171.3413801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2587144054982adc9b4c5adef760f45bf3be0a26\",\"title\":\"Multi-Person Action Recognition in Microwave Sensors\",\"url\":\"https://www.semanticscholar.org/paper/2587144054982adc9b4c5adef760f45bf3be0a26\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40422134\",\"name\":\"Dawei Liu\"},{\"authorId\":\"39145049\",\"name\":\"W. Wang\"},{\"authorId\":\"3642625\",\"name\":\"Xiaokai Wang\"},{\"authorId\":\"41130715\",\"name\":\"C. Wang\"},{\"authorId\":\"73489743\",\"name\":\"Jiangyun Pei\"},{\"authorId\":\"47483413\",\"name\":\"Wenchao Chen\"}],\"doi\":\"10.1109/TGRS.2019.2947149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"621de73f578b5f48a39d424ee697663e7a502d97\",\"title\":\"Poststack Seismic Data Denoising Based on 3-D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/621de73f578b5f48a39d424ee697663e7a502d97\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":\"1811.09795\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1609/aaai.v33i01.33018545\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3dbd24407f6e58f6b7bc461fd21782062f0f361\",\"title\":\"Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles\",\"url\":\"https://www.semanticscholar.org/paper/b3dbd24407f6e58f6b7bc461fd21782062f0f361\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8600022\",\"name\":\"Yanqiu Liao\"},{\"authorId\":\"2325197\",\"name\":\"Pengwen Xiong\"},{\"authorId\":\"34924661\",\"name\":\"Weidong Min\"},{\"authorId\":\"121339840\",\"name\":\"Weiqiong Min\"},{\"authorId\":\"49301901\",\"name\":\"Jiahao Lu\"}],\"doi\":\"10.1109/ACCESS.2019.2904749\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c14e8fbed0da55cdefcff0d5f9cb98e20e88ef2f\",\"title\":\"Dynamic Sign Language Recognition Based on Video Sequence With BLSTM-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/c14e8fbed0da55cdefcff0d5f9cb98e20e88ef2f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2004.14840\",\"authors\":[{\"authorId\":\"3397911\",\"name\":\"Georgios Paraskevopoulos\"},{\"authorId\":\"2739353\",\"name\":\"Srinivas Parthasarathy\"},{\"authorId\":\"40038450\",\"name\":\"Aparna Khare\"},{\"authorId\":\"1734989\",\"name\":\"Shiva Sundaram\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0612582490c445b1859f7feea0c04daf17598014\",\"title\":\"Multiresolution and Multimodal Speech Recognition with Transformers\",\"url\":\"https://www.semanticscholar.org/paper/0612582490c445b1859f7feea0c04daf17598014\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D18-1117\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b5647cbbfdc7d1ee91a8ec264b200b66afd7b8b2\",\"title\":\"A Dataset for Telling the Stories of Social Media Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5647cbbfdc7d1ee91a8ec264b200b66afd7b8b2\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f921aad7da763dcc7516bd4a1b78433b47f20f6c\",\"title\":\"Revisiting Temporal Modeling for Video-based Person\",\"url\":\"https://www.semanticscholar.org/paper/f921aad7da763dcc7516bd4a1b78433b47f20f6c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4492316\",\"name\":\"Fangyi Zhu\"},{\"authorId\":\"3090135\",\"name\":\"Jeng-Neng Hwang\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"145886114\",\"name\":\"Jun Guo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"745f54a822bdbd33cf08e65b665ab3f3528cdf78\",\"title\":\"Object-Oriented Video Captioning with Temporal Graph and Prior Knowledge Building\",\"url\":\"https://www.semanticscholar.org/paper/745f54a822bdbd33cf08e65b665ab3f3528cdf78\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.04852\",\"authors\":[{\"authorId\":\"3286107\",\"name\":\"X. Wang\"},{\"authorId\":\"1884134\",\"name\":\"Xiya Zhang\"},{\"authorId\":\"51280237\",\"name\":\"Yinheng Zhu\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"2536159\",\"name\":\"Xiaoyun Yuan\"},{\"authorId\":\"83620577\",\"name\":\"Liuyu Xiang\"},{\"authorId\":\"96309455\",\"name\":\"Z. Wang\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1741299\",\"name\":\"D. Brady\"},{\"authorId\":\"48382219\",\"name\":\"Qiong-hai Dai\"},{\"authorId\":\"47547866\",\"name\":\"Lu Fang\"}],\"doi\":\"10.1109/cvpr42600.2020.00333\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf9a30ee3ef6320780c6980f21f3c3ea43fc2c62\",\"title\":\"PANDA: A Gigapixel-Level Human-Centric Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bf9a30ee3ef6320780c6980f21f3c3ea43fc2c62\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004341822\",\"name\":\"Noorhan K. Fawzy\"},{\"authorId\":\"37370786\",\"name\":\"M. Marey\"},{\"authorId\":\"143987203\",\"name\":\"Mostafa Aref\"}],\"doi\":\"10.1007/978-3-030-58669-0_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18bacea52db19f69bc4933c6ad82eb5d22da281b\",\"title\":\"Video Captioning Using Attention Based Visual Fusion with Bi-temporal Context and Bi-modal Semantic Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/18bacea52db19f69bc4933c6ad82eb5d22da281b\",\"venue\":\"AISI\",\"year\":2020},{\"arxivId\":\"2012.07175\",\"authors\":[{\"authorId\":\"3151024\",\"name\":\"Lang Su\"},{\"authorId\":\"2037365541\",\"name\":\"Chuqing Hu\"},{\"authorId\":\"46439101\",\"name\":\"G. Li\"},{\"authorId\":\"1491099112\",\"name\":\"Dongpu Cao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da72f519272681d685b5fb07e8d2e42b447e680b\",\"title\":\"MSAF: Multimodal Split Attention Fusion\",\"url\":\"https://www.semanticscholar.org/paper/da72f519272681d685b5fb07e8d2e42b447e680b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471106222\",\"name\":\"Huan Liu\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"151501346\",\"name\":\"H. Zhao\"},{\"authorId\":\"120292094\",\"name\":\"Yanzhang Lyu\"}],\"doi\":\"10.1016/j.ins.2020.01.025\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5e9e16c9874f4baa58137d26c6f6fa79c3df4ce\",\"title\":\"Dual-stream generative adversarial networks for distributionally robust zero-shot learning\",\"url\":\"https://www.semanticscholar.org/paper/c5e9e16c9874f4baa58137d26c6f6fa79c3df4ce\",\"venue\":\"Inf. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"title\":\"Multi-Variate Temporal GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3327256\",\"name\":\"M. Favorskaya\"},{\"authorId\":\"122575918\",\"name\":\"L. C. Jain\"}],\"doi\":\"10.31799/1684-8853-2019-3-10-36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"title\":\"Saliency detection in deep learning era: trends of development\",\"url\":\"https://www.semanticscholar.org/paper/6fe7379f40fd2354e5bbe5f8be79069feb0c6ea2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.12326\",\"authors\":[{\"authorId\":\"144692784\",\"name\":\"Mohsen Joneidi\"},{\"authorId\":\"2621521\",\"name\":\"Alireza Zaeemzadeh\"},{\"authorId\":\"1789219\",\"name\":\"N. Rahnavard\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2019.00556\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b\",\"title\":\"Iterative Projection and Matching: Finding Structure-Preserving Representatives and Its Application to Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1516118831\",\"name\":\"Kaito Hirasawa\"},{\"authorId\":\"47761580\",\"name\":\"K. Maeda\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/GCCE50665.2020.9291955\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c6bb5fbb71e26e1c13f6fb4d7fec9c8fb10933f\",\"title\":\"Important Scene Prediction of Baseball Videos Using Twitter and Video Analysis Based on LSTM\",\"url\":\"https://www.semanticscholar.org/paper/0c6bb5fbb71e26e1c13f6fb4d7fec9c8fb10933f\",\"venue\":\"2020 IEEE 9th Global Conference on Consumer Electronics (GCCE)\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.09183\",\"authors\":[{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"40495154\",\"name\":\"M. Hayashi\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1109/ICIP40778.2020.9190820\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63a5b2f09fd2b217fa5a3792b84a78397fc10be4\",\"title\":\"Retrieving and Highlighting Action with Spatiotemporal Reference\",\"url\":\"https://www.semanticscholar.org/paper/63a5b2f09fd2b217fa5a3792b84a78397fc10be4\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2004.01823\",\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"title\":\"Temporal Shift GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/31ce95cc12c4e58fd5d7051d9797589859d5dda1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8962288\",\"name\":\"Zichen zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"title\":\"Attention Before and After Feature Extraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674907\",\"name\":\"Lili Meng\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"115284322\",\"name\":\"W. Sun\"},{\"authorId\":\"1402348340\",\"name\":\"Frederich Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCVW.2019.00189\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"title\":\"Interpretable Spatio-Temporal Attention for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1811.11387\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"title\":\"Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.11105\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"145128144\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3b1e7592d91717a3cf0e9c42bd27c22ca5d3aab\",\"title\":\"Adaptive and Iteratively Improving Recurrent Lateral Connections\",\"url\":\"https://www.semanticscholar.org/paper/f3b1e7592d91717a3cf0e9c42bd27c22ca5d3aab\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4866145\",\"name\":\"Jilin Tang\"},{\"authorId\":\"2043870\",\"name\":\"H. Hu\"},{\"authorId\":\"7451768\",\"name\":\"Q. Zhou\"},{\"authorId\":\"1692900\",\"name\":\"H. Shan\"},{\"authorId\":\"143827460\",\"name\":\"Chuan Tian\"},{\"authorId\":\"1718541\",\"name\":\"T. Quek\"}],\"doi\":\"10.1109/ICIP.2019.8803792\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02c8d013c4aca5169e8bc98529ba854e0a981aa4\",\"title\":\"Pose Guided Global and Local GAN for Appearance Preserving Human Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/02c8d013c4aca5169e8bc98529ba854e0a981aa4\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11027451\",\"name\":\"Dario Bega\"},{\"authorId\":\"145829671\",\"name\":\"M. Gramaglia\"},{\"authorId\":\"2398171\",\"name\":\"R. P\\u00e9rez\"},{\"authorId\":\"1944788067\",\"name\":\"Marco Fiore\"},{\"authorId\":\"2214003\",\"name\":\"A. Banchs\"},{\"authorId\":\"1680055\",\"name\":\"X. Costa\"}],\"doi\":\"10.1109/MNET.001.2000047\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d10e1a787ad5d5be9c2d8c02f9fcfd57c4b8ff1e\",\"title\":\"AI-Based Autonomous Control, Management, and Orchestration in 5G: From Standards to Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/d10e1a787ad5d5be9c2d8c02f9fcfd57c4b8ff1e\",\"venue\":\"IEEE Network\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143796376\",\"name\":\"L. Jin\"},{\"authorId\":\"152905258\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"1986828946\",\"name\":\"Kaiming Kuang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"3152330\",\"name\":\"Yiyi Gao\"},{\"authorId\":\"51350339\",\"name\":\"Yingli Sun\"},{\"authorId\":\"50735393\",\"name\":\"P. Gao\"},{\"authorId\":\"1561537170\",\"name\":\"Weiling Ma\"},{\"authorId\":\"147613351\",\"name\":\"M. Tan\"},{\"authorId\":\"104048467\",\"name\":\"H. Kang\"},{\"authorId\":\"49252622\",\"name\":\"Jia-jun Chen\"},{\"authorId\":\"39778912\",\"name\":\"M. Li\"}],\"doi\":\"10.1016/j.ebiom.2020.103106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08a09d527fcc33283bfbbf1c4c7473e6df4b7873\",\"title\":\"Deep-learning-assisted detection and segmentation of rib fractures from CT scans: Development and validation of FracNet\",\"url\":\"https://www.semanticscholar.org/paper/08a09d527fcc33283bfbbf1c4c7473e6df4b7873\",\"venue\":\"EBioMedicine\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153504672\",\"name\":\"Hong Zhang\"},{\"authorId\":\"2000677733\",\"name\":\"Jiexiong Rong\"}],\"doi\":\"10.1007/S11042-020-09564-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe960aebd7429164f20643301456b06fadb89165\",\"title\":\"Enhanced 3D residual network for video event recognition in shipping monitoring\",\"url\":\"https://www.semanticscholar.org/paper/fe960aebd7429164f20643301456b06fadb89165\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405779274\",\"name\":\"Braulio J. Solano-Rojas\"},{\"authorId\":\"1405779270\",\"name\":\"Ricardo Villal\\u00f3n-Fonseca\"},{\"authorId\":\"1401720650\",\"name\":\"Gabriela Mar\\u00edn-Ravent\\u00f3s\"}],\"doi\":\"10.1007/978-3-030-51517-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e8b09e017390705ab4d892e8d2bb7f4a39289053\",\"title\":\"Alzheimer\\u2019s Disease Early Detection Using a Low Cost Three-Dimensional Densenet-121 Architecture\",\"url\":\"https://www.semanticscholar.org/paper/e8b09e017390705ab4d892e8d2bb7f4a39289053\",\"venue\":\"ICOST\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47591075\",\"name\":\"F. Chen\"},{\"authorId\":\"48211673\",\"name\":\"J. Liu\"},{\"authorId\":\"50086003\",\"name\":\"Peng Wan\"},{\"authorId\":\"47405681\",\"name\":\"Hongen Liao\"},{\"authorId\":\"6402561\",\"name\":\"W. Kong\"}],\"doi\":\"10.1007/s11517-020-02164-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5829ce49e66715f66d00cfff9f0ad399864f57d4\",\"title\":\"Immunohistochemical index prediction of breast tumor based on multi-dimension features in contrast-enhanced ultrasound\",\"url\":\"https://www.semanticscholar.org/paper/5829ce49e66715f66d00cfff9f0ad399864f57d4\",\"venue\":\"Medical & Biological Engineering & Computing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26632228\",\"name\":\"Woan-Shiuan Chien\"},{\"authorId\":\"49424463\",\"name\":\"Hao-Chun Yang\"},{\"authorId\":\"2467369\",\"name\":\"Chi-Chun Lee\"}],\"doi\":\"10.1145/3394171.3413552\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36ff1c15d61e7aa9fa280b70438107df50d6900a\",\"title\":\"Cross Corpus Physiological-based Emotion Recognition Using a Learnable Visual Semantic Graph Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/36ff1c15d61e7aa9fa280b70438107df50d6900a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39042074\",\"name\":\"Ian Tu\"},{\"authorId\":\"145901092\",\"name\":\"A. Bhalerao\"},{\"authorId\":\"144482645\",\"name\":\"N. Griffiths\"},{\"authorId\":\"49625872\",\"name\":\"M. Delgado\"},{\"authorId\":\"2059974\",\"name\":\"Alasdair Thomason\"},{\"authorId\":\"2568126\",\"name\":\"T. Popham\"},{\"authorId\":\"2261735\",\"name\":\"A. Mouzakitis\"}],\"doi\":\"10.1109/IVS.2018.8500564\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"27b06d8d09b0190f44597214627f0e8c65031ad9\",\"title\":\"Dual Viewpoint Passenger State Classification Using 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/27b06d8d09b0190f44597214627f0e8c65031ad9\",\"venue\":\"2018 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"144067957\",\"name\":\"K. Mao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"title\":\"Semantic-filtered Soft-Split-Aware video captioning with audio-augmented feature\",\"url\":\"https://www.semanticscholar.org/paper/fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2004.02753\",\"authors\":[{\"authorId\":\"1612061859\",\"name\":\"Joshua Knights\"},{\"authorId\":\"1612351216\",\"name\":\"Anthony Vanderkop\"},{\"authorId\":\"143679553\",\"name\":\"D. Ward\"},{\"authorId\":\"1612210724\",\"name\":\"Olivia Mackenzie-Ross\"},{\"authorId\":\"145136889\",\"name\":\"P. Moghadam\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"195a51f9e4be3537f930d87f5200e63a51b9a226\",\"title\":\"Temporally Coherent Embeddings for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/195a51f9e4be3537f930d87f5200e63a51b9a226\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09215\",\"authors\":[{\"authorId\":\"50218817\",\"name\":\"Zhengwei Wang\"},{\"authorId\":\"1486411393\",\"name\":\"Qi She\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/CVPRW50498.2020.00123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"title\":\"CatNet: Class Incremental 3D ConvNets for Lifelong Egocentric Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2009.05757\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"152978186\",\"name\":\"Xiao-wei Guo\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfff32dd150ee568384d60708622e2a3917fd6cf\",\"title\":\"Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion\",\"url\":\"https://www.semanticscholar.org/paper/cfff32dd150ee568384d60708622e2a3917fd6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430706\",\"name\":\"Luke M. Guerdan\"},{\"authorId\":\"153146302\",\"name\":\"P. Sun\"},{\"authorId\":\"73771457\",\"name\":\"Connor Rowland\"},{\"authorId\":\"1380689103\",\"name\":\"Logan Harrison\"},{\"authorId\":\"98509794\",\"name\":\"Zhicheng Tang\"},{\"authorId\":\"3430560\",\"name\":\"Nickolas M. Wergeles\"},{\"authorId\":\"152856501\",\"name\":\"Yi Shang\"}],\"doi\":\"10.1007/978-3-030-31901-4_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ad3b73ac661b6dbccda2199a1430b8a36d458a0\",\"title\":\"Deep Learning vs. Classical Machine Learning: A Comparison of Methods for Fluid Intelligence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5ad3b73ac661b6dbccda2199a1430b8a36d458a0\",\"venue\":\"ABCD-NP@MICCAI\",\"year\":2019},{\"arxivId\":\"1906.05323\",\"authors\":[{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":\"10.1609/AAAI.V34I04.5875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bacd236d97211a49f5976453568aad02cb78727\",\"title\":\"Specifying Weight Priors in Bayesian Deep Neural Networks with Empirical Bayes\",\"url\":\"https://www.semanticscholar.org/paper/3bacd236d97211a49f5976453568aad02cb78727\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.14752\",\"authors\":[{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"title\":\"A Comprehensive Review on Recent Methods and Challenges of Video Description\",\"url\":\"https://www.semanticscholar.org/paper/baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.14405\",\"authors\":[{\"authorId\":\"1729516889\",\"name\":\"Komal Chugh\"},{\"authorId\":\"1483595780\",\"name\":\"Parul Gupta\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"48236457\",\"name\":\"R. Subramanian\"}],\"doi\":\"10.1145/3394171.3413700\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4b03ff87322570e0ad26e37582ec4150d4d89f7\",\"title\":\"Not made for each other- Audio-Visual Dissonance-based Deepfake Detection and Localization\",\"url\":\"https://www.semanticscholar.org/paper/a4b03ff87322570e0ad26e37582ec4150d4d89f7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.01065\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58580-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"202c79bbb45ab6524141feacc81caacc4ba00401\",\"title\":\"Memory-augmented Dense Predictive Coding for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/202c79bbb45ab6524141feacc81caacc4ba00401\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152197164\",\"name\":\"P. Mukherjee\"},{\"authorId\":\"5510802\",\"name\":\"M. Zhou\"},{\"authorId\":\"1388846801\",\"name\":\"Edward H. Lee\"},{\"authorId\":\"1742241323\",\"name\":\"Anne Schicht\"},{\"authorId\":\"2183529\",\"name\":\"Y. Balagurunathan\"},{\"authorId\":\"46510615\",\"name\":\"S. Napel\"},{\"authorId\":\"4579991\",\"name\":\"R. Gillies\"},{\"authorId\":\"145544306\",\"name\":\"S. Wong\"},{\"authorId\":\"38259767\",\"name\":\"A. Thieme\"},{\"authorId\":\"1850992\",\"name\":\"A. Leung\"},{\"authorId\":\"46820244\",\"name\":\"O. Gevaert\"}],\"doi\":\"10.1038/s42256-020-0173-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"759710287e84e14b1dfaf2bdc5da4027ed417370\",\"title\":\"A shallow convolutional neural network predicts prognosis of lung cancer patients in multi-institutional computed tomography image datasets\",\"url\":\"https://www.semanticscholar.org/paper/759710287e84e14b1dfaf2bdc5da4027ed417370\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.02086\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"title\":\"Self-supervised learning using consistency regularization of spatio-temporal data augmentation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.02104\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b531ca7fb392468f7053ab6861c11c30adef7b5\",\"title\":\"Revisiting Temporal Modeling for Video-based Person ReID\",\"url\":\"https://www.semanticscholar.org/paper/3b531ca7fb392468f7053ab6861c11c30adef7b5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"48126134\",\"name\":\"Raman Arora\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"144404308\",\"name\":\"Amanda Duarte\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"},{\"authorId\":\"51261844\",\"name\":\"N. Holzenberger\"},{\"authorId\":\"1908331\",\"name\":\"Chiraag Lala\"},{\"authorId\":\"2513954\",\"name\":\"S. Lee\"},{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"78476552\",\"name\":\"K. Mulligan\"},{\"authorId\":\"1752987954\",\"name\":\"Alissa Ostapenka\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"}],\"doi\":\"10.1109/JSTSP.2020.2998415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14aadd24040edaa9ce9978b53b00aeede015f859\",\"title\":\"Grounded Sequence to Sequence Transduction\",\"url\":\"https://www.semanticscholar.org/paper/14aadd24040edaa9ce9978b53b00aeede015f859\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"2006.11808\",\"authors\":[{\"authorId\":\"143630472\",\"name\":\"Minseok Seo\"},{\"authorId\":\"120704782\",\"name\":\"Jae-Min Lee\"},{\"authorId\":\"72297759\",\"name\":\"Jongchan Park\"},{\"authorId\":\"2854596\",\"name\":\"Dong-Geol Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f6749b9ce96ff36892871c1a60f1f04af7845b2e\",\"title\":\"Sequential Feature Filtering Classifier\",\"url\":\"https://www.semanticscholar.org/paper/f6749b9ce96ff36892871c1a60f1f04af7845b2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143741745\",\"name\":\"Y. Lei\"},{\"authorId\":\"2419917\",\"name\":\"Y. Tian\"},{\"authorId\":\"3449207\",\"name\":\"Hongming Shan\"},{\"authorId\":\"2247926\",\"name\":\"Junping Zhang\"},{\"authorId\":\"144749285\",\"name\":\"G. Wang\"},{\"authorId\":\"1764113\",\"name\":\"M. Kalra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3123492e1685b90157ec87d862a17dd90f651401\",\"title\":\"Soft Activation Mapping of Lung Nodules in Low-Dose CT images\",\"url\":\"https://www.semanticscholar.org/paper/3123492e1685b90157ec87d862a17dd90f651401\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.15319\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.acl-main.518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af73d7815f13794223384004096ff4fc62c3d4a9\",\"title\":\"Video-Grounded Dialogues with Pretrained Generation Language Models\",\"url\":\"https://www.semanticscholar.org/paper/af73d7815f13794223384004096ff4fc62c3d4a9\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49694933\",\"name\":\"Ziheng Guo\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47504563\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Junhao Zhang\"}],\"doi\":\"10.1007/978-3-030-30508-6_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"title\":\"An Efficient 3D-NAS Method for Video-Based Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"2005.04684\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"144250505\",\"name\":\"X. Chen\"},{\"authorId\":\"2780667\",\"name\":\"Z. Ren\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"}],\"doi\":\"10.24963/ijcai.2020/668\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"248b264f95429e62c855b4f1a0b33e88a3cbdb2a\",\"title\":\"From Standard Summarization to New Tasks and Beyond: Summarization with Manifold Information\",\"url\":\"https://www.semanticscholar.org/paper/248b264f95429e62c855b4f1a0b33e88a3cbdb2a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2003.13158\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/cvpr42600.2020.00987\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d57d0c8071378c26967fa428bf339193713b91a5\",\"title\":\"Learning Interactions and Relationships Between Movie Characters\",\"url\":\"https://www.semanticscholar.org/paper/d57d0c8071378c26967fa428bf339193713b91a5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1810.12819\",\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"563143c5f4fed0184c1f3e661917da94cfed1d46\",\"title\":\"Informed Democracy: Voting-based Novelty Detection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/563143c5f4fed0184c1f3e661917da94cfed1d46\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894435\",\"name\":\"M. Almasi\"},{\"authorId\":\"1742528579\",\"name\":\"Seyed Adel Ghaeinian\"},{\"authorId\":\"1580485424\",\"name\":\"S. Samiee\"},{\"authorId\":\"1742490137\",\"name\":\"Hamed Fathi\"}],\"doi\":\"10.1109/ICICT48043.2020.9112400\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17d40e7de4e9aece88d187febc28b079f72d5b42\",\"title\":\"Investigating the Application of Human Motion Recognition for Athletics Talent Identification using the Head-Mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/17d40e7de4e9aece88d187febc28b079f72d5b42\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":\"1911.09449\",\"authors\":[{\"authorId\":\"108526754\",\"name\":\"Linxi Jiang\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6be44364db3a46ab5fcf8172910650b210cc5c39\",\"title\":\"Black-box Adversarial Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/6be44364db3a46ab5fcf8172910650b210cc5c39\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47521591\",\"name\":\"Qingsong Zhao\"},{\"authorId\":\"144796414\",\"name\":\"Shijie Sun\"},{\"authorId\":\"5623317\",\"name\":\"Xiaopeng Ji\"},{\"authorId\":\"48169641\",\"name\":\"Lei Wang\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"}],\"doi\":\"10.1007/978-3-030-27538-9_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"856acf3cd1da2826926c2994fc9f7d59b23173b3\",\"title\":\"View Invariant Human Action Recognition Using 3D Geometric Features\",\"url\":\"https://www.semanticscholar.org/paper/856acf3cd1da2826926c2994fc9f7d59b23173b3\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02422\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00240\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"title\":\"Resource Efficient 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.11853\",\"authors\":[{\"authorId\":\"8248199\",\"name\":\"Jiawen Yao\"},{\"authorId\":\"32060935\",\"name\":\"Y. Shi\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"145981199\",\"name\":\"Ling Zhang\"}],\"doi\":\"10.1007/978-3-030-59713-9_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"103257816e2a8be988ad46136ff9609d20ae22c3\",\"title\":\"DeepPrognosis: Preoperative Prediction of Pancreatic Cancer Survival and Surgical Margin via Contrast-Enhanced CT Imaging\",\"url\":\"https://www.semanticscholar.org/paper/103257816e2a8be988ad46136ff9609d20ae22c3\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48211087\",\"name\":\"Jinping Liu\"},{\"authorId\":\"72217143\",\"name\":\"H. Liu\"},{\"authorId\":\"144221423\",\"name\":\"ZhaoHui Tang\"},{\"authorId\":\"145202887\",\"name\":\"W. Gui\"},{\"authorId\":\"1900776\",\"name\":\"Tian-yu Ma\"},{\"authorId\":\"7202140\",\"name\":\"Su-bo Gong\"},{\"authorId\":\"3094791\",\"name\":\"Q. Gao\"},{\"authorId\":\"7767746\",\"name\":\"Yongfang Xie\"},{\"authorId\":\"107766913\",\"name\":\"Jean Paul Niyoyita\"}],\"doi\":\"10.1038/s41598-020-63242-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae399f43b8805bf70aeb63cc678a596318c81e4a\",\"title\":\"IOUC-3DSFCNN: Segmentation of Brain Tumors via IOU Constraint 3D Symmetric Full Convolution Network with Multimodal Auto-context\",\"url\":\"https://www.semanticscholar.org/paper/ae399f43b8805bf70aeb63cc678a596318c81e4a\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":\"2012.07248\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1527112562\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1807805250\",\"name\":\"Muchen Li\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"965571810fcb79fdaaed7329ff57b3720508a241\",\"title\":\"TDAF: Top-Down Attention Framework for Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/965571810fcb79fdaaed7329ff57b3720508a241\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"105070829\",\"name\":\"P. Bilinski\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"3299530\",\"name\":\"A. Dantcheva\"}],\"doi\":\"10.1109/WACV45572.2020.9093492\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"title\":\"ImaGINator: Conditional Spatio-Temporal GAN for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/493e753062f82e36b9c24ec48a13dd4b424f65a3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471681696\",\"name\":\"Mingjie Liu\"},{\"authorId\":\"1471646837\",\"name\":\"K. Zhu\"},{\"authorId\":\"2098601\",\"name\":\"Jiaqi Gu\"},{\"authorId\":\"28908836\",\"name\":\"Linxiao Shen\"},{\"authorId\":\"2145419\",\"name\":\"X. Tang\"},{\"authorId\":\"153726321\",\"name\":\"N. Sun\"},{\"authorId\":\"1681705\",\"name\":\"D. Pan\"}],\"doi\":\"10.23919/DATE48585.2020.9116330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1024d357193969bab399ef48eb07137d46a51fe8\",\"title\":\"Towards Decrypting the Art of Analog Layout: Placement Quality Prediction via Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/1024d357193969bab399ef48eb07137d46a51fe8\",\"venue\":\"2020 Design, Automation & Test in Europe Conference & Exhibition (DATE)\",\"year\":2020},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993259\",\"name\":\"Song-Le Chen\"},{\"authorId\":\"47039312\",\"name\":\"X. Zhao\"},{\"authorId\":\"143943645\",\"name\":\"Zhe Sun\"},{\"authorId\":\"143813312\",\"name\":\"F. Xiang\"},{\"authorId\":\"3261741\",\"name\":\"Z. Sun\"}],\"doi\":\"10.1007/978-3-030-24271-8_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66df2053faf9778aa14d81851f585cafec202b63\",\"title\":\"Shape Recognition with Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/66df2053faf9778aa14d81851f585cafec202b63\",\"venue\":\"ICAIS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2186316\",\"name\":\"H. Chen\"},{\"authorId\":\"3102340\",\"name\":\"Mingcong Song\"},{\"authorId\":\"9693830\",\"name\":\"J. Zhao\"},{\"authorId\":\"145279386\",\"name\":\"Yuting Dai\"},{\"authorId\":null,\"name\":\"Tao Li\"}],\"doi\":\"10.1145/3307650.3322260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0ad728e01d83ff880bd63735a0fc2156e908fd53\",\"title\":\"3D-based Video Recognition Acceleration by Leveraging Temporal Locality\",\"url\":\"https://www.semanticscholar.org/paper/0ad728e01d83ff880bd63735a0fc2156e908fd53\",\"venue\":\"2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)\",\"year\":2019},{\"arxivId\":\"1905.02540\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"607048b431cea997ae9dd01f029a73c502d0273f\",\"title\":\"Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/607048b431cea997ae9dd01f029a73c502d0273f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.03579\",\"authors\":[{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2820254\",\"name\":\"Eirina Bourtsoulatze\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3023597\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"title\":\"Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing\",\"url\":\"https://www.semanticscholar.org/paper/5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.11755\",\"authors\":[{\"authorId\":\"1780642035\",\"name\":\"Mohammad Zaki Zadeh\"},{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"47589592\",\"name\":\"Ashish Jaiswal\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f3836b9243086c715f348c9758966c25430b894\",\"title\":\"Self-Supervised Human Activity Recognition by Augmenting Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f3836b9243086c715f348c9758966c25430b894\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453104568\",\"name\":\"P. Rajpurkar\"},{\"authorId\":\"31659673\",\"name\":\"Allison Park\"},{\"authorId\":\"1453116587\",\"name\":\"Jeremy A. Irvin\"},{\"authorId\":\"1517032702\",\"name\":\"Chris Chute\"},{\"authorId\":\"1517037139\",\"name\":\"Michael Bereket\"},{\"authorId\":\"1517049123\",\"name\":\"Domenico Mastrodicasa\"},{\"authorId\":\"2356307\",\"name\":\"C. Langlotz\"},{\"authorId\":\"4204731\",\"name\":\"M. Lungren\"},{\"authorId\":\"144110208\",\"name\":\"A. C. Ng\"},{\"authorId\":\"5485740\",\"name\":\"B. Patel\"}],\"doi\":\"10.1038/s41598-020-61055-6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"209fe25bdf47cb194a464842c6ee9134873aaca9\",\"title\":\"AppendiXNet: Deep Learning for Diagnosis of Appendicitis from A Small Dataset of CT Exams Using Video Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/209fe25bdf47cb194a464842c6ee9134873aaca9\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":\"2008.03800\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1486442460\",\"name\":\"Tianjian Meng\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"3154495\",\"name\":\"H. Wang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1387716705\",\"name\":\"Yin Cui\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"title\":\"Spatiotemporal Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020}],\"corpusId\":4539700,\"doi\":\"10.1109/CVPR.2018.00685\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":129,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"references\":[{\"arxivId\":\"1711.10305\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.590\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"024d037d46ae933c7e12fd16af61953c7161773a\",\"title\":\"Learning Spatio-Temporal Representation with Pseudo-3D Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/024d037d46ae933c7e12fd16af61953c7161773a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2017.502\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1708.07632\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICCVW.2017.373\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":false,\"paperId\":\"07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"title\":\"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1609.08675\",\"authors\":[{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"144317839\",\"name\":\"Nisarg Kothari\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"title\":\"YouTube-8M: A Large-Scale Video Classification Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1611.05431\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2017.634\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"title\":\"Aggregated Residual Transformations for Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f6e0856b4a9199fa968ac00da612a9407b5cb85c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1608.06993\",\"authors\":[{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":null,\"name\":\"Zhuang Liu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"}],\"doi\":\"10.1109/CVPR.2017.243\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"title\":\"Densely Connected Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5694e46284460a648fe29117cbc55f6c9be3fa3c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1605.07146\",\"authors\":[{\"authorId\":\"2134433\",\"name\":\"Sergey Zagoruyko\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"}],\"doi\":\"10.5244/C.30.87\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"1c4e9156ca07705531e45960b7a919dc473abb51\",\"title\":\"Wide Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c4e9156ca07705531e45960b7a919dc473abb51\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145557639\",\"name\":\"V. Nair\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a538b05ebb01a40323997629e171c91aa28b8e2f\",\"title\":\"Rectified Linear Units Improve Restricted Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/a538b05ebb01a40323997629e171c91aa28b8e2f\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2017.787\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1708.05038\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":null,\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"title\":\"ConvNet Architecture Search for Spatiotemporal Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/a92adfdd8996ab2bd7cdc910ea1d3db03c66d34f\",\"venue\":\"ArXiv\",\"year\":2017}],\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"topics\":[{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"3D computer graphics\",\"topicId\":\"100829\",\"url\":\"https://www.semanticscholar.org/topic/100829\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Kinesiology\",\"topicId\":\"113188\",\"url\":\"https://www.semanticscholar.org/topic/113188\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Test set\",\"topicId\":\"24168\",\"url\":\"https://www.semanticscholar.org/topic/24168\"},{\"topic\":\"Code\",\"topicId\":\"595\",\"url\":\"https://www.semanticscholar.org/topic/595\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Kinetics Internet Protocol\",\"topicId\":\"3591972\",\"url\":\"https://www.semanticscholar.org/topic/3591972\"}],\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018}\n"