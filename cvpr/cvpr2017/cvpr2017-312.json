"{\"abstract\":\"We learn models to generate the immediate future in video. This problem has two main challenges. Firstly, since the future is uncertain, models should be multi-modal, which can be difficult to learn. Secondly, since the future is similar to the past, models store low-level details, which complicates learning of high-level semantics. We propose a framework to tackle both of these challenges. We present a model that generates the future by transforming pixels in the past. Our approach explicitly disentangles the models memory from the prediction, which helps the model learn desirable invariances. Experiments suggest that this model can generate short videos of plausible futures. We believe predictive models have many applications in robotics, health-care, and video understanding.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\",\"url\":\"https://www.semanticscholar.org/author/1856025\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\",\"url\":\"https://www.semanticscholar.org/author/143805211\"}],\"citationVelocity\":37,\"citations\":[{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48f3640cbf9747083a07790a9c7a8089f9131cbd\",\"title\":\"HARMONIZING MAXIMUM LIKELIHOOD WITH GANS\",\"url\":\"https://www.semanticscholar.org/paper/48f3640cbf9747083a07790a9c7a8089f9131cbd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.08922\",\"authors\":[{\"authorId\":\"51998809\",\"name\":\"Serkan Sulun\"},{\"authorId\":\"1747853\",\"name\":\"A. Tekalp\"}],\"doi\":\"10.1007/s11760-020-01751-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2d5ea0bc35cc76fb4aa2b7eb1f7616b42a87651\",\"title\":\"Can Learned Frame-Prediction Compete with Block-Motion Compensation for Video Coding?\",\"url\":\"https://www.semanticscholar.org/paper/e2d5ea0bc35cc76fb4aa2b7eb1f7616b42a87651\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.02992\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1609/aaai.v33i01.33013510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1bb03b7c37bea7536eb62d5db7a8462dc992777\",\"title\":\"Controllable Image-to-Video Translation: A Case Study on Facial Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/e1bb03b7c37bea7536eb62d5db7a8462dc992777\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1803.09760\",\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69f7045d901dab5e949948a16beb89a4b0b38c15\",\"title\":\"Predicting the Future with Transformational States\",\"url\":\"https://www.semanticscholar.org/paper/69f7045d901dab5e949948a16beb89a4b0b38c15\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.10946\",\"authors\":[{\"authorId\":\"51998809\",\"name\":\"Serkan Sulun\"}],\"doi\":\"10.13140/RG.2.2.28590.54085\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a2c27a3fcf88ae9b518d71e29c4c3e25ae71d23\",\"title\":\"Deep Learned Frame Prediction for Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/7a2c27a3fcf88ae9b518d71e29c4c3e25ae71d23\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2ae2633d5addd3dac975345e72b66dc6300020f\",\"title\":\"Generative modelling and adversarial learning\",\"url\":\"https://www.semanticscholar.org/paper/b2ae2633d5addd3dac975345e72b66dc6300020f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.12363\",\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1388389416\",\"name\":\"Cosmin George Alexandru\"},{\"authorId\":\"36145068\",\"name\":\"Marius Marinel St\\u0103nescu\"},{\"authorId\":\"1388389422\",\"name\":\"Octavian Pascu\"},{\"authorId\":\"1387471255\",\"name\":\"Alexandru Magan\"},{\"authorId\":\"1859313\",\"name\":\"Adrian Postelnicu\"},{\"authorId\":\"1700021\",\"name\":\"Horia Cucu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3f6fba03f90fb6b052b7b069ec2a6189074f2616\",\"title\":\"The Quo Vadis submission at Traffic4cast 2019\",\"url\":\"https://www.semanticscholar.org/paper/3f6fba03f90fb6b052b7b069ec2a6189074f2616\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.02749\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"69869231\",\"name\":\"R. Pottorf\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a7ae2b9dbc825407ccf67a5e6c9e2a857766d75\",\"title\":\"Video Interpolation and Prediction with Unsupervised Landmarks\",\"url\":\"https://www.semanticscholar.org/paper/8a7ae2b9dbc825407ccf67a5e6c9e2a857766d75\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5685594\",\"name\":\"G. Lorre\"},{\"authorId\":\"2962220\",\"name\":\"J. Rabarisoa\"},{\"authorId\":\"19258632\",\"name\":\"A. Orcesi\"},{\"authorId\":\"2910432\",\"name\":\"Samia Ainouz\"},{\"authorId\":\"10451773\",\"name\":\"St\\u00e9phane Canu\"}],\"doi\":\"10.1109/WACV45572.2020.9093278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90f84c25039d6c69bd25e70c719251aeacc50978\",\"title\":\"Temporal Contrastive Pretraining for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90f84c25039d6c69bd25e70c719251aeacc50978\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1912.12773\",\"authors\":[{\"authorId\":\"88726258\",\"name\":\"Karl Schmeckpeper\"},{\"authorId\":\"14484808\",\"name\":\"Annie Xie\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"71692259\",\"name\":\"Stephen Tian\"},{\"authorId\":\"1751586\",\"name\":\"Kostas Daniilidis\"},{\"authorId\":\"1381906625\",\"name\":\"Sergey Levine\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"}],\"doi\":\"10.1007/978-3-030-58565-5_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"title\":\"Learning Predictive Models From Observation and Interaction\",\"url\":\"https://www.semanticscholar.org/paper/124ec2c95bc0fe417be2bb0d0701f88583d6a16a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1901.03728\",\"authors\":[{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"66572445\",\"name\":\"Mahdieh Izadpanahkakhk\"},{\"authorId\":\"66760000\",\"name\":\"E. Omrani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37fd19e135c065659875e2e824a455ad56689507\",\"title\":\"Anticipation and next action forecasting in video: an end-to-end model with memory\",\"url\":\"https://www.semanticscholar.org/paper/37fd19e135c065659875e2e824a455ad56689507\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102509914\",\"name\":\"Radamanthys Stivaktakis\"},{\"authorId\":\"47952527\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"1694755\",\"name\":\"P. Tsakalides\"}],\"doi\":\"10.3390/make2030017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3d8366c5186914be2cfbf43a6457df6d83db861\",\"title\":\"Semantic Predictive Coding with Arbitrated Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d3d8366c5186914be2cfbf43a6457df6d83db861\",\"venue\":\"Mach. Learn. Knowl. Extr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49415643\",\"name\":\"Y. Wang\"},{\"authorId\":\"46696648\",\"name\":\"L. Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2018.00557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"title\":\"Temporal Hallucinating for Action Recognition with Few Still Images\",\"url\":\"https://www.semanticscholar.org/paper/1b8b9332886ea661e5a46bb87118956f1f4c15f3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.10666\",\"authors\":[{\"authorId\":\"3306760\",\"name\":\"Hsu-Kuang Chiu\"},{\"authorId\":\"3419364\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/LRA.2020.2992184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73c28cef6c0d58b101204609137af39c3e94c047\",\"title\":\"Segmenting the Future\",\"url\":\"https://www.semanticscholar.org/paper/73c28cef6c0d58b101204609137af39c3e94c047\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392265907\",\"name\":\"V\\u00e9ronique Prinet\"}],\"doi\":\"10.1109/ICIP.2019.8803620\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ce3a4efc6e3f9bc8280c2074ec3f079ba69376c\",\"title\":\"Domain-Agnostic Video Prediction from Motion Selective Kernels\",\"url\":\"https://www.semanticscholar.org/paper/4ce3a4efc6e3f9bc8280c2074ec3f079ba69376c\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1904.09412\",\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018263\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c970f99e844f774236511a40bf43b8950dde339f\",\"title\":\"Cubic LSTMs for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c970f99e844f774236511a40bf43b8950dde339f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.04430\",\"authors\":[{\"authorId\":\"3121735\",\"name\":\"Paritosh Parmar\"},{\"authorId\":\"49059658\",\"name\":\"B. Morris.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7aef63bbe103760e78f359223e35562cdaed16c1\",\"title\":\"HalluciNet-ing Spatiotemporal Representations Using 2D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7aef63bbe103760e78f359223e35562cdaed16c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yumei Wang\"},{\"authorId\":\"19285052\",\"name\":\"C. Li\"},{\"authorId\":\"1401890077\",\"name\":\"Hanyu Shan\"},{\"authorId\":null,\"name\":\"Dawei Zhang\"},{\"authorId\":\"143872544\",\"name\":\"T. Jiang\"}],\"doi\":\"10.1109/PIERS-Fall48861.2019.9021348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0d6f53d94deac23a37bfda7d7e1c196ee725ba4\",\"title\":\"A New Method of System-level EMC Evaluation Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/f0d6f53d94deac23a37bfda7d7e1c196ee725ba4\",\"venue\":\"2019 Photonics & Electromagnetics Research Symposium - Fall (PIERS - Fall)\",\"year\":2019},{\"arxivId\":\"1806.06003\",\"authors\":[{\"authorId\":\"3331786\",\"name\":\"Markus Wulfmeier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"51cb2116c5a32d076f54b1a192cf4e850390f665\",\"title\":\"On Machine Learning and Structure for Mobile Robots\",\"url\":\"https://www.semanticscholar.org/paper/51cb2116c5a32d076f54b1a192cf4e850390f665\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.06106\",\"authors\":[{\"authorId\":\"50644949\",\"name\":\"M. Yilmaz\"},{\"authorId\":\"1747853\",\"name\":\"A. Tekalp\"}],\"doi\":\"10.1109/ICIP.2019.8803624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cd30d93802ac0e886452ca6821a389b201fc251\",\"title\":\"Effect of Architectures and Training Methods on the Performance of Learned Video Frame Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3cd30d93802ac0e886452ca6821a389b201fc251\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145031814\",\"name\":\"J. Walker\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"title\":\"Data-Driven Visual Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/66af27ae7c29f5fadf83f29b710a1b9c89987d09\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"2998590\",\"name\":\"Paul Vernaza\"}],\"doi\":\"10.1007/978-3-030-01261-8_47\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a36530e30b34f4f057b097dfbb952c794ec52f41\",\"title\":\"r2p2: A ReparameteRized Pushforward Policy for Diverse, Precise Generative Path Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/a36530e30b34f4f057b097dfbb952c794ec52f41\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.00892\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00560\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"title\":\"When will you do what? - Anticipating Temporal Occurrences of Activities\",\"url\":\"https://www.semanticscholar.org/paper/33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35060007\",\"name\":\"A. Sagel\"},{\"authorId\":\"144417576\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15088d16873c83f738d3023917211ba5fbfcd9f8\",\"title\":\"Linearizing Visual Processes with Convolutional Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/15088d16873c83f738d3023917211ba5fbfcd9f8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e98a7f4e73f49248c912b141c43031a241d4ac33\",\"title\":\"Self-supervised learning of predictive segmentation models from video. (Apprentissage autosupervis\\u00e9 de mod\\u00e8les pr\\u00e9dictifs de segmentation \\u00e0 partir de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/e98a7f4e73f49248c912b141c43031a241d4ac33\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.00684\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"144391743\",\"name\":\"R. Kirby\"},{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"2924393\",\"name\":\"D. Tarjan\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01234-2_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"title\":\"SDC-Net: Video Prediction Using Spatially-Displaced Convolution\",\"url\":\"https://www.semanticscholar.org/paper/c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.09755\",\"authors\":[{\"authorId\":\"1754382\",\"name\":\"Yijun Li\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"145574672\",\"name\":\"Xin Lu\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01240-3_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27680266bcfa3febb1a1537180a83129d2be4834\",\"title\":\"Flow-Grounded Spatial-Temporal Video Prediction from Still Images\",\"url\":\"https://www.semanticscholar.org/paper/27680266bcfa3febb1a1537180a83129d2be4834\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1902.09225\",\"authors\":[{\"authorId\":\"31273037\",\"name\":\"Soochan Lee\"},{\"authorId\":\"36078919\",\"name\":\"J. Ha\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dc02a63400c4f1899c952afdc620479238abedf\",\"title\":\"Harmonizing Maximum Likelihood with GANs for Multimodal Conditional Generation\",\"url\":\"https://www.semanticscholar.org/paper/0dc02a63400c4f1899c952afdc620479238abedf\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1710.00421\",\"authors\":[{\"authorId\":\"2664705\",\"name\":\"Y. Li\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144752689\",\"name\":\"David Edwin Carlson\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"title\":\"Video Generation From Text\",\"url\":\"https://www.semanticscholar.org/paper/3a2bbf1f895a1850da3bb6d92b4ffbe61b68145d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144650675\",\"name\":\"M. Tang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"7737775\",\"name\":\"Yifeng He\"}],\"doi\":\"10.1007/978-3-030-00776-8_53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f49c1aef8ef2385ee9f4481f3bd35f4d0540e9d8\",\"title\":\"Adaptive Hierarchical Motion-Focused Model for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f49c1aef8ef2385ee9f4481f3bd35f4d0540e9d8\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1908.06217\",\"authors\":[{\"authorId\":\"8806222\",\"name\":\"Carlo Innamorati\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"},{\"authorId\":\"145794288\",\"name\":\"D. Kaufman\"},{\"authorId\":\"1710455\",\"name\":\"N. Mitra\"}],\"doi\":\"10.1109/ICCV.2019.00881\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ea024b69849e80cb0e3de35ba1d5725fa41595c\",\"title\":\"Neural Re-Simulation for Generating Bounces in Single Images\",\"url\":\"https://www.semanticscholar.org/paper/4ea024b69849e80cb0e3de35ba1d5725fa41595c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.04149\",\"authors\":[{\"authorId\":\"14506569\",\"name\":\"S. Wang\"},{\"authorId\":\"2212690\",\"name\":\"Justin Lazarow\"},{\"authorId\":\"2668978\",\"name\":\"Kwonjoon Lee\"},{\"authorId\":\"47744833\",\"name\":\"Zhuowen Tu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"133fc14499b24a51c5f1f80e033ab2094ebff504\",\"title\":\"Unaligned Image-to-Sequence Transformation with Loop Consistency\",\"url\":\"https://www.semanticscholar.org/paper/133fc14499b24a51c5f1f80e033ab2094ebff504\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.09905\",\"authors\":[{\"authorId\":\"146270823\",\"name\":\"Beibei Jin\"},{\"authorId\":\"1943030\",\"name\":\"Y. Hu\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"66692321\",\"name\":\"Jingyu Niu\"},{\"authorId\":\"144578811\",\"name\":\"Z. Shi\"},{\"authorId\":\"152713339\",\"name\":\"Yinhe Han\"},{\"authorId\":\"40613624\",\"name\":\"Xiaowei Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00461\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a280048e69d41750c42d6f96e451e75c52c07741\",\"title\":\"Exploring Spatial-Temporal Multi-Frequency Analysis for High-Fidelity and Temporal-Consistency Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a280048e69d41750c42d6f96e451e75c52c07741\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.05037\",\"authors\":[{\"authorId\":\"2327234\",\"name\":\"Alexander Bihlo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76d6302efc2a75d71639eb263bdac4bc384d44fb\",\"title\":\"Precipitation nowcasting using a stochastic variational frame predictor with learned prior distribution\",\"url\":\"https://www.semanticscholar.org/paper/76d6302efc2a75d71639eb263bdac4bc384d44fb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2178958\",\"name\":\"Yueqi Duan\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"72315096\",\"name\":\"Wenzhao Zheng\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/TIP.2019.2948472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b77b74caffad07ad35784122c55f699fd0f90a36\",\"title\":\"Deep Adversarial Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/b77b74caffad07ad35784122c55f699fd0f90a36\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.04231\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"title\":\"Relational Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50024168\",\"name\":\"Yitong Li\"},{\"authorId\":\"5477477\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":null,\"name\":\"Dinghan Shen\"},{\"authorId\":null,\"name\":\"David Carlson\"},{\"authorId\":\"145006560\",\"name\":\"Lawrence Carin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"13cdaa567cee45a83bd47cad047c591e04336d0c\",\"title\":\"\\u223c N ( 0 , 1 ) Video Generator Video Discriminator Real ? Fake ?\",\"url\":\"https://www.semanticscholar.org/paper/13cdaa567cee45a83bd47cad047c591e04336d0c\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"},{\"authorId\":null,\"name\":\"Xiaogang Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Tgt . ( a ) GT sequence ( b ) ImagineFlow ( c ) Backward warping Before After\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1802.06869\",\"authors\":[{\"authorId\":\"49027577\",\"name\":\"Yunfei Teng\"},{\"authorId\":\"3216141\",\"name\":\"A. Choromanska\"},{\"authorId\":\"3146322\",\"name\":\"M. Bojarski\"}],\"doi\":\"10.3390/computation7020020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8010e17774e81de1ea91cfd5dbb653995be1837\",\"title\":\"Invertible Autoencoder for domain adaptation\",\"url\":\"https://www.semanticscholar.org/paper/c8010e17774e81de1ea91cfd5dbb653995be1837\",\"venue\":\"Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19235216\",\"name\":\"Zekun Hao\"},{\"authorId\":\"47932904\",\"name\":\"Xun Huang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/CVPR.2018.00819\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d629ee73070e7c693ae6924aa52df129a127b33\",\"title\":\"Controllable Video Generation with Sparse Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/9d629ee73070e7c693ae6924aa52df129a127b33\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.12185\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1007/978-3-030-58568-6_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61b166040abff8309e23d804551fc3d3acc833f6\",\"title\":\"Action Localization through Continual Predictive Learning\",\"url\":\"https://www.semanticscholar.org/paper/61b166040abff8309e23d804551fc3d3acc833f6\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ae02e601eae125ce137324c678ab68e9ab272ea0\",\"title\":\"Self-supervised learning of predictive segmentation models from video\",\"url\":\"https://www.semanticscholar.org/paper/ae02e601eae125ce137324c678ab68e9ab272ea0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2011.08614\",\"authors\":[{\"authorId\":\"1729222937\",\"name\":\"P. Sreekar\"},{\"authorId\":\"121701447\",\"name\":\"U. Tiwari\"},{\"authorId\":\"3185334\",\"name\":\"A. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a391f92d0479295f24043bc388ce5bd292fab0e5\",\"title\":\"Mutual Information Based Method for Unsupervised Disentanglement of Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/a391f92d0479295f24043bc388ce5bd292fab0e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.01523\",\"authors\":[{\"authorId\":\"49250083\",\"name\":\"Alex X. Lee\"},{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"title\":\"Stochastic Adversarial Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f67271a1edea3bf80c64c2d54e2a0a57612a567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"2388085\",\"name\":\"M. K\\u00f6rner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fc9b202107bafa4b755c913c904d8ab046b8113\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing Autoencoder GANs\",\"url\":\"https://www.semanticscholar.org/paper/0fc9b202107bafa4b755c913c904d8ab046b8113\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46213138\",\"name\":\"Minyoung Huh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa7405a3ac4487ab44a9098b8f315931159a017\",\"title\":\"Temporal Scene Completion with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3fa7405a3ac4487ab44a9098b8f315931159a017\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153920582\",\"name\":\"Luk\\u00e1s Neumann\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPRW.2019.00354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"title\":\"Future Event Prediction: If and When\",\"url\":\"https://www.semanticscholar.org/paper/4eea7f5b0e1365eb7f7354626cc2acb3701e84d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/TPAMI.2018.2873794\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"title\":\"First-Person Activity Forecasting from Video with Online Inverse Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/008085275d5c1b7f0cc2631c9eae3d015ed244ca\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2178958\",\"name\":\"Yueqi Duan\"},{\"authorId\":\"72315096\",\"name\":\"Wenzhao Zheng\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00294\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80ba35906f48f3bf95268b1b9da7995466cf3251\",\"title\":\"Deep Adversarial Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/80ba35906f48f3bf95268b1b9da7995466cf3251\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1812.04558\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"title\":\"Grounded Human-Object Interaction Hotspots From Video\",\"url\":\"https://www.semanticscholar.org/paper/316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66438378\",\"name\":\"Kongtao Zhu\"},{\"authorId\":\"3300934\",\"name\":\"Xiwei Liu\"},{\"authorId\":\"27391286\",\"name\":\"Hongxue Yang\"}],\"doi\":\"10.1109/CAC.2018.8623645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f571725ffc18c6249702ab457b287495302a4e68\",\"title\":\"A Survey of Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f571725ffc18c6249702ab457b287495302a4e68\",\"venue\":\"2018 Chinese Automation Congress (CAC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Xiong wxiongwhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b73255bbd31922e6995b3216fba68de9547e3ce6\",\"title\":\"Mini-proposal Understanding Videos with Low Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/b73255bbd31922e6995b3216fba68de9547e3ce6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1903.00913\",\"authors\":[{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"47093626\",\"name\":\"Jiaming Guo\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"545f3b0c15a0a555fda0d2377646c0c70090c185\",\"title\":\"Unsupervised Bi-directional Flow-based Video Generation from one Snapshot\",\"url\":\"https://www.semanticscholar.org/paper/545f3b0c15a0a555fda0d2377646c0c70090c185\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.09092\",\"authors\":[{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"1681089\",\"name\":\"S. Palazzo\"},{\"authorId\":\"1403265508\",\"name\":\"Salvatore D\\u2019Oro\"},{\"authorId\":\"2004177\",\"name\":\"F. Murabito\"},{\"authorId\":\"35906202\",\"name\":\"D. Giordano\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eacba5e8fbafb1302866c0860fc260a2bdfff232\",\"title\":\"VOS-GAN: Adversarial Learning of Visual-Temporal Dynamics for Unsupervised Dense Prediction in Videos\",\"url\":\"https://www.semanticscholar.org/paper/eacba5e8fbafb1302866c0860fc260a2bdfff232\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1709.07592\",\"authors\":[{\"authorId\":\"39272336\",\"name\":\"W. Xiong\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2018.00251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87a818723a2ada66a1193baf17b0383d9766781b\",\"title\":\"Learning to Generate Time-Lapse Videos Using Multi-stage Dynamic Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/87a818723a2ada66a1193baf17b0383d9766781b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35494343\",\"name\":\"Pranjal Sahu\"},{\"authorId\":\"33830021\",\"name\":\"D. Yu\"},{\"authorId\":\"1780708\",\"name\":\"K. Yager\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"145199626\",\"name\":\"H. Qin\"}],\"doi\":\"10.1145/3217197.3217204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc4b1a6ac94d3af019d4a0db089cafa6b5c701cb\",\"title\":\"In-Operando Tracking and Prediction of Transition in Material System using LSTM\",\"url\":\"https://www.semanticscholar.org/paper/dc4b1a6ac94d3af019d4a0db089cafa6b5c701cb\",\"venue\":\"AI-Science@HPDC\",\"year\":2018},{\"arxivId\":\"1904.03273\",\"authors\":[{\"authorId\":\"10386960\",\"name\":\"Nazanin Mehrasa\"},{\"authorId\":\"72388323\",\"name\":\"Akash Abdu Jyothi\"},{\"authorId\":\"2375749\",\"name\":\"T. Durand\"},{\"authorId\":\"50775044\",\"name\":\"Jiawei He\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2019.00328\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89583143a04d7f02a45e0831a4fc55eaf090573c\",\"title\":\"A Variational Auto-Encoder Model for Stochastic Point Processes\",\"url\":\"https://www.semanticscholar.org/paper/89583143a04d7f02a45e0831a4fc55eaf090573c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1109/IJCNN.2019.8852090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a525e9553fdbaec7648bb64e97d8865be07c526\",\"title\":\"Directional Attention based Video Frame Prediction using Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a525e9553fdbaec7648bb64e97d8865be07c526\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12360172\",\"name\":\"T. Rotondo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1083e3977cc5c9784ac3d953179277c36e4c223\",\"title\":\"Multi-sensor Data Fusion for Wearable Devices\",\"url\":\"https://www.semanticscholar.org/paper/a1083e3977cc5c9784ac3d953179277c36e4c223\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1710.11252\",\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"143775101\",\"name\":\"R. Campbell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"title\":\"Stochastic Variational Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/59d86da5c5936e7a236678bf5eaaa7753c226fb1\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1810.01325\",\"authors\":[{\"authorId\":\"51466944\",\"name\":\"Sandra Aigner\"},{\"authorId\":\"119567230\",\"name\":\"Marco Korner\"}],\"doi\":\"10.5194/isprs-archives-xlii-2-w16-3-2019\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"title\":\"FutureGAN: Anticipating the Future Frames of Video Sequences using Spatio-Temporal 3d Convolutions in Progressively Growing GANs\",\"url\":\"https://www.semanticscholar.org/paper/b6cad0b0ffd5d7b5ec1db60173c194ae2a9ec947\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1802.06822\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01219-9_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"title\":\"Online Detection of Action Start in Untrimmed, Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144620586\",\"name\":\"X. Wu\"},{\"authorId\":\"144024533\",\"name\":\"Kun Xu\"},{\"authorId\":\"144003456\",\"name\":\"P. Hall\"}],\"doi\":\"10.23919/TST.2017.8195348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"722514cf193ea8b301475de9da5a0061f2e47bdd\",\"title\":\"A survey of image synthesis and editing with generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/722514cf193ea8b301475de9da5a0061f2e47bdd\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22803355\",\"name\":\"Beibei Jin\"},{\"authorId\":\"144985887\",\"name\":\"Y. Hu\"},{\"authorId\":\"145492828\",\"name\":\"Y. Zeng\"},{\"authorId\":\"31431435\",\"name\":\"Qiankun Tang\"},{\"authorId\":\"32758259\",\"name\":\"Shice Liu\"},{\"authorId\":\"144030865\",\"name\":\"Jing Ye\"}],\"doi\":\"10.1109/IROS.2018.8594264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9431e81519d16c87859a55bb1735f61a9e013f7e\",\"title\":\"VarNet: Exploring Variations for Unsupervised Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9431e81519d16c87859a55bb1735f61a9e013f7e\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d5d85a741f7926d8774e037c57a245ae6c94356\",\"title\":\"Online Action Detection in Untrimmed, Streaming Videos - Modeling and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/2d5d85a741f7926d8774e037c57a245ae6c94356\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"82619398\",\"name\":\"P. D'Oro\"},{\"authorId\":\"1390194542\",\"name\":\"D. Giordano\"},{\"authorId\":\"147598837\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s11263-019-01246-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d50b45969bef86bf29bcaf9052beade2282fa094\",\"title\":\"Adversarial Framework for Unsupervised Learning of Motion Dynamics in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d50b45969bef86bf29bcaf9052beade2282fa094\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-20870-7_42\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ac8807838df5ff426e47e5ffc3eea10d3b103e8\",\"title\":\"Predicting Video Frames Using Feature Based Locally Guided Objectives\",\"url\":\"https://www.semanticscholar.org/paper/5ac8807838df5ff426e47e5ffc3eea10d3b103e8\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"115939427\",\"name\":\"R. Campbell\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d4841ad9dd4caaec61b5921950df477d7b75b2b\",\"title\":\"S Tochastic V Ariational V Ideo P Rediction\",\"url\":\"https://www.semanticscholar.org/paper/0d4841ad9dd4caaec61b5921950df477d7b75b2b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.10666\",\"authors\":[{\"authorId\":\"3306760\",\"name\":\"Hsu-Kuang Chiu\"},{\"authorId\":\"46408185\",\"name\":\"Ehsan Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"119131638\",\"name\":\"Stanford\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"73c28cef6c0d58b101204609137af39c3e94c047\",\"title\":\"Video Frames Output : Future Semantic Segmentation Semantic Segmentation Forecasting Input : Past Video Frames Output : Future Semantic Segmentation Semantic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/73c28cef6c0d58b101204609137af39c3e94c047\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.08635\",\"authors\":[{\"authorId\":\"49006120\",\"name\":\"Osamu Shouno\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a274a36cd1d4f2562f92d8e32cb8e72db3993f21\",\"title\":\"Photo-Realistic Video Prediction on Natural Videos of Largely Changing Frames\",\"url\":\"https://www.semanticscholar.org/paper/a274a36cd1d4f2562f92d8e32cb8e72db3993f21\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47506758\",\"name\":\"Q. Wu\"},{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"50293996\",\"name\":\"Zhongyi Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"}],\"doi\":\"10.1109/icme46284.2020.9102876\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4e87129ff7cc33a09f6ac6f0291c5d7fcda2c6a\",\"title\":\"Generating Future Frames with Mask-Guided Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c4e87129ff7cc33a09f6ac6f0291c5d7fcda2c6a\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.10157\",\"authors\":[{\"authorId\":\"3234769\",\"name\":\"V. Prinet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3b934bc47fd6c0adedaaab9e694b64336899317\",\"title\":\"Motion Selective Prediction for Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c3b934bc47fd6c0adedaaab9e694b64336899317\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.06827\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145794288\",\"name\":\"D. Kaufman\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b39399b1b7c8d2950109b645552439a712913bf1\",\"title\":\"Bounce and Learn: Modeling Scene Dynamics with Real-World Bounces\",\"url\":\"https://www.semanticscholar.org/paper/b39399b1b7c8d2950109b645552439a712913bf1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3460423\",\"name\":\"Yichao Yan\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"1780882\",\"name\":\"W. Zhang\"},{\"authorId\":\"49763212\",\"name\":\"J. Tang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"}],\"doi\":\"10.1016/J.CVIU.2019.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23633493bc7bd73116adfe922991aef3f0201b4a\",\"title\":\"Cross-modality motion parameterization for fine-grained video prediction\",\"url\":\"https://www.semanticscholar.org/paper/23633493bc7bd73116adfe922991aef3f0201b4a\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.07461\",\"authors\":[{\"authorId\":\"26393556\",\"name\":\"Ayush Jaiswal\"},{\"authorId\":\"17806729\",\"name\":\"Wael AbdAlmageed\"},{\"authorId\":\"41205922\",\"name\":\"Yue Wu\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":\"10.1007/978-3-030-20893-6_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a02184707247a79a236a03f85ab35d99a68be33\",\"title\":\"Bidirectional Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/0a02184707247a79a236a03f85ab35d99a68be33\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1807.06980\",\"authors\":[{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33240704f9efc39f75b4229983c2e10a56ca609f\",\"title\":\"Video Time: Properties, Encoders and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/33240704f9efc39f75b4229983c2e10a56ca609f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbe18855b85bc6f218c53993cf289e2607518b1\",\"title\":\"Learning Policies to Forecast Agent Behavior with Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/6dbe18855b85bc6f218c53993cf289e2607518b1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"144530691\",\"name\":\"Lili Wan\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1145/3343031.3351073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13bf8def0af5ce1883d3d046b4c48ee6153d6241\",\"title\":\"Prediction-CGAN: Human Action Prediction with Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/13bf8def0af5ce1883d3d046b4c48ee6153d6241\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1806.04166\",\"authors\":[{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d38ee16ed990689c3a85160dbc20e22b72afb6d\",\"title\":\"Learning to Decompose and Disentangle Representations for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1d38ee16ed990689c3a85160dbc20e22b72afb6d\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1712.09867\",\"authors\":[{\"authorId\":\"48152297\",\"name\":\"W. Liu\"},{\"authorId\":\"2074878\",\"name\":\"Weixin Luo\"},{\"authorId\":\"35180251\",\"name\":\"Dongze Lian\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00684\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a6acba7fb2aad1299fcf35701417e063d410ed4\",\"title\":\"Future Frame Prediction for Anomaly Detection - A New Baseline\",\"url\":\"https://www.semanticscholar.org/paper/8a6acba7fb2aad1299fcf35701417e063d410ed4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144371270\",\"name\":\"M. Kumar\"},{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46573521\",\"name\":\"Laurent Dinh\"},{\"authorId\":\"70429380\",\"name\":\"Durk Kingma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c740302dddf0e54c50c43110716f987edd73329b\",\"title\":\"VideoFlow: A Flow-Based Generative Model for Video\",\"url\":\"https://www.semanticscholar.org/paper/c740302dddf0e54c50c43110716f987edd73329b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50676103\",\"name\":\"Yash Agarwal\"},{\"authorId\":\"1658817894\",\"name\":\"Devansh Batra\"},{\"authorId\":\"2080658\",\"name\":\"Ganesh Bagler\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97c0e33c260aec7a68f6fc17a31de4094d5eb283\",\"title\":\"Building Hierarchically Disentangled Language Models for Text Generation with Named Entities\",\"url\":\"https://www.semanticscholar.org/paper/97c0e33c260aec7a68f6fc17a31de4094d5eb283\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1774721\",\"name\":\"Cong Phuoc Huynh\"},{\"authorId\":\"3244141\",\"name\":\"A. Ciptadi\"},{\"authorId\":\"36183106\",\"name\":\"Ambrish Tyagi\"},{\"authorId\":\"145972497\",\"name\":\"Amit Agrawal\"}],\"doi\":\"10.1007/978-3-030-11015-4_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25b683ffcdb5c7676713f945d5baead4d9e4a4dd\",\"title\":\"CRAFT: Complementary Recommendation by Adversarial Feature Transform\",\"url\":\"https://www.semanticscholar.org/paper/25b683ffcdb5c7676713f945d5baead4d9e4a4dd\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4188929861988cd5c9c7ed063926f2c0c86f3f86\",\"title\":\"VIDEOFLOW: A CONDITIONAL FLOW-BASED MODEL\",\"url\":\"https://www.semanticscholar.org/paper/4188929861988cd5c9c7ed063926f2c0c86f3f86\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2208488\",\"name\":\"Bernhard Kratzwald\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"71879671\",\"name\":\"A. Dinesh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0b936f643f7462068517e0a840e775d6bd4abfb\",\"title\":\"Improving Video Generation for Multi-functional Applications.\",\"url\":\"https://www.semanticscholar.org/paper/d0b936f643f7462068517e0a840e775d6bd4abfb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1802.07687\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de3b9eb697feed3d097e3f671afe395f48c1ab76\",\"title\":\"Stochastic Video Generation with a Learned Prior\",\"url\":\"https://www.semanticscholar.org/paper/de3b9eb697feed3d097e3f671afe395f48c1ab76\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"1906.10101\",\"authors\":[{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":null,\"name\":\"Yitong Li\"},{\"authorId\":\"152283180\",\"name\":\"W. Cao\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"52395103\",\"name\":\"Q. Wei\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3daa80501c69508dbb681cb8d70c7fae744548a8\",\"title\":\"LMVP: Video Predictor with Leaked Motion Information\",\"url\":\"https://www.semanticscholar.org/paper/3daa80501c69508dbb681cb8d70c7fae744548a8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.11453\",\"authors\":[{\"authorId\":\"2208488\",\"name\":\"Bernhard Kratzwald\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"571b04fc6e624b730f9c924e33a2cf6ea8049992\",\"title\":\"Towards an Understanding of Our World by GANing Videos in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/571b04fc6e624b730f9c924e33a2cf6ea8049992\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2012.09855\",\"authors\":[{\"authorId\":\"2926666\",\"name\":\"A. Liu\"},{\"authorId\":\"4129805\",\"name\":\"R. Tucker\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"2159982\",\"name\":\"A. Makadia\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"20615377\",\"name\":\"A. Kanazawa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"714143e49c3476bf1aa4e6d0454151e6ab490be3\",\"title\":\"Infinite Nature: Perpetual View Generation of Natural Scenes from a Single Image\",\"url\":\"https://www.semanticscholar.org/paper/714143e49c3476bf1aa4e6d0454151e6ab490be3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.01434\",\"authors\":[{\"authorId\":\"153792767\",\"name\":\"M. Kumar\"},{\"authorId\":\"3365707\",\"name\":\"M. Babaeizadeh\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"46573521\",\"name\":\"Laurent Dinh\"},{\"authorId\":\"70429380\",\"name\":\"Durk Kingma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a78bc54068384d9ea6f07db89a1ce902ef56c2c6\",\"title\":\"VideoFlow: A Conditional Flow-Based Model for Stochastic Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/a78bc54068384d9ea6f07db89a1ce902ef56c2c6\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.10734\",\"authors\":[{\"authorId\":\"2023002\",\"name\":\"William Lotter\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"145679323\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"672942fb74cfec39977190b48438300126142a91\",\"title\":\"A neural network trained to predict future video frames mimics critical properties of biological neuronal responses and perception\",\"url\":\"https://www.semanticscholar.org/paper/672942fb74cfec39977190b48438300126142a91\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"}],\"doi\":\"10.1109/TMM.2019.2946475\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0cd4513409f0e4942dc5890d2530ddeda1b800e\",\"title\":\"Uni-and-Bi-Directional Video Prediction via Learning Object-Centric Transformation\",\"url\":\"https://www.semanticscholar.org/paper/e0cd4513409f0e4942dc5890d2530ddeda1b800e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49287389\",\"name\":\"L. Xu\"}],\"doi\":\"10.1109/JAS.2019.1911603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d4f5533756d37373b5fe09d8714257a032b8182\",\"title\":\"An overview and perspectives on bidirectional intelligence: Lmser duality, double IA harmony, and causal computation\",\"url\":\"https://www.semanticscholar.org/paper/4d4f5533756d37373b5fe09d8714257a032b8182\",\"venue\":\"IEEE/CAA Journal of Automatica Sinica\",\"year\":2019},{\"arxivId\":\"2003.04035\",\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"40550616\",\"name\":\"D. Casas\"},{\"authorId\":\"2895238\",\"name\":\"Yotam Doron\"},{\"authorId\":\"51042571\",\"name\":\"Albin Cassirer\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"title\":\"Transformation-based Adversarial Video Prediction on Large-Scale Data\",\"url\":\"https://www.semanticscholar.org/paper/e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.05827\",\"authors\":[{\"authorId\":\"32970572\",\"name\":\"Kuo-Hao Zeng\"},{\"authorId\":\"41187419\",\"name\":\"Bokui (William) Shen\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2017.326\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c5cbbdaa76e10106c4ea12a17826bec88e5efc3\",\"title\":\"Visual Forecasting by Imitating Dynamics in Natural Sequences\",\"url\":\"https://www.semanticscholar.org/paper/9c5cbbdaa76e10106c4ea12a17826bec88e5efc3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.10871\",\"authors\":[{\"authorId\":\"1774721\",\"name\":\"Cong Phuoc Huynh\"},{\"authorId\":\"41021334\",\"name\":\"Arri Ciptadi\"},{\"authorId\":\"36183106\",\"name\":\"Ambrish Tyagi\"},{\"authorId\":\"145972497\",\"name\":\"Amit Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a90e44814b6a2780445169ad14dc791d5b4c7e2d\",\"title\":\"CRAFT: Complementary Recommendations Using Adversarial Feature Transformer\",\"url\":\"https://www.semanticscholar.org/paper/a90e44814b6a2780445169ad14dc791d5b4c7e2d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"29be236bb68e503a6df6bb4932984fbca5452669\",\"title\":\"Learning, Moving, And Predicting With Global Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/29be236bb68e503a6df6bb4932984fbca5452669\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143804836\",\"name\":\"Ruibing Hou\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/FG.2019.8756585\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88cb11aecad56a2af1dd46e994746cd7a19c5902\",\"title\":\"Video Prediction with Bidirectional Constraint Network\",\"url\":\"https://www.semanticscholar.org/paper/88cb11aecad56a2af1dd46e994746cd7a19c5902\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23982870\",\"name\":\"Badour Albahar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6ef158d95042f39765df04373c01546524c9ccd\",\"title\":\"Im2Vid: Future Video Prediction for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b6ef158d95042f39765df04373c01546524c9ccd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-11015-4_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92592480ff60ed8bdf068c90bf614c1d7a8c0eb8\",\"title\":\"Context Graph Based Video Frame Prediction Using Locally Guided Objective\",\"url\":\"https://www.semanticscholar.org/paper/92592480ff60ed8bdf068c90bf614c1d7a8c0eb8\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66073991\",\"name\":\"Edoardo Alati\"},{\"authorId\":\"65770249\",\"name\":\"L. Mauro\"},{\"authorId\":\"2368860\",\"name\":\"Valsamis Ntouskos\"},{\"authorId\":\"1695016\",\"name\":\"F. Pirri\"}],\"doi\":\"10.1109/ICIP.2019.8803155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1069d9cc11006078dfb9ed76bc2c44379ae325f\",\"title\":\"Help by Predicting What to Do\",\"url\":\"https://www.semanticscholar.org/paper/c1069d9cc11006078dfb9ed76bc2c44379ae325f\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40379799\",\"name\":\"Nirvana Pillay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"94fee2e20b39d747db68ae9daa4f0767d0a7bffb\",\"title\":\"Conceptualization of a GAN for future frame prediction\",\"url\":\"https://www.semanticscholar.org/paper/94fee2e20b39d747db68ae9daa4f0767d0a7bffb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121654636\",\"name\":\"Yuxin Hou\"},{\"authorId\":\"31255274\",\"name\":\"Hongxun Yao\"},{\"authorId\":\"102625994\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"51258443\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3340463\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6888287d7bfbdd83474103e08477ea2de2df4ba2\",\"title\":\"Soul Dancer\",\"url\":\"https://www.semanticscholar.org/paper/6888287d7bfbdd83474103e08477ea2de2df4ba2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1803.00657\",\"authors\":[{\"authorId\":\"2518211\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"},{\"authorId\":\"143901532\",\"name\":\"X. Yao\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TEVC.2019.2895748\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbca46c24c800bee41b21ac0258651db54892e80\",\"title\":\"Evolutionary Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/cbca46c24c800bee41b21ac0258651db54892e80\",\"venue\":\"IEEE Transactions on Evolutionary Computation\",\"year\":2019},{\"arxivId\":\"1907.08845\",\"authors\":[{\"authorId\":\"71563120\",\"name\":\"Junyan Wang\"},{\"authorId\":\"145726327\",\"name\":\"BingZhang Hu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"48953082\",\"name\":\"Y. Guan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c799bd32890aad031032b0391f024e5042887097\",\"title\":\"Order Matters: Shuffling Sequence Generation for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c799bd32890aad031032b0391f024e5042887097\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2002.09219\",\"authors\":[{\"authorId\":\"35622441\",\"name\":\"Jean-Yves Franceschi\"},{\"authorId\":\"32278921\",\"name\":\"Edouard Delasalles\"},{\"authorId\":\"51301828\",\"name\":\"Mickael Chen\"},{\"authorId\":\"1782552\",\"name\":\"Sylvain Lamprier\"},{\"authorId\":\"150259685\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"title\":\"Stochastic Latent Residual Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e277ba39f761dcfbdc6efc40b2b89492566f3477\",\"venue\":\"ICML\",\"year\":2020}],\"corpusId\":8234308,\"doi\":\"10.1109/CVPR.2017.319\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"}],\"doi\":\"10.1109/CVPR.2015.7298744\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0e6e543307679a1de67989b91777bc5b8c95462\",\"title\":\"Discovering states and transformations in image collections\",\"url\":\"https://www.semanticscholar.org/paper/b0e6e543307679a1de67989b91777bc5b8c95462\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"title\":\"Anticipating Visual Representations from Unlabeled Video\",\"url\":\"https://www.semanticscholar.org/paper/932ac3707e1ed84ab67526692a1ef8f064f24ab5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00295\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/ICCV.2015.281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"title\":\"Dense Optical Flow Prediction from a Static Image\",\"url\":\"https://www.semanticscholar.org/paper/098fa9b4c3f7fb41c7a178d36f5dbb50a3ffa377\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.06434\",\"authors\":[{\"authorId\":\"38909097\",\"name\":\"A. Radford\"},{\"authorId\":\"2096458\",\"name\":\"Luke Metz\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8388f1be26329fa45e5807e968a641ce170ea078\",\"title\":\"Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8388f1be26329fa45e5807e968a641ce170ea078\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1403025868\",\"name\":\"Jean Pouget-Abadie\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"144738865\",\"name\":\"Bing Xu\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"1955694\",\"name\":\"Sherjil Ozair\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"title\":\"Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/54e325aee6b2d476bbbb88615ac15e251c6e8214\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1610.00527\",\"authors\":[{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b01871c114b122340209562972ff515b86b16ccf\",\"title\":\"Video Pixel Networks\",\"url\":\"https://www.semanticscholar.org/paper/b01871c114b122340209562972ff515b86b16ccf\",\"venue\":\"ICML\",\"year\":2017},{\"arxivId\":\"1505.05192\",\"authors\":[{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/ICCV.2015.167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"title\":\"Unsupervised Visual Representation Learning by Context Prediction\",\"url\":\"https://www.semanticscholar.org/paper/fc1b1c9364c58ec406f494dd944b609a6a038ba6\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1705557\",\"name\":\"K. Fragkiadaki\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"2986395\",\"name\":\"Panna Felsen\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/ICCV.2015.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ec7433aeb4777e7d5c903920ae945e5429d3bc4\",\"title\":\"Recurrent Network Models for Human Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/1ec7433aeb4777e7d5c903920ae945e5429d3bc4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1506.02025\",\"authors\":[{\"authorId\":\"3093886\",\"name\":\"Max Jaderberg\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"title\":\"Spatial Transformer Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe87ea16d5eb1c7509da9a0314bbf4c7b0676506\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1410.3916\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71ae756c75ac89e2d731c9c79649562b5768ff39\",\"title\":\"Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/71ae756c75ac89e2d731c9c79649562b5768ff39\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1608.07724\",\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/978-3-319-46484-8_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bf3b2a5591f2a2f0c648dc5a1f4ff3bd6b9102a\",\"title\":\"Learning Temporal Transformations from Time-Lapse Videos\",\"url\":\"https://www.semanticscholar.org/paper/5bf3b2a5591f2a2f0c648dc5a1f4ff3bd6b9102a\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1503.01817\",\"authors\":[{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"2532460\",\"name\":\"B. Elizalde\"},{\"authorId\":\"36845351\",\"name\":\"Karl Ni\"},{\"authorId\":\"143669214\",\"name\":\"D. Poland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"},{\"authorId\":\"118220290\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/2812802\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"title\":\"YFCC100M: the new data in multimedia research\",\"url\":\"https://www.semanticscholar.org/paper/354c029c88be2bbc27dfd2e2e729c0ae622511e6\",\"venue\":\"Commun. ACM\",\"year\":2016},{\"arxivId\":\"1608.07017\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-319-46448-0_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"title\":\"Ambient Sound Provides Supervision for Visual Learning\",\"url\":\"https://www.semanticscholar.org/paper/93a87dfa72f22fba14ef243a62c7d0a6906dfed7\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46448-0_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"title\":\"Shuffle and Learn: Unsupervised Learning Using Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/6d4e3616d0b27957c4107ae877dc0dd4504b69ab\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1505.02206\",\"authors\":[{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2015.166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c426ba865e9158a0f7962a86a50575aa943051b1\",\"title\":\"Learning Image Representations Tied to Ego-Motion\",\"url\":\"https://www.semanticscholar.org/paper/c426ba865e9158a0f7962a86a50575aa943051b1\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455017\",\"name\":\"Yipin Zhou\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.511\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"title\":\"Temporal Perception and Prediction in Ego-Centric Video\",\"url\":\"https://www.semanticscholar.org/paper/d12c567768b401f8d7f1ad532a2b23320ca29b49\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.07379\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1109/CVPR.2016.278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"title\":\"Context Encoders: Feature Learning by Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/7d0effebfa4bed19b6ba41f3af5b7e5b6890de87\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.6856\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"title\":\"Object Detectors Emerge in Deep Scene CNNs\",\"url\":\"https://www.semanticscholar.org/paper/9f3e5169a19df9bbfc91bf8eab8543594530f3cd\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1505.00687\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2015.320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"title\":\"Unsupervised Learning of Visual Representations Using Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d4ff172c2d1820f33c0c72286d52b846ab5a216\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056091\",\"name\":\"M. Everingham\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145715698\",\"name\":\"C. K. Williams\"},{\"authorId\":\"33652486\",\"name\":\"J. Winn\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-009-0275-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82635fb63640ae95f90ee9bdc07832eb461ca881\",\"title\":\"The Pascal Visual Object Classes (VOC) Challenge\",\"url\":\"https://www.semanticscholar.org/paper/82635fb63640ae95f90ee9bdc07832eb461ca881\",\"venue\":\"International Journal of Computer Vision\",\"year\":2009},{\"arxivId\":\"1411.1784\",\"authors\":[{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"title\":\"Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/353ecf7b66b3e9ff5e9f41145a147e899a2eea5c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1112.6209\",\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"145834163\",\"name\":\"Kai Chen\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1109/ICASSP.2013.6639343\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72e93aa6767ee683de7f001fa72f1314e40a8f35\",\"title\":\"Building high-level features using large scale unsupervised learning\",\"url\":\"https://www.semanticscholar.org/paper/72e93aa6767ee683de7f001fa72f1314e40a8f35\",\"venue\":\"2013 IEEE International Conference on Acoustics, Speech and Signal Processing\",\"year\":2013},{\"arxivId\":\"1511.01844\",\"authors\":[{\"authorId\":\"2073063\",\"name\":\"L. Theis\"},{\"authorId\":\"3422336\",\"name\":\"A. Oord\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39e0c341351f8f4a39ac890b96217c7f4bde5369\",\"title\":\"A note on the evaluation of generative models\",\"url\":\"https://www.semanticscholar.org/paper/39e0c341351f8f4a39ac890b96217c7f4bde5369\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"title\":\"End-To-End Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/4f10b9f47c5bb6b54dd4f5ca8d9fa2c0bbd7ec5e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1605.08104\",\"authors\":[{\"authorId\":\"2023002\",\"name\":\"William Lotter\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"},{\"authorId\":\"145679323\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad367b44f3434b9ba6b46b41ab083210f6827a9f\",\"title\":\"Deep Predictive Coding Networks for Video Prediction and Unsupervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad367b44f3434b9ba6b46b41ab083210f6827a9f\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1506.03134\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"39067762\",\"name\":\"Meire Fortunato\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9653d5c2c7844347343d073bbedd96e05d52f69b\",\"title\":\"Pointer Networks\",\"url\":\"https://www.semanticscholar.org/paper/9653d5c2c7844347343d073bbedd96e05d52f69b\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1603.05631\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46493-0_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c763df6843aba88d7fb3ab3c55a5937a5f39276\",\"title\":\"Generative Image Modeling Using Style and Structure Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c763df6843aba88d7fb3ab3c55a5937a5f39276\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1606.07873\",\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-46478-7_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"title\":\"An Uncertain Future: Forecasting from Static Images Using Variational Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/5e96c4626e4b3d09727bcbfbdb2672dd9b886743\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1603.09439\",\"authors\":[{\"authorId\":\"1879100\",\"name\":\"P. Nguyen\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"title\":\"The Open World of Micro-Videos\",\"url\":\"https://www.semanticscholar.org/paper/f631f754afc9a82fa7a5e5a70eac37376c7379ef\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143928130\",\"name\":\"J. Walker\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2014.416\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"title\":\"Patch to the Future: Unsupervised Visual Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cc0bb8f933e514dd9441e3082a34a9f129e35500\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1505.00315\",\"authors\":[{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/ICCV.2015.508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16fdd6d842475e6fbe58fc809beabbed95f0642e\",\"title\":\"Learning Temporal Embeddings for Complex Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/16fdd6d842475e6fbe58fc809beabbed95f0642e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3197570\",\"name\":\"Chao-Yeh Chen\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"title\":\"Watching Unlabeled Video Helps Learn New Human Actions from Very Few Labeled Snapshots\",\"url\":\"https://www.semanticscholar.org/paper/db0b7b99bf25fda8673ab169ce8c1d7cb70ff8a6\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.15607/RSS.2013.IX.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e6907faab99d8304e9dc5baf05d5e5aca28737a1\",\"title\":\"Anticipating Human Activities using Object Affordances for Reactive Robotic Response\",\"url\":\"https://www.semanticscholar.org/paper/e6907faab99d8304e9dc5baf05d5e5aca28737a1\",\"venue\":\"Robotics: Science and Systems\",\"year\":2013},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143738177\",\"name\":\"J. Yuen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-642-15552-9_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed01c2706c1dd05de8664bee1e42a628a49480ad\",\"title\":\"A Data-Driven Approach for Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ed01c2706c1dd05de8664bee1e42a628a49480ad\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1753269\",\"name\":\"Brian D. Ziebart\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-642-33765-9_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d8a5addbd17d2c7c8043d8877234675da19938a\",\"title\":\"Activity Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/0d8a5addbd17d2c7c8043d8877234675da19938a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1511.07122\",\"authors\":[{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"145231047\",\"name\":\"V. Koltun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"title\":\"Multi-Scale Context Aggregation by Dilated Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7f5fc84819c0cf94b771fe15141f65b123f7b8ec\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1512.08512\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"2324658\",\"name\":\"J. McDermott\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2016.264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"title\":\"Visually Indicated Sounds\",\"url\":\"https://www.semanticscholar.org/paper/ac640c2d0f33fb3ab49f37b26982948fc31e3191\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.04166\",\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/CVPR.2016.179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5952835e5e57ce3d5b5f3f851f852aeb3e47d96\",\"title\":\"Unsupervised Learning of Edges\",\"url\":\"https://www.semanticscholar.org/paper/f5952835e5e57ce3d5b5f3f851f852aeb3e47d96\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.05751\",\"authors\":[{\"authorId\":\"40081727\",\"name\":\"Emily L. Denton\"},{\"authorId\":\"2127604\",\"name\":\"Soumith Chintala\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"title\":\"Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/47900aca2f0b50da3010ad59b394c870f0e6c02e\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3232655\",\"name\":\"H. Mobahi\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1145/1553374.1553469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2c477de72bb7718f5304c6f38457fda9c8334b1\",\"title\":\"Deep learning from temporal coherence in video\",\"url\":\"https://www.semanticscholar.org/paper/e2c477de72bb7718f5304c6f38457fda9c8334b1\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016}],\"title\":\"Generating the Future with Adversarial Transformers\",\"topics\":[{\"topic\":\"Transformers\",\"topicId\":\"927204\",\"url\":\"https://www.semanticscholar.org/topic/927204\"},{\"topic\":\"Robotics\",\"topicId\":\"2759\",\"url\":\"https://www.semanticscholar.org/topic/2759\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Predictive modelling\",\"topicId\":\"38565\",\"url\":\"https://www.semanticscholar.org/topic/38565\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Futures and promises\",\"topicId\":\"21431\",\"url\":\"https://www.semanticscholar.org/topic/21431\"}],\"url\":\"https://www.semanticscholar.org/paper/6d2892f82a89bfc81f9924adb8bd070fe007adf7\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"