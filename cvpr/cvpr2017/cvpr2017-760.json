"{\"abstract\":\"Effective image and sentence matching depends on how to well measure their global visual-semantic similarity. Based on the observation that such a global similarity arises from a complex aggregation of multiple local similarities between pairwise instances of image (objects) and sentence (words), we propose a selective multimodal Long Short-Term Memory network (sm-LSTM) for instance-aware image and sentence matching. The sm-LSTM includes a multimodal context-modulated attention scheme at each timestep that can selectively attend to a pair of instances of image and sentence, by predicting pairwise instance-aware saliency maps for image and sentence. For selected pairwise instances, their representations are obtained based on the predicted saliency maps, and then compared to measure their local similarity. By similarly measuring multiple local similarities within a few timesteps, the sm-LSTM sequentially aggregates them with hidden states to obtain a final matching score as the desired global similarity. Extensive experiments show that our model can well match image and sentence with complex content, and achieve the state-of-the-art results on two public benchmark datasets.\",\"arxivId\":\"1611.05588\",\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\",\"url\":\"https://www.semanticscholar.org/author/49867037\"},{\"authorId\":null,\"name\":\"Wei Wang\",\"url\":null},{\"authorId\":null,\"name\":\"Liang Wang\",\"url\":null}],\"citationVelocity\":37,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.1145/3372278.3390674\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"title\":\"Forward and Backward Multimodal NMT for Improved Monolingual and Multilingual Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2004.09144\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8185538174d9f751125407cad3687994ff08fadb\",\"title\":\"Transformer Reasoning Network for Image-Text Matching and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8185538174d9f751125407cad3687994ff08fadb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.10348\",\"authors\":[{\"authorId\":\"8815141\",\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e16de062b9cdeecfcbda0de022f1fc4e741a2e6\",\"title\":\"Learning Visually-Grounded Semantics from Contrastive Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/3e16de062b9cdeecfcbda0de022f1fc4e741a2e6\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1906.01205\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"}],\"doi\":\"10.18653/v1/P19-2023\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"edd200e1e18794202c3a55a810717e87be7b7dba\",\"title\":\"A Strong and Robust Baseline for Text-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/edd200e1e18794202c3a55a810717e87be7b7dba\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1909.02701\",\"authors\":[{\"authorId\":\"49243413\",\"name\":\"Kunpeng Li\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"47003439\",\"name\":\"Yuanyuan Li\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/ICCV.2019.00475\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"title\":\"Visual Semantic Reasoning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/26500af6bb97bf2dab1cc14dfb3b8b08fef67940\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3348635\",\"name\":\"Haoran Wang\"},{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1007/978-3-030-00764-5_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d37d6b75a1578f4f5bc3cab7e42ca2bc976f0b58\",\"title\":\"Cross-Modal Retrieval with Discriminative Dual-Path CNN\",\"url\":\"https://www.semanticscholar.org/paper/d37d6b75a1578f4f5bc3cab7e42ca2bc976f0b58\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41017837\",\"name\":\"Zhuobin Zheng\"},{\"authorId\":\"80414744\",\"name\":\"Youcheng Ben\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"title\":\"Multi-Scale Visual Semantics Aggregation with Self-Attention for End-to-End Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"venue\":\"ACML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"144019476\",\"name\":\"M. Lopes\"},{\"authorId\":\"41050099\",\"name\":\"Martin D. More\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/WACV.2018.00207\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"185e7191dc5eca046d90205527da597b6ba9ae3c\",\"title\":\"Fast Self-Attentive Multimodal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/185e7191dc5eca046d90205527da597b6ba9ae3c\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1909.09953\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b488019592d8e0c08e6cd011ae0543a6ac451357\",\"title\":\"Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators\",\"url\":\"https://www.semanticscholar.org/paper/b488019592d8e0c08e6cd011ae0543a6ac451357\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.05535\",\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"40a943746d3a6156f9ca477e437263c7841118ac\",\"title\":\"Dual-Path Convolutional Image-Text Embedding\",\"url\":\"https://www.semanticscholar.org/paper/40a943746d3a6156f9ca477e437263c7841118ac\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3323873.3325043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"title\":\"Improving What Cross-Modal Retrieval Models Learn through Object-Oriented Inter- and Intra-Modal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868596\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-01246-5_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a86eb42952412ee02e3f6da06f874f1946eff6b\",\"title\":\"Deep Cross-Modal Projection Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a86eb42952412ee02e3f6da06f874f1946eff6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144128023\",\"name\":\"Youcai Zhang\"},{\"authorId\":\"49986789\",\"name\":\"Yiwei Gu\"},{\"authorId\":null,\"name\":\"Xiaodong Gu\"}],\"doi\":\"10.1007/978-3-030-01418-6_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be23d7493c3b1aaf3cbc160358e53335f502d1cb\",\"title\":\"Two-Stream Convolutional Neural Network for Multimodal Matching\",\"url\":\"https://www.semanticscholar.org/paper/be23d7493c3b1aaf3cbc160358e53335f502d1cb\",\"venue\":\"ICANN\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75409785b6b6e7fee81489cc5db731c1718dbd3e\",\"title\":\"GRU Encoder Word Embeddings Fusing with MLP Predicted Word : Vase\",\"url\":\"https://www.semanticscholar.org/paper/75409785b6b6e7fee81489cc5db731c1718dbd3e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454388\",\"name\":\"Saemi Choi\"},{\"authorId\":\"143892374\",\"name\":\"Shun Matsumura\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"}],\"doi\":\"10.1145/3323873.3325037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"625a85f85e67ea48535af743d048dda773c048da\",\"title\":\"Assist Users' Interactions in Font Search with Unexpected but Useful Concepts Generated by Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/625a85f85e67ea48535af743d048dda773c048da\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120897486\",\"name\":\"Anwen Hu\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"title\":\"ICECAP: Information Concentrated Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50077572\",\"name\":\"Zheng Yu\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682424\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2af1f3ef29f6e66a31b879eab5d58f5861394da4\",\"title\":\"Multi-step Self-attention Network for Cross-modal Retrieval Based on a Limited Text Space\",\"url\":\"https://www.semanticscholar.org/paper/2af1f3ef29f6e66a31b879eab5d58f5861394da4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2081209\",\"name\":\"Kuang-Jui Hsu\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1109/CVPR.2019.00905\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff74e1866a7397462cef8e35145bde9135e015aa\",\"title\":\"DeepCO3: Deep Instance Co-Segmentation by Co-Peak Search and Co-Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/ff74e1866a7397462cef8e35145bde9135e015aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/tcyb.2020.2985716\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"758890bef9a1a85a25a1f6831a58f00a462476af\",\"title\":\"SMAN: Stacked Multimodal Attention Network for Cross-Modal Image-Text Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/758890bef9a1a85a25a1f6831a58f00a462476af\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1705203\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2018.8545064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ad37f14f42125cd3cdc0326d59e4d227a2468ed\",\"title\":\"Aligning Text and Document Illustrations: Towards Visually Explainable Digital Humanities\",\"url\":\"https://www.semanticscholar.org/paper/5ad37f14f42125cd3cdc0326d59e4d227a2468ed\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1863856\",\"name\":\"Kaimin Wei\"},{\"authorId\":\"2392310\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2996407\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"title\":\"Adversarial Attentive Multi-Modal Embedding Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1909.01976\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"1688013\",\"name\":\"F. Shafait\"}],\"doi\":\"10.1109/ICCVW.2019.00551\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"title\":\"Do Cross Modal Systems Leverage Semantic Relationships?\",\"url\":\"https://www.semanticscholar.org/paper/5d965a354bd3a96c7b3117fd332bd3ebf736fe0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9927990\",\"name\":\"Armand Vilalta\"},{\"authorId\":\"1389953200\",\"name\":\"Dario Garcia-Gasulla\"},{\"authorId\":\"144954447\",\"name\":\"Ferran Par\\u00e9s\"},{\"authorId\":\"1744495\",\"name\":\"E. Ayguad\\u00e9\"},{\"authorId\":\"1699563\",\"name\":\"J. Labarta\"},{\"authorId\":\"1401454398\",\"name\":\"Eduardo Ulises Moya-S\\u00e1nchez\"},{\"authorId\":\"1742700\",\"name\":\"U. Cort\\u00e9s\"}],\"doi\":\"10.3233/SW-180341\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0d7662d98dc9e10d5496a55c0f77461285351a8\",\"title\":\"Studying the impact of the Full-Network embedding on multimodal pipelines\",\"url\":\"https://www.semanticscholar.org/paper/e0d7662d98dc9e10d5496a55c0f77461285351a8\",\"venue\":\"Semantic Web\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52205400\",\"name\":\"Vikram Sharma Mailthody\"},{\"authorId\":\"52209305\",\"name\":\"Zaid Qureshi\"},{\"authorId\":\"151253861\",\"name\":\"Weixin Liang\"},{\"authorId\":\"9402167\",\"name\":\"Ziyan Feng\"},{\"authorId\":\"2192182\",\"name\":\"Simon Garcia De Gonzalo\"},{\"authorId\":\"50024633\",\"name\":\"Youjie Li\"},{\"authorId\":\"1771872\",\"name\":\"H. Franke\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"117578373\",\"name\":\"J. Huang\"},{\"authorId\":\"1723122\",\"name\":\"Wen-Mei Hwu\"}],\"doi\":\"10.1145/3352460.3358320\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"522beabcb6e0a8bb5b6b6badfb4bd27071fe926a\",\"title\":\"DeepStore: In-Storage Acceleration for Intelligent Queries\",\"url\":\"https://www.semanticscholar.org/paper/522beabcb6e0a8bb5b6b6badfb4bd27071fe926a\",\"venue\":\"MICRO\",\"year\":2019},{\"arxivId\":\"1911.10097\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"},{\"authorId\":\"39742349\",\"name\":\"X. Wang\"},{\"authorId\":\"50341799\",\"name\":\"Shuaipeng Li\"}],\"doi\":\"10.1609/AAAI.V34I07.6823\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c669e7deed061f3e7f110330ecc28e0ed076f8\",\"title\":\"HAL: Improved Text-Image Matching by Mitigating Visual Semantic Hubs\",\"url\":\"https://www.semanticscholar.org/paper/51c669e7deed061f3e7f110330ecc28e0ed076f8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145747299\",\"name\":\"Shaonan Wei\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"46676502\",\"name\":\"Y. Sun\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"}],\"doi\":\"10.1007/978-3-030-31726-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f13152e19d8381b2df13bbd8d4b0718c57635d3d\",\"title\":\"Scenario Referring Expression Comprehension via Attributes of Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/f13152e19d8381b2df13bbd8d4b0718c57635d3d\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112305\",\"name\":\"Chunxiao Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"3181822\",\"name\":\"Wenyu Zang\"},{\"authorId\":null,\"name\":\"Bin Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"title\":\"A Neighbor-aware Approach for Image-text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66880635\",\"name\":\"Angelo Carraggi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-030-11024-6_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"316a266fa464d0963a6156854bac57deac71f586\",\"title\":\"Visual-Semantic Alignment Across Domains Using a Semi-Supervised Approach\",\"url\":\"https://www.semanticscholar.org/paper/316a266fa464d0963a6156854bac57deac71f586\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1904.09471\",\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/ICCV.2019.00585\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d2d1f64a11ca9234716a777dedc962586930a9\",\"title\":\"Saliency-Guided Attention Network for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/a3d2d1f64a11ca9234716a777dedc962586930a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"2750647\",\"name\":\"Zequn Jie\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"40143631\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TCSVT.2019.2916167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"title\":\"Matching Image and Sentence With Multi-Faceted Representations\",\"url\":\"https://www.semanticscholar.org/paper/4f15a43aba873c83f688fe3fd0d11eedb2398a23\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1807.07364\",\"authors\":[{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"51093708\",\"name\":\"Muhammad Kamran Janjua\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"title\":\"Revisiting Cross Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7fe117f5bbf91f85a97720eca8be36da87a5f8a8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1109/DSAA.2019.00029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"title\":\"Cross-Media Image-Text Retrieval Combined with Global Similarity and Local Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"venue\":\"2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49039449\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1703234\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TMM.2020.2972830\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"title\":\"Reasoning on the Relation: Enhancing Visual Representation for Visual Question Answering and Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/CVPR.2018.00805\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"083551c35be43aa3f0cc45408c09ec46b7a239ea\",\"title\":\"Bidirectional Retrieval Made Simple\",\"url\":\"https://www.semanticscholar.org/paper/083551c35be43aa3f0cc45408c09ec46b7a239ea\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1016/j.patcog.2020.107359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"title\":\"Stacked squeeze-and-excitation recurrent residual network for visual-semantic matching\",\"url\":\"https://www.semanticscholar.org/paper/124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2004.01095\",\"authors\":[{\"authorId\":\"1510708452\",\"name\":\"Han Fu\"},{\"authorId\":\"123028363\",\"name\":\"Renji Wu\"},{\"authorId\":\"2039481\",\"name\":\"Chenghao Liu\"},{\"authorId\":\"4346236\",\"name\":\"Jianling Sun\"}],\"doi\":\"10.1109/cvpr42600.2020.01458\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b5114380c1c9b3a2fc849ca74ef44e5d8fec507\",\"title\":\"MCEN: Bridging Cross-Modal Gap between Cooking Recipes and Dish Images with Latent Variable Model\",\"url\":\"https://www.semanticscholar.org/paper/1b5114380c1c9b3a2fc849ca74ef44e5d8fec507\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7415284\",\"name\":\"Y. Jia\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"49830854\",\"name\":\"P. Wang\"},{\"authorId\":\"1805712\",\"name\":\"Jinlin Guo\"},{\"authorId\":\"2248082\",\"name\":\"Yuxiang Xie\"},{\"authorId\":\"145344058\",\"name\":\"Tianyuan Yu\"}],\"doi\":\"10.1007/s11042-018-5692-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2a1866646e29ba6994adecef14757587dd5735\",\"title\":\"Irrelevance reduction with locality-sensitive hash learning for efficient cross-media retrieval\",\"url\":\"https://www.semanticscholar.org/paper/aa2a1866646e29ba6994adecef14757587dd5735\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1809184\",\"name\":\"Z. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2018.00601\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"356c211af3bd0ce664bc2369b8489a43dfcf98a6\",\"title\":\"End-to-End Convolutional Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/356c211af3bd0ce664bc2369b8489a43dfcf98a6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.04011\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350875\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"title\":\"Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7415284\",\"name\":\"Y. Jia\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"49830854\",\"name\":\"P. Wang\"},{\"authorId\":\"1805712\",\"name\":\"Jinlin Guo\"},{\"authorId\":\"2248082\",\"name\":\"Yuxiang Xie\"}],\"doi\":\"10.1007/978-3-319-73603-7_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64caa670a1286cfe73012b1a94111419c72a36bf\",\"title\":\"Deep Convolutional Neural Network for Correlating Images and Sentences\",\"url\":\"https://www.semanticscholar.org/paper/64caa670a1286cfe73012b1a94111419c72a36bf\",\"venue\":\"MMM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/s13735-018-00166-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6305115f393d96df92f9044b8951969e28aa7114\",\"title\":\"Joint embeddings with multimodal cues for video-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6305115f393d96df92f9044b8951969e28aa7114\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30814238\",\"name\":\"W. Wei\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"49958606\",\"name\":\"Heng Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ACCESS.2020.2992187\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bdfb3fde985493fc53c379cb79ef4a5da2977a3\",\"title\":\"Boosting Cross-Modal Retrieval With MVSE++ and Reciprocal Neighbors\",\"url\":\"https://www.semanticscholar.org/paper/7bdfb3fde985493fc53c379cb79ef4a5da2977a3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121789307\",\"name\":\"W. Guo\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"144496860\",\"name\":\"Xiangwei Kong\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":\"10.1145/3343031.3351053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"title\":\"Learning Disentangled Representation for Cross-Modal Retrieval with Deep Mutual Information Estimation\",\"url\":\"https://www.semanticscholar.org/paper/52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1808.07793\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"3000659\",\"name\":\"Evangelos E. Papalexakis\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3240508.3240712\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"title\":\"Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"title\":\"ENGAGING IMAGE CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TPAMI.2017.2701380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2c50f93f6d0892918e0ff653750d198ccab48d0\",\"title\":\"Video Super-Resolution via Bidirectional Recurrent Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/a2c50f93f6d0892918e0ff653750d198ccab48d0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1909.11416\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3343031.3350869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d149507610400ddc2f2b29d9a39f7688b613039\",\"title\":\"Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2d149507610400ddc2f2b29d9a39f7688b613039\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359993\",\"name\":\"Fabian Karl\"},{\"authorId\":\"2388081\",\"name\":\"Mikko Lauri\"},{\"authorId\":\"31565315\",\"name\":\"Chris Biemann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfd1533d49d0213278d3d3301491cbe40f4d100b\",\"title\":\"Creating Information-maximizing Natural Language Messages Through Image Captioning-Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/dfd1533d49d0213278d3d3301491cbe40f4d100b\",\"venue\":\"KONVENS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"2285442\",\"name\":\"M. Xu\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":\"10.1145/3383184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"title\":\"Dual-path Convolutional Image-Text Embeddings with Instance Loss\",\"url\":\"https://www.semanticscholar.org/paper/58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2020.2995815\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"title\":\"Enhancing Cross-Modal Retrieval Based on Modality-Specific and Embedding Spaces\",\"url\":\"https://www.semanticscholar.org/paper/5fcbabfac84c2fcf1e9d4af4d132e18bf6da5ee1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461528\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"46458102\",\"name\":\"L. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"title\":\"CycleMatch: A cycle-consistent embedding network for image-text matching\",\"url\":\"https://www.semanticscholar.org/paper/d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/ICCV.2017.520\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"title\":\"Referring Expression Generation and Comprehension via Attributes\",\"url\":\"https://www.semanticscholar.org/paper/841471bf6f4c980bdb77e712f608ec64f8ad5833\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2397961\",\"name\":\"Qiyue Yin\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"50425438\",\"name\":\"S. Wu\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1007/978-981-10-7302-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1c54b6e34e10b7bb74a6811091822f1daf9426a\",\"title\":\"Learning Shared and Specific Factors for Multi-modal Data\",\"url\":\"https://www.semanticscholar.org/paper/f1c54b6e34e10b7bb74a6811091822f1daf9426a\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152205275\",\"name\":\"Naqash Gerard\"},{\"authorId\":\"2005872978\",\"name\":\"Talha Yousuf\"},{\"authorId\":\"2005751708\",\"name\":\"Ahmed Husnain Johar\"},{\"authorId\":\"3224900\",\"name\":\"Umer Asgher\"},{\"authorId\":\"2005466084\",\"name\":\"Imran Malik\"},{\"authorId\":\"2005198395\",\"name\":\"Adnan ul Hasan\"},{\"authorId\":\"50251237\",\"name\":\"Faisal Shafait\"}],\"doi\":\"10.1007/978-3-030-51041-1_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d321abb4ed74e5e0f17b6e5154ab7e676292409c\",\"title\":\"Detection of Subject Attention in an Active Environment Through Facial Expressions Using Deep Learning Techniques and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/d321abb4ed74e5e0f17b6e5154ab7e676292409c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961512\",\"name\":\"Yi-Ling Wu\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"2847159\",\"name\":\"Guoli Song\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3343031.3350940\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1830b5c741aa93b417e15ca1e26e56dfe83d3ce9\",\"title\":\"Learning Fragment Self-Attention Embeddings for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1830b5c741aa93b417e15ca1e26e56dfe83d3ce9\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1903.11649\",\"authors\":[{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/ICCV.2019.00269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a89cd9056c0fb037d659215b121686ff3b454fd5\",\"title\":\"Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment\",\"url\":\"https://www.semanticscholar.org/paper/a89cd9056c0fb037d659215b121686ff3b454fd5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a26d15d75febf100209cd5d198e8046be9c51f9\",\"title\":\"Re-ranking image-text matching by adaptive metric fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a26d15d75febf100209cd5d198e8046be9c51f9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3343031.3350991\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56e3758cd9acc97f41ed3dbefd66fd76f238e4fb\",\"title\":\"Deep Adversarial Graph Attention Convolution Network for Text-Based Person Search\",\"url\":\"https://www.semanticscholar.org/paper/56e3758cd9acc97f41ed3dbefd66fd76f238e4fb\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.05521\",\"authors\":[{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"98697868\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":null,\"name\":\"Weiwei Sun\"},{\"authorId\":\"1712167\",\"name\":\"W. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2f1b71e1003552afd5420c9a0427269a7c7b454\",\"title\":\"UniVSE: Robust Visual Semantic Embeddings via Structured Semantic Representations\",\"url\":\"https://www.semanticscholar.org/paper/e2f1b71e1003552afd5420c9a0427269a7c7b454\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145662486\",\"name\":\"L. Zhang\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"49721678\",\"name\":\"J. Liu\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"20212496\",\"name\":\"Y. Yang\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1109/TMM.2019.2931352\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93d4d2fabad7c7a7a5bbf8a767e07276f9384aa0\",\"title\":\"Deep Top-$k$ Ranking for Image\\u2013Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/93d4d2fabad7c7a7a5bbf8a767e07276f9384aa0\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1371af87f6d5e22ef6d8c5f9977f5e924f176f6\",\"title\":\"Bidirectional Retrieval Made Simple J\\u00f4natas Wehrmann\",\"url\":\"https://www.semanticscholar.org/paper/e1371af87f6d5e22ef6d8c5f9977f5e924f176f6\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999410\",\"name\":\"Zhibin Hu\"},{\"authorId\":\"40132308\",\"name\":\"Yongsheng Luo\"},{\"authorId\":\"46698321\",\"name\":\"Jiong Lin\"},{\"authorId\":\"144761066\",\"name\":\"Yan Yan\"},{\"authorId\":\"5869774\",\"name\":\"J. Chen\"}],\"doi\":\"10.24963/ijcai.2019/111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10012e6a7a0ad10391533326b95bd1291df6f199\",\"title\":\"Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/10012e6a7a0ad10391533326b95bd1291df6f199\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wenhui Li\"},{\"authorId\":null,\"name\":\"Song Yang\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":null,\"name\":\"Dan Song\"},{\"authorId\":null,\"name\":\"Xuanya Li\"}],\"doi\":\"10.1016/j.ipm.2020.102432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"title\":\"Multi-level similarity learning for image-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2081209\",\"name\":\"Kuang-Jui Hsu\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24bf508131582b478d3941add15bdd096dff2205\",\"title\":\"Supplementary material : DeepCO 3 : Deep Instance Co-segmentation by Co-peak Search and Co-saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/24bf508131582b478d3941add15bdd096dff2205\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471463062\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1522102572\",\"name\":\"Zhen Lei\"},{\"authorId\":\"1415720379\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00359\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"title\":\"Context-Aware Attention Network for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47166189\",\"name\":\"Xiaojing Yu\"},{\"authorId\":\"2648459\",\"name\":\"Tianlong Chen\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1516504563\",\"name\":\"M. Mugo\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/ICCVW.2019.00223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5522c0d74d37ee5e0bca6aae9026cb5994bf7a7d\",\"title\":\"Cross-Modal Person Search: A Coarse-to-Fine Framework using Bi-Directional Text-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/5522c0d74d37ee5e0bca6aae9026cb5994bf7a7d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1711.06420\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"724b253a55e86ad230ba05c7eb78f249e09258d9\",\"title\":\"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/724b253a55e86ad230ba05c7eb78f249e09258d9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"98608166\",\"name\":\"M. Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/TIP.2020.3038354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"title\":\"Deep Relation Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"46389488\",\"name\":\"H. Ma\"}],\"doi\":\"10.1109/ACCESS.2020.2969808\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"title\":\"Combining Global and Local Similarity for Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"145987795\",\"name\":\"M. A. Lopes\"},{\"authorId\":\"145877010\",\"name\":\"Douglas M. Souza\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/ICCV.2019.00590\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"84010f883e9a7283666a6628226016ca4f8d28f1\",\"title\":\"Language-Agnostic Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/84010f883e9a7283666a6628226016ca4f8d28f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2004.00277\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01093\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"title\":\"Graph Structured Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1910.05134\",\"authors\":[{\"authorId\":\"49184936\",\"name\":\"S. Wang\"},{\"authorId\":\"3373117\",\"name\":\"R. Wang\"},{\"authorId\":\"12977859\",\"name\":\"Z. Yao\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/WACV45572.2020.9093614\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c9f1b9e51c1d16c346e1ef679c243d61702a8a80\",\"title\":\"Cross-modal Scene Graph Matching for Relationship-aware Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c9f1b9e51c1d16c346e1ef679c243d61702a8a80\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1910.06514\",\"authors\":[{\"authorId\":\"144872058\",\"name\":\"Takashi Matsubara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"743164e8d89d7d6138ce32ee069489d9097bb816\",\"title\":\"Target-Oriented Deformation of Visual-Semantic Embedding Space\",\"url\":\"https://www.semanticscholar.org/paper/743164e8d89d7d6138ce32ee069489d9097bb816\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491248838\",\"name\":\"Xingyao Zhang\"},{\"authorId\":\"145781464\",\"name\":\"C. Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":\"10.1145/3366423.3380181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22ac5ccdb41ef36d5e29d884817d7aeab237d31b\",\"title\":\"DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment Prediction\",\"url\":\"https://www.semanticscholar.org/paper/22ac5ccdb41ef36d5e29d884817d7aeab237d31b\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1711.08976\",\"authors\":[{\"authorId\":null,\"name\":\"Yi Yu\"},{\"authorId\":\"1764527\",\"name\":\"S. Tang\"},{\"authorId\":\"38811707\",\"name\":\"F. Raposo\"},{\"authorId\":\"49330176\",\"name\":\"Lei Chen\"}],\"doi\":\"10.1145/3281746\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64fd61db1d4736be8f0becc3ecf3c53e620ef810\",\"title\":\"Deep Cross-Modal Correlation Learning for Audio and Lyrics in Music Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/64fd61db1d4736be8f0becc3ecf3c53e620ef810\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.10534\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"93809632\",\"name\":\"Xiang Xu\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCV.2019.00591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"title\":\"Adversarial Representation Learning for Text-to-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.00500\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.01074\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"title\":\"Multi-Task Learning of Hierarchical Vision-Language Representation\",\"url\":\"https://www.semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731827\",\"name\":\"Shuo Wang\"},{\"authorId\":\"144713153\",\"name\":\"Dan Guo\"},{\"authorId\":\"7925966\",\"name\":\"X. Xu\"},{\"authorId\":\"145210913\",\"name\":\"L. Zhuo\"},{\"authorId\":\"73160450\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1145/3314577\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b83d310ab8626d93c175371e480c41978889c2d7\",\"title\":\"Cross-Modality Retrieval by Joint Correlation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b83d310ab8626d93c175371e480c41978889c2d7\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3206025.3206064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9dbca9da6a72ba3739813288b677888a6cf76272\",\"title\":\"Learning Joint Embedding with Multimodal Cues for Cross-Modal Video-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9dbca9da6a72ba3739813288b677888a6cf76272\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1990265392\",\"name\":\"Leigang Qu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413961\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"922d677867e1aa2a7cca05241af4746a0be04dd0\",\"title\":\"Context-Aware Multi-View Summarization Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/922d677867e1aa2a7cca05241af4746a0be04dd0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50025815\",\"name\":\"Yongzhi Li\"},{\"authorId\":\"47845273\",\"name\":\"D. Zhang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/cvpr42600.2020.01280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"title\":\"Visual-Semantic Matching by Exploring High-Order Attention and Distraction\",\"url\":\"https://www.semanticscholar.org/paper/a35fa7f676ec5258d507cfdeb3c3dcda3bc5b0fc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7314814\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1435766877\",\"name\":\"Gu Xiao-peng\"}],\"doi\":\"10.1145/3362065\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0d39fb70393e9a17e5556708852829743380eeed\",\"title\":\"ACMNet: Adaptive Confidence Matching Network for Human Behavior Analysis via Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0d39fb70393e9a17e5556708852829743380eeed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1109/TIP.2017.2698918\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a73405038fdc0d8bf986539ef755a80ebd341e97\",\"title\":\"Conditional High-Order Boltzmann Machines for Supervised Relation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a73405038fdc0d8bf986539ef755a80ebd341e97\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66596988\",\"name\":\"J. Guo\"},{\"authorId\":\"47891446\",\"name\":\"Jing Yu\"},{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"1690665\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-22741-8_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cda7f63f402c025ddff99732e0f286dcafd8c6f4\",\"title\":\"2D-Convolution Based Feature Fusion for Cross-Modal Correlation Learning\",\"url\":\"https://www.semanticscholar.org/paper/cda7f63f402c025ddff99732e0f286dcafd8c6f4\",\"venue\":\"ICCS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2210714\",\"name\":\"Jiabao Zhao\"},{\"authorId\":\"97711464\",\"name\":\"X. Lin\"},{\"authorId\":\"145558445\",\"name\":\"Jie Zhou\"},{\"authorId\":\"49500097\",\"name\":\"Jing Yang\"},{\"authorId\":\"145836226\",\"name\":\"Liang He\"},{\"authorId\":\"40993275\",\"name\":\"Z. Yang\"}],\"doi\":\"10.1109/icme46284.2020.9102809\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f35c620014753c4bbff8f1020d8d7d9d61efaf8\",\"title\":\"Knowledge-Based Fine-Grained Classification For Few-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/8f35c620014753c4bbff8f1020d8d7d9d61efaf8\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2003.03669\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58601-0_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"title\":\"Adaptive Offline Quintuplet Loss for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"145093507\",\"name\":\"Yao Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3300939\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70e80065c4db089c3792245535ecacdca3770577\",\"title\":\"Modality-Invariant Image-Text Embedding for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/70e80065c4db089c3792245535ecacdca3770577\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2001.08179\",\"authors\":[{\"authorId\":\"2944745\",\"name\":\"Xingyao Zhang\"},{\"authorId\":\"2892704\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":\"10.1145/1122445.1122456\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc893c34ac761f70f5eeea3ea6542574dad3c8dc\",\"title\":\"DeepEnroll: Patient-Trial Matching with Deep Embedding and Entailment Prediction\",\"url\":\"https://www.semanticscholar.org/paper/cc893c34ac761f70f5eeea3ea6542574dad3c8dc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118023258\",\"name\":\"X. Wei\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"2694924\",\"name\":\"Y. Li\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"1684705122\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPR42600.2020.01095\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"caabcf61499e00c78d8ee692b8939caf98544a9c\",\"title\":\"Multi-Modality Cross Attention Network for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/caabcf61499e00c78d8ee692b8939caf98544a9c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47987162\",\"name\":\"Hao Wu\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"51437593\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"143872729\",\"name\":\"Weiwei Sun\"},{\"authorId\":\"1712167\",\"name\":\"W. Ma\"}],\"doi\":\"10.1109/CVPR.2019.00677\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"title\":\"Unified Visual-Semantic Embeddings: Bridging Vision and Language With Structured Meaning Representations\",\"url\":\"https://www.semanticscholar.org/paper/08a302f0bb8dc360ae3a0a20fa7b7555920380d4\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.03772\",\"authors\":[{\"authorId\":\"67228310\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"46522306\",\"name\":\"Xudong Liu\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"102551205\",\"name\":\"J. Liu\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/cvpr42600.2020.01267\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a\",\"title\":\"IMRAM: Iterative Matching With Recurrent Attention Memory for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f5a58e715afad8499d90c4855824c6967dbf39\",\"title\":\"Learning Visually Grounded and Multilingual Representations\",\"url\":\"https://www.semanticscholar.org/paper/58f5a58e715afad8499d90c4855824c6967dbf39\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3343031.3350894\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"title\":\"Annotation Efficient Cross-Modal Retrieval with Adversarial Attentive Alignment\",\"url\":\"https://www.semanticscholar.org/paper/b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134342162\",\"name\":\"Li Wen-jie\"},{\"authorId\":\"153697517\",\"name\":\"Y. Zheng\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"},{\"authorId\":\"1878750882\",\"name\":\"Weiguo Fan\"}],\"doi\":\"10.1002/asi.24373\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"title\":\"Cross\\u2010modal retrieval with dual multi\\u2010angle self\\u2010attention\",\"url\":\"https://www.semanticscholar.org/paper/fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"46911598\",\"name\":\"Lin Zuo\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2020.2967597\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"title\":\"Cross-Modal Attention With Semantic Consistence for Image\\u2013Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1906.04402\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/CVPR.2019.00208\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a39d5919531a56de0e36f6b76142041b5d508213\",\"title\":\"Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47012336\",\"name\":\"Xin Fu\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"49339608\",\"name\":\"Yufeng Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/TMM.2019.2957948\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c2195652dddf015880ceacefd811a3df7cae30c\",\"title\":\"Rich Features Embedding for Cross-Modal Retrieval: A Simple Baseline\",\"url\":\"https://www.semanticscholar.org/paper/7c2195652dddf015880ceacefd811a3df7cae30c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1910.03291\",\"authors\":[{\"authorId\":\"1387993874\",\"name\":\"Alireza Mohammadshahi\"},{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"1751802\",\"name\":\"K. Aberer\"}],\"doi\":\"10.18653/v1/D19-6605\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d880af464e477421e5cddc794e971c6db193b8c\",\"title\":\"Aligning Multilingual Word Embeddings for Cross-Modal Retrieval Task\",\"url\":\"https://www.semanticscholar.org/paper/2d880af464e477421e5cddc794e971c6db193b8c\",\"venue\":\"IJCNLP 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"title\":\"ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2397961\",\"name\":\"Qiyue Yin\"},{\"authorId\":\"50425438\",\"name\":\"S. Wu\"},{\"authorId\":\"40476140\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TNNLS.2017.2786743\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6477d29c3e962ef1666f5c2b78412505a5364428\",\"title\":\"Multiview Clustering via Unified and View-Specific Embeddings Learning\",\"url\":\"https://www.semanticscholar.org/paper/6477d29c3e962ef1666f5c2b78412505a5364428\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"2002.10016\",\"authors\":[{\"authorId\":\"52200777\",\"name\":\"Hadi Abdi Khojasteh\"},{\"authorId\":\"31459942\",\"name\":\"Ebrahim Ansari\"},{\"authorId\":\"2671497\",\"name\":\"Parvin Razzaghi\"},{\"authorId\":\"2369481\",\"name\":\"Akbar Karimi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61ee052718bdeae8ab352359bf2828bf7b2b0e45\",\"title\":\"Deep Multimodal Image-Text Embeddings for Automatic Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/61ee052718bdeae8ab352359bf2828bf7b2b0e45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"5057217\",\"name\":\"Takahiro Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ACCESS.2019.2947409\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85dac483e80fb6b1b3bfe8598a2df337856258b1\",\"title\":\"Query is GAN: Scene Retrieval With Attentional Text-to-Image Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/85dac483e80fb6b1b3bfe8598a2df337856258b1\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1387712541\",\"name\":\"Zijin Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1145/3343031.3351055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42001225313e0f5376a8f4b1759e687225cd9d00\",\"title\":\"Cross-Modal Image-Text Retrieval with Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/42001225313e0f5376a8f4b1759e687225cd9d00\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":8039072,\"doi\":\"10.1109/CVPR.2017.767\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":15,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"references\":[{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9aae97e3c67313b32e9fd7882be44ff75e758907\",\"title\":\"An effective regional saliency model based on extended site entropy rate\",\"url\":\"https://www.semanticscholar.org/paper/9aae97e3c67313b32e9fd7882be44ff75e758907\",\"venue\":\"Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3286262\",\"name\":\"M. Chun\"},{\"authorId\":\"47240989\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1111/1467-9280.00168\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83e74b0a256168d871d1f00f64937a53e951f6ef\",\"title\":\"Top-Down Attentional Guidance Based on Implicit Learning of Visual Covariation\",\"url\":\"https://www.semanticscholar.org/paper/83e74b0a256168d871d1f00f64937a53e951f6ef\",\"venue\":\"\",\"year\":1999},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1016/j.tics.2007.09.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb827f0d325b453d8bb2cbf2e7b35dc3833a1f5e\",\"title\":\"The role of context in object recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb827f0d325b453d8bb2cbf2e7b35dc3833a1f5e\",\"venue\":\"Trends in Cognitive Sciences\",\"year\":2007},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2279670\",\"name\":\"Andrea Frome\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aa4069693bee00d1b0759ca3df35e59284e9845\",\"title\":\"DeViSE: A Deep Visual-Semantic Embedding Model\",\"url\":\"https://www.semanticscholar.org/paper/4aa4069693bee00d1b0759ca3df35e59284e9845\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":\"1412.7755\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7845f1d3e796b5704d4bd37a945e0cf3fb8bbf1f\",\"title\":\"Multiple Object Recognition with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7845f1d3e796b5704d4bd37a945e0cf3fb8bbf1f\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"48099761\",\"name\":\"K. Paliwal\"}],\"doi\":\"10.1109/78.650093\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"title\":\"Bidirectional recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e23c34414e66118ecd9b08cf0cd4d016f59b0b85\",\"venue\":\"IEEE Trans. Signal Process.\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TMM.2015.2476658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e7702f8992572dcfabc9262b9d15b82236a0d47\",\"title\":\"Unconstrained Multimodal Multi-Label Learning\",\"url\":\"https://www.semanticscholar.org/paper/8e7702f8992572dcfabc9262b9d15b82236a0d47\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2241127\",\"name\":\"Marie-Catherine de Marneffe\"},{\"authorId\":\"3257930\",\"name\":\"Bill MacCartney\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3cc228402f31ca749112197720b9ef6af0c16790\",\"title\":\"Generating Typed Dependency Parses from Phrase Structure Parses\",\"url\":\"https://www.semanticscholar.org/paper/3cc228402f31ca749112197720b9ef6af0c16790\",\"venue\":\"LREC\",\"year\":2006},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Wang\"},{\"authorId\":\"36880488\",\"name\":\"Cheng Chen\"},{\"authorId\":\"1717863\",\"name\":\"Yizhou Wang\"},{\"authorId\":\"40570471\",\"name\":\"T. Jiang\"},{\"authorId\":\"143816774\",\"name\":\"Fang Fang\"},{\"authorId\":\"144779803\",\"name\":\"Y. Yao\"}],\"doi\":\"10.1109/CVPR.2011.5995423\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c28041fa976c32d6ef7ca77d85b0274cc87f3360\",\"title\":\"Simulating human saccadic scanpaths on natural images\",\"url\":\"https://www.semanticscholar.org/paper/c28041fa976c32d6ef7ca77d85b0274cc87f3360\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/CVPR.2015.7298966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"title\":\"Deep correlation for matching images and text\",\"url\":\"https://www.semanticscholar.org/paper/efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1602.06291\",\"authors\":[{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2704071\",\"name\":\"B. Strope\"},{\"authorId\":\"39526910\",\"name\":\"Scott Roy\"},{\"authorId\":\"4328360\",\"name\":\"T. Dean\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6067628004373e61b962bd4b470308882e57448b\",\"title\":\"Contextual LSTM (CLSTM) models for Large scale NLP tasks\",\"url\":\"https://www.semanticscholar.org/paper/6067628004373e61b962bd4b470308882e57448b\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"1717863\",\"name\":\"Yizhou Wang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/CVPR.2010.5539927\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2b4206d7c58047e0351242df3dcf2c83dd9d8fa\",\"title\":\"Measuring visual saliency by Site Entropy Rate\",\"url\":\"https://www.semanticscholar.org/paper/e2b4206d7c58047e0351242df3dcf2c83dd9d8fa\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186314\",\"name\":\"M. Bindemann\"}],\"doi\":\"10.1016/j.visres.2010.08.016\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fc87290a5b910a3816608c6521dcc7ec32c59114\",\"title\":\"Scene and screen center bias early eye movements in scene viewing\",\"url\":\"https://www.semanticscholar.org/paper/fc87290a5b910a3816608c6521dcc7ec32c59114\",\"venue\":\"Vision Research\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f74d5a71f2342f7d0b1569743ca173b3ff77b451\",\"title\":\"Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/f74d5a71f2342f7d0b1569743ca173b3ff77b451\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46837630\",\"name\":\"Po-He Tseng\"},{\"authorId\":\"34414200\",\"name\":\"R. Carmi\"},{\"authorId\":\"145777626\",\"name\":\"I. G. Cameron\"},{\"authorId\":\"144440243\",\"name\":\"D. Munoz\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1167/9.7.4\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fe311d83782515767e5584c4fa0239daee14075c\",\"title\":\"Quantifying center bias of observers in free viewing of dynamic natural scenes.\",\"url\":\"https://www.semanticscholar.org/paper/fe311d83782515767e5584c4fa0239daee14075c\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"3344005\",\"name\":\"C. Dance\"}],\"doi\":\"10.1109/CVPR.2007.383266\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23694b6d61668e62bb11f17c1d75dde3b4951948\",\"title\":\"Fisher Kernels on Visual Vocabularies for Image Categorization\",\"url\":\"https://www.semanticscholar.org/paper/23694b6d61668e62bb11f17c1d75dde3b4951948\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1410.1090\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"title\":\"Explain Images with Multimodal Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/82fdca623c65b6acf6b06bdeed48b2a9ebdb80a9\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015}],\"title\":\"Instance-Aware Image and Sentence Matching with Selective Multimodal LSTM\",\"topics\":[{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Modulation\",\"topicId\":\"2260\",\"url\":\"https://www.semanticscholar.org/topic/2260\"},{\"topic\":\"Semantic similarity\",\"topicId\":\"34825\",\"url\":\"https://www.semanticscholar.org/topic/34825\"},{\"topic\":\"Map\",\"topicId\":\"2392\",\"url\":\"https://www.semanticscholar.org/topic/2392\"},{\"topic\":\"Automatic image annotation\",\"topicId\":\"244589\",\"url\":\"https://www.semanticscholar.org/topic/244589\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/e1b6735f6ecb09e1d83b0aa9d2cde42993ee2eb0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"