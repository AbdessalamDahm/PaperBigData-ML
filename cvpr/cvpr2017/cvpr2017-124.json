"{\"abstract\":\"Recently it has been shown that policy-gradient methods for reinforcement learning can be utilized to train deep end-to-end systems directly on non-differentiable metrics for the task at hand. In this paper we consider the problem of optimizing image captioning systems using reinforcement learning, and show that by carefully optimizing our systems using the test metrics of the MSCOCO task, significant gains in performance can be realized. Our systems are built using a new optimization approach that we call self-critical sequence training (SCST). SCST is a form of the popular REINFORCE algorithm that, rather than estimating a baseline to normalize the rewards and reduce variance, utilizes the output of its own test-time inference algorithm to normalize the rewards it experiences. Using this approach, estimating the reward signal (as actor-critic methods must do) and estimating normalization (as REINFORCE algorithms typically do) is avoided, while at the same time harmonizing the model with respect to its test-time inference procedure. Empirically we find that directly optimizing the CIDEr metric with SCST and greedy decoding at test-time is highly effective. Our results on the MSCOCO evaluation sever establish a new state-of-the-art on the task, improving the best result in terms of CIDEr from 104.9 to 114.7.\",\"arxivId\":\"1612.00563\",\"authors\":[{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\",\"url\":\"https://www.semanticscholar.org/author/2071376\"},{\"authorId\":\"2293163\",\"name\":\"E. Marcheret\",\"url\":\"https://www.semanticscholar.org/author/2293163\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\",\"url\":\"https://www.semanticscholar.org/author/2211263\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\",\"url\":\"https://www.semanticscholar.org/author/39320489\"},{\"authorId\":\"1782589\",\"name\":\"V. Goel\",\"url\":\"https://www.semanticscholar.org/author/1782589\"}],\"citationVelocity\":177,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.18653/v1/P18-5004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"532837c431617d37c03361ba5a7d5fdb082c55f4\",\"title\":\"Connecting Language and Vision to Actions\",\"url\":\"https://www.semanticscholar.org/paper/532837c431617d37c03361ba5a7d5fdb082c55f4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"2005.14386\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"46208708\",\"name\":\"G. Shakhnarovich\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"57ace777e00c0df5d0b729990eed12ed6b0dcfe9\",\"title\":\"Controlling Length in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/57ace777e00c0df5d0b729990eed12ed6b0dcfe9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"144162125\",\"name\":\"J. Langford\"},{\"authorId\":\"145499435\",\"name\":\"G. Tucker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"882502c4c795f2b76e4c6a8343b199d216066353\",\"title\":\"The 2nd Learning from Limited Labeled Data (LLD) Workshop: Representation Learning for Weak Supervision and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/882502c4c795f2b76e4c6a8343b199d216066353\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405390891\",\"name\":\"Diego Garc\\u00eda-Olano\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c974a5a60beea00fc120c9b6bbc7e87f4c5cdd98\",\"title\":\"Generating Counterfactual Explanations using Reinforcement Learning Methods for Tabular and Text data\",\"url\":\"https://www.semanticscholar.org/paper/c974a5a60beea00fc120c9b6bbc7e87f4c5cdd98\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.11872\",\"authors\":[{\"authorId\":\"153040576\",\"name\":\"T. Mei\"},{\"authorId\":\"101586660\",\"name\":\"W. Zhang\"},{\"authorId\":\"48577275\",\"name\":\"Ting Yao\"}],\"doi\":\"10.1017/ATSIP.2020.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"title\":\"Vision and Language: from Visual Perception to Content Creation\",\"url\":\"https://www.semanticscholar.org/paper/3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51376876\",\"name\":\"X. Li\"},{\"authorId\":\"1557265719\",\"name\":\"Zhen Huang\"},{\"authorId\":\"144774112\",\"name\":\"F. Liu\"},{\"authorId\":\"50096677\",\"name\":\"Changjian Wang\"},{\"authorId\":\"8367832\",\"name\":\"Minghao Hu\"},{\"authorId\":\"12482226\",\"name\":\"Shiyi Xu\"},{\"authorId\":\"49236691\",\"name\":\"Yu-xing Peng\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a3bf1eea8ce0be5252257edc4b8712c3d77177a\",\"title\":\"RAD: Reinforced Attention Decoder Model On Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/5a3bf1eea8ce0be5252257edc4b8712c3d77177a\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.08191\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1609/aaai.v33i01.33018465\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2b02822cfbc50d17ec5220a19556be9d601c132\",\"title\":\"Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/c2b02822cfbc50d17ec5220a19556be9d601c132\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1711.06420\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724b253a55e86ad230ba05c7eb78f249e09258d9\",\"title\":\"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/724b253a55e86ad230ba05c7eb78f249e09258d9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.07011\",\"authors\":[{\"authorId\":\"143872936\",\"name\":\"Xavier Puig\"},{\"authorId\":\"50974654\",\"name\":\"Kevin Ra\"},{\"authorId\":\"1765505\",\"name\":\"M. Boben\"},{\"authorId\":\"22133106\",\"name\":\"Jiaman Li\"},{\"authorId\":\"3428549\",\"name\":\"Tingwu Wang\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2018.00886\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7139a5f730652abbeabf9e140009907d2c7da3e5\",\"title\":\"VirtualHome: Simulating Household Activities Via Programs\",\"url\":\"https://www.semanticscholar.org/paper/7139a5f730652abbeabf9e140009907d2c7da3e5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423621769\",\"name\":\"B. T. Nguyen\"},{\"authorId\":\"50259366\",\"name\":\"O. Prakash\"},{\"authorId\":\"1580282435\",\"name\":\"A. H. Vo\"}],\"doi\":\"10.1007/978-3-030-62324-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21a742ee840b4a063deee66028409f9cf7f3829d\",\"title\":\"Attention Mechanism for Fashion Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/21a742ee840b4a063deee66028409f9cf7f3829d\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66583249\",\"name\":\"Wanwei He\"},{\"authorId\":\"144346839\",\"name\":\"Min Yang\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"1753529\",\"name\":\"Ruifeng Xu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.281\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d170af772b2e954e6f6ef9eb45eae3515b068d64\",\"title\":\"Amalgamating Knowledge from Two Teachers for Task-oriented Dialogue System with Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/d170af772b2e954e6f6ef9eb45eae3515b068d64\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48411954\",\"name\":\"Hyunsoo Lee\"},{\"authorId\":\"46252888\",\"name\":\"Y. Choi\"},{\"authorId\":\"2790175\",\"name\":\"J. Lee\"}],\"doi\":\"10.1145/3341105.3373892\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aad2beba23eaf73693382527ca3d1ca4c10ed855\",\"title\":\"Attention history-based attention for abstractive text summarization\",\"url\":\"https://www.semanticscholar.org/paper/aad2beba23eaf73693382527ca3d1ca4c10ed855\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40607664\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c71934550456ef3f92edc6b7e98d6b2d9c519382\",\"title\":\"Team RUC AI\\u00b7M Technical Report at VMT Challenge 2020: Enhancing Neural Machine Translation with Multimodal Rewards\",\"url\":\"https://www.semanticscholar.org/paper/c71934550456ef3f92edc6b7e98d6b2d9c519382\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.00249\",\"authors\":[{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.24963/ijcai.2019/132\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"title\":\"Convolutional Auto-encoding of Sentence Topics for Image Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/0b8f0e00f953ae51a7ea72ba51c699bb959cc948\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":null,\"name\":\"Patr Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae447685c5dddac6b961079d2c15cf92fa1a8d0a\",\"title\":\"How Many Glances? Modeling Multi-duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/ae447685c5dddac6b961079d2c15cf92fa1a8d0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452223\",\"name\":\"Kazuto Nakashima\"},{\"authorId\":\"1795530\",\"name\":\"Y. Iwashita\"},{\"authorId\":\"1801213\",\"name\":\"R. Kurazume\"}],\"doi\":\"10.1186/s40648-020-00181-2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76b4b7aa99a8434d80f3af553fbfa013f5cbfe6b\",\"title\":\"Lifelogging caption generation via fourth-person vision in a human\\u2013robot symbiotic environment\",\"url\":\"https://www.semanticscholar.org/paper/76b4b7aa99a8434d80f3af553fbfa013f5cbfe6b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4522297\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"1734743\",\"name\":\"L. Zhuang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802972\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f452255860e37af6090e9558e66495441141e0d5\",\"title\":\"Continuous Sign Language Recognition via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f452255860e37af6090e9558e66495441141e0d5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153407705\",\"name\":\"Qing Zhou\"},{\"authorId\":\"72655924\",\"name\":\"Jin-Kao Hao\"},{\"authorId\":\"1500391821\",\"name\":\"Zhe Sun\"},{\"authorId\":\"50528688\",\"name\":\"Qinghua Wu\"}],\"doi\":\"10.1016/j.asoc.2020.106440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"666e1a1436949c652aa6bd764d088c5b8a091a31\",\"title\":\"Memetic search for composing medical crews with equity and efficiency\",\"url\":\"https://www.semanticscholar.org/paper/666e1a1436949c652aa6bd764d088c5b8a091a31\",\"venue\":\"Appl. Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120800460\",\"name\":\"L. Zhou\"},{\"authorId\":\"98110081\",\"name\":\"J. Gao\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"},{\"authorId\":\"70362337\",\"name\":\"Heung-Yeung Shum\"}],\"doi\":\"10.1162/coli_a_00368\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3737b57e8b739b595cd5b877769cbc719c42f2c7\",\"title\":\"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot\",\"url\":\"https://www.semanticscholar.org/paper/3737b57e8b739b595cd5b877769cbc719c42f2c7\",\"venue\":\"Computational Linguistics\",\"year\":2020},{\"arxivId\":\"2010.14551\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"25576460\",\"name\":\"Ruth C. Fong\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b796497f350d15bd47d06cb4794bad15a149a72\",\"title\":\"Quantifying Learnability and Describability of Visual Concepts Emerging in Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1b796497f350d15bd47d06cb4794bad15a149a72\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.07896\",\"authors\":[{\"authorId\":\"40607664\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c9c256c33ed4db6b83321c516025b1feb62ddfb\",\"title\":\"Team RUC_AIM3 Technical Report at Activitynet 2020 Task 2: Exploring Sequential Events Detection for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9c256c33ed4db6b83321c516025b1feb62ddfb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00850\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8367832\",\"name\":\"Minghao Hu\"},{\"authorId\":\"2653582\",\"name\":\"Y. Peng\"},{\"authorId\":\"144786392\",\"name\":\"Z. Huang\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"}],\"doi\":\"10.24963/ijcai.2018/570\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e0222a1ae6874f7fff128c3da8769ab95963da04\",\"title\":\"Reinforced Mnemonic Reader for Machine Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/e0222a1ae6874f7fff128c3da8769ab95963da04\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1711.08393\",\"authors\":[{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"50333123\",\"name\":\"Abhishek Kumar\"},{\"authorId\":\"30126647\",\"name\":\"Steven Rennie\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1109/CVPR.2018.00919\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e16cfe727e27be27115d0f842375c46e7e3f384b\",\"title\":\"BlockDrop: Dynamic Inference Paths in Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/e16cfe727e27be27115d0f842375c46e7e3f384b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.06356\",\"authors\":[{\"authorId\":\"7670835\",\"name\":\"Shiyue Zhang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D19-1253\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8f23c219233fb67eedb1e4333c8458edb1c5cd68\",\"title\":\"Addressing Semantic Drift in Question Generation for Semi-Supervised Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8f23c219233fb67eedb1e4333c8458edb1c5cd68\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2123563\",\"name\":\"Shihao Wang\"},{\"authorId\":\"81983870\",\"name\":\"Hong Mo\"},{\"authorId\":\"1749615\",\"name\":\"Yue Xu\"},{\"authorId\":\"145717893\",\"name\":\"W. Wu\"},{\"authorId\":\"144812501\",\"name\":\"Zhong Zhou\"}],\"doi\":\"10.1007/978-3-030-00764-5_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51c48633735a10c2e509374ba7fad8e267f322e1\",\"title\":\"Intra-Image Region Context for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51c48633735a10c2e509374ba7fad8e267f322e1\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117788399\",\"name\":\"Chandresh S. Kanani\"},{\"authorId\":\"1777669\",\"name\":\"Sriparna Saha\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206644\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2194227d8766086b01bfa3e28b863bd5c596efab\",\"title\":\"Improving Diversity and Reducing Redundancy in Paragraph Captions\",\"url\":\"https://www.semanticscholar.org/paper/2194227d8766086b01bfa3e28b863bd5c596efab\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92716077\",\"name\":\"Shaokang Yang\"},{\"authorId\":\"122218340\",\"name\":\"J. Niu\"},{\"authorId\":\"1809483\",\"name\":\"Jiyan Wu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"}],\"doi\":\"10.1007/978-3-030-60248-2_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"title\":\"Automatic Medical Image Report Generation with Multi-view and Multi-modal Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"venue\":\"ICA3PP\",\"year\":2020},{\"arxivId\":\"2007.06077\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"51510489\",\"name\":\"Marius Mosbach\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c6d4f0afbe3a7d6ba8e94f446878977721a21eb\",\"title\":\"Sparse Graph to Sequence Learning for Vision Conditioned Long Textual Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/7c6d4f0afbe3a7d6ba8e94f446878977721a21eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.12536\",\"authors\":[{\"authorId\":\"29988001\",\"name\":\"Zhouxia Wang\"},{\"authorId\":\"145345504\",\"name\":\"JiaWei Zhang\"},{\"authorId\":\"3388973\",\"name\":\"Mude Lin\"},{\"authorId\":\"1661045088\",\"name\":\"Jiong Wang\"},{\"authorId\":\"144389940\",\"name\":\"Ping Luo\"},{\"authorId\":\"1500380173\",\"name\":\"Jimmy Ren\"}],\"doi\":\"10.1109/CVPR42600.2020.00189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac6e858ec767e2ded0d3d60f74b3d438f7caff6d\",\"title\":\"Learning a Reinforced Agent for Flexible Exposure Bracketing Selection\",\"url\":\"https://www.semanticscholar.org/paper/ac6e858ec767e2ded0d3d60f74b3d438f7caff6d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.03966\",\"authors\":[{\"authorId\":\"1928586\",\"name\":\"B. Uzkent\"},{\"authorId\":\"144088780\",\"name\":\"Christopher Yeh\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":\"10.1109/WACV45572.2020.9093447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3755e239dbfb47ba33471ad10984dfc3f6abb93\",\"title\":\"Efficient Object Detection in Large Images Using Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b3755e239dbfb47ba33471ad10984dfc3f6abb93\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993712503\",\"name\":\"Xincheng Ju\"},{\"authorId\":\"1771537\",\"name\":\"D. Zhang\"},{\"authorId\":\"47787394\",\"name\":\"J. Li\"},{\"authorId\":\"143740949\",\"name\":\"G. Zhou\"}],\"doi\":\"10.1145/3394171.3413577\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"daf4a3fb8e9e9f153687aaf7e999534eec242d0f\",\"title\":\"Transformer-based Label Set Generation for Multi-modal Multi-label Emotion Detection\",\"url\":\"https://www.semanticscholar.org/paper/daf4a3fb8e9e9f153687aaf7e999534eec242d0f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1712.09532\",\"authors\":[{\"authorId\":\"144801511\",\"name\":\"S. Le\"},{\"authorId\":\"2763884\",\"name\":\"G. Henter\"},{\"authorId\":\"1768065\",\"name\":\"Yusuke Miyao\"},{\"authorId\":\"1700567\",\"name\":\"Shin'ichi Satoh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96c866f07ff999ee11459519aa361fa4fdfc2139\",\"title\":\"Consensus-based Sequence Training for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96c866f07ff999ee11459519aa361fa4fdfc2139\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1909.03169\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"67001969\",\"name\":\"Mahmoud Elsayed\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7af5c94fedc32f3104a08301a46c62f51b044a81\",\"title\":\"Look and Modify: Modification Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7af5c94fedc32f3104a08301a46c62f51b044a81\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"title\":\"Generalization to new compositions of known entities in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144815038\",\"name\":\"Nan Jiang\"},{\"authorId\":\"145880092\",\"name\":\"Sheng Jin\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ed3fd08d89d130e5b028f83e550d4fc8c5c177d\",\"title\":\"Hierarchical automatic curriculum learning: Converting a sparse reward navigation task into dense reward\",\"url\":\"https://www.semanticscholar.org/paper/3ed3fd08d89d130e5b028f83e550d4fc8c5c177d\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1909.02201\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.18653/v1/D19-1208\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a87d5654c41f3dfa7252d079045d7094f601f78e\",\"title\":\"Image Captioning with Very Scarce Supervised Data: Adversarial Semi-Supervised Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/a87d5654c41f3dfa7252d079045d7094f601f78e\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50994378\",\"name\":\"Chen Chen\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"14156382\",\"name\":\"T. Yu\"},{\"authorId\":\"35365476\",\"name\":\"R. Rossi\"},{\"authorId\":\"3139133\",\"name\":\"Razvan C. Bunescu\"}],\"doi\":\"10.1145/3341162.3345601\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"32df387bd612771cfe92f1a34d5de8cdedf7482e\",\"title\":\"Neural caption generation over figures\",\"url\":\"https://www.semanticscholar.org/paper/32df387bd612771cfe92f1a34d5de8cdedf7482e\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2019},{\"arxivId\":\"1912.08492\",\"authors\":[{\"authorId\":\"34338341\",\"name\":\"Kushal Chawla\"},{\"authorId\":\"1455114388\",\"name\":\"Hrituraj Singh\"},{\"authorId\":\"1469310857\",\"name\":\"Arijit Pramanik\"},{\"authorId\":\"121332479\",\"name\":\"M. Kumar\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"34e1c43dfbd30b3eee238a0c71d757b2cc900df8\",\"title\":\"Generating summaries tailored to target characteristics\",\"url\":\"https://www.semanticscholar.org/paper/34e1c43dfbd30b3eee238a0c71d757b2cc900df8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381776125\",\"name\":\"Avinash Swaminathan\"},{\"authorId\":\"1630333413\",\"name\":\"H. Zhang\"},{\"authorId\":\"1630420259\",\"name\":\"Debanjan Mahata\"},{\"authorId\":\"1630420821\",\"name\":\"Rakesh Gosangi\"},{\"authorId\":\"1753278\",\"name\":\"R. Shah\"},{\"authorId\":\"1379977554\",\"name\":\"Amanda Stent\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.645\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68b91348a53171887b64d656d5a72af242c252c3\",\"title\":\"A Preliminary Exploration of GANs for Keyphrase Generation\",\"url\":\"https://www.semanticscholar.org/paper/68b91348a53171887b64d656d5a72af242c252c3\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1910.06426\",\"authors\":[{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"143979421\",\"name\":\"F. Xu\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"title\":\"Tell-the-difference: Fine-grained Visual Descriptor via a Discriminating Referee\",\"url\":\"https://www.semanticscholar.org/paper/dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.12794\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f472b819ce521337c01e4ebf91714f93413d9997\",\"title\":\"Fashion IQ: A New Dataset towards Retrieving Images by Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/f472b819ce521337c01e4ebf91714f93413d9997\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143704786\",\"name\":\"David Balderas\"},{\"authorId\":\"144302764\",\"name\":\"P. Ponce\"},{\"authorId\":\"144394807\",\"name\":\"A. Molina\"}],\"doi\":\"10.1016/J.ESWA.2018.12.055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dca5599927a69bc8b8c315197cbd1b877e8af556\",\"title\":\"Convolutional long short term memory deep neural networks for image sequence prediction\",\"url\":\"https://www.semanticscholar.org/paper/dca5599927a69bc8b8c315197cbd1b877e8af556\",\"venue\":\"Expert Syst. Appl.\",\"year\":2019},{\"arxivId\":\"2009.12313\",\"authors\":[{\"authorId\":\"32556011\",\"name\":\"Victor Milewski\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"b89e002625b0703f08b7590a1763ca7c8be66ad4\",\"title\":\"Are scene graphs good enough to improve Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/b89e002625b0703f08b7590a1763ca7c8be66ad4\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1410066063\",\"name\":\"Yuan Xie\"},{\"authorId\":\"152345893\",\"name\":\"F. Wu\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"40178769\",\"name\":\"Wenjin Lu\"},{\"authorId\":\"46824190\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1016/j.sigpro.2019.107329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea53299a067694a24e5e9cf8e852e122d5918847\",\"title\":\"Image captioning via hierarchical attention mechanism and policy gradient optimization\",\"url\":\"https://www.semanticscholar.org/paper/ea53299a067694a24e5e9cf8e852e122d5918847\",\"venue\":\"Signal Process.\",\"year\":2020},{\"arxivId\":\"2007.06877\",\"authors\":[{\"authorId\":\"51175635\",\"name\":\"Jiuniu Wang\"},{\"authorId\":\"50232214\",\"name\":\"Wenjia Xu\"},{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-58452-8_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"title\":\"Compare and Reweight: Distinctive Image Captioning Using Similar Images Sets\",\"url\":\"https://www.semanticscholar.org/paper/e38274d1d544af5fad2cb814d62a028e2ff7437b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.05493\",\"authors\":[{\"authorId\":\"144943572\",\"name\":\"H. Le\"},{\"authorId\":\"1786362\",\"name\":\"Christophe Cerisara\"},{\"authorId\":\"1794075\",\"name\":\"Claire Gardent\"}],\"doi\":\"10.1007/978-3-030-62144-5_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edd560f021587bc921410b1079f5da24362c6189\",\"title\":\"Quality of syntactic implication of RL-based sentence summarization\",\"url\":\"https://www.semanticscholar.org/paper/edd560f021587bc921410b1079f5da24362c6189\",\"venue\":\"AAAI 2020\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"title\":\"When an Image Tells a Story: The Role of Visual and Semantic Information for Generating Paragraph Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":\"2010.10866\",\"authors\":[{\"authorId\":\"88764446\",\"name\":\"C. Rebuffel\"},{\"authorId\":\"145159652\",\"name\":\"L. Soulier\"},{\"authorId\":\"1470491994\",\"name\":\"Geoffrey Scoutheeten\"},{\"authorId\":\"150259685\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b2c59094d8b8b49af3fd72c1c908a805c1240d2\",\"title\":\"PARENTing via Model-Agnostic Reinforcement Learning to Correct Pathological Behaviors in Data-to-Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/3b2c59094d8b8b49af3fd72c1c908a805c1240d2\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5387396\",\"name\":\"Huidong Li\"},{\"authorId\":\"145144398\",\"name\":\"Dandan Song\"},{\"authorId\":\"3000498\",\"name\":\"Lejian Liao\"},{\"authorId\":\"151479762\",\"name\":\"Cuimei Peng\"}],\"doi\":\"10.1109/ICME.2019.00228\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1567fff9f411af320f678c66b812d2c963151678\",\"title\":\"REVnet: Bring Reviewing Into Video Captioning for a Better Description\",\"url\":\"https://www.semanticscholar.org/paper/1567fff9f411af320f678c66b812d2c963151678\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1808.01571\",\"authors\":[{\"authorId\":\"1679279\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"2371221\",\"name\":\"Y. Shen\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01270-0_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a808a17f5c86413bd552a324ee6ba180a12f46d\",\"title\":\"Improving Deep Visual Representation for Person Re-identification by Global and Local Image-language Association\",\"url\":\"https://www.semanticscholar.org/paper/0a808a17f5c86413bd552a324ee6ba180a12f46d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1810.02851\",\"authors\":[{\"authorId\":\"46394797\",\"name\":\"Yau-Shian Wang\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"}],\"doi\":\"10.18653/v1/D18-1451\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"684aff02486808d7ff20a94dca849d7e646f4798\",\"title\":\"Learning to Encode Text as Human-Readable Summaries using Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/684aff02486808d7ff20a94dca849d7e646f4798\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1811.00511\",\"authors\":[{\"authorId\":\"31497621\",\"name\":\"W. S. Cho\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"48379819\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"145731462\",\"name\":\"Mengdi Wang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4449b78444844917f52b88be02e5d902e384a494\",\"title\":\"A bird's-eye view on coherence, and a worm's-eye view on cohesion\",\"url\":\"https://www.semanticscholar.org/paper/4449b78444844917f52b88be02e5d902e384a494\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"145211780\",\"name\":\"Bin Fan\"},{\"authorId\":\"1380311632\",\"name\":\"Shinming Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.18653/v1/D19-1213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"title\":\"Guiding the Flowing of Semantics: Interpretable Video Captioning via POS Tag\",\"url\":\"https://www.semanticscholar.org/paper/ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38593127\",\"name\":\"Wei Wang\"},{\"authorId\":\"49171048\",\"name\":\"Haitao Zheng\"},{\"authorId\":\"47778853\",\"name\":\"Zibo Lin\"}],\"doi\":\"10.1109/ICASSP40776.2020.9052954\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee525efb5a15aa0f2d5ecac7fcb45be0d679bff0\",\"title\":\"Self-Attention and Retrieval Enhanced Neural Networks for Essay Generation\",\"url\":\"https://www.semanticscholar.org/paper/ee525efb5a15aa0f2d5ecac7fcb45be0d679bff0\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2001.05876\",\"authors\":[{\"authorId\":\"46659203\",\"name\":\"L. Wang\"},{\"authorId\":\"1486057423\",\"name\":\"Zechen Bai\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1609/aaai.v34i07.6898\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"85079d64d6fdd0ba5318fda119d152f2d2946391\",\"title\":\"Show, Recall, and Tell: Image Captioning with Recall Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/85079d64d6fdd0ba5318fda119d152f2d2946391\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huan Yang\"},{\"authorId\":\"145144398\",\"name\":\"Dandan Song\"},{\"authorId\":\"3000498\",\"name\":\"Lejian Liao\"}],\"doi\":\"10.1007/978-3-319-97310-4_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1473ca131d8a6030def18ca196b8d39e0665613\",\"title\":\"Image Captioning with Relational Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c1473ca131d8a6030def18ca196b8d39e0665613\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.398\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"venue\":\"ICCV 2017\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49267101\",\"name\":\"T. Nishino\"},{\"authorId\":\"2078217\",\"name\":\"R. Ozaki\"},{\"authorId\":\"70423357\",\"name\":\"Yohei Momoki\"},{\"authorId\":\"8820088\",\"name\":\"T. Taniguchi\"},{\"authorId\":\"29012843\",\"name\":\"Ryuji Kano\"},{\"authorId\":\"2003604069\",\"name\":\"Norihisa Nakano\"},{\"authorId\":\"30965869\",\"name\":\"Y. Tagawa\"},{\"authorId\":\"22281965\",\"name\":\"Motoki Taniguchi\"},{\"authorId\":\"35084305\",\"name\":\"T. Ohkuma\"},{\"authorId\":\"48569006\",\"name\":\"K. Nakamura\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.202\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f39d7195ee43a5eececf801ed0543cec1461a577\",\"title\":\"Reinforcement Learning with Imbalanced Dataset for Data-to-Text Medical Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/f39d7195ee43a5eececf801ed0543cec1461a577\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007655179\",\"name\":\"Thien-Hoa Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02765d54eda3d807101e7a159609c1c8592145ae\",\"title\":\"Neural Methods for Sentiment Analysis and Text Summarization. (M\\u00e9thodes neuronales pour l'analyse des sentiments et la synth\\u00e8se des textes)\",\"url\":\"https://www.semanticscholar.org/paper/02765d54eda3d807101e7a159609c1c8592145ae\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924571\",\"name\":\"Jing Wang\"},{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3413753\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"021d50ba5ae1c66e9175428f546976798126dd9f\",\"title\":\"Multimodal Attention with Image Text Spatial Relationship for OCR-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/021d50ba5ae1c66e9175428f546976798126dd9f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701889\",\"name\":\"Tianyu Liu\"},{\"authorId\":\"17866105\",\"name\":\"Fuli Luo\"},{\"authorId\":\"46709826\",\"name\":\"Pengcheng Yang\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"39488576\",\"name\":\"Baobao Chang\"},{\"authorId\":\"3335836\",\"name\":\"Z. Sui\"}],\"doi\":\"10.18653/v1/P19-1600\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07da5f1b0089d080a1ed9295676ded47505ca25a\",\"title\":\"Towards Comprehensive Description Generation from Factual Attribute-value Tables\",\"url\":\"https://www.semanticscholar.org/paper/07da5f1b0089d080a1ed9295676ded47505ca25a\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145522783\",\"name\":\"Z. Sun\"},{\"authorId\":\"144361839\",\"name\":\"X. Lin\"},{\"authorId\":\"50218964\",\"name\":\"Zhaohui Wang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00767-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8b600d520f95b811857052d864ee54567064dd9\",\"title\":\"Multi-decoder Based Co-attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b8b600d520f95b811857052d864ee54567064dd9\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2005.04690\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"153003010\",\"name\":\"Xingjian He\"},{\"authorId\":\"1575173011\",\"name\":\"Jie Jiang\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.24963/ijcai.2020/106\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9637ae1fbb8aebc8deb6e3c15dd93839e327e1c\",\"title\":\"Non-Autoregressive Image Captioning with Counterfactuals-Critical Multi-Agent Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9637ae1fbb8aebc8deb6e3c15dd93839e327e1c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144455084\",\"name\":\"Y. Chang\"},{\"authorId\":\"1878461\",\"name\":\"Hang Lei\"},{\"authorId\":\"1597361648\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"46844241\",\"name\":\"Yi-Ming Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fbf313b7fd9f193225861db4c2e4f4475cce17b\",\"title\":\"A Reinforced Improved Attention Model for Abstractive Text Summarization\",\"url\":\"https://www.semanticscholar.org/paper/6fbf313b7fd9f193225861db4c2e4f4475cce17b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130190\",\"name\":\"Song Liu\"},{\"authorId\":\"14895949\",\"name\":\"Jiawei Zhan\"},{\"authorId\":\"1500394033\",\"name\":\"Zhengding Luo\"},{\"authorId\":\"1500393714\",\"name\":\"Gege Qi\"},{\"authorId\":\"49836169\",\"name\":\"Zhiqiang Bai\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/ICTAI.2019.00050\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecfef3cb71299d933d096f5ad0081bb179b9e6ef\",\"title\":\"Deep Captioning Hashing Network for Complex Scene Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/ecfef3cb71299d933d096f5ad0081bb179b9e6ef\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":\"1911.02541\",\"authors\":[{\"authorId\":\"49889487\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"2976167\",\"name\":\"Derek Merck\"},{\"authorId\":\"36355051\",\"name\":\"E. Tsai\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"2356307\",\"name\":\"C. Langlotz\"}],\"doi\":\"10.18653/v1/2020.acl-main.458\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3bba9e45d2f031e417c840caf62b0c7a3d82537\",\"title\":\"Optimizing the Factual Correctness of a Summary: A Study of Summarizing Radiology Reports\",\"url\":\"https://www.semanticscholar.org/paper/f3bba9e45d2f031e417c840caf62b0c7a3d82537\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46407634\",\"name\":\"Jind\\u0159ich Helcl\"},{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"}],\"doi\":\"10.1515/pralin-2017-0001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0267e8dab6669a6c10be2e29bea44ea32c41e990\",\"title\":\"Neural Monkey: An Open-source Tool for Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/0267e8dab6669a6c10be2e29bea44ea32c41e990\",\"venue\":\"Prague Bull. Math. Linguistics\",\"year\":2017},{\"arxivId\":\"2012.05545\",\"authors\":[{\"authorId\":\"67333377\",\"name\":\"Zeliang Song\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"title\":\"Image Captioning with Context-Aware Auxiliary Guidance\",\"url\":\"https://www.semanticscholar.org/paper/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153030413\",\"name\":\"Xuenan Xu\"},{\"authorId\":\"2451839\",\"name\":\"H. Dinkel\"},{\"authorId\":\"3000684\",\"name\":\"Mengyue Wu\"},{\"authorId\":\"143819768\",\"name\":\"K. Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e0bd03576152ef283d37529fb9dedd1d0b249ee3\",\"title\":\"THE SJTU SUBMISSION FOR DCASE2020 TASK 6: A CRNN-GRU BASED REINFORCEMENT LEARNING APPROACH TO AUDIOCAPTION Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/e0bd03576152ef283d37529fb9dedd1d0b249ee3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1708.09667\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3123266.3123420\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6199348281e14a5a127b539f5cdb92fcddbac17\",\"title\":\"Video Captioning with Guidance of Multimodal Latent Topics\",\"url\":\"https://www.semanticscholar.org/paper/a6199348281e14a5a127b539f5cdb92fcddbac17\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2009.12682\",\"authors\":[{\"authorId\":\"1485330641\",\"name\":\"He Sun\"},{\"authorId\":\"10394991\",\"name\":\"Zhun Deng\"},{\"authorId\":\"67228310\",\"name\":\"H. Chen\"},{\"authorId\":\"30907562\",\"name\":\"D. Parkes\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0404edbdf045766810c602038b498209d2a55c5c\",\"title\":\"Decision-Aware Conditional GANs for Time Series Data\",\"url\":\"https://www.semanticscholar.org/paper/0404edbdf045766810c602038b498209d2a55c5c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TIP.2020.3042086\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"title\":\"Cross-Domain Image Captioning via Cross-Modal Retrieval and Model Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bf2f223b2f4c425275f6b31f9e0111af32b41882\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"50248791\",\"name\":\"G. Wang\"},{\"authorId\":\"49969968\",\"name\":\"Zhipeng Li\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1007/978-3-030-36802-9_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"797089139d87aeda56bee0b0374bee71521ae169\",\"title\":\"Delving into Precise Attention in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/797089139d87aeda56bee0b0374bee71521ae169\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-030-36718-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"title\":\"SACIC: A Semantics-Aware Convolutional Image Captioner Using Multi-level Pervasive Attention\",\"url\":\"https://www.semanticscholar.org/paper/9c940e8b66e822dbdd8d0dde9a6640ed01834e31\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1701.07274\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1e9e56d80146766bc2316efbc54d8b770a23df\",\"title\":\"Deep Reinforcement Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ahmed Shehab Khan\"},{\"authorId\":null,\"name\":\"Zhiyuan Li\"},{\"authorId\":null,\"name\":\"Jie Cai\"},{\"authorId\":null,\"name\":\"Yan Tong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"170f403ca462bf88513197f8e499e31dd7701d1a\",\"title\":\"Regional Attention Networks with Context-aware Fusion for Group Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/170f403ca462bf88513197f8e499e31dd7701d1a\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Hockenmaier\"},{\"authorId\":null,\"name\":\"J. Tsujii\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfa66d4f68efb2621c7d1e16c426a02c6b3fd59d\",\"title\":\"BanditSum: Extractive Summarization as a Contextual Bandit\",\"url\":\"https://www.semanticscholar.org/paper/cfa66d4f68efb2621c7d1e16c426a02c6b3fd59d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.04144\",\"authors\":[{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"title\":\"End-to-end Image Captioning Exploits Multimodal Distributional Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6610cecb59fdd108c8fcb73cac3562fa10d5e845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e93c977025e2829f852fc8c1e8f9547c3588dbf0\",\"title\":\"vv 1 camping tent food fire Residual BRNN Input Video Visual Encoder ( CNN ) Video Encoder Sentence Encoder Word 2 Vecs Sentence Semantic Embedding vv 2 vv 3 vvNN \\u2212 1 vvNN vv Video Semantic Embedding xx\",\"url\":\"https://www.semanticscholar.org/paper/e93c977025e2829f852fc8c1e8f9547c3588dbf0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.00279\",\"authors\":[{\"authorId\":\"48598711\",\"name\":\"Zhichao Yang\"},{\"authorId\":\"10330431\",\"name\":\"Pengshan Cai\"},{\"authorId\":\"1717629\",\"name\":\"Yansong Feng\"},{\"authorId\":\"144695376\",\"name\":\"Fei Li\"},{\"authorId\":\"2415466\",\"name\":\"Weijiang Feng\"},{\"authorId\":\"114986604\",\"name\":\"Elena Suet-Ying Chiu\"},{\"authorId\":null,\"name\":\"Hong Yu\"}],\"doi\":\"10.18653/v1/D19-1637\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1807377957da486c94f7ae1b99f309330e76655a\",\"title\":\"Generating Classical Chinese Poems from Vernacular Chinese\",\"url\":\"https://www.semanticscholar.org/paper/1807377957da486c94f7ae1b99f309330e76655a\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1808.06167\",\"authors\":[{\"authorId\":\"37374479\",\"name\":\"He Bai\"},{\"authorId\":\"47943048\",\"name\":\"Y. Zhou\"},{\"authorId\":\"38358352\",\"name\":\"Jiajun Zhang\"},{\"authorId\":\"145927744\",\"name\":\"Liang Zhao\"},{\"authorId\":\"144091892\",\"name\":\"M. Hwang\"},{\"authorId\":\"2423168\",\"name\":\"C. Zong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2957520e029cf3566ad93df7b89f1a82c03ea55d\",\"title\":\"Source Critical Reinforcement Learning for Transferring Spoken Language Understanding to a New Language\",\"url\":\"https://www.semanticscholar.org/paper/2957520e029cf3566ad93df7b89f1a82c03ea55d\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa98d7de8fd711fe1bb9d99214319af8d0eef952\",\"title\":\"Incorporating Politeness across Languages in Customer Care Responses: Towards building a Multi-lingual Empathetic Dialogue Agent\",\"url\":\"https://www.semanticscholar.org/paper/aa98d7de8fd711fe1bb9d99214319af8d0eef952\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"2006.04224\",\"authors\":[{\"authorId\":\"50430041\",\"name\":\"Kumar Ayush\"},{\"authorId\":\"1928586\",\"name\":\"B. Uzkent\"},{\"authorId\":\"32582096\",\"name\":\"M. Burke\"},{\"authorId\":\"2465182\",\"name\":\"D. Lobell\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f565f211b690c0f80ccbdd27833076deedcf8bca\",\"title\":\"Efficient Poverty Mapping using Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f565f211b690c0f80ccbdd27833076deedcf8bca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.09461\",\"authors\":[{\"authorId\":\"2180949\",\"name\":\"Yaser Keneshloo\"},{\"authorId\":\"145531789\",\"name\":\"Tian Shi\"},{\"authorId\":\"1755938\",\"name\":\"Naren Ramakrishnan\"},{\"authorId\":\"144417522\",\"name\":\"C. Reddy\"}],\"doi\":\"10.1109/TNNLS.2019.2929141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15a06d8601539b5eb6df5baf6bc4c3bdefb34855\",\"title\":\"Deep Reinforcement Learning for Sequence-to-Sequence Models\",\"url\":\"https://www.semanticscholar.org/paper/15a06d8601539b5eb6df5baf6bc4c3bdefb34855\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"2007.13831\",\"authors\":[{\"authorId\":\"1387878041\",\"name\":\"T. Syeda-Mahmood\"},{\"authorId\":\"32117189\",\"name\":\"K. Wong\"},{\"authorId\":\"143763011\",\"name\":\"Yaniv Gur\"},{\"authorId\":\"40346984\",\"name\":\"Joy T. Wu\"},{\"authorId\":\"144736530\",\"name\":\"A. Jadhav\"},{\"authorId\":\"1720737615\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"2308391\",\"name\":\"Alexandros Karargyris\"},{\"authorId\":\"48867210\",\"name\":\"Anup Pillai\"},{\"authorId\":\"50465259\",\"name\":\"A. Sharma\"},{\"authorId\":\"1717319338\",\"name\":\"A. Syed\"},{\"authorId\":\"147729319\",\"name\":\"O. Boyko\"},{\"authorId\":\"98655520\",\"name\":\"Mehdi Moradi\"}],\"doi\":\"10.1007/978-3-030-59713-9_54\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c777d40dc381dbe4535ad80ec7d64c8fc4fbf786\",\"title\":\"Chest X-ray Report Generation through Fine-Grained Label Learning\",\"url\":\"https://www.semanticscholar.org/paper/c777d40dc381dbe4535ad80ec7d64c8fc4fbf786\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2005.01279\",\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"150116410\",\"name\":\"G. Wang\"},{\"authorId\":\"1500397567\",\"name\":\"Zheng Wen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.acl-main.227\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6675640a8ad5e180a3a68fb5e8b34386df28c68f\",\"title\":\"Improving Adversarial Text Generation by Modeling the Distant Future\",\"url\":\"https://www.semanticscholar.org/paper/6675640a8ad5e180a3a68fb5e8b34386df28c68f\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"2896799\",\"name\":\"Ye Zhao\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":\"10.1109/BigMM.2018.8499172\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96418bb981ac738468340c7836a8362fa08cc1f2\",\"title\":\"Enhanced Text-Guided Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96418bb981ac738468340c7836a8362fa08cc1f2\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.05355\",\"authors\":[{\"authorId\":\"9192775\",\"name\":\"Preksha Nema\"},{\"authorId\":\"1389549528\",\"name\":\"Akash Kumar Mohankumar\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"},{\"authorId\":\"1723632\",\"name\":\"Balaraman Ravindran\"}],\"doi\":\"10.18653/v1/D19-1326\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ea017faae8706d07a8ebc2a321969a899e8fad9\",\"title\":\"Let's Ask Again: Refine Network for Automatic Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/5ea017faae8706d07a8ebc2a321969a899e8fad9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1804.00819\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/CVPR.2018.00911\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"35ed258aede3df17ee20a6635364cb5fd2461049\",\"title\":\"End-to-End Dense Video Captioning with Masked Transformer\",\"url\":\"https://www.semanticscholar.org/paper/35ed258aede3df17ee20a6635364cb5fd2461049\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"title\":\"Learning to Caption Images with Two-Stream Attention and Sentence Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.02059\",\"authors\":[{\"authorId\":\"49974609\",\"name\":\"Eva Sharma\"},{\"authorId\":\"80518559\",\"name\":\"Luyang huang\"},{\"authorId\":\"144869276\",\"name\":\"Zhe Hu\"},{\"authorId\":\"31835031\",\"name\":\"L. Wang\"}],\"doi\":\"10.18653/v1/D19-1323\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d298f0286937fdc2cf5b094b6c9719aa8a86b385\",\"title\":\"An Entity-Driven Framework for Abstractive Summarization\",\"url\":\"https://www.semanticscholar.org/paper/d298f0286937fdc2cf5b094b6c9719aa8a86b385\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2011.14752\",\"authors\":[{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"title\":\"A Comprehensive Review on Recent Methods and Challenges of Video Description\",\"url\":\"https://www.semanticscholar.org/paper/baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.705\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b01bc15919f72929d36fc0443395e97b632c81b8\",\"title\":\"CapWAP: Image Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/b01bc15919f72929d36fc0443395e97b632c81b8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46296760\",\"name\":\"Dandan Guo\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"1450708782\",\"name\":\"Ruiying Lu\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf5c373aa728f6708b365bc73be19b045ca8f604\",\"title\":\"Recurrent Hierarchical Topic-Guided Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/bf5c373aa728f6708b365bc73be19b045ca8f604\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2006.11337\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"1380008340\",\"name\":\"Wei Xiong\"},{\"authorId\":\"2743695\",\"name\":\"Haitian Zheng\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3414690\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2289751abfa6543be36227a4ce5a10e25bc3a602\",\"title\":\"Image Sentiment Transfer\",\"url\":\"https://www.semanticscholar.org/paper/2289751abfa6543be36227a4ce5a10e25bc3a602\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1803.10357\",\"authors\":[{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"2691021\",\"name\":\"Antoine Bosselut\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/N18-1150\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"05b1127ee39504516009b25384ca2bd7f2e1b9d9\",\"title\":\"Deep Communicating Agents for Abstractive Summarization\",\"url\":\"https://www.semanticscholar.org/paper/05b1127ee39504516009b25384ca2bd7f2e1b9d9\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1912.10337\",\"authors\":[{\"authorId\":\"46296760\",\"name\":\"Dandan Guo\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"1450708782\",\"name\":\"Ruiying Lu\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e62219ff826633491b8ba8326dfb25f10a5ab75f\",\"title\":\"Recurrent Hierarchical Topic-Guided RNN for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/e62219ff826633491b8ba8326dfb25f10a5ab75f\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"1777025\",\"name\":\"J. Guo\"},{\"authorId\":\"36197757\",\"name\":\"J. Xu\"},{\"authorId\":\"1717004\",\"name\":\"X. Cheng\"}],\"doi\":\"10.1609/AAAI.V33I01.33016682\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7e5c1314bd8d6f0c78b352ea66cb4e851753ed\",\"title\":\"Differentiated Distribution Recovery for Neural Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/0d7e5c1314bd8d6f0c78b352ea66cb4e851753ed\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2007.07268\",\"authors\":[{\"authorId\":\"10098888\",\"name\":\"R. Bigazzi\"},{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"3492481\",\"name\":\"S. Cascianelli\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ffc4fa1db8372d763f990a1f0a6985260d693b0\",\"title\":\"Explore and Explain: Self-supervised Navigation and Recounting\",\"url\":\"https://www.semanticscholar.org/paper/9ffc4fa1db8372d763f990a1f0a6985260d693b0\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":\"1911.01857\",\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1016/j.patrec.2020.03.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"583222b6a573ad698207a0ebabb06685c4517558\",\"title\":\"Video Captioning with Text-based Dynamic Attention and Step-by-Step Learning\",\"url\":\"https://www.semanticscholar.org/paper/583222b6a573ad698207a0ebabb06685c4517558\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"01fe0c5f0d033141a29f4958f15520798022bbe7\",\"title\":\"ULTRA-CONTEXT: MAXIMIZING THE CONTEXT FOR BETTER IMAGE CAPTION GENERATION\",\"url\":\"https://www.semanticscholar.org/paper/01fe0c5f0d033141a29f4958f15520798022bbe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.06861\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/CVPR.2019.00646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"title\":\"Self-Critical N-Step Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3113866\",\"name\":\"Thanapon Noraset\"},{\"authorId\":\"48418509\",\"name\":\"David Demeter\"},{\"authorId\":\"145612610\",\"name\":\"Doug Downey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c5860bb9b2e2469e6cf9deb0ba2baf460871067\",\"title\":\"Controlling Global Statistics in Recurrent Neural Network Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/6c5860bb9b2e2469e6cf9deb0ba2baf460871067\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"24952249\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2c60061ad32e28eb1e20aff42e062c9160786be\",\"title\":\"Diverse and Controllable Image Captioning with Part-of-Speech Guidance\",\"url\":\"https://www.semanticscholar.org/paper/b2c60061ad32e28eb1e20aff42e062c9160786be\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.02435\",\"authors\":[{\"authorId\":\"2416001\",\"name\":\"Shashank Bujimalla\"},{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"81e7e74d0f5f200e575df1908a1b0a5f0500906b\",\"title\":\"B-SCST: Bayesian Self-Critical Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/81e7e74d0f5f200e575df1908a1b0a5f0500906b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8218640e95bb2d925a617b1c3012eed7d209351\",\"title\":\"Show, Reward and Tell: Automatic Generation of Narrative Paragraph From Photo Stream by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/b8218640e95bb2d925a617b1c3012eed7d209351\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2012.10033\",\"authors\":[{\"authorId\":\"67313599\",\"name\":\"Jerry Zikun Chen\"},{\"authorId\":\"144536952\",\"name\":\"Shi Yu\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8ec7afa0166676f18db59c58ff0e0f801cc046e\",\"title\":\"Exploring Fluent Query Reformulations with Text-to-Text Transformers and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a8ec7afa0166676f18db59c58ff0e0f801cc046e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.07280\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"12139064\",\"name\":\"Jake Bruce\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00387\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6bd9642470ff8c2089427f7a6392cd17d213a334\",\"title\":\"Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\",\"url\":\"https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.11696\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"8350409\",\"name\":\"I. Padhi\"},{\"authorId\":\"2535094\",\"name\":\"Mattia Rigotti\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"1999174380\",\"name\":\"Yair Schiff\"},{\"authorId\":\"49832828\",\"name\":\"R. A. Young\"},{\"authorId\":\"2679155\",\"name\":\"Brian M. Belgodere\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"title\":\"Image Captioning as an Assistive Technology: Lessons Learned from VizWiz 2020 Challenge\",\"url\":\"https://www.semanticscholar.org/paper/5d4b265d7f80b185c618fb230ea14dcf909beed7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1805.00145\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"47585344\",\"name\":\"Yu Cheng\"},{\"authorId\":\"30126647\",\"name\":\"Steven Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f7158bd1635bf7bb87c557c429774d5236703e64\",\"title\":\"Dialog-based Interactive Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f7158bd1635bf7bb87c557c429774d5236703e64\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/ICCV.2019.00434\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"title\":\"Generating Diverse and Descriptive Image Captions Using Visual Paraphrases\",\"url\":\"https://www.semanticscholar.org/paper/b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.06365\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"title\":\"Fast Image Caption Generation with Position Alignment\",\"url\":\"https://www.semanticscholar.org/paper/38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1807.10018\",\"authors\":[{\"authorId\":\"51152390\",\"name\":\"Yilei Xiong\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01252-6_29\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b74a094b6e35fab07e1a4694afd12cad9696f1c1\",\"title\":\"Move Forward and Tell: A Progressive Generator of Video Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/b74a094b6e35fab07e1a4694afd12cad9696f1c1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kool\"},{\"authorId\":null,\"name\":\"van Hoof\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce4f001c1d8ddb9a95cf54e14240ef02c44bd329\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Attention , learn to solve routing problems !\",\"url\":\"https://www.semanticscholar.org/paper/ce4f001c1d8ddb9a95cf54e14240ef02c44bd329\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.06339\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":\"10.1201/9781351006620-6\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"title\":\"Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1805.08298\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2a2818ec251d947acd9c74c2040337e656946bc\",\"title\":\"Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/e2a2818ec251d947acd9c74c2040337e656946bc\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2004.14231\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"title\":\"Image Captioning through Image Transformer\",\"url\":\"https://www.semanticscholar.org/paper/657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395029708\",\"name\":\"Woon Sang Cho\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"50468734\",\"name\":\"M. Wang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/W19-2401\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32bfc242d0e85f1b6f2ff838c37287f8cfddf7c2\",\"title\":\"Towards Coherent and Cohesive Long-form Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/32bfc242d0e85f1b6f2ff838c37287f8cfddf7c2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.12197\",\"authors\":[{\"authorId\":\"9708363\",\"name\":\"A. Kechaou\"},{\"authorId\":null,\"name\":\"Manuel Martinez\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6bc97221f649ef491631dac04caa3395eab0c16\",\"title\":\"Detective: An Attentive Recurrent Model for Sparse Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/c6bc97221f649ef491631dac04caa3395eab0c16\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.05683\",\"authors\":[{\"authorId\":\"2579885\",\"name\":\"H. Xiong\"},{\"authorId\":\"37985966\",\"name\":\"Zhongjun He\"},{\"authorId\":\"40354707\",\"name\":\"Hua Wu\"},{\"authorId\":\"49528872\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33017338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37c338cd2ea7b6c87175384d2699c7e3dbc5a009\",\"title\":\"Modeling Coherence for Discourse Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/37c338cd2ea7b6c87175384d2699c7e3dbc5a009\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31465302\",\"name\":\"E. Wang\"},{\"authorId\":\"46182609\",\"name\":\"X. Zhang\"},{\"authorId\":\"39907479\",\"name\":\"F. Wang\"},{\"authorId\":\"1682589\",\"name\":\"T. Wu\"},{\"authorId\":\"144404748\",\"name\":\"Chien-Ming Chen\"}],\"doi\":\"10.1109/ACCESS.2019.2917771\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"title\":\"Multilayer Dense Attention Model for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/751e871c12f70bf05ea012b21f1434849d6fe5ce\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1805.03642\",\"authors\":[{\"authorId\":\"26418299\",\"name\":\"A. Bose\"},{\"authorId\":\"18900686\",\"name\":\"Huan Ling\"},{\"authorId\":\"2902068\",\"name\":\"Yanshuai Cao\"}],\"doi\":\"10.18653/v1/P18-1094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaaf7b9166934e379f10a038ac5610d3360c12b3\",\"title\":\"Adversarial Contrastive Estimation\",\"url\":\"https://www.semanticscholar.org/paper/eaaf7b9166934e379f10a038ac5610d3360c12b3\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"}],\"doi\":\"10.1145/3347449.3357484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"989730c00381805543baa470a2d6490cc5354a13\",\"title\":\"L-STAP: Learned Spatio-Temporal Adaptive Pooling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/989730c00381805543baa470a2d6490cc5354a13\",\"venue\":\"AI4TV@MM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22603654\",\"name\":\"Xuecheng Ning\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1007/978-3-030-37734-2_55\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"120b849abbfcaefe0e212c38141e86958118d1d7\",\"title\":\"Multi-hop Interactive Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/120b849abbfcaefe0e212c38141e86958118d1d7\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"2011.01385\",\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"123275544\",\"name\":\"Jian Zhang\"},{\"authorId\":\"47506551\",\"name\":\"Qiang Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"title\":\"Dual Attention on Pyramid Feature Maps for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144469308\",\"name\":\"Jian Wang\"},{\"authorId\":\"145534714\",\"name\":\"Jie Feng\"}],\"doi\":\"10.1109/ACCESS.2020.3018546\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"123361e4769f2f8a17742197aa52cc676a4caa9a\",\"title\":\"Hybrid Attention Distribution and Factorized Embedding Matrix in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123361e4769f2f8a17742197aa52cc676a4caa9a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/ISM.2018.00021\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"title\":\"Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.10410\",\"authors\":[{\"authorId\":\"150259692\",\"name\":\"Phanideep Gampa\"},{\"authorId\":\"33208854\",\"name\":\"Sumio Fujita\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a15d89fd6e7f2d2c918d0fce82c35db991f2623c\",\"title\":\"BanditRank: Learning to Rank Using Contextual Bandits\",\"url\":\"https://www.semanticscholar.org/paper/a15d89fd6e7f2d2c918d0fce82c35db991f2623c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46180754\",\"name\":\"Philippe Laban\"},{\"authorId\":\"1754922339\",\"name\":\"Andrew Hsi Bloomberg\"},{\"authorId\":\"1729041\",\"name\":\"J. Canny\"},{\"authorId\":\"1716902\",\"name\":\"Marti A. Hearst\"}],\"doi\":\"10.18653/v1/2020.acl-main.460\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed32242d76f0f52e3eace19b0314868f1d868b89\",\"title\":\"The Summary Loop: Learning to Write Abstractive Summaries Without Examples\",\"url\":\"https://www.semanticscholar.org/paper/ed32242d76f0f52e3eace19b0314868f1d868b89\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255213\",\"name\":\"Z. Zhang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"47337540\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"2597292\",\"name\":\"Chuanqi Tan\"}],\"doi\":\"10.1109/TCSVT.2019.2936526\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"title\":\"Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152923588\",\"name\":\"Giuseppe Lancioni\"},{\"authorId\":\"2008158617\",\"name\":\"Saida S.Mohamed\"},{\"authorId\":\"1805998814\",\"name\":\"Beatrice Portelli\"},{\"authorId\":\"2275344\",\"name\":\"G. Serra\"},{\"authorId\":\"1705232\",\"name\":\"C. Tasso\"}],\"doi\":\"10.18653/v1/2020.sustainlp-1.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51443355ff6f4bbf07d04e0840bf4702cd173379\",\"title\":\"Keyphrase Generation with GANs in Low-Resources Scenarios\",\"url\":\"https://www.semanticscholar.org/paper/51443355ff6f4bbf07d04e0840bf4702cd173379\",\"venue\":\"SUSTAINLP\",\"year\":2020},{\"arxivId\":\"1908.10419\",\"authors\":[{\"authorId\":\"3375249\",\"name\":\"Yuning Mao\"},{\"authorId\":\"47068990\",\"name\":\"Jing-jing Tian\"},{\"authorId\":\"122203801\",\"name\":\"J. Han\"},{\"authorId\":\"152437364\",\"name\":\"Xiang Ren\"}],\"doi\":\"10.18653/v1/D19-1042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"140b121bbe5b242ff15629285f06ab755541d8d1\",\"title\":\"Hierarchical Text Classification with Reinforced Label Assignment\",\"url\":\"https://www.semanticscholar.org/paper/140b121bbe5b242ff15629285f06ab755541d8d1\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1911.10082\",\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"title\":\"Injecting Prior Knowledge into Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e4dcd3fa308b263cee8c7581e2d695dc15c2f51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.02923\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":\"10.1613/jair.1.12025\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"title\":\"Image Captioning using Facial Expression and Attention\",\"url\":\"https://www.semanticscholar.org/paper/29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2020},{\"arxivId\":\"2002.08277\",\"authors\":[{\"authorId\":\"1591146157\",\"name\":\"Yixiao Zhang\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"1742135\",\"name\":\"Ziyue Xu\"},{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"}],\"doi\":\"10.1609/AAAI.V34I07.6989\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5fa82dfbf469a793d7c98804a63a8acf7d9e4a5f\",\"title\":\"When Radiology Report Generation Meets Knowledge Graph\",\"url\":\"https://www.semanticscholar.org/paper/5fa82dfbf469a793d7c98804a63a8acf7d9e4a5f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50443188\",\"name\":\"Shuqi Yu\"},{\"authorId\":\"1771202\",\"name\":\"Linmei Hu\"},{\"authorId\":\"144730520\",\"name\":\"B. Wu\"}],\"doi\":\"10.1007/978-3-030-29551-6_62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"807b538d7deac7400915659176d72f1fbf5c018a\",\"title\":\"DRAM: A Deep Reinforced Intra-attentive Model for Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/807b538d7deac7400915659176d72f1fbf5c018a\",\"venue\":\"KSEM\",\"year\":2019},{\"arxivId\":\"1808.10584\",\"authors\":[{\"authorId\":\"2006291\",\"name\":\"Harsh Jhamtani\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"}],\"doi\":\"10.18653/v1/D18-1436\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7062b5de5fddb298823cf8969c7dfa6165ea933e\",\"title\":\"Learning to Describe Differences Between Pairs of Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/7062b5de5fddb298823cf8969c7dfa6165ea933e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"144675299\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"title\":\"The Fashion IQ Dataset: Retrieving Images by Combining Side Information and Relative Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/32c0166abbf99a962c43722d78cf15ba3f843fbf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.04689\",\"authors\":[{\"authorId\":\"51436197\",\"name\":\"Erion cCano\"},{\"authorId\":\"151158933\",\"name\":\"Ondvrej Bojar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"036153fac75e306c00ac05a262d2bd4d029f7ec5\",\"title\":\"Two Huge Title and Keyword Generation Corpora of Research Articles\",\"url\":\"https://www.semanticscholar.org/paper/036153fac75e306c00ac05a262d2bd4d029f7ec5\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121240779\",\"name\":\"Y. Huang\"},{\"authorId\":\"102732209\",\"name\":\"J. Feng\"},{\"authorId\":\"1625890628\",\"name\":\"Min Hu\"},{\"authorId\":\"50171614\",\"name\":\"X. Wu\"},{\"authorId\":\"49709601\",\"name\":\"Xiaoyu Du\"},{\"authorId\":\"48837101\",\"name\":\"S. Ma\"}],\"doi\":\"10.18653/v1/2020.acl-main.636\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c997f56183ca4fbffdb16666e7996c7552e9a0e3\",\"title\":\"Meta-Reinforced Multi-Domain State Generator for Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/c997f56183ca4fbffdb16666e7996c7552e9a0e3\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.98\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3263b941d0a77bbd2040612ec774ef063ef64c48\",\"title\":\"Semi-Supervised Learning for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3263b941d0a77bbd2040612ec774ef063ef64c48\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.12214\",\"authors\":[{\"authorId\":\"9729107\",\"name\":\"N. Sultana\"},{\"authorId\":\"145642632\",\"name\":\"Jeffrey Chan\"},{\"authorId\":\"145587600\",\"name\":\"A. Qin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3805c99f092f961f81538bea1d3727f552b72727\",\"title\":\"Learning to Optimise General TSP Instances\",\"url\":\"https://www.semanticscholar.org/paper/3805c99f092f961f81538bea1d3727f552b72727\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.15454\",\"authors\":[{\"authorId\":null,\"name\":\"Wei-Ning Hsu\"},{\"authorId\":null,\"name\":\"David Harwath\"},{\"authorId\":null,\"name\":\"Christopher Song\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"title\":\"Text-Free Image-to-Speech Synthesis Using Learned Segmental Units\",\"url\":\"https://www.semanticscholar.org/paper/5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443433\",\"name\":\"William Boag\"},{\"authorId\":\"50229020\",\"name\":\"Emily Alsentzer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28af66148c1728fc1cd9775242cecf6c6fc7f3c3\",\"title\":\"Baselines for Chest X-Ray Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/28af66148c1728fc1cd9775242cecf6c6fc7f3c3\",\"venue\":\"ML4H@NeurIPS\",\"year\":2019},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1807.10854\",\"authors\":[{\"authorId\":\"51151229\",\"name\":\"Daniel W. Otter\"},{\"authorId\":\"51149804\",\"name\":\"J. R. Medina\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/tnnls.2020.2979670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"title\":\"A Survey of the Usages of Deep Learning in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1777482\",\"name\":\"W. Wang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"48626691\",\"name\":\"Haoran Shi\"},{\"authorId\":\"145162320\",\"name\":\"F. Xu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82ae0d4b41046ccedb435ece08a61f198cf77bb9\",\"title\":\"Toward Unsupervised Text Content Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/82ae0d4b41046ccedb435ece08a61f198cf77bb9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.00121\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"145468578\",\"name\":\"Ke Lin\"},{\"authorId\":\"1772128\",\"name\":\"A. Maye\"},{\"authorId\":\"47786863\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3389/frobt.2020.475767\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"304f94dbe2ed228309e86298766ad24d9b6c6747\",\"title\":\"A Semantics-Assisted Video Captioning Model Trained With Scheduled Sampling\",\"url\":\"https://www.semanticscholar.org/paper/304f94dbe2ed228309e86298766ad24d9b6c6747\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"49865085\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-20876-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"title\":\"Multivariate Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2374218\",\"name\":\"Jinpeng Li\"},{\"authorId\":\"151505992\",\"name\":\"Chuang Zhang\"},{\"authorId\":\"39932166\",\"name\":\"Xiaojun Chen\"},{\"authorId\":\"1500401931\",\"name\":\"Yanan Cao\"},{\"authorId\":\"1420372357\",\"name\":\"Ruipeng Jia\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206950\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57752b9ca1127bf923537a6f4d1a6afdaba1518a\",\"title\":\"Improving Abstractive Summarization with Iterative Representation\",\"url\":\"https://www.semanticscholar.org/paper/57752b9ca1127bf923537a6f4d1a6afdaba1518a\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145523333\",\"name\":\"Peng Yao\"},{\"authorId\":\"102227937\",\"name\":\"J. Li\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"}],\"doi\":\"10.1109/ICME46284.2020.9102935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59d65f0719287512f3f605615f64b7eda27db97b\",\"title\":\"Modeling Local and Global Contexts for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59d65f0719287512f3f605615f64b7eda27db97b\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150347383\",\"name\":\"Y. Deng\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.24963/ijcai.2019/688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"653c9afe0c93d27047cc09e69d4151d55abc6a46\",\"title\":\"Learning Assistance from an Adversarial Critic for Multi-Outputs Prediction\",\"url\":\"https://www.semanticscholar.org/paper/653c9afe0c93d27047cc09e69d4151d55abc6a46\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"2001.06944\",\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"86724befacdd9fd8748607f5b025aa59fb7ef010\",\"title\":\"Nested-Wasserstein Self-Imitation Learning for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/86724befacdd9fd8748607f5b025aa59fb7ef010\",\"venue\":\"AISTATS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3375353\",\"name\":\"Ali Montazeralghaem\"},{\"authorId\":\"1830454635\",\"name\":\"Hamed Zamani\"},{\"authorId\":\"31847540\",\"name\":\"J. Allan\"}],\"doi\":\"10.1145/3397271.3401099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86d587c272257787ca4d207d3f5c697deef9cf06\",\"title\":\"A Reinforcement Learning Framework for Relevance Feedback\",\"url\":\"https://www.semanticscholar.org/paper/86d587c272257787ca4d207d3f5c697deef9cf06\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.11988\",\"authors\":[{\"authorId\":\"15311497\",\"name\":\"Pirmin Lemberger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"746d91676fe851df1704d8c4eda816afe8f521e9\",\"title\":\"Deep Learning Models for Automatic Summarization\",\"url\":\"https://www.semanticscholar.org/paper/746d91676fe851df1704d8c4eda816afe8f521e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.07112\",\"authors\":[{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"39108991\",\"name\":\"Shuai Mu\"},{\"authorId\":\"1410650653\",\"name\":\"Wanpeng Xiao\"},{\"authorId\":\"1410066883\",\"name\":\"Zexiong Ye\"},{\"authorId\":\"1410052649\",\"name\":\"Liesi Wu\"},{\"authorId\":\"102396462\",\"name\":\"Fuming Ma\"},{\"authorId\":\"34974680\",\"name\":\"Q. Ju\"}],\"doi\":\"10.1609/aaai.v33i01.33018142\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"title\":\"Improving Image Captioning with Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3237142\",\"name\":\"Junwen Duan\"},{\"authorId\":\"145411800\",\"name\":\"Xiao Ding\"},{\"authorId\":\"46999402\",\"name\":\"T. Liu\"}],\"doi\":\"10.18653/v1/N18-1051\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce8aa63c8b19d8bae13e051b70356353823eee0b\",\"title\":\"Learning Sentence Representations over Tree Structures for Target-Dependent Classification\",\"url\":\"https://www.semanticscholar.org/paper/ce8aa63c8b19d8bae13e051b70356353823eee0b\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144426235\",\"name\":\"J. Hughes\"},{\"authorId\":\"1845928\",\"name\":\"Keng-hao Chang\"},{\"authorId\":\"1694966\",\"name\":\"R. Zhang\"}],\"doi\":\"10.1145/3292500.3330754\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"19738b0337a6265b3c7e7238565588d71af5dcdd\",\"title\":\"Generating Better Search Engine Text Advertisements with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/19738b0337a6265b3c7e7238565588d71af5dcdd\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ming Jiang\"},{\"authorId\":null,\"name\":\"Qi Zhao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3977c0056755c2911811509ac38e0cef532004b0\",\"title\":\"Self-Distillation for Few-Shot Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3977c0056755c2911811509ac38e0cef532004b0\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46252591\",\"name\":\"Xiangpeng Wei\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"30967877\",\"name\":\"Luxi Xing\"},{\"authorId\":\"145795798\",\"name\":\"Li Gao\"}],\"doi\":\"10.18653/v1/K19-1027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f53c642670562d41a530e391d4d08df63ea76674\",\"title\":\"Unsupervised Neural Machine Translation with Future Rewarding\",\"url\":\"https://www.semanticscholar.org/paper/f53c642670562d41a530e391d4d08df63ea76674\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141700\",\"name\":\"D. Huang\"},{\"authorId\":\"46700619\",\"name\":\"Jing Liu\"},{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"},{\"authorId\":\"144926874\",\"name\":\"J. Yin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"caeb950e503872a903e18a3b259424e3cc3c6006\",\"title\":\"Neural Math Word Problem Solver with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/caeb950e503872a903e18a3b259424e3cc3c6006\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"},{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"},{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1394465427\",\"name\":\"Qiuyu Cai\"}],\"doi\":\"10.1145/3394171.3416290\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"93aed487e9b9f51bf05803ef69c92599001358ac\",\"title\":\"XlanV Model with Adaptively Multi-Modality Feature Fusing for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93aed487e9b9f51bf05803ef69c92599001358ac\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.00760\",\"authors\":[{\"authorId\":\"3443241\",\"name\":\"Bicheng Xu\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.14288/1.0392691\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e7139debfcff8c193bc0141302218fe0d4c8a32\",\"title\":\"Consistent Multiple Sequence Decoding\",\"url\":\"https://www.semanticscholar.org/paper/5e7139debfcff8c193bc0141302218fe0d4c8a32\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.11102\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1923156\",\"name\":\"Peng Yao\"},{\"authorId\":\"1749850\",\"name\":\"Jing Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shichen Lu\"},{\"authorId\":\"2125223\",\"name\":\"Zheng Gen Yu\"},{\"authorId\":\"46641690\",\"name\":\"Wei Liu\"},{\"authorId\":\"46386029\",\"name\":\"Hanqing Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"title\":\"Multi-View Features and Hybrid Reward Strategies for Vatex Video Captioning Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47906104\",\"name\":\"Yucheng Wang\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"1799071\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/D18-1090\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ad65a10d18b162524e78f023c5fa0d10ceb56888\",\"title\":\"Automatic Essay Scoring Incorporating Rating Schema via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/ad65a10d18b162524e78f023c5fa0d10ceb56888\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1909.09953\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b488019592d8e0c08e6cd011ae0543a6ac451357\",\"title\":\"Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators\",\"url\":\"https://www.semanticscholar.org/paper/b488019592d8e0c08e6cd011ae0543a6ac451357\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.13374\",\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"9108287\",\"name\":\"Chunyan Miao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65cd8db16879150a3266eb989f6358c6eac32b8b\",\"title\":\"Decomposed Generation Networks with Structure Prediction for Recipe Generation from Food Images\",\"url\":\"https://www.semanticscholar.org/paper/65cd8db16879150a3266eb989f6358c6eac32b8b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978802390\",\"name\":\"Haolei Pei\"},{\"authorId\":\"8559954\",\"name\":\"Q. Chen\"},{\"authorId\":\"13257164\",\"name\":\"J. Wang\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"1680030\",\"name\":\"Yubo Jia\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206815\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"title\":\"Visual Relational Reasoning for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362315\",\"name\":\"J. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"},{\"authorId\":\"47789939\",\"name\":\"J. Lu\"}],\"doi\":\"10.1109/ICC40277.2020.9149264\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3a5a6c759925570ab178c45340d34174fc8760f3\",\"title\":\"Local-to-Global Semantic Supervised Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3a5a6c759925570ab178c45340d34174fc8760f3\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":\"2010.11553\",\"authors\":[{\"authorId\":\"1455114388\",\"name\":\"Hrituraj Singh\"},{\"authorId\":\"145816931\",\"name\":\"Gaurav Verma\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.96\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"de0f85927c9d300fc6458b9552a267b6cd952054\",\"title\":\"Incorporating Stylistic Lexical Preferences in Generative Language Models\",\"url\":\"https://www.semanticscholar.org/paper/de0f85927c9d300fc6458b9552a267b6cd952054\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924492\",\"name\":\"Jian Wang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"1844673750\",\"name\":\"Wei Bi\"},{\"authorId\":\"3028405\",\"name\":\"Xiaojiang Liu\"},{\"authorId\":\"30804815\",\"name\":\"Kejing He\"},{\"authorId\":\"1753529\",\"name\":\"Ruifeng Xu\"},{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8d1bba29ee07abcc0586d5cbe056d11f8041077\",\"title\":\"Dual Dynamic Memory Network for End-to-End Multi-turn Task-oriented Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/d8d1bba29ee07abcc0586d5cbe056d11f8041077\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1911.03047\",\"authors\":[{\"authorId\":\"31497621\",\"name\":\"W. S. Cho\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1675319352\",\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144628574\",\"name\":\"Chenyan Xiong\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"50468734\",\"name\":\"M. Wang\"},{\"authorId\":\"66648221\",\"name\":\"B. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab2777c7f39c5352dd8ab2335c45aafa4194a025\",\"title\":\"Contrastive Multi-document Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/ab2777c7f39c5352dd8ab2335c45aafa4194a025\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38593127\",\"name\":\"Wei Wang\"},{\"authorId\":\"16215052\",\"name\":\"Hai-Tao Zheng\"},{\"authorId\":\"38314901\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-16142-2_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"542805bb3421578e390de5ee249e675f103050ba\",\"title\":\"User Preference-Aware Review Generation\",\"url\":\"https://www.semanticscholar.org/paper/542805bb3421578e390de5ee249e675f103050ba\",\"venue\":\"PAKDD\",\"year\":2019},{\"arxivId\":\"1811.09740\",\"authors\":[{\"authorId\":\"10918587\",\"name\":\"Bowen Tan\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b2c61b87f82b888d86fb10c7947c5b380c3cbf06\",\"title\":\"Connecting the Dots Between MLE and RL for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/b2c61b87f82b888d86fb10c7947c5b380c3cbf06\",\"venue\":\"DeepRLStructPred@ICLR\",\"year\":2019},{\"arxivId\":\"2011.07635\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"48843025\",\"name\":\"Han Guo\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.625\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1fb985c6624bede346e05f9ef16aa4505731c330\",\"title\":\"DORB: Dynamically Optimizing Multiple Rewards with Bandits\",\"url\":\"https://www.semanticscholar.org/paper/1fb985c6624bede346e05f9ef16aa4505731c330\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.06822\",\"authors\":[{\"authorId\":\"9252833\",\"name\":\"Faeze Brahman\"},{\"authorId\":\"37202877\",\"name\":\"S. Chaturvedi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.426\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"63c1abce10c354c64b9d521ee959f9d3dd409169\",\"title\":\"Modeling Protagonist Emotions for Emotion-Aware Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/63c1abce10c354c64b9d521ee959f9d3dd409169\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.06165\",\"authors\":[{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"145307652\",\"name\":\"Li Dong\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1007/978-3-030-58577-8_8\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"title\":\"Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/818e5cbc337e4e1b98e65a2d7c2d6d2a0318cd57\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8353931\",\"name\":\"Jiahe Shi\"},{\"authorId\":\"5550675\",\"name\":\"Y. Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"}],\"doi\":\"10.1109/ICIP.2019.8803149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c054cda5375018e902daab0b0875773a854d035\",\"title\":\"Cascade Attention: Multiple Feature Based Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c054cda5375018e902daab0b0875773a854d035\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1809.04585\",\"authors\":[{\"authorId\":\"31688795\",\"name\":\"Yichen Jiang\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D18-1440\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"318173d2c078f42ce4c6a1da5c621b707a9cdec8\",\"title\":\"Closed-Book Training to Improve Summarization Encoder Memory\",\"url\":\"https://www.semanticscholar.org/paper/318173d2c078f42ce4c6a1da5c621b707a9cdec8\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fc8df4ad35282ccf19261e02de87d8e35c956537\",\"title\":\"Binary Image Selection (BISON): Interpretable Evaluation of Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fc8df4ad35282ccf19261e02de87d8e35c956537\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123261131\",\"name\":\"Alexios Gidiotis\"},{\"authorId\":\"2502501\",\"name\":\"Grigorios Tsoumakas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac87ce22d3b8cd2668793d93ce7b361cda7193c0\",\"title\":\"A Divide-and-Conquer Approach to the Summarization of Academic Articles\",\"url\":\"https://www.semanticscholar.org/paper/ac87ce22d3b8cd2668793d93ce7b361cda7193c0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.01475\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/CVPR.2019.01275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908c6b1577a1f5309ae183daf2e24363039f22a8\",\"title\":\"Good News, Everyone! Context Driven Entity-Aware Captioning for News Images\",\"url\":\"https://www.semanticscholar.org/paper/908c6b1577a1f5309ae183daf2e24363039f22a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8682392\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4dee549ba6f09e59c6d6d13434a2b023d868467a\",\"title\":\"Image Captioning with Two Cascaded Agents\",\"url\":\"https://www.semanticscholar.org/paper/4dee549ba6f09e59c6d6d13434a2b023d868467a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145823439\",\"name\":\"Q. Song\"},{\"authorId\":\"1575953512\",\"name\":\"Yonghuan Wu\"},{\"authorId\":\"1729394659\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1145/3386415.3387080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70c4996ffd3d65b1b67a13c33637caa0a7267a1b\",\"title\":\"An Overview of Deep Learning in Power Production\",\"url\":\"https://www.semanticscholar.org/paper/70c4996ffd3d65b1b67a13c33637caa0a7267a1b\",\"venue\":\"ICITEE\",\"year\":2019},{\"arxivId\":\"1909.09060\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"312799645adfafb886f156708a7a36f2db459c62\",\"title\":\"Adaptively Aligned Image Captioning via Adaptive Attention Time\",\"url\":\"https://www.semanticscholar.org/paper/312799645adfafb886f156708a7a36f2db459c62\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4634604\",\"name\":\"Xinyuan Qi\"},{\"authorId\":\"1795646\",\"name\":\"Z. Cao\"},{\"authorId\":\"144209660\",\"name\":\"Yang Xiao\"},{\"authorId\":\"46584851\",\"name\":\"J. Wang\"},{\"authorId\":null,\"name\":\"Chao Zhang\"}],\"doi\":\"10.1007/978-3-030-03338-5_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c828c5700dbd26d351d9b222db1c826ba4e81c\",\"title\":\"The Accurate Guidance for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/e0c828c5700dbd26d351d9b222db1c826ba4e81c\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"144841444\",\"name\":\"Michelangelo Ceci\"},{\"authorId\":\"1725650\",\"name\":\"S. Ferilli\"},{\"authorId\":\"40291891\",\"name\":\"A. Poggi\"}],\"doi\":\"10.1007/978-3-030-39905-4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"267f2d6635177ff0b0983c560c5d513b10a30626\",\"title\":\"Digital Libraries: The Era of Big Data and Data Science: 16th Italian Research Conference on Digital Libraries, IRCDL 2020, Bari, Italy, January 30\\u201331, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/267f2d6635177ff0b0983c560c5d513b10a30626\",\"venue\":\"IRCDL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"2001.11691\",\"authors\":[{\"authorId\":\"150341221\",\"name\":\"Wangchunshu Zhou\"},{\"authorId\":\"50251691\",\"name\":\"Tao Ge\"},{\"authorId\":\"71084877\",\"name\":\"Ke Xu\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"92660691\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0a2a6ceb81855761e8e5d14ec43901714d455b92\",\"title\":\"Self-Adversarial Learning with Comparative Discrimination for Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/0a2a6ceb81855761e8e5d14ec43901714d455b92\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5947095\",\"name\":\"Byeong Jo Kim\"},{\"authorId\":\"47634928\",\"name\":\"Yong Hoon Choi\"}],\"doi\":\"10.1145/3341105.3374063\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"title\":\"Automatic baseball commentary generation using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/ad8dd9815372778e0d2617a67cc0ace7771c3fb3\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"1812.08989\",\"authors\":[{\"authorId\":\"49718206\",\"name\":\"L. Zhou\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1162/coli_a_00368\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"66b7d31527f980bb2eecc23629f08ba6037facc4\",\"title\":\"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot\",\"url\":\"https://www.semanticscholar.org/paper/66b7d31527f980bb2eecc23629f08ba6037facc4\",\"venue\":\"Computational Linguistics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394741222\",\"name\":\"Yuling Gui\"},{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"97522088\",\"name\":\"Ye Zhao\"}],\"doi\":\"10.1145/3347319.3356839\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9fc5e1793d9836d6c19cbd933d8b1fcc01dcc22f\",\"title\":\"Semantic Enhanced Encoder-Decoder Network (SEN) for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fc5e1793d9836d6c19cbd933d8b1fcc01dcc22f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.02347\",\"authors\":[{\"authorId\":\"143891667\",\"name\":\"Long Chen\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/ICCV.2019.00471\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"title\":\"Counterfactual Critic Multi-Agent Training for Scene Graph Generation\",\"url\":\"https://www.semanticscholar.org/paper/f37d93ac4dc22b00d8a0cd1b5d54764eb8a2c5d5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2860490\",\"name\":\"K. Acheampong\"},{\"authorId\":\"39720104\",\"name\":\"W. Tian\"},{\"authorId\":\"1420117549\",\"name\":\"Addis Abebe Assifa\"}],\"doi\":\"10.1145/3361758.3361783\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f99c7fe2007002073876a3c0c9f43de67df235c4\",\"title\":\"Redefining Learning in Visual Comparison with Spatio-relational Context-aware Representations\",\"url\":\"https://www.semanticscholar.org/paper/f99c7fe2007002073876a3c0c9f43de67df235c4\",\"venue\":\"BDIOT 2019\",\"year\":2019},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1906.01452\",\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"40474871\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1109/TPAMI.2019.2920899\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"83a3fe38887880bccc15daa740d8d5041f826d91\",\"title\":\"Reconstruct and Represent Video Contents for Captioning via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/83a3fe38887880bccc15daa740d8d5041f826d91\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/cvpr42600.2020.01098\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"title\":\"X-Linear Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1903.10658\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"7574699\",\"name\":\"Handong Zhao\"},{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICCV.2019.01042\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"title\":\"Unpaired Image Captioning via Scene Graph Alignments\",\"url\":\"https://www.semanticscholar.org/paper/f4c60c3ee4904d61ff84c9d4c15c9aecdcf04cdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.11693\",\"authors\":[{\"authorId\":\"1563987322\",\"name\":\"Teng Wang\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":\"47730643\",\"name\":\"Mingjing Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2383f16ecc732601af6c3929e8a3abfca193d87\",\"title\":\"Dense-Captioning Events in Videos: SYSU Submission to ActivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/d2383f16ecc732601af6c3929e8a3abfca193d87\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37212795\",\"name\":\"R\\u00e9mi Leblond\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"868687266b8af75ac6ceb21d9d8b38cdba448c57\",\"title\":\"Asynchronous optimization for machine learning\",\"url\":\"https://www.semanticscholar.org/paper/868687266b8af75ac6ceb21d9d8b38cdba448c57\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.13370\",\"authors\":[{\"authorId\":\"2524647\",\"name\":\"Tahira Naseem\"},{\"authorId\":\"37686925\",\"name\":\"Abhishek Shah\"},{\"authorId\":\"49537705\",\"name\":\"Hui Wan\"},{\"authorId\":\"1707117\",\"name\":\"Radu Florian\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"143668305\",\"name\":\"Miguel Ballesteros\"}],\"doi\":\"10.18653/v1/P19-1451\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cc369961ce9cd04f300ee0a81646556ee0626c3\",\"title\":\"Rewarding Smatch: Transition-Based AMR Parsing with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/8cc369961ce9cd04f300ee0a81646556ee0626c3\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"2003.02738\",\"authors\":[{\"authorId\":\"145235730\",\"name\":\"Florian Schmidt\"},{\"authorId\":\"153379696\",\"name\":\"T. Hofmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de9e7d6319b26c0d9f0da20c79403e9b9367fff4\",\"title\":\"BERT as a Teacher: Contextual Embeddings for Sequence-Level Reward\",\"url\":\"https://www.semanticscholar.org/paper/de9e7d6319b26c0d9f0da20c79403e9b9367fff4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"2003.03107\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"1411260673\",\"name\":\"Luke Melas-Kyriazi\"}],\"doi\":\"10.1109/cvpr42600.2020.00486\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e9419436682726232e1b37a04c53bba919b12025\",\"title\":\"Show, Edit and Tell: A Framework for Editing Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/e9419436682726232e1b37a04c53bba919b12025\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0af1363c2d03e5d2435d9ba2b05ca5aecd568fd\",\"title\":\"PicSOM and EURECOM Experiments in TRECVID 2019\",\"url\":\"https://www.semanticscholar.org/paper/d0af1363c2d03e5d2435d9ba2b05ca5aecd568fd\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6998\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9421fa26257e6a8d59bb874cf3b376c6d4c4118b\",\"title\":\"MemCap: Memorizing Style Knowledge for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9421fa26257e6a8d59bb874cf3b376c6d4c4118b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.08897\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01034\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"833560cd68a3e3d1be1bc650756dd6c679798551\",\"title\":\"Normalized and Geometry-Aware Self-Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/833560cd68a3e3d1be1bc650756dd6c679798551\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145113946\",\"name\":\"J. Tang\"},{\"authorId\":\"144005516\",\"name\":\"Jing Wang\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3291925\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a437bb550d1df02188e4b145e01675551da36336\",\"title\":\"Show, Reward, and Tell\",\"url\":\"https://www.semanticscholar.org/paper/a437bb550d1df02188e4b145e01675551da36336\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1901.06283\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"Bai Li\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"717daba98eb57b898687fc013b705f763eb2916b\",\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/717daba98eb57b898687fc013b705f763eb2916b\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"3374688\",\"name\":\"M. Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":null,\"name\":\"Heng Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"}],\"doi\":\"10.1016/J.PATREC.2019.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749f376d0addb83569fcc7536e46308abbb232d4\",\"title\":\"How much do cross-modal related semantics benefit image captioning by weighting attributes and re-ranking sentences?\",\"url\":\"https://www.semanticscholar.org/paper/749f376d0addb83569fcc7536e46308abbb232d4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"2011.07680\",\"authors\":[{\"authorId\":\"1477956290\",\"name\":\"Wenting Xu\"},{\"authorId\":\"2023765018\",\"name\":\"C. Qi\"},{\"authorId\":\"50070382\",\"name\":\"Zhenghua Xu\"},{\"authorId\":\"1690572\",\"name\":\"Thomas Lukasiewicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"504e7bba81083ebbc4e114e48938ebaffb5ba03c\",\"title\":\"Reinforced Medical Report Generation with X-Linear Attention and Repetition Penalty\",\"url\":\"https://www.semanticscholar.org/paper/504e7bba81083ebbc4e114e48938ebaffb5ba03c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10604\",\"authors\":[{\"authorId\":\"8010189\",\"name\":\"Xinjie Fan\"},{\"authorId\":\"1515867113\",\"name\":\"Shujian Zhang\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"83243b3639bbb42566bc300b4999db9a2b7a93c3\",\"title\":\"Bayesian Attention Modules\",\"url\":\"https://www.semanticscholar.org/paper/83243b3639bbb42566bc300b4999db9a2b7a93c3\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042707165\",\"name\":\"Anfal Attai\"},{\"authorId\":\"145973534\",\"name\":\"Ashraf Elnagar\"}],\"doi\":\"10.1109/IIT50501.2020.9299027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"002544729825daf6843a471ccb22d446969511b7\",\"title\":\"A survey on Arabic Image Captioning Systems Using Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/002544729825daf6843a471ccb22d446969511b7\",\"venue\":\"2020 14th International Conference on Innovations in Information Technology (IIT)\",\"year\":2020},{\"arxivId\":\"2003.00425\",\"authors\":[{\"authorId\":\"1928586\",\"name\":\"B. Uzkent\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"}],\"doi\":\"10.1109/cvpr42600.2020.01236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c34d96ea25c5e702c7f6329403503736d6ddf9d\",\"title\":\"Learning When and Where to Zoom With Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/0c34d96ea25c5e702c7f6329403503736d6ddf9d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30658665\",\"name\":\"Z. Li\"},{\"authorId\":\"108085542\",\"name\":\"Rui Wang\"},{\"authorId\":\"2849740\",\"name\":\"Kehai Chen\"},{\"authorId\":\"1583166440\",\"name\":\"Masso Utiyama\"},{\"authorId\":\"1698363\",\"name\":\"Eiichiro Sumita\"},{\"authorId\":\"3322871\",\"name\":\"Zhuosheng Zhang\"},{\"authorId\":\"47941144\",\"name\":\"Hai Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"69e4dabf1f140915878a365c1adb86ceb2362ab6\",\"title\":\"Data-dependent Gaussian Prior Objective for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/69e4dabf1f140915878a365c1adb86ceb2362ab6\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1804.10974\",\"authors\":[{\"authorId\":\"3422912\",\"name\":\"Zihang Dai\"},{\"authorId\":\"1912046\",\"name\":\"Qizhe Xie\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.18653/v1/P18-1155\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a72b85f65e1886da2c55fe8aa8f386fc873ba3b\",\"title\":\"From Credit Assignment to Entropy Regularization: Two New Algorithms for Neural Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3a72b85f65e1886da2c55fe8aa8f386fc873ba3b\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":\"10.1109/CVPR.2019.01071\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"title\":\"Adversarial Semantic Alignment for Improved Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145361612\",\"name\":\"N. Ye\"},{\"authorId\":\"2326719\",\"name\":\"A. Fuxman\"},{\"authorId\":\"2525389\",\"name\":\"Vivek Ramavajjala\"},{\"authorId\":\"145675237\",\"name\":\"S. Nazarov\"},{\"authorId\":\"48549223\",\"name\":\"J. P. McGregor\"},{\"authorId\":\"35014893\",\"name\":\"Sujith Ravi\"}],\"doi\":\"10.1145/3178876.3186164\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e1b04ba3e5c839046dc49c7af6a75599483431f\",\"title\":\"PhotoReply: Automatically Suggesting Conversational Responses to Photos\",\"url\":\"https://www.semanticscholar.org/paper/7e1b04ba3e5c839046dc49c7af6a75599483431f\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":\"1910.04748\",\"authors\":[{\"authorId\":\"12650171\",\"name\":\"Yi-Wen Chen\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"46958716\",\"name\":\"Tiantian Wang\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0096ee35502910ef560fc554b2980010aa1947b5\",\"title\":\"Referring Expression Object Segmentation with Caption-Aware Consistency\",\"url\":\"https://www.semanticscholar.org/paper/0096ee35502910ef560fc554b2980010aa1947b5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1808.00491\",\"authors\":[{\"authorId\":\"2920247\",\"name\":\"J. Niehues\"},{\"authorId\":\"50214018\",\"name\":\"N. Pham\"},{\"authorId\":\"3348286\",\"name\":\"Thanh-Le Ha\"},{\"authorId\":\"3011998\",\"name\":\"Matthias Sperber\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.21437/Interspeech.2018-1055\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a6c8b467167781a8570dfdfa111a70bf4046d73\",\"title\":\"Low-Latency Neural Speech Translation\",\"url\":\"https://www.semanticscholar.org/paper/3a6c8b467167781a8570dfdfa111a70bf4046d73\",\"venue\":\"INTERSPEECH\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41050714\",\"name\":\"Sandeep Narayan Parameswaran\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1145/3293353.3293391\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"title\":\"A Bottom-Up and Top-Down Approach for Image Captioning using Transformer\",\"url\":\"https://www.semanticscholar.org/paper/acc9221fbfbfe52a6a81032ea02f42449fc1eca9\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"46700004\",\"name\":\"J. Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TMM.2019.2951226\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"837a513a43c7bcce903edbacbfc507cba6451e21\",\"title\":\"Show, Tell, and Polish: Ruminant Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/837a513a43c7bcce903edbacbfc507cba6451e21\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49046908\",\"name\":\"Chunyi Liu\"},{\"authorId\":\"46808404\",\"name\":\"P. Wang\"},{\"authorId\":\"97576364\",\"name\":\"J. Xu\"},{\"authorId\":\"49969600\",\"name\":\"Z. Li\"},{\"authorId\":\"144030870\",\"name\":\"Jieping Ye\"}],\"doi\":\"10.1145/3292500.3330683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bcd44495a39ef35adcafc1d4dc32d3ecf3f4fac\",\"title\":\"Automatic Dialogue Summary Generation for Customer Service\",\"url\":\"https://www.semanticscholar.org/paper/3bcd44495a39ef35adcafc1d4dc32d3ecf3f4fac\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144093402\",\"name\":\"Peter Makarov\"},{\"authorId\":\"2053272\",\"name\":\"S. Clematide\"}],\"doi\":\"10.5167/UZH-162579\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e82d5e7210ac4a5a9ccb07af86a38ddd3c1c1933\",\"title\":\"Neural Transition-based String Transduction for Limited-Resource Setting in Morphology\",\"url\":\"https://www.semanticscholar.org/paper/e82d5e7210ac4a5a9ccb07af86a38ddd3c1c1933\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1901.06595\",\"authors\":[{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1109/ICCVW.2019.00237\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"title\":\"Evaluating Text-to-Image Matching using Binary Image Selection (BISON)\",\"url\":\"https://www.semanticscholar.org/paper/5a97e9a253a60814f76dab86e8a4ec65fc86e261\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34338341\",\"name\":\"Kushal Chawla\"},{\"authorId\":\"49363537\",\"name\":\"B. Srinivasan\"},{\"authorId\":\"2954043\",\"name\":\"Niyati Chhaya\"}],\"doi\":\"10.18653/v1/K19-1078\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"673d2cca98edea91ea25bf7b7660056819c73429\",\"title\":\"Generating Formality-Tuned Summaries Using Input-Dependent Rewards\",\"url\":\"https://www.semanticscholar.org/paper/673d2cca98edea91ea25bf7b7660056819c73429\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"2010.16056\",\"authors\":[{\"authorId\":\"46843171\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"1922182598\",\"name\":\"Yan Song\"},{\"authorId\":\"2678812\",\"name\":\"Tsung-Hui Chang\"},{\"authorId\":\"2005096276\",\"name\":\"Xiang Wan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.112\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"ebfc629ef2ed733e1c77df5e27c94f05eb012cab\",\"title\":\"Generating Radiology Reports via Memory-driven Transformer\",\"url\":\"https://www.semanticscholar.org/paper/ebfc629ef2ed733e1c77df5e27c94f05eb012cab\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.02143\",\"authors\":[{\"authorId\":\"144786228\",\"name\":\"D. Gupta\"},{\"authorId\":\"144612044\",\"name\":\"H. Chauhan\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"aed734405591bb0e836295900ceaf9e33951fee7\",\"title\":\"Reinforced Multi-task Approach for Multi-hop Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/aed734405591bb0e836295900ceaf9e33951fee7\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2010.15881\",\"authors\":[{\"authorId\":\"3479260\",\"name\":\"Yuncheng Hua\"},{\"authorId\":\"152244300\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":\"1730054\",\"name\":\"G. Qi\"},{\"authorId\":\"92476037\",\"name\":\"W. Wu\"},{\"authorId\":\"47538817\",\"name\":\"Jingyao Zhang\"},{\"authorId\":\"51892829\",\"name\":\"Daiqing Qi\"}],\"doi\":\"10.1016/j.websem.2020.100612\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d031e704e77e8010874c8f44f1b290a4f1fd02ad\",\"title\":\"Less is More: Data-Efficient Complex Question Answering over Knowledge Bases\",\"url\":\"https://www.semanticscholar.org/paper/d031e704e77e8010874c8f44f1b290a4f1fd02ad\",\"venue\":\"J. Web Semant.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3336495\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"715fe60a8615d283c70d12db13857d8948baebca\",\"title\":\"Pseudo-3D Attention Transfer Network with Content-aware Strategy for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/715fe60a8615d283c70d12db13857d8948baebca\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2005.01159\",\"authors\":[{\"authorId\":\"80518559\",\"name\":\"Luyang huang\"},{\"authorId\":\"50789977\",\"name\":\"L. Wu\"},{\"authorId\":\"153755145\",\"name\":\"L. Wang\"}],\"doi\":\"10.18653/v1/2020.acl-main.457\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa83f4f369af53e5d4fbdc7cce1808520e8e50a2\",\"title\":\"Knowledge Graph-Augmented Abstractive Summarization with Semantic-Driven Cloze Reward\",\"url\":\"https://www.semanticscholar.org/paper/fa83f4f369af53e5d4fbdc7cce1808520e8e50a2\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2012.14124\",\"authors\":[{\"authorId\":\"47475299\",\"name\":\"K. Shirai\"},{\"authorId\":\"2036498481\",\"name\":\"Kazuma Hashimoto\"},{\"authorId\":\"50123248\",\"name\":\"A. Eriguchi\"},{\"authorId\":\"49584970\",\"name\":\"T. Ninomiya\"},{\"authorId\":\"48608426\",\"name\":\"S. Mori\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6c65402de67aef611852baa6c89d0b97b3e4f06\",\"title\":\"Neural Text Generation with Artificial Negative Examples\",\"url\":\"https://www.semanticscholar.org/paper/f6c65402de67aef611852baa6c89d0b97b3e4f06\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.00145\",\"authors\":[{\"authorId\":\"3381900\",\"name\":\"E. Dodds\"},{\"authorId\":\"31922487\",\"name\":\"J. Culpepper\"},{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e09df55b9aaf6e81b210815106d5ea075e3aaad0\",\"title\":\"Modality-Agnostic Attention Fusion for visual search with text feedback\",\"url\":\"https://www.semanticscholar.org/paper/e09df55b9aaf6e81b210815106d5ea075e3aaad0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14451\",\"authors\":[{\"authorId\":\"21771052\",\"name\":\"Allen Nie\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.173\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"88c86523d500d636f453647385ddaa04085b5f1b\",\"title\":\"Pragmatic Issue-Sensitive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88c86523d500d636f453647385ddaa04085b5f1b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392406002\",\"name\":\"Arturs Polis\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4bfeae734bced5b2613af9f7d8271354b614e08e\",\"title\":\"Paragraph-length image captioning using hierarchical recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/4bfeae734bced5b2613af9f7d8271354b614e08e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":\"10.1145/3372278.3390679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1fd4006dd7edbdf6c28fb6db21c59dda8e16d08\",\"title\":\"Actor-Critic Sequence Generation for Relative Difference Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f1fd4006dd7edbdf6c28fb6db21c59dda8e16d08\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"},{\"authorId\":\"145469964\",\"name\":\"Manfred Huber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0da3c13de7923ca02cdf815328cf179e7b93f498\",\"title\":\"Show, Infer and Tell: Contextual Inference for Creative Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0da3c13de7923ca02cdf815328cf179e7b93f498\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394268425\",\"name\":\"Pascal Fecht\"},{\"authorId\":\"35327822\",\"name\":\"Sebastian Blank\"},{\"authorId\":\"40374223\",\"name\":\"Hans-Peter Zorn\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f92d3d4fc0d321dc5fe644eff4ee6beb1e7ffbb9\",\"title\":\"Sequential Transfer Learning in NLP for German Text Summarization\",\"url\":\"https://www.semanticscholar.org/paper/f92d3d4fc0d321dc5fe644eff4ee6beb1e7ffbb9\",\"venue\":\"SwissText\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1856671082\",\"name\":\"Shengjia Chen\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1145/3340531.3411948\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3428bac9141f6db961fc4665db1cbc9a196152da\",\"title\":\"Image Captioning with Internal and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3428bac9141f6db961fc4665db1cbc9a196152da\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":\"1911.09753\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.1609/AAAI.V34I03.5655\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b49c4285c6f744eaa5a653e7f7f0bc741ddbb8f5\",\"title\":\"Reinforcing an Image Caption Generator Using Off-Line Human Feedback\",\"url\":\"https://www.semanticscholar.org/paper/b49c4285c6f744eaa5a653e7f7f0bc741ddbb8f5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1905.00245\",\"authors\":[{\"authorId\":\"1722299\",\"name\":\"Charles Chen\"},{\"authorId\":\"3139133\",\"name\":\"Razvan C. Bunescu\"}],\"doi\":\"10.18653/v1/N19-1360\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4fcd069322b2249fbf6db44d1e54f36c0b095212\",\"title\":\"Context-Dependent Semantic Parsing over Temporally Structured Data\",\"url\":\"https://www.semanticscholar.org/paper/4fcd069322b2249fbf6db44d1e54f36c0b095212\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2003.03749\",\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1109/CVPR42600.2020.01090\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96485bda4f4118da249cc8a898230281ac8040a7\",\"title\":\"Better Captioning With Sequence-Level Exploration\",\"url\":\"https://www.semanticscholar.org/paper/96485bda4f4118da249cc8a898230281ac8040a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.05634\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/CVPR.2019.00676\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"title\":\"Adversarial Inference for Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145607944\",\"name\":\"Xin Guo\"},{\"authorId\":\"49532658\",\"name\":\"B. Zhu\"},{\"authorId\":\"2454625\",\"name\":\"L. Polan\\u00eda\"},{\"authorId\":\"35020996\",\"name\":\"Charles Boncelet\"},{\"authorId\":\"1800783\",\"name\":\"K. Barner\"}],\"doi\":\"10.1145/3242969.3264990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf4e5206722ba16061982b885f8c7c86beacd27c\",\"title\":\"Group-Level Emotion Recognition Using Hybrid Deep Models Based on Faces, Scenes, Skeletons and Visual Attentions\",\"url\":\"https://www.semanticscholar.org/paper/cf4e5206722ba16061982b885f8c7c86beacd27c\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":\"1904.00720\",\"authors\":[{\"authorId\":\"3366595\",\"name\":\"Ziyu Yao\"},{\"authorId\":\"88923917\",\"name\":\"Jayavardhan Reddy Peddamail\"},{\"authorId\":\"11121990\",\"name\":\"Huan Sun\"}],\"doi\":\"10.1145/3308558.3313632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9700322c4ccbf441373973f133e2aa95e5d73b2\",\"title\":\"CoaCor: Code Annotation for Code Retrieval with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/b9700322c4ccbf441373973f133e2aa95e5d73b2\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":\"1909.05316\",\"authors\":[{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.1609/AAAI.V34I05.6305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"title\":\"What Makes A Good Story? Designing Composite Rewards for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/978-3-030-31756-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"title\":\"The Encoder-Decoder Framework and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.02904\",\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"39341431\",\"name\":\"J. Zhang\"},{\"authorId\":\"32642190\",\"name\":\"Zhaoda Ye\"}],\"doi\":\"10.1109/TMM.2019.2951462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb0faa931e34f989962881f1528854c902ec6221\",\"title\":\"Deep Reinforcement Learning for Image Hashing\",\"url\":\"https://www.semanticscholar.org/paper/eb0faa931e34f989962881f1528854c902ec6221\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2008.05231\",\"authors\":[{\"authorId\":\"67213349\",\"name\":\"N. Messina\"},{\"authorId\":\"144514869\",\"name\":\"G. Amato\"},{\"authorId\":\"1699411\",\"name\":\"Andrea Esuli\"},{\"authorId\":\"1846129\",\"name\":\"F. Falchi\"},{\"authorId\":\"2209975\",\"name\":\"C. Gennaro\"},{\"authorId\":\"1405499517\",\"name\":\"St\\u00e9phane Marchand-Maillet\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52011033fb859c38bbcc82c311667feb38994ae3\",\"title\":\"Fine-grained Visual Textual Alignment for Cross-Modal Retrieval using Transformer Encoders\",\"url\":\"https://www.semanticscholar.org/paper/52011033fb859c38bbcc82c311667feb38994ae3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.11701\",\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":\"10.1145/3366423.3380137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a842fe8c25348627764462a57f0cd43d8cef103b\",\"title\":\"CLARA: Clinical Report Auto-completion\",\"url\":\"https://www.semanticscholar.org/paper/a842fe8c25348627764462a57f0cd43d8cef103b\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"2002.00876\",\"authors\":[{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"}],\"doi\":\"10.18653/v1/2020.acl-demos.38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab67dfaedee72c5551f127c3b2727ee69941cf0\",\"title\":\"Torch-Struct: Deep Structured Prediction Library\",\"url\":\"https://www.semanticscholar.org/paper/3ab67dfaedee72c5551f127c3b2727ee69941cf0\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153297544\",\"name\":\"X. Yang\"},{\"authorId\":\"118565563\",\"name\":\"Chong-Yang Gao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1145/3394171.3413859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"title\":\"Hierarchical Scene Graph Encoder-Decoder for Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92538707\",\"name\":\"Qi Zheng\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR42600.2020.01311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"title\":\"Syntax-Aware Action Targeting for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.11782\",\"authors\":[{\"authorId\":\"152584142\",\"name\":\"Zhengxiong Jia\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"}],\"doi\":\"10.1145/3372278.3390697\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"title\":\"iCap: Interactive Image Captioning with Predictive Text\",\"url\":\"https://www.semanticscholar.org/paper/87c7ec86e37178720686eba4d00ea53b2aca93d7\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50506129\",\"name\":\"E. Barati\"},{\"authorId\":\"2410994\",\"name\":\"Xue-wen Chen\"}],\"doi\":\"10.1145/3343031.3351037\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cf8a3f260fbe4ee104380437cd576a556dccd290\",\"title\":\"Critic-based Attention Network for Event-based Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cf8a3f260fbe4ee104380437cd576a556dccd290\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123247172\",\"name\":\"W. Zhang\"},{\"authorId\":\"39390758\",\"name\":\"Yue Ying\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1609/AAAI.V34I05.6503\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"076b02b481a41f1e07b8a2bdbe0ac8d946f9872e\",\"title\":\"Learning Long- and Short-Term User Literal-Preference with Multimodal Hierarchical Transformer Network for Personalized Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/076b02b481a41f1e07b8a2bdbe0ac8d946f9872e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2007.01350\",\"authors\":[{\"authorId\":\"41197234\",\"name\":\"J. Navr\\u00e1til\"},{\"authorId\":\"152294551\",\"name\":\"M. Arnold\"},{\"authorId\":\"6178753\",\"name\":\"B. Elder\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f96fc7a61be9e482bf91d1f42fe4621fde2e5d8\",\"title\":\"Uncertainty Prediction for Deep Sequential Regression Using Meta Models\",\"url\":\"https://www.semanticscholar.org/paper/9f96fc7a61be9e482bf91d1f42fe4621fde2e5d8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32125063\",\"name\":\"Hung-Jen Chen\"},{\"authorId\":\"26921530\",\"name\":\"A. Cheng\"},{\"authorId\":\"50270386\",\"name\":\"D. Juan\"},{\"authorId\":\"2005422893\",\"name\":\"Wei Wei\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5a58c44049977d8a8069f175af2d57e3fb81c49\",\"title\":\"Mitigating Forgetting in Online Continual Learning via Instance-Aware Parameterization\",\"url\":\"https://www.semanticscholar.org/paper/c5a58c44049977d8a8069f175af2d57e3fb81c49\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"36620933\",\"name\":\"S. Wang\"},{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8b2d224c8b69191c02dce750257c39d46b1c4a7b\",\"title\":\"A Reinforcement Learning Framework for Natural Question Generation using Bi-discriminators\",\"url\":\"https://www.semanticscholar.org/paper/8b2d224c8b69191c02dce750257c39d46b1c4a7b\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nasrin Sultana\"},{\"authorId\":null,\"name\":\"Jeffrey Chan\"},{\"authorId\":null,\"name\":\"A. K. Qin\"},{\"authorId\":null,\"name\":\"Tabinda Sarwar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3805c99f092f961f81538bea1d3727f552b72727\",\"title\":\"L G ] 3 N ov 2 02 0 Learning to Optimise General TSP Instances A Preprint\",\"url\":\"https://www.semanticscholar.org/paper/3805c99f092f961f81538bea1d3727f552b72727\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09774\",\"authors\":[{\"authorId\":\"1823518201\",\"name\":\"Brielen Madureira\"},{\"authorId\":\"69056125\",\"name\":\"D. Schlangen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4069dd677b205fba61b4dea75e26c148dee99c5\",\"title\":\"An Overview of Natural Language State Representation for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4069dd677b205fba61b4dea75e26c148dee99c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.04595\",\"authors\":[{\"authorId\":\"1754818\",\"name\":\"Anran Wang\"},{\"authorId\":\"26336902\",\"name\":\"Anh Tuan Luu\"},{\"authorId\":\"2121484\",\"name\":\"Chuan-Sheng Foo\"},{\"authorId\":\"7296648\",\"name\":\"Hongyuan Zhu\"},{\"authorId\":\"144447820\",\"name\":\"Yi Tay\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"}],\"doi\":\"10.1109/TIP.2019.2931534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"title\":\"Holistic Multi-Modal Memory Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/09acc6d00f710c8307ffa118a7dc77a00c692b74\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49168719\",\"name\":\"C. Yin\"},{\"authorId\":\"39835284\",\"name\":\"B. Qian\"},{\"authorId\":\"39791510\",\"name\":\"Jishang Wei\"},{\"authorId\":\"4185657\",\"name\":\"X. Li\"},{\"authorId\":\"1491248835\",\"name\":\"X. Zhang\"},{\"authorId\":\"48514123\",\"name\":\"Y. Li\"},{\"authorId\":\"50320297\",\"name\":\"Qinghua Zheng\"}],\"doi\":\"10.1109/ICDM.2019.00083\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b19f5a65e327868bf31a85fc03752b58e09d0d03\",\"title\":\"Automatic Generation of Medical Imaging Diagnostic Report with Hierarchical Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b19f5a65e327868bf31a85fc03752b58e09d0d03\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":\"1907.12905\",\"authors\":[{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":\"10.1145/3343031.3351060\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ea12e7ccefa226593a6918ae3100bfcd4b2d284\",\"title\":\"Watch It Twice: Video Captioning with a Refocused Video Encoder\",\"url\":\"https://www.semanticscholar.org/paper/5ea12e7ccefa226593a6918ae3100bfcd4b2d284\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Fabian Retkowski\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94486ed250a0a679a6487217aee2d1feaa642fac\",\"title\":\"Reinforcement Learning for Sequence-to-Sequence Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/94486ed250a0a679a6487217aee2d1feaa642fac\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1712.07101\",\"authors\":[{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":\"10.1109/ICASSP.2018.8462361\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"527dc08f670981d22bfeb831d9e249d25a449380\",\"title\":\"Improving End-to-End Speech Recognition with Policy Learning\",\"url\":\"https://www.semanticscholar.org/paper/527dc08f670981d22bfeb831d9e249d25a449380\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14156382\",\"name\":\"T. Yu\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"46413384\",\"name\":\"Xiangyu Zeng\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.1145/3343031.3350935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"276855eb1a4487be77de1c62947bd443bfe2da0f\",\"title\":\"Vision-Language Recommendation via Attribute Augmented Multimodal Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/276855eb1a4487be77de1c62947bd443bfe2da0f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144210171\",\"name\":\"S. Messaoud\"},{\"authorId\":\"145743549\",\"name\":\"Maghav Kumar\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR42600.2020.00761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82b8c2b16cd843c50ebec3bf9e5667008b284119\",\"title\":\"Can We Learn Heuristics for Graphical Model Inference Using Reinforcement Learning?\",\"url\":\"https://www.semanticscholar.org/paper/82b8c2b16cd843c50ebec3bf9e5667008b284119\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143866730\",\"name\":\"X. Lan\"},{\"authorId\":\"51290319\",\"name\":\"Hangxiao Wang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"}],\"doi\":\"10.5244/C.31.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5bb767da66226449b1ccf06d1cd004ee2413892d\",\"title\":\"Deep Reinforcement Learning Attention Selection For Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/5bb767da66226449b1ccf06d1cd004ee2413892d\",\"venue\":\"BMVC\",\"year\":2017},{\"arxivId\":\"1812.08658\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"46395829\",\"name\":\"Yufei Wang\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607624548\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.1109/ICCV.2019.00904\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"title\":\"nocaps: novel object captioning at scale\",\"url\":\"https://www.semanticscholar.org/paper/8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.03983\",\"authors\":[{\"authorId\":\"1557300901\",\"name\":\"Mingshuang Luo\"},{\"authorId\":\"7389074\",\"name\":\"S. Yang\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0872f4a6e14c6da98424e6daefe4d9b626ba4d3d\",\"title\":\"Pseudo-Convolutional Policy Gradient for Sequence-to-Sequence Lip-Reading\",\"url\":\"https://www.semanticscholar.org/paper/0872f4a6e14c6da98424e6daefe4d9b626ba4d3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.08389\",\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91956c41190231eefd2186f21b79d1ca1495a68e\",\"title\":\"Joint Image Captioning and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91956c41190231eefd2186f21b79d1ca1495a68e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.12267\",\"authors\":[{\"authorId\":\"1519970315\",\"name\":\"Xinsheng Wang\"},{\"authorId\":\"1514891263\",\"name\":\"Siyuan Feng\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"1399115926\",\"name\":\"M. Hasegawa-Johnson\"},{\"authorId\":\"144951859\",\"name\":\"O. Scharenborg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7b2a37fac581795101120989c0ff76147938a4a\",\"title\":\"Show and Speak: Directly Synthesize Spoken Description of Images\",\"url\":\"https://www.semanticscholar.org/paper/d7b2a37fac581795101120989c0ff76147938a4a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1805.12589\",\"authors\":[{\"authorId\":\"31121723\",\"name\":\"A. Deshpande\"},{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"39709900\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/CVPR.2019.01095\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"title\":\"Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech\",\"url\":\"https://www.semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50349716\",\"name\":\"W. Kool\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a69a34408555a6fcdb0491e9bf82af8675876ae\",\"title\":\"Attention Solves Your TSP\",\"url\":\"https://www.semanticscholar.org/paper/0a69a34408555a6fcdb0491e9bf82af8675876ae\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144249776\",\"name\":\"H. Chen\"},{\"authorId\":\"3393888\",\"name\":\"M. Giuffrida\"},{\"authorId\":\"4553782\",\"name\":\"P. Doerner\"},{\"authorId\":\"1919157\",\"name\":\"S. Tsaftaris\"}],\"doi\":\"10.1109/CVPRW.2019.00318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f41b3500e556203de6659ed57a3d8fdd5496a4c\",\"title\":\"Adversarial Large-Scale Root Gap Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/9f41b3500e556203de6659ed57a3d8fdd5496a4c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"}],\"doi\":\"10.1145/3240508.3240583\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"title\":\"Look Deeper See Richer: Depth-aware Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2012.02206\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"47621053\",\"name\":\"A. Gholami\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"title\":\"Scan2Cap: Context-aware Dense Captioning in RGB-D Scans\",\"url\":\"https://www.semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2019.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"title\":\"Cross-Modality Personalization for Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51349878\",\"name\":\"Y. C. Yoon\"},{\"authorId\":\"49591454\",\"name\":\"SoYoung Park\"},{\"authorId\":\"14966100\",\"name\":\"Soo Park\"},{\"authorId\":\"153803012\",\"name\":\"H. Lim\"}],\"doi\":\"10.4218/ETRIJ.2018-0621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"title\":\"Image classification and captioning model considering a CAM\\u2010based disagreement loss\",\"url\":\"https://www.semanticscholar.org/paper/ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.07873\",\"authors\":[{\"authorId\":\"3403184\",\"name\":\"P. Vijayaraghavan\"},{\"authorId\":\"145364504\",\"name\":\"D. Roy\"}],\"doi\":\"10.1007/978-3-030-46147-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33dd4fade148f19f6d750a6177fa996509b57512\",\"title\":\"Generating Black-Box Adversarial Examples for Text Classifiers Using a Deep Reinforced Model\",\"url\":\"https://www.semanticscholar.org/paper/33dd4fade148f19f6d750a6177fa996509b57512\",\"venue\":\"ECML/PKDD\",\"year\":2019},{\"arxivId\":\"1805.03766\",\"authors\":[{\"authorId\":\"2691021\",\"name\":\"Antoine Bosselut\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.18653/v1/N18-1016\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"680bfa179c33d56f524c6adf9b7f7f5a62e5ef46\",\"title\":\"Discourse-Aware Neural Rewards for Coherent Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/680bfa179c33d56f524c6adf9b7f7f5a62e5ef46\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145093155\",\"name\":\"Min Xu\"},{\"authorId\":\"1677510167\",\"name\":\"Lingxiang Wu\"},{\"authorId\":\"121134294\",\"name\":\"S. Qian\"},{\"authorId\":\"3061725\",\"name\":\"Jianwei Cui\"}],\"doi\":\"10.1145/3381858\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"238611bc2a79d64271a2238cf164bcfde3e5cb13\",\"title\":\"Image to Modern Chinese Poetry Creation via a Constrained Topic-aware Model\",\"url\":\"https://www.semanticscholar.org/paper/238611bc2a79d64271a2238cf164bcfde3e5cb13\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1911.10115\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"title\":\"TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2005.01508\",\"authors\":[{\"authorId\":\"144210171\",\"name\":\"S. Messaoud\"},{\"authorId\":\"145743549\",\"name\":\"Maghav Kumar\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPRW50498.2020.00391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55d71e7f65f852a82468db7190bcc167861e549a\",\"title\":\"Can We Learn Heuristics For Graphical Model Inference Using Reinforcement Learning?\",\"url\":\"https://www.semanticscholar.org/paper/55d71e7f65f852a82468db7190bcc167861e549a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1803.09693\",\"authors\":[{\"authorId\":\"145360004\",\"name\":\"David Acuna\"},{\"authorId\":\"18900686\",\"name\":\"Huan Ling\"},{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00096\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a985aba7699d0904f51785608496526eede02d6e\",\"title\":\"Efficient Interactive Annotation of Segmentation Datasets with Polygon-RNN++\",\"url\":\"https://www.semanticscholar.org/paper/a985aba7699d0904f51785608496526eede02d6e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51173986\",\"name\":\"Mingtong Liu\"},{\"authorId\":\"102816010\",\"name\":\"Erguang Yang\"},{\"authorId\":\"48402957\",\"name\":\"Deyi Xiong\"},{\"authorId\":\"49890812\",\"name\":\"Y. Zhang\"},{\"authorId\":\"151469755\",\"name\":\"Yao Meng\"},{\"authorId\":\"3913592\",\"name\":\"C. Hu\"},{\"authorId\":\"100558769\",\"name\":\"Jinan Xu\"},{\"authorId\":\"47559028\",\"name\":\"Yufeng Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4f7778e66b19b8cb19970567989f55d03cb86c2\",\"title\":\"A Learning-Exploring Method to Generate Diverse Paraphrases with Multi-Objective Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4f7778e66b19b8cb19970567989f55d03cb86c2\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2010.03855\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"title\":\"Dense Relational Image Captioning via Multi-task Triple-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.04016\",\"authors\":[{\"authorId\":\"48615144\",\"name\":\"Yan Xu\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"49411511\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"49891118\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00426\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aacdfd9fd9bf59afdc6612678440581f229d270e\",\"title\":\"Exact Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables\",\"url\":\"https://www.semanticscholar.org/paper/aacdfd9fd9bf59afdc6612678440581f229d270e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1806.02934\",\"authors\":[{\"authorId\":\"51043791\",\"name\":\"A. Kalyan\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d2237f995d280edb8a47e27886261709ea3f654a\",\"title\":\"Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d2237f995d280edb8a47e27886261709ea3f654a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":\"2010.02407\",\"authors\":[{\"authorId\":\"2831377\",\"name\":\"Vipul Raheja\"},{\"authorId\":\"1958685\",\"name\":\"Dimitrios Alikaniotis\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85dbf9a3d71b8d9a9e3168938a132104621e2b1\",\"title\":\"Adversarial Grammatical Error Correction\",\"url\":\"https://www.semanticscholar.org/paper/e85dbf9a3d71b8d9a9e3168938a132104621e2b1\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2010.05994\",\"authors\":[{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9827221\",\"name\":\"J. Li\"},{\"authorId\":\"1661029011\",\"name\":\"Hao Fu\"},{\"authorId\":\"14768555\",\"name\":\"Yuh-Chen Lin\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"144286907\",\"name\":\"Qian Yang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e64c6228919810fbd3796563b20ef2813ffa8d54\",\"title\":\"Improving Text Generation with Student-Forcing Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/e64c6228919810fbd3796563b20ef2813ffa8d54\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"1618896088\",\"name\":\"Hong Kong\"}],\"doi\":\"10.1109/cvpr42600.2020.00453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffc481c86d46ca812eff85030f812588bb20b80\",\"title\":\"How Much Time Do You Have? Modeling Multi-Duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cffc481c86d46ca812eff85030f812588bb20b80\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.10258\",\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"1491357190\",\"name\":\"Yang Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f882bc53ded32b2a32b291078c9454d82f6f108b\",\"title\":\"ParaCNN: Visual Paragraph Generation via Adversarial Twin Contextual CNNs\",\"url\":\"https://www.semanticscholar.org/paper/f882bc53ded32b2a32b291078c9454d82f6f108b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":\"10.1145/3394171.3413901\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bcec12a99cfcd649ea36d6b7215d025bad12974\",\"title\":\"Iterative Back Modification for Faster Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0bcec12a99cfcd649ea36d6b7215d025bad12974\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19209527\",\"name\":\"Mingkuan Yuan\"},{\"authorId\":\"92817440\",\"name\":\"Yuxin Peng\"}],\"doi\":\"10.1109/TMM.2019.2951463\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70de83272caac9af3bb1dd6a159ec3c1b314ff8e\",\"title\":\"CKD: Cross-Task Knowledge Distillation for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/70de83272caac9af3bb1dd6a159ec3c1b314ff8e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40139368\",\"name\":\"Lujun Zhao\"},{\"authorId\":\"7750270\",\"name\":\"Kaisong Song\"},{\"authorId\":\"35273607\",\"name\":\"Changlong Sun\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"},{\"authorId\":\"1713802\",\"name\":\"Xiaozhong Liu\"}],\"doi\":\"10.1145/3308558.3313581\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2aa0c96074cf0baef3d130803382ae4a3d37566f\",\"title\":\"Review Response Generation in E-Commerce Platforms with External Product Information\",\"url\":\"https://www.semanticscholar.org/paper/2aa0c96074cf0baef3d130803382ae4a3d37566f\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9729107\",\"name\":\"N. Sultana\"},{\"authorId\":\"145642632\",\"name\":\"Jeffrey Chan\"},{\"authorId\":\"145587600\",\"name\":\"A. Qin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff23bb6d87031fbf2eb78e4950e8d1ac4b771322\",\"title\":\"L G ] 2 3 O ct 2 02 0 Learning to Optimise General TSP Instances A Preprint\",\"url\":\"https://www.semanticscholar.org/paper/ff23bb6d87031fbf2eb78e4950e8d1ac4b771322\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66528414\",\"name\":\"Xiangheng He\"},{\"authorId\":\"48569127\",\"name\":\"Xinde Li\"}],\"doi\":\"10.1109/ICARM49381.2020.9195335\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"287a19d2ec291618882c0660d2c4856642559227\",\"title\":\"Modeling coherence and diversity for image paragraph captioning\",\"url\":\"https://www.semanticscholar.org/paper/287a19d2ec291618882c0660d2c4856642559227\",\"venue\":\"2020 5th International Conference on Advanced Robotics and Mechatronics (ICARM)\",\"year\":2020},{\"arxivId\":\"2007.07987\",\"authors\":[{\"authorId\":\"30691613\",\"name\":\"X. Wang\"},{\"authorId\":\"97292409\",\"name\":\"C. MacDonald\"},{\"authorId\":\"1698205\",\"name\":\"I. Ounis\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fef515fb2cf24695db1b09bf87dc53e7911119ac\",\"title\":\"Deep Reinforced Query Reformulation for Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/fef515fb2cf24695db1b09bf87dc53e7911119ac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390788836\",\"name\":\"Guangxiang Zhao\"},{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"50317060\",\"name\":\"Zhiyuan Zhang\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"11774802\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4237bdd7df710c08b58d02bb48f8dcecd2521a80\",\"title\":\"Sparse Transformer: Concentrated Attention Through Explicit Selection\",\"url\":\"https://www.semanticscholar.org/paper/4237bdd7df710c08b58d02bb48f8dcecd2521a80\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"145414746\",\"name\":\"Kun Fu\"},{\"authorId\":\"143900006\",\"name\":\"Lei Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8851721\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"title\":\"Image Captioning with Partially Rewarded Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f33c9e9e76e1d41d64d21c09ae434b05d83bc7f6\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1705.02798\",\"authors\":[{\"authorId\":\"8367832\",\"name\":\"Minghao Hu\"},{\"authorId\":\"2653582\",\"name\":\"Y. Peng\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"42d2338a8c2e44154e10ff4d68a3c389aeca3913\",\"title\":\"Reinforced Mnemonic Reader for Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/42d2338a8c2e44154e10ff4d68a3c389aeca3913\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.06632\",\"authors\":[{\"authorId\":\"145859178\",\"name\":\"Jian Zheng\"},{\"authorId\":\"33770363\",\"name\":\"Sudha Krishnamurthy\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"11004494\",\"name\":\"Zhenhao Ge\"},{\"authorId\":\"47056922\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"854a20d09da5e412dbaf41513d97dca2f67b647b\",\"title\":\"Image Captioning with Integrated Bottom-Up and Multi-level Residual Top-Down Attention for Game Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/854a20d09da5e412dbaf41513d97dca2f67b647b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.09393\",\"authors\":[{\"authorId\":\"13545491\",\"name\":\"Serhii Havrylov\"},{\"authorId\":\"2067996\",\"name\":\"Germ\\u00e1n Kruszewski\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"}],\"doi\":\"10.18653/v1/N19-1115\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0e2fe0fe9f4fc4ce05d5f637baff96a7e966c01\",\"title\":\"Cooperative Learning of Disjoint Syntax and Semantics\",\"url\":\"https://www.semanticscholar.org/paper/b0e2fe0fe9f4fc4ce05d5f637baff96a7e966c01\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1910.00292\",\"authors\":[{\"authorId\":\"145235730\",\"name\":\"Florian Schmidt\"}],\"doi\":\"10.18653/v1/D19-5616\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee79d4318ddd3b8886efd11203533c98329eccc8\",\"title\":\"Generalization in Generation: A closer look at Exposure Bias\",\"url\":\"https://www.semanticscholar.org/paper/ee79d4318ddd3b8886efd11203533c98329eccc8\",\"venue\":\"NGT@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98727476\",\"name\":\"Tsan-Hwei Huang\"},{\"authorId\":\"2024357948\",\"name\":\"Hunter Hsieh\"},{\"authorId\":\"2025282857\",\"name\":\"Jiaqi Qin\"},{\"authorId\":\"2024727250\",\"name\":\"Hsien-Fung Liu\"},{\"authorId\":\"2377003\",\"name\":\"M. Eirinaki\"}],\"doi\":\"10.1109/TransAI49837.2020.00008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"title\":\"Play it again IMuCo! Music Composition to Match your Mood\",\"url\":\"https://www.semanticscholar.org/paper/30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"venue\":\"2020 Second International Conference on Transdisciplinary AI (TransAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9358850\",\"name\":\"Ruifan Li\"},{\"authorId\":\"4189987\",\"name\":\"Haoyu Liang\"},{\"authorId\":\"46571714\",\"name\":\"Yihui Shi\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1016/j.neucom.2020.02.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f85b7e09e60315d725b316ffc813d20535b21b2\",\"title\":\"Dual-CNN: A Convolutional language decoder for paragraph image captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f85b7e09e60315d725b316ffc813d20535b21b2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029315929\",\"name\":\"Nikolaos Panagiaris\"},{\"authorId\":\"144988281\",\"name\":\"E. Hart\"},{\"authorId\":\"2921637\",\"name\":\"Dimitra Gkatzia\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9915eb6475247e72a084eb8d6a89d602ee1c27a0\",\"title\":\"Improving the Naturalness and Diversity of Referring Expression Generation models using Minimum Risk Training\",\"url\":\"https://www.semanticscholar.org/paper/9915eb6475247e72a084eb8d6a89d602ee1c27a0\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":\"1910.06737\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac87d8ef6da4be7d7822053355c0528c58d8ddf5\",\"title\":\"Integrating Temporal and Spatial Attentions for VATEX Video Captioning Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/ac87d8ef6da4be7d7822053355c0528c58d8ddf5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.01881\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03158341c61b8bfedc9ccd503610ab150678a7c1\",\"title\":\"Better Understanding Hierarchical Visual Relationship for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/03158341c61b8bfedc9ccd503610ab150678a7c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46428422\",\"name\":\"Q. Li\"},{\"authorId\":null,\"name\":\"Hui Su\"},{\"authorId\":\"150954670\",\"name\":\"Cheng Niu\"},{\"authorId\":\"1766692\",\"name\":\"D. Wang\"},{\"authorId\":\"15401738\",\"name\":\"Zekang Li\"},{\"authorId\":null,\"name\":\"Shi Feng\"},{\"authorId\":\"36233573\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.18653/v1/D19-5805\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f603f6002866c4217d82d772d5ed11ed560cb110\",\"title\":\"Answer-Supervised Question Reformulation for Enhancing Conversational Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/f603f6002866c4217d82d772d5ed11ed560cb110\",\"venue\":\"MRQA@EMNLP\",\"year\":2019},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2007.01488\",\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"37510256\",\"name\":\"Yanyan Lan\"},{\"authorId\":\"70414094\",\"name\":\"J. Guo\"},{\"authorId\":\"47172591\",\"name\":\"Xueqi Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"97dd692e8e07c8e30551443dc443da14db5c8fdc\",\"title\":\"On the Relation between Quality-Diversity Evaluation and Distribution-Fitting Goal in Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/97dd692e8e07c8e30551443dc443da14db5c8fdc\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1812.06624\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"title\":\"Feature Fusion Effects of Tensor Product Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7cc8e0430de6b9f1a2970e7f4f7596be0a0716e\",\"title\":\"CLARA: Dynamic Doctor Representation Learning for Clinical Trial Recruitment\",\"url\":\"https://www.semanticscholar.org/paper/e7cc8e0430de6b9f1a2970e7f4f7596be0a0716e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.05963\",\"authors\":[{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"40441990\",\"name\":\"Armin Kappeler\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"},{\"authorId\":\"145730823\",\"name\":\"J. Soares\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b499228aa74b59be32711c3926e44de208d6b636\",\"title\":\"Image Captioning: Transforming Objects into Words\",\"url\":\"https://www.semanticscholar.org/paper/b499228aa74b59be32711c3926e44de208d6b636\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47458613\",\"name\":\"A. Tripathi\"},{\"authorId\":\"145305735\",\"name\":\"Siddharth Srivastava\"},{\"authorId\":\"144174561\",\"name\":\"R. Kothari\"}],\"doi\":\"10.1007/978-3-030-04780-1_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"title\":\"Deep Neural Network Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a819e54b2d980dcff85ac8ab13801178aac5b59a\",\"venue\":\"BDA\",\"year\":2018},{\"arxivId\":\"1812.06398\",\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/cvpr42600.2020.01346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"524acde4aad3bcde1b2a90245ef25c4e4d17c849\",\"title\":\"Gold Seeker: Information Gain From Policy Distributions for Goal-Oriented Vision-and-Langauge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/524acde4aad3bcde1b2a90245ef25c4e4d17c849\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.07689\",\"authors\":[{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"145527705\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/P19-1182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4eb2e2b9c22cb1da8561044ca0dc8fc0b13e3157\",\"title\":\"Expressing Visual Relationships via Language\",\"url\":\"https://www.semanticscholar.org/paper/4eb2e2b9c22cb1da8561044ca0dc8fc0b13e3157\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2010.04314\",\"authors\":[{\"authorId\":\"32395619\",\"name\":\"Xiaomian Kang\"},{\"authorId\":\"34340526\",\"name\":\"Y. Zhao\"},{\"authorId\":\"38358352\",\"name\":\"Jiajun Zhang\"},{\"authorId\":\"70486345\",\"name\":\"Chengqing Zong\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.175\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e362020296df7e519d2c8c1d5d8b388ed679433\",\"title\":\"Dynamic Context Selection for Document-level Neural Machine Translation via Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/4e362020296df7e519d2c8c1d5d8b388ed679433\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.08543\",\"authors\":[{\"authorId\":\"152601809\",\"name\":\"Minh Thu Nguyen\"},{\"authorId\":\"6195410\",\"name\":\"D. Phung\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"2008200586\",\"name\":\"Thien Huu Nguyen\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.411\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"title\":\"Structural and Functional Decomposition for Personality Image Captioning in a Communication Game\",\"url\":\"https://www.semanticscholar.org/paper/28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.03291\",\"authors\":[{\"authorId\":\"1387993874\",\"name\":\"Alireza Mohammadshahi\"},{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"1751802\",\"name\":\"K. Aberer\"}],\"doi\":\"10.18653/v1/D19-6605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d880af464e477421e5cddc794e971c6db193b8c\",\"title\":\"Aligning Multilingual Word Embeddings for Cross-Modal Retrieval Task\",\"url\":\"https://www.semanticscholar.org/paper/2d880af464e477421e5cddc794e971c6db193b8c\",\"venue\":\"IJCNLP 2019\",\"year\":2019},{\"arxivId\":\"1910.02974\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICRA40945.2020.9196653\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe6f2a08cb8911d52533a413b071638d0463f10a\",\"title\":\"SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability\",\"url\":\"https://www.semanticscholar.org/paper/fe6f2a08cb8911d52533a413b071638d0463f10a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1707.03804\",\"authors\":[{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5dbb7039fe593990186f4bc0dca0a6d14ff5b06\",\"title\":\"Source-Target Inference Models for Spatial Instruction Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a5dbb7039fe593990186f4bc0dca0a6d14ff5b06\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1705.00930\",\"authors\":[{\"authorId\":\"3451456\",\"name\":\"Tseng-Hung Chen\"},{\"authorId\":\"1826179\",\"name\":\"Yuan-Hong Liao\"},{\"authorId\":\"8551209\",\"name\":\"Ching-Yao Chuang\"},{\"authorId\":\"2717138\",\"name\":\"W. T. Hsu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2017.64\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"828a7b3122ebd5b8b0c617902bc04ac5a6c60240\",\"title\":\"Show, Adapt and Tell: Adversarial Training of Cross-Domain Image Captioner\",\"url\":\"https://www.semanticscholar.org/paper/828a7b3122ebd5b8b0c617902bc04ac5a6c60240\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1906.04106\",\"authors\":[{\"authorId\":\"23181435\",\"name\":\"Hou Pong Chan\"},{\"authorId\":\"50504105\",\"name\":\"Wang Chen\"},{\"authorId\":\"31835031\",\"name\":\"L. Wang\"},{\"authorId\":\"145310663\",\"name\":\"Irwin King\"}],\"doi\":\"10.18653/v1/P19-1208\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"272730c72d6c40cf9cd6ca82664fcd273e032192\",\"title\":\"Neural Keyphrase Generation via Reinforcement Learning with Adaptive Rewards\",\"url\":\"https://www.semanticscholar.org/paper/272730c72d6c40cf9cd6ca82664fcd273e032192\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"1908331\",\"name\":\"Chiraag Lala\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"37922370\",\"name\":\"S. Frank\"}],\"doi\":\"10.18653/v1/W18-6402\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b37fc91f2fbfad3ae70827e7259997c383e041ff\",\"title\":\"Findings of the Third Shared Task on Multimodal Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/b37fc91f2fbfad3ae70827e7259997c383e041ff\",\"venue\":\"WMT\",\"year\":2018},{\"arxivId\":\"1811.04697\",\"authors\":[{\"authorId\":\"46407634\",\"name\":\"Jind\\u0159ich Helcl\"},{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"}],\"doi\":\"10.18653/v1/W17-4749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7444adac0f4c0004fe557e7fd68fdc89c99ca10b\",\"title\":\"CUNI System for the WMT17 Multimodal Translation Task\",\"url\":\"https://www.semanticscholar.org/paper/7444adac0f4c0004fe557e7fd68fdc89c99ca10b\",\"venue\":\"WMT\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12551031\",\"name\":\"P. Li\"},{\"authorId\":\"26659900\",\"name\":\"Xinde Li\"},{\"authorId\":\"48568708\",\"name\":\"Xiaobin Li\"},{\"authorId\":\"1900890711\",\"name\":\"Hong Pan\"},{\"authorId\":\"51071590\",\"name\":\"M. O. Khyam\"},{\"authorId\":\"1398730731\",\"name\":\"Md. Noor-A.-Rahim\"},{\"authorId\":\"2426877\",\"name\":\"S. S. Ge\"}],\"doi\":\"10.1016/J.PATCOG.2020.107680\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b7af5e66c07318cdc3b2b1186bb199e1380e98\",\"title\":\"Place perception from the fusion of different image representation\",\"url\":\"https://www.semanticscholar.org/paper/38b7af5e66c07318cdc3b2b1186bb199e1380e98\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2010.16011\",\"authors\":[{\"authorId\":\"119684532\",\"name\":\"Yeong-Dae Kwon\"},{\"authorId\":\"65774523\",\"name\":\"Jinho Choo\"},{\"authorId\":\"3132555\",\"name\":\"Byoungjip Kim\"},{\"authorId\":\"36612888\",\"name\":\"Iljoo Yoon\"},{\"authorId\":\"3025470\",\"name\":\"Seungjai Min\"},{\"authorId\":\"2163133\",\"name\":\"Youngjune Gwon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bad0200cc40d843de26988ef96b73ac1e2438d60\",\"title\":\"POMO: Policy Optimization with Multiple Optima for Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/bad0200cc40d843de26988ef96b73ac1e2438d60\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3390891\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb9fb10f604a196515e48ad90f217d33794f5991\",\"title\":\"Recurrent Attention Network with Reinforced Generator for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cb9fb10f604a196515e48ad90f217d33794f5991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120897486\",\"name\":\"Anwen Hu\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413576\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"title\":\"ICECAP: Information Concentrated Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.01999\",\"authors\":[{\"authorId\":\"1986560192\",\"name\":\"Ruchika Chavhan\"},{\"authorId\":\"49124777\",\"name\":\"Biplab Banerjee\"},{\"authorId\":\"40049070\",\"name\":\"X. Zhu\"},{\"authorId\":\"144527833\",\"name\":\"S. Chaudhuri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e67be13c2d1d8bb45cd2a3130532a4d8f7f82be\",\"title\":\"A Novel Actor Dual-Critic Model for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2e67be13c2d1d8bb45cd2a3130532a4d8f7f82be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.05190\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Li\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"39895985\",\"name\":\"D. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37eccaba2a370d60e32cc4daf179383265b6904\",\"title\":\"Vispi: Automatic Visual Perception and Interpretation of Chest X-rays\",\"url\":\"https://www.semanticscholar.org/paper/f37eccaba2a370d60e32cc4daf179383265b6904\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19268185\",\"name\":\"Niange Yu\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"38524079\",\"name\":\"Binheng Song\"},{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"39665190\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2018.2889922\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"title\":\"Topic-Oriented Image Captioning Based on Order-Embedding\",\"url\":\"https://www.semanticscholar.org/paper/d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.02156\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"40895688\",\"name\":\"Kaylee Burns\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D18-1437\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4921243268c81d0d6db99053a9d004852225a622\",\"title\":\"Object Hallucination in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4921243268c81d0d6db99053a9d004852225a622\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2006.03315\",\"authors\":[{\"authorId\":\"1387548078\",\"name\":\"K. Lin\"},{\"authorId\":\"1738276592\",\"name\":\"Zhuoxin Gan\"},{\"authorId\":\"46659782\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"title\":\"Multi-modal Feature Fusion with Feature Attention for VATEX Captioning Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/aea0c2fdcb618d3b0fdea17a5fc5b068b80a0ec3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3434285\",\"name\":\"Qibin Zheng\"},{\"authorId\":\"2384464\",\"name\":\"Xiaoguang Ren\"},{\"authorId\":\"46179714\",\"name\":\"Y. Liu\"},{\"authorId\":\"1720767577\",\"name\":\"Wei Qin\"}],\"doi\":\"10.1145/3404555.3404610\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1acdafed6cc44777b507e1d1e4703085fb56fb8d\",\"title\":\"Generalization or Instantiation?: Estimating the Relative Abstractness between Images and Text\",\"url\":\"https://www.semanticscholar.org/paper/1acdafed6cc44777b507e1d1e4703085fb56fb8d\",\"venue\":\"ICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029649059\",\"name\":\"Liuyin Wang\"},{\"authorId\":\"48559591\",\"name\":\"Zi-Han Xu\"},{\"authorId\":\"47778853\",\"name\":\"Zibo Lin\"},{\"authorId\":\"16215052\",\"name\":\"Hai-Tao Zheng\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e2687e227ce64e500d0695eeb1cb6d21c7868ec4\",\"title\":\"Answer-driven Deep Question Generation based on Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/e2687e227ce64e500d0695eeb1cb6d21c7868ec4\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145837511\",\"name\":\"Y. Ma\"},{\"authorId\":\"47422357\",\"name\":\"Q. Li\"}],\"doi\":\"10.1007/s11280-018-0591-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be3a39572b8cbe2daa77186d5e116f5c0a092bb4\",\"title\":\"A weakly-supervised extractive framework for sentiment-preserving document summarization\",\"url\":\"https://www.semanticscholar.org/paper/be3a39572b8cbe2daa77186d5e116f5c0a092bb4\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1811.10201\",\"authors\":[{\"authorId\":\"26921530\",\"name\":\"A. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"144854012\",\"name\":\"Da-Cheng Juan\"},{\"authorId\":\"1725923\",\"name\":\"W. Wei\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1609/AAAI.V34I04.5764\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"918f0f4b94c42de1c6c7681d9444ffac2ecd9892\",\"title\":\"InstaNAS: Instance-aware Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/918f0f4b94c42de1c6c7681d9444ffac2ecd9892\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1908.08529\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/ICCV.2019.00436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49d46b0245475067bb7192d9bb1538701ae1c014\",\"title\":\"Sequential Latent Spaces for Modeling the Intention During Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/49d46b0245475067bb7192d9bb1538701ae1c014\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.01102\",\"authors\":[{\"authorId\":\"1617876693\",\"name\":\"Yuxi Xie\"},{\"authorId\":\"3470231\",\"name\":\"Liangming Pan\"},{\"authorId\":\"47858806\",\"name\":\"Dongzhe Wang\"},{\"authorId\":\"37596605\",\"name\":\"Min-Yen Kan\"},{\"authorId\":\"50753314\",\"name\":\"Yansong Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5dcdbab92fc3184178917497ffa34777961155db\",\"title\":\"Exploring Question-Specific Rewards for Generating Deep Questions\",\"url\":\"https://www.semanticscholar.org/paper/5dcdbab92fc3184178917497ffa34777961155db\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31497621\",\"name\":\"W. S. Cho\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":null,\"name\":\"Sudha Rao\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144628574\",\"name\":\"Chenyan Xiong\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"50468734\",\"name\":\"M. Wang\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"baba959c5defcf4e2c74e34ddcb135d029e1902f\",\"title\":\"Unsupervised Common Question Generation from Multiple Documents using Reinforced Contrastive Coordinator\",\"url\":\"https://www.semanticscholar.org/paper/baba959c5defcf4e2c74e34ddcb135d029e1902f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.11297\",\"authors\":[{\"authorId\":\"10703821\",\"name\":\"Mengting Hu\"},{\"authorId\":\"2516425\",\"name\":\"Shiwan Zhao\"},{\"authorId\":\"3144353\",\"name\":\"H. Guo\"},{\"authorId\":\"35391375\",\"name\":\"Renhong Cheng\"},{\"authorId\":\"115640628\",\"name\":\"Z. Su\"}],\"doi\":\"10.18653/v1/K19-1091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66aea69df8f80814e71c6a521832679c71666168\",\"title\":\"Learning to Detect Opinion Snippet for Aspect-Based Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/66aea69df8f80814e71c6a521832679c71666168\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1903.10122\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1609/AAAI.V33I01.33016666\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"adc998ac4fa71bdab19537c50e3d84bf982974c1\",\"title\":\"Knowledge-driven Encode, Retrieve, Paraphrase for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/adc998ac4fa71bdab19537c50e3d84bf982974c1\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/3292058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"title\":\"Image Captioning With Visual-Semantic Double Attention\",\"url\":\"https://www.semanticscholar.org/paper/1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400258083\",\"name\":\"Chunpu Xu\"},{\"authorId\":\"1940342\",\"name\":\"Y. Li\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"},{\"authorId\":\"1605170624\",\"name\":\"Xiang Ao\"},{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"39090191\",\"name\":\"Jin-Wen Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17c2549052978c3be85351541f69bf2b25e75f5f\",\"title\":\"Interactive Key-Value Memory-augmented Attention for Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/17c2549052978c3be85351541f69bf2b25e75f5f\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1804.08473\",\"authors\":[{\"authorId\":\"143672100\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"32878737\",\"name\":\"M. Kato\"},{\"authorId\":\"1740865\",\"name\":\"M. Yoshikawa\"}],\"doi\":\"10.1145/3240508.3240587\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"99e56f1fd88d967aab6be2a51f3633697e2df667\",\"title\":\"Beyond Narrative Description: Generating Poetry from Images by Multi-Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/99e56f1fd88d967aab6be2a51f3633697e2df667\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.09971\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b57c9a293934b7434b99807c82d6146634cafa61\",\"title\":\"A Better Variant of Self-Critical Sequence Training\",\"url\":\"https://www.semanticscholar.org/paper/b57c9a293934b7434b99807c82d6146634cafa61\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06015\",\"authors\":[{\"authorId\":\"9407280\",\"name\":\"Y. Chen\"},{\"authorId\":\"3008832\",\"name\":\"Lingfei Wu\"},{\"authorId\":\"1693515\",\"name\":\"Mohammed J. Zaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"febcbcac5f8b20a9748d170f3093d2e1eba4f040\",\"title\":\"Toward Subgraph Guided Knowledge Graph Question Generation with Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/febcbcac5f8b20a9748d170f3093d2e1eba4f040\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1706.09601\",\"authors\":[{\"authorId\":\"50081790\",\"name\":\"L. Zhang\"},{\"authorId\":\"40497013\",\"name\":\"Flood Sung\"},{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"title\":\"Actor-Critic Sequence Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58ee208dce1f06724bb443b4cfe0aa30d6cc9d30\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1709.01058\",\"authors\":[{\"authorId\":\"1748796\",\"name\":\"Linfeng Song\"},{\"authorId\":\"40296541\",\"name\":\"Z. Wang\"},{\"authorId\":\"1836135\",\"name\":\"W. Hamza\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d864750eb8877bc46d8f8e7ec5305f734ddc91aa\",\"title\":\"A Unified Query-based Generative Model for Question Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d864750eb8877bc46d8f8e7ec5305f734ddc91aa\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1812.00235\",\"authors\":[{\"authorId\":\"1516206362\",\"name\":\"Tingke Shen\"},{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2019.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4cb0a7617212eb40c537f4053d571faa4b8227c\",\"title\":\"Learning to Caption Images Through a Lifetime by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/b4cb0a7617212eb40c537f4053d571faa4b8227c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1908.07810\",\"authors\":[{\"authorId\":\"50118263\",\"name\":\"Yike Wu\"},{\"authorId\":\"2516425\",\"name\":\"Shiwan Zhao\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"48379958\",\"name\":\"Ying Zhang\"},{\"authorId\":\"1721029\",\"name\":\"Xiaojie Yuan\"},{\"authorId\":\"1703625\",\"name\":\"Zhong Su\"}],\"doi\":\"10.1109/ICME.2019.00070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4b29b999bc2d907d6d01ad30829058721d29394\",\"title\":\"Improving Captioning for Low-Resource Languages by Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d4b29b999bc2d907d6d01ad30829058721d29394\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.02943\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"},{\"authorId\":\"119899233\",\"name\":\"Len Hamey\"}],\"doi\":\"10.1007/978-3-030-29908-8_22\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d236d1415ac9a52ec599f0c100e15589cfceefd9\",\"title\":\"Towards Generating Stylized Image Captions via Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/d236d1415ac9a52ec599f0c100e15589cfceefd9\",\"venue\":\"PRICAI\",\"year\":2019},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98482977\",\"name\":\"\\u0411\\u043e\\u0440\\u0438\\u0441\\u043e\\u0432 \\u0413\\u0435\\u043e\\u0440\\u0433\\u0438\\u0439 \\u0410\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u043e\\u0432\\u0438\\u0447\"},{\"authorId\":\"97625681\",\"name\":\"\\u0422\\u0438\\u0445\\u043e\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430 \\u0422\\u0430\\u043c\\u0430\\u0440\\u0430 \\u041f\\u0435\\u0442\\u0440\\u043e\\u0432\\u043d\\u0430\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de0cec214cf34d089a9fce9015256b63534cd08\",\"title\":\"\\u0417\\u0430\\u0434\\u0430\\u0447\\u0438 \\u0438 \\u043c\\u0435\\u0442\\u043e\\u0434\\u044b \\u0440\\u0435\\u0441\\u0443\\u0440\\u0441\\u043e\\u0441\\u0431\\u0435\\u0440\\u0435\\u0433\\u0430\\u044e\\u0449\\u0435\\u0439 \\u043e\\u043f\\u0442\\u0438\\u043c\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u0432 \\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u044d\\u043d\\u0435\\u0440\\u0433\\u0435\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0435\",\"url\":\"https://www.semanticscholar.org/paper/0de0cec214cf34d089a9fce9015256b63534cd08\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1803.05526\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_31\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"title\":\"Unpaired Image Captioning by Language Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/05544876b7bc58b59b9ec5a8ee09e3ce9b4791ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1811.12104\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"143973868\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"title\":\"Towards Human-Friendly Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.04219\",\"authors\":[{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"49681507\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1007/978-3-030-01237-3_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdc254119ff7166d67aeedb544b987ccb8b9eae6\",\"title\":\"How Local is the Local Diversity? Reinforcing Sequential Determinantal Point Processes with Dynamic Ground Sets for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/cdc254119ff7166d67aeedb544b987ccb8b9eae6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.01032\",\"authors\":[{\"authorId\":\"1847848\",\"name\":\"M. Ma\"},{\"authorId\":\"40223399\",\"name\":\"Renjie Zheng\"},{\"authorId\":\"144768480\",\"name\":\"Liang Huang\"}],\"doi\":\"10.18653/v1/N19-1187\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1a0bae0f6e8be60a9786a2c5da0621a5ce92bed8\",\"title\":\"Learning to Stop in Structured Prediction for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/1a0bae0f6e8be60a9786a2c5da0621a5ce92bed8\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2004.08070\",\"authors\":[{\"authorId\":\"51163002\",\"name\":\"Alasdair Tran\"},{\"authorId\":\"46953477\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"}],\"doi\":\"10.1109/CVPR42600.2020.01305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"title\":\"Transform and Tell: Entity-Aware News Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"2009.14352\",\"authors\":[{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"1410092701\",\"name\":\"Xu Yang\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":\"10.1007/978-3-030-58568-6_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b41882903384ef849688a325d747fdaad8ecee82\",\"title\":\"Finding It at Another Side: A Viewpoint-Adapted Matching Encoder for Change Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b41882903384ef849688a325d747fdaad8ecee82\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50994378\",\"name\":\"Chen Chen\"},{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"35910905\",\"name\":\"E. Koh\"},{\"authorId\":\"39618262\",\"name\":\"Sungchul Kim\"},{\"authorId\":\"152452655\",\"name\":\"S. Cohen\"},{\"authorId\":\"35365476\",\"name\":\"R. Rossi\"}],\"doi\":\"10.1109/WACV45572.2020.9093592\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40e09c8e31bc859d90ba8ceeb70ef7534bf6b7a5\",\"title\":\"Figure Captioning with Relation Maps for Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/40e09c8e31bc859d90ba8ceeb70ef7534bf6b7a5\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yuxuan Xiong\"},{\"authorId\":\"49667078\",\"name\":\"B. Du\"},{\"authorId\":\"144855557\",\"name\":\"Pingkun Yan\"}],\"doi\":\"10.1007/978-3-030-32692-0_77\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be41a3d2ba68be5fc435fd33b2d54ac42c60b40f\",\"title\":\"Reinforced Transformer for Medical Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/be41a3d2ba68be5fc435fd33b2d54ac42c60b40f\",\"venue\":\"MLMI@MICCAI\",\"year\":2019},{\"arxivId\":\"1804.06870\",\"authors\":[{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/N18-2071\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90800d28c61854659fd8d813158ecac5653695fa\",\"title\":\"Object Ordering with Bidirectional Matchings for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/90800d28c61854659fd8d813158ecac5653695fa\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89766800\",\"name\":\"Zhenru Li\"},{\"authorId\":\"121704343\",\"name\":\"Yaoyi Li\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-36802-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"title\":\"Improve Image Captioning by Self-attention\",\"url\":\"https://www.semanticscholar.org/paper/c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1803.01457\",\"authors\":[{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"47527850\",\"name\":\"W. Zhang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1007/978-3-030-01261-8_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"title\":\"Less Is More: Picking Informative Frames for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d5ff7a4580fbfdecc1d912746eee36980f29278b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.03162\",\"authors\":[{\"authorId\":\"144412704\",\"name\":\"Tong Niu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1162/tacl_a_00027\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f1cba8a5a73c8151c2f5cb6edd5bc6a7c03e80fa\",\"title\":\"Polite Dialogue Generation Without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/f1cba8a5a73c8151c2f5cb6edd5bc6a7c03e80fa\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"30889568\",\"name\":\"Abdulmotaleb El Saddik\"}],\"doi\":\"10.1145/3279952\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"title\":\"Deep Learning\\u2013Based Multimedia Analytics\",\"url\":\"https://www.semanticscholar.org/paper/bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398104959\",\"name\":\"Justin R. Lovelace\"},{\"authorId\":\"144156074\",\"name\":\"Bobak Mortazavi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a554243e6806ac419ffdb19c354686f77ef2b848\",\"title\":\"Learning to Generate Clinically Coherent Chest X-Ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/a554243e6806ac419ffdb19c354686f77ef2b848\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1809.04276\",\"authors\":[{\"authorId\":\"50736467\",\"name\":\"Qingfu Zhu\"},{\"authorId\":\"145500846\",\"name\":\"Lei Cui\"},{\"authorId\":\"8031058\",\"name\":\"W. Zhang\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"1519044290\",\"name\":\"Yi-ning Chen\"},{\"authorId\":\"152244126\",\"name\":\"T. Liu\"}],\"doi\":\"10.18653/v1/P19-1366\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9a3bcba412f971bbc386f894287ef64113c7213\",\"title\":\"Retrieval-Enhanced Adversarial Training for Neural Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/e9a3bcba412f971bbc386f894287ef64113c7213\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1007/978-3-030-37731-1_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"title\":\"Image Captioning Based on Visual and Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"98608166\",\"name\":\"M. Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/TIP.2020.3038354\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"title\":\"Deep Relation Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bbd0f64077fb85365360ef8f71dfd2cd7d431536\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"2002.10310\",\"authors\":[{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"79456794\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":\"10.1109/CVPR42600.2020.00980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b2781e76085f61783277de5862d45438ff3682c\",\"title\":\"Sketch Less for More: On-the-Fly Fine-Grained Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5b2781e76085f61783277de5862d45438ff3682c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":\"1706.00130\",\"authors\":[{\"authorId\":\"18900686\",\"name\":\"Huan Ling\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7a9fe5781220cca6ca600833015f200a9c03d50e\",\"title\":\"Teaching Machines to Describe Images with Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/7a9fe5781220cca6ca600833015f200a9c03d50e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2012.07061\",\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"46491945\",\"name\":\"Yunpeng Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"40366236\",\"name\":\"Yue Gao\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"title\":\"Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.03744\",\"authors\":[{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"},{\"authorId\":\"46429484\",\"name\":\"F. Wang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"461420c80d3bdc156e5db7af13264a955a6a2010\",\"title\":\"Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/461420c80d3bdc156e5db7af13264a955a6a2010\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"47655360\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1445303213\",\"name\":\"Jiaqi Zhao\"},{\"authorId\":\"49353948\",\"name\":\"Mingming Liu\"}],\"doi\":\"10.1016/j.knosys.2020.105920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"title\":\"Remote sensing image captioning via Variational Autoencoder and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2010.03157\",\"authors\":[{\"authorId\":\"143786326\",\"name\":\"Sheng Bi\"},{\"authorId\":\"152258664\",\"name\":\"Xiya Cheng\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":null,\"name\":\"Yongzhen Wang\"},{\"authorId\":\"1730054\",\"name\":\"G. Qi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2148250fd5b0c1f532ff6ee46143236c7f98783b\",\"title\":\"Knowledge-enriched, Type-constrained and Grammar-guided Question Generation over Knowledge Bases\",\"url\":\"https://www.semanticscholar.org/paper/2148250fd5b0c1f532ff6ee46143236c7f98783b\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"title\":\"Learning Latent Graph Representations for Relational VQA\",\"url\":\"https://www.semanticscholar.org/paper/6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1970583\",\"name\":\"Liangke Gui\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4abe9de230e5179a62043568bd089da5a33e2e39\",\"title\":\"Adaptive Context-aware Reinforced Agent for Handwritten Text Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4abe9de230e5179a62043568bd089da5a33e2e39\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400258083\",\"name\":\"Chunpu Xu\"},{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"31991405\",\"name\":\"Min Yang\"},{\"authorId\":\"2441161\",\"name\":\"Xiang Ao\"},{\"authorId\":\"1405918472\",\"name\":\"Wangrong Cheng\"},{\"authorId\":\"1936983\",\"name\":\"J. Tian\"}],\"doi\":\"10.1145/3357384.3358105\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e81c97c18cb4f4922e4442664350350536a71a13\",\"title\":\"A Unified Generation-Retrieval Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e81c97c18cb4f4922e4442664350350536a71a13\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df40d057b584de2cf74123a2ef4274de582d6b03\",\"title\":\"Detailed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df40d057b584de2cf74123a2ef4274de582d6b03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2005.03119\",\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/2020.acl-main.731\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4318f99804c5fd57fd7c0a1087b22bbe6268e276\",\"title\":\"Unsupervised Multimodal Neural Machine Translation with Pseudo Visual Pivoting\",\"url\":\"https://www.semanticscholar.org/paper/4318f99804c5fd57fd7c0a1087b22bbe6268e276\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1905.04354\",\"authors\":[{\"authorId\":\"103688686\",\"name\":\"Jonah Philion\"}],\"doi\":\"10.1109/CVPR.2019.01185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15e8801290c1a0208fe7e2df465974bd6eed464e\",\"title\":\"FastDraw: Addressing the Long Tail of Lane Detection by Adapting a Sequential Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/15e8801290c1a0208fe7e2df465974bd6eed464e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145246869\",\"name\":\"Chen Liang\"},{\"authorId\":\"1914797\",\"name\":\"N. Lao\"},{\"authorId\":\"144365797\",\"name\":\"W. Ling\"},{\"authorId\":\"2566656\",\"name\":\"Zita Marinho\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"50815748\",\"name\":\"Lu Wang\"},{\"authorId\":\"47271859\",\"name\":\"J. Williams\"},{\"authorId\":\"1777414\",\"name\":\"A. Durand\"},{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"93e256d558f972769d10484b5b10e3402c1be79b\",\"title\":\"Deep Reinforcement Learning Meets Structured Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93e256d558f972769d10484b5b10e3402c1be79b\",\"venue\":\"ICLR 2019\",\"year\":2019},{\"arxivId\":\"2012.02339\",\"authors\":[{\"authorId\":\"2031911881\",\"name\":\"Edwin G. Ng\"},{\"authorId\":\"48157646\",\"name\":\"Bo Pang\"},{\"authorId\":\"153513927\",\"name\":\"P. Sharma\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"title\":\"Understanding Guided Image Captioning Performance across Domains\",\"url\":\"https://www.semanticscholar.org/paper/0795ae19cae966a9f71d8da78ef09447ab9080a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145235730\",\"name\":\"Florian Schmidt\"}],\"doi\":\"10.3929/ETHZ-B-000421025\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"c1a77db59032012be6f52c02ea551f8f64c7ff51\",\"title\":\"Stochasticity and Non-Autoregressive Modeling in Deep Generative Models of Text\",\"url\":\"https://www.semanticscholar.org/paper/c1a77db59032012be6f52c02ea551f8f64c7ff51\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391204924\",\"name\":\"Zongjian Zhang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"50528721\",\"name\":\"Qiuyun Wu\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/IJCNN.2019.8851832\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"title\":\"Visual Relationship Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1711.11135\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00443\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74b284a66e75b65f5970d05bac000fe91243ee49\",\"title\":\"Video Captioning via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74b284a66e75b65f5970d05bac000fe91243ee49\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.06227\",\"authors\":[{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"}],\"doi\":\"10.18653/v1/D18-1083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a78199a2cc678818489087454fe1150db4870196\",\"title\":\"Improving Reinforcement Learning Based Image Captioning with Natural Language Prior\",\"url\":\"https://www.semanticscholar.org/paper/a78199a2cc678818489087454fe1150db4870196\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40630836\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1591126916\",\"name\":\"Yunye Zhang\"},{\"authorId\":\"151486938\",\"name\":\"Yan Shi\"},{\"authorId\":\"51303869\",\"name\":\"Wenxin Yu\"},{\"authorId\":\"145191696\",\"name\":\"Li Nie\"},{\"authorId\":\"153179411\",\"name\":\"Gang He\"},{\"authorId\":\"119905363\",\"name\":\"Yibo Fan\"},{\"authorId\":\"144557426\",\"name\":\"Zhuo Yang\"}],\"doi\":\"10.1007/978-3-030-36802-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a5aaf408be292c1b6cbe1a4553f395c5a5c5ba5\",\"title\":\"Dense Image Captioning Based on Precise Feature Extraction\",\"url\":\"https://www.semanticscholar.org/paper/0a5aaf408be292c1b6cbe1a4553f395c5a5c5ba5\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"2012.09742\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49336560\",\"name\":\"Weining Wang\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"title\":\"AutoCaption: Image Captioning with Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/eb3f19de52d330ded5b3eebb79b89876648f67cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.00794\",\"authors\":[{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"48626691\",\"name\":\"Haoran Shi\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"10918587\",\"name\":\"Bowen Tan\"},{\"authorId\":\"8200875\",\"name\":\"Tiancheng Zhao\"},{\"authorId\":\"6215698\",\"name\":\"Junxian He\"},{\"authorId\":\"47825050\",\"name\":\"W. Wang\"},{\"authorId\":\"50188458\",\"name\":\"Xingjiang Yu\"},{\"authorId\":\"3444092\",\"name\":\"Lianhui Qin\"},{\"authorId\":\"144629030\",\"name\":\"Di Wang\"},{\"authorId\":\"2378954\",\"name\":\"Xuezhe Ma\"},{\"authorId\":\"100468503\",\"name\":\"Zhengzhong Liu\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"51439692\",\"name\":\"Wanrong Zhu\"},{\"authorId\":\"39670454\",\"name\":\"Devendra Singh Sachan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/W18-2503\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a1aff8c2a2812ac49d23ea816fc62bd9a20323d\",\"title\":\"Texar: A Modularized, Versatile, and Extensible Toolkit for Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/8a1aff8c2a2812ac49d23ea816fc62bd9a20323d\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"2010.10042\",\"authors\":[{\"authorId\":\"2965600\",\"name\":\"Y. Miura\"},{\"authorId\":\"49889487\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"2356307\",\"name\":\"C. Langlotz\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9e90c17ef40404b79ad0f12d9b9c94656f12dfcd\",\"title\":\"Improving Factual Completeness and Consistency of Image-to-Text Radiology Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e90c17ef40404b79ad0f12d9b9c94656f12dfcd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50704161\",\"name\":\"Lingxuan Li\"},{\"authorId\":\"11232438\",\"name\":\"Yihong Zhao\"},{\"authorId\":\"96515479\",\"name\":\"Zhaorui Zhang\"},{\"authorId\":\"1733076573\",\"name\":\"Tianrui Niu\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"48631332\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-60457-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c0d407899b7c535ce90fa798309214902ae0cba\",\"title\":\"Referring Expression Generation via Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0c0d407899b7c535ce90fa798309214902ae0cba\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"2010.11364\",\"authors\":[{\"authorId\":\"103203746\",\"name\":\"Junzi Zhang\"},{\"authorId\":\"102361165\",\"name\":\"J. Kim\"},{\"authorId\":\"1389654226\",\"name\":\"Brendan O'Donoghue\"},{\"authorId\":\"153421980\",\"name\":\"Stephen Boyd\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"305e04357a7e16292fad7248426e7cf4f51c93a9\",\"title\":\"Sample Efficient Reinforcement Learning with REINFORCE\",\"url\":\"https://www.semanticscholar.org/paper/305e04357a7e16292fad7248426e7cf4f51c93a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.05614\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"38376468\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3233/FAIA200204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0c33980d7c011a8c657afb825220632e17b1568\",\"title\":\"Delving Deeper into the Decoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f0c33980d7c011a8c657afb825220632e17b1568\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49868702\",\"name\":\"Ran Wei\"},{\"authorId\":\"144065286\",\"name\":\"Li Mi\"},{\"authorId\":\"7741774\",\"name\":\"Y. Hu\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1016/j.jvcir.2020.102751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b43ca6f4615d5e384a9b404964a49ed21a14805\",\"title\":\"Exploiting the local temporal information for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4b43ca6f4615d5e384a9b404964a49ed21a14805\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3503889\",\"name\":\"Y. Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"143953684\",\"name\":\"M. Lin\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dbd733060f5ef80b0e140e80d27a2cd0a98eef0\",\"title\":\"Learning and Thinking Strategy for Training Sequence Generation Models\",\"url\":\"https://www.semanticscholar.org/paper/8dbd733060f5ef80b0e140e80d27a2cd0a98eef0\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2009.13682\",\"authors\":[{\"authorId\":\"50049779\",\"name\":\"X. Hu\"},{\"authorId\":\"1629039205\",\"name\":\"Xi Yin\"},{\"authorId\":\"51188307\",\"name\":\"Kevin Lin\"},{\"authorId\":\"29957038\",\"name\":\"Longguang Wang\"},{\"authorId\":\"1720539\",\"name\":\"L. Zhang\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1691128\",\"name\":\"Zicheng Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f147279c9d1edddda57f1f21f23b3b58998bad74\",\"title\":\"VIVO: Surpassing Human Performance in Novel Object Captioning with Visual Vocabulary Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/f147279c9d1edddda57f1f21f23b3b58998bad74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02365\",\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144864336\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2909864\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"title\":\"Context-Aware Visual Policy Network for Fine-Grained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/DICTA.2018.8615788\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"title\":\"Size-Invariant Attention Accuracy Metric for Image Captioning with High-Resolution Residual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":\"1903.02507\",\"authors\":[{\"authorId\":\"3259825\",\"name\":\"Jiayun Li\"},{\"authorId\":\"39367903\",\"name\":\"Mohammad K. Ebrahimpour\"},{\"authorId\":\"33129821\",\"name\":\"Azadeh Moghtaderi\"},{\"authorId\":\"1915432\",\"name\":\"Yen-Yun Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ea752a837e24686a5774e6cbe6f787a76cd014d\",\"title\":\"Image captioning with weakly-supervised attention penalty\",\"url\":\"https://www.semanticscholar.org/paper/2ea752a837e24686a5774e6cbe6f787a76cd014d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2486c41d1ec20dd53de912c77035743816638b6\",\"title\":\"An Active Information Seeking Model for Goal-oriented Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c2486c41d1ec20dd53de912c77035743816638b6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1624658620\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"1429199889\",\"name\":\"Shaozu Yuan\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981513\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"711be95a04da16c93b6bc880169532b68cdca37a\",\"title\":\"Hierarchical Attention-Based Fusion for Image Caption With Multi-Grained Rewards\",\"url\":\"https://www.semanticscholar.org/paper/711be95a04da16c93b6bc880169532b68cdca37a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629172313\",\"name\":\"Liqing Wan\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"34985619\",\"name\":\"Xiaoping Che\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"title\":\"A Fast Action Recognition Method with Cascaded Networks\",\"url\":\"https://www.semanticscholar.org/paper/bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394268425\",\"name\":\"Pascal Fecht\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d544945e3426bb10ebc388a97fd4f101c378f6d2\",\"title\":\"Sequential transfer learning in NLP for text summarization\",\"url\":\"https://www.semanticscholar.org/paper/d544945e3426bb10ebc388a97fd4f101c378f6d2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1411260673\",\"name\":\"Luke Melas-Kyriazi\"},{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"},{\"authorId\":\"50552688\",\"name\":\"G. Han\"}],\"doi\":\"10.18653/v1/D18-1084\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8298cf0056af5afa3185181ddd5f6bb03181696\",\"title\":\"Training for Diversity in Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b8298cf0056af5afa3185181ddd5f6bb03181696\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2825517\",\"name\":\"D. Stoyanov\"},{\"authorId\":\"39356467\",\"name\":\"Z. Taylor\"},{\"authorId\":\"145575177\",\"name\":\"G. Carneiro\"},{\"authorId\":\"1387878041\",\"name\":\"T. Syeda-Mahmood\"},{\"authorId\":\"32057916\",\"name\":\"A. Martel\"},{\"authorId\":\"1397958668\",\"name\":\"L. Maier-Hein\"},{\"authorId\":\"144168728\",\"name\":\"J. Tavares\"},{\"authorId\":\"1720617\",\"name\":\"A. Bradley\"},{\"authorId\":\"1759037\",\"name\":\"J. Papa\"},{\"authorId\":\"1882784\",\"name\":\"Vasileios Belagiannis\"},{\"authorId\":\"3259175\",\"name\":\"J. Nascimento\"},{\"authorId\":\"1389208367\",\"name\":\"Zhi Lu\"},{\"authorId\":\"2546103\",\"name\":\"Sailesh Conjeti\"},{\"authorId\":\"1380480289\",\"name\":\"Mehdi Moradi\"},{\"authorId\":\"143942875\",\"name\":\"H. Greenspan\"},{\"authorId\":\"1705442\",\"name\":\"A. Madabhushi\"}],\"doi\":\"10.1007/978-3-030-00889-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f463e645ca4438a4c624ba981017fec2931fca24\",\"title\":\"Deep Learning in Medical Image Analysis and Multimodal Learning for Clinical Decision Support: 4th International Workshop, DLMIA 2018, and 8th International Workshop, ML-CDS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 20, 2018, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/f463e645ca4438a4c624ba981017fec2931fca24\",\"venue\":\"DLMIA/ML-CDS@MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2037486210\",\"name\":\"Qiaoqiao Yang\"},{\"authorId\":\"1410201319\",\"name\":\"Guangxing Wang\"},{\"authorId\":\"1695975266\",\"name\":\"Xiaoyu Zhang\"},{\"authorId\":\"2037477833\",\"name\":\"Christos Grecos\"},{\"authorId\":\"143823414\",\"name\":\"Peng Ren\"}],\"doi\":\"10.2112/SI102-018.1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"556edd10f961c30fc523f291fe657db56a297850\",\"title\":\"Coastal Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/556edd10f961c30fc523f291fe657db56a297850\",\"venue\":\"Journal of Coastal Research\",\"year\":2020},{\"arxivId\":\"2002.11848\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"title\":\"Analysis of diversity-accuracy tradeoff in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/9ed8c8ee62b0afc403e44c29f6deedf6632885d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2003.10925\",\"authors\":[{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"title\":\"Learning Compact Reward for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32701193\",\"name\":\"Yuanzhi Liang\"},{\"authorId\":\"2643877\",\"name\":\"Y. Bai\"},{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"4096586\",\"name\":\"L. Zhu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.01050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"db717d20dc699f4b402db0ddf923135108a9e686\",\"title\":\"VrR-VG: Refocusing Visually-Relevant Relationships\",\"url\":\"https://www.semanticscholar.org/paper/db717d20dc699f4b402db0ddf923135108a9e686\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.08089\",\"authors\":[{\"authorId\":\"50695615\",\"name\":\"Shiyin Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60cb01b81c1d3daa31308b95ad670705b5ed7504\",\"title\":\"Predicting Drug Responses by Propagating Interactions through Text-Enhanced Drug-Gene Networks\",\"url\":\"https://www.semanticscholar.org/paper/60cb01b81c1d3daa31308b95ad670705b5ed7504\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df9a08016fa553a169d893ce2d3fca375bab4781\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df9a08016fa553a169d893ce2d3fca375bab4781\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.06043\",\"authors\":[{\"authorId\":\"50349716\",\"name\":\"W. Kool\"},{\"authorId\":\"47662867\",\"name\":\"H. V. Hoof\"},{\"authorId\":\"1678311\",\"name\":\"M. Welling\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f068c285e7ffe09886b944cc0144c88afe65825b\",\"title\":\"Estimating Gradients for Discrete Random Variables by Sampling without Replacement\",\"url\":\"https://www.semanticscholar.org/paper/f068c285e7ffe09886b944cc0144c88afe65825b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2008.02693\",\"authors\":[{\"authorId\":\"8314407\",\"name\":\"X. Yang\"},{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"145657309\",\"name\":\"D. Jin\"},{\"authorId\":\"49421744\",\"name\":\"Yingru Liu\"},{\"authorId\":\"120931191\",\"name\":\"Chi-Hao Wu\"},{\"authorId\":\"34331333\",\"name\":\"Jianchao Tan\"},{\"authorId\":\"47300385\",\"name\":\"Dongliang Xie\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":null,\"name\":\"Xin Wang\"}],\"doi\":\"10.1007/978-3-030-58601-0_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf72a4a75b6ecd6dbc4c1af52a9592ec61abcfb5\",\"title\":\"Fashion Captioning: Towards Generating Accurate Descriptions with Semantic Rewards\",\"url\":\"https://www.semanticscholar.org/paper/bf72a4a75b6ecd6dbc4c1af52a9592ec61abcfb5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2011.04264\",\"authors\":[{\"authorId\":\"32763968\",\"name\":\"A. Fisch\"},{\"authorId\":\"2544107\",\"name\":\"Kenton Lee\"},{\"authorId\":\"1744179\",\"name\":\"Ming-Wei Chang\"},{\"authorId\":\"144797264\",\"name\":\"J. Clark\"},{\"authorId\":\"1741283\",\"name\":\"R. Barzilay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ca71f61139c69131ab200368a30a3dc72fa6785\",\"title\":\"CapWAP: Captioning with a Purpose\",\"url\":\"https://www.semanticscholar.org/paper/8ca71f61139c69131ab200368a30a3dc72fa6785\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2004.14530\",\"authors\":[{\"authorId\":\"50531624\",\"name\":\"Peng Qi\"},{\"authorId\":\"49889487\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17cabd746318248f0c1210c5896f7b65666867ac\",\"title\":\"Stay Hungry, Stay Focused: Generating Informative and Specific Questions in Information-Seeking Conversations\",\"url\":\"https://www.semanticscholar.org/paper/17cabd746318248f0c1210c5896f7b65666867ac\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.05131\",\"authors\":[{\"authorId\":\"51102360\",\"name\":\"Yilei Zeng\"},{\"authorId\":\"51924717\",\"name\":\"Deren Lei\"},{\"authorId\":\"29892900\",\"name\":\"Beichen Li\"},{\"authorId\":\"1667072221\",\"name\":\"Gangrong Jiang\"},{\"authorId\":\"48898287\",\"name\":\"Emilio Ferrara\"},{\"authorId\":\"51371300\",\"name\":\"Michael Zyda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"219d7b3a87c7919db5e64f834d43322ad4dfe1f1\",\"title\":\"Learning to Reason in Round-based Games: Multi-task Sequence Generation for Purchasing Decision Making in First-person Shooters\",\"url\":\"https://www.semanticscholar.org/paper/219d7b3a87c7919db5e64f834d43322ad4dfe1f1\",\"venue\":\"AAAI 2020\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"134473682\",\"name\":\"Mingwen Shao\"},{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"}],\"doi\":\"10.1016/j.neucom.2019.12.073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50260b547a481a95a2346759da8dba9366e89348\",\"title\":\"Multi-Attention Generative Adversarial Network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/50260b547a481a95a2346759da8dba9366e89348\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2008.04504\",\"authors\":[{\"authorId\":\"38921864\",\"name\":\"J. Li\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"1585272537\",\"name\":\"Juncheng Li\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"93192602\",\"name\":\"Fei Wu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3394171.3413886\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6108971941fc5cd73c55bc3b42dd892fd4da6eb2\",\"title\":\"Topic Adaptation and Prototype Encoding for Few-Shot Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/6108971941fc5cd73c55bc3b42dd892fd4da6eb2\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"47666390\",\"name\":\"H. Chen\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/s12559-018-9581-x\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"title\":\"Neural Image Caption Generation with Weighted Training and Reference\",\"url\":\"https://www.semanticscholar.org/paper/848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"venue\":\"Cognitive Computation\",\"year\":2018},{\"arxivId\":\"1910.14208\",\"authors\":[{\"authorId\":\"9095876\",\"name\":\"Jipeng Wu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61b1bb801d03a9b0da5721c6beaabf1dc6cd90c0\",\"title\":\"Hidden State Guidance: Improving Image Captioning Using an Image Conditioned Autoencoder\",\"url\":\"https://www.semanticscholar.org/paper/61b1bb801d03a9b0da5721c6beaabf1dc6cd90c0\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s12559-019-09656-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"title\":\"Image Captioning with Memorized Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"venue\":\"Cognitive Computation\",\"year\":2019},{\"arxivId\":\"1905.11978\",\"authors\":[{\"authorId\":\"2902068\",\"name\":\"Yanshuai Cao\"},{\"authorId\":null,\"name\":\"Peng Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0870d4e61fd243e604c70593956b2adf220300bd\",\"title\":\"Better Long-Range Dependency By Bootstrapping A Mutual Information Regularizer\",\"url\":\"https://www.semanticscholar.org/paper/0870d4e61fd243e604c70593956b2adf220300bd\",\"venue\":\"AISTATS\",\"year\":2020},{\"arxivId\":\"1812.03283\",\"authors\":[{\"authorId\":\"4760298\",\"name\":\"J. Du\"},{\"authorId\":\"144485517\",\"name\":\"Yu Qin\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b75163ef32d63ba076e94d9321442ca8223fcd4\",\"title\":\"Attend More Times for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0b75163ef32d63ba076e94d9321442ca8223fcd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"49991208\",\"name\":\"Jimeng Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c631bb439284f6a5a90608b715fa631d5c5807e4\",\"title\":\"EEGtoText: Learning to Write Medical Reports from EEG Recordings\",\"url\":\"https://www.semanticscholar.org/paper/c631bb439284f6a5a90608b715fa631d5c5807e4\",\"venue\":\"MLHC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29461008\",\"name\":\"Lecheng Wang\"},{\"authorId\":\"51478887\",\"name\":\"Shizheng Qin\"},{\"authorId\":\"14565924\",\"name\":\"Meng-long Xu\"},{\"authorId\":\"97937527\",\"name\":\"Rui Zhang\"},{\"authorId\":\"1410674575\",\"name\":\"Lizhe Qi\"},{\"authorId\":\"50550297\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/ROBIO49542.2019.8961449\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a70981ab7b4011b8f4e656e383685d8c3cd58c79\",\"title\":\"From Quick-draw To Story: A Story Generation System for Kids\\u2019 Robot\",\"url\":\"https://www.semanticscholar.org/paper/a70981ab7b4011b8f4e656e383685d8c3cd58c79\",\"venue\":\"2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145381969\",\"name\":\"T. Yu\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"}],\"doi\":\"10.1145/3292500.3330991\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78b25ca3f02d1abe1fa5440d02dd5fa82c8dfa3c\",\"title\":\"A Visual Dialog Augmented Interactive Recommender System\",\"url\":\"https://www.semanticscholar.org/paper/78b25ca3f02d1abe1fa5440d02dd5fa82c8dfa3c\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97636424\",\"name\":\"G. Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144303230\",\"name\":\"Ping Liu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICCV.2019.00902\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"title\":\"Entangled Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.05942\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00643\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"title\":\"Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning\",\"url\":\"https://www.semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2006.06346\",\"authors\":[{\"authorId\":\"117361255\",\"name\":\"Rob D. Hesselink\"},{\"authorId\":\"2782694\",\"name\":\"W. Aziz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69d9ff18f384a8e38350cb4bee15d5bc508e67d9\",\"title\":\"Latent Transformations for Discrete-Data Normalising Flows\",\"url\":\"https://www.semanticscholar.org/paper/69d9ff18f384a8e38350cb4bee15d5bc508e67d9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389373080\",\"name\":\"Ruoyu Chen\"},{\"authorId\":\"2607225\",\"name\":\"Zhongnian Li\"},{\"authorId\":\"1772283\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-1398-5_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bab70faa1e36b525766f85b5ff87bff4566d0294\",\"title\":\"Adaptive Joint Attention with Reinforcement Training for Convolutional Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/bab70faa1e36b525766f85b5ff87bff4566d0294\",\"venue\":\"HBAI@IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"144346837\",\"name\":\"Min Yang\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"28106616\",\"name\":\"Yabing Feng\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1145/3132847.3132920\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3844a6cef7960729125722e2d07024058dd9204a\",\"title\":\"Dual Learning for Cross-domain Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3844a6cef7960729125722e2d07024058dd9204a\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145960537\",\"name\":\"W. Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1007/978-981-10-7299-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"title\":\"Relevance and Coherence Based Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805478\",\"name\":\"Dheeraj Kumar Peri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"214679a3a2a6a2325a9d168006e58c6150b4eae0\",\"title\":\"Multi-modal learning using deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/214679a3a2a6a2325a9d168006e58c6150b4eae0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1809.01694\",\"authors\":[{\"authorId\":\"20851195\",\"name\":\"Kazuma Hashimoto\"},{\"authorId\":\"143946906\",\"name\":\"Yoshimasa Tsuruoka\"}],\"doi\":\"10.18653/v1/N19-1315\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2d07ce330e7c9e62f5dbdf0759078bc9341894a8\",\"title\":\"Accelerated Reinforcement Learning for Sentence Generation by Vocabulary Prediction\",\"url\":\"https://www.semanticscholar.org/paper/2d07ce330e7c9e62f5dbdf0759078bc9341894a8\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143790499\",\"name\":\"S. Narayan\"},{\"authorId\":\"1794075\",\"name\":\"Claire Gardent\"}],\"doi\":\"10.2200/s00979ed1v01y201912hlt044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5423c3e681fe9333f6877362663bada7c03489d3\",\"title\":\"Deep Learning Approaches to Text Production\",\"url\":\"https://www.semanticscholar.org/paper/5423c3e681fe9333f6877362663bada7c03489d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.03600\",\"authors\":[{\"authorId\":\"1557382779\",\"name\":\"N. Mazyavkina\"},{\"authorId\":\"91059972\",\"name\":\"S. Sviridov\"},{\"authorId\":\"37133975\",\"name\":\"S. Ivanov\"},{\"authorId\":\"51139941\",\"name\":\"Evgeny Burnaev\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c51431592f748c771a2afa8c91dc25c07d5fdee1\",\"title\":\"Reinforcement Learning for Combinatorial Optimization: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/c51431592f748c771a2afa8c91dc25c07d5fdee1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.12870\",\"authors\":[{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"8157338\",\"name\":\"Zhenhao Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"title\":\"Multimodal Learning for Hateful Memes Detection\",\"url\":\"https://www.semanticscholar.org/paper/14e5d984af4ac965579644bd0ea4ae42587b6a00\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.01288\",\"authors\":[{\"authorId\":\"144407296\",\"name\":\"J. Gao\"},{\"authorId\":\"1960607091\",\"name\":\"Yi Zhou\"},{\"authorId\":\"2721708\",\"name\":\"P. Yu\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8405576136062ea661febeeedbc5076235d5eb42\",\"title\":\"Unsupervised Cross-lingual Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8405576136062ea661febeeedbc5076235d5eb42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696589727\",\"name\":\"Dongming Zhou\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"48708659\",\"name\":\"Zhiwen Wang\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"title\":\"Multi-level Visual Fusion Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1608.05777\",\"authors\":[{\"authorId\":\"145949097\",\"name\":\"Lei Xu\"},{\"authorId\":\"51046992\",\"name\":\"Z. Wang\"},{\"authorId\":\"3393818\",\"name\":\"Ayana\"},{\"authorId\":\"49293587\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/s11432-019-2657-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f62a7806c4f45a7096553a5e0689d73e66c1de4f\",\"title\":\"Topic-sensitive neural headline generation\",\"url\":\"https://www.semanticscholar.org/paper/f62a7806c4f45a7096553a5e0689d73e66c1de4f\",\"venue\":\"Science China Information Sciences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90163180\",\"name\":\"Farshid Faal\"},{\"authorId\":\"3152306\",\"name\":\"J. Yu\"},{\"authorId\":\"47990249\",\"name\":\"K. Schmitt\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207289\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0b1dcb631379aad89130e94f5bf4ede9d22d0f8\",\"title\":\"Transformer Decoder Based Reinforcement Learning Approach for Conversational Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/e0b1dcb631379aad89130e94f5bf4ede9d22d0f8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713611\",\"name\":\"J. Filipe\"},{\"authorId\":\"17324395\",\"name\":\"A. Ghosh\"},{\"authorId\":\"1690892\",\"name\":\"R. Prates\"},{\"authorId\":\"2395016\",\"name\":\"O. Shehory\"},{\"authorId\":\"2338905\",\"name\":\"E. Farchi\"},{\"authorId\":\"38124254\",\"name\":\"Guy Barash\"}],\"doi\":\"10.1007/978-3-030-62144-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d51bb594214e62031b4cd8c92e53035f38d367b9\",\"title\":\"Engineering Dependable and Secure Machine Learning Systems: Third International Workshop, EDSMLS 2020, New York City, NY, USA, February 7, 2020, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/d51bb594214e62031b4cd8c92e53035f38d367b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47196880\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"}],\"doi\":\"10.1007/978-3-030-39469-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fb87759fff098cbb487d74404ce8ca1098253a1\",\"title\":\"PAIC: Parallelised Attentive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7fb87759fff098cbb487d74404ce8ca1098253a1\",\"venue\":\"ADC\",\"year\":2020},{\"arxivId\":\"1809.03182\",\"authors\":[{\"authorId\":\"50214018\",\"name\":\"N. Pham\"},{\"authorId\":\"2920247\",\"name\":\"J. Niehues\"},{\"authorId\":\"1724972\",\"name\":\"Alexander H. Waibel\"}],\"doi\":\"10.18653/v1/W18-2712\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cdcdb52d89fb4c730c8ef360b41d3f19e1d20b9b\",\"title\":\"Towards one-shot learning for rare-word translation with external experts\",\"url\":\"https://www.semanticscholar.org/paper/cdcdb52d89fb4c730c8ef360b41d3f19e1d20b9b\",\"venue\":\"NMT@ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37310105\",\"name\":\"L. Zhao\"},{\"authorId\":\"47423527\",\"name\":\"Chunxia Zhang\"},{\"authorId\":null,\"name\":\"Xi Zhang\"},{\"authorId\":\"3034224\",\"name\":\"Yating Hu\"},{\"authorId\":\"8253080\",\"name\":\"Z. Niu\"}],\"doi\":\"10.1007/978-3-319-97304-3_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f472524ad1a5989aa1d66634a477041cd6ec9b64\",\"title\":\"A Deep Reinforced Training Method for Location-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f472524ad1a5989aa1d66634a477041cd6ec9b64\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":\"2005.05256\",\"authors\":[{\"authorId\":\"30053596\",\"name\":\"Abhilasha Sancheti\"},{\"authorId\":\"38716503\",\"name\":\"K. Krishna\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"},{\"authorId\":\"3365985\",\"name\":\"Anandhavelu Natarajan\"}],\"doi\":\"10.1007/978-3-030-45439-5_36\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5f61790116132de62e1cad3c3fe5f863cb6ff00\",\"title\":\"Reinforced Rewards Framework for Text Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b5f61790116132de62e1cad3c3fe5f863cb6ff00\",\"venue\":\"ECIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113270085\",\"name\":\"Jianxing Yu\"},{\"authorId\":\"38472218\",\"name\":\"Xiaojun Quan\"},{\"authorId\":\"2482836\",\"name\":\"Qinliang Su\"},{\"authorId\":\"1635933070\",\"name\":\"Jian Yin\"}],\"doi\":\"10.1145/3366423.3380114\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c8e5f64e98bab3dcc706e4b0d680dc5308a9b17\",\"title\":\"Generating Multi-hop Reasoning Questions to Improve Machine Reading Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/3c8e5f64e98bab3dcc706e4b0d680dc5308a9b17\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1807.09958\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"50816334\",\"name\":\"D. Ye\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01228-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"title\":\"Rethinking the Form of Latent States in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120133200\",\"name\":\"A. Joey\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"894ea31904c908710ceb43da557a1be196d4db80\",\"title\":\"Active Learning through Adversarial Exploration in Contrastive Objectives\",\"url\":\"https://www.semanticscholar.org/paper/894ea31904c908710ceb43da557a1be196d4db80\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"title\":\"Nested-Wasserstein Distance for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3444866\",\"name\":\"Alessandro Suglia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4eeaeedb7fa72341ce385a173d88b48a943faa5\",\"title\":\"Empowering Conversational Agents with Situated Natural Language Communication Skills by Exploiting Deep Reinforcement Learning Techniques\",\"url\":\"https://www.semanticscholar.org/paper/b4eeaeedb7fa72341ce385a173d88b48a943faa5\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1809.03118\",\"authors\":[{\"authorId\":\"46709826\",\"name\":\"Pengcheng Yang\"},{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":null,\"name\":\"Yi Zhang\"},{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"48987995\",\"name\":\"Q. Su\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f3ec3462b15472182142ef1896d9368477dd692e\",\"title\":\"A Deep Reinforced Sequence-to-Set Model for Multi-Label Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/f3ec3462b15472182142ef1896d9368477dd692e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2012.07333\",\"authors\":[{\"authorId\":\"1733071048\",\"name\":\"Chao Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7212df671c50beb567e3d3d608b0c14405c40e3\",\"title\":\"Intrinsic Image Captioning Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7212df671c50beb567e3d3d608b0c14405c40e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yongzhen Wang\"},{\"authorId\":\"7898160\",\"name\":\"J. Wang\"},{\"authorId\":\"1748032\",\"name\":\"Heng Huang\"},{\"authorId\":\"49404593\",\"name\":\"Hongsong Li\"},{\"authorId\":\"1713802\",\"name\":\"Xiaozhong Liu\"}],\"doi\":\"10.1145/3397271.3401140\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7080d224ab4cb1c9dd52017d4d7d8b0d0214b9a\",\"title\":\"Evolutionary Product Description Generation: A Dynamic Fine-Tuning Approach Leveraging User Click Behavior\",\"url\":\"https://www.semanticscholar.org/paper/f7080d224ab4cb1c9dd52017d4d7d8b0d0214b9a\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1706.04499\",\"authors\":[{\"authorId\":\"37212795\",\"name\":\"R\\u00e9mi Leblond\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"145319877\",\"name\":\"A. Osokin\"},{\"authorId\":\"1388317459\",\"name\":\"S. Lacoste-Julien\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"345bbd344177815dfb9214c61403cb7eac6de450\",\"title\":\"SEARNN: Training RNNs with Global-Local Losses\",\"url\":\"https://www.semanticscholar.org/paper/345bbd344177815dfb9214c61403cb7eac6de450\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1909.03622\",\"authors\":[{\"authorId\":\"36538344\",\"name\":\"James O'Neill\"},{\"authorId\":\"2720656\",\"name\":\"Danushka Bollegala\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e382d10993daae43659a06c99b7ae8f3b00ad75\",\"title\":\"Transfer Reward Learning for Policy Gradient-Based Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/8e382d10993daae43659a06c99b7ae8f3b00ad75\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50610439\",\"name\":\"Songtao Ding\"},{\"authorId\":\"2641875\",\"name\":\"Shiru Qu\"},{\"authorId\":\"6962569\",\"name\":\"Yuling Xi\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"}],\"doi\":\"10.1016/J.FUTURE.2018.10.054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36f66917c5726b0ff65fad588e24874fcfbc2c88\",\"title\":\"A long video caption generation algorithm for big video data retrieval\",\"url\":\"https://www.semanticscholar.org/paper/36f66917c5726b0ff65fad588e24874fcfbc2c88\",\"venue\":\"Future Gener. Comput. Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2012.02033\",\"authors\":[{\"authorId\":\"152332057\",\"name\":\"Baohua Sun\"},{\"authorId\":\"1999579263\",\"name\":\"Michael Lin\"},{\"authorId\":\"1505825326\",\"name\":\"Hao Sha\"},{\"authorId\":\"1986616718\",\"name\":\"Lin Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"title\":\"SuperOCR: A Conversion from Optical Character Recognition to Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412728173\",\"name\":\"Amal M. Al-Numai\"},{\"authorId\":\"2569677\",\"name\":\"Aqil M. Azmi\"}],\"doi\":\"10.4018/978-1-5225-9373-7.CH002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"872da01fe74907ce8f4c0426be4a3e3f3fc8345f\",\"title\":\"The Development of Single-Document Abstractive Text Summarizer During the Last Decade\",\"url\":\"https://www.semanticscholar.org/paper/872da01fe74907ce8f4c0426be4a3e3f3fc8345f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13122\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5318abd4f12a5b25c2847e9c66713951341af504\",\"title\":\"SubICap: Towards Subword-informed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5318abd4f12a5b25c2847e9c66713951341af504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.08271\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d87489d2facf197caafd24d0796523d55d47fb62\",\"title\":\"A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer\",\"url\":\"https://www.semanticscholar.org/paper/d87489d2facf197caafd24d0796523d55d47fb62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12274\",\"authors\":[{\"authorId\":\"29860450\",\"name\":\"Baoyu Jing\"},{\"authorId\":\"1905077\",\"name\":\"Zeya Wang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/P19-1657\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"title\":\"Show, Describe and Conclude: On Exploiting the Structure Information of Chest X-ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"venue\":\"ACL\",\"year\":2019}],\"corpusId\":206594923,\"doi\":\"10.1109/CVPR.2017.131\",\"fieldsOfStudy\":[\"Computer Science\",\"Mathematics\"],\"influentialCitationCount\":141,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"references\":[{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"a blue boat is sitting on the side of a building \\u00ad0\",\"url\":\"\",\"venue\":\"a blue boat is sitting on the side of a building \\u00ad0\",\"year\":1946},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699645\",\"name\":\"R. Sutton\"},{\"authorId\":\"1730590\",\"name\":\"A. Barto\"}],\"doi\":\"10.1109/TNN.1998.712192\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97efafdb4a3942ab3efba53ded7413199f79c054\",\"title\":\"Reinforcement Learning: An Introduction\",\"url\":\"https://www.semanticscholar.org/paper/97efafdb4a3942ab3efba53ded7413199f79c054\",\"venue\":\"IEEE Transactions on Neural Networks\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1794917\",\"name\":\"M. J. Choi\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"1701607\",\"name\":\"A. Willsky\"}],\"doi\":\"10.1016/j.patrec.2011.12.004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"28aa465c3af7e5ccf1b10ae9cf76e83aab3ee34f\",\"title\":\"Context models and out-of-context objects\",\"url\":\"https://www.semanticscholar.org/paper/28aa465c3af7e5ccf1b10ae9cf76e83aab3ee34f\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Myung Jinchoi\"},{\"authorId\":null,\"name\":\"Antonio Torralba\"},{\"authorId\":null,\"name\":\"Alan S Willsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Context models and out-of\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40410858\",\"name\":\"R. J. Williams\"}],\"doi\":\"10.1007/BF00992696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"title\":\"Simple statistical gradient-following algorithms for connectionist reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/4c915c1eecb217c123a36dc6d3ce52d12c742614\",\"venue\":\"Machine Learning\",\"year\":2004},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":\"1607.07086\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2616163\",\"name\":\"Philemon Brakel\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d24a0695c9fc669e643bad51d4e14f056329dec\",\"title\":\"An Actor-Critic Algorithm for Sequence Prediction\",\"url\":\"https://www.semanticscholar.org/paper/0d24a0695c9fc669e643bad51d4e14f056329dec\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.02438\",\"authors\":[{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"29912342\",\"name\":\"P. Moritz\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"},{\"authorId\":\"1694621\",\"name\":\"Michael I. Jordan\"},{\"authorId\":\"1689992\",\"name\":\"P. Abbeel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d316c82c12cf4c45f9e85211ef3d1fa62497bff8\",\"title\":\"High-Dimensional Continuous Control Using Generalized Advantage Estimation\",\"url\":\"https://www.semanticscholar.org/paper/d316c82c12cf4c45f9e85211ef3d1fa62497bff8\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1402.0030\",\"authors\":[{\"authorId\":\"1714004\",\"name\":\"A. Mnih\"},{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"018300f5f0e679cee5241d9c69c8d88e00e8bf31\",\"title\":\"Neural Variational Inference and Learning in Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/018300f5f0e679cee5241d9c69c8d88e00e8bf31\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Image Caption Generation Demo With Visual Attention\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.06732\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"2325985\",\"name\":\"M. Auli\"},{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"title\":\"Sequence Level Training with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/35c1668dc64d24a28c6041978e5fcca754eb2f4b\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"a blue street sign on the side of a building \\u00ad0.224760 3. a blue umbrella sitting on top of a building \\u00ad0\",\"url\":\"\",\"venue\":\"a blue street sign on the side of a building \\u00ad0.224760 3. a blue umbrella sitting on top of a building \\u00ad0\",\"year\":null},{\"arxivId\":\"1610.09038\",\"authors\":[{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"title\":\"Professor Forcing: A New Algorithm for Training Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/db38edba294b7d2fd8ca3aad65721bd9dce32619\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"a blue boat sitting on the side of a building \\u00ad0\",\"url\":\"\",\"venue\":\"a blue boat sitting on the side of a building \\u00ad0\",\"year\":null},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kyunghyun Cho\"},{\"authorId\":null,\"name\":\"Bart van Merrienboer\"},{\"authorId\":null,\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":null,\"name\":\"Fethi Bougares\"},{\"authorId\":null,\"name\":\"Holger Schwenk\"},{\"authorId\":null,\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning phrase representations using RNN encoderdecoder for statistical machine\",\"url\":\"\",\"venue\":\"\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.06647\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"48818137\",\"name\":\"Samy Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/TPAMI.2016.2587640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"title\":\"Show and Tell: Lessons Learned from the 2015 MSCOCO Image Captioning Challenge\",\"url\":\"https://www.semanticscholar.org/paper/62f74d3aaf9e86633e4d88b04a6d04ca93e8b81e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1505.00521\",\"authors\":[{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f10e071292d593fef939e6ef4a59baf0bb3a6c2b\",\"title\":\"Reinforcement Learning Neural Turing Machines\",\"url\":\"https://www.semanticscholar.org/paper/f10e071292d593fef939e6ef4a59baf0bb3a6c2b\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Attention heat-maps for the best model in the XE-trained ensemble of attention models, for the image depicted in figure 6\",\"url\":\"\",\"venue\":\"\",\"year\":null}],\"title\":\"Self-Critical Sequence Training for Image Captioning\",\"topics\":[{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"SCST\",\"topicId\":\"1215207\",\"url\":\"https://www.semanticscholar.org/topic/1215207\"},{\"topic\":\"Greedy algorithm\",\"topicId\":\"4173\",\"url\":\"https://www.semanticscholar.org/topic/4173\"},{\"topic\":\"Database normalization\",\"topicId\":\"16746\",\"url\":\"https://www.semanticscholar.org/topic/16746\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Gradient\",\"topicId\":\"3221\",\"url\":\"https://www.semanticscholar.org/topic/3221\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"}],\"url\":\"https://www.semanticscholar.org/paper/6c8353697cdbb98dfba4f493875778c4286d3e3a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"