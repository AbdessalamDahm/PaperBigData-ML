"{\"abstract\":\"Localizing functional regions of objects or affordances is an important aspect of scene understanding and relevant for many robotics applications. In this work, we introduce a pixel-wise annotated affordance dataset of 3090 images containing 9916 object instances. Since parts of an object can have multiple affordances, we address this by a convolutional neural network for multilabel affordance segmentation. We also propose an approach to train the network from very few keypoint annotations. Our approach achieves a higher affordance detection accuracy than other weakly supervised methods that also rely on keypoint annotations or image annotations as weak supervision.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\",\"url\":\"https://www.semanticscholar.org/author/7229001\"},{\"authorId\":\"1716023\",\"name\":\"A. Srikantha\",\"url\":\"https://www.semanticscholar.org/author/1716023\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\",\"url\":\"https://www.semanticscholar.org/author/145689714\"}],\"citationVelocity\":11,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1700439375\",\"name\":\"S. Hussain\"},{\"authorId\":\"1409897231\",\"name\":\"Liu Liu\"},{\"authorId\":\"2000358050\",\"name\":\"Wenqiang Xu\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190733\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48bec606919e41025f7383f2fa8f3b37a14d4ac0\",\"title\":\"FPHA-Afford: A Domain-Specific Benchmark Dataset for Occluded Object Affordance Estimation in Human-Object-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/48bec606919e41025f7383f2fa8f3b37a14d4ac0\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1906.01963\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53d399e3ef23eeb477c46d59fc5558a8ed721e34\",\"title\":\"Grounded Human-Object Interaction Hotspots from Video (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/53d399e3ef23eeb477c46d59fc5558a8ed721e34\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.09761\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"af4df89ad28580d98113fa6a816195137f7d1a1d\",\"title\":\"Scene Understanding for Autonomous Manipulation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/af4df89ad28580d98113fa6a816195137f7d1a1d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39731965\",\"name\":\"Krishneel Chaudhary\"},{\"authorId\":\"1683608\",\"name\":\"K. Okada\"},{\"authorId\":\"1749935\",\"name\":\"M. Inaba\"},{\"authorId\":\"46772443\",\"name\":\"Xiangyu Chen\"}],\"doi\":\"10.1109/IROS.2018.8593617\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32351e6d9397cc65c9c4d4a9b3ae022a32ce1153\",\"title\":\"Predicting Part Affordances of Objects Using Two-Stream Fully Convolutional Network with Multimodal Inputs\",\"url\":\"https://www.semanticscholar.org/paper/32351e6d9397cc65c9c4d4a9b3ae022a32ce1153\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2240300\",\"name\":\"Safoura Rezapour Lakani\"}],\"doi\":null,\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"c6e274e39e870f16357f5c3614cc7456fcc04363\",\"title\":\"Affordance-Driven Visual Object Representation\",\"url\":\"https://www.semanticscholar.org/paper/c6e274e39e870f16357f5c3614cc7456fcc04363\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.11142\",\"authors\":[{\"authorId\":\"8134097\",\"name\":\"W. Liu\"},{\"authorId\":\"2590565\",\"name\":\"A. Daruna\"},{\"authorId\":\"114896876\",\"name\":\"S. Chernova\"}],\"doi\":\"10.1109/ICRA40945.2020.9197289\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f79a30fd9d88649c82ac072d76a1b82ee3e0e2f\",\"title\":\"CAGE: Context-Aware Grasping Engine\",\"url\":\"https://www.semanticscholar.org/paper/7f79a30fd9d88649c82ac072d76a1b82ee3e0e2f\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73235537\",\"name\":\"Timo L\\u00fcddecke\"},{\"authorId\":\"1705543\",\"name\":\"Tomas Kulvicius\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":\"10.1016/J.ROBOT.2019.05.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdd2d905ad09df66f50bcbc72186d1f33e8add6e\",\"title\":\"Context-based affordance segmentation from 2D images for robot actions\",\"url\":\"https://www.semanticscholar.org/paper/cdd2d905ad09df66f50bcbc72186d1f33e8add6e\",\"venue\":\"Robotics Auton. Syst.\",\"year\":2019},{\"arxivId\":\"1812.04558\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2019.00878\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"title\":\"Grounded Human-Object Interaction Hotspots From Video\",\"url\":\"https://www.semanticscholar.org/paper/316a16485bf9ad67a6a07888f8e0d24604d96b76\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3122743\",\"name\":\"F. Chu\"},{\"authorId\":\"19260257\",\"name\":\"Ruinian Xu\"},{\"authorId\":\"71043187\",\"name\":\"Landan Seguin\"},{\"authorId\":\"1736403\",\"name\":\"P. Vela\"}],\"doi\":\"10.1109/LRA.2019.2930364\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c3b73a4be4cb050705a02f47efceea548f03071\",\"title\":\"Toward Affordance Detection and Ranking on Novel Objects for Real-World Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/5c3b73a4be4cb050705a02f47efceea548f03071\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7968301\",\"name\":\"Peter Regier\"},{\"authorId\":\"26351048\",\"name\":\"Andres Milioto\"},{\"authorId\":\"1722062\",\"name\":\"C. Stachniss\"},{\"authorId\":\"2990518\",\"name\":\"Maren Bennewitz\"}],\"doi\":\"10.1142/s0219843620500139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59e2b2bea9a681aa2069319212fde6253b136e47\",\"title\":\"Classifying Obstacles and Exploiting Class Information for Humanoid Navigation Through Cluttered Environments\",\"url\":\"https://www.semanticscholar.org/paper/59e2b2bea9a681aa2069319212fde6253b136e47\",\"venue\":\"Int. J. Humanoid Robotics\",\"year\":2020},{\"arxivId\":\"1707.02850\",\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2017.164\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2298e44d71c34eff9c9e3406b0de574d60f79dd2\",\"title\":\"Adaptive Binarization for Weakly Supervised Affordance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2298e44d71c34eff9c9e3406b0de574d60f79dd2\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2240300\",\"name\":\"Safoura Rezapour Lakani\"},{\"authorId\":\"1401895875\",\"name\":\"A. Rodr\\u00edguez-S\\u00e1nchez\"},{\"authorId\":\"46666481\",\"name\":\"J. Piater\"}],\"doi\":\"10.1109/LRA.2018.2853639\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":false,\"paperId\":\"f79121c5bfca1cb5e9c8ace68234b603bb7bce98\",\"title\":\"Exercising Affordances of Objects: A Part-Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/f79121c5bfca1cb5e9c8ace68234b603bb7bce98\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"3370510\",\"name\":\"Martin Garbade\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1007/978-3-030-12939-2_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"606cfdcc43203351dbb944a3bb3719695e557e37\",\"title\":\"Ex Paucis Plura: Learning Affordance Segmentation from Very Few Examples\",\"url\":\"https://www.semanticscholar.org/paper/606cfdcc43203351dbb944a3bb3719695e557e37\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":\"1807.06775\",\"authors\":[{\"authorId\":\"145867132\",\"name\":\"Mohammed Hassanin\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"},{\"authorId\":\"2312383\",\"name\":\"M. Tahtali\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"81d327ec41c67728b15438bca86d10b72de1d88f\",\"title\":\"Visual Affordance and Function Understanding: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/81d327ec41c67728b15438bca86d10b72de1d88f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145428272\",\"name\":\"E. Ruiz\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.3389/fnbot.2020.00045\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de786022db9ba870f982e9446f38990d1bcc2209\",\"title\":\"Geometric Affordance Perception: Leveraging Deep 3D Saliency With the Interaction Tensor\",\"url\":\"https://www.semanticscholar.org/paper/de786022db9ba870f982e9446f38990d1bcc2209\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":\"1709.07326\",\"authors\":[{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":null,\"name\":\"Anh Nguyen\"},{\"authorId\":\"93622602\",\"name\":\"Ian Reid\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":\"10.1109/ICRA.2018.8460902\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d3b74d0702bbdca96f326d2d0ba96349f5c42a6\",\"title\":\"AffordanceNet: An End-to-End Deep Learning Approach for Object Affordance Detection\",\"url\":\"https://www.semanticscholar.org/paper/5d3b74d0702bbdca96f326d2d0ba96349f5c42a6\",\"venue\":\"2018 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35137594\",\"name\":\"Jinpeng Mi\"},{\"authorId\":\"51436910\",\"name\":\"Hongzhuo Liang\"},{\"authorId\":\"1693350606\",\"name\":\"Nikolaos Katsakis\"},{\"authorId\":\"145194289\",\"name\":\"Song Tang\"},{\"authorId\":\"153082688\",\"name\":\"Qingdu Li\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"50561627\",\"name\":\"J. Zhang\"}],\"doi\":\"10.3389/fnbot.2020.00026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e08cc165e4ea5706c3dea16118bb845bea47645\",\"title\":\"Intention-Related Natural Language Grounding via Object Affordance Detection and Intention Semantic Extraction\",\"url\":\"https://www.semanticscholar.org/paper/2e08cc165e4ea5706c3dea16118bb845bea47645\",\"venue\":\"Frontiers in Neurorobotics\",\"year\":2020},{\"arxivId\":\"1909.05770\",\"authors\":[{\"authorId\":\"3122743\",\"name\":\"F. Chu\"},{\"authorId\":\"19260257\",\"name\":\"Ruinian Xu\"},{\"authorId\":\"1736403\",\"name\":\"P. Vela\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1f17e6e2afbd36262a9d7bafd2b04fb457d36ae5\",\"title\":\"Detecting Robotic Affordances on Novel Objects with Regional Attention and Attributes\",\"url\":\"https://www.semanticscholar.org/paper/1f17e6e2afbd36262a9d7bafd2b04fb457d36ae5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.08644\",\"authors\":[{\"authorId\":\"3418004\",\"name\":\"Spyridon Thermos\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"},{\"authorId\":\"1423737852\",\"name\":\"Gerasimos Potamianos\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fd3cb7b995b66312bb42220eadde30d0ae130cd\",\"title\":\"A Deep Learning Approach to Object Affordance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8fd3cb7b995b66312bb42220eadde30d0ae130cd\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1904.03000\",\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"144306299\",\"name\":\"C. Grund\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00779\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7b36024652d99cdf1f75a1daa891729ef0aa0cb\",\"title\":\"What Object Should I Use? - Task Driven Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/e7b36024652d99cdf1f75a1daa891729ef0aa0cb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93687040\",\"name\":\"Xue Zhao\"},{\"authorId\":\"47184911\",\"name\":\"Y. Cao\"},{\"authorId\":\"144283695\",\"name\":\"Y. Kang\"}],\"doi\":\"10.1007/s00521-019-04336-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b2263c2a3993112bd14ea6344ad649436dbbaa1\",\"title\":\"Object affordance detection with relationship-aware network\",\"url\":\"https://www.semanticscholar.org/paper/8b2263c2a3993112bd14ea6344ad649436dbbaa1\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31641118\",\"name\":\"D. Hu\"},{\"authorId\":\"47067361\",\"name\":\"H. Zhong\"},{\"authorId\":\"145418879\",\"name\":\"Shuai Li\"},{\"authorId\":\"66564114\",\"name\":\"J. Tan\"},{\"authorId\":\"144410998\",\"name\":\"Q. He\"}],\"doi\":\"10.1016/j.buildenv.2020.107226\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e48e803cbf0b40964fe21c37533ffbd62b10a4c\",\"title\":\"Segmenting areas of potential contamination for adaptive robotic disinfection in built environments\",\"url\":\"https://www.semanticscholar.org/paper/4e48e803cbf0b40964fe21c37533ffbd62b10a4c\",\"venue\":\"Building and Environment\",\"year\":2020},{\"arxivId\":\"1909.05770\",\"authors\":[{\"authorId\":\"3122743\",\"name\":\"F. Chu\"},{\"authorId\":\"19260257\",\"name\":\"Ruinian Xu\"},{\"authorId\":\"1389424399\",\"name\":\"Chao Tang\"},{\"authorId\":\"1736403\",\"name\":\"P. Vela\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2fc3c29077f28775e2a5bf6db1e66f379aed0bd\",\"title\":\"Recognizing Object Affordances to Support Scene Reasoning for Manipulation Tasks.\",\"url\":\"https://www.semanticscholar.org/paper/f2fc3c29077f28775e2a5bf6db1e66f379aed0bd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.07572\",\"authors\":[{\"authorId\":\"65950129\",\"name\":\"H. Wu\"},{\"authorId\":\"153674583\",\"name\":\"D. Misra\"},{\"authorId\":\"30086906\",\"name\":\"Gregory S. Chirikjian\"}],\"doi\":\"10.1109/ICRA40945.2020.9197384\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ceef6cf0d7a821684375e68e4d979f7ba0850426\",\"title\":\"Is That a Chair? Imagining Affordances Using Simulations of an Articulated Human Body\",\"url\":\"https://www.semanticscholar.org/paper/ceef6cf0d7a821684375e68e4d979f7ba0850426\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1904.12907\",\"authors\":[{\"authorId\":\"1801517\",\"name\":\"H. Chen\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"39135743\",\"name\":\"A. Kuntz\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1682091\",\"name\":\"Ron Alterovitz\"}],\"doi\":\"10.1109/ICRA40945.2020.9197315\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a408f0de8de968782e590704c50bf61ccd03c75\",\"title\":\"Enabling Robots to Understand Incomplete Natural Language Instructions Using Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/8a408f0de8de968782e590704c50bf61ccd03c75\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1905.06784\",\"authors\":[{\"authorId\":\"7229001\",\"name\":\"Johann Sawatzky\"},{\"authorId\":\"35635012\",\"name\":\"D. Banerjee\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00549\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61c6936412354cfff657f54864f1b2ba84f4d15f\",\"title\":\"Harvesting Information from Captions for Weakly Supervised Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/61c6936412354cfff657f54864f1b2ba84f4d15f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2240300\",\"name\":\"Safoura Rezapour Lakani\"},{\"authorId\":\"1401895875\",\"name\":\"A. Rodr\\u00edguez-S\\u00e1nchez\"},{\"authorId\":\"1772389\",\"name\":\"J. Piater\"}],\"doi\":\"10.1007/S10514-018-9787-5\",\"intent\":[\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"4921c88b7567ddef338199b5282849d8c7ae2342\",\"title\":\"Towards affordance detection for robot manipulation using affordance for parts and parts for affordance\",\"url\":\"https://www.semanticscholar.org/paper/4921c88b7567ddef338199b5282849d8c7ae2342\",\"venue\":\"Auton. Robots\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51293455\",\"name\":\"Alexia Toumpa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"976c5e6104ae2c5aebd4f38f1f47033a0fdb9732\",\"title\":\"Relational Graph Representation Learning for Predicting Object Affordances\",\"url\":\"https://www.semanticscholar.org/paper/976c5e6104ae2c5aebd4f38f1f47033a0fdb9732\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3122743\",\"name\":\"F. Chu\"},{\"authorId\":\"19260257\",\"name\":\"Ruinian Xu\"},{\"authorId\":\"1736403\",\"name\":\"P. Vela\"}],\"doi\":\"10.1109/LRA.2019.2894439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e5bbd9719902a0b537691abd4a15dc4050d0ab2\",\"title\":\"Learning Affordance Segmentation for Real-World Robotic Manipulation via Synthetic Images\",\"url\":\"https://www.semanticscholar.org/paper/9e5bbd9719902a0b537691abd4a15dc4050d0ab2\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145532503\",\"name\":\"Marco Leo\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11024-6_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"title\":\"Deep Learning for Assistive Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2008.07817\",\"authors\":[{\"authorId\":\"2377286\",\"name\":\"Tomu Tahara\"},{\"authorId\":\"2931786\",\"name\":\"T. Seno\"},{\"authorId\":\"46705767\",\"name\":\"G. Narita\"},{\"authorId\":\"2195997\",\"name\":\"Tomoya Ishikawa\"}],\"doi\":\"10.1109/ISMAR-Adjunct51615.2020.00072\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4272bbc49b885aeb270cb34c74d0be77ea45f168\",\"title\":\"Retargetable AR: Context-aware Augmented Reality in Indoor Scenes based on 3D Scene Graph\",\"url\":\"https://www.semanticscholar.org/paper/4272bbc49b885aeb270cb34c74d0be77ea45f168\",\"venue\":\"2020 IEEE International Symposium on Mixed and Augmented Reality Adjunct (ISMAR-Adjunct)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"79993756\",\"name\":\"Haruya Ishikawa\"},{\"authorId\":\"1396355519\",\"name\":\"Shuichi Akizuki\"},{\"authorId\":\"2742021\",\"name\":\"Masaki Yamazaki\"},{\"authorId\":\"1491629206\",\"name\":\"Y. Taniguchi\"},{\"authorId\":\"1716469\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.1109/ICAR46387.2019.8981633\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a39171df86cfe305eeac8c5f2cb299a1ba3cd330\",\"title\":\"Task-oriented Function Detection Based on Operational Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a39171df86cfe305eeac8c5f2cb299a1ba3cd330\",\"venue\":\"2019 19th International Conference on Advanced Robotics (ICAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629426879\",\"name\":\"Kun Qian\"},{\"authorId\":\"80018757\",\"name\":\"X. Jing\"},{\"authorId\":\"8626806\",\"name\":\"Yanhui Duan\"},{\"authorId\":\"145465575\",\"name\":\"B. Zhou\"},{\"authorId\":\"144703383\",\"name\":\"F. Fang\"},{\"authorId\":\"144193174\",\"name\":\"Jing Xia\"},{\"authorId\":\"48577827\",\"name\":\"Xudong Ma\"}],\"doi\":\"10.1007/s10846-020-01202-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"34b392ce9918f9fe5c174651e6126db4ddff64da\",\"title\":\"Grasp Pose Detection with Affordance-based Task Constraint Learning in Single-view Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/34b392ce9918f9fe5c174651e6126db4ddff64da\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":\"2008.02321\",\"authors\":[{\"authorId\":\"1491625402\",\"name\":\"Hongtao Wu\"},{\"authorId\":\"1778107\",\"name\":\"G. Chirikjian\"}],\"doi\":\"10.1109/LRA.2020.3039943\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1f4034f241a72d4d0640902adaf75f5579abdae\",\"title\":\"Can I Pour Into It? Robot Imagining Open Containability Affordance of Previously Unseen Objects via Physical Simulations\",\"url\":\"https://www.semanticscholar.org/paper/c1f4034f241a72d4d0640902adaf75f5579abdae\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2021}],\"corpusId\":21087860,\"doi\":\"10.1109/CVPR.2017.552\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"e427c8d3c1b616d319c8b5f233e725d4ebfd9768\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145767346\",\"name\":\"Tucker Hermans\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5502dfe47ac26e60e0fb25fc0f810cae6f5173c0\",\"title\":\"Affordance Prediction via Learned Object Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5502dfe47ac26e60e0fb25fc0f810cae6f5173c0\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2133680\",\"name\":\"Hyun Oh Song\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"2125436\",\"name\":\"D. G\\u00f6hring\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TASE.2015.2396014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5898d86bfaa0e6ef61cad05d82992ea2baa7e1d0\",\"title\":\"Learning to Detect Visual Grasp Affordance\",\"url\":\"https://www.semanticscholar.org/paper/5898d86bfaa0e6ef61cad05d82992ea2baa7e1d0\",\"venue\":\"IEEE Transactions on Automation Science and Engineering\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2918740\",\"name\":\"A. Vezhnevets\"},{\"authorId\":\"1682548\",\"name\":\"J. Buhmann\"}],\"doi\":\"10.1109/CVPR.2010.5540060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79b090bb907b74c1c023f9191d63fb54a4be7acd\",\"title\":\"Towards weakly supervised semantic segmentation by means of multiple instance and multitask learning\",\"url\":\"https://www.semanticscholar.org/paper/79b090bb907b74c1c023f9191d63fb54a4be7acd\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756036\",\"name\":\"C. Rother\"},{\"authorId\":\"144653005\",\"name\":\"V. Kolmogorov\"},{\"authorId\":\"145162067\",\"name\":\"A. Blake\"}],\"doi\":\"10.1145/1186562.1015720\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f26d35d2e32934150cd27b030d4d769942126184\",\"title\":\"\\\"GrabCut\\\": interactive foreground extraction using iterated graph cuts\",\"url\":\"https://www.semanticscholar.org/paper/f26d35d2e32934150cd27b030d4d769942126184\",\"venue\":\"ACM Trans. Graph.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2011.5995327\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e56890e7300090691d770270ccb2ce96ab0cac9\",\"title\":\"What makes a chair a chair?\",\"url\":\"https://www.semanticscholar.org/paper/1e56890e7300090691d770270ccb2ce96ab0cac9\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47528349\",\"name\":\"W. Zhang\"},{\"authorId\":\"48486934\",\"name\":\"Sheng Zeng\"},{\"authorId\":\"2774612\",\"name\":\"Dequan Wang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/CVPR.2015.7298888\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afaa13a1e2e0a91c068f8482243e7ead1a48a474\",\"title\":\"Weakly supervised semantic segmentation for social images\",\"url\":\"https://www.semanticscholar.org/paper/afaa13a1e2e0a91c068f8482243e7ead1a48a474\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/ICCV.2011.6126281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23e568fcf0192e4ff5e6bed7507ee5b9e6c43598\",\"title\":\"Relative attributes\",\"url\":\"https://www.semanticscholar.org/paper/23e568fcf0192e4ff5e6bed7507ee5b9e6c43598\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2918740\",\"name\":\"A. Vezhnevets\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"1682548\",\"name\":\"J. Buhmann\"}],\"doi\":\"10.1109/ICCV.2011.6126299\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2932a9c686ede327f41069e17962d330a7a3ebf\",\"title\":\"Weakly supervised semantic segmentation with a multi-image model\",\"url\":\"https://www.semanticscholar.org/paper/c2932a9c686ede327f41069e17962d330a7a3ebf\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":\"1603.06098\",\"authors\":[{\"authorId\":\"144629422\",\"name\":\"Alexander Kolesnikov\"},{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"}],\"doi\":\"10.1007/978-3-319-46493-0_42\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"50002d139c1c94c896257f876ef567356b37a5f0\",\"title\":\"Seed, Expand and Constrain: Three Principles for Weakly-Supervised Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/50002d139c1c94c896257f876ef567356b37a5f0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"145585296\",\"name\":\"B. Kuipers\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/CVPR.2011.5995353\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7483fd4a7716f144c624b1bf1241280759727648\",\"title\":\"Recognizing human actions by attributes\",\"url\":\"https://www.semanticscholar.org/paper/7483fd4a7716f144c624b1bf1241280759727648\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"},{\"authorId\":\"1748758\",\"name\":\"H. Nickisch\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPRW.2009.5206594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"title\":\"Learning to detect unseen object classes by between-class attribute transfer\",\"url\":\"https://www.semanticscholar.org/paper/0566bf06a0368b518b8b474166f7b1dfef3f9283\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"461d2c494d0353834c54f13e74cc80cd56dbe365\",\"title\":\"Learning Visual Attributes\",\"url\":\"https://www.semanticscholar.org/paper/461d2c494d0353834c54f13e74cc80cd56dbe365\",\"venue\":\"NIPS\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"1757665\",\"name\":\"Y. Zhao\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2015.7298903\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3de78c766cfceaceca7ee3932304d2478f98107b\",\"title\":\"Understanding tools: Task-oriented object modeling, learning and recognition\",\"url\":\"https://www.semanticscholar.org/paper/3de78c766cfceaceca7ee3932304d2478f98107b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"18761726\",\"name\":\"D. Katz\"},{\"authorId\":\"1978198\",\"name\":\"A. Venkatraman\"},{\"authorId\":\"1705341\",\"name\":\"M. Kazemi\"},{\"authorId\":\"1756566\",\"name\":\"J. Bagnell\"},{\"authorId\":\"1722938\",\"name\":\"A. Stentz\"}],\"doi\":\"10.1007/s10514-014-9407-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"122d6fb21ccc7960d67af5f82de3a58ed7c83b68\",\"title\":\"Perceiving, learning, and exploiting object affordances for autonomous pile manipulation\",\"url\":\"https://www.semanticscholar.org/paper/122d6fb21ccc7960d67af5f82de3a58ed7c83b68\",\"venue\":\"Auton. Robots\",\"year\":2014},{\"arxivId\":\"1210.1207\",\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1996326\",\"name\":\"Rudhir Gupta\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1177/0278364913478446\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f\",\"title\":\"Learning human activities and object affordances from RGB-D videos\",\"url\":\"https://www.semanticscholar.org/paper/e45cd7ec5fb4a4d6c51e0a56feb7feba69e6066f\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32375492\",\"name\":\"Jia Deng\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2012.6248086\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb4f27d02b997025f9163b62c04ae7ef61802e3a\",\"title\":\"Hedging your bets: Optimizing accuracy-specificity trade-offs in large scale visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb4f27d02b997025f9163b62c04ae7ef61802e3a\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1506.03648\",\"authors\":[{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2015.209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74baf0185659ef0e1f8d412d3e906f6e73a6a873\",\"title\":\"Constrained Convolutional Neural Networks for Weakly Supervised Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/74baf0185659ef0e1f8d412d3e906f6e73a6a873\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/TPAMI.2015.2430335\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50a00d4fa9bf2e7bff37bc944ac48b403f5eb097\",\"title\":\"Anticipating Human Activities Using Object Affordances for Reactive Robotic Response\",\"url\":\"https://www.semanticscholar.org/paper/50a00d4fa9bf2e7bff37bc944ac48b403f5eb097\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50827772\",\"name\":\"G. Patterson\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2012.6247998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"add89dbbd15b82d8275d712f7f969f1b511f96fd\",\"title\":\"SUN attribute database: Discovering, annotating, and recognizing scene attributes\",\"url\":\"https://www.semanticscholar.org/paper/add89dbbd15b82d8275d712f7f969f1b511f96fd\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. S. Koppula\"},{\"authorId\":null,\"name\":\"A. Saxena\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Physically grounded spatiotemporal object affordances\",\"url\":\"\",\"venue\":\"In ECCV,\",\"year\":2014},{\"arxivId\":\"1505.00256\",\"authors\":[{\"authorId\":\"48239619\",\"name\":\"Chenyi Chen\"},{\"authorId\":\"2233674\",\"name\":\"Ari Seff\"},{\"authorId\":\"17434392\",\"name\":\"A. Kornhauser\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":\"10.1109/ICCV.2015.312\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6b93b766dff2066cebbc897c9ec7fbc44848ad7\",\"title\":\"DeepDriving: Learning Affordance for Direct Perception in Autonomous Driving\",\"url\":\"https://www.semanticscholar.org/paper/d6b93b766dff2066cebbc897c9ec7fbc44848ad7\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1606.00915\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/TPAMI.2017.2699184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cab372bc3824780cce20d9dd1c22d4df39ed081a\",\"title\":\"DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\",\"url\":\"https://www.semanticscholar.org/paper/cab372bc3824780cce20d9dd1c22d4df39ed081a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50204169\",\"name\":\"D. Kim\"},{\"authorId\":\"1732493\",\"name\":\"G. Sukhatme\"}],\"doi\":\"10.1109/ICRA.2014.6907679\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"beab662003317c1774f7ca0f21fe2d47a601c38d\",\"title\":\"Semantic labeling of 3D point clouds with object affordance for robot manipulation\",\"url\":\"https://www.semanticscholar.org/paper/beab662003317c1774f7ca0f21fe2d47a601c38d\",\"venue\":\"2014 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2918740\",\"name\":\"A. Vezhnevets\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"1682548\",\"name\":\"J. Buhmann\"}],\"doi\":\"10.1109/CVPR.2012.6247757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe18596c57b9100c20b8117e8f395c8340840a34\",\"title\":\"Weakly supervised structured output learning for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/fe18596c57b9100c20b8117e8f395c8340840a34\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1502.02734\",\"authors\":[{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"49312774\",\"name\":\"K. Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.203\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"da2f85e313160992b1a0e3db70eb02b58ec740c0\",\"title\":\"Weakly-and Semi-Supervised Learning of a Deep Convolutional Network for Semantic Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/da2f85e313160992b1a0e3db70eb02b58ec740c0\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50262304\",\"name\":\"Yun Jiang\"},{\"authorId\":\"1723948\",\"name\":\"H. Koppula\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1109/CVPR.2013.385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0c2e331fea01cc4a30608507a9f0693142169e5\",\"title\":\"Hallucinated Humans as the Hidden Context for Labeling 3D Scenes\",\"url\":\"https://www.semanticscholar.org/paper/c0c2e331fea01cc4a30608507a9f0693142169e5\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1301.3592\",\"authors\":[{\"authorId\":\"1966934\",\"name\":\"I. Lenz\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"1681995\",\"name\":\"A. Saxena\"}],\"doi\":\"10.1177/0278364914549607\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"260b98e772c4785fa06a5e8fe1c205eb05ec01e2\",\"title\":\"Deep learning for detecting robotic grasps\",\"url\":\"https://www.semanticscholar.org/paper/260b98e772c4785fa06a5e8fe1c205eb05ec01e2\",\"venue\":\"Int. J. Robotics Res.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40277674\",\"name\":\"C. Desai\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPRW.2013.141\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"506e76681d02dc3a3748e326fb57c4e4ab66778e\",\"title\":\"Predicting Functional Regions on Objects\",\"url\":\"https://www.semanticscholar.org/paper/506e76681d02dc3a3748e326fb57c4e4ab66778e\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-10605-2_27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea8fe33cc1596b2e493ddd87f22cd21f563664e8\",\"title\":\"Reasoning about Object Affordances in a Knowledge Base Representation\",\"url\":\"https://www.semanticscholar.org/paper/ea8fe33cc1596b2e493ddd87f22cd21f563664e8\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Gall H. Grabner\"},{\"authorId\":null,\"name\":\"L. Van Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Describing objects by their attributes Learning visual attributes\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1007/978-3-319-46493-0_12\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bb6f922cc6f94beacc93aead7af53e9bcb9fe3b4\",\"title\":\"A Multi-scale CNN for Affordance Segmentation in RGB Images\",\"url\":\"https://www.semanticscholar.org/paper/bb6f922cc6f94beacc93aead7af53e9bcb9fe3b4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"50218076\",\"name\":\"Z. Wang\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"}],\"doi\":\"10.1109/CVPR.2015.7299054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59537e0ea318265bee343fa97f1c0d073ccc09cc\",\"title\":\"Mining semantic affordances of visual object categories\",\"url\":\"https://www.semanticscholar.org/paper/59537e0ea318265bee343fa97f1c0d073ccc09cc\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743399\",\"name\":\"Claudio Castellini\"},{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"},{\"authorId\":\"3033284\",\"name\":\"B. Caputo\"}],\"doi\":\"10.1109/TAMD.2011.2106782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5586dc017702769c8fcc30bf04500dbb19d87570\",\"title\":\"Using Object Affordances to Improve Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5586dc017702769c8fcc30bf04500dbb19d87570\",\"venue\":\"IEEE Transactions on Autonomous Mental Development\",\"year\":2011},{\"arxivId\":\"1506.02106\",\"authors\":[{\"authorId\":\"1927362\",\"name\":\"Amy L. Bearman\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"143865718\",\"name\":\"V. Ferrari\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46478-7_34\",\"intent\":[\"methodology\",\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"d7da9bddc31fd6e851f6b06a894d613c3529d09c\",\"title\":\"What's the Point: Semantic Segmentation with Point Supervision\",\"url\":\"https://www.semanticscholar.org/paper/d7da9bddc31fd6e851f6b06a894d613c3529d09c\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"},{\"authorId\":\"143881914\",\"name\":\"J. Romero\"},{\"authorId\":\"1731490\",\"name\":\"D. Kragic\"}],\"doi\":\"10.1016/j.cviu.2010.08.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e60545a2db405c900d86b3c72068cb2e44fa252d\",\"title\":\"Visual object-action recognition: Inferring object affordances from human demonstration\",\"url\":\"https://www.semanticscholar.org/paper/e60545a2db405c900d86b3c72068cb2e44fa252d\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"3288214\",\"name\":\"Rao Muhammad Anwer\"},{\"authorId\":\"2820687\",\"name\":\"Joost van de Weijer\"},{\"authorId\":\"1749498\",\"name\":\"Andrew D. Bagdanov\"},{\"authorId\":\"144465192\",\"name\":\"M. Vanrell\"},{\"authorId\":\"144187725\",\"name\":\"Antonio M. L\\u00f3pez\"}],\"doi\":\"10.1109/CVPR.2012.6248068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bca0ca7bb642b747797c17a4899206116fb0b25\",\"title\":\"Color attributes for object detection\",\"url\":\"https://www.semanticscholar.org/paper/0bca0ca7bb642b747797c17a4899206116fb0b25\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1412.7062\",\"authors\":[{\"authorId\":\"34192119\",\"name\":\"Liang-Chieh Chen\"},{\"authorId\":\"2776496\",\"name\":\"G. Papandreou\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"39ad6c911f3351a3b390130a6e4265355b4d593b\",\"title\":\"Semantic Image Segmentation with Deep Convolutional Nets and Fully Connected CRFs\",\"url\":\"https://www.semanticscholar.org/paper/39ad6c911f3351a3b390130a6e4265355b4d593b\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49588480\",\"name\":\"A. Myers\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":\"10.1109/ICRA.2015.7139369\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0458cec30079a53a2b7726a14f5dd826b9b39bfd\",\"title\":\"Affordance detection of tool parts from geometric features\",\"url\":\"https://www.semanticscholar.org/paper/0458cec30079a53a2b7726a14f5dd826b9b39bfd\",\"venue\":\"2015 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"143812406\",\"name\":\"D. Walter\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298911\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caccc069e658ea397c9faf673e74c959c734ff53\",\"title\":\"Evaluation of output embeddings for fine-grained image classification\",\"url\":\"https://www.semanticscholar.org/paper/caccc069e658ea397c9faf673e74c959c734ff53\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"2831988\",\"name\":\"Ian Endres\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1109/cvprw.2009.5206772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6a8aef1bf134294482d8088f982d5643347d2ff\",\"title\":\"Describing objects by their attributes\",\"url\":\"https://www.semanticscholar.org/paper/c6a8aef1bf134294482d8088f982d5643347d2ff\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1609.00446\",\"authors\":[{\"authorId\":\"35441838\",\"name\":\"Fatemehsadat Saleh\"},{\"authorId\":\"3462343\",\"name\":\"M. Akbarian\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"}],\"doi\":\"10.1007/978-3-319-46484-8_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f33e88328dcd2f3aa4859cba96e14725e21d43c\",\"title\":\"Built-in Foreground/Background Prior for Weakly-Supervised Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/7f33e88328dcd2f3aa4859cba96e14725e21d43c\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1109/CVPR.2014.408\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"866ace76c906edc8d0e4ba9152204563c525f1c3\",\"title\":\"Tell Me What You See and I Will Show You Where It Is\",\"url\":\"https://www.semanticscholar.org/paper/866ace76c906edc8d0e4ba9152204563c525f1c3\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015}],\"title\":\"Weakly Supervised Affordance Detection\",\"topics\":[{\"topic\":\"Supervised learning\",\"topicId\":\"8357\",\"url\":\"https://www.semanticscholar.org/topic/8357\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Robotics\",\"topicId\":\"2759\",\"url\":\"https://www.semanticscholar.org/topic/2759\"},{\"topic\":\"Instance (computer science)\",\"topicId\":\"106358\",\"url\":\"https://www.semanticscholar.org/topic/106358\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Image segmentation\",\"topicId\":\"502\",\"url\":\"https://www.semanticscholar.org/topic/502\"},{\"topic\":\"Social affordance\",\"topicId\":\"2246751\",\"url\":\"https://www.semanticscholar.org/topic/2246751\"},{\"topic\":\"Abstraction layer\",\"topicId\":\"12858\",\"url\":\"https://www.semanticscholar.org/topic/12858\"},{\"topic\":\"Object detection\",\"topicId\":\"14349\",\"url\":\"https://www.semanticscholar.org/topic/14349\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Universal Media Disc\",\"topicId\":\"819942\",\"url\":\"https://www.semanticscholar.org/topic/819942\"}],\"url\":\"https://www.semanticscholar.org/paper/e427c8d3c1b616d319c8b5f233e725d4ebfd9768\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"