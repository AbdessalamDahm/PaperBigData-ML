"{\"abstract\":\"This paper revisits visual saliency prediction by evaluating the recent advancements in this field such as crowd-sourced mouse tracking-based databases and contextual annotations. We pursue a critical and quantitative approach towards some of the new challenges including the quality of mouse tracking versus eye tracking for model training and evaluation. We extend quantitative evaluation of models in order to incorporate contextual information by proposing an evaluation methodology that allows accounting for contextual factors such as text, faces, and object attributes. The proposed contextual evaluation scheme facilitates detailed analysis of models and helps identify their pros and cons. Through several experiments, we find that (1) mouse tracking data has lower inter-participant visual congruency and higher dispersion, compared to the eye tracking data, (2) mouse tracking data does not totally agree with eye tracking in general and in terms of different contextual regions in specific, and (3) mouse tracking data leads to acceptable results in training current existing models, and (4) mouse tracking data is less reliable for model selection and evaluation. The contextual evaluation also reveals that, among the studied models, there is no single model that performs best on all the tested annotations.\",\"arxivId\":\"1705.10546\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\",\"url\":\"https://www.semanticscholar.org/author/2319672\"},{\"authorId\":\"2253528\",\"name\":\"F. Ahmed\",\"url\":\"https://www.semanticscholar.org/author/2253528\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\",\"url\":\"https://www.semanticscholar.org/author/3177797\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\",\"url\":\"https://www.semanticscholar.org/author/1708642\"}],\"citationVelocity\":0,\"citations\":[{\"arxivId\":\"1910.02618\",\"authors\":[{\"authorId\":\"1387992157\",\"name\":\"Memoona Tahira\"},{\"authorId\":\"1387992189\",\"name\":\"Sobas Mehboob\"},{\"authorId\":\"31321802\",\"name\":\"A. U. Rahman\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/ACCESS.2019.2956840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b141eabff673e534644f68929d4efcad2c34c74\",\"title\":\"CrowdFix: An Eyetracking Dataset of Real Life Crowd Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b141eabff673e534644f68929d4efcad2c34c74\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1905.10693\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"51004202\",\"name\":\"A. Borji\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"title\":\"DAVE: A Deep Audio-Visual Embedding for Dynamic Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/827b68bdb1e38bb75e0db020ce764d25997b4c60\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"77a4096c59f51711469d4a2d8936fc5ef62ffdf8\",\"title\":\"BubbleView: a validation of a mouse-contingent interface for crowdsourcing image importance and tracking visual attention\",\"url\":\"https://www.semanticscholar.org/paper/77a4096c59f51711469d4a2d8936fc5ef62ffdf8\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2007.14419\",\"authors\":[{\"authorId\":\"94011352\",\"name\":\"S. Chen\"},{\"authorId\":\"1405907659\",\"name\":\"Ming Jiang\"},{\"authorId\":\"7788087\",\"name\":\"J. Yang\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1007/978-3-030-58452-8_6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"title\":\"AiR: Attention with Reasoning Capability\",\"url\":\"https://www.semanticscholar.org/paper/96150d2fdbb72e11882ad06b346d6e0d2e819d51\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1902.06634\",\"authors\":[{\"authorId\":\"144373348\",\"name\":\"A. Kroner\"},{\"authorId\":\"2581474\",\"name\":\"Mario Senden\"},{\"authorId\":\"1695114\",\"name\":\"K. Driessens\"},{\"authorId\":\"145960031\",\"name\":\"R. Goebel\"}],\"doi\":\"10.1016/j.neunet.2020.05.004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4fa6aac2143c713561603083a5f953c395ba2131\",\"title\":\"Contextual Encoder-Decoder Network for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4fa6aac2143c713561603083a5f953c395ba2131\",\"venue\":\"Neural Networks\",\"year\":2020},{\"arxivId\":\"1810.03716\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"title\":\"Saliency Prediction in the Deep Learning Era: An Empirical Investigation\",\"url\":\"https://www.semanticscholar.org/paper/4df34e0194faa27078832cb5078a2af6c9d0ea9b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144705452\",\"name\":\"S. Lopez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9546681a0d0088a66fa2c9b4338d4a65750c7db0\",\"title\":\"Content based images retrieval based on implicit gaze annotations. (Classification d'images \\u00e0 partir d'une annotation implicite par le regard)\",\"url\":\"https://www.semanticscholar.org/paper/9546681a0d0088a66fa2c9b4338d4a65750c7db0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"J. Laaksonen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"title\":\"Can Saliency Information Benefit Image Captioning Models?\",\"url\":\"https://www.semanticscholar.org/paper/204184e8a54c42bac589c19c3fa0c5d3d2c6009b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1704.07434\",\"authors\":[{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":\"10.1109/ICCV.2017.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"title\":\"Paying Attention to Descriptions Generated by Image Captioning Models\",\"url\":\"https://www.semanticscholar.org/paper/e4a11cc697c94fdda9eedbac7d83a865646bd4cc\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49144713\",\"name\":\"J. King\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"50720b049d8d6eb41d42a9ac6a70b8beda339e80\",\"title\":\"Beyond words : non-linguistic signals and the recovery of meaning\",\"url\":\"https://www.semanticscholar.org/paper/50720b049d8d6eb41d42a9ac6a70b8beda339e80\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"title\":\"Saliency Prediction in the Deep Learning Era: Successes, Limitations, and Future Challenges\",\"url\":\"https://www.semanticscholar.org/paper/3d173893dd3f22fd73acc16b94f0ea98469c9855\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0c001b2f619ee55114b29ded767c0295d88ce02\",\"title\":\"Computational perception for multi-modal document understanding\",\"url\":\"https://www.semanticscholar.org/paper/b0c001b2f619ee55114b29ded767c0295d88ce02\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.02048\",\"authors\":[{\"authorId\":\"51484264\",\"name\":\"Shivanthan A.C. Yohanandan\"},{\"authorId\":\"2483748\",\"name\":\"A. Dyer\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"},{\"authorId\":\"49077845\",\"name\":\"Andy Song\"}],\"doi\":\"10.1007/978-3-030-01231-1_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c07aed544463018e6afdb0cffa6ad1aa98fa6c98\",\"title\":\"Saliency Preservation in Low-Resolution Grayscale Images\",\"url\":\"https://www.semanticscholar.org/paper/c07aed544463018e6afdb0cffa6ad1aa98fa6c98\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2008.13745\",\"authors\":[{\"authorId\":\"46533364\",\"name\":\"Sandeep Mishra\"},{\"authorId\":\"49194775\",\"name\":\"Oindrila Saha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13fa6726305b77aa815b148469c495b6ceeed72b\",\"title\":\"RecSal : Deep Recursive Supervision for Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/13fa6726305b77aa815b148469c495b6ceeed72b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1740586345\",\"name\":\"Naoyuki Awano\"},{\"authorId\":\"1740584291\",\"name\":\"Y. Hayashi\"}],\"doi\":\"10.1007/s41095-020-0169-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"431dddd3de684ac0d208f46dceef3fe206444e1d\",\"title\":\"Psychological potential field and human eye fixation on binary line-drawing images: A comparative experimental study\",\"url\":\"https://www.semanticscholar.org/paper/431dddd3de684ac0d208f46dceef3fe206444e1d\",\"venue\":\"Computational Visual Media\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2426112\",\"name\":\"N. Kim\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fefcfdfe517e2e670bf345bc2a4fc2c52a9db35\",\"title\":\"BubbleView: An Interface for Crowdsourcing Image Importance Maps and Tracking Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/6fefcfdfe517e2e670bf345bc2a4fc2c52a9db35\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1702.05150\",\"authors\":[{\"authorId\":\"2201320\",\"name\":\"N. W. Kim\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2203252\",\"name\":\"M. Borkin\"},{\"authorId\":\"1770992\",\"name\":\"Krzysztof Z Gajos\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/3131275\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc2e0b445dc1825c634768517de557ba4bf22e81\",\"title\":\"BubbleView\",\"url\":\"https://www.semanticscholar.org/paper/fc2e0b445dc1825c634768517de557ba4bf22e81\",\"venue\":\"ACM Trans. Comput. Hum. Interact.\",\"year\":2017},{\"arxivId\":\"1903.02501\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/CVPR.2019.01045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"38410376deedfdfc32e53b7369b9ea2297fa521f\",\"title\":\"Understanding and Visualizing Deep Visual Saliency Models\",\"url\":\"https://www.semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.12476\",\"authors\":[{\"authorId\":\"46398397\",\"name\":\"Y. Liu\"},{\"authorId\":\"23999143\",\"name\":\"Deng-Ping Fan\"},{\"authorId\":\"16069700\",\"name\":\"Guang-Yu Nie\"},{\"authorId\":\"50812963\",\"name\":\"Xinyu Zhang\"},{\"authorId\":\"144376278\",\"name\":\"V. Petrosyan\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0db85e552e2e051a1a14987740bb8135bcc6a99\",\"title\":\"DNA: Deeply-supervised Nonlinear Aggregation for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/f0db85e552e2e051a1a14987740bb8135bcc6a99\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1414141968\",\"name\":\"Alexandre Milisavljevic\"},{\"authorId\":\"1414160762\",\"name\":\"Kevin Hamard\"},{\"authorId\":\"32096419\",\"name\":\"C. Petermann\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"1398674875\",\"name\":\"K. Dor\\u00e9-Mazars\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"}],\"doi\":\"10.5220/0006618800860093\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b62c795669b340324ac03184854833bd9082355\",\"title\":\"Eye and Mouse Coordination During Task: From Behaviour to Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1b62c795669b340324ac03184854833bd9082355\",\"venue\":\"VISIGRAPP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"1482544051\",\"name\":\"Pat Sukhum\"},{\"authorId\":\"2204049\",\"name\":\"Y. Zhang\"},{\"authorId\":\"51150125\",\"name\":\"Nanxuan Zhao\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"1618896088\",\"name\":\"Hong Kong\"}],\"doi\":\"10.1109/cvpr42600.2020.00453\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cffc481c86d46ca812eff85030f812588bb20b80\",\"title\":\"How Much Time Do You Have? Modeling Multi-Duration Saliency\",\"url\":\"https://www.semanticscholar.org/paper/cffc481c86d46ca812eff85030f812588bb20b80\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.02142\",\"authors\":[{\"authorId\":\"47119743\",\"name\":\"Xi Wang\"},{\"authorId\":\"1751554\",\"name\":\"Marc Alexa\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c138e780db882893631567329bfa6e031c967a0\",\"title\":\"Maps of Visual Importance\",\"url\":\"https://www.semanticscholar.org/paper/3c138e780db882893631567329bfa6e031c967a0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1810.05680\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"}],\"doi\":\"10.1007/978-1-4614-7320-6_100656-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"title\":\"Bottom-up Attention, Models of\",\"url\":\"https://www.semanticscholar.org/paper/554fecc6cc5d0ca43cdde2eee30a9f819fe49ae6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491124548\",\"name\":\"Yu Qiu\"},{\"authorId\":\"39798475\",\"name\":\"Yun Liu\"},{\"authorId\":\"9105875\",\"name\":\"Honbo Yang\"},{\"authorId\":\"150166903\",\"name\":\"J. Xu\"}],\"doi\":\"10.1016/j.neucom.2019.12.123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f65c1c542755942c47b31d25b1c5eb4433113f21\",\"title\":\"A simple saliency detection approach via automatic top-down feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/f65c1c542755942c47b31d25b1c5eb4433113f21\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1907.02336\",\"authors\":[{\"authorId\":\"150007878\",\"name\":\"Alexandre Bruckert\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143962642\",\"name\":\"Zhi Liu\"},{\"authorId\":\"1701717\",\"name\":\"M. Christie\"},{\"authorId\":\"1789744\",\"name\":\"O. Meur\"}],\"doi\":\"10.1016/j.neucom.2020.06.131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"title\":\"Deep Saliency Models : The Quest For The Loss Function\",\"url\":\"https://www.semanticscholar.org/paper/79c5b0d6dc39e7b0f59690520c17e33007a6b985\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134310797\",\"name\":\"Luis A. Leiva\"},{\"authorId\":\"46364507\",\"name\":\"Y. Xue\"},{\"authorId\":\"1977519209\",\"name\":\"Avya Bansal\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1977535062\",\"name\":\"Tu\\u00f0\\u00e7e K\\u00f6ro\\u00f0lu\"},{\"authorId\":\"1977523763\",\"name\":\"Jingzhou Du\"},{\"authorId\":\"3229795\",\"name\":\"N. Dayama\"},{\"authorId\":\"2663734\",\"name\":\"Antti Oulasvirta\"}],\"doi\":\"10.1145/3379503.3403557\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a74c3af655784448f353620b86a2cf69e937ed8\",\"title\":\"Understanding Visual Saliency in Mobile User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/7a74c3af655784448f353620b86a2cf69e937ed8\",\"venue\":\"MobileHCI\",\"year\":2020}],\"corpusId\":12317174,\"doi\":\"10.1109/CVPR.2017.673\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":0,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1946538\",\"name\":\"J. Xu\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-319-10584-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"title\":\"Saliency in Crowd\",\"url\":\"https://www.semanticscholar.org/paper/2042aed660796b14925db17c0a8b9fbdd7f3ebac\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1109/ICCV.2013.147\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"79c761353fe46544a758b284813dfa2908664db2\",\"title\":\"Saliency and Human Fixations: State-of-the-Art and Study of Comparison Metrics\",\"url\":\"https://www.semanticscholar.org/paper/79c761353fe46544a758b284813dfa2908664db2\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1742936\",\"name\":\"S. Ramanathan\"},{\"authorId\":\"2478739\",\"name\":\"H. Katti\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-642-15561-1_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"title\":\"An Eye Fixation Database for Saliency Detection in Images\",\"url\":\"https://www.semanticscholar.org/paper/ec80f411ef1c08eae586047d97977f9ef59dd6f5\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2997408\",\"name\":\"Matthias K\\u00fcmmerer\"},{\"authorId\":\"49737748\",\"name\":\"Thomas S. A. Wallis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1073/pnas.1510393112\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01058e4aabd61571da9e43a618834c90aabaf691\",\"title\":\"Information-theoretic model comparison unifies saliency metrics\",\"url\":\"https://www.semanticscholar.org/paper/01058e4aabd61571da9e43a618834c90aabaf691\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/ICCV.2013.118\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"title\":\"Analysis of Scores, Datasets, and Models in Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40527314\",\"name\":\"G. Kootstra\"},{\"authorId\":\"3464677\",\"name\":\"B. Boer\"},{\"authorId\":\"1799278\",\"name\":\"Lambert Schomaker\"}],\"doi\":\"10.1007/s12559-010-9089-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a96c05654aa68c050bc6fed82a95aa97891f418c\",\"title\":\"Predicting Eye Fixations on Complex Visual Stimuli Using Local Symmetry\",\"url\":\"https://www.semanticscholar.org/paper/a96c05654aa68c050bc6fed82a95aa97891f418c\",\"venue\":\"Cognitive Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944545\",\"name\":\"A. Toet\"}],\"doi\":\"10.1109/TPAMI.2011.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b26b2bf08f0b8d0b7f5ac904ff745c2778e860d5\",\"title\":\"Computational versus Psychophysical Bottom-Up Image Saliency: A Comparative Evaluation Study\",\"url\":\"https://www.semanticscholar.org/paper/b26b2bf08f0b8d0b7f5ac904ff745c2778e860d5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":\"1603.00845\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"2470219\",\"name\":\"E. Sayrol\"},{\"authorId\":\"3100480\",\"name\":\"Xavier Giro-i-Nieto\"},{\"authorId\":\"145470864\",\"name\":\"Kevin McGuinness\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"}],\"doi\":\"10.1109/CVPR.2016.71\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"title\":\"Shallow and Deep Convolutional Networks for Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9528e2e8c20517ab916f803c0371abb4f0ed488b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TIP.2012.2210727\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"title\":\"Quantitative Analysis of Human-Model Agreement in Visual Saliency Modeling: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/c0b60d02b2d59123f6b336fe2e287bdb02a2a776\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"title\":\"A Benchmark of Computational Models of Saliency to Predict Human Fixations\",\"url\":\"https://www.semanticscholar.org/paper/daef3fdc4190927c063ae94c12437cf82a6d1c20\",\"venue\":\"\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1007/978-3-319-46454-1_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"title\":\"Where Should Saliency Models Look Next?\",\"url\":\"https://www.semanticscholar.org/paper/a6d6d0de32939a5d15d2abfb04d131884d2cadc4\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144645142\",\"name\":\"M. Jiang\"},{\"authorId\":\"1961257\",\"name\":\"Shengsheng Huang\"},{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/CVPR.2015.7298710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c71db5d3546e22227662ee0f0ce586495ef18899\",\"title\":\"SALICON: Saliency in Context\",\"url\":\"https://www.semanticscholar.org/paper/c71db5d3546e22227662ee0f0ce586495ef18899\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145481070\",\"name\":\"D. Xu\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":\"10.1007/s11263-014-0730-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8811d5f62c9d6a116f2b4fa70bbd649bfa2cde9f\",\"title\":\"Guest Editor\\u2019s Introduction to the Special Issue on Domain Adaptation for Vision Applications\",\"url\":\"https://www.semanticscholar.org/paper/8811d5f62c9d6a116f2b4fa70bbd649bfa2cde9f\",\"venue\":\"International Journal of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143615083\",\"name\":\"R. J. Peters\"},{\"authorId\":\"4292093\",\"name\":\"A. Iyer\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/j.visres.2005.03.019\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"title\":\"Components of bottom-up gaze allocation in natural images\",\"url\":\"https://www.semanticscholar.org/paper/a7447f7e6197c0875a28686efdffe4ba4beb5460\",\"venue\":\"Vision Research\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32369256\",\"name\":\"T. Jost\"},{\"authorId\":\"3151890\",\"name\":\"N. Ouerhani\"},{\"authorId\":\"1939985\",\"name\":\"R. Wartburg\"},{\"authorId\":\"34663587\",\"name\":\"R. M\\u00fcri\"},{\"authorId\":\"152447339\",\"name\":\"Heinz Hugli\"}],\"doi\":\"10.1016/j.cviu.2004.10.009\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72fc3f2d4805c3d7b060d4a6aa19326d2ad37fbc\",\"title\":\"Assessing the contribution of color in visual attention\",\"url\":\"https://www.semanticscholar.org/paper/72fc3f2d4805c3d7b060d4a6aa19326d2ad37fbc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Jiang\"},{\"authorId\":null,\"name\":\"S. Huang\"},{\"authorId\":null,\"name\":\"J. Duan\"},{\"authorId\":null,\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Saliency in context\",\"url\":\"\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Bylinskii\"},{\"authorId\":null,\"name\":\"T. Judd\"},{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"L. Itti\"},{\"authorId\":null,\"name\":\"F. Durand\"},{\"authorId\":null,\"name\":\"A. Oliva\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Mit saliency benchmark\",\"url\":\"\",\"venue\":\"Online,\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Huang\"},{\"authorId\":null,\"name\":\"C. Shen\"},{\"authorId\":null,\"name\":\"X. Boix\"},{\"authorId\":null,\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Reduc - ing the semantic gap in saliency prediction by adapting deep neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":2007},{\"arxivId\":\"1604.03605\",\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"152627906\",\"name\":\"T. Judd\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"}],\"doi\":\"10.1109/TPAMI.2018.2815601\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"title\":\"What Do Different Evaluation Metrics Tell Us About Saliency Models?\",\"url\":\"https://www.semanticscholar.org/paper/bfdf3431ff5182b585b3b0c11fa8cbfc13a6bde4\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144114624\",\"name\":\"Juan Xu\"},{\"authorId\":\"144889908\",\"name\":\"M. Jiang\"},{\"authorId\":\"40440632\",\"name\":\"Shuo Wang\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"},{\"authorId\":\"51027614\",\"name\":\"Q. Zhao\"}],\"doi\":\"10.1167/14.1.28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"title\":\"Predicting human gaze beyond pixels.\",\"url\":\"https://www.semanticscholar.org/paper/709e8791193cc3fe9fef9ad983afcd2891e6c680\",\"venue\":\"Journal of vision\",\"year\":2014},{\"arxivId\":\"1505.03581\",\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"519feb1f3c23baea6960dfa204521f96a74b82bb\",\"title\":\"CAT2000: A Large Scale Fixation Dataset for Boosting Saliency Research\",\"url\":\"https://www.semanticscholar.org/paper/519feb1f3c23baea6960dfa204521f96a74b82bb\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"144902513\",\"name\":\"P. Baldi\"}],\"doi\":\"10.1016/j.visres.2008.09.007\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aebd8bab5cff769fed204dba35112e364a47e504\",\"title\":\"Bayesian surprise attracts human attention\",\"url\":\"https://www.semanticscholar.org/paper/aebd8bab5cff769fed204dba35112e364a47e504\",\"venue\":\"Vision Research\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2835449\",\"name\":\"B. Velichkovsky\"},{\"authorId\":\"47244151\",\"name\":\"M. Pomplun\"},{\"authorId\":\"112894916\",\"name\":\"Johannes Rieser\"}],\"doi\":\"10.1016/S0166-4115(96)80074-4\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44a0928dba02f22ee6702bfbde3e8cd62c0f002c\",\"title\":\"Attention and communication: Eye-movement-based research paradigms\",\"url\":\"https://www.semanticscholar.org/paper/44a0928dba02f22ee6702bfbde3e8cd62c0f002c\",\"venue\":\"\",\"year\":1996},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Borji\"},{\"authorId\":null,\"name\":\"L. Itti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\". State - ofthe - art in visual attention model\",\"url\":\"\",\"venue\":\"IEEE Trans . Pattern Anal . Mach . Intell .\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Itti . Stateoftheart in visual attention model\",\"url\":\"\",\"venue\":\"IEEE Trans . Pattern Anal . Mach . Intell .\",\"year\":null},{\"arxivId\":\"1406.2807\",\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR.2014.43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40e71c10edc2afc68d079546e8f4952cd52dc671\",\"title\":\"The Secrets of Salient Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/40e71c10edc2afc68d079546e8f4952cd52dc671\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1789744\",\"name\":\"O. Meur\"},{\"authorId\":\"1731790\",\"name\":\"T. Baccino\"}],\"doi\":\"10.3758/s13428-012-0226-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"title\":\"Methods for comparing scanpaths and saliency maps: strengths and weaknesses\",\"url\":\"https://www.semanticscholar.org/paper/a98a0079fef4c434e5e1f775ce47f8151149bf47\",\"venue\":\"Behavior research methods\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775672\",\"name\":\"Tilke Judd\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2009.5459462\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"title\":\"Learning to predict where humans look\",\"url\":\"https://www.semanticscholar.org/paper/c7614898de1cfee1a3a1c564f52c1e67879c29b3\",\"venue\":\"2009 IEEE 12th International Conference on Computer Vision\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4218304\",\"name\":\"C. Wloka\"},{\"authorId\":\"7382216\",\"name\":\"John Tstotsos\"}],\"doi\":\"10.1109/CVPR.2016.63\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2774dfff4416ffc51679aadd83905147e7dcb95e\",\"title\":\"Spatially Binned ROC: A Comprehensive Saliency Metric\",\"url\":\"https://www.semanticscholar.org/paper/2774dfff4416ffc51679aadd83905147e7dcb95e\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"1944405\",\"name\":\"M. Dorr\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"}],\"doi\":\"10.1109/CVPR.2014.358\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8693c32dff29e851760fa0b6af464050ffc383d6\",\"title\":\"Large-Scale Optimization of Hierarchical Features for Saliency Prediction in Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/8693c32dff29e851760fa0b6af464050ffc383d6\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1007/978-3-642-04697-1_32\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"title\":\"Decorrelation and Distinctiveness Provide with Human-Like Saliency\",\"url\":\"https://www.semanticscholar.org/paper/749e554382fd343fc7c81ec61dfc7cd2fd997745\",\"venue\":\"ACIVS\",\"year\":2009},{\"arxivId\":\"1606.00110\",\"authors\":[{\"authorId\":\"51285293\",\"name\":\"Christopher Thomas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36541e5dcc7964f80bd622e6212fa5808730fe95\",\"title\":\"OpenSalicon: An Open Source Implementation of the Salicon Saliency Model\",\"url\":\"https://www.semanticscholar.org/paper/36541e5dcc7964f80bd622e6212fa5808730fe95\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/TPAMI.2012.89\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"title\":\"State-of-the-Art in Visual Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/aa57b9bdb0736cbb38abf0a9d12047212c2a2425\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1504.06755\",\"authors\":[{\"authorId\":\"2366042\",\"name\":\"Pingmei Xu\"},{\"authorId\":\"1865091\",\"name\":\"Krista A. Ehinger\"},{\"authorId\":\"2507239\",\"name\":\"Y. Zhang\"},{\"authorId\":\"37737599\",\"name\":\"Adam Finkelstein\"},{\"authorId\":\"1697413\",\"name\":\"S. Kulkarni\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3433627f803953280b66ae1576d083fc9a68385a\",\"title\":\"TurkerGaze: Crowdsourcing Saliency with Webcam based Eye Tracking\",\"url\":\"https://www.semanticscholar.org/paper/3433627f803953280b66ae1576d083fc9a68385a\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"}],\"doi\":\"10.1167/13.4.11\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9896b03aeb17e06181c1842773fec4b742d7c51f\",\"title\":\"Visual saliency estimation by nonlinearly integrating features using region covariances.\",\"url\":\"https://www.semanticscholar.org/paper/9896b03aeb17e06181c1842773fec4b742d7c51f\",\"venue\":\"Journal of vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3326347\",\"name\":\"Z. Bylinskii\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"20212360\",\"name\":\"C. Bainbridge\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1016/j.visres.2015.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca0d27a1ecb3976cf57256af91d7543b2b3b61a5\",\"title\":\"Intrinsic and extrinsic effects on image memorability\",\"url\":\"https://www.semanticscholar.org/paper/ca0d27a1ecb3976cf57256af91d7543b2b3b61a5\",\"venue\":\"Vision Research\",\"year\":2015}],\"title\":\"Saliency Revisited: Analysis of Mouse Movements Versus Fixations\",\"topics\":[{\"topic\":\"Mouse tracking\",\"topicId\":\"465948\",\"url\":\"https://www.semanticscholar.org/topic/465948\"},{\"topic\":\"Eye tracking\",\"topicId\":\"7621\",\"url\":\"https://www.semanticscholar.org/topic/7621\"},{\"topic\":\"Model selection\",\"topicId\":\"23168\",\"url\":\"https://www.semanticscholar.org/topic/23168\"},{\"topic\":\"Crowdsourcing\",\"topicId\":\"85\",\"url\":\"https://www.semanticscholar.org/topic/85\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Database\",\"topicId\":\"1307\",\"url\":\"https://www.semanticscholar.org/topic/1307\"},{\"topic\":\"Lazy evaluation\",\"topicId\":\"19479\",\"url\":\"https://www.semanticscholar.org/topic/19479\"}],\"url\":\"https://www.semanticscholar.org/paper/42f4aeff8219942153104c3ed5d9d661663d0cd3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"