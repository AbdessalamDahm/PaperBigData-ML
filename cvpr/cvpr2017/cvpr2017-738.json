"{\"abstract\":\"Recent research endeavors have shown the potential of using feed-forward convolutional neural networks to accomplish fast style transfer for images. In this work, we take one step further to explore the possibility of exploiting a feed-forward network to perform style transfer for videos and simultaneously maintain temporal consistency among stylized video frames. Our feed-forward network is trained by enforcing the outputs of consecutive frames to be both well stylized and temporally consistent. More specifically, a hybrid loss is proposed to capitalize on the content information of input frames, the style information of a given style image, and the temporal information of consecutive frames. To calculate the temporal loss during the training stage, a novel two-frame synergic training mechanism is proposed. Compared with directly applying an existing image style transfer method to videos, our proposed method employs the trained network to yield temporally consistent stylized videos which are much more visually pleasant. In contrast to the prior video style transfer method which relies on time-consuming optimization on the fly, our method runs in real time while generating competitive visual results.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\",\"url\":\"https://www.semanticscholar.org/author/7192666\"},{\"authorId\":null,\"name\":\"Hao Wang\",\"url\":null},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\",\"url\":\"https://www.semanticscholar.org/author/145909988\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\",\"url\":\"https://www.semanticscholar.org/author/145698310\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\",\"url\":\"https://www.semanticscholar.org/author/2093119\"},{\"authorId\":\"35130187\",\"name\":\"Xiaolong Zhu\",\"url\":\"https://www.semanticscholar.org/author/35130187\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\",\"url\":\"https://www.semanticscholar.org/author/1911510\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\",\"url\":\"https://www.semanticscholar.org/author/46641573\"}],\"citationVelocity\":27,\"citations\":[{\"arxivId\":\"1905.02949\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6671a8f5c5ed906501f9c441fda64942a682800\",\"title\":\"Deep Blind Video Decaptioning by Temporal Aggregation and Recurrence\",\"url\":\"https://www.semanticscholar.org/paper/d6671a8f5c5ed906501f9c441fda64942a682800\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3062171\",\"name\":\"Maria Silvia Ito\"},{\"authorId\":\"145643264\",\"name\":\"E. Izquierdo\"}],\"doi\":\"10.1109/VCIP47243.2019.8966057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebc08da8c71a9442d8faeb38d4a2553e4507c0cd\",\"title\":\"A Dataset and Evaluation Framework for Deep Learning Based Video Stabilization Systems\",\"url\":\"https://www.semanticscholar.org/paper/ebc08da8c71a9442d8faeb38d4a2553e4507c0cd\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64926d883d0c48d20835a97679340391bcdceb23\",\"title\":\"Animating Your Life: Real-Time Video-to-Animation Translation\",\"url\":\"https://www.semanticscholar.org/paper/64926d883d0c48d20835a97679340391bcdceb23\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648821\",\"name\":\"Chaehan So\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f870ddb310e7f39a38acc8eff8f0d0b52392f1ec\",\"title\":\"Aesthetic Preferences of Neural Style Transfer-Generated Portrait Images: An Exploratory Study with the Two-Alternative-Forced-Choice Task\",\"url\":\"https://www.semanticscholar.org/paper/f870ddb310e7f39a38acc8eff8f0d0b52392f1ec\",\"venue\":\"ICCC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3207491\",\"name\":\"Chunpeng Wu\"},{\"authorId\":\"144877709\",\"name\":\"Bin Ni\"},{\"authorId\":\"1688858\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207095\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39afc0ef66f9853e897bd2c67685190f4ae27689\",\"title\":\"Redistributing and Re-Stylizing Features for Training a Fast Photorealistic Stylizer\",\"url\":\"https://www.semanticscholar.org/paper/39afc0ef66f9853e897bd2c67685190f4ae27689\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1802.00265\",\"authors\":[{\"authorId\":\"40098310\",\"name\":\"Jingwei Zhang\"},{\"authorId\":\"70308463\",\"name\":\"L. Tai\"},{\"authorId\":\"144199717\",\"name\":\"Peng Yun\"},{\"authorId\":\"10797184\",\"name\":\"Yufeng Xiong\"},{\"authorId\":\"145111967\",\"name\":\"M. Liu\"},{\"authorId\":\"145581493\",\"name\":\"J. Boedecker\"},{\"authorId\":\"1725973\",\"name\":\"W. Burgard\"}],\"doi\":\"10.1109/LRA.2019.2894216\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dc80d94a55f96eed71358b08f72427e214400538\",\"title\":\"VR-Goggles for Robots: Real-to-Sim Domain Adaptation for Visual Control\",\"url\":\"https://www.semanticscholar.org/paper/dc80d94a55f96eed71358b08f72427e214400538\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151494072\",\"name\":\"Qiyang Zhang\"},{\"authorId\":\"9450088\",\"name\":\"Shengwu Xiong\"},{\"authorId\":\"151502209\",\"name\":\"Anna Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"978102c3cb3dadadef7868f3e0a46bc40b7b5f30\",\"title\":\"Neural Style Transfer for Characters Synthesis via Stack Network\",\"url\":\"https://www.semanticscholar.org/paper/978102c3cb3dadadef7868f3e0a46bc40b7b5f30\",\"venue\":\"Aust. J. Intell. Inf. Process. Syst.\",\"year\":2019},{\"arxivId\":\"1802.09985\",\"authors\":[{\"authorId\":\"1382034111\",\"name\":\"Xinyu Gong\"},{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"36066491\",\"name\":\"Tong Zhang\"}],\"doi\":\"10.1007/978-3-030-01228-1_4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13a3df27e8a1bfef2d858cdeede3674784f15f2d\",\"title\":\"Neural Stereoscopic Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/13a3df27e8a1bfef2d858cdeede3674784f15f2d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2004.10634\",\"authors\":[{\"authorId\":\"1423723631\",\"name\":\"Hao Su\"},{\"authorId\":\"143929163\",\"name\":\"J. Niu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"},{\"authorId\":\"47422334\",\"name\":\"Q. Li\"},{\"authorId\":\"9424770\",\"name\":\"Jiahe Cui\"},{\"authorId\":\"144768030\",\"name\":\"Ji Wan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8c42e3f550f0b52227d0c482e9a2023fac8522c\",\"title\":\"Unpaired Photo-to-manga Translation Based on The Methodology of Manga Drawing\",\"url\":\"https://www.semanticscholar.org/paper/c8c42e3f550f0b52227d0c482e9a2023fac8522c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3407321\",\"name\":\"Falong Shen\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"39159696\",\"name\":\"Gang Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00841\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd68e6f668670f7651345670961a5f8eddeddd97\",\"title\":\"Neural Style Transfer via Meta Networks\",\"url\":\"https://www.semanticscholar.org/paper/bd68e6f668670f7651345670961a5f8eddeddd97\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491487338\",\"name\":\"Yongchuan Tang\"},{\"authorId\":\"2557640\",\"name\":\"Jiang-jie Huang\"},{\"authorId\":\"145684975\",\"name\":\"M. Yao\"},{\"authorId\":\"145316287\",\"name\":\"J. Wei\"},{\"authorId\":\"39634635\",\"name\":\"Wei Li\"},{\"authorId\":\"1491507742\",\"name\":\"Yong-xing He\"},{\"authorId\":\"49969791\",\"name\":\"Z. Li\"}],\"doi\":\"10.1631/FITEE.1900398\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"042c105bba950bec9d48e0357106a1c01655a073\",\"title\":\"A review of design intelligence: progress, problems, and challenges\",\"url\":\"https://www.semanticscholar.org/paper/042c105bba950bec9d48e0357106a1c01655a073\",\"venue\":\"Frontiers of Information Technology & Electronic Engineering\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"153737613\",\"name\":\"Yongming Tang\"}],\"doi\":\"10.1109/CIRSYSSIM.2019.8935613\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7cc3f3304063f4c0f9e1ac9049a98e36e6bad8d8\",\"title\":\"Development of Real-Time Style Transfer for Video System\",\"url\":\"https://www.semanticscholar.org/paper/7cc3f3304063f4c0f9e1ac9049a98e36e6bad8d8\",\"venue\":\"2019 3rd International Conference on Circuits, System and Simulation (ICCSS)\",\"year\":2019},{\"arxivId\":\"2003.08407\",\"authors\":[{\"authorId\":\"51152314\",\"name\":\"Dmytro Kotovenko\"},{\"authorId\":\"3451249\",\"name\":\"A. Sanakoyeu\"},{\"authorId\":\"144933398\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"114651332\",\"name\":\"Sabine Lang\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1109/CVPR.2019.01027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84d3064593ded6838300adc366e485fa54839d3f\",\"title\":\"A Content Transformation Block for Image Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/84d3064593ded6838300adc366e485fa54839d3f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.02085\",\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"46606038\",\"name\":\"Jimmy Ren\"},{\"authorId\":\"120809851\",\"name\":\"Jianbo Liu\"},{\"authorId\":\"41021816\",\"name\":\"J. Zhang\"},{\"authorId\":\"10775732\",\"name\":\"Xiaohao Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e46069c69b5a71f9cda748036b95438803c29a21\",\"title\":\"Learning Selfie-Friendly Abstraction from Artistic Style Images\",\"url\":\"https://www.semanticscholar.org/paper/e46069c69b5a71f9cda748036b95438803c29a21\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":\"1807.07930\",\"authors\":[{\"authorId\":\"1405198343\",\"name\":\"Eduardo P\\u00e9rez-Pellitero\"},{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"},{\"authorId\":\"1707625\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"85c7985cd6f2be1840f1ec885bf5ef8479b21324\",\"title\":\"Photorealistic Video Super Resolution\",\"url\":\"https://www.semanticscholar.org/paper/85c7985cd6f2be1840f1ec885bf5ef8479b21324\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Hanggao Xin\"},{\"authorId\":null,\"name\":\"Shaokun Zheng\"},{\"authorId\":null,\"name\":\"Kun Xu\"},{\"authorId\":\"79692150\",\"name\":\"Lingqi Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dc3fc9c4683d527b8504f92ef8d3ee560bcec07b\",\"title\":\"Lightweight Bilateral Convolutional Neural Networks for Real-time Diffuse Global Illumination\",\"url\":\"https://www.semanticscholar.org/paper/dc3fc9c4683d527b8504f92ef8d3ee560bcec07b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276048\",\"name\":\"Jiayue Li\"},{\"authorId\":\"47598731\",\"name\":\"Q. Wang\"},{\"authorId\":\"50829126\",\"name\":\"Hong Chen\"},{\"authorId\":\"98073932\",\"name\":\"Jiahui An\"},{\"authorId\":\"15822241\",\"name\":\"S. Li\"}],\"doi\":\"10.1088/1742-6596/1651/1/012156\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95e8c6b7df0e03906880c330f7065529b4e08eeb\",\"title\":\"A Review on Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/95e8c6b7df0e03906880c330f7065529b4e08eeb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.00449\",\"authors\":[{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-01267-0_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"title\":\"Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/098b68fe34dba7fc4e206035ae2d149944bbca8f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1906.00668\",\"authors\":[{\"authorId\":\"145871213\",\"name\":\"M. Lu\"},{\"authorId\":\"46430948\",\"name\":\"Hao Zhao\"},{\"authorId\":\"2021251\",\"name\":\"A. Yao\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"143979431\",\"name\":\"Feng Xu\"},{\"authorId\":\"28354921\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652113e09c8430aade40b6969f01a18f0e781e00\",\"title\":\"A Closed-Form Solution to Universal Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/652113e09c8430aade40b6969f01a18f0e781e00\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737466611\",\"name\":\"Songhua Liu\"},{\"authorId\":\"46477223\",\"name\":\"H. Wu\"},{\"authorId\":\"1993702394\",\"name\":\"Shoutong Luo\"},{\"authorId\":\"30370666\",\"name\":\"Z. Sun\"}],\"doi\":\"10.1145/3394171.3413526\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2a0f99ded70f351306522c387fca0065d0a92f2\",\"title\":\"Stable Video Style Transfer Based on Partial Convolution with Depth-Aware Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a2a0f99ded70f351306522c387fca0065d0a92f2\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.05471\",\"authors\":[{\"authorId\":\"49543209\",\"name\":\"Xiaochang Liu\"},{\"authorId\":\"3601471\",\"name\":\"Xuan-yi Li\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"103234888\",\"name\":\"P. Hall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"391d560a30884a77cf8d0edc1e17bfc20dc9d706\",\"title\":\"Geometric Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/391d560a30884a77cf8d0edc1e17bfc20dc9d706\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48514551\",\"name\":\"Yuanhao Li\"},{\"authorId\":\"4207450\",\"name\":\"Tianying Zhang\"},{\"authorId\":null,\"name\":\"Xu Han\"},{\"authorId\":\"35906216\",\"name\":\"Yali Qi\"}],\"doi\":\"10.1109/ICSAI.2018.8599501\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1ba91bfcbf1974632bab83c973511acb8be412f\",\"title\":\"Image Style Transfer in Deep Learning Networks\",\"url\":\"https://www.semanticscholar.org/paper/d1ba91bfcbf1974632bab83c973511acb8be412f\",\"venue\":\"2018 5th International Conference on Systems and Informatics (ICSAI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65798502\",\"name\":\"Zheyang Xiong\"},{\"authorId\":\"66092785\",\"name\":\"C. Weber\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.1109/ICICIP.2018.8606694\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"24d0b9afd3a7b18b4045e21620b619b32364bf16\",\"title\":\"Frame Difference-Based Real-Time Video Stylization in Video Calls\",\"url\":\"https://www.semanticscholar.org/paper/24d0b9afd3a7b18b4045e21620b619b32364bf16\",\"venue\":\"2018 Ninth International Conference on Intelligent Control and Information Processing (ICICIP)\",\"year\":2018},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2743695\",\"name\":\"Haitian Zheng\"},{\"authorId\":\"145585312\",\"name\":\"Haofu Liao\"},{\"authorId\":\"152875073\",\"name\":\"Lele Chen\"},{\"authorId\":\"2014900616\",\"name\":\"Wei Xiong\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58568-6_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66d695c001e245ef943a41e159a2761b727b589a\",\"title\":\"Example-Guided Image Synthesis Using Masked Spatial-Channel Attention and Self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/66d695c001e245ef943a41e159a2761b727b589a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543200\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"2795697\",\"name\":\"Jingfan Guo\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"47033372\",\"name\":\"L. Huang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3240508.3241402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1e2d97d26aaaa35995a36a8cf5ff143f9609940\",\"title\":\"HeterStyle: A Heterogeneous Video Style Transfer Application\",\"url\":\"https://www.semanticscholar.org/paper/a1e2d97d26aaaa35995a36a8cf5ff143f9609940\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2006.09029\",\"authors\":[{\"authorId\":\"1733982458\",\"name\":\"Jie An\"},{\"authorId\":\"46230717\",\"name\":\"T. Li\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":null,\"name\":\"Xuan Wang\"},{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"1685259\",\"name\":\"Jinwen Ma\"},{\"authorId\":\"40584023\",\"name\":\"Wei Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6df5b4353cce3b6ba7eb6bf85907acf6c72473ff\",\"title\":\"Real-time Universal Style Transfer on High-resolution Images via Zero-channel Pruning\",\"url\":\"https://www.semanticscholar.org/paper/6df5b4353cce3b6ba7eb6bf85907acf6c72473ff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443774270\",\"name\":\"Hongfei Sun\"},{\"authorId\":\"1443774544\",\"name\":\"Kun Zhang\"},{\"authorId\":\"1443787177\",\"name\":\"Rongbo Fan\"},{\"authorId\":\"1443783816\",\"name\":\"Wenjun Xiong\"},{\"authorId\":\"1443799277\",\"name\":\"Jianhua Yang\"}],\"doi\":\"10.1109/ACCESS.2019.2953923\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43b236adc7b2147ca9d449623e2582ba8302c2c9\",\"title\":\"Stepwise Local Synthetic Pseudo-CT Imaging Based on Anatomical Semantic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/43b236adc7b2147ca9d449623e2582ba8302c2c9\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453600148\",\"name\":\"Dingkun Yan\"},{\"authorId\":\"50198403\",\"name\":\"Y. Sheng\"},{\"authorId\":\"46701588\",\"name\":\"Xiaoyang Mao\"}],\"doi\":\"10.1111/cgf.13819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f733bf19d66e880d5684884441adda085cf088e\",\"title\":\"Pencil Drawing Video Rendering Using Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5f733bf19d66e880d5684884441adda085cf088e\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":\"1802.10591\",\"authors\":[{\"authorId\":\"49025576\",\"name\":\"Dongdong Chen\"},{\"authorId\":\"145347148\",\"name\":\"L. Yuan\"},{\"authorId\":null,\"name\":\"Jing Liao\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/CVPR.2018.00696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa4568b0c02d63eea0ddc7faea9ce069f6d6285a\",\"title\":\"Stereoscopic Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fa4568b0c02d63eea0ddc7faea9ce069f6d6285a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"47538816\",\"name\":\"Jingang Zhang\"},{\"authorId\":\"2291143\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"3182192\",\"name\":\"Gaofeng Meng\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TIP.2018.2876178\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"281b8c4e4ed6a9237a5b65a6f95048882340253c\",\"title\":\"Deep Video Dehazing With Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/281b8c4e4ed6a9237a5b65a6f95048882340253c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2010.10056\",\"authors\":[{\"authorId\":\"3302135\",\"name\":\"Xide Xia\"},{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"1399908730\",\"name\":\"Zheng Sun\"},{\"authorId\":\"1999258759\",\"name\":\"Abby Chang\"},{\"authorId\":\"1692670\",\"name\":\"B. Kulis\"},{\"authorId\":\"50763062\",\"name\":\"Jiawen Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1dcaad6826c65beea06801ab9973c49d0cb1830b\",\"title\":\"Real-time Localized Photorealistic Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1dcaad6826c65beea06801ab9973c49d0cb1830b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.08091\",\"authors\":[{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"35912331\",\"name\":\"G. Yang\"},{\"authorId\":\"40370556\",\"name\":\"Jin-Kun Lin\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"144918349\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa2d3996a0095eef90f8e0fcec7ab3b4ba63cd3f\",\"title\":\"Deep Online Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/fa2d3996a0095eef90f8e0fcec7ab3b4ba63cd3f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.12043\",\"authors\":[{\"authorId\":\"50383147\",\"name\":\"M. Doukas\"},{\"authorId\":\"1790503\",\"name\":\"V. Sharmanska\"},{\"authorId\":\"1776444\",\"name\":\"S. Zafeiriou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"title\":\"Video-to-Video Translation for Visual Speech Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/a2f7e7adbbd2326c7ac7cbb67fa43214108bb372\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b109686dae36cefec1867ce18c52ab10ec602a7\",\"title\":\"Real-time Coherent Video Style Transfer Final Report\",\"url\":\"https://www.semanticscholar.org/paper/3b109686dae36cefec1867ce18c52ab10ec602a7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ad368a4f1e6585b4abe355ed4c7f68601ab162a\",\"title\":\"Temporally Coherent GANs for Video Super-Resolution (TecoGAN)\",\"url\":\"https://www.semanticscholar.org/paper/1ad368a4f1e6585b4abe355ed4c7f68601ab162a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3317083\",\"name\":\"Gao Chang\"},{\"authorId\":null,\"name\":\"Gu Derun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd4f5257f1087cfe1f996c0d1bf3dfd104d70642\",\"title\":\"COMP 4801 Final Year Project Interim Report Project title : Real-time Coherent Video Style Transfer Group member :\",\"url\":\"https://www.semanticscholar.org/paper/cd4f5257f1087cfe1f996c0d1bf3dfd104d70642\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.12362\",\"authors\":[{\"authorId\":\"2743695\",\"name\":\"Haitian Zheng\"},{\"authorId\":\"145585312\",\"name\":\"Haofu Liao\"},{\"authorId\":\"152875073\",\"name\":\"Lele Chen\"},{\"authorId\":\"1380008340\",\"name\":\"Wei Xiong\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d509bd1e3c5149801b0158f7fe9176d77b379719\",\"title\":\"Example-Guided Scene Image Synthesis using Masked Spatial-Channel Attention and Patch-Based Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/d509bd1e3c5149801b0158f7fe9176d77b379719\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.08079\",\"authors\":[{\"authorId\":\"2967089\",\"name\":\"Duc Minh Vo\"},{\"authorId\":\"47344473\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1007/s00138-020-01086-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e11183b888201f8182a708768f51edf58f1cd44\",\"title\":\"Two-stream FCNs to balance content and style for style transfer\",\"url\":\"https://www.semanticscholar.org/paper/4e11183b888201f8182a708768f51edf58f1cd44\",\"venue\":\"Machine Vision and Applications\",\"year\":2020},{\"arxivId\":\"1807.01197\",\"authors\":[{\"authorId\":\"144525219\",\"name\":\"Chang Gao\"},{\"authorId\":\"51115672\",\"name\":\"Derun Gu\"},{\"authorId\":\"6767755\",\"name\":\"Fangjun Zhang\"},{\"authorId\":\"1841911\",\"name\":\"Y. Yu\"}],\"doi\":\"10.1007/978-3-030-20876-9_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"767eeaa478b835b7276523a6b1d018b21f0f83c1\",\"title\":\"ReCoNet: Real-time Coherent Video Style Transfer Network\",\"url\":\"https://www.semanticscholar.org/paper/767eeaa478b835b7276523a6b1d018b21f0f83c1\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1940676570\",\"name\":\"Hanggao Xin\"},{\"authorId\":\"1939127415\",\"name\":\"Shaokun Zheng\"},{\"authorId\":\"151485141\",\"name\":\"Kun Xu\"},{\"authorId\":\"79692150\",\"name\":\"Lingqi Yan\"}],\"doi\":\"10.1109/TVCG.2020.3023129\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44062a5d6bdbd6c8272d5abbc89904a4dc2a1d77\",\"title\":\"Lightweight Bilateral Convolutional Neural Networks for Interactive Single-bounce Diffuse Indirect Illumination.\",\"url\":\"https://www.semanticscholar.org/paper/44062a5d6bdbd6c8272d5abbc89904a4dc2a1d77\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2020},{\"arxivId\":\"1903.06571\",\"authors\":[{\"authorId\":\"2350325\",\"name\":\"D. Lee\"},{\"authorId\":\"1945962\",\"name\":\"T. Pfister\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.01030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bcad284af2a484d508a695dc534b0363812b1993\",\"title\":\"Inserting Videos Into Videos\",\"url\":\"https://www.semanticscholar.org/paper/bcad284af2a484d508a695dc534b0363812b1993\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.10852\",\"authors\":[{\"authorId\":\"2648821\",\"name\":\"Chaehan So\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9abc8649967ade79c9ce565c20716f42de62855\",\"title\":\"A Pragmatic AI Approach to Creating Artistic Visual Variations by Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/f9abc8649967ade79c9ce565c20716f42de62855\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/CVPR42600.2020.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103664864\",\"name\":\"Chia-chi Cheng\"},{\"authorId\":\"40846050\",\"name\":\"Hungyu Chen\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":\"10.1109/cvpr42600.2020.00568\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"title\":\"Time Flies: Animating a Still Image With Time-Lapse Video As Reference\",\"url\":\"https://www.semanticscholar.org/paper/4daed2840a1fd1cada30cdee782c1d0c1f72f577\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471431417\",\"name\":\"K. H. Shibly\"},{\"authorId\":\"1642244249\",\"name\":\"S. Rahman\"},{\"authorId\":\"46669310\",\"name\":\"S. K. Dey\"},{\"authorId\":\"2007454613\",\"name\":\"Shahadat Hossain Shamim\"}],\"doi\":\"10.1007/978-3-030-52856-0_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"73b42e0267c758ee1466a3b4eb81ac9af84505dc\",\"title\":\"Advanced Artistic Style Transfer Using Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/73b42e0267c758ee1466a3b4eb81ac9af84505dc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.09393\",\"authors\":[{\"authorId\":\"32464128\",\"name\":\"Mengyu Chu\"},{\"authorId\":\"9071227\",\"name\":\"You Xie\"},{\"authorId\":\"2208679\",\"name\":\"Jonas Mayer\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1786445\",\"name\":\"N. Th\\u00fcrey\"}],\"doi\":\"10.1145/3386569.3392457\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e52488ea7e83bf44aaa94c86b337a66f326c5e6\",\"title\":\"Learning temporal coherence via self-supervision for GAN-based video generation\",\"url\":\"https://www.semanticscholar.org/paper/9e52488ea7e83bf44aaa94c86b337a66f326c5e6\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2004.15021\",\"authors\":[{\"authorId\":\"46612306\",\"name\":\"Xuan Luo\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"},{\"authorId\":\"40353974\",\"name\":\"K. Matzen\"},{\"authorId\":\"2891193\",\"name\":\"Johannes Kopf\"}],\"doi\":\"10.1145/3386569.3392377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43550e50110d6a500ac827e30f54f391aae5f8c7\",\"title\":\"Consistent video depth estimation\",\"url\":\"https://www.semanticscholar.org/paper/43550e50110d6a500ac827e30f54f391aae5f8c7\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"1809.01372\",\"authors\":[{\"authorId\":\"7192666\",\"name\":\"H. Huang\"},{\"authorId\":\"2063358\",\"name\":\"Senzhe Xu\"},{\"authorId\":\"15996814\",\"name\":\"Junxiong Cai\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144110127\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TIP.2019.2925550\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14d1e3c6405ed22d30d88d577275233cca89d3a0\",\"title\":\"Temporally Coherent Video Harmonization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/14d1e3c6405ed22d30d88d577275233cca89d3a0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2003.00706\",\"authors\":[{\"authorId\":\"6603147\",\"name\":\"P. Kohli\"},{\"authorId\":\"84260591\",\"name\":\"S. Gunaseelan\"},{\"authorId\":\"144412329\",\"name\":\"J. Orozco\"},{\"authorId\":\"50051908\",\"name\":\"Y. Hua\"},{\"authorId\":\"34494617\",\"name\":\"Edward Li\"},{\"authorId\":\"1515554561\",\"name\":\"Nicolas Dahlquist\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"003af88548f11f4f3f0e29924a41ea2f1ca6574c\",\"title\":\"GPU-Accelerated Mobile Multi-view Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/003af88548f11f4f3f0e29924a41ea2f1ca6574c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05146\",\"authors\":[{\"authorId\":\"1736061\",\"name\":\"Xinghao Chen\"},{\"authorId\":\"46868350\",\"name\":\"Yiman Zhang\"},{\"authorId\":null,\"name\":\"Yunhe Wang\"},{\"authorId\":\"144305248\",\"name\":\"H. Shu\"},{\"authorId\":\"1691522\",\"name\":\"Chunjing Xu\"},{\"authorId\":\"145371957\",\"name\":\"Chang Xu\"}],\"doi\":\"10.1007/978-3-030-58539-6_37\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b1b2e2fc090ad383dc2923aaa16445f4c847ca9\",\"title\":\"Optical Flow Distillation: Towards Efficient and Stable Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/3b1b2e2fc090ad383dc2923aaa16445f4c847ca9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405198343\",\"name\":\"Eduardo P\\u00e9rez-Pellitero\"},{\"authorId\":\"2283034\",\"name\":\"Mehdi S. M. Sajjadi\"},{\"authorId\":\"144566512\",\"name\":\"M. Hirsch\"},{\"authorId\":\"46224364\",\"name\":\"B. Sch\\u00f6lkopf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b268dfb22e80862d84855ada1a1d85fee5d7d20\",\"title\":\"Perceptual Video Super Resolution with Enhanced Temporal Consistency.\",\"url\":\"https://www.semanticscholar.org/paper/8b268dfb22e80862d84855ada1a1d85fee5d7d20\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710978\",\"name\":\"D. Schnieders\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"70b70f07c400ea0d845b95e5e4d0c70881cf8ee1\",\"title\":\"Real-time Coherent Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/70b70f07c400ea0d845b95e5e4d0c70881cf8ee1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.07815\",\"authors\":[{\"authorId\":\"1423723631\",\"name\":\"Hao Su\"},{\"authorId\":\"143929163\",\"name\":\"J. Niu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"},{\"authorId\":\"47422334\",\"name\":\"Q. Li\"},{\"authorId\":\"144768030\",\"name\":\"Ji Wan\"},{\"authorId\":\"2285442\",\"name\":\"M. Xu\"},{\"authorId\":\"48419180\",\"name\":\"Tao Ren\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"912c9b3c3f3913b4ace558512d1c1925b89c4023\",\"title\":\"An End-to-end Method for Producing Scanning-robust Stylized QR Codes\",\"url\":\"https://www.semanticscholar.org/paper/912c9b3c3f3913b4ace558512d1c1925b89c4023\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.03264\",\"authors\":[{\"authorId\":\"2485552\",\"name\":\"B. Li\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"1696179\",\"name\":\"Y. Zhou\"},{\"authorId\":\"47059263\",\"name\":\"L. Zhang\"},{\"authorId\":\"1724841\",\"name\":\"R. Chu\"}],\"doi\":\"10.1007/978-3-030-20890-5_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7b446c0f2bc5012951248564f1a6db472fbf801\",\"title\":\"Neural Abstract Style Transfer for Chinese Traditional Painting\",\"url\":\"https://www.semanticscholar.org/paper/e7b446c0f2bc5012951248564f1a6db472fbf801\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380767265\",\"name\":\"Fabian Stahl\"},{\"authorId\":\"88162050\",\"name\":\"M. Meyer\"},{\"authorId\":\"2092849\",\"name\":\"U. Schwanecke\"}],\"doi\":\"10.1109/ISPA.2019.8868438\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1f768d52450c6fca536d9fb6814c471752c7e77\",\"title\":\"IST - Style Transfer with Instance Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e1f768d52450c6fca536d9fb6814c471752c7e77\",\"venue\":\"2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48243939\",\"name\":\"L. Sun\"},{\"authorId\":\"120125782\",\"name\":\"P. Chen\"},{\"authorId\":\"144455676\",\"name\":\"W. Xiang\"},{\"authorId\":\"46915168\",\"name\":\"P. Chen\"},{\"authorId\":\"1491488644\",\"name\":\"W. Gao\"},{\"authorId\":\"1710905\",\"name\":\"Kejun Zhang\"}],\"doi\":\"10.1631/FITEE.1900386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0883f112a100eff302c48f6a92f7e90e95bba25e\",\"title\":\"SmartPaint: a co-creative drawing system based on generative adversarial networks\",\"url\":\"https://www.semanticscholar.org/paper/0883f112a100eff302c48f6a92f7e90e95bba25e\",\"venue\":\"Frontiers of Information Technology & Electronic Engineering\",\"year\":2019},{\"arxivId\":\"1708.04538\",\"authors\":[{\"authorId\":\"37003547\",\"name\":\"M. Ruder\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/s11263-018-1089-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8270cfa97e74ee341938685a66a9b75cb65abc17\",\"title\":\"Artistic Style Transfer for Videos and Spherical Images\",\"url\":\"https://www.semanticscholar.org/paper/8270cfa97e74ee341938685a66a9b75cb65abc17\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"2005.03415\",\"authors\":[{\"authorId\":\"50261693\",\"name\":\"Wojciech Dudzik\"},{\"authorId\":\"1680029766\",\"name\":\"Damian Kosowski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfc6b978902a45901bb8ae53e9425a685c053325\",\"title\":\"Kunster - AR Art Video Maker - Real time video neural style transfer on mobile devices\",\"url\":\"https://www.semanticscholar.org/paper/bfc6b978902a45901bb8ae53e9425a685c053325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.11139\",\"authors\":[{\"authorId\":\"67100504\",\"name\":\"C. Thomas\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-20893-6_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c748531e6277098d3135a4c552a74def520c9c9a\",\"title\":\"Artistic Object Recognition by Unsupervised Style Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/c748531e6277098d3135a4c552a74def520c9c9a\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1712.03534\",\"authors\":[{\"authorId\":\"2017906\",\"name\":\"Wissam J. Baddar\"},{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"2909533\",\"name\":\"S. Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"title\":\"Dynamics Transfer GAN: Generating Video by Transferring Arbitrary Temporal Dynamics from a Source Video to a Single Target Image\",\"url\":\"https://www.semanticscholar.org/paper/deb0cbced8a5986e0771209cf786b0ebdedc119d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2005.11630\",\"authors\":[{\"authorId\":\"100895685\",\"name\":\"Ang Li\"},{\"authorId\":\"3207491\",\"name\":\"Chunpeng Wu\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"},{\"authorId\":\"144877709\",\"name\":\"Bin Ni\"}],\"doi\":\"10.1145/3397166.3409140\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c493a367d34f862a11d65a5e6d859535b3cfbb02\",\"title\":\"MVStylizer: an efficient edge-assisted video photorealistic style transfer system for mobile phones\",\"url\":\"https://www.semanticscholar.org/paper/c493a367d34f862a11d65a5e6d859535b3cfbb02\",\"venue\":\"MobiHoc\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824743\",\"name\":\"W. Wang\"},{\"authorId\":\"1474586426\",\"name\":\"Shuai Yang\"},{\"authorId\":\"1697982\",\"name\":\"Jizheng Xu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/TIP.2020.3024018\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"afdbaa80e2dc9b98017dd990615ed5982768caaa\",\"title\":\"Consistent Video Style Transfer via Relaxation and Regularization\",\"url\":\"https://www.semanticscholar.org/paper/afdbaa80e2dc9b98017dd990615ed5982768caaa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"1994473526\",\"name\":\"Jialu Chen\"}],\"doi\":\"10.1145/3394171.3413872\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f01bf32bcc38bf5e4d81f820494a7f8d7dbb2a3c\",\"title\":\"Preserving Global and Local Temporal Consistency for Arbitrary Video Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/f01bf32bcc38bf5e4d81f820494a7f8d7dbb2a3c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1908.09514\",\"authors\":[{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350937\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"61a8b0469f6eec9b6b78433c40a2a3e197f8787e\",\"title\":\"Mocycle-GAN: Unpaired Video-to-Video Translation\",\"url\":\"https://www.semanticscholar.org/paper/61a8b0469f6eec9b6b78433c40a2a3e197f8787e\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71283867\",\"name\":\"Hui-Huang Zhao\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"144891983\",\"name\":\"Yu-Kun Lai\"},{\"authorId\":\"150218492\",\"name\":\"Mugang Lin\"},{\"authorId\":\"150270467\",\"name\":\"Qinyun Liu\"}],\"doi\":\"10.1109/ACCESS.2019.2922554\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f56512d458cd92a487700eca5b8fdea1d7af8d0a\",\"title\":\"Image Neural Style Transfer With Global and Local Optimization Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f56512d458cd92a487700eca5b8fdea1d7af8d0a\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2012.01642\",\"authors\":[{\"authorId\":\"84267967\",\"name\":\"C. Thomas\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e6fd339e247604e00f4ca40de44438a96835471\",\"title\":\"Learning to Transfer Visual Effects from Videos to Images\",\"url\":\"https://www.semanticscholar.org/paper/0e6fd339e247604e00f4ca40de44438a96835471\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.06106\",\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"7284555\",\"name\":\"Arnav Kumar Jain\"},{\"authorId\":\"1758797\",\"name\":\"Prabir Kumar Biswas\"},{\"authorId\":\"144240262\",\"name\":\"Pabitra Mitra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc685d7a68b078db350ad128bc3eacf7d84adab4\",\"title\":\"Improving Consistency and Correctness of Sequence Inpainting using Semantically Guided Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/fc685d7a68b078db350ad128bc3eacf7d84adab4\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2004.03142\",\"authors\":[{\"authorId\":\"48116039\",\"name\":\"Jian Ren\"},{\"authorId\":\"1752091\",\"name\":\"M. Chai\"},{\"authorId\":\"145582202\",\"name\":\"S. Tulyakov\"},{\"authorId\":\"49479171\",\"name\":\"Chen Fang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"47988297\",\"name\":\"Jianchao Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce3f80b0e1f43aa6fa94288710da0a5bdae2a9d\",\"title\":\"Human Motion Transfer from Poses in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/dce3f80b0e1f43aa6fa94288710da0a5bdae2a9d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11838\",\"authors\":[{\"authorId\":\"2121274\",\"name\":\"Chenyang Lei\"},{\"authorId\":\"152136086\",\"name\":\"Yazhou Xing\"},{\"authorId\":\"1559427865\",\"name\":\"Qifeng Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6716353f880fd7cb2be30d82c3f1dcd3abaebd98\",\"title\":\"Blind Video Temporal Consistency via Deep Video Prior\",\"url\":\"https://www.semanticscholar.org/paper/6716353f880fd7cb2be30d82c3f1dcd3abaebd98\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2002.11220\",\"authors\":[{\"authorId\":\"144856828\",\"name\":\"D. Hart\"},{\"authorId\":\"1507591373\",\"name\":\"Jessica Greenland\"},{\"authorId\":\"2877830\",\"name\":\"B. Morse\"}],\"doi\":\"10.1109/WACV45572.2020.9093478\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815e8f65aa086544c53fceba5b8e1cb00e78a439\",\"title\":\"Style Transfer for Light Field Photography\",\"url\":\"https://www.semanticscholar.org/paper/815e8f65aa086544c53fceba5b8e1cb00e78a439\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2769710\",\"name\":\"Xingxing Wei\"},{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"3078190\",\"name\":\"Sitong Feng\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"}],\"doi\":\"10.1145/3240508.3240708\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7183b44d2085f940c7521b21a670f61ef2c11625\",\"title\":\"Video-to-Video Translation with Global Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/7183b44d2085f940c7521b21a670f61ef2c11625\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47943365\",\"name\":\"Y. Zhou\"},{\"authorId\":\"12186775\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"143663465\",\"name\":\"Huimin Lu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3394171.3413788\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"92ff7b00d7782c483ddc239e107acb034cda5536\",\"title\":\"Temporal Denoising Mask Synthesis Network for Learning Blind Video Temporal Consistency\",\"url\":\"https://www.semanticscholar.org/paper/92ff7b00d7782c483ddc239e107acb034cda5536\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1705.04058\",\"authors\":[{\"authorId\":\"9633703\",\"name\":\"Yongcheng Jing\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"7357719\",\"name\":\"Zunlei Feng\"},{\"authorId\":\"3764313\",\"name\":\"Jingwen Ye\"},{\"authorId\":\"144646841\",\"name\":\"M. Song\"}],\"doi\":\"10.1109/TVCG.2019.2921336\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0760764dc573b519f76d5a79531d49af333c67a\",\"title\":\"Neural Style Transfer: A Review\",\"url\":\"https://www.semanticscholar.org/paper/b0760764dc573b519f76d5a79531d49af333c67a\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":\"2007.01466\",\"authors\":[{\"authorId\":\"145331259\",\"name\":\"Meng Cao\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"},{\"authorId\":\"3705643\",\"name\":\"H. Wang\"},{\"authorId\":null,\"name\":\"Xuan Wang\"},{\"authorId\":\"152148573\",\"name\":\"L. Shen\"},{\"authorId\":\"94385031\",\"name\":\"Sd Wang\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff13757be71ff9deae63150b5572158eb394aa9c\",\"title\":\"Task-agnostic Temporally Consistent Facial Video Editing\",\"url\":\"https://www.semanticscholar.org/paper/ff13757be71ff9deae63150b5572158eb394aa9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.10520\",\"authors\":[{\"authorId\":\"108145101\",\"name\":\"Yuanbin Fu\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"33465926\",\"name\":\"Xiaojie Guo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"809c69d4a2ebd5f9f8ec39949ffcbe4a9914e599\",\"title\":\"EDIT: Exemplar-Domain Aware Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/809c69d4a2ebd5f9f8ec39949ffcbe4a9914e599\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145037972\",\"name\":\"Gilles Puy\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/CVPR.2019.00917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02ea20eb2597ce4ffd6026713a1f804e9436f4d\",\"title\":\"A Flexible Convolutional Solver for Fast Style Transfers\",\"url\":\"https://www.semanticscholar.org/paper/f02ea20eb2597ce4ffd6026713a1f804e9436f4d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1474573850\",\"name\":\"Valentin Vasiliu\"},{\"authorId\":\"2660931\",\"name\":\"G\\u00e1bor S\\u00f6r\\u00f6s\"}],\"doi\":\"10.1109/ISMAR.2019.00-25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b8c4612d3cd8744d8518cac45fc7dfacf3b72e8b\",\"title\":\"Coherent Rendering of Virtual Smile Previews with Fast Neural Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b8c4612d3cd8744d8518cac45fc7dfacf3b72e8b\",\"venue\":\"2019 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46874123\",\"name\":\"W. Gao\"},{\"authorId\":\"50024008\",\"name\":\"Y. Li\"},{\"authorId\":\"2926974\",\"name\":\"Yihang Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/WACV45572.2020.9093420\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0da4bd286cac8a8aa8577867ff87cab279ca964f\",\"title\":\"Fast Video Multi-Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/0da4bd286cac8a8aa8577867ff87cab279ca964f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2007.03532\",\"authors\":[{\"authorId\":\"2598159\",\"name\":\"Luca Stornaiuolo\"},{\"authorId\":\"9716460\",\"name\":\"Nima Dehmamy\"},{\"authorId\":\"102115549\",\"name\":\"Albert-L\\u00e1szl\\u00f3 Barab\\u00e1si\"},{\"authorId\":\"49711231\",\"name\":\"M. Martino\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a79daa9660d7011db057626e61607ca76d2d302\",\"title\":\"3D Topology Transformation with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/4a79daa9660d7011db057626e61607ca76d2d302\",\"venue\":\"ICCC\",\"year\":2020},{\"arxivId\":\"2004.10024\",\"authors\":[{\"authorId\":\"2743695\",\"name\":\"Haitian Zheng\"},{\"authorId\":\"145585312\",\"name\":\"Haofu Liao\"},{\"authorId\":\"152875073\",\"name\":\"Lele Chen\"},{\"authorId\":\"4969405\",\"name\":\"W. Xiong\"},{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45fd600e5adca237c3c645b6691499234f19fd94\",\"title\":\"Example-Guided Image Synthesis across Arbitrary Scenes using Masked Spatial-Channel Attention and Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/45fd600e5adca237c3c645b6691499234f19fd94\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.01314\",\"authors\":[{\"authorId\":\"47446564\",\"name\":\"Miao Wang\"},{\"authorId\":\"35912331\",\"name\":\"G. Yang\"},{\"authorId\":\"47370189\",\"name\":\"R. Li\"},{\"authorId\":\"134652625\",\"name\":\"Run-Ze Liang\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"134579041\",\"name\":\"P. M. Hall\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/CVPR.2019.00159\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d6ff2398d85edb0cea8a24df01784696f7c40ca\",\"title\":\"Example-Guided Style-Consistent Image Synthesis From Semantic Labeling\",\"url\":\"https://www.semanticscholar.org/paper/0d6ff2398d85edb0cea8a24df01784696f7c40ca\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39765532\",\"name\":\"Miao Wang\"},{\"authorId\":\"35912331\",\"name\":\"G. Yang\"},{\"authorId\":\"40370556\",\"name\":\"Jin-Kun Lin\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"144918349\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1109/TIP.2018.2884280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c96faae7bb03d3222c57d56c9383c0cfdb6590fa\",\"title\":\"Deep Online Video Stabilization With Multi-Grid Warping Transformation Learning\",\"url\":\"https://www.semanticscholar.org/paper/c96faae7bb03d3222c57d56c9383c0cfdb6590fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019}],\"corpusId\":28280219,\"doi\":\"10.1109/CVPR.2017.745\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"33431659\",\"name\":\"Genzhi Ye\"},{\"authorId\":\"34601098\",\"name\":\"Elena Garces\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\"},{\"authorId\":\"144954808\",\"name\":\"Q. Dai\"},{\"authorId\":\"143876232\",\"name\":\"D. Gutierrez\"}],\"doi\":\"10.1145/2601097.2601135\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76abf690192e6b6219d7691d0925894c433ddf2a\",\"title\":\"Intrinsic video and applications\",\"url\":\"https://www.semanticscholar.org/paper/76abf690192e6b6219d7691d0925894c433ddf2a\",\"venue\":\"ACM Trans. Graph.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1607.08022\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"63de0ad39d807f0c256f851428f211e8d5fcd3bb\",\"title\":\"Instance Normalization: The Missing Ingredient for Fast Stylization\",\"url\":\"https://www.semanticscholar.org/paper/63de0ad39d807f0c256f851428f211e8d5fcd3bb\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33031081\",\"name\":\"N. Kong\"},{\"authorId\":\"2871555\",\"name\":\"P. Gehler\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-319-10605-2_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a00224d82adfbd8bc4bf9f0cd43dd005472de0a4\",\"title\":\"Intrinsic Video\",\"url\":\"https://www.semanticscholar.org/paper/a00224d82adfbd8bc4bf9f0cd43dd005472de0a4\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"10251113\",\"name\":\"C. Jacobs\"},{\"authorId\":\"145709776\",\"name\":\"N. Oliver\"},{\"authorId\":\"143800609\",\"name\":\"Brian Curless\"},{\"authorId\":\"1745260\",\"name\":\"D. Salesin\"}],\"doi\":\"10.1145/383259.383295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923562d216386a88947d40da310d94bbb1376a41\",\"title\":\"Image analogies\",\"url\":\"https://www.semanticscholar.org/paper/923562d216386a88947d40da310d94bbb1376a41\",\"venue\":\"SIGGRAPH '01\",\"year\":2001},{\"arxivId\":\"1610.07629\",\"authors\":[{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99542f614d7e4146cad17196e76c997e57a69e4d\",\"title\":\"A Learned Representation For Artistic Style\",\"url\":\"https://www.semanticscholar.org/paper/99542f614d7e4146cad17196e76c997e57a69e4d\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":\"1412.0035\",\"authors\":[{\"authorId\":\"32694028\",\"name\":\"Aravindh Mahendran\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/CVPR.2015.7299155\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d790c8fae40357d24813d085fa74a436847fb49\",\"title\":\"Understanding deep image representations by inverting them\",\"url\":\"https://www.semanticscholar.org/paper/4d790c8fae40357d24813d085fa74a436847fb49\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1410.0759\",\"authors\":[{\"authorId\":\"3003738\",\"name\":\"Sharan Chetlur\"},{\"authorId\":\"2266717\",\"name\":\"C. Woolley\"},{\"authorId\":\"2101730\",\"name\":\"Philippe Vandermersch\"},{\"authorId\":\"145678733\",\"name\":\"J. Cohen\"},{\"authorId\":\"145927488\",\"name\":\"John Tran\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31c36d445367ba204244bb74893c5654e31c3869\",\"title\":\"cuDNN: Efficient Primitives for Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/31c36d445367ba204244bb74893c5654e31c3869\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1602.07188\",\"authors\":[{\"authorId\":\"27482628\",\"name\":\"Yaroslav Nikulin\"},{\"authorId\":\"39068839\",\"name\":\"Roman Novak\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0bb95c67cb5b96d4197a6b36cdeb7321d6c4d16d\",\"title\":\"Exploring the Neural Algorithm of Artistic Style\",\"url\":\"https://www.semanticscholar.org/paper/0bb95c67cb5b96d4197a6b36cdeb7321d6c4d16d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2615673\",\"name\":\"Peter Litwinowicz\"}],\"doi\":\"10.1145/258734.258893\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40064ed4de01e9c66a5d827463850816d1f681cc\",\"title\":\"Processing images and video for an impressionist effect\",\"url\":\"https://www.semanticscholar.org/paper/40064ed4de01e9c66a5d827463850816d1f681cc\",\"venue\":\"SIGGRAPH '97\",\"year\":1997},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3449b65008b27f6e60a73d80c1fd990f0481126b\",\"title\":\"Torch7: A Matlab-like Environment for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/3449b65008b27f6e60a73d80c1fd990f0481126b\",\"venue\":\"NIPS 2011\",\"year\":2011},{\"arxivId\":\"1603.08511\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46487-9_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"title\":\"Colorful Image Colorization\",\"url\":\"https://www.semanticscholar.org/paper/8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033193\",\"name\":\"Manuel Lang\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"2769987\",\"name\":\"T. Aydin\"},{\"authorId\":\"50663593\",\"name\":\"A. Smolic\"},{\"authorId\":\"144877481\",\"name\":\"M. Gross\"}],\"doi\":\"10.1145/2185520.2185530\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"923a2a63ee027c5ab6dbc0af6848022dc867be03\",\"title\":\"Practical temporal consistency for image-based graphics applications\",\"url\":\"https://www.semanticscholar.org/paper/923a2a63ee027c5ab6dbc0af6848022dc867be03\",\"venue\":\"TOGS\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1145/2897824.2925974\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec3453b0892ed8bf0531ffb5370c0159597eec11\",\"title\":\"Let there be color!\",\"url\":\"https://www.semanticscholar.org/paper/ec3453b0892ed8bf0531ffb5370c0159597eec11\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722900\",\"name\":\"Nicolas Bonneel\"},{\"authorId\":null,\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"143758236\",\"name\":\"H. Pfister\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7d6fa129323b6e159f340d68eea7dd6595704cc\",\"title\":\"Example-Based Video Color Grading Supplemental material \\u2013 Curvature estimation\",\"url\":\"https://www.semanticscholar.org/paper/f7d6fa129323b6e159f340d68eea7dd6595704cc\",\"venue\":\"\",\"year\":2013},{\"arxivId\":\"1601.04589\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1109/CVPR.2016.272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526\",\"title\":\"Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"My. Com. Artisto\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Videvo free footage\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722900\",\"name\":\"Nicolas Bonneel\"},{\"authorId\":\"1854493\",\"name\":\"J. Tompkin\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"}],\"doi\":\"10.1145/2816795.2818107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cf676a6227d3b1388802991ef4f44ffaf98bec1\",\"title\":\"Blind video temporal consistency\",\"url\":\"https://www.semanticscholar.org/paper/5cf676a6227d3b1388802991ef4f44ffaf98bec1\",\"venue\":\"ACM Trans. Graph.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8386151\",\"name\":\"H. Lee\"},{\"authorId\":\"5686109\",\"name\":\"Sanghyun Seo\"},{\"authorId\":\"2044658\",\"name\":\"Seungtaek Ryoo\"},{\"authorId\":\"7457154\",\"name\":\"Kyunghyun Yoon\"}],\"doi\":\"10.1145/1809939.1809945\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"649b3d0c965389fc6bde969b4c533c8fa9d9837a\",\"title\":\"Directional texture transfer\",\"url\":\"https://www.semanticscholar.org/paper/649b3d0c965389fc6bde969b4c533c8fa9d9837a\",\"venue\":\"NPAR\",\"year\":2010},{\"arxivId\":\"1603.03417\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"47606739\",\"name\":\"V. Lebedev\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"title\":\"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images\",\"url\":\"https://www.semanticscholar.org/paper/ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1604.08610\",\"authors\":[{\"authorId\":\"37003547\",\"name\":\"M. Ruder\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-45886-1_3\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5181a9c3c9a36672a3890321dcc0faf4f8ea658e\",\"title\":\"Artistic Style Transfer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/5181a9c3c9a36672a3890321dcc0faf4f8ea658e\",\"venue\":\"GCPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2015.7298965\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"title\":\"Fully convolutional networks for semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/9201bf6f8222c2335913002e13fbac640fc0f4ec\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"Real-Time Neural Style Transfer for Videos\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Feedforward neural network\",\"topicId\":\"153499\",\"url\":\"https://www.semanticscholar.org/topic/153499\"},{\"topic\":\"Synergy\",\"topicId\":\"16865\",\"url\":\"https://www.semanticscholar.org/topic/16865\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Temporal logic\",\"topicId\":\"480\",\"url\":\"https://www.semanticscholar.org/topic/480\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Computation\",\"topicId\":\"339\",\"url\":\"https://www.semanticscholar.org/topic/339\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"On the fly\",\"topicId\":\"9003\",\"url\":\"https://www.semanticscholar.org/topic/9003\"},{\"topic\":\"Color\",\"topicId\":\"2390\",\"url\":\"https://www.semanticscholar.org/topic/2390\"},{\"topic\":\"Real-time clock\",\"topicId\":\"121831\",\"url\":\"https://www.semanticscholar.org/topic/121831\"},{\"topic\":\"Real-time transcription\",\"topicId\":\"763488\",\"url\":\"https://www.semanticscholar.org/topic/763488\"}],\"url\":\"https://www.semanticscholar.org/paper/6d05778f51fb0138a4ba46a6f007702a9a93654c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"