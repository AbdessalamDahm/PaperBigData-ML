"{\"abstract\":\"In recent years, Deep Learning has been successfully applied to multimodal learning problems, with the aim of learning useful joint representations in data fusion applications. When the available modalities consist of time series data such as video, audio and sensor signals, it becomes imperative to consider their temporal structure during the fusion process. In this paper, we propose the Correlational Recurrent Neural Network (CorrRNN), a novel temporal fusion model for fusing multiple input modalities that are inherently temporal in nature. Key features of our proposed model include: (i) simultaneous learning of the joint representation and temporal dependencies between modalities, (ii) use of multiple loss terms in the objective function, including a maximum correlation loss term to enhance learning of cross-modal information, and (iii) the use of an attention model to dynamically adjust the contribution of different input modalities to the joint representation. We validate our model via experimentation on two different tasks: video-and sensor-based activity classification, and audio-visual speech recognition. We empirically analyze the contributions of different components of the proposed CorrRNN model, and demonstrate its robustness, effectiveness and state-of-the-art performance on multiple datasets.\",\"arxivId\":\"1704.03152\",\"authors\":[{\"authorId\":\"3042242\",\"name\":\"X. Yang\",\"url\":\"https://www.semanticscholar.org/author/3042242\"},{\"authorId\":\"40327196\",\"name\":\"Palghat Ramesh\",\"url\":\"https://www.semanticscholar.org/author/40327196\"},{\"authorId\":\"1776163\",\"name\":\"Radha Chitta\",\"url\":\"https://www.semanticscholar.org/author/1776163\"},{\"authorId\":\"2234121\",\"name\":\"S. Madhvanath\",\"url\":\"https://www.semanticscholar.org/author/2234121\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\",\"url\":\"https://www.semanticscholar.org/author/2164140\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\",\"url\":\"https://www.semanticscholar.org/author/33642939\"}],\"citationVelocity\":14,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737799609\",\"name\":\"Tai-Te Chu\"},{\"authorId\":\"49420869\",\"name\":\"Yiting Liu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bc8a1d9bc331edd01228294b0e46a5ff2e190625\",\"title\":\"NLP301 at the NTCIR-15 Micro-activity Retrieval Task: Incorporating Region of Interest Features into Supervised Encoder\",\"url\":\"https://www.semanticscholar.org/paper/bc8a1d9bc331edd01228294b0e46a5ff2e190625\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C\\u0103t\\u0103lina Cangea\"},{\"authorId\":\"3444569\",\"name\":\"Petar Velickovic\"},{\"authorId\":\"144269589\",\"name\":\"Pietro Li\\u00f2\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0aa4d68b217e533f6dfadfe707dc8f4aaf42ef24\",\"title\":\"ETWORKS FOR A UDIOVISUAL C LASSIFICATION\",\"url\":\"https://www.semanticscholar.org/paper/0aa4d68b217e533f6dfadfe707dc8f4aaf42ef24\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8142030\",\"name\":\"S. Rayatdoost\"}],\"doi\":\"10.1145/3136755.3137034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21ab3ec8b8ac620413ec53e0d10108a94d928512\",\"title\":\"Cross-modality interaction between EEG signals and facial expression\",\"url\":\"https://www.semanticscholar.org/paper/21ab3ec8b8ac620413ec53e0d10108a94d928512\",\"venue\":\"ICMI\",\"year\":2017},{\"arxivId\":\"1907.13098\",\"authors\":[{\"authorId\":\"14656092\",\"name\":\"M. Lee\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1389620826\",\"name\":\"Peter Zachares\"},{\"authorId\":\"144323731\",\"name\":\"Matthew Tan\"},{\"authorId\":\"1391084712\",\"name\":\"K. Srinivasan\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"3245752\",\"name\":\"Feifei Li\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/TRO.2019.2959445\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1be579f4c120a8bf15c4df78d622549913b4d8f7\",\"title\":\"Making Sense of Vision and Touch: Learning Multimodal Representations for Contact-Rich Tasks\",\"url\":\"https://www.semanticscholar.org/paper/1be579f4c120a8bf15c4df78d622549913b4d8f7\",\"venue\":\"IEEE Transactions on Robotics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed9b230a1629049656c62bf4434d1212faeacc1f\",\"title\":\"C V ] 9 N ov 2 01 8 Cross and Learn : Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/ed9b230a1629049656c62bf4434d1212faeacc1f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.04979\",\"authors\":[{\"authorId\":\"2847159\",\"name\":\"Guoli Song\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tpami.2019.2942028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1634a591fe556530a4cf7605af70f8f190a13aec\",\"title\":\"Harmonized Multimodal Learning with Gaussian Process Latent Variable Models\",\"url\":\"https://www.semanticscholar.org/paper/1634a591fe556530a4cf7605af70f8f190a13aec\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152366931\",\"name\":\"Lei Zhu\"},{\"authorId\":\"153583278\",\"name\":\"Jiayu Song\"},{\"authorId\":\"3351330\",\"name\":\"X. Wei\"},{\"authorId\":\"37629830\",\"name\":\"H. Yu\"},{\"authorId\":\"1390782640\",\"name\":\"Jun Long\"}],\"doi\":\"10.1007/s11042-020-09983-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"224aea37455d3d981c7a6f66e1b3f74439a994c7\",\"title\":\"CAESAR: concept augmentation based semantic representation for cross-modal retrieval\",\"url\":\"https://www.semanticscholar.org/paper/224aea37455d3d981c7a6f66e1b3f74439a994c7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.03414\",\"authors\":[{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1109/ICASSP.2019.8683898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97924ebc712b3739adfdadfd428247fce84af4b5\",\"title\":\"Dense Multimodal Fusion for Hierarchically Joint Representation\",\"url\":\"https://www.semanticscholar.org/paper/97924ebc712b3739adfdadfd428247fce84af4b5\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1810.04547\",\"authors\":[{\"authorId\":\"3442611\",\"name\":\"David Semedo\"},{\"authorId\":\"144431718\",\"name\":\"J. Magalh\\u00e3es\"}],\"doi\":\"10.1145/3240508.3240665\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"243575d6baf3ba8e2b8783abc4a35d47bd194929\",\"title\":\"Temporal Cross-Media Retrieval with Soft-Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/243575d6baf3ba8e2b8783abc4a35d47bd194929\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.05448\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/N18-2125\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"title\":\"Watch, Listen, and Describe: Globally and Locally Aligned Cross-Modal Attentions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2714a3932b9d096b7bb285f6ec415cb047eafe09\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042697526\",\"name\":\"Haomin Qiu\"},{\"authorId\":\"144238413\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/ICTAI50040.2020.00107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6df60ba532272469595d79e2117d735762cb8de2\",\"title\":\"A State Representation Dueling Network for Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/6df60ba532272469595d79e2117d735762cb8de2\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26418330\",\"name\":\"Timoth\\u00e9e Lesort\"},{\"authorId\":\"1403234166\",\"name\":\"N. D\\u00edaz-Rodr\\u00edguez\"},{\"authorId\":\"35945520\",\"name\":\"Jean-Fran\\u00e7ois Goudou\"},{\"authorId\":\"119972619\",\"name\":\"David\"},{\"authorId\":null,\"name\":\"Filliat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"728ca14eb85e6dd2d36fe3b300ff043f68fc77af\",\"title\":\"J un 2 01 8 State Representation Learning for Control : An Overview\",\"url\":\"https://www.semanticscholar.org/paper/728ca14eb85e6dd2d36fe3b300ff043f68fc77af\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51036510\",\"name\":\"Athma Narayanan\"},{\"authorId\":\"145608726\",\"name\":\"Avinash Siravuru\"},{\"authorId\":\"2086607\",\"name\":\"Behzad Dariush\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6f3e3703491e8e193dbe24b0dd832767c0a9fada\",\"title\":\"Temporal Multimodal Fusion for Driver Behavior Prediction Tasks using Gated Recurrent Fusion Units\",\"url\":\"https://www.semanticscholar.org/paper/6f3e3703491e8e193dbe24b0dd832767c0a9fada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.00628\",\"authors\":[{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"71124982\",\"name\":\"Avinash Siravuru\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/LRA.2020.2967738\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"997a31a9a32a1769adccbf4a5f77d69ac29fe229\",\"title\":\"Gated Recurrent Fusion to Learn Driving Behavior from Temporal Multimodal Data\",\"url\":\"https://www.semanticscholar.org/paper/997a31a9a32a1769adccbf4a5f77d69ac29fe229\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1780024\",\"name\":\"R. Polikar\"}],\"doi\":\"10.1007/978-3-030-12939-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b05362caf719e2161f04b035c54b3172d6749cdb\",\"title\":\"Pattern Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b05362caf719e2161f04b035c54b3172d6749cdb\",\"venue\":\"Lecture Notes in Computer Science\",\"year\":2018},{\"arxivId\":\"1811.03879\",\"authors\":[{\"authorId\":\"51921002\",\"name\":\"N. Sayed\"},{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1007/978-3-030-12939-2_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"title\":\"Cross and Learn: Cross-Modal Self-Supervision\",\"url\":\"https://www.semanticscholar.org/paper/04f2a94a388dbc77d23ef5ec73cdb49ff251c1bd\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2265721\",\"name\":\"Naser Damer\"},{\"authorId\":\"23610745\",\"name\":\"Kristiyan Dimitrov\"},{\"authorId\":\"35528774\",\"name\":\"Abbey C. Braun\"},{\"authorId\":\"145307900\",\"name\":\"Arjan Kuijper\"}],\"doi\":\"10.1109/BTAS46853.2019.9186011\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b5562a78ffda726ca89125843c883de36371714\",\"title\":\"On Learning Joint Multi-biometric Representations by Deep Fusion\",\"url\":\"https://www.semanticscholar.org/paper/1b5562a78ffda726ca89125843c883de36371714\",\"venue\":\"2019 IEEE 10th International Conference on Biometrics Theory, Applications and Systems (BTAS)\",\"year\":2019},{\"arxivId\":\"1902.07473\",\"authors\":[{\"authorId\":\"2564871\",\"name\":\"Yan-Bo Lin\"},{\"authorId\":\"3312576\",\"name\":\"Yu-Jhe Li\"},{\"authorId\":\"2733735\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"title\":\"Dual-modality Seq2Seq Network for Audio-visual Event Localization\",\"url\":\"https://www.semanticscholar.org/paper/6dad33f2e317cc23abeba8596a4c8a4a13117d54\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116604389\",\"name\":\"Imant Daunhawer\"},{\"authorId\":\"34827176\",\"name\":\"T. Sutter\"},{\"authorId\":\"8258126\",\"name\":\"J. Vogt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c54f63144f9aee8a6713b42fb654e134d61f3ab\",\"title\":\"Improving Multimodal Generative Models with Disentangled Latent Partitions\",\"url\":\"https://www.semanticscholar.org/paper/6c54f63144f9aee8a6713b42fb654e134d61f3ab\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153907133\",\"name\":\"R. Couronne\"},{\"authorId\":\"27751049\",\"name\":\"Maxime Louis\"},{\"authorId\":\"2689496\",\"name\":\"S. Durrleman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eeba9df3990c96fa2f90fde7ab1b1e4b4258a86\",\"title\":\"Longitudinal autoencoder for multi-modal disease progression modelling\",\"url\":\"https://www.semanticscholar.org/paper/0eeba9df3990c96fa2f90fde7ab1b1e4b4258a86\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202626\",\"name\":\"Shibo Zhang\"},{\"authorId\":\"2959332\",\"name\":\"Nabil Alshurafa\"}],\"doi\":\"10.1145/3410530.3414329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6f3a2c99e797e21f4ad301f8c1150d5f554d1b1\",\"title\":\"Deep generative cross-modal on-body accelerometer data synthesis from videos\",\"url\":\"https://www.semanticscholar.org/paper/b6f3a2c99e797e21f4ad301f8c1150d5f554d1b1\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000202162\",\"name\":\"Soheil Rayatdoost\"},{\"authorId\":\"3090887\",\"name\":\"D. Rudrauf\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1145/3382507.3418867\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e9d701e44afaa58df40ba056bf7ddd6d75a24341\",\"title\":\"Multimodal Gated Information Fusion for Emotion Recognition from EEG Signals and Facial Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/e9d701e44afaa58df40ba056bf7ddd6d75a24341\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8142030\",\"name\":\"S. Rayatdoost\"},{\"authorId\":\"46878686\",\"name\":\"D. Rudrauf\"},{\"authorId\":\"143626389\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33bd26f586a1e1af2e0a5281fe0f6ae8989d2acd\",\"title\":\"Expression-Guided EEG Representation Learning for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33bd26f586a1e1af2e0a5281fe0f6ae8989d2acd\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2012.00201\",\"authors\":[{\"authorId\":\"14656092\",\"name\":\"M. Lee\"},{\"authorId\":\"144323731\",\"name\":\"Matthew Tan\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a1e0609d36ad5a8687416b945d821e5e3b16161\",\"title\":\"Detect, Reject, Correct: Crossmodal Compensation of Corrupted Sensors\",\"url\":\"https://www.semanticscholar.org/paper/4a1e0609d36ad5a8687416b945d821e5e3b16161\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418404\",\"name\":\"V. Valindria\"},{\"authorId\":\"39034356\",\"name\":\"Nick Pawlowski\"},{\"authorId\":\"2526670\",\"name\":\"Martin Rajchl\"},{\"authorId\":\"3482484\",\"name\":\"I. Lavdas\"},{\"authorId\":\"3473975\",\"name\":\"E. Aboagye\"},{\"authorId\":\"3484344\",\"name\":\"A. Rockall\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"1709824\",\"name\":\"Ben Glocker\"}],\"doi\":\"10.1109/WACV.2018.00066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3bbe426c3d221e01daf83c3aa4747f68d736a43\",\"title\":\"Multi-modal Learning from Unpaired Images: Application to Multi-organ Segmentation in CT and MRI\",\"url\":\"https://www.semanticscholar.org/paper/c3bbe426c3d221e01daf83c3aa4747f68d736a43\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27751049\",\"name\":\"Maxime Louis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48750a71930061447d9ce62438ed375bca3b5999\",\"title\":\"Computational and statistical methods for trajectory analysis in a Riemannian geometry setting. (M\\u00e9thodes num\\u00e9riques et statistiques pour l'analyse de trajectoire dans un cadre de geom\\u00e9trie Riemannienne)\",\"url\":\"https://www.semanticscholar.org/paper/48750a71930061447d9ce62438ed375bca3b5999\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1707.01922\",\"authors\":[{\"authorId\":\"2692770\",\"name\":\"K. Peng\"},{\"authorId\":\"3311781\",\"name\":\"Z. Wu\"},{\"authorId\":\"39497207\",\"name\":\"J. Ernst\"}],\"doi\":\"10.1007/978-3-030-01252-6_47\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1232e99e695437d08c1dd3cd19d7a25bc8f417e4\",\"title\":\"Zero-Shot Deep Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/1232e99e695437d08c1dd3cd19d7a25bc8f417e4\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1802.04181\",\"authors\":[{\"authorId\":\"26418330\",\"name\":\"Timoth\\u00e9e Lesort\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"},{\"authorId\":\"35945520\",\"name\":\"Jean-Fran\\u00e7ois Goudou\"},{\"authorId\":\"1771194\",\"name\":\"David Filliat\"}],\"doi\":\"10.1016/j.neunet.2018.07.006\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eed8cae46eb28311e88f6fc41f788528ca2d0f00\",\"title\":\"State Representation Learning for Control: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/eed8cae46eb28311e88f6fc41f788528ca2d0f00\",\"venue\":\"Neural Networks\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3442611\",\"name\":\"David Semedo\"},{\"authorId\":\"32552576\",\"name\":\"J. Magalh\\u00e3es\"}],\"doi\":\"10.1145/3394171.3413540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d211dbf630834c025cb29fc82fe6aee4d0eabce\",\"title\":\"Adaptive Temporal Triplet-loss for Cross-modal Embedding Learning\",\"url\":\"https://www.semanticscholar.org/paper/0d211dbf630834c025cb29fc82fe6aee4d0eabce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49420307\",\"name\":\"Y. Liu\"},{\"authorId\":\"1390925314\",\"name\":\"Yue Yao\"},{\"authorId\":\"1390878200\",\"name\":\"Zhengjie Wang\"},{\"authorId\":\"1390011966\",\"name\":\"J. Plested\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1109/IJCNN.2019.8852216\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc225b4fcb30c5c0a62c58bd64a4abdac3388f52\",\"title\":\"Generalized Alignment for Multimodal Physiological Signal Learning\",\"url\":\"https://www.semanticscholar.org/paper/dc225b4fcb30c5c0a62c58bd64a4abdac3388f52\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1810.10191\",\"authors\":[{\"authorId\":\"14656092\",\"name\":\"M. Lee\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"1391084712\",\"name\":\"K. Srinivasan\"},{\"authorId\":\"50127853\",\"name\":\"Parth Shah\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1873736\",\"name\":\"Animesh Garg\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/ICRA.2019.8793485\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8e7b0b23e70624fbc3bc5ab74ae01e39c6750a5\",\"title\":\"Making Sense of Vision and Touch: Self-Supervised Learning of Multimodal Representations for Contact-Rich Tasks\",\"url\":\"https://www.semanticscholar.org/paper/e8e7b0b23e70624fbc3bc5ab74ae01e39c6750a5\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46867171\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1749536978\",\"name\":\"Shibo Zhang\"},{\"authorId\":\"1515834500\",\"name\":\"Miao Liu\"},{\"authorId\":\"1400525235\",\"name\":\"Elyse Daly\"},{\"authorId\":\"1640089797\",\"name\":\"S. Battalio\"},{\"authorId\":\"46574709\",\"name\":\"Santosh Kumar\"},{\"authorId\":\"144789964\",\"name\":\"B. Spring\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"2959332\",\"name\":\"Nabil Alshurafa\"}],\"doi\":\"10.1145/3411824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d26c7c539401ec8e0a8e2f76b4ac54653109f19\",\"title\":\"SyncWISE: Window Induced Shift Estimation for Synchronization of Video and Accelerometry from Wearable Sensors\",\"url\":\"https://www.semanticscholar.org/paper/9d26c7c539401ec8e0a8e2f76b4ac54653109f19\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35503335\",\"name\":\"L. Drees\"},{\"authorId\":\"97967771\",\"name\":\"J. Kusche\"},{\"authorId\":\"46525320\",\"name\":\"R. Roscher\"},{\"authorId\":\"46525320\",\"name\":\"R. Roscher\"}],\"doi\":\"10.5194/isprs-annals-v-2-2020-813-2020\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0fcf7969b57b5569b80afaa426ecbc3ef698c2ae\",\"title\":\"MULTI-MODAL DEEP LEARNING WITH SENTINEL-3 OBSERVATIONS FOR THE DETECTION OF OCEANIC INTERNAL WAVES\",\"url\":\"https://www.semanticscholar.org/paper/0fcf7969b57b5569b80afaa426ecbc3ef698c2ae\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.03701\",\"authors\":[{\"authorId\":\"48255022\",\"name\":\"B. Canuel\"},{\"authorId\":\"98117787\",\"name\":\"S. Abend\"},{\"authorId\":\"1389873493\",\"name\":\"P. Amaro-Seoane\"},{\"authorId\":\"51897799\",\"name\":\"F. Badaracco\"},{\"authorId\":\"48446601\",\"name\":\"Q. Beaufils\"},{\"authorId\":\"50356673\",\"name\":\"A. Bertoldi\"},{\"authorId\":\"50562773\",\"name\":\"K. Bongs\"},{\"authorId\":\"49626130\",\"name\":\"P. Bouyer\"},{\"authorId\":\"48031279\",\"name\":\"C. Braxmaier\"},{\"authorId\":\"4253716\",\"name\":\"W. Chaibi\"},{\"authorId\":\"152503078\",\"name\":\"N. Christensen\"},{\"authorId\":\"1700416\",\"name\":\"F. Fitzek\"},{\"authorId\":\"69398607\",\"name\":\"G. Flouris\"},{\"authorId\":\"116853003\",\"name\":\"N. Gaaloul\"},{\"authorId\":\"9358563\",\"name\":\"S. Gaffet\"},{\"authorId\":\"4726091\",\"name\":\"C. G. Alzar\"},{\"authorId\":\"143889639\",\"name\":\"R. Geiger\"},{\"authorId\":\"1400414895\",\"name\":\"S. Guellati-Kh'elifa\"},{\"authorId\":\"3404493\",\"name\":\"K. Hammerer\"},{\"authorId\":\"144368832\",\"name\":\"J. Harms\"},{\"authorId\":\"116444875\",\"name\":\"J. Hinderer\"},{\"authorId\":\"7990929\",\"name\":\"J. Junc\\u00e0\"},{\"authorId\":\"66530859\",\"name\":\"S. Katsanevas\"},{\"authorId\":\"30128199\",\"name\":\"C. Klempt\"},{\"authorId\":\"3221688\",\"name\":\"C. Kozanitis\"},{\"authorId\":\"7275185\",\"name\":\"M. Krutzik\"},{\"authorId\":\"2503261\",\"name\":\"A. Landragin\"},{\"authorId\":\"89310791\",\"name\":\"I. L. Roche\"},{\"authorId\":\"103045755\",\"name\":\"B. Leykauf\"},{\"authorId\":\"134890752\",\"name\":\"Y.-H. Lien\"},{\"authorId\":\"103097367\",\"name\":\"S. Loriani\"},{\"authorId\":\"32012406\",\"name\":\"S. Merlet\"},{\"authorId\":\"49422080\",\"name\":\"M. Merzougui\"},{\"authorId\":\"50318195\",\"name\":\"M. Nofrar\\u00edas\"},{\"authorId\":\"31617790\",\"name\":\"P. Papadakos\"},{\"authorId\":\"113414396\",\"name\":\"F. Pereira\"},{\"authorId\":\"1383272340\",\"name\":\"A. Peters\"},{\"authorId\":\"20577958\",\"name\":\"D. Plexousakis\"},{\"authorId\":\"102703053\",\"name\":\"M. Prevedelli\"},{\"authorId\":\"1388560646\",\"name\":\"E. Rasel\"},{\"authorId\":\"51308369\",\"name\":\"Y. Rogister\"},{\"authorId\":\"7994953\",\"name\":\"S. Rosat\"},{\"authorId\":\"48846817\",\"name\":\"A. Roura\"},{\"authorId\":\"9965648\",\"name\":\"D. Sabulsky\"},{\"authorId\":\"31243908\",\"name\":\"V. Schkolnik\"},{\"authorId\":\"30919621\",\"name\":\"D. Schlippert\"},{\"authorId\":\"29487456\",\"name\":\"C. Schubert\"},{\"authorId\":\"7991148\",\"name\":\"L. Sidorenkov\"},{\"authorId\":\"1400414862\",\"name\":\"J.-N. Siemss\"},{\"authorId\":\"103175406\",\"name\":\"C. Sopuerta\"},{\"authorId\":\"46415498\",\"name\":\"F. Sorrentino\"},{\"authorId\":\"122026160\",\"name\":\"C. Struckmann\"},{\"authorId\":\"2904760\",\"name\":\"G. Tino\"},{\"authorId\":\"50982175\",\"name\":\"G. Tsagkatakis\"},{\"authorId\":\"94947289\",\"name\":\"A. Vicer\\u00e9\"},{\"authorId\":\"5168507\",\"name\":\"W. Klitzing\"},{\"authorId\":\"7484490\",\"name\":\"L. Woerner\"},{\"authorId\":\"115347276\",\"name\":\"X. Zou\"}],\"doi\":\"10.1088/1361-6382/aba80e\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bff30ace64b7826c81e4e2bc146693432366d249\",\"title\":\"ELGAR -- a European Laboratory for Gravitation and Atom-interferometric Research\",\"url\":\"https://www.semanticscholar.org/paper/bff30ace64b7826c81e4e2bc146693432366d249\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451396\",\"name\":\"Nikos Papasarantopoulos\"},{\"authorId\":\"2875615\",\"name\":\"Lea Frermann\"},{\"authorId\":\"1747893\",\"name\":\"Mirella Lapata\"},{\"authorId\":\"40146204\",\"name\":\"Shay B. Cohen\"}],\"doi\":\"10.18653/v1/D19-1212\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"187e69900484453fda35d853cdc8c5a298ecbd24\",\"title\":\"Partners in Crime: Multi-view Sequential Inference for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/187e69900484453fda35d853cdc8c5a298ecbd24\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2008.11450\",\"authors\":[{\"authorId\":\"1879340740\",\"name\":\"Jason Armitage\"},{\"authorId\":\"1907806910\",\"name\":\"Shramana Thakur\"},{\"authorId\":\"153011857\",\"name\":\"R. Tripathi\"},{\"authorId\":\"71564931\",\"name\":\"J. Lehmann\"},{\"authorId\":\"2298633\",\"name\":\"M. Maleshkova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7dfc582314a551c0d18021b969f3fb6e4b9d4d4c\",\"title\":\"Training Multimodal Systems for Classification with Multiple Objectives\",\"url\":\"https://www.semanticscholar.org/paper/7dfc582314a551c0d18021b969f3fb6e4b9d4d4c\",\"venue\":\"CLEOPATRA@ESWC\",\"year\":2020},{\"arxivId\":\"1811.08890\",\"authors\":[{\"authorId\":\"51261844\",\"name\":\"N. Holzenberger\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"}],\"doi\":\"10.1109/ICASSP.2019.8683540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a01ae256dfe7bd10734fec8a66549fb7ea876a05\",\"title\":\"Learning from Multiview Correlations in Open-domain Videos\",\"url\":\"https://www.semanticscholar.org/paper/a01ae256dfe7bd10734fec8a66549fb7ea876a05\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1811.11067\",\"authors\":[{\"authorId\":\"52021869\",\"name\":\"P. Solovev\"},{\"authorId\":\"144961117\",\"name\":\"V. Aliev\"},{\"authorId\":\"51447154\",\"name\":\"Pavel Ostyakov\"},{\"authorId\":\"51434572\",\"name\":\"Gleb Sterkin\"},{\"authorId\":\"145879692\",\"name\":\"E. Logacheva\"},{\"authorId\":\"51962204\",\"name\":\"Stepan Troeshestov\"},{\"authorId\":\"1956107\",\"name\":\"R. Suvorov\"},{\"authorId\":\"51995877\",\"name\":\"A. Mashikhin\"},{\"authorId\":\"50168812\",\"name\":\"Oleg Khomenko\"},{\"authorId\":\"1742235\",\"name\":\"S. Nikolenko\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3e358d5101bb1cd975fb8a5cf976318ab932ae9\",\"title\":\"Learning State Representations in Complex Systems with Multimodal Data\",\"url\":\"https://www.semanticscholar.org/paper/d3e358d5101bb1cd975fb8a5cf976318ab932ae9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311853\",\"name\":\"Sen Zhang\"},{\"authorId\":\"50445850\",\"name\":\"Changzheng Zhang\"},{\"authorId\":\"49680751\",\"name\":\"Lanjun Wang\"},{\"authorId\":\"1391213506\",\"name\":\"Cixing Li\"},{\"authorId\":\"2929196\",\"name\":\"Dandan Tu\"},{\"authorId\":\"48846876\",\"name\":\"R. Luo\"},{\"authorId\":\"49502400\",\"name\":\"G. Qi\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-32692-0_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"023ba45d57d1b049b63099a653ceff24e523ba76\",\"title\":\"MSAFusionNet: Multiple Subspace Attention Based Deep Multi-modal Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/023ba45d57d1b049b63099a653ceff24e523ba76\",\"venue\":\"MLMI@MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51906624\",\"name\":\"Catalina Cangea\"},{\"authorId\":\"3444569\",\"name\":\"Petar Velickovic\"},{\"authorId\":\"144269589\",\"name\":\"P. Li\\u00f2\"}],\"doi\":\"10.1109/TNNLS.2019.2945992\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e10055d62462c4112c2fbd4d8ba929e9eb769b58\",\"title\":\"XFlow: Cross-Modal Deep Neural Networks for Audiovisual Classification\",\"url\":\"https://www.semanticscholar.org/paper/e10055d62462c4112c2fbd4d8ba929e9eb769b58\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"2008.02171\",\"authors\":[{\"authorId\":\"1779351\",\"name\":\"C. Schockaert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81638131f60b64b3af1f9b6491c2cc4e3bb8205c\",\"title\":\"A Causal-based Framework for Multimodal Multivariate Time Series Validation Enhanced by Unsupervised Deep Learning as an Enabler for Industry 4.0\",\"url\":\"https://www.semanticscholar.org/paper/81638131f60b64b3af1f9b6491c2cc4e3bb8205c\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":16702244,\"doi\":\"10.1109/CVPR.2017.538\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"01f4e52ead817b83d65478d03f6a9d7e9074d889\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"50721828\",\"name\":\"F. J. Morales\"},{\"authorId\":\"1703539\",\"name\":\"D. Roggen\"}],\"doi\":\"10.3390/s16010115\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8599a64beec9ec141a97c8117aa5b1726c13223\",\"title\":\"Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8599a64beec9ec141a97c8117aa5b1726c13223\",\"venue\":\"Sensors\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763894\",\"name\":\"David R. Hardoon\"},{\"authorId\":\"2540580\",\"name\":\"S. Szedm\\u00e1k\"},{\"authorId\":\"1404459229\",\"name\":\"J. Shawe-Taylor\"}],\"doi\":\"10.1162/0899766042321814\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6b5b20151c752beb74508f813699fa5216dedfa\",\"title\":\"Canonical Correlation Analysis: An Overview with Application to Learning Methods\",\"url\":\"https://www.semanticscholar.org/paper/a6b5b20151c752beb74508f813699fa5216dedfa\",\"venue\":\"Neural Computation\",\"year\":2004},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145270321\",\"name\":\"E. B. Patterson\"},{\"authorId\":\"3097743\",\"name\":\"S. Gurbuz\"},{\"authorId\":\"3351861\",\"name\":\"Z. Tufekci\"},{\"authorId\":\"33978317\",\"name\":\"J.N. Gowdy\"}],\"doi\":\"10.1109/ICASSP.2002.5745028\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"dd70cd5c716b7c484f4a9833cf61453e1e70d387\",\"title\":\"CUAVE: A new audio-visual database for multimodal human-computer interface research\",\"url\":\"https://www.semanticscholar.org/paper/dd70cd5c716b7c484f4a9833cf61453e1e70d387\",\"venue\":\"2002 IEEE International Conference on Acoustics, Speech, and Signal Processing\",\"year\":2002},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Chandar\"},{\"authorId\":null,\"name\":\"M M Khapra\"},{\"authorId\":null,\"name\":\"H Larochelle\"},{\"authorId\":null,\"name\":\"B Ravindran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Correlational neural networks. Neural computation\",\"url\":\"\",\"venue\":\"Correlational neural networks. Neural computation\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"},{\"authorId\":\"3185424\",\"name\":\"S. Bahaadini\"},{\"authorId\":\"143719659\",\"name\":\"R. Molina\"}],\"doi\":\"10.1109/JPROC.2015.2459017\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01fecf4553132a5252b6bf6d264f68568a8dbf6e\",\"title\":\"Audiovisual Fusion: Challenges and New Approaches\",\"url\":\"https://www.semanticscholar.org/paper/01fecf4553132a5252b6bf6d264f68568a8dbf6e\",\"venue\":\"Proceedings of the IEEE\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2020608\",\"name\":\"J. Ngiam\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"4738460\",\"name\":\"Mingyu Kim\"},{\"authorId\":\"145578392\",\"name\":\"Juhan Nam\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"title\":\"Multimodal Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/80e9e3fc3670482c1fee16b2542061b779f47c4f\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48307541\",\"name\":\"Natalia Neverova\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2969296\",\"name\":\"Florian Nebout\"}],\"doi\":\"10.1109/TPAMI.2015.2461544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bd90c857bb4c6569aa8b7776af54328e6a71413\",\"title\":\"ModDrop: Adaptive Multi-Modal Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bd90c857bb4c6569aa8b7776af54328e6a71413\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143775793\",\"name\":\"J. Kumar\"},{\"authorId\":\"144326109\",\"name\":\"Q. Li\"},{\"authorId\":\"2164893\",\"name\":\"Survi Kyal\"},{\"authorId\":\"2164140\",\"name\":\"E. Bernal\"},{\"authorId\":\"145652623\",\"name\":\"R. Bala\"}],\"doi\":\"10.1109/CVPRW.2015.7301344\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ca4ce8ab704b44701bf7ef8dda01c8dbb226fac\",\"title\":\"On-the-fly hand detection training with application in egocentric action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ca4ce8ab704b44701bf7ef8dda01c8dbb226fac\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2015},{\"arxivId\":\"1504.07225\",\"authors\":[{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1723632\",\"name\":\"Balaraman Ravindran\"}],\"doi\":\"10.1162/NECO_a_00801\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f525f231ea7c9ae335ffdd411c0a59bdf9c9e8\",\"title\":\"Correlational Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/39f525f231ea7c9ae335ffdd411c0a59bdf9c9e8\",\"venue\":\"Neural Computation\",\"year\":2016},{\"arxivId\":\"1602.04364\",\"authors\":[{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"46972608\",\"name\":\"Yongtao Hu\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"144479026\",\"name\":\"Q. Yan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a704b38c275d3f583627ed8858e1042a69b1a6fa\",\"title\":\"Look, Listen and Learn - A Multimodal LSTM for Speaker Identification\",\"url\":\"https://www.semanticscholar.org/paper/a704b38c275d3f583627ed8858e1042a69b1a6fa\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144339350\",\"name\":\"G. Andrew\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6\",\"title\":\"Deep Canonical Correlation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e2257e3f56ccb12875a57bc0a8cca1d9d7e93ec6\",\"venue\":\"ICML\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703539\",\"name\":\"D. Roggen\"},{\"authorId\":\"35158228\",\"name\":\"A. Calatroni\"},{\"authorId\":\"2892459\",\"name\":\"M. Rossi\"},{\"authorId\":\"1678853\",\"name\":\"Thomas Holleczek\"},{\"authorId\":\"35235859\",\"name\":\"K. F\\u00f6rster\"},{\"authorId\":\"144119654\",\"name\":\"G. Tr\\u00f6ster\"},{\"authorId\":\"143951813\",\"name\":\"P. Lukowicz\"},{\"authorId\":\"2237172\",\"name\":\"D. Bannach\"},{\"authorId\":\"2491719\",\"name\":\"Gerald Pirkl\"},{\"authorId\":\"1745790\",\"name\":\"A. Ferscha\"},{\"authorId\":\"3338727\",\"name\":\"Jakob Doppler\"},{\"authorId\":\"2215719\",\"name\":\"C. Holzmann\"},{\"authorId\":\"40386305\",\"name\":\"M. Kurz\"},{\"authorId\":\"3239112\",\"name\":\"Gerald Holl\"},{\"authorId\":\"1690926\",\"name\":\"Ricardo Chavarriaga\"},{\"authorId\":\"1689792\",\"name\":\"H. Sagha\"},{\"authorId\":\"1771655\",\"name\":\"H. Bayati\"},{\"authorId\":\"3083766\",\"name\":\"Marco Creatura\"},{\"authorId\":\"1716694\",\"name\":\"J. Mill\\u00e1n\"}],\"doi\":\"10.1109/INSS.2010.5573462\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e887429bb73054b19d38d57d380477c7690fe4f\",\"title\":\"Collecting complex activity datasets in highly rich networked sensor environments\",\"url\":\"https://www.semanticscholar.org/paper/9e887429bb73054b19d38d57d380477c7690fe4f\",\"venue\":\"2010 Seventh International Conference on Networked Sensing Systems (INSS)\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D Bahdanau\"},{\"authorId\":null,\"name\":\"K Cho\"},{\"authorId\":null,\"name\":\"Y Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neural machine translation by jointly learning to align and translate. in ICLR 2015, abs/1409\",\"url\":\"\",\"venue\":\"Neural machine translation by jointly learning to align and translate. in ICLR 2015, abs/1409\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144213476\",\"name\":\"Chao Sui\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2444665\",\"name\":\"R. Togneri\"}],\"doi\":\"10.1109/ICCV.2015.26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ad036ad46fc14212d6b9ffdb1a823c4a9e89195b\",\"title\":\"Listening with Your Eyes: Towards a Practical Visual Speech Recognition System Using Deep Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/ad036ad46fc14212d6b9ffdb1a823c4a9e89195b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1711695\",\"name\":\"I. Matthews\"},{\"authorId\":\"7205190\",\"name\":\"T. Cootes\"},{\"authorId\":\"144427091\",\"name\":\"J. Bangham\"},{\"authorId\":\"35132323\",\"name\":\"S. Cox\"},{\"authorId\":\"144439756\",\"name\":\"R. Harvey\"}],\"doi\":\"10.1109/34.982900\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f78867834f7f6797ca6396f98edb10aad2a864fb\",\"title\":\"Extraction of Visual Features for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/f78867834f7f6797ca6396f98edb10aad2a864fb\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4599641\",\"name\":\"M. Amer\"},{\"authorId\":\"1832513\",\"name\":\"Behjat Siddiquie\"},{\"authorId\":\"144791561\",\"name\":\"Saad M. Khan\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":\"10.1109/WACV.2014.6836053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cfd123e03844c32f8a25f6c4bfc0a93e145ecc2d\",\"title\":\"Multimodal fusion using dynamic hybrid models\",\"url\":\"https://www.semanticscholar.org/paper/cfd123e03844c32f8a25f6c4bfc0a93e145ecc2d\",\"venue\":\"IEEE Winter Conference on Applications of Computer Vision\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"F. Ringeval\"},{\"authorId\":null,\"name\":\"B. Schuller\"},{\"authorId\":null,\"name\":\"M. Valstar\"},{\"authorId\":null,\"name\":\"S. Jaiswal\"},{\"authorId\":null,\"name\":\"E. Marchi\"},{\"authorId\":null,\"name\":\"D. Lalanne\"},{\"authorId\":null,\"name\":\"R. Cowie\"},{\"authorId\":null,\"name\":\"M. Pantic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The av+ ec 2015 multimodal affect recognition challenge: Bridging across audio, video, and physiological data\",\"url\":\"\",\"venue\":\"In Proceedings of the 5rd ACM International Workshop on Audio/Visual Emotion Challenge. ACM,\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5726c7b40fcc454b77d989656c085520bf6c15fa\",\"title\":\"Multimodal learning with deep Boltzmann machines\",\"url\":\"https://www.semanticscholar.org/paper/5726c7b40fcc454b77d989656c085520bf6c15fa\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48080348\",\"name\":\"D. Hu\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/CVPR.2016.389\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"51e0f0ebda30075940c9cd8b07047eddc2505663\",\"title\":\"Temporal Multimodal Learning in Audiovisual Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e0f0ebda30075940c9cd8b07047eddc2505663\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Ferscha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Look , listen and learna multimodal lstm for speaker identification The av + ec 2015 multimodal affect recognition challenge : Bridging across audio , video , and physiological data\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702290\",\"name\":\"Weiran Wang\"},{\"authorId\":\"144365054\",\"name\":\"R. Arora\"},{\"authorId\":\"2924113\",\"name\":\"Karen Livescu\"},{\"authorId\":\"1748118\",\"name\":\"J. Bilmes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc57291062df473c678bc89eba56056259bd2546\",\"title\":\"On Deep Multi-View Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/fc57291062df473c678bc89eba56056259bd2546\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729571\",\"name\":\"Kihyuk Sohn\"},{\"authorId\":\"3163480\",\"name\":\"W. Shang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64bfeb1ddd35838706e4fffc469234cc2f215631\",\"title\":\"Improved Multimodal Deep Learning with Variation of Information\",\"url\":\"https://www.semanticscholar.org/paper/64bfeb1ddd35838706e4fffc469234cc2f215631\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2124680\",\"name\":\"Fabien Ringeval\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1795528\",\"name\":\"M. Valstar\"},{\"authorId\":\"2736086\",\"name\":\"Shashank Jaiswal\"},{\"authorId\":\"1779097\",\"name\":\"E. Marchi\"},{\"authorId\":\"1707657\",\"name\":\"D. Lalanne\"},{\"authorId\":\"145635430\",\"name\":\"R. Cowie\"},{\"authorId\":\"145387780\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1145/2808196.2811642\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d315792a497cd1d88e238c45303b0d5637c18d2\",\"title\":\"AV+EC 2015: The First Affect Recognition Challenge Bridging Across Audio, Video, and Physiological Data\",\"url\":\"https://www.semanticscholar.org/paper/2d315792a497cd1d88e238c45303b0d5637c18d2\",\"venue\":\"AVEC@ACM Multimedia\",\"year\":2015}],\"title\":\"Deep Multimodal Representation Learning from Temporal Data\",\"topics\":[{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Multimodal learning\",\"topicId\":\"406692\",\"url\":\"https://www.semanticscholar.org/topic/406692\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"Modal logic\",\"topicId\":\"61528\",\"url\":\"https://www.semanticscholar.org/topic/61528\"},{\"topic\":\"Audio-visual speech recognition\",\"topicId\":\"53783\",\"url\":\"https://www.semanticscholar.org/topic/53783\"},{\"topic\":\"Modality (human\\u2013computer interaction)\",\"topicId\":\"462\",\"url\":\"https://www.semanticscholar.org/topic/462\"},{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Asynchronous I/O\",\"topicId\":\"125497\",\"url\":\"https://www.semanticscholar.org/topic/125497\"},{\"topic\":\"Time series\",\"topicId\":\"1293\",\"url\":\"https://www.semanticscholar.org/topic/1293\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Optimization problem\",\"topicId\":\"12682\",\"url\":\"https://www.semanticscholar.org/topic/12682\"},{\"topic\":\"Imperative programming\",\"topicId\":\"1485\",\"url\":\"https://www.semanticscholar.org/topic/1485\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"},{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"Oracle Fusion Architecture\",\"topicId\":\"4475853\",\"url\":\"https://www.semanticscholar.org/topic/4475853\"},{\"topic\":\"Loss function\",\"topicId\":\"3650\",\"url\":\"https://www.semanticscholar.org/topic/3650\"}],\"url\":\"https://www.semanticscholar.org/paper/01f4e52ead817b83d65478d03f6a9d7e9074d889\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"