"{\"abstract\":\"Despite the recent success of neural networks in image feature learning, a major problem in the video domain is the lack of sufficient labeled data for learning to model temporal information. In this paper, we propose an unsupervised temporal modeling method that learns from untrimmed videos. The speed of motion varies constantly, e.g., a man may run quickly or slowly. We therefore train a Multirate Visual Recurrent Model (MVRM) by encoding frames of a clip with different intervals. This learning process makes the learned model more capable of dealing with motion speed variance. Given a clip sampled from a video, we use its past and future neighboring clips as the temporal context, and reconstruct the two temporal transitions, i.e., present-past transition and present-future transition, reflecting the temporal information in different views. The proposed method exploits the two transitions simultaneously by incorporating a bidirectional reconstruction which consists of a backward reconstruction and a forward reconstruction. We apply the proposed method to two challenging video tasks, i.e., complex event detection and video captioning, in which it achieves state-of-the-art performance. Notably, our method generates the best single feature for event detection with a relative improvement of 10.4% on the MEDTest-13 dataset and achieves the best performance in video captioning across all evaluation metrics on the YouTube2Text dataset.\",\"arxivId\":\"1611.09053\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\",\"url\":\"https://www.semanticscholar.org/author/2948393\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\",\"url\":\"https://www.semanticscholar.org/author/2351434\"},{\"authorId\":null,\"name\":\"Yi Yang\",\"url\":null}],\"citationVelocity\":17,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2742322\",\"name\":\"Xingzhong Du\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1720932\",\"name\":\"X. Zhou\"}],\"doi\":\"10.1007/s11280-017-0505-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"614fab39d9899c519616bb837a3fa035294c4b0e\",\"title\":\"Exploiting detected visual objects for frame-level video filtering\",\"url\":\"https://www.semanticscholar.org/paper/614fab39d9899c519616bb837a3fa035294c4b0e\",\"venue\":\"World Wide Web\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240677\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"title\":\"Spotting and Aggregating Salient Regions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"}],\"doi\":\"10.1016/j.sigpro.2018.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"111f60f8b8b0a510a170f951a21ace9a4df12dfd\",\"title\":\"Event patches: Mining effective parts for event detection and understanding\",\"url\":\"https://www.semanticscholar.org/paper/111f60f8b8b0a510a170f951a21ace9a4df12dfd\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.04465\",\"authors\":[{\"authorId\":\"9929684\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.1109/CVPR.2019.00186\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe8907302f9d14233cd03cc2948a1c4e2a50bdb6\",\"title\":\"Searching for a Robust Neural Architecture in Four GPU Hours\",\"url\":\"https://www.semanticscholar.org/paper/fe8907302f9d14233cd03cc2948a1c4e2a50bdb6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"}],\"doi\":\"10.1016/j.neucom.2019.08.043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30fc6edf2c499025b26dc0e55e95af03c35d34d5\",\"title\":\"Convolutional relation network for skeleton-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/30fc6edf2c499025b26dc0e55e95af03c35d34d5\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46701988\",\"name\":\"Haimin Zhang\"},{\"authorId\":\"143679002\",\"name\":\"Min Xu\"}],\"doi\":\"10.1109/TMM.2018.2808760\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecd3975e55798972deb89708ebe9365f67b7eaf5\",\"title\":\"Recognition of Emotions in User-Generated Videos With Kernelized Features\",\"url\":\"https://www.semanticscholar.org/paper/ecd3975e55798972deb89708ebe9365f67b7eaf5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"title\":\"Large-scale video analysis and understanding\",\"url\":\"https://www.semanticscholar.org/paper/6bd7ff039ff38f4bb41f7a4b9a1f370ef02eed80\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1904.01310\",\"authors\":[{\"authorId\":\"145314938\",\"name\":\"Minfeng Zhu\"},{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"50504401\",\"name\":\"Wei Chen\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/CVPR.2019.00595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab995f96722969a0dfc6dc9139eef4c9b13c0524\",\"title\":\"DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/ab995f96722969a0dfc6dc9139eef4c9b13c0524\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153389599\",\"name\":\"Junchao Zhang\"},{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1109/TIP.2020.2988435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efb373e597cee2046d0616dd4a1d8a1d1e2c7ad3\",\"title\":\"Video Captioning With Object-Aware Spatio-Temporal Correlation and Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/efb373e597cee2046d0616dd4a1d8a1d1e2c7ad3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1707.04143\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1732242\",\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c0ff3fbca31be3c9ed2460df6c6edecec19fc3c\",\"title\":\"UTS submission to Google YouTube-8M Challenge 2017\",\"url\":\"https://www.semanticscholar.org/paper/7c0ff3fbca31be3c9ed2460df6c6edecec19fc3c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TMM.2018.2879749\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c1d06998c57d06a792df88a48f4e52b59f730ff\",\"title\":\"Discovering Latent Discriminative Patterns for Multi-Mode Event Representation\",\"url\":\"https://www.semanticscholar.org/paper/2c1d06998c57d06a792df88a48f4e52b59f730ff\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000290876\",\"name\":\"He Li\"},{\"authorId\":\"28070336\",\"name\":\"Weihang Kong\"},{\"authorId\":\"1390851515\",\"name\":\"Shihui Zhang\"}],\"doi\":\"10.1016/J.KNOSYS.2020.106485\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44367641892e7dec62b2fae1a4516770c754488b\",\"title\":\"Deeply scale aggregation network for object counting\",\"url\":\"https://www.semanticscholar.org/paper/44367641892e7dec62b2fae1a4516770c754488b\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49308892\",\"name\":\"Mahlagha Afrasiabi\"},{\"authorId\":\"2264128\",\"name\":\"H. Khotanlou\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"}],\"doi\":\"10.1007/s11042-020-08845-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"233fde55a797ac4fcd018bb2e7e967e51731c341\",\"title\":\"Spatial-temporal dual-actor CNN for human interaction prediction in video\",\"url\":\"https://www.semanticscholar.org/paper/233fde55a797ac4fcd018bb2e7e967e51731c341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1906.09383\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"48607331\",\"name\":\"Yu Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"title\":\"Baidu-UTS Submission to the EPIC-Kitchens Action Recognition Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"14618116\",\"name\":\"Chongyang Gao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1016/J.PATREC.2018.07.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab27d39857f613af36eff3fa3796904f474f8cbd\",\"title\":\"Sequence in sequence for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/ab27d39857f613af36eff3fa3796904f474f8cbd\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.24963/ijcai.2018/143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"title\":\"Multi-modal Circulant Fusion for Video-to-Language and Backward\",\"url\":\"https://www.semanticscholar.org/paper/e2e5cef45c60c52fb0d0415cca6cbf35beab3873\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"title\":\"Motion Guided Spatial Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/75719b4df1cd244fe5bda0d01b9eb7e0c053857d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153185012\",\"name\":\"G. Li\"},{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9b77854443654cec7e2ac5c298f245dbe838c0f5\",\"title\":\"UTS CAI submission at TRECVID 2017 Video to Text Description Task\",\"url\":\"https://www.semanticscholar.org/paper/9b77854443654cec7e2ac5c298f245dbe838c0f5\",\"venue\":\"TRECVID\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36251013\",\"name\":\"Wei Li\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.10.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ba881ec9ed2b435468ba6bbdc1821bde7778417\",\"title\":\"Multimodal architecture for video captioning with memory networks and an attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/0ba881ec9ed2b435468ba6bbdc1821bde7778417\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"2011.07231\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00877\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"title\":\"ActBERT: Learning Global-Local Video-Text Representations\",\"url\":\"https://www.semanticscholar.org/paper/8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969948\",\"name\":\"Zhihui Li\"},{\"authorId\":\"2082966\",\"name\":\"L. Yao\"},{\"authorId\":\"144962210\",\"name\":\"F. Nie\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"145093158\",\"name\":\"M. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a4dbd2db0e09a4f3aab3d2602db3176f825d8f9\",\"title\":\"Multi-Rate Gated Recurrent Convolutional Networks for Video-Based Pedestrian Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/6a4dbd2db0e09a4f3aab3d2602db3176f825d8f9\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49813626\",\"name\":\"Y. Guo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eecfaf49500434d91970b24831081d5d2c68697e\",\"title\":\"Sequence to Sequence Model for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eecfaf49500434d91970b24831081d5d2c68697e\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1906.04375\",\"authors\":[{\"authorId\":\"153389599\",\"name\":\"Junchao Zhang\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1109/CVPR.2019.00852\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6c9bd4d49d7bd70e1610c0f28fbd78ff97d0d0b5\",\"title\":\"Object-Aware Aggregation With Bidirectional Temporal Graph for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c9bd4d49d7bd70e1610c0f28fbd78ff97d0d0b5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-01234-2_46\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"396520344fb4894849a826b3de56fc86d4d79100\",\"title\":\"Compound Memory Networks for Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/396520344fb4894849a826b3de56fc86d4d79100\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2061528\",\"name\":\"Wenqing Chu\"},{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"39019048\",\"name\":\"Chengwei Yao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TMM.2018.2846411\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d3b00381c619912337c60897307322ba4edff3b\",\"title\":\"Sparse Coding Guided Spatiotemporal Feature Learning for Abnormal Event Detection in Large Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d3b00381c619912337c60897307322ba4edff3b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1769315\",\"name\":\"D. Koelma\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1145/3377875\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83288d73e85700698168f07d7c2290864fa32198\",\"title\":\"Shuffled ImageNet Banks for Video Event Detection and Search\",\"url\":\"https://www.semanticscholar.org/paper/83288d73e85700698168f07d7c2290864fa32198\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48000598\",\"name\":\"Zhiqiang Zeng\"},{\"authorId\":\"46947305\",\"name\":\"Z. Li\"},{\"authorId\":\"145067864\",\"name\":\"De Cheng\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"},{\"authorId\":\"1918754\",\"name\":\"Kun Zhan\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/TII.2017.2767557\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f31c9328b5b4678388c19a39064a8056313f7cf4\",\"title\":\"Two-Stream Multirate Recurrent Neural Network for Video-Based Pedestrian Reidentification\",\"url\":\"https://www.semanticscholar.org/paper/f31c9328b5b4678388c19a39064a8056313f7cf4\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1906550\",\"name\":\"Yanfeng Gu\"},{\"authorId\":\"102736009\",\"name\":\"H. Liu\"},{\"authorId\":\"1563987327\",\"name\":\"Tengfei Wang\"},{\"authorId\":\"2973521\",\"name\":\"Shengyang Li\"},{\"authorId\":\"1910913\",\"name\":\"Guoming Gao\"}],\"doi\":\"10.1007/s11432-019-2784-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f0f9790533d0585a60d1cf53b03985357371a11\",\"title\":\"Deep feature extraction and motion representation for satellite video scene classification\",\"url\":\"https://www.semanticscholar.org/paper/0f0f9790533d0585a60d1cf53b03985357371a11\",\"venue\":\"Science China Information Sciences\",\"year\":2020},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46315010\",\"name\":\"W. Wang\"},{\"authorId\":\"47971190\",\"name\":\"Yan Yan\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TPAMI.2018.2803166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fec438794c9cc3350d6dd9a16cd48d1b8d13b32a\",\"title\":\"Recurrent Face Aging with Hierarchical AutoRegressive Memory\",\"url\":\"https://www.semanticscholar.org/paper/fec438794c9cc3350d6dd9a16cd48d1b8d13b32a\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49812342\",\"name\":\"Y. Gui\"},{\"authorId\":\"66384390\",\"name\":\"Y. Tian\"},{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"40912044\",\"name\":\"Zong-You Xie\"},{\"authorId\":\"1741060\",\"name\":\"Yiyu Cai\"}],\"doi\":\"10.1109/TCSVT.2019.2961267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ada5a32d9cbc70a8abded1b81f0ed8cf12c32cd\",\"title\":\"Reliable and Dynamic Appearance Modeling and Label Consistency Enforcing for Fast and Coherent Video Object Segmentation With the Bilateral Grid\",\"url\":\"https://www.semanticscholar.org/paper/5ada5a32d9cbc70a8abded1b81f0ed8cf12c32cd\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1902.10322\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2019.01277\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20888a7aebaf77a306c0886f165bd0d468db806d\",\"title\":\"Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/20888a7aebaf77a306c0886f165bd0d468db806d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.12522\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-030-20893-6_34\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"283181a2173b485726664edc6fe73f0465387629\",\"title\":\"Random Temporal Skipping for Multirate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/283181a2173b485726664edc6fe73f0465387629\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be775b7c6c59d40a7437f1ca49f3697b4d2f6d97\",\"title\":\"Inflated Episodic Memory With Region Self-Attention for Long-Tailed Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be775b7c6c59d40a7437f1ca49f3697b4d2f6d97\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40791626\",\"name\":\"Reham Abobeah\"},{\"authorId\":\"39781659\",\"name\":\"A. Shoukry\"},{\"authorId\":\"1788294\",\"name\":\"J. Katto\"}],\"doi\":\"10.1109/ACCESS.2020.2967750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"15c795b754f44f5f1c8664a5adb18e01e33eb8e5\",\"title\":\"Video Alignment Using Bi-Directional Attention Flow in a Multi-Stage Learning Model\",\"url\":\"https://www.semanticscholar.org/paper/15c795b754f44f5f1c8664a5adb18e01e33eb8e5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50118603\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"7179962\",\"name\":\"Yan-qi Yang\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2020.3040521\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acfa6fcd7343c14e3f150c0541cc94e672cf1a73\",\"title\":\"Learning to Anticipate Egocentric Actions by Imagination\",\"url\":\"https://www.semanticscholar.org/paper/acfa6fcd7343c14e3f150c0541cc94e672cf1a73\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1896064\",\"name\":\"S. Reaungamornrat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6641ec78c7656ffd8c4872544be2273fee3127a0\",\"title\":\"Deformable Image Registration for Surgical Guidance using Intraoperative Cone-Beam CT\",\"url\":\"https://www.semanticscholar.org/paper/6641ec78c7656ffd8c4872544be2273fee3127a0\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10033841\",\"name\":\"Xinzhe Zhou\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1145/3372278.3390687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"title\":\"Google Helps YouTube: Learning Few-Shot Video Classification from Historic Tasks and Cross-Domain Sample Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3239379\",\"name\":\"J. Zhang\"},{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1007/978-3-030-05710-7_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f321353dafe2a43ef25cb0d6e9714f833a5bb\",\"title\":\"Hierarchical Vision-Language Alignment for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5c5f321353dafe2a43ef25cb0d6e9714f833a5bb\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1813915\",\"name\":\"S. Liu\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1145/3240508.3240667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"849642b4701ac11c035326069f707f23a51a6f1a\",\"title\":\"SibNet: Sibling Convolutional Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/849642b4701ac11c035326069f707f23a51a6f1a\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387016\",\"name\":\"Ziwei Yang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3123266.3127904\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7a736b7347fc5ea93c196ddfe0630ecddc17d324\",\"title\":\"Multirate Multimodal Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7a736b7347fc5ea93c196ddfe0630ecddc17d324\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"2007.14164\",\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58548-8_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5fb52197928290d3020b2256ccab22d5bf93c366\",\"title\":\"Learning Modality Interaction for Temporal Sentence Localization and Event Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5fb52197928290d3020b2256ccab22d5bf93c366\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1907.10255\",\"authors\":[{\"authorId\":\"8809422\",\"name\":\"Vishwanath Sindagi\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/TIP.2019.2928634\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f8a1d07216259a87fe8968feb9379c14629ad9f\",\"title\":\"HA-CCN: Hierarchical Attention-Based Crowd Counting Network\",\"url\":\"https://www.semanticscholar.org/paper/8f8a1d07216259a87fe8968feb9379c14629ad9f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144850642\",\"name\":\"W. Ren\"},{\"authorId\":\"47538816\",\"name\":\"Jingang Zhang\"},{\"authorId\":\"2291143\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1719250\",\"name\":\"Xiaochun Cao\"},{\"authorId\":\"3182192\",\"name\":\"Gaofeng Meng\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/TIP.2018.2876178\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"281b8c4e4ed6a9237a5b65a6f95048882340253c\",\"title\":\"Deep Video Dehazing With Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/281b8c4e4ed6a9237a5b65a6f95048882340253c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8387016\",\"name\":\"Ziwei Yang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"50219447\",\"name\":\"Zheng Wang\"}],\"doi\":\"10.1145/3123266.3123327\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abc2e6431a7092fb11418b79ca1c41a76b811ea0\",\"title\":\"Catching the Temporal Regions-of-Interest for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/abc2e6431a7092fb11418b79ca1c41a76b811ea0\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1901.00976\",\"authors\":[{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2019.00503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"675b96a38f37f92043189d7e90377a6b41a2a9cd\",\"title\":\"Contrastive Adaptation Network for Unsupervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/675b96a38f37f92043189d7e90377a6b41a2a9cd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.09412\",\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c970f99e844f774236511a40bf43b8950dde339f\",\"title\":\"Cubic LSTMs for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c970f99e844f774236511a40bf43b8950dde339f\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"49418159\",\"name\":\"Y. Wang\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/TCSVT.2019.2894161\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c75881e226b5d57e1c5570bf8e51a93bdada9e8\",\"title\":\"stagNet: An Attentive Semantic RNN for Group Activity and Individual Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c75881e226b5d57e1c5570bf8e51a93bdada9e8\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020}],\"corpusId\":18360943,\"doi\":\"10.1109/CVPR.2017.147\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"533d14e539ae5cdca0ece392487a2b19106d468a\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.06309\",\"authors\":[{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"},{\"authorId\":\"34653454\",\"name\":\"A. Handa\"},{\"authorId\":\"1745672\",\"name\":\"R. Cipolla\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"title\":\"Spatio-temporal video autoencoder with differentiable memory\",\"url\":\"https://www.semanticscholar.org/paper/b6e7d0ec83f2a40fadc99bb0f1ced8508f5cfee5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R Girshick\"},{\"authorId\":null,\"name\":\"R Fast\"},{\"authorId\":null,\"name\":\"Cnn\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICCV\",\"url\":\"\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1503.04144\",\"authors\":[{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"1689313\",\"name\":\"Florian Luisier\"},{\"authorId\":\"144941335\",\"name\":\"Walter Andrews\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":\"10.5244/C.29.60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"title\":\"Exploiting Image-trained CNN Architectures for Unconstrained Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/dc9bd029276ec08a4c57c5fbf6df22190aa28d78\",\"venue\":\"BMVC\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Kiros\"},{\"authorId\":null,\"name\":\"Y. Zhu\"},{\"authorId\":null,\"name\":\"R. R. Salakhutdinov\"},{\"authorId\":null,\"name\":\"R. Zemel\"},{\"authorId\":null,\"name\":\"R. Urtasun\"},{\"authorId\":null,\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A method for stochastic optimization\",\"url\":\"\",\"venue\":\"In ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Torabi\"},{\"authorId\":null,\"name\":\"K. Cho\"},{\"authorId\":null,\"name\":\"N. Ballas\"},{\"authorId\":null,\"name\":\"C. Pal\"},{\"authorId\":null,\"name\":\"H. Larochelle\"},{\"authorId\":null,\"name\":\"A. Courville\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"UTS - CMU at THUMOS\",\"url\":\"\",\"venue\":\"THUMOS Challenge\",\"year\":2015},{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1605.08695\",\"authors\":[{\"authorId\":\"51284110\",\"name\":\"M. Abadi\"},{\"authorId\":\"144758007\",\"name\":\"P. Barham\"},{\"authorId\":\"47740021\",\"name\":\"J. Chen\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"36347083\",\"name\":\"Andy Davis\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"1780892\",\"name\":\"Sanjay Ghemawat\"},{\"authorId\":\"145659929\",\"name\":\"Geoffrey Irving\"},{\"authorId\":\"73195837\",\"name\":\"M. Isard\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"},{\"authorId\":\"3369421\",\"name\":\"Josh Levenberg\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"144375552\",\"name\":\"Sherry Moore\"},{\"authorId\":\"20154699\",\"name\":\"D. Murray\"},{\"authorId\":\"32163737\",\"name\":\"B. Steiner\"},{\"authorId\":\"2080690\",\"name\":\"P. Tucker\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"47941411\",\"name\":\"Pete Warden\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"145167058\",\"name\":\"Y. Yu\"},{\"authorId\":\"47957022\",\"name\":\"Xiaoqiang Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46200b99c40e8586c8a0f588488ab6414119fb28\",\"title\":\"TensorFlow: A system for large-scale machine learning\",\"url\":\"https://www.semanticscholar.org/paper/46200b99c40e8586c8a0f588488ab6414119fb28\",\"venue\":\"OSDI\",\"year\":2016},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"},{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"34f25a8704614163c4095b3ee2fc969b60de4698\",\"title\":\"Dropout: a simple way to prevent neural networks from overfitting\",\"url\":\"https://www.semanticscholar.org/paper/34f25a8704614163c4095b3ee2fc969b60de4698\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1402.3511\",\"authors\":[{\"authorId\":\"2865775\",\"name\":\"J. Koutn\\u00edk\"},{\"authorId\":\"3035541\",\"name\":\"Klaus Greff\"},{\"authorId\":\"145842938\",\"name\":\"F. Gomez\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5522764282c85aea422f1c4dc92ff7e0ca6987bc\",\"title\":\"A Clockwork RNN\",\"url\":\"https://www.semanticscholar.org/paper/5522764282c85aea422f1c4dc92ff7e0ca6987bc\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10129966\",\"name\":\"D. Schacter\"},{\"authorId\":\"1882520\",\"name\":\"D. Addis\"},{\"authorId\":\"1838779\",\"name\":\"D. Hassabis\"},{\"authorId\":\"144865533\",\"name\":\"V. C. Mart\\u00edn\"},{\"authorId\":\"2836333\",\"name\":\"R. N. Spreng\"},{\"authorId\":\"2375292\",\"name\":\"K. Szpunar\"}],\"doi\":\"10.1016/j.neuron.2012.11.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a6472998c8da1a20213877cca72d9966aea08e7\",\"title\":\"The Future of Memory: Remembering, Imagining, and the Brain\",\"url\":\"https://www.semanticscholar.org/paper/4a6472998c8da1a20213877cca72d9966aea08e7\",\"venue\":\"Neuron\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1312.4569\",\"authors\":[{\"authorId\":\"40094154\",\"name\":\"Vu Pham\"},{\"authorId\":\"2156685\",\"name\":\"Christopher Kermorvant\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"}],\"doi\":\"10.1109/ICFHR.2014.55\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0b624c46b51920dfec5aa02cc86323c0beb0df5\",\"title\":\"Dropout Improves Recurrent Neural Networks for Handwriting Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0b624c46b51920dfec5aa02cc86323c0beb0df5\",\"venue\":\"2014 14th International Conference on Frontiers in Handwriting Recognition\",\"year\":2014},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Devin\"},{\"authorId\":null,\"name\":\"M. Isard\"},{\"authorId\":null,\"name\":\"M. Kudlur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"TRECVID MED 13\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1301.3781\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"title\":\"Efficient Estimation of Word Representations in Vector Space\",\"url\":\"https://www.semanticscholar.org/paper/330da625c15427c6e42ccfa3b747fb29e5835bf0\",\"venue\":\"ICLR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. L. Schacter\"},{\"authorId\":null,\"name\":\"D. R. Addis\"},{\"authorId\":null,\"name\":\"D. Hassabis\"},{\"authorId\":null,\"name\":\"V. C. Martin\"},{\"authorId\":null,\"name\":\"R. N. Spreng\"},{\"authorId\":null,\"name\":\"K. K. Szpunar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"The future of memory: Remembering\",\"url\":\"\",\"venue\":\"imagining, and the brain. Neuron, 76(4):677\\u2013694\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Simonyan\"},{\"authorId\":null,\"name\":\"A.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Zisserman . Twostream convolutional networks for action recognition in videos\",\"url\":\"\",\"venue\":\"\",\"year\":2012},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c285082615c8ef7301321e457c91905b40d2a39\",\"title\":\"UTS-CMU at THUMOS 2015\",\"url\":\"https://www.semanticscholar.org/paper/4c285082615c8ef7301321e457c91905b40d2a39\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Koutnik\"},{\"authorId\":null,\"name\":\"K Greff\"},{\"authorId\":null,\"name\":\"F Gomez\"},{\"authorId\":null,\"name\":\"J Schmidhuber\"},{\"authorId\":null,\"name\":\"Rnn Clockwork\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"ICML\",\"url\":\"\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/CVPR.2015.7298616\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4006\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298789\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"title\":\"A discriminative CNN video representation for event detection\",\"url\":\"https://www.semanticscholar.org/paper/10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1511.03476\",\"authors\":[{\"authorId\":\"1991108\",\"name\":\"P. Pan\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2016.117\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9a66904559011d48245bba01e55f72246927e77\",\"title\":\"Hierarchical Recurrent Neural Encoder for Video Representation with Application to Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e9a66904559011d48245bba01e55f72246927e77\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z Xu\"},{\"authorId\":null,\"name\":\"L Zhu\"},{\"authorId\":null,\"name\":\"Y Yang\"},{\"authorId\":null,\"name\":\"A G Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"UTS-CMU at THUMOS 2015. THUMOS Challenge\",\"url\":\"\",\"venue\":\"UTS-CMU at THUMOS 2015. THUMOS Challenge\",\"year\":2015},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"},{\"authorId\":\"40508553\",\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45815fb24d9d699f3ac2ba8b2481ee3f80bd477b\",\"title\":\"Complex Event Detection using Semantic Saliency and Nearly-Isotonic SVM\",\"url\":\"https://www.semanticscholar.org/paper/45815fb24d9d699f3ac2ba8b2481ee3f80bd477b\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/CVPR.2010.5540039\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"400e09ceca374f0621335f84a4daf2049d5902be\",\"title\":\"Aggregating local descriptors into a compact image representation\",\"url\":\"https://www.semanticscholar.org/paper/400e09ceca374f0621335f84a4daf2049d5902be\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.04670\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ed7d774684a1770445c1c53e276011a8364b9e2\",\"title\":\"Uncovering Temporal Context for Video Question and Answering\",\"url\":\"https://www.semanticscholar.org/paper/9ed7d774684a1770445c1c53e276011a8364b9e2\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012}],\"title\":\"Bidirectional Multirate Reconstruction for Temporal Modeling in Videos\",\"topics\":[{\"topic\":\"Feature learning\",\"topicId\":\"20551\",\"url\":\"https://www.semanticscholar.org/topic/20551\"},{\"topic\":\"Unsupervised learning\",\"topicId\":\"7721\",\"url\":\"https://www.semanticscholar.org/topic/7721\"},{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Feature (computer vision)\",\"topicId\":\"25652\",\"url\":\"https://www.semanticscholar.org/topic/25652\"},{\"topic\":\"Mac OS X 10.4 Tiger\",\"topicId\":\"60932\",\"url\":\"https://www.semanticscholar.org/topic/60932\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"}],\"url\":\"https://www.semanticscholar.org/paper/533d14e539ae5cdca0ece392487a2b19106d468a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"