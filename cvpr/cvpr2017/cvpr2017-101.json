"{\"abstract\":\"We propose a novel framework named StyleNet to address the task of generating attractive captions for images and videos with different styles. To this end, we devise a novel model component, named factored LSTM, which automatically distills the style factors in the monolingual text corpus. Then at runtime, we can explicitly control the style in the caption generation process so as to produce attractive visual captions with the desired style. Our approach achieves this goal by leveraging two sets of data: 1) factual image/video-caption paired data, and 2) stylized monolingual text data (e.g., romantic and humorous sentences). We show experimentally that StyleNet outperforms existing approaches for generating visual captions with different styles, measured in both automatic and human evaluation metrics on the newly collected FlickrStyle10K image caption dataset, which contains 10K Flickr images with corresponding humorous and romantic captions.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\",\"url\":\"https://www.semanticscholar.org/author/144158271\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\",\"url\":\"https://www.semanticscholar.org/author/144702900\"},{\"authorId\":\"144137069\",\"name\":\"X. He\",\"url\":\"https://www.semanticscholar.org/author/144137069\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\",\"url\":\"https://www.semanticscholar.org/author/1800422\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\",\"url\":\"https://www.semanticscholar.org/author/144718788\"}],\"citationVelocity\":38,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/CVPR.2018.00808\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"title\":\"Visual Grounding via Accumulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/8d1c8dd0559642a3bdd5c7234d2ce4611e911e23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.04364\",\"authors\":[{\"authorId\":\"3101288\",\"name\":\"Qiongkai Xu\"},{\"authorId\":\"14352700\",\"name\":\"Juyan Zhang\"},{\"authorId\":\"14564042\",\"name\":\"Lizhen Qu\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1718786\",\"name\":\"R. Nock\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d407ad82df08aed159c86606161dff6a32386968\",\"title\":\"D-PAGE: Diverse Paraphrase Generation\",\"url\":\"https://www.semanticscholar.org/paper/d407ad82df08aed159c86606161dff6a32386968\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.03879\",\"authors\":[{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f66f124bcfa4c3d9d0e54af0c1103f1219c1c8c\",\"title\":\"Knowledge Aided Consistency for Weakly Supervised Phrase Grounding\",\"url\":\"https://www.semanticscholar.org/paper/0f66f124bcfa4c3d9d0e54af0c1103f1219c1c8c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.07894\",\"authors\":[{\"authorId\":\"4947404\",\"name\":\"Zhirui Zhang\"},{\"authorId\":\"2017195\",\"name\":\"Shuo Ren\"},{\"authorId\":\"1803054\",\"name\":\"Shujie Liu\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"},{\"authorId\":null,\"name\":\"Peng Chen\"},{\"authorId\":null,\"name\":\"Mu Li\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1200a733652f744ba0d86ed38aafbdcbd9c2723\",\"title\":\"Style Transfer as Unsupervised Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/f1200a733652f744ba0d86ed38aafbdcbd9c2723\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.08205\",\"authors\":[{\"authorId\":\"2365530\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1726601\",\"name\":\"Rebecca Hwa\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a425e30375e3dd3cb9afed5dc31d2bda8e82384f\",\"title\":\"Equal But Not The Same: Understanding the Implicit Relationship Between Persuasive Images and Text\",\"url\":\"https://www.semanticscholar.org/paper/a425e30375e3dd3cb9afed5dc31d2bda8e82384f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"2348236\",\"name\":\"Fuyuan Hu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TMM.2019.2894964\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb722f44a88a5138c26fcc4b0299ca5a6cf729ac\",\"title\":\"Attend and Imagine: Multi-Label Image Classification With Visual Attention and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fb722f44a88a5138c26fcc4b0299ca5a6cf729ac\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1905.12926\",\"authors\":[{\"authorId\":\"50394960\",\"name\":\"Ke Wang\"},{\"authorId\":\"33851005\",\"name\":\"Hang Hua\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"35577859fcbb1f1911021e6d5bc4a489558eab79\",\"title\":\"Controllable Unsupervised Text Attribute Transfer via Editing Entangled Latent Representation\",\"url\":\"https://www.semanticscholar.org/paper/35577859fcbb1f1911021e6d5bc4a489558eab79\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1902.08327\",\"authors\":[{\"authorId\":\"4500245\",\"name\":\"Ting-Yao Hsu\"},{\"authorId\":\"2465856\",\"name\":\"Yen-Chia Hsu\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"}],\"doi\":\"10.1145/3290607.3312965\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d2b4e33f1b66b7ca8e28aedbd700299945e03f3\",\"title\":\"On How Users Edit Computer-Generated Visual Stories\",\"url\":\"https://www.semanticscholar.org/paper/1d2b4e33f1b66b7ca8e28aedbd700299945e03f3\",\"venue\":\"CHI Extended Abstracts\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152969844\",\"name\":\"N. Zakharov\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"39197903\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2151203\",\"name\":\"J. Gl\\u00e4scher\"}],\"doi\":\"10.1016/J.JVCIR.2019.102574\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e0d5efef6e620050435280f8a3e2df982dce8ea\",\"title\":\"Towards controllable image descriptions with semi-supervised VAE\",\"url\":\"https://www.semanticscholar.org/paper/1e0d5efef6e620050435280f8a3e2df982dce8ea\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00850\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.02923\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":\"10.1613/jair.1.12025\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"title\":\"Image Captioning using Facial Expression and Attention\",\"url\":\"https://www.semanticscholar.org/paper/29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145093155\",\"name\":\"Min Xu\"},{\"authorId\":\"1677510167\",\"name\":\"Lingxiang Wu\"},{\"authorId\":\"121134294\",\"name\":\"S. Qian\"},{\"authorId\":\"3061725\",\"name\":\"Jianwei Cui\"}],\"doi\":\"10.1145/3381858\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"238611bc2a79d64271a2238cf164bcfde3e5cb13\",\"title\":\"Image to Modern Chinese Poetry Creation via a Constrained Topic-aware Model\",\"url\":\"https://www.semanticscholar.org/paper/238611bc2a79d64271a2238cf164bcfde3e5cb13\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1907.11496\",\"authors\":[{\"authorId\":\"144523744\",\"name\":\"X. Wang\"},{\"authorId\":\"143847264\",\"name\":\"B. Wu\"},{\"authorId\":\"72522575\",\"name\":\"Y. Ye\"},{\"authorId\":\"3288514\",\"name\":\"Y. Zhong\"}],\"doi\":\"10.1145/3343031.3350909\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8418b33a03804680fffd4b03aff0d95c29929deb\",\"title\":\"Outfit Compatibility Prediction and Diagnosis with Multi-Layered Comparison Network\",\"url\":\"https://www.semanticscholar.org/paper/8418b33a03804680fffd4b03aff0d95c29929deb\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1703.07022\",\"authors\":[{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"1682058\",\"name\":\"H. Zhang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/ICCV.2017.364\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428818a9edfb547431be6d7ec165c6af576c83d5\",\"title\":\"Recurrent Topic-Transition GAN for Visual Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/428818a9edfb547431be6d7ec165c6af576c83d5\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47011474\",\"name\":\"Kun Xiong\"},{\"authorId\":\"1807459832\",\"name\":\"Liu Jiang\"},{\"authorId\":\"39056715\",\"name\":\"Xuan Dang\"},{\"authorId\":\"50248791\",\"name\":\"G. Wang\"},{\"authorId\":\"1830569732\",\"name\":\"Wenwen Ye\"},{\"authorId\":\"1489386471\",\"name\":\"Zheng Qin\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dafb451fc3a51032c825eea6cc2037911089d47c\",\"title\":\"Towards Personalized Aesthetic Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dafb451fc3a51032c825eea6cc2037911089d47c\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2011.00416\",\"authors\":[{\"authorId\":\"145657309\",\"name\":\"D. Jin\"},{\"authorId\":\"8752221\",\"name\":\"Zhijing Jin\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"44bd6111520ebb7323e834d14aa8b2fe4e4b3b79\",\"title\":\"Deep Learning for Text Attribute Transfer: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/44bd6111520ebb7323e834d14aa8b2fe4e4b3b79\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"153017460\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":null,\"name\":\"Yan Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"title\":\"Variational Structured Semantic Inference for Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1887384857\",\"name\":\"Mingxuan Hu\"},{\"authorId\":\"144852481\",\"name\":\"Min He\"},{\"authorId\":\"144344946\",\"name\":\"W. Su\"},{\"authorId\":\"1490676314\",\"name\":\"Abdellah Chehri\"}],\"doi\":\"10.1007/s00530-020-00714-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4d640b97c2d0cdbc5a068a6e1a3b3919e91a297\",\"title\":\"A TextCNN and WGAN-gp based deep learning frame for unpaired text style transfer in multimedia services\",\"url\":\"https://www.semanticscholar.org/paper/c4d640b97c2d0cdbc5a068a6e1a3b3919e91a297\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Yunchen Pu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ce86da3e0a0ab5f6cf944cdfef7a607a61b16e2\",\"title\":\"Deep Generative Models for Image Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ce86da3e0a0ab5f6cf944cdfef7a607a61b16e2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.12510\",\"authors\":[{\"authorId\":\"2040795598\",\"name\":\"Daisheng Jin\"},{\"authorId\":\"115844431\",\"name\":\"X. Ma\"},{\"authorId\":\"7923989\",\"name\":\"Chongzhi Zhang\"},{\"authorId\":\"1414131756\",\"name\":\"Yizhuo Zhou\"},{\"authorId\":\"1484222417\",\"name\":\"Jiashu Tao\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"49453102\",\"name\":\"H. Zhao\"},{\"authorId\":\"48929393\",\"name\":\"Shuai Yi\"},{\"authorId\":\"2282019\",\"name\":\"Zhoujun Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"119885708\",\"name\":\"Hongsheng Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d30e7b068590697dac591023bbfde008b4a9132c\",\"title\":\"Towards Overcoming False Positives in Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/d30e7b068590697dac591023bbfde008b4a9132c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145816931\",\"name\":\"Gaurav Verma\"},{\"authorId\":\"1519982037\",\"name\":\"Suryateja Bv\"},{\"authorId\":\"1519989202\",\"name\":\"Samagra Sharma\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"}],\"doi\":\"10.1145/3377325.3377487\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"893154dbcd6c6c6d1c4913002de37d6e739cf5f2\",\"title\":\"Generating need-adapted multimodal fragments\",\"url\":\"https://www.semanticscholar.org/paper/893154dbcd6c6c6d1c4913002de37d6e739cf5f2\",\"venue\":\"IUI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48215680\",\"name\":\"Y. Abe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da4838756194c5d6bf4d4758baa1ce245fb953d4\",\"title\":\"Generative Adversarial Networks toward Representation Learning for Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/da4838756194c5d6bf4d4758baa1ce245fb953d4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":null,\"name\":\"Rui Wang\"},{\"authorId\":\"144241178\",\"name\":\"B. Lyu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/BigMM.2018.8499066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"title\":\"Image Captioning Based on Adaptive Balancing Loss\",\"url\":\"https://www.semanticscholar.org/paper/9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1908.09395\",\"authors\":[{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":\"10.18653/v1/D19-1325\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e986cdd257a64cd8628b2680cff33f0e47c6a772\",\"title\":\"Domain Adaptive Text Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/e986cdd257a64cd8628b2680cff33f0e47c6a772\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8837036\",\"name\":\"Kushal Singla\"},{\"authorId\":\"1695724\",\"name\":\"N. Mukherjee\"},{\"authorId\":\"2494103\",\"name\":\"Hari M. Koduvely\"},{\"authorId\":\"3134070\",\"name\":\"Joy Bose\"}],\"doi\":\"10.1109/INDICON45594.2018.8987165\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7daa16af08b190c9c8764f22e59ae650ad7d316f\",\"title\":\"Evaluating Usage of Images for App Classificatio\",\"url\":\"https://www.semanticscholar.org/paper/7daa16af08b190c9c8764f22e59ae650ad7d316f\",\"venue\":\"2018 15th IEEE India Council International Conference (INDICON)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"40034021\",\"name\":\"Y. Sun\"},{\"authorId\":\"145819866\",\"name\":\"J. Liang\"},{\"authorId\":\"144651371\",\"name\":\"B. Ren\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"}],\"doi\":\"10.1016/j.neucom.2018.03.078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"title\":\"Image captioning by incorporating affective concepts learned from both visual and textual components\",\"url\":\"https://www.semanticscholar.org/paper/adcd5dd4e851ffc0e3e23a4620095ef9b5ca2837\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1812.08989\",\"authors\":[{\"authorId\":\"49718206\",\"name\":\"L. Zhou\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"},{\"authorId\":\"144154486\",\"name\":\"H. Shum\"}],\"doi\":\"10.1162/coli_a_00368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66b7d31527f980bb2eecc23629f08ba6037facc4\",\"title\":\"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot\",\"url\":\"https://www.semanticscholar.org/paper/66b7d31527f980bb2eecc23629f08ba6037facc4\",\"venue\":\"Computational Linguistics\",\"year\":2018},{\"arxivId\":\"1906.01764\",\"authors\":[{\"authorId\":\"4500245\",\"name\":\"Ting-Yao Hsu\"},{\"authorId\":\"1414028847\",\"name\":\"Huang Chieh-Yang\"},{\"authorId\":\"2465856\",\"name\":\"Yen-Chia Hsu\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"}],\"doi\":\"10.18653/v1/p19-1658\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37fa5e2ab18e4c69b060b66bd602b55adddc0ba2\",\"title\":\"Visual Story Post-Editing\",\"url\":\"https://www.semanticscholar.org/paper/37fa5e2ab18e4c69b060b66bd602b55adddc0ba2\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"}],\"doi\":\"10.1109/CVPR.2018.00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2115fe369b3a6b859c6992ba023d5c11b1689801\",\"title\":\"GroupCap: Group-Based Image Captioning with Structured Relevance and Diversity Constraints\",\"url\":\"https://www.semanticscholar.org/paper/2115fe369b3a6b859c6992ba023d5c11b1689801\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.01475\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/CVPR.2019.01275\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"908c6b1577a1f5309ae183daf2e24363039f22a8\",\"title\":\"Good News, Everyone! Context Driven Entity-Aware Captioning for News Images\",\"url\":\"https://www.semanticscholar.org/paper/908c6b1577a1f5309ae183daf2e24363039f22a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672730\",\"name\":\"Chunyuan Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3c211c6e8dbea9849790a1c9491aed290a1e144\",\"title\":\"Towards Better Representations with Deep/Bayesian Learning\",\"url\":\"https://www.semanticscholar.org/paper/e3c211c6e8dbea9849790a1c9491aed290a1e144\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944765097\",\"name\":\"Beigeng Zhao\"}],\"doi\":\"10.1109/ACCESS.2020.3021312\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"title\":\"DrunaliaCap: Image Captioning for Drug-Related Paraphernalia With Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/acbbb090caf30b6f8bf140f03ebe912c9e6a8c6d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.00945\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"title\":\"Image-Chat: Engaging Grounded Conversations\",\"url\":\"https://www.semanticscholar.org/paper/b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1808.07311\",\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhang\"},{\"authorId\":\"47883405\",\"name\":\"Jingjing Xu\"},{\"authorId\":\"46709826\",\"name\":\"Pengcheng Yang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1138\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"054c5e07cdef8fb077ee19ff582fef3689e5e3e9\",\"title\":\"Learning Sentiment Memories for Sentiment Modification without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/054c5e07cdef8fb077ee19ff582fef3689e5e3e9\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3242155\",\"name\":\"Libin Jiao\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"4853966\",\"name\":\"H. Wang\"},{\"authorId\":\"145149132\",\"name\":\"R. Bie\"}],\"doi\":\"10.1109/ACCESS.2018.2882592\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f625ae421416c5c44df24ff89224562c0cdba3\",\"title\":\"Text Recovery via Deep CNN-BiLSTM Recognition and Bayesian Inference\",\"url\":\"https://www.semanticscholar.org/paper/e0f625ae421416c5c44df24ff89224562c0cdba3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"40281988\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3394171.3413908\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"title\":\"Controllable Video Captioning with an Exemplar Sentence\",\"url\":\"https://www.semanticscholar.org/paper/40b3dc37f80cb9981e7b77a8e898aa87e2e408e7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.00692\",\"authors\":[{\"authorId\":\"35345881\",\"name\":\"S. N. Chowdhury\"},{\"authorId\":\"2499758\",\"name\":\"Simon Razniewski\"},{\"authorId\":\"1751591\",\"name\":\"G. Weikum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"971bf8654232421843ba35e632c9602a5acdf341\",\"title\":\"Story-oriented Image Selection and Placement\",\"url\":\"https://www.semanticscholar.org/paper/971bf8654232421843ba35e632c9602a5acdf341\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92351120\",\"name\":\"Yuan Li\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"47058148\",\"name\":\"Xiujun Li\"},{\"authorId\":\"2250250\",\"name\":\"Guoqing Zheng\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1609/AAAI.V34I05.6346\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c07fde0164b1415180e72320094d0a12edb92b8\",\"title\":\"Complementary Auxiliary Classifiers for Label-Conditional Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/6c07fde0164b1415180e72320094d0a12edb92b8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2623871\",\"name\":\"Xinchen Liu\"},{\"authorId\":\"153092591\",\"name\":\"Meng Zhang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350857\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5e14849a01d23313556b7692a821090bfe2f97c\",\"title\":\"BraidNet: Braiding Semantics and Details for Accurate Human Parsing\",\"url\":\"https://www.semanticscholar.org/paper/b5e14849a01d23313556b7692a821090bfe2f97c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2007.09580\",\"authors\":[{\"authorId\":\"41036094\",\"name\":\"C. Deng\"},{\"authorId\":\"46649124\",\"name\":\"Ning Ding\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1007/978-3-030-58601-0_42\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2320f853059c29ce7e70409fa559074d727da5a2\",\"title\":\"Length-Controllable Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2320f853059c29ce7e70409fa559074d727da5a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1809.06214\",\"authors\":[{\"authorId\":null,\"name\":\"Cheng Kuan Chen\"},{\"authorId\":\"1383271298\",\"name\":\"Zhufeng Pan\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e79138fd656ebea59eb008fcb97c97be7be8007\",\"title\":\"Unsupervised Stylish Image Description Generation via Domain Layer Norm\",\"url\":\"https://www.semanticscholar.org/paper/5e79138fd656ebea59eb008fcb97c97be7be8007\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.02250\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"119899233\",\"name\":\"Len Hamey\"}],\"doi\":\"10.1007/978-3-030-10925-7_14\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"036c29c2c2a2494faae205c0f270ce4d076cc3f2\",\"title\":\"Face-Cap: Image Captioning using Facial Expression Analysis\",\"url\":\"https://www.semanticscholar.org/paper/036c29c2c2a2494faae205c0f270ce4d076cc3f2\",\"venue\":\"ECML/PKDD\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9421fa26257e6a8d59bb874cf3b376c6d4c4118b\",\"title\":\"MemCap: Memorizing Style Knowledge for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9421fa26257e6a8d59bb874cf3b376c6d4c4118b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1910.06426\",\"authors\":[{\"authorId\":\"23999166\",\"name\":\"Shuangjie Xu\"},{\"authorId\":\"143979421\",\"name\":\"F. Xu\"},{\"authorId\":\"153655416\",\"name\":\"Yu Cheng\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"title\":\"Tell-the-difference: Fine-grained Visual Descriptor via a Discriminating Referee\",\"url\":\"https://www.semanticscholar.org/paper/dc9b8dbd11e3786d6f8dee167a8b8353a0b8ffd1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042704741\",\"name\":\"Xiaohan Zou\"},{\"authorId\":\"144289788\",\"name\":\"C. Lin\"},{\"authorId\":\"2042741172\",\"name\":\"Yinjia Zhang\"},{\"authorId\":\"1729695\",\"name\":\"Qinpei Zhao\"}],\"doi\":\"10.1109/ICTAI50040.2020.00124\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8465dc22e66853636edce1cd537317120ecfcbb\",\"title\":\"To be an Artist: Automatic Generation on Food Image Aesthetic Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f8465dc22e66853636edce1cd537317120ecfcbb\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1708.02478\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2018.2851077\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d78c47093fbf3d85225fd502674aba4a29b3987\",\"title\":\"From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d78c47093fbf3d85225fd502674aba4a29b3987\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.02943\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"},{\"authorId\":\"119899233\",\"name\":\"Len Hamey\"}],\"doi\":\"10.1007/978-3-030-29908-8_22\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d236d1415ac9a52ec599f0c100e15589cfceefd9\",\"title\":\"Towards Generating Stylized Image Captions via Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/d236d1415ac9a52ec599f0c100e15589cfceefd9\",\"venue\":\"PRICAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2033733225\",\"name\":\"Mukuntha Narayanan Sundararaman\"},{\"authorId\":\"32740723\",\"name\":\"Z. Ahmad\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bf7159ff13aa4f1811b75febb84044e56ada0ee\",\"title\":\"Unsupervised Aspect-Level Sentiment Controllable Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1bf7159ff13aa4f1811b75febb84044e56ada0ee\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65827589\",\"name\":\"Nivetha Vijayaraju\"}],\"doi\":\"10.31979/etd.vm9n-39ed\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ede7e0721133697781fa3bb4b09e5a99373ab803\",\"title\":\"Image Retrieval Using Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ede7e0721133697781fa3bb4b09e5a99373ab803\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.08543\",\"authors\":[{\"authorId\":\"152601809\",\"name\":\"Minh Thu Nguyen\"},{\"authorId\":\"6195410\",\"name\":\"D. Phung\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"2008200586\",\"name\":\"Thien Huu Nguyen\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.411\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"title\":\"Structural and Functional Decomposition for Personality Image Captioning in a Communication Game\",\"url\":\"https://www.semanticscholar.org/paper/28ffdee5f50398202f236fd088fbc0c624b9f9ce\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00433\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1912.12144\",\"authors\":[{\"authorId\":\"8837036\",\"name\":\"Kushal Singla\"},{\"authorId\":\"1695724\",\"name\":\"N. Mukherjee\"},{\"authorId\":\"2494103\",\"name\":\"Hari M. Koduvely\"},{\"authorId\":\"120462071\",\"name\":\"Joy Bose\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e15f0e098178a5bb3a14b1738b282d0daf4b288\",\"title\":\"Evaluating Usage of Images for App Classification\",\"url\":\"https://www.semanticscholar.org/paper/5e15f0e098178a5bb3a14b1738b282d0daf4b288\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3351094\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0b12c784965baac88b6597890303fa834fa9eea\",\"title\":\"Watch, Reason and Code: Learning to Represent Videos Using Program\",\"url\":\"https://www.semanticscholar.org/paper/c0b12c784965baac88b6597890303fa834fa9eea\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1830455445\",\"name\":\"Nishant Prabhu\"},{\"authorId\":\"1704709\",\"name\":\"Vasudeva Varma\"},{\"authorId\":\"2881425\",\"name\":\"Balaji Vasan Srinivasan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30b9a631d23b756680da6c27f44b254997d98c3d\",\"title\":\"Text Simplification: From Daedalian to Simple\",\"url\":\"https://www.semanticscholar.org/paper/30b9a631d23b756680da6c27f44b254997d98c3d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1802.10240\",\"authors\":[{\"authorId\":\"3174935\",\"name\":\"Wenshan Wang\"},{\"authorId\":\"4456978\",\"name\":\"S. Yang\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2985995\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1049/iet-cvi.2019.0361\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2f950677e6a42beb234e507b3022964980b6556\",\"title\":\"Neural Aesthetic Image Reviewer\",\"url\":\"https://www.semanticscholar.org/paper/e2f950677e6a42beb234e507b3022964980b6556\",\"venue\":\"IET Comput. Vis.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"},{\"authorId\":\"49697077\",\"name\":\"Yue-Lin Sun\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206632\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03a53b48a2c869658f969856acd2830711dc9ba9\",\"title\":\"Extricating from GroundTruth: An Unpaired Learning Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/03a53b48a2c869658f969856acd2830711dc9ba9\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1711.07613\",\"authors\":[{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"144282676\",\"name\":\"Peng Wang\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dde6ed569684356c46217fa53224272b668bae8\",\"title\":\"Are You Talking to Me? Reasoned Visual Dialog Generation Through Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dde6ed569684356c46217fa53224272b668bae8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.06437\",\"authors\":[{\"authorId\":\"2965260\",\"name\":\"Juncen Li\"},{\"authorId\":\"3422908\",\"name\":\"Robin Jia\"},{\"authorId\":\"144533687\",\"name\":\"He He\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":\"10.18653/v1/N18-1169\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1975ae6d8693eedfb07d5348798351fe51ab242b\",\"title\":\"Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1975ae6d8693eedfb07d5348798351fe51ab242b\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.14257\",\"authors\":[{\"authorId\":\"21626987\",\"name\":\"Aman Madaan\"},{\"authorId\":\"80366270\",\"name\":\"Amrith Rajagopal Setlur\"},{\"authorId\":\"46719088\",\"name\":\"Tanmay Parekh\"},{\"authorId\":\"1719347\",\"name\":\"B. P\\u00f3czos\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"},{\"authorId\":\"9358910\",\"name\":\"Shrimai Prabhumoye\"}],\"doi\":\"10.18653/v1/2020.acl-main.169\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80257b7d02ad4d6a762ebc0d7f1560e0ef182354\",\"title\":\"Politeness Transfer: A Tag and Generate Approach\",\"url\":\"https://www.semanticscholar.org/paper/80257b7d02ad4d6a762ebc0d7f1560e0ef182354\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2325845\",\"name\":\"Ching-Han Chen\"},{\"authorId\":\"2029365216\",\"name\":\"Ming-Fang Shiu\"}],\"doi\":\"10.1109/ICCE-Taiwan49838.2020.9258014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e29be5ca20a259a34e917a957101fa307258ec2\",\"title\":\"Smart guiding glasses with descriptive video service and spoken dialogue system for visually impaired\",\"url\":\"https://www.semanticscholar.org/paper/6e29be5ca20a259a34e917a957101fa307258ec2\",\"venue\":\"2020 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-Taiwan)\",\"year\":2020},{\"arxivId\":\"1711.08447\",\"authors\":[{\"authorId\":\"2257769\",\"name\":\"Xintong Han\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"144494743\",\"name\":\"Zhe Wu\"},{\"authorId\":\"2180291\",\"name\":\"Ruichi Yu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2018.00787\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"473993aad08d6e1967ad692513e7c539f07b780e\",\"title\":\"VITON: An Image-Based Virtual Try-on Network\",\"url\":\"https://www.semanticscholar.org/paper/473993aad08d6e1967ad692513e7c539f07b780e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1805.07030\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1109/CVPR.2018.00896\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"title\":\"SemStyle: Learning to Generate Stylised Image Captions Using Unaligned Text\",\"url\":\"https://www.semanticscholar.org/paper/beeebd2af0d8f130dcf234231de4569d584cb7fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2008.10966\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"47268124\",\"name\":\"T. Li\"},{\"authorId\":\"46499812\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1007/978-3-030-58536-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"title\":\"In-Home Daily-Life Captioning Using Radio Signals\",\"url\":\"https://www.semanticscholar.org/paper/fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.14451\",\"authors\":[{\"authorId\":\"21771052\",\"name\":\"Allen Nie\"},{\"authorId\":\"1398108805\",\"name\":\"Reuben Cohn-Gordon\"},{\"authorId\":\"144922861\",\"name\":\"Christopher Potts\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88c86523d500d636f453647385ddaa04085b5f1b\",\"title\":\"Pragmatic Issue-Sensitive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/88c86523d500d636f453647385ddaa04085b5f1b\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34963191\",\"name\":\"Angus G. Forbes\"}],\"doi\":\"10.7238/a.v0i26.3370\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffcfcb8d7bc728d9f81e663f3b043910aa58f4c3\",\"title\":\"\\u00abCreative AI: From Expressive Mimicry to Critical Inquiry\\u00bb\",\"url\":\"https://www.semanticscholar.org/paper/ffcfcb8d7bc728d9f81e663f3b043910aa58f4c3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"title\":\"ENGAGING IMAGE CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47130190\",\"name\":\"Song Liu\"},{\"authorId\":\"14895949\",\"name\":\"Jiawei Zhan\"},{\"authorId\":\"1500394033\",\"name\":\"Zhengding Luo\"},{\"authorId\":\"1500393714\",\"name\":\"Gege Qi\"},{\"authorId\":\"49836169\",\"name\":\"Zhiqiang Bai\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/ICTAI.2019.00050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecfef3cb71299d933d096f5ad0081bb179b9e6ef\",\"title\":\"Deep Captioning Hashing Network for Complex Scene Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/ecfef3cb71299d933d096f5ad0081bb179b9e6ef\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5c35e70954a05ec4b836f166882982f459eefa\",\"title\":\"Adaptive Feature Abstraction for Translating Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/4b5c35e70954a05ec4b836f166882982f459eefa\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1801.01957\",\"authors\":[{\"authorId\":\"144154486\",\"name\":\"H. Shum\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"}],\"doi\":\"10.1631/FITEE.1700826\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"60e6d991462d3995cdb6079e5e49ee40e5a583b4\",\"title\":\"From Eliza to XiaoIce: challenges and opportunities with social chatbots\",\"url\":\"https://www.semanticscholar.org/paper/60e6d991462d3995cdb6079e5e49ee40e5a583b4\",\"venue\":\"Frontiers of Information Technology & Electronic Engineering\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.01822\",\"authors\":[{\"authorId\":\"9358910\",\"name\":\"Shrimai Prabhumoye\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0f77fe7fc62ec627db40aa8deb40de06cfe8be4\",\"title\":\"Exploring Controllable Text Generation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/f0f77fe7fc62ec627db40aa8deb40de06cfe8be4\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":\"1806.04510\",\"authors\":[{\"authorId\":\"1411254465\",\"name\":\"V. AbelL.Peirson\"},{\"authorId\":\"9934480\",\"name\":\"E. Tolunay\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"47ec091ba9d916e391c2f4e8ec36edcb59d104d6\",\"title\":\"Dank Learning: Generating Memes Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/47ec091ba9d916e391c2f4e8ec36edcb59d104d6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.09789\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9347ee91bf90129582e7ed414d23ad3495180235\",\"title\":\"Senti-Attend: Image Captioning using Sentiment and Attention\",\"url\":\"https://www.semanticscholar.org/paper/9347ee91bf90129582e7ed414d23ad3495180235\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897421\",\"name\":\"Rachel N. Simons\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62cd6ac2eaadf030eac67d9ec33554daee05e178\",\"title\":\"\\\"I Hope This Is Helpful\\\": Understanding Crowdworkers\\u2019 Challenges and Motivations for an Image Description Task\",\"url\":\"https://www.semanticscholar.org/paper/62cd6ac2eaadf030eac67d9ec33554daee05e178\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"title\":\"Engaging Image Chat: Modeling Personality in Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.02214\",\"authors\":[{\"authorId\":\"50087162\",\"name\":\"Yixuan Su\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":\"152134464\",\"name\":\"S. Baker\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3028405\",\"name\":\"Xiaojiang Liu\"},{\"authorId\":\"145762465\",\"name\":\"Anna Korhonen\"},{\"authorId\":\"50638196\",\"name\":\"Nigel Collier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d645d1b87e4f0bb371fd95fc9cb890d3a6cd8de1\",\"title\":\"Prototype-to-Style: Dialogue Generation with Style-Aware Editing on Retrieval Memory\",\"url\":\"https://www.semanticscholar.org/paper/d645d1b87e4f0bb371fd95fc9cb890d3a6cd8de1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.00403\",\"authors\":[{\"authorId\":\"115950550\",\"name\":\"M. Tran\"},{\"authorId\":\"2760404\",\"name\":\"Yipeng Zhang\"},{\"authorId\":\"143626389\",\"name\":\"M. Soleymani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ff6503218bd68227315c8a051d5e84f64533c1a\",\"title\":\"Towards A Friendly Online Community: An Unsupervised Style Transfer Framework for Profanity Redaction\",\"url\":\"https://www.semanticscholar.org/paper/7ff6503218bd68227315c8a051d5e84f64533c1a\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038515405\",\"name\":\"Yazid Bounab\"},{\"authorId\":\"1471224685\",\"name\":\"Mourad Oussalah\"},{\"authorId\":\"2038543683\",\"name\":\"Ahlam Ferdenache\"}],\"doi\":\"10.1109/IPTA50016.2020.9286602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"title\":\"Reconciling Image Captioning and User\\u2019s Comments for Urban Tourism\",\"url\":\"https://www.semanticscholar.org/paper/12246cc5d29c1d8d7177d7a6e820fe3038ccd1d5\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d42142285c46207a16bd4294e437d504e419a9b7\",\"title\":\"Varying image description tasks: spoken versus written descriptions\",\"url\":\"https://www.semanticscholar.org/paper/d42142285c46207a16bd4294e437d504e419a9b7\",\"venue\":\"VarDial@COLING 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79893149\",\"name\":\"A. L. Peirson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0509ab96c57189720bd5dad4eca655888f70071\",\"title\":\"C L ] 8 J un 2 01 8 Dank Learning : Generating Memes Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e0509ab96c57189720bd5dad4eca655888f70071\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144897421\",\"name\":\"Rachel N. Simons\"},{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"3079031\",\"name\":\"Kenneth R. Fleischmann\"}],\"doi\":\"10.1145/3415176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"title\":\"\\\"I Hope This Is Helpful\\\"\",\"url\":\"https://www.semanticscholar.org/paper/f2d4b8de7f9ed9a1a0b403e9f1ad9365b599c5ad\",\"venue\":\"Proc. ACM Hum. Comput. Interact.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39491387\",\"name\":\"J. Zhou\"},{\"authorId\":\"21576252\",\"name\":\"Jiangbo Ai\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"}],\"doi\":\"10.1109/TIP.2018.2855422\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd3d94fac6a282414406716040b10c1746634ecd\",\"title\":\"Video Captioning by Adversarial LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fd3d94fac6a282414406716040b10c1746634ecd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120800460\",\"name\":\"L. Zhou\"},{\"authorId\":\"98110081\",\"name\":\"J. Gao\"},{\"authorId\":\"49620738\",\"name\":\"Di Li\"},{\"authorId\":\"70362337\",\"name\":\"Heung-Yeung Shum\"}],\"doi\":\"10.1162/coli_a_00368\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3737b57e8b739b595cd5b877769cbc719c42f2c7\",\"title\":\"The Design and Implementation of XiaoIce, an Empathetic Social Chatbot\",\"url\":\"https://www.semanticscholar.org/paper/3737b57e8b739b595cd5b877769cbc719c42f2c7\",\"venue\":\"Computational Linguistics\",\"year\":2020},{\"arxivId\":\"1712.02051\",\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"49490596\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d190282ed59639b16e726a3237938b53976077\",\"title\":\"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d190282ed59639b16e726a3237938b53976077\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005646844\",\"name\":\"Bruno Caldas Vianna\"}],\"doi\":\"10.7238/a.v0i26.3350\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"83f31d066609324443380a1883474f5b936be9f3\",\"title\":\"Generative Art: Between the Nodes of Neuron Networks\",\"url\":\"https://www.semanticscholar.org/paper/83f31d066609324443380a1883474f5b936be9f3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2002.08565\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"150353841\",\"name\":\"Yinan Zhao\"},{\"authorId\":\"1409765557\",\"name\":\"Meng Zhang\"},{\"authorId\":\"23364558\",\"name\":\"Nilavra Bhattacharya\"}],\"doi\":\"10.1007/978-3-030-58520-4_25\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c936d878003254cdab662a966cecd29e8be652d0\",\"title\":\"Captioning Images Taken by People Who Are Blind\",\"url\":\"https://www.semanticscholar.org/paper/c936d878003254cdab662a966cecd29e8be652d0\",\"venue\":\"ECCV\",\"year\":2020}],\"corpusId\":23414983,\"doi\":\"10.1109/CVPR.2017.108\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":11,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"references\":[{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1504.08083\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2015.169\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"title\":\"Fast R-CNN\",\"url\":\"https://www.semanticscholar.org/paper/7ffdbc358b63378f07311e883dddacc9faeeaf4b\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Gella\"},{\"authorId\":null,\"name\":\"M. Mitchell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Residual multiple instance learning for visually impaired image descriptions\",\"url\":\"\",\"venue\":\"NIPS Women in Machine Learning Workshop,\",\"year\":2016},{\"arxivId\":\"1605.07912\",\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"title\":\"Encode, Review, and Decode: Reviewer Module for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1509.07225\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/ICCV.2015.298\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d925db7c9e3cca2e8fed644f750d218a48cd081\",\"title\":\"Automatic Concept Discovery from Parallel Text and Visual Corpora\",\"url\":\"https://www.semanticscholar.org/paper/4d925db7c9e3cca2e8fed644f750d218a48cd081\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1756655\",\"name\":\"C. L. Teo\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"title\":\"Corpus-Guided Sentence Generation of Natural Images\",\"url\":\"https://www.semanticscholar.org/paper/76a1dca3a9c2b0229c1b12c95752dcf40dc95a11\",\"venue\":\"EMNLP\",\"year\":2011},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1605.02688\",\"authors\":[{\"authorId\":\"1388360943\",\"name\":\"Rami Al-Rfou\"},{\"authorId\":\"1815021\",\"name\":\"G. Alain\"},{\"authorId\":\"2634674\",\"name\":\"Amjad Almahairi\"},{\"authorId\":\"48765757\",\"name\":\"Christof Angerm\\u00fcller\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"3227028\",\"name\":\"Fr\\u00e9d\\u00e9ric Bastien\"},{\"authorId\":\"145040409\",\"name\":\"J. Bayer\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"7330729\",\"name\":\"A. Belopolsky\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"47944877\",\"name\":\"Arnaud Bergeron\"},{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"115295647\",\"name\":\"Valentin Bisson\"},{\"authorId\":\"32308836\",\"name\":\"Josh Bleecher Snyder\"},{\"authorId\":\"14362225\",\"name\":\"Nicolas Bouchard\"},{\"authorId\":\"1395619597\",\"name\":\"Nicolas Boulanger-Lewandowski\"},{\"authorId\":\"2900675\",\"name\":\"Xavier Bouthillier\"},{\"authorId\":\"2346028\",\"name\":\"A. D. Br\\u00e9bisson\"},{\"authorId\":\"1967465\",\"name\":\"Olivier Breuleux\"},{\"authorId\":\"153921980\",\"name\":\"Pierre Luc Carrier\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"29848635\",\"name\":\"Paul F. Christiano\"},{\"authorId\":\"2348758\",\"name\":\"Tim Cooijmans\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"39977229\",\"name\":\"Myriam C\\u00f4t\\u00e9\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"2460212\",\"name\":\"Olivier Delalleau\"},{\"authorId\":\"32604218\",\"name\":\"Julien Demouth\"},{\"authorId\":\"2755582\",\"name\":\"G. Desjardins\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"46573521\",\"name\":\"Laurent Dinh\"},{\"authorId\":\"2812151\",\"name\":\"Melanie Ducoffe\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"40557013\",\"name\":\"Ziye Fan\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"},{\"authorId\":\"39844381\",\"name\":\"M. Germain\"},{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"48196087\",\"name\":\"M. Graham\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"48080691\",\"name\":\"P. Hamel\"},{\"authorId\":\"1405640115\",\"name\":\"Iban Harlouchet\"},{\"authorId\":\"114956664\",\"name\":\"J. Heng\"},{\"authorId\":\"2507883\",\"name\":\"Bal\\u00e1zs Hidasi\"},{\"authorId\":\"25056820\",\"name\":\"S. Honari\"},{\"authorId\":\"36399635\",\"name\":\"Arjun Jain\"},{\"authorId\":\"152857609\",\"name\":\"S\\u00e9bastien Jean\"},{\"authorId\":\"49104216\",\"name\":\"Kai Jia\"},{\"authorId\":\"3025583\",\"name\":\"M. Korobov\"},{\"authorId\":\"144592382\",\"name\":\"Vivek Kulkarni\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"3087941\",\"name\":\"Pascal Lamblin\"},{\"authorId\":\"153109766\",\"name\":\"E. Larsen\"},{\"authorId\":\"40201308\",\"name\":\"C\\u00e9sar Laurent\"},{\"authorId\":\"72490641\",\"name\":\"Sueryun Lee\"},{\"authorId\":\"47682610\",\"name\":\"S. Lefran\\u00e7ois\"},{\"authorId\":\"2387233\",\"name\":\"S. Lemieux\"},{\"authorId\":\"144828689\",\"name\":\"N. L\\u00e9onard\"},{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"3245814\",\"name\":\"J. A. Livezey\"},{\"authorId\":\"40532172\",\"name\":\"C. Lorenz\"},{\"authorId\":\"102472217\",\"name\":\"J. Lowin\"},{\"authorId\":null,\"name\":\"Qianli Ma\"},{\"authorId\":\"1798462\",\"name\":\"Pierre-Antoine Manzagol\"},{\"authorId\":\"3422889\",\"name\":\"Olivier Mastropietro\"},{\"authorId\":\"1914552\",\"name\":\"Robert McGibbon\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"40479190\",\"name\":\"Alberto Orlandi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"121252563\",\"name\":\"M. Pezeshki\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"49577546\",\"name\":\"Daniel Renshaw\"},{\"authorId\":\"3146111\",\"name\":\"M. Rocklin\"},{\"authorId\":\"114117487\",\"name\":\"Adriana Romero\"},{\"authorId\":\"48127262\",\"name\":\"M. Roth\"},{\"authorId\":\"47696458\",\"name\":\"Peter Sadowski\"},{\"authorId\":\"3373139\",\"name\":\"J. Salvatier\"},{\"authorId\":\"47918629\",\"name\":\"F. Savard\"},{\"authorId\":\"1382154289\",\"name\":\"Jan Schl\\u00fcter\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"40116153\",\"name\":\"Gabriel Schwartz\"},{\"authorId\":\"48190457\",\"name\":\"I. Serban\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"3197429\",\"name\":\"Samira Shabanian\"},{\"authorId\":\"39442397\",\"name\":\"\\u00c9tienne Simon\"},{\"authorId\":\"11115628\",\"name\":\"Sigurd Spieckermann\"},{\"authorId\":\"120638144\",\"name\":\"S. Subramanyam\"},{\"authorId\":\"3407592\",\"name\":\"Jakub Sygnowski\"},{\"authorId\":\"66454233\",\"name\":\"J\\u00e9r\\u00e9mie Tanguay\"},{\"authorId\":\"3220768\",\"name\":\"G. V. Tulder\"},{\"authorId\":\"153160559\",\"name\":\"Joseph P. Turian\"},{\"authorId\":\"19555508\",\"name\":\"S. Urban\"},{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"2077146\",\"name\":\"Francesco Visin\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"27358391\",\"name\":\"D. J. Webb\"},{\"authorId\":\"39561601\",\"name\":\"M. Willson\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"47936713\",\"name\":\"Lijun Xue\"},{\"authorId\":\"97709924\",\"name\":\"L. Yao\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b570069f14c7588e066f7138e1f21af59d62e61\",\"title\":\"Theano: A Python framework for fast computation of mathematical expressions\",\"url\":\"https://www.semanticscholar.org/paper/6b570069f14c7588e066f7138e1f21af59d62e61\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1510.01431\",\"authors\":[{\"authorId\":\"3175685\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"title\":\"SentiCap: Generating Image Descriptions with Sentiments\",\"url\":\"https://www.semanticscholar.org/paper/7da9c26ea68a31d119e8222d1a5c33ef136ebed8\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":\"1604.01729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.18653/v1/D16-1204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"title\":\"Improving LSTM-based Video Description with Linguistic Knowledge Mined from Text\",\"url\":\"https://www.semanticscholar.org/paper/d1ffd519ff274517ec6fd014ae67af0d0c68a969\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1504.06692\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"144287022\",\"name\":\"Xu Wei\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"152924551\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2015.291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb847564774394c484e701437dbcffbf040ff3cc\",\"title\":\"Learning Like a Child: Fast Novel Visual Concept Learning from Sentence Descriptions of Images\",\"url\":\"https://www.semanticscholar.org/paper/eb847564774394c484e701437dbcffbf040ff3cc\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"title\":\"Composing Simple Image Descriptions using Web-scale N-grams\",\"url\":\"https://www.semanticscholar.org/paper/fbdbe747c6aa8b35b981d21e475ff1506a1bae66\",\"venue\":\"CoNLL\",\"year\":2011},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1506.03099\",\"authors\":[{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"},{\"authorId\":\"1846258\",\"name\":\"Noam Shazeer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"title\":\"Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/df137487e20ba7c6e1e2b9a1e749f2a578b5ad99\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"title\":\"Im2Text: Describing Images Using 1 Million Captioned Photographs\",\"url\":\"https://www.semanticscholar.org/paper/8e080b98efbe65c02a116439205ca2344b9f7cd4\",\"venue\":\"NIPS\",\"year\":2011},{\"arxivId\":\"1605.00743\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/CVPR.2016.17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1e4f2c791f81a5fe95e693644e002fb652adb39\",\"title\":\"Learning Attributes Equals Multi-Source Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/e1e4f2c791f81a5fe95e693644e002fb652adb39\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":\"1511.06114\",\"authors\":[{\"authorId\":\"1707242\",\"name\":\"Minh-Thang Luong\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d76c07211479e233f7c6a6f32d5346c983c5598f\",\"title\":\"Multi-task Sequence to Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/d76c07211479e233f7c6a6f32d5346c983c5598f\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":\"1609.08976\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145153424\",\"name\":\"Ricardo Henao\"},{\"authorId\":\"50242822\",\"name\":\"X. Yuan\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9074631\",\"name\":\"A. Stevens\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"title\":\"Variational Autoencoder for Deep Learning of Images, Labels and Captions\",\"url\":\"https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.07571\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.494\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"title\":\"DenseCap: Fully Convolutional Localization Networks for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7ce5665a72c0b607f484c1b448875f02ddfac3b\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/ICCV.2015.277\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3640aae13e344ad70a926510221dada626a44de\",\"title\":\"Guiding the Long-Short Term Memory Model for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/c3640aae13e344ad70a926510221dada626a44de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1162/tacl_a_00188\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59927ded86ab4f7253fc32efb351e5a13e746ead\",\"title\":\"TreeTalk: Composition and Compression of Trees for Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/59927ded86ab4f7253fc32efb351e5a13e746ead\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013}],\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"topics\":[{\"topic\":\"Flickr\",\"topicId\":\"67227\",\"url\":\"https://www.semanticscholar.org/topic/67227\"},{\"topic\":\"Text corpus\",\"topicId\":\"14829\",\"url\":\"https://www.semanticscholar.org/topic/14829\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Multi-task learning\",\"topicId\":\"76682\",\"url\":\"https://www.semanticscholar.org/topic/76682\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Computer multitasking\",\"topicId\":\"6968\",\"url\":\"https://www.semanticscholar.org/topic/6968\"},{\"topic\":\"Run time (program lifecycle phase)\",\"topicId\":\"896\",\"url\":\"https://www.semanticscholar.org/topic/896\"},{\"topic\":\"Time complexity\",\"topicId\":\"3448\",\"url\":\"https://www.semanticscholar.org/topic/3448\"}],\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"