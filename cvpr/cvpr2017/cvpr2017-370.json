"{\"abstract\":\"We introduce a new problem of gaze anticipation on egocentric videos. This substantially extends the conventional gaze prediction problem to future frames by no longer confining it on the current frame. To solve this problem, we propose a new generative adversarial neural network based model, Deep Future Gaze (DFG). DFG generates multiple future frames conditioned on the single current frame and anticipates corresponding future gazes in next few seconds. It consists of two networks: generator and discriminator. The generator uses a two-stream spatial temporal convolution architecture (3D-CNN) explicitly untangling the foreground and the background to generate future frames. It then attaches another 3D-CNN for gaze anticipation based on these synthetic frames. The discriminator plays against the generator by differentiating the synthetic frames of the generator from the real frames. Through competition with discriminator, the generator progressively improves quality of the future frames and thus anticipates future gaze better. Experimental results on the publicly available egocentric datasets show that DFG significantly outperforms all well-established baselines. Moreover, we demonstrate that DFG achieves better performance of gaze prediction on current frames than state-of-the-art methods. This is due to benefiting from learning motion discriminative representations in frame generation. We further contribute a new egocentric dataset (OST) in the object search task. DFG also achieves the best performance for this challenging dataset.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\",\"url\":\"https://www.semanticscholar.org/author/2418491\"},{\"authorId\":\"21007367\",\"name\":\"K. T. Ma\",\"url\":\"https://www.semanticscholar.org/author/21007367\"},{\"authorId\":\"153239355\",\"name\":\"J. H. Lim\",\"url\":\"https://www.semanticscholar.org/author/153239355\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\",\"url\":\"https://www.semanticscholar.org/author/49033321\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\",\"url\":\"https://www.semanticscholar.org/author/33221685\"}],\"citationVelocity\":15,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"51243449\",\"name\":\"Atanas Poibrenski\"},{\"authorId\":\"1798357\",\"name\":\"M. Klusch\"},{\"authorId\":\"1596870919\",\"name\":\"Igor Vozniak\"},{\"authorId\":\"143851843\",\"name\":\"C. M\\u00fcller\"}],\"doi\":\"10.1145/3341105.3373877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a6af33e8117079372b60ba65dc15a4738105162\",\"title\":\"M2P3: multimodal multi-pedestrian path prediction by self-driving cars with egocentric vision\",\"url\":\"https://www.semanticscholar.org/paper/6a6af33e8117079372b60ba65dc15a4738105162\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885012300\",\"name\":\"Sam Van Damme\"},{\"authorId\":\"2349719\",\"name\":\"M. T. Vega\"},{\"authorId\":\"1715957\",\"name\":\"F. Turck\"}],\"doi\":\"10.1109/NetSoft48620.2020.9165335\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5fd38ccf3b10f21b15fda8f36466959e7da125e3\",\"title\":\"Human-centric Quality Management of Immersive Multimedia Applications\",\"url\":\"https://www.semanticscholar.org/paper/5fd38ccf3b10f21b15fda8f36466959e7da125e3\",\"venue\":\"2020 6th IEEE Conference on Network Softwarization (NetSoft)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144480984\",\"name\":\"Qiang Hu\"},{\"authorId\":\"49895169\",\"name\":\"J. Zhou\"},{\"authorId\":\"47957191\",\"name\":\"Xiao-yun Zhang\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"49538591\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/s11042-019-08390-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"title\":\"Viewport-adaptive 360-degree video coding\",\"url\":\"https://www.semanticscholar.org/paper/9fcb0a329cff574b89567e2b26a7bb4d79a77744\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66438378\",\"name\":\"Kongtao Zhu\"},{\"authorId\":\"3300934\",\"name\":\"Xiwei Liu\"},{\"authorId\":\"27391286\",\"name\":\"Hongxue Yang\"}],\"doi\":\"10.1109/CAC.2018.8623645\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f571725ffc18c6249702ab457b287495302a4e68\",\"title\":\"A Survey of Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/f571725ffc18c6249702ab457b287495302a4e68\",\"venue\":\"2018 Chinese Automation Congress (CAC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"38821423\",\"name\":\"S. Heinen\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1007/s11042-018-5953-1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"title\":\"Foveated convolutional neural networks for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/14389a8a68fe7a23de82285ea813c7c9f8a433c9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476813805\",\"name\":\"M. Al-Naser\"},{\"authorId\":\"29005173\",\"name\":\"S. Siddiqui\"},{\"authorId\":\"151425311\",\"name\":\"Hiroki Ohashi\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1476817066\",\"name\":\"Nakamura Katsuyki\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"}],\"doi\":\"10.1109/DICTA47822.2019.8945893\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"title\":\"OGaze: Gaze Prediction in Egocentric Videos for Attentional Object Selection\",\"url\":\"https://www.semanticscholar.org/paper/697f3ccd584b7be126cbea9ced53d5b5e00372f1\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7869872\",\"name\":\"Y. Xu\"},{\"authorId\":\"49266038\",\"name\":\"Yanbing Dong\"},{\"authorId\":\"3423101\",\"name\":\"Junru Wu\"},{\"authorId\":\"30581936\",\"name\":\"Zhengzhong Sun\"},{\"authorId\":\"34692825\",\"name\":\"Zhiru Shi\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"},{\"authorId\":\"1702868\",\"name\":\"Shenghua Gao\"}],\"doi\":\"10.1109/CVPR.2018.00559\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"title\":\"Gaze Prediction in Dynamic 360\\u00b0 Immersive Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc3bd1659d005ee25c26e3f6aab3c7361f6172b7\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15597895\",\"name\":\"Hamed AlQahtani\"},{\"authorId\":\"1400351274\",\"name\":\"Manolya Kavakli-Thorne\"},{\"authorId\":\"1384018582\",\"name\":\"G. Kumar\"}],\"doi\":\"10.1007/s11831-019-09388-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42e5ce74677cc10144b2d352f7f7cc37fd54f0bc\",\"title\":\"Applications of Generative Adversarial Networks (GANs): An Updated Review\",\"url\":\"https://www.semanticscholar.org/paper/42e5ce74677cc10144b2d352f7f7cc37fd54f0bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1907.11115\",\"authors\":[{\"authorId\":\"31944767\",\"name\":\"Mihai B\\u00e2ce\"},{\"authorId\":\"122525926\",\"name\":\"Sander Staal\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55b879974c751301a94fa36b08a7042282bf22e3\",\"title\":\"Accurate and Robust Eye Contact Detection During Everyday Mobile Device Interactions\",\"url\":\"https://www.semanticscholar.org/paper/55b879974c751301a94fa36b08a7042282bf22e3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1959507901\",\"name\":\"Xiaolan Jiang\"},{\"authorId\":\"1961460065\",\"name\":\"Si Ahmed Naas\"},{\"authorId\":\"2427829\",\"name\":\"Yi-Han Chiang\"},{\"authorId\":\"49772612\",\"name\":\"S. Sigg\"},{\"authorId\":\"2609825\",\"name\":\"Yusheng Ji\"}],\"doi\":\"10.1109/ACCESS.2020.3022062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c6ff0f183c701b2b7386021e03e79baa088fad6\",\"title\":\"SVP: Sinusoidal Viewport Prediction for 360-Degree Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/7c6ff0f183c701b2b7386021e03e79baa088fad6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1803.09125\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1007/978-3-030-01225-0_46\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e236d33dce5d30348aeb494e491a13468133b4e\",\"title\":\"Predicting Gaze in Egocentric Video by Learning Task-dependent Attention Transition\",\"url\":\"https://www.semanticscholar.org/paper/7e236d33dce5d30348aeb494e491a13468133b4e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056962\",\"name\":\"Shujon Naha\"},{\"authorId\":null,\"name\":\"Alimoor Reza\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80338d1010c36fcbe87c3ce2323b350139521523\",\"title\":\"Localizing Novel Attended Objects in Egocentric Views\",\"url\":\"https://www.semanticscholar.org/paper/80338d1010c36fcbe87c3ce2323b350139521523\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145295896\",\"name\":\"Y. Shen\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"2492392\",\"name\":\"N. Zhuang\"}],\"doi\":\"10.1007/978-3-030-01216-8_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"title\":\"Egocentric Activity Prediction via Event Modulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"}],\"doi\":\"10.1109/ICCVW.2019.00536\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71f3a2632d924f29ca6eb2e789f8ff6d46250c82\",\"title\":\"EgoVQA - An Egocentric Video Question Answering Benchmark Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71f3a2632d924f29ca6eb2e789f8ff6d46250c82\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1904.06250\",\"authors\":[{\"authorId\":\"47625239\",\"name\":\"Jiaqi Guan\"},{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"1974383\",\"name\":\"Nicholas Rhinehart\"}],\"doi\":\"10.1109/cvpr42600.2020.00025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e81711be35d918d1bc5c987f25e0eaa9cfb7170\",\"title\":\"Generative Hybrid Representations for Activity Forecasting With No-Regret Learning\",\"url\":\"https://www.semanticscholar.org/paper/1e81711be35d918d1bc5c987f25e0eaa9cfb7170\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"145864858\",\"name\":\"Chen Yu\"},{\"authorId\":\"2798750\",\"name\":\"Sven Bambach\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"title\":\"From Coarse Attention to Fine-Grained Gaze: A Two-stage 3D Fully Convolutional Network for Predicting Eye Gaze in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/5a089bc28160fa236f219c6760b6a48c9b8d3d10\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1711.07461\",\"authors\":[{\"authorId\":\"26393556\",\"name\":\"Ayush Jaiswal\"},{\"authorId\":\"17806729\",\"name\":\"Wael AbdAlmageed\"},{\"authorId\":\"41205922\",\"name\":\"Yue Wu\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":\"10.1007/978-3-030-20893-6_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a02184707247a79a236a03f85ab35d99a68be33\",\"title\":\"Bidirectional Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/0a02184707247a79a236a03f85ab35d99a68be33\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153170974\",\"name\":\"D. K. Sharma\"},{\"authorId\":\"1577865199\",\"name\":\"A. Khera\"},{\"authorId\":\"144996780\",\"name\":\"Dharmesh Singh\"}],\"doi\":\"10.1007/978-3-030-35252-3_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d58f38a8a82fa310867f8b323d46f1dbbf113fd6\",\"title\":\"Using Artificial Intelligence to Bring Accurate Real-Time Simulation to Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/d58f38a8a82fa310867f8b323d46f1dbbf113fd6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.07844\",\"authors\":[{\"authorId\":\"34735743\",\"name\":\"T. Fernando\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdc4adb29c8348b3a631ba2c4cad864be4402f6e\",\"title\":\"Exploiting Human Social Cognition for the Detection of Fake and Fraudulent Faces via Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/bdc4adb29c8348b3a631ba2c4cad864be4402f6e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.11217\",\"authors\":[{\"authorId\":\"31485927\",\"name\":\"T. Yagi\"},{\"authorId\":\"11379939\",\"name\":\"Karttikeya Mangalam\"},{\"authorId\":\"1899753\",\"name\":\"Ryo Yonetani\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/CVPR.2018.00792\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d1b8ac91ca95f5234d58602078aa13753f3c73b\",\"title\":\"Future Person Localization in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d1b8ac91ca95f5234d58602078aa13753f3c73b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.12185\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"145306925\",\"name\":\"Sudeep Sarkar\"}],\"doi\":\"10.1007/978-3-030-58568-6_18\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"61b166040abff8309e23d804551fc3d3acc833f6\",\"title\":\"Action Localization through Continual Predictive Learning\",\"url\":\"https://www.semanticscholar.org/paper/61b166040abff8309e23d804551fc3d3acc833f6\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.06460\",\"authors\":[{\"authorId\":\"2104164\",\"name\":\"Juanyong Duan\"},{\"authorId\":\"47878001\",\"name\":\"S. Ong\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"987cf7458f60dff46f27f575ffff4fe5ec520806\",\"title\":\"Human Annotations Improve GAN Performances\",\"url\":\"https://www.semanticscholar.org/paper/987cf7458f60dff46f27f575ffff4fe5ec520806\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1710.07035\",\"authors\":[{\"authorId\":\"3433026\",\"name\":\"Antonia Creswell\"},{\"authorId\":\"40603980\",\"name\":\"T. White\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"68972911\",\"name\":\"Kai Arulkumaran\"},{\"authorId\":\"46609038\",\"name\":\"B. Sengupta\"},{\"authorId\":\"2815535\",\"name\":\"A. Bharath\"}],\"doi\":\"10.1109/MSP.2017.2765202\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e36fc1485ee735796a6ac39ff8155bb2c4f7017\",\"title\":\"Generative Adversarial Networks: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/6e36fc1485ee735796a6ac39ff8155bb2c4f7017\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47190795\",\"name\":\"Feifei Zhang\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/CVPR.2018.00354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9da429ce36afc75f2c457880a9d7129220ac9225\",\"title\":\"Joint Pose and Expression Modeling for Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9da429ce36afc75f2c457880a9d7129220ac9225\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145532503\",\"name\":\"Marco Leo\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"3463966\",\"name\":\"G. Medioni\"},{\"authorId\":\"1713989\",\"name\":\"M. Trivedi\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11024-6_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"title\":\"Deep Learning for Assistive Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/3975d9e34ccd9714ffc05fe12c66d91be45da32f\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.06045\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"1947383\",\"name\":\"Ashish Tawari\"},{\"authorId\":\"1841835\",\"name\":\"Sujitha Martin\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICRA40945.2020.9197104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"title\":\"Interaction Graphs for Object Importance Estimation in On-road Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1904.06090\",\"authors\":[{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2019.00035\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b14286fdc78b3039fc724274c18aa24caee8b59e\",\"title\":\"Digging Deeper Into Egocentric Gaze Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b14286fdc78b3039fc724274c18aa24caee8b59e\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1912.07148\",\"authors\":[{\"authorId\":\"9284940\",\"name\":\"Harshala Gammulle\"},{\"authorId\":\"1980700\",\"name\":\"Simon Denman\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICCV.2019.00566\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2b4960bb3997105073779651a54255b2c129d3d6\",\"title\":\"Predicting the Future: A Jointly Learnt Model for Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2b4960bb3997105073779651a54255b2c129d3d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.08900\",\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90e9702ca01ebda8d131e1ec7c46506fc4959f2e\",\"title\":\"Whose hand is this? Person Identification from Egocentric Hand Gestures\",\"url\":\"https://www.semanticscholar.org/paper/90e9702ca01ebda8d131e1ec7c46506fc4959f2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICIP.2019.8803534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee5eac18cb8f201c44d7aa5fa3ca677b8d4d3da5\",\"title\":\"Egocentric Action Anticipation by Disentangling Encoding and Inference\",\"url\":\"https://www.semanticscholar.org/paper/ee5eac18cb8f201c44d7aa5fa3ca677b8d4d3da5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiao Li\"},{\"authorId\":\"7489463\",\"name\":\"Si-yi Wang\"},{\"authorId\":\"144469725\",\"name\":\"C. Zhu\"},{\"authorId\":\"144157729\",\"name\":\"L. Song\"},{\"authorId\":\"144509678\",\"name\":\"Rong Xie\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/BMSB47279.2019.8971933\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c512d2010a6de275cf7d36c6fee18eac6c45f758\",\"title\":\"Viewport Prediction for Panoramic Video with Multi-CNN\",\"url\":\"https://www.semanticscholar.org/paper/c512d2010a6de275cf7d36c6fee18eac6c45f758\",\"venue\":\"2019 IEEE International Symposium on Broadband Multimedia Systems and Broadcasting (BMSB)\",\"year\":2019},{\"arxivId\":\"2001.06937\",\"authors\":[{\"authorId\":\"48603577\",\"name\":\"Jie Gui\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"2778556\",\"name\":\"Jie-ping Ye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"title\":\"A Review on Generative Adversarial Networks: Algorithms, Theory, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/fbc5486a1ffb9039dbb5046b84f0eb32e4ce8eea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1801.06011\",\"authors\":[{\"authorId\":\"2920056\",\"name\":\"Julian Steil\"},{\"authorId\":\"49569816\",\"name\":\"P. M\\u00fcller\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/3229434.3229439\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26dce5da1b49488c7a25a8841637c97b66d4cc00\",\"title\":\"Forecasting user attention during everyday mobile interactions using device-integrated and wearable sensors\",\"url\":\"https://www.semanticscholar.org/paper/26dce5da1b49488c7a25a8841637c97b66d4cc00\",\"venue\":\"MobileHCI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49569816\",\"name\":\"P. M\\u00fcller\"},{\"authorId\":\"51235014\",\"name\":\"Ekta Sood\"},{\"authorId\":\"3194727\",\"name\":\"Andreas Bulling\"}],\"doi\":\"10.1145/3379155.3391332\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b5eb5e6c98f65b12fa7b5e5f94dba84b59e2c4d\",\"title\":\"Anticipating Averted Gaze in Dyadic Interactions\",\"url\":\"https://www.semanticscholar.org/paper/6b5eb5e6c98f65b12fa7b5e5f94dba84b59e2c4d\",\"venue\":\"ETRA\",\"year\":2020},{\"arxivId\":\"2001.11580\",\"authors\":[{\"authorId\":\"24057502\",\"name\":\"Sathyanarayanan N. Aakur\"},{\"authorId\":\"144227173\",\"name\":\"A. Bagavathi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"title\":\"Unsupervised Gaze Prediction in Egocentric Videos by Energy-based Surprise Modeling\",\"url\":\"https://www.semanticscholar.org/paper/af5c027f9435bb4c26cbf48bb28a1d8456e164e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.11702\",\"authors\":[{\"authorId\":\"1410334693\",\"name\":\"Miguel Fabian Romero-Rond\\u00f3n\"},{\"authorId\":\"1750472\",\"name\":\"L. Sassatelli\"},{\"authorId\":\"1398078454\",\"name\":\"R. Aparicio-Pardo\"},{\"authorId\":\"150103589\",\"name\":\"F. Precioso\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"title\":\"Revisiting Deep Architectures for Head Motion Prediction in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/fbc949df3b994709a806ddb2a3d4ce5414657cd0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50333150\",\"name\":\"Ning Zhuang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"5925215\",\"name\":\"Y. Xu\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"144913615\",\"name\":\"W. Zhang\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"}],\"doi\":\"10.1109/TCSVT.2019.2940479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db2d2b1b4fbf791157bf094530fc22d3f4f79344\",\"title\":\"MUGGLE: MUlti-Stream Group Gaze Learning and Estimation\",\"url\":\"https://www.semanticscholar.org/paper/db2d2b1b4fbf791157bf094530fc22d3f4f79344\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2418491\",\"name\":\"M. Zhang\"},{\"authorId\":\"1397677751\",\"name\":\"Keng Teck Ma\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"},{\"authorId\":\"153386875\",\"name\":\"Q. Zhao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/TPAMI.2018.2871688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"title\":\"Anticipating Where People will Look Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2f04a3d8eacfa22a299e0c5a7edcc69d0fdd5933\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1767658\",\"name\":\"Yingyue Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"title\":\"Computational modeling for visual attention analysis\",\"url\":\"https://www.semanticscholar.org/paper/bb6a1cab0cfd4adc3de102eb8835d40ffd99874c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.14260\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"46756438\",\"name\":\"Chen Yu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"title\":\"A Self Validation Network for Object-Level Human Attention Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3572197\",\"name\":\"K. Menden\"},{\"authorId\":\"2550295\",\"name\":\"M. Marouf\"},{\"authorId\":\"4080895\",\"name\":\"Sergio Oller\"},{\"authorId\":\"120691028\",\"name\":\"Anupriya Dalmia\"},{\"authorId\":\"32283202\",\"name\":\"D. S. Magruder\"},{\"authorId\":\"1601445530\",\"name\":\"Karin Kloiber\"},{\"authorId\":\"46681175\",\"name\":\"P. Heutink\"},{\"authorId\":\"4783273\",\"name\":\"S. Bonn\"}],\"doi\":\"10.1126/sciadv.aba2619\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e0c7a3a7904756aa111ae4e89e8461572fba77\",\"title\":\"Deep learning\\u2013based cell composition analysis from tissue expression profiles\",\"url\":\"https://www.semanticscholar.org/paper/72e0c7a3a7904756aa111ae4e89e8461572fba77\",\"venue\":\"Science Advances\",\"year\":2020}],\"corpusId\":5911448,\"doi\":\"10.1109/CVPR.2017.377\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":6,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"f95e349489aa48fc57494aab101d58c496cc35f5\",\"references\":[{\"arxivId\":\"1311.2901\",\"authors\":[{\"authorId\":\"48799969\",\"name\":\"Matthew D. Zeiler\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":\"10.1007/978-3-319-10590-1_53\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"title\":\"Visualizing and Understanding Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1a2a770d23b4a171fa81de62a78a3deb0588f238\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/cvprw.2009.5206697\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa9f82781a0d844faec8616ffbe68113536fefea\",\"title\":\"Large displacement optical flow\",\"url\":\"https://www.semanticscholar.org/paper/aa9f82781a0d844faec8616ffbe68113536fefea\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"3271571\",\"name\":\"E. Niebur\"}],\"doi\":\"10.1109/34.730558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"title\":\"A Model of Saliency-Based Visual Attention for Rapid Scene Analysis\",\"url\":\"https://www.semanticscholar.org/paper/4816f0b6f0d05da3901441bfa5cc7be044b4da8b\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-642-33718-5_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"title\":\"Learning to Recognize Daily Actions Using Gaze\",\"url\":\"https://www.semanticscholar.org/paper/985e1f2dc17db0d590de883cbf1e30535169cb1a\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"34b08f92306f4a20f6ec00c35a1b22c0c30a03cf\",\"title\":\"Saliency Detection within a Deep Convolutional Architecture\",\"url\":\"https://www.semanticscholar.org/paper/34b08f92306f4a20f6ec00c35a1b22c0c30a03cf\",\"venue\":\"AAAI 2014\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Christopoulos\"},{\"authorId\":null,\"name\":\"A. Gaitatzes\"},{\"authorId\":null,\"name\":\"G. Papaioannou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Imagebased techniques for enhancing virtual reality environments\",\"url\":\"\",\"venue\":\"In 2nd International Workshop on ICT\\u2019s, Arts and Cultural Heritage,\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5699468\",\"name\":\"R. Ohme\"},{\"authorId\":\"15273727\",\"name\":\"M. Matukin\"},{\"authorId\":\"1422339292\",\"name\":\"Beata Pacula-Lesniak\"}],\"doi\":\"10.1080/15252019.2011.10722185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"278c4e116a6a4b05562fc90de3624407d42450fd\",\"title\":\"Biometric Measures for Interactive Advertising Research\",\"url\":\"https://www.semanticscholar.org/paper/278c4e116a6a4b05562fc90de3624407d42450fd\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396144799\",\"name\":\"A. Garc\\u00eda-D\\u00edaz\"},{\"authorId\":\"1398290502\",\"name\":\"Xos\\u00e9 R. Fern\\u00e1ndez-Vidal\"},{\"authorId\":\"1768258\",\"name\":\"X. Pardo\"},{\"authorId\":\"1751198\",\"name\":\"Raquel Dosil\"}],\"doi\":\"10.1016/j.imavis.2011.11.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b089afcf58bfdc73a956e015c82a8005ec313dac\",\"title\":\"Saliency from hierarchical adaptation through decorrelation and variance normalization\",\"url\":\"https://www.semanticscholar.org/paper/b089afcf58bfdc73a956e015c82a8005ec313dac\",\"venue\":\"Image Vis. Comput.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. France F. Multon\"},{\"authorId\":null,\"name\":\"M.-P. Cani-Gascuel\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"LeCun . Deep multi - scale video prediction beyond mean square error\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1605.03688\",\"authors\":[{\"authorId\":\"2238622\",\"name\":\"Minghuang Ma\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2016.209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"444eba373d46c9f7d58cad74989ec9109b0d5219\",\"title\":\"Going Deeper into First-Person Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/444eba373d46c9f7d58cad74989ec9109b0d5219\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.02612\",\"authors\":[{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.13016/M26GIH-TNYZ\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"title\":\"Generating Videos with Scene Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/ee091ccf24c4f053c5c3dfbefe4a7975ed3447c1\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47059693\",\"name\":\"L. Zhang\"},{\"authorId\":\"49488601\",\"name\":\"M. Tong\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"2207531\",\"name\":\"Honghao Shan\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"}],\"doi\":\"10.1167/8.7.32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e80c48441351fc1d928524710b4500a0de8315bb\",\"title\":\"SUN: A Bayesian framework for saliency using natural statistics.\",\"url\":\"https://www.semanticscholar.org/paper/e80c48441351fc1d928524710b4500a0de8315bb\",\"venue\":\"Journal of vision\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713625\",\"name\":\"R. Zeleznik\"},{\"authorId\":\"1700671\",\"name\":\"J. Schulze\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60dc5c21863a73546d0bd980fe9efb140b8c01fa\",\"title\":\"Look-That-There : Exploiting Gaze in Virtual Reality Interactions\",\"url\":\"https://www.semanticscholar.org/paper/60dc5c21863a73546d0bd980fe9efb140b8c01fa\",\"venue\":\"\",\"year\":2004},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3205375\",\"name\":\"T. Lindeberg\"}],\"doi\":\"10.1109/ICCV.2003.1238378\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f90d79809325d2b78e35a79ecb372407f81b3993\",\"title\":\"Space-time interest points\",\"url\":\"https://www.semanticscholar.org/paper/f90d79809325d2b78e35a79ecb372407f81b3993\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"143852685\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/ICCV.2013.118\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"title\":\"Analysis of Scores, Datasets, and Models in Visual Saliency Prediction\",\"url\":\"https://www.semanticscholar.org/paper/05375a7489f0a84d47a316bacb4d86e8a7bda0df\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40529331\",\"name\":\"C. Huang\"},{\"authorId\":\"2211183\",\"name\":\"Sean Andrist\"},{\"authorId\":\"2354698\",\"name\":\"Allison Saupp\\u00e9\"},{\"authorId\":\"145656551\",\"name\":\"B. Mutlu\"}],\"doi\":\"10.3389/fpsyg.2015.01049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03686afbbb854ef995200bd6196d404371466286\",\"title\":\"Using gaze patterns to predict task intent in collaboration\",\"url\":\"https://www.semanticscholar.org/paper/03686afbbb854ef995200bd6196d404371466286\",\"venue\":\"Front. Psychol.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12857024\",\"name\":\"Wei Ding\"},{\"authorId\":\"144787614\",\"name\":\"P. Chen\"},{\"authorId\":\"1398560253\",\"name\":\"H. Al-Mubaid\"},{\"authorId\":\"1739588\",\"name\":\"M. Pomplun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"911af62564ec95c26f168fb9936daef551eb4f06\",\"title\":\"A Gaze-Controlled Interface to Virtual Reality Applications for Motor-and Speech-Impaired Users\",\"url\":\"https://www.semanticscholar.org/paper/911af62564ec95c26f168fb9936daef551eb4f06\",\"venue\":\"\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2989773\",\"name\":\"Nicolas Riche\"},{\"authorId\":\"2896417\",\"name\":\"Matthieu Duvinage\"},{\"authorId\":\"1681157\",\"name\":\"M. Mancas\"},{\"authorId\":\"50276543\",\"name\":\"B. Gosselin\"},{\"authorId\":\"49164810\",\"name\":\"T. Dutoit\"}],\"doi\":\"10.1109/ICCV.2013.147\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"79c761353fe46544a758b284813dfa2908664db2\",\"title\":\"Saliency and Human Fixations: State-of-the-Art and Study of Comparison Metrics\",\"url\":\"https://www.semanticscholar.org/paper/79c761353fe46544a758b284813dfa2908664db2\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7326223\",\"name\":\"L. Itti\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1016/S0042-6989(99)00163-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3\",\"title\":\"A saliency-based search mechanism for overt and covert shifts of visual attention\",\"url\":\"https://www.semanticscholar.org/paper/7b4b801de1ba8a4456adcde7b1a9c5bc5cf09fc3\",\"venue\":\"Vision Research\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1743045\",\"name\":\"S. Ullman\"}],\"doi\":\"10.1007/978-94-009-3833-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"title\":\"Shifts in selective visual attention: towards the underlying neural circuitry.\",\"url\":\"https://www.semanticscholar.org/paper/0ce672e6ef09e9ab4c43f1eb75443dc7a5cb38c6\",\"venue\":\"Human neurobiology\",\"year\":1985},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2267017\",\"name\":\"M. Stengel\"},{\"authorId\":\"2860857\",\"name\":\"S. Grogorick\"},{\"authorId\":\"1701306\",\"name\":\"M. Eisemann\"},{\"authorId\":\"1737690\",\"name\":\"E. Eisemann\"},{\"authorId\":\"1686739\",\"name\":\"M. Magnor\"}],\"doi\":\"10.1145/2733373.2806265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f323255b6564ff0f7387deb02a7c04eb3fa0811a\",\"title\":\"An Affordable Solution for Binocular Eye Tracking and Calibration in Head-mounted Displays\",\"url\":\"https://www.semanticscholar.org/paper/f323255b6564ff0f7387deb02a7c04eb3fa0811a\",\"venue\":\"ACM Multimedia\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731192\",\"name\":\"F. Multon\"},{\"authorId\":\"1808449\",\"name\":\"L. France\"},{\"authorId\":\"1710314\",\"name\":\"M. Cani\"},{\"authorId\":\"2185915\",\"name\":\"Gilles Debunne\"}],\"doi\":\"10.1002/(SICI)1099-1778(199901/03)10:1%3C39::AID-VIS195%3E3.0.CO;2-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4febaa16086b065d1ca161c88e7f1209729ca9c7\",\"title\":\"Computer animation of human walking: a survey\",\"url\":\"https://www.semanticscholar.org/paper/4febaa16086b065d1ca161c88e7f1209729ca9c7\",\"venue\":\"Comput. Animat. Virtual Worlds\",\"year\":1999},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2013.399\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"title\":\"Learning to Predict Gaze in Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/cd6f8f20f549bd9d6711c1c7e89c3350ed48f8c1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29969655\",\"name\":\"M. Kumar\"},{\"authorId\":\"1699245\",\"name\":\"T. Winograd\"},{\"authorId\":\"1750481\",\"name\":\"A. Paepcke\"},{\"authorId\":\"2367620\",\"name\":\"Jeff Klingner\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2e010fa6bb855a88f8b87a9a7c1ae058cdd69a4\",\"title\":\"Gaze-enhanced user interface design\",\"url\":\"https://www.semanticscholar.org/paper/b2e010fa6bb855a88f8b87a9a7c1ae058cdd69a4\",\"venue\":\"\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701293\",\"name\":\"J. Zhang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":\"10.1109/ICCV.2013.26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"title\":\"Saliency Detection: A Boolean Map Approach\",\"url\":\"https://www.semanticscholar.org/paper/75ee5cd7712b6ad13d64c3b4de24aa592a869fc1\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2502152\",\"name\":\"A. Treisman\"},{\"authorId\":\"46475250\",\"name\":\"G. Gelade\"}],\"doi\":\"10.1016/0010-0285(80)90005-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76361a44e145732a39dbc68d9418871038c83be2\",\"title\":\"A feature-integration theory of attention\",\"url\":\"https://www.semanticscholar.org/paper/76361a44e145732a39dbc68d9418871038c83be2\",\"venue\":\"Cognitive Psychology\",\"year\":1980},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144247007\",\"name\":\"X. Huang\"},{\"authorId\":\"3329744\",\"name\":\"Chengyao Shen\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1109/ICCV.2015.38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"title\":\"SALICON: Reducing the Semantic Gap in Saliency Prediction by Adapting Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1281e443d2cf1c1dd71ed3b7b0376d408d0958af\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33230676\",\"name\":\"Kiwon Yun\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"145654220\",\"name\":\"D. Samaras\"},{\"authorId\":\"1696991\",\"name\":\"G. Zelinsky\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.3389/fpsyg.2013.00917\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13b214d6cebbded0f5599309425fa38192487980\",\"title\":\"Exploring the role of gaze behavior and object detection in scene understanding\",\"url\":\"https://www.semanticscholar.org/paper/13b214d6cebbded0f5599309425fa38192487980\",\"venue\":\"Front. Psychol.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2060684\",\"name\":\"Monica S. Castelhano\"},{\"authorId\":\"1889476\",\"name\":\"J. Henderson\"}],\"doi\":\"10.1037/0033-295X.113.4.766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"title\":\"Contextual guidance of eye movements and attention in real-world scenes: the role of global features in object search.\",\"url\":\"https://www.semanticscholar.org/paper/b35e4d00d9a9bfae83a8b0914eb1073a77a11d78\",\"venue\":\"Psychological review\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"title\":\"Saliency Based on Information Maximization\",\"url\":\"https://www.semanticscholar.org/paper/4f847b4ddc105d73bc78f3e7220e6c1f71a7dfb6\",\"venue\":\"NIPS\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"2037692\",\"name\":\"Dicky N. Sihite\"},{\"authorId\":\"7326223\",\"name\":\"L. Itti\"}],\"doi\":\"10.1109/CVPR.2012.6247710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"title\":\"Probabilistic learning of task-specific visual attention\",\"url\":\"https://www.semanticscholar.org/paper/6666ffdc35f3b80f291b63e62fdcc29462662c47\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40466012\",\"name\":\"M. Land\"}],\"doi\":\"10.1007/s00221-004-1951-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"002bb7cd16eef36dcc6477af9da8df2b5f985ec7\",\"title\":\"The coordination of rotations of the eyes, head and trunk in saccadic turns produced in natural situations\",\"url\":\"https://www.semanticscholar.org/paper/002bb7cd16eef36dcc6477af9da8df2b5f985ec7\",\"venue\":\"Experimental Brain Research\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Koch J. Harel\"},{\"authorId\":null,\"name\":\"P. Perona\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Graph - based visual salien\",\"url\":\"\",\"venue\":\"In NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Fathi\"},{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Behav - ior recognition via sparse spatio - temporal features On space - time interest points\",\"url\":\"\",\"venue\":\"International Journal of Computer Vision\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"}],\"doi\":\"10.7551/mitpress/7503.003.0073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"title\":\"Graph-Based Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f412bb31ec9ef8bbef70eefc7ffd04420c1365d9\",\"venue\":\"NIPS\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3084719\",\"name\":\"Xiaodi Hou\"},{\"authorId\":\"39810944\",\"name\":\"Jonathan Harel\"},{\"authorId\":\"145624227\",\"name\":\"C. Koch\"}],\"doi\":\"10.1109/TPAMI.2011.146\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"title\":\"Image Signature: Highlighting Sparse Salient Regions\",\"url\":\"https://www.semanticscholar.org/paper/48c2b8a35ce9468b84ac032af70cf2b100f5c1fc\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2605132\",\"name\":\"D. Christopoulos\"},{\"authorId\":\"2139492\",\"name\":\"A. Gaitatzes\"},{\"authorId\":\"143854900\",\"name\":\"G. Papaioannou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3274a81410a870bf55287723f2b6fdd99b1ab2ea\",\"title\":\"Image-Based Techniques for Enhancing Virtual Reality Environments.\",\"url\":\"https://www.semanticscholar.org/paper/3274a81410a870bf55287723f2b6fdd99b1ab2ea\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50295846\",\"name\":\"K. Yamada\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"},{\"authorId\":\"1805464\",\"name\":\"K. Hiraki\"}],\"doi\":\"10.1007/978-3-642-25367-6_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2e5b460fbc692e63e160cdef26141d236f5211f\",\"title\":\"Attention Prediction in Egocentric Video Using Motion and Visual Saliency\",\"url\":\"https://www.semanticscholar.org/paper/f2e5b460fbc692e63e160cdef26141d236f5211f\",\"venue\":\"PSIVT\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2866780\",\"name\":\"Neil D. B. Bruce\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1167/9.3.5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25e67f4ca6f45533cbe5cec4c6d169b7daf3af2b\",\"title\":\"Saliency, attention, and visual search: an information theoretic approach.\",\"url\":\"https://www.semanticscholar.org/paper/25e67f4ca6f45533cbe5cec4c6d169b7daf3af2b\",\"venue\":\"Journal of vision\",\"year\":2009},{\"arxivId\":\"1409.1484\",\"authors\":[{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"9587913\",\"name\":\"C. Regazzoni\"},{\"authorId\":\"1736974\",\"name\":\"M. Rauterberg\"}],\"doi\":\"10.1109/TCSVT.2015.2409731\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d317bf369e62fca415d54b091d9025b9e0e63181\",\"title\":\"The Evolution of First Person Vision Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/d317bf369e62fca415d54b091d9025b9e0e63181\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1684507\",\"name\":\"Sileye O. Ba\"},{\"authorId\":\"1719610\",\"name\":\"J. Odobez\"}],\"doi\":\"10.1109/TPAMI.2010.69\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1b3d2f4600961adeb30ce2ec094bcc22028737c\",\"title\":\"Multiperson Visual Focus of Attention from Head Pose and Meeting Contextual Cues\",\"url\":\"https://www.semanticscholar.org/paper/a1b3d2f4600961adeb30ce2ec094bcc22028737c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2011}],\"title\":\"Deep Future Gaze: Gaze Anticipation on Egocentric Videos Using Adversarial Networks\",\"topics\":[{\"topic\":\"Discriminator\",\"topicId\":\"41710\",\"url\":\"https://www.semanticscholar.org/topic/41710\"},{\"topic\":\"Activity recognition\",\"topicId\":\"46497\",\"url\":\"https://www.semanticscholar.org/topic/46497\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Reverse engineering\",\"topicId\":\"38634\",\"url\":\"https://www.semanticscholar.org/topic/38634\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Generator (computer programming)\",\"topicId\":\"6331\",\"url\":\"https://www.semanticscholar.org/topic/6331\"},{\"topic\":\"Multitier architecture\",\"topicId\":\"19387\",\"url\":\"https://www.semanticscholar.org/topic/19387\"},{\"topic\":\"Synthetic intelligence\",\"topicId\":\"1588157\",\"url\":\"https://www.semanticscholar.org/topic/1588157\"},{\"topic\":\"Synthetic data\",\"topicId\":\"16840\",\"url\":\"https://www.semanticscholar.org/topic/16840\"}],\"url\":\"https://www.semanticscholar.org/paper/f95e349489aa48fc57494aab101d58c496cc35f5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"