"{\"abstract\":\"We propose a novel method for temporally pooling frames in a video for the task of human action recognition. The method is motivated by the observation that there are only a small number of frames which, together, contain sufficient information to discriminate an action class present in a video, from the rest. The proposed method learns to pool such discriminative and informative frames, while discarding a majority of the non-informative frames in a single temporal scan of the video. Our algorithm does so by continuously predicting the discriminative importance of each video frame and subsequently pooling them in a deep learning framework. We show the effectiveness of our proposed pooling method on standard benchmarks where it consistently improves on baseline pooling methods, with both RGB and optical flow based Convolutional networks. Further, in combination with complementary video representations, we show results that are competitive with respect to the state-of-the-art results on two challenging and publicly available benchmark datasets.\",\"arxivId\":\"1611.08240\",\"authors\":[{\"authorId\":\"24899770\",\"name\":\"Amlan Kar\",\"url\":\"https://www.semanticscholar.org/author/24899770\"},{\"authorId\":\"145193060\",\"name\":\"N. Rai\",\"url\":\"https://www.semanticscholar.org/author/145193060\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\",\"url\":\"https://www.semanticscholar.org/author/39707211\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\",\"url\":\"https://www.semanticscholar.org/author/144054467\"}],\"citationVelocity\":30,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1394421585\",\"name\":\"Matthew Korban\"},{\"authorId\":\"51484592\",\"name\":\"X. Li\"}],\"doi\":\"10.1007/978-3-030-58565-5_45\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"8f95972c62058480d34893095e1bdd5660e4641a\",\"title\":\"DDGCN: A Dynamic Directed Graph Convolutional Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8f95972c62058480d34893095e1bdd5660e4641a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"}],\"doi\":\"10.1007/978-3-030-12177-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7f93e107e81125397652c5d2ae4535c5344612\",\"title\":\"Three-Stream Convolution Networks After Background Subtraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d7f93e107e81125397652c5d2ae4535c5344612\",\"venue\":\"FFER/DLPR@ICPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152153140\",\"name\":\"Xiuping Bao\"},{\"authorId\":\"49706674\",\"name\":\"J. Yuan\"},{\"authorId\":null,\"name\":\"Bei Chen\"}],\"doi\":\"10.1109/ICTAI.2019.00089\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60de1895702532f93b93b616d7a47096dfd1dc6c\",\"title\":\"ECPNet: An Efficient Attention-Based Convolution Network with Pseudo-3D Block for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60de1895702532f93b93b616d7a47096dfd1dc6c\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143627655\",\"name\":\"Guan Luo\"},{\"authorId\":\"1387518609\",\"name\":\"Jiutong Wei\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2019.2955561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be8d5cc013082e9ac8b5588c04177953a2d5047e\",\"title\":\"Tangent Fisher Vector on Matrix Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be8d5cc013082e9ac8b5588c04177953a2d5047e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1703.10025\",\"authors\":[{\"authorId\":\"2578924\",\"name\":\"X. Zhu\"},{\"authorId\":null,\"name\":\"Yujie Wang\"},{\"authorId\":\"3304536\",\"name\":\"Jifeng Dai\"},{\"authorId\":\"145347147\",\"name\":\"Lu Yuan\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"}],\"doi\":\"10.1109/ICCV.2017.52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0246f6754c38324a837c0ebd1b51976f413f80ad\",\"title\":\"Flow-Guided Feature Aggregation for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/0246f6754c38324a837c0ebd1b51976f413f80ad\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Kun Zhang\"},{\"authorId\":\"145688446\",\"name\":\"P. He\"},{\"authorId\":\"31878830\",\"name\":\"Ping Yao\"},{\"authorId\":\"72111330\",\"name\":\"Ge Chen\"},{\"authorId\":\"102756770\",\"name\":\"Chuanguang Yang\"},{\"authorId\":\"4119237\",\"name\":\"H. Li\"},{\"authorId\":\"145535103\",\"name\":\"L. Fu\"},{\"authorId\":\"50844506\",\"name\":\"Tianyao Zheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"289b4f06a7d0b297a63e41af38cba69b4c8789a4\",\"title\":\"DNANet: De-Normalized Attention Based Multi-Resolution Network for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/289b4f06a7d0b297a63e41af38cba69b4c8789a4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9649314\",\"name\":\"Sheeraz Arif\"},{\"authorId\":\"1414105614\",\"name\":\"Tehseen Ul-Hassan\"},{\"authorId\":\"14858604\",\"name\":\"F. Hussain\"},{\"authorId\":\"152924726\",\"name\":\"Jing Wang\"},{\"authorId\":\"144506603\",\"name\":\"Zesong Fei\"}],\"doi\":\"10.1080/1206212X.2018.1486001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"title\":\"Video representation by dense trajectories motion map applied to human activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c7c22b79447d6c2e17162c582ba8a824ec5060e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8962288\",\"name\":\"Zichen zhou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"title\":\"Attention Before and After Feature Extraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48708322\",\"name\":\"Z. Wang\"},{\"authorId\":\"5283546\",\"name\":\"Jiali Jin\"},{\"authorId\":\"37230165\",\"name\":\"Tong Liu\"},{\"authorId\":\"50152717\",\"name\":\"S. Liu\"},{\"authorId\":\"50561022\",\"name\":\"J. Zhang\"},{\"authorId\":\"144370717\",\"name\":\"S. Chen\"},{\"authorId\":null,\"name\":\"Zhen Zhang\"},{\"authorId\":\"2004175\",\"name\":\"Dongyan Guo\"},{\"authorId\":\"2544367\",\"name\":\"Zhanpeng Shao\"}],\"doi\":\"10.1016/j.neucom.2018.09.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebe11290d37c7a5c6b7dd3bedc761b44a01052e8\",\"title\":\"Understanding human activities in videos: A joint action and interaction learning approach\",\"url\":\"https://www.semanticscholar.org/paper/ebe11290d37c7a5c6b7dd3bedc761b44a01052e8\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145594181\",\"name\":\"B. Zhu\"}],\"doi\":\"10.1007/978-3-030-03338-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"title\":\"Feature Aggregation Tree: Capture Temporal Motion Information for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":\"2937291\",\"name\":\"Zhikang Fu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"title\":\"Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map Based Feature Extraction for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1802.02522\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"title\":\"Joint Attention in Driver-Pedestrian Interaction: from Theory to Practice\",\"url\":\"https://www.semanticscholar.org/paper/a6270914cf5f60627a1332bcc3f5951c9eea3be0\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1907.04988\",\"authors\":[{\"authorId\":\"145639696\",\"name\":\"Hao Luo\"},{\"authorId\":\"47033130\",\"name\":\"Lichao Huang\"},{\"authorId\":\"11815649\",\"name\":\"H. Shen\"},{\"authorId\":\"48513975\",\"name\":\"Y. Li\"},{\"authorId\":\"98560100\",\"name\":\"Chang Huang\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"760230e6b741e47629bbfa4a19e2c0b39f327f14\",\"title\":\"Object Detection in Video with Spatial-temporal Context Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/760230e6b741e47629bbfa4a19e2c0b39f327f14\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ACPR.2017.28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08acfa0920abbac5c5046edcff01e41b12c98be7\",\"title\":\"Learning Principal Orientations Descriptor for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08acfa0920abbac5c5046edcff01e41b12c98be7\",\"venue\":\"2017 4th IAPR Asian Conference on Pattern Recognition (ACPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378843\",\"name\":\"L. Lu\"},{\"authorId\":\"1932096\",\"name\":\"Huijun Di\"},{\"authorId\":\"1803391\",\"name\":\"Y. Lu\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccb80471d2bb2236b7f2c37ff9159e9b0d082474\",\"title\":\"A two-level attention-based interaction model for multi-person activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccb80471d2bb2236b7f2c37ff9159e9b0d082474\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ICASSP.2018.8461988\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"title\":\"A 203 FPS VLSI Architecture of Improved Dense Trajectories for Real-Time Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/14b44a1b159fbb8ec84d340297fac5a676a55fa5\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1804.10021\",\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"2404621\",\"name\":\"Hanlin Qin\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"22e03419db32dd1a68394a545dcc400653df58f5\",\"title\":\"Deep Keyframe Detection in Human Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/22e03419db32dd1a68394a545dcc400653df58f5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"143657565\",\"name\":\"P. Jiang\"}],\"doi\":\"10.1007/s10489-018-1347-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"57bb032953f09168953f1cc03102b9269eeee7f5\",\"title\":\"Learning multi-temporal-scale deep information for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/57bb032953f09168953f1cc03102b9269eeee7f5\",\"venue\":\"Applied Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"title\":\"T-C3D: Temporal Convolutional 3D Network for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/ICIP.2018.8451255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad58b92ebc45e71e40ce68d4375441267549b054\",\"title\":\"DA-VLAD: Discriminative Action Vector of Locally Aggregated Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad58b92ebc45e71e40ce68d4375441267549b054\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2761710\",\"name\":\"Dengdi Sun\"},{\"authorId\":\"46476972\",\"name\":\"Hanqing Wu\"},{\"authorId\":\"2430623\",\"name\":\"Zhuanlian Ding\"},{\"authorId\":\"144625999\",\"name\":\"B. Luo\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"}],\"doi\":\"10.1007/978-3-030-00776-8_78\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"99cea5d749086408983e54e4ce7e27a5d35e9c9f\",\"title\":\"Spatial-Temporal Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/99cea5d749086408983e54e4ce7e27a5d35e9c9f\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"46461307\",\"name\":\"S. Z. Gilani\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"},{\"authorId\":\"9493788\",\"name\":\"Han-lin Qin\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.3390/s20236941\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"title\":\"Self-Supervised Learning to Detect Key Frames in Videos\",\"url\":\"https://www.semanticscholar.org/paper/61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.02100\",\"authors\":[{\"authorId\":\"153037548\",\"name\":\"S. H. Shabbeer Basha\"},{\"authorId\":\"51485920\",\"name\":\"Viswanath Pulabaigari\"},{\"authorId\":\"34356161\",\"name\":\"Snehasis Mukherjee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42bf5be4b315c0eb68dd8d7fd4a6519304217c25\",\"title\":\"An Information-rich Sampling Technique over Spatio-Temporal CNN for Classification of Human Actions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/42bf5be4b315c0eb68dd8d7fd4a6519304217c25\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.10553\",\"authors\":[{\"authorId\":\"1587802238\",\"name\":\"Ifrah Idrees\"},{\"authorId\":\"1684347\",\"name\":\"S. Reiss\"},{\"authorId\":\"2913681\",\"name\":\"Stefanie Tellex\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b59ad020f7393319f969399790ad584c4068fda3\",\"title\":\"RoboMem: Giving Long Term Memory to Robots\",\"url\":\"https://www.semanticscholar.org/paper/b59ad020f7393319f969399790ad584c4068fda3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"50469612\",\"name\":\"Guangyu Guo\"},{\"authorId\":null,\"name\":\"Dong Huang\"},{\"authorId\":\"145877494\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87e3a8c0429a2d8c4349f9b55fce4ff2c8540deb\",\"title\":\"presented a deep 3 D convolutional architecture that models the flow estimation problem as a \\u201c Voxel 2 Voxel \\u201d prediction problem\",\"url\":\"https://www.semanticscholar.org/paper/87e3a8c0429a2d8c4349f9b55fce4ff2c8540deb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5970591\",\"name\":\"P. G. Shambharkar\"},{\"authorId\":\"145015417\",\"name\":\"M. N. Doja\"}],\"doi\":\"10.1007/s11042-020-08922-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0c657f8e1a41e06c629ad85cdac81363c6e91745\",\"title\":\"Movie trailer classification using deer hunting optimization based deep convolutional neural network in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/0c657f8e1a41e06c629ad85cdac81363c6e91745\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79823975\",\"name\":\"Utkarsh Shreemali\"},{\"authorId\":\"46264522\",\"name\":\"A. Chakraborty\"}],\"doi\":\"10.1007/s11042-020-10132-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"278d3594b44f2552be36fe3d33b909e3f8eb01bb\",\"title\":\"Robust gait based human identification on incomplete and multi-view sequences\",\"url\":\"https://www.semanticscholar.org/paper/278d3594b44f2552be36fe3d33b909e3f8eb01bb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.05896\",\"authors\":[{\"authorId\":\"30174297\",\"name\":\"Congrui Hetang\"},{\"authorId\":\"46636770\",\"name\":\"Hongwei Qin\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c3a7279581df2c01af56b9f7141ab3e8d202aca\",\"title\":\"Impression Network for Video Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c3a7279581df2c01af56b9f7141ab3e8d202aca\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2905296\",\"name\":\"Hanchuan Xu\"},{\"authorId\":\"2056790\",\"name\":\"Y. Pan\"},{\"authorId\":\"8549633\",\"name\":\"J. Li\"},{\"authorId\":\"49954387\",\"name\":\"L. Nie\"},{\"authorId\":\"1785762\",\"name\":\"X. Xu\"}],\"doi\":\"10.1109/ACCESS.2019.2894184\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ca0aaa47b184449372072ba9db0e587b261986a2\",\"title\":\"Activity Recognition Method for Home-Based Elderly Care Service Based on Random Forest and Activity Similarity\",\"url\":\"https://www.semanticscholar.org/paper/ca0aaa47b184449372072ba9db0e587b261986a2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32062468\",\"name\":\"H. Ou\"},{\"authorId\":\"2994709\",\"name\":\"J. Sun\"}],\"doi\":\"10.1117/1.JEI.28.2.023009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"title\":\"Spatiotemporal information deep fusion network with frame attention mechanism for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fbb35c26df06eb8e0afe82d1213b8561af4af7a5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1810.11189\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"145681036\",\"name\":\"Xiao Tan\"},{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"39826117\",\"name\":\"Kaiyu Yue\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1007/978-3-030-01228-1_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1102250a0fae62263979b32ad3c25749be9bca6b\",\"title\":\"Fine-Grained Video Categorization with Redundancy Reduction Attention\",\"url\":\"https://www.semanticscholar.org/paper/1102250a0fae62263979b32ad3c25749be9bca6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.01448\",\"authors\":[{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce407c2899ac955fa67dc7f6ba3a7f07ecd18855\",\"title\":\"Understanding Visual Ads by Aligning Symbols and Objects using Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/ce407c2899ac955fa67dc7f6ba3a7f07ecd18855\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144130711\",\"name\":\"C. Lin\"},{\"authorId\":\"2003807524\",\"name\":\"Mengxiang Lin\"},{\"authorId\":\"2003808280\",\"name\":\"Suhui Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3032430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25db1ba302821f83040021e164e34d323354b154\",\"title\":\"SOPNet Method for the Fine-Grained Measurement and Prediction of Precipitation Intensity Using Outdoor Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/25db1ba302821f83040021e164e34d323354b154\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"50469612\",\"name\":\"Guangyu Guo\"},{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/CVPR.2018.00707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f8b1030baee3c1350662903d76510754793db83\",\"title\":\"PoseFlow: A Deep Motion Representation for Understanding Human Behaviors in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0f8b1030baee3c1350662903d76510754793db83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"47628927\",\"name\":\"Mingyang Li\"},{\"authorId\":null,\"name\":\"He Bai\"},{\"authorId\":\"88502672\",\"name\":\"L. Ma\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"}],\"doi\":\"10.1007/s00521-019-04030-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"title\":\"DKD\\u2013DAD: a novel framework with discriminative kinematic descriptor and deep attention-pooled descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/55995e4ac050563d10cbcdc07a79b729ccd1b25b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"1907.05023\",\"authors\":[{\"authorId\":\"3381691\",\"name\":\"Yante Li\"},{\"authorId\":\"46423139\",\"name\":\"Xiaohua Huang\"},{\"authorId\":\"1757287\",\"name\":\"Guoying Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2dba6123c278ab7be92cc21cd18b74bb9db97eb3\",\"title\":\"Micro-expression Action Unit Detection withSpatio-temporal Adaptive Pooling\",\"url\":\"https://www.semanticscholar.org/paper/2dba6123c278ab7be92cc21cd18b74bb9db97eb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1819203\",\"name\":\"Zufan Zhang\"},{\"authorId\":\"2000399066\",\"name\":\"Zongming Lv\"},{\"authorId\":\"2901849\",\"name\":\"Chenquan Gan\"},{\"authorId\":\"145649216\",\"name\":\"Qingyi Zhu\"}],\"doi\":\"10.1016/j.neucom.2020.06.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"851edff1c8deded530836d0338ea6cbe50f30594\",\"title\":\"Human action recognition using convolutional LSTM and fully-connected LSTM with different attentions\",\"url\":\"https://www.semanticscholar.org/paper/851edff1c8deded530836d0338ea6cbe50f30594\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145309464\",\"name\":\"Min Jiang\"},{\"authorId\":\"51010977\",\"name\":\"N. Pan\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"}],\"doi\":\"10.1016/j.jvcir.2020.102846\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"title\":\"Spatial-temporal saliency action mask attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10250\",\"authors\":[{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"31170827\",\"name\":\"J. Meng\"},{\"authorId\":\"2019493593\",\"name\":\"Jin Zhou\"},{\"authorId\":\"2004175\",\"name\":\"Dongyan Guo\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"1739956171\",\"name\":\"Jianhua Zhang\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"1739189491\",\"name\":\"Shengyong Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"title\":\"LAGNet: Logic-Aware Graph Network for Human Interaction Understanding\",\"url\":\"https://www.semanticscholar.org/paper/2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7766883\",\"name\":\"Zhi-Yi Lin\"},{\"authorId\":\"34422142\",\"name\":\"J. Chen\"},{\"authorId\":\"1714180\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/ISCAS.2018.8350912\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"title\":\"A 65 fps Full-HD Hardware Implementation of HOG, HOF, MBHx, and MBHy for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9fc4d25c13c49536bdb9c4d2b78d6739635da68a\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2515126\",\"name\":\"Yuanyao Lu\"},{\"authorId\":\"144518459\",\"name\":\"Jie Yan\"}],\"doi\":\"10.1142/S0218001420540038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c62ce4d3fa9dad6d0568d4107fdb6bab05c0ba9\",\"title\":\"Automatic Lip Reading Using Convolution Neural Network and Bidirectional Long Short-term Memory\",\"url\":\"https://www.semanticscholar.org/paper/5c62ce4d3fa9dad6d0568d4107fdb6bab05c0ba9\",\"venue\":\"Int. J. Pattern Recognit. Artif. Intell.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1909523920\",\"name\":\"Jen-Kai Tsai\"},{\"authorId\":\"144926927\",\"name\":\"Chen-Chien Hsu\"},{\"authorId\":\"2653046\",\"name\":\"W. Wang\"},{\"authorId\":\"2814144\",\"name\":\"Shao-Kang Huang\"}],\"doi\":\"10.3390/s20174758\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9923da669485dfa56e69e4b8f4bb5620ea2161ba\",\"title\":\"Deep Learning-Based Real-Time Multiple-Person Action Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/9923da669485dfa56e69e4b8f4bb5620ea2161ba\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"title\":\"Part-aligned pose-guided recurrent network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1707.06830\",\"authors\":[{\"authorId\":\"145784776\",\"name\":\"R. Sharma\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"},{\"authorId\":\"144054467\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV.2018.00058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5531b5626c1ee3b6f9aed281a98338439d06d12\",\"title\":\"Multichannel Attention Network for Analyzing Visual Behavior in Public Speaking\",\"url\":\"https://www.semanticscholar.org/paper/a5531b5626c1ee3b6f9aed281a98338439d06d12\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151493680\",\"name\":\"Jingjun Chen\"},{\"authorId\":\"1682580\",\"name\":\"Y. Song\"},{\"authorId\":\"1591129121\",\"name\":\"Yuanlin Zhang\"}],\"doi\":\"10.1109/ICME.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"title\":\"Spatial Mask ConvLSTM Network and Intra-Class Joint Training Method for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"49185004\",\"name\":\"Shuhang Wang\"},{\"authorId\":\"46285365\",\"name\":\"Yifan Yang\"},{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"}],\"doi\":\"10.1007/s00138-018-0956-5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"title\":\"End-to-end temporal attention extraction and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"51036717\",\"name\":\"J. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f72405e74c3c4f962c4821bf5f34b9106009801c\",\"title\":\"Unsupervised Deep Learning of Mid-Level Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f72405e74c3c4f962c4821bf5f34b9106009801c\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781560\",\"name\":\"Z. Liu\"},{\"authorId\":\"66454724\",\"name\":\"Zeya Li\"},{\"authorId\":\"150238936\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"152714157\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1007/978-981-15-3651-9_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9de826c60e7258e2a69b74836213fec465ef2601\",\"title\":\"Spatiotemporal Saliency Based Multi-stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9de826c60e7258e2a69b74836213fec465ef2601\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1803.10861\",\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"title\":\"Memory Warps for Learning Long-Term Online Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-58610-2_40\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19d574a2238ad11142de1d6f2713315880b2d218\",\"title\":\"Shuffle and Attend: Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/19d574a2238ad11142de1d6f2713315880b2d218\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1906.09955\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1109/TIP.2019.2925285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"title\":\"A Comparative Review of Recent Kinect-Based Action Recognition Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904697\",\"name\":\"Zhenbing Liu\"},{\"authorId\":\"1796258521\",\"name\":\"Zeya Li\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"51251812\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"}],\"doi\":\"10.1007/s00521-020-05144-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"575448ab04aef0856a73d8eba3a75a5321e0506d\",\"title\":\"Spatiotemporal saliency-based multi-stream networks with attention-aware LSTM for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/575448ab04aef0856a73d8eba3a75a5321e0506d\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145799039\",\"name\":\"N. Akhtar\"},{\"authorId\":\"51322338\",\"name\":\"U. Ragavendran\"}],\"doi\":\"10.1007/s00521-019-04296-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a443e06ba4966090d48bd8d15774ae368a6f89d7\",\"title\":\"Interpretation of intelligence in CNN-pooling processes: a methodological survey\",\"url\":\"https://www.semanticscholar.org/paper/a443e06ba4966090d48bd8d15774ae368a6f89d7\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2944007\",\"name\":\"Guanghua Tan\"},{\"authorId\":\"1883252\",\"name\":\"Rui Miao\"},{\"authorId\":\"151471091\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1007/978-3-030-30508-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"title\":\"Action Recognition Based on Divide-and-Conquer\",\"url\":\"https://www.semanticscholar.org/paper/53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4399218\",\"name\":\"F. Wang\"},{\"authorId\":\"9418656\",\"name\":\"Shusen Zhao\"},{\"authorId\":\"51053159\",\"name\":\"Xingqun Zhou\"},{\"authorId\":\"49673074\",\"name\":\"C. Li\"},{\"authorId\":\"152303276\",\"name\":\"Mingyao Li\"},{\"authorId\":\"46490640\",\"name\":\"Z. Zeng\"}],\"doi\":\"10.3390/s19112495\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c30024ffc4af7bf2b98f21ed27f3cea343798c9\",\"title\":\"An Recognition\\u2013Verification Mechanism for Real-Time Chinese Sign Language Recognition Based on Multi-Information Fusion\",\"url\":\"https://www.semanticscholar.org/paper/5c30024ffc4af7bf2b98f21ed27f3cea343798c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758964\",\"name\":\"Jie Yan\"},{\"authorId\":\"1783055\",\"name\":\"Guihe Qin\"},{\"authorId\":\"10431066\",\"name\":\"R. Zhao\"},{\"authorId\":\"46992126\",\"name\":\"Yan-hua Liang\"},{\"authorId\":\"150270946\",\"name\":\"Qianyi Xu\"}],\"doi\":\"10.1109/ACCESS.2019.2961383\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"title\":\"Mixpred: Video Prediction Beyond Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/c19ef8d8dfefb8ca898fc3b9b58cb3b499ed3836\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46176327\",\"name\":\"A. Jahagirdar\"},{\"authorId\":\"9349710\",\"name\":\"M. Nagmode\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"837e4ae747a03bd7a52599e9f4686b4856cf39c5\",\"title\":\"Human Action Recognition using Ensemble of Shape, Texture and Motion features\",\"url\":\"https://www.semanticscholar.org/paper/837e4ae747a03bd7a52599e9f4686b4856cf39c5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"144805693\",\"name\":\"C. Kuo\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"103483753\",\"name\":\"Yu-Hung Liu\"},{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"1491078400\",\"name\":\"Zijun Li\"},{\"authorId\":\"121418048\",\"name\":\"J. Shen\"},{\"authorId\":\"1743408\",\"name\":\"L. Fu\"}],\"doi\":\"10.1109/IROS40897.2019.8968533\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f98c4ae113621fdddaf5321b6f2f22310698f994\",\"title\":\"ResFlow: Multi-tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/f98c4ae113621fdddaf5321b6f2f22310698f994\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"49543595\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/SmartWorld.2018.00123\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"303b832123a0d219e91a3e0bed337d74f68b3fcc\",\"title\":\"Constructing Hierarchical Spatiotemporal Information for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/303b832123a0d219e91a3e0bed337d74f68b3fcc\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145505204\",\"name\":\"J. Guo\"},{\"authorId\":\"2245433\",\"name\":\"Hao Bai\"},{\"authorId\":\"2238603\",\"name\":\"Z. Tang\"},{\"authorId\":\"47569011\",\"name\":\"P. Xu\"},{\"authorId\":\"1723390275\",\"name\":\"Daguang Gan\"},{\"authorId\":\"50677991\",\"name\":\"B. Liu\"}],\"doi\":\"10.1007/s11042-020-08998-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3d45565c3dd515afdf7f90510a410e918b3c4d8\",\"title\":\"Multi modal human action recognition for video content matching\",\"url\":\"https://www.semanticscholar.org/paper/f3d45565c3dd515afdf7f90510a410e918b3c4d8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020}],\"corpusId\":9162411,\"doi\":\"10.1109/CVPR.2017.604\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":13,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"574ad7ef015995efb7338829a021776bf9daaa08\",\"references\":[{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1504.05524\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-015-0846-5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"title\":\"A Robust and Efficient Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"144954807\",\"name\":\"Q. Dai\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1007/978-3-642-33715-4_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b071b910f8dc0c64c26730da144cddbedc29ed07\",\"title\":\"Trajectory-Based Modeling of Human Actions with Motion Reference Points\",\"url\":\"https://www.semanticscholar.org/paper/b071b910f8dc0c64c26730da144cddbedc29ed07\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"50678963\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/CVPR.2012.6247808\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6acdddc36ea57ec84581e9e196665f246e8157ab\",\"title\":\"Learning latent temporal structure for complex event detection\",\"url\":\"https://www.semanticscholar.org/paper/6acdddc36ea57ec84581e9e196665f246e8157ab\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Donahue\"},{\"authorId\":null,\"name\":\"L. Anne Hendricks\"},{\"authorId\":null,\"name\":\"S. Guadarrama\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"},{\"authorId\":null,\"name\":\"S. Venugopalan\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2013.342\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9bc95b2fa949b0de6ef028fde359e2a60fceee04\",\"title\":\"Poselet Key-Framing: A Model for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9bc95b2fa949b0de6ef028fde359e2a60fceee04\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1411.6660\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144247571\",\"name\":\"Ming Lin\"},{\"authorId\":\"2314980\",\"name\":\"X. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":\"10.1109/CVPR.2015.7298616\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"title\":\"Beyond Gaussian Pyramid: Multi-skip Feature Stacking for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/10af69f11301679b6fbb23855bf10f6af1f3d2e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":\"1512.01848\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/TPAMI.2016.2558148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4defba71c686946351f5e7a090c7aa8136d32f\",\"title\":\"Rank Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4defba71c686946351f5e7a090c7aa8136d32f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A comparative study of encoding\",\"url\":\"\",\"venue\":\"pooling and normalization methods for action recognition. In ACCV\",\"year\":2012},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cisco White\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Cisco vni forecast and methodology, 2015-2020. http://www.cisco.com/c/en/us/ solutions/collateral/service-provider/ visual-networking-index-vni/ complete-white-paper-c11-481360\",\"url\":\"\",\"venue\":\"Cisco vni forecast and methodology, 2015-2020. http://www.cisco.com/c/en/us/ solutions/collateral/service-provider/ visual-networking-index-vni/ complete-white-paper-c11-481360\",\"year\":2016},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2015.7299056\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2cf5ff18580c6073e555cf34793d71a63b40d406\",\"title\":\"Multiple instance learning for soft bags via top instances\",\"url\":\"https://www.semanticscholar.org/paper/2cf5ff18580c6073e555cf34793d71a63b40d406\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"31064779\",\"name\":\"W. Zhang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/ICCV.2013.442\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21e8f3344170a8f133b69308c178518df8a27274\",\"title\":\"Action Recognition with Actons\",\"url\":\"https://www.semanticscholar.org/paper/21e8f3344170a8f133b69308c178518df8a27274\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"2487006\",\"name\":\"Brian Fulkerson\"}],\"doi\":\"10.1145/1873951.1874249\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d720a95e1501922ea17ee31f299f43b2db5e15ef\",\"title\":\"Vlfeat: an open and portable library of computer vision algorithms\",\"url\":\"https://www.semanticscholar.org/paper/d720a95e1501922ea17ee31f299f43b2db5e15ef\",\"venue\":\"ACM Multimedia\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2013.65\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"title\":\"Temporal Localization of Actions with Actoms\",\"url\":\"https://www.semanticscholar.org/paper/404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Sharma\"},{\"authorId\":null,\"name\":\"R Kiros\"},{\"authorId\":null,\"name\":\"R Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Action recognition using visual attention. arXiv preprint arXiv:1511\",\"url\":\"\",\"venue\":\"Action recognition using visual attention. arXiv preprint arXiv:1511\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"2976163\",\"name\":\"Kuiyuan Yang\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2016.106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26201e1b76f276187e31c7db84eab0bfcda01102\",\"title\":\"You Lead, We Exceed: Labor-Free Video Concept Learning by Jointly Exploiting Web Videos and Images\",\"url\":\"https://www.semanticscholar.org/paper/26201e1b76f276187e31c7db84eab0bfcda01102\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"120896463\",\"name\":\"Chih-Wei Chen\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15552-9_29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"994a7b903b937f8b177c035db86852091fd26aa7\",\"title\":\"Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/994a7b903b937f8b177c035db86852091fd26aa7\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2949240\",\"name\":\"Scott Satkin\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-642-15549-9_39\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d34869f88eede4c0dd6315f8489dcd5d1b6da42\",\"title\":\"Modeling the Temporal Extent of Actions\",\"url\":\"https://www.semanticscholar.org/paper/4d34869f88eede4c0dd6315f8489dcd5d1b6da42\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1604.06397\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2016.295\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae7122103f0868995ea2b53695479af553ab1361\",\"title\":\"Improving Human Action Recognition by Non-action Classification\",\"url\":\"https://www.semanticscholar.org/paper/ae7122103f0868995ea2b53695479af553ab1361\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W. Xu S. Ji\"},{\"authorId\":null,\"name\":\"M. Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bengio . Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"\",\"venue\":\"International Conference on Artificial Intelligence and Statistics\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/WACV.2013.6474994\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6ad6f3d311b6fc2fe7c4f85077b24d59c208452\",\"title\":\"Large-scale web video event classification by use of Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/f6ad6f3d311b6fc2fe7c4f85077b24d59c208452\",\"venue\":\"2013 IEEE Workshop on Applications of Computer Vision (WACV)\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048032\",\"name\":\"P. Scovanner\"},{\"authorId\":\"38245610\",\"name\":\"Saad Ali\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1145/1291233.1291311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"title\":\"A 3-dimensional sift descriptor and its application to action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"venue\":\"ACM Multimedia\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-013-0677-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d83c2948c37421913c425a76c3dcc292fac0471d\",\"title\":\"Activity representation with motion hierarchies\",\"url\":\"https://www.semanticscholar.org/paper/d83c2948c37421913c425a76c3dcc292fac0471d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"E. Gavves\"},{\"authorId\":null,\"name\":\"M. Jain\"},{\"authorId\":null,\"name\":\"C. G. Snoek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Videolstm convolves\",\"url\":\"\",\"venue\":\"attends and flows for action recognition. arXiv preprint arXiv:1607.01794\",\"year\":2016},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2013.333\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b11228f6ce7d681a2a065b4ba191a51456671d29\",\"title\":\"Mining Motion Atoms and Phrases for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b11228f6ce7d681a2a065b4ba191a51456671d29\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1007/978-3-642-37431-9_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"536bd55a69a5f536fc4450ac4f482d47333b0270\",\"title\":\"A Comparative Study of Encoding, Pooling and Normalization Methods for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/536bd55a69a5f536fc4450ac4f482d47333b0270\",\"venue\":\"ACCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2015.7298698\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"title\":\"ActivityNet: A large-scale video benchmark for human activity understanding\",\"url\":\"https://www.semanticscholar.org/paper/0a28efacb92d16e6e0dd4d87b5aca91b28be8853\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/ICCV.2013.339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70a97b4191e31bd5c6d2aef82ff6086dfb1282db\",\"title\":\"Dynamic Pooling for Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/70a97b4191e31bd5c6d2aef82ff6086dfb1282db\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. Anne Hendricks J. Donahue\"},{\"authorId\":null,\"name\":\"S. Guadarrama\"},{\"authorId\":null,\"name\":\"M. Rohrbach\"},{\"authorId\":null,\"name\":\"S. Venugopalan\"},{\"authorId\":null,\"name\":\"K. Saenko\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015}],\"title\":\"AdaScan: Adaptive Scan Pooling in Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Overfitting\",\"topicId\":\"70499\",\"url\":\"https://www.semanticscholar.org/topic/70499\"},{\"topic\":\"Multiple instance learning\",\"topicId\":\"97196\",\"url\":\"https://www.semanticscholar.org/topic/97196\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Information\",\"topicId\":\"185548\",\"url\":\"https://www.semanticscholar.org/topic/185548\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Redundancy (engineering)\",\"topicId\":\"520284\",\"url\":\"https://www.semanticscholar.org/topic/520284\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Computational resource\",\"topicId\":\"36160\",\"url\":\"https://www.semanticscholar.org/topic/36160\"},{\"topic\":\"Relevance\",\"topicId\":\"503\",\"url\":\"https://www.semanticscholar.org/topic/503\"},{\"topic\":\"Sparse matrix\",\"topicId\":\"126\",\"url\":\"https://www.semanticscholar.org/topic/126\"},{\"topic\":\"Neural network software\",\"topicId\":\"172426\",\"url\":\"https://www.semanticscholar.org/topic/172426\"},{\"topic\":\"Importance sampling\",\"topicId\":\"96047\",\"url\":\"https://www.semanticscholar.org/topic/96047\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Integrated information theory\",\"topicId\":\"2033124\",\"url\":\"https://www.semanticscholar.org/topic/2033124\"},{\"topic\":\"Mean squared error\",\"topicId\":\"49130\",\"url\":\"https://www.semanticscholar.org/topic/49130\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Graham scan\",\"topicId\":\"912373\",\"url\":\"https://www.semanticscholar.org/topic/912373\"},{\"topic\":\"Titan\",\"topicId\":\"3876518\",\"url\":\"https://www.semanticscholar.org/topic/3876518\"},{\"topic\":\"Multiple-instance learning\",\"topicId\":\"97190\",\"url\":\"https://www.semanticscholar.org/topic/97190\"}],\"url\":\"https://www.semanticscholar.org/paper/574ad7ef015995efb7338829a021776bf9daaa08\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"