"{\"abstract\":\"We introduce the task of Visual Dialog, which requires an AI agent to hold a meaningful dialog with humans in natural, conversational language about visual content. Specifically, given an image, a dialog history, and a question about the image, the agent has to ground the question in image, infer context from history, and answer the question accurately. Visual Dialog is disentangled enough from a specific downstream task so as to serve as a general test of machine intelligence, while being grounded in vision enough to allow objective evaluation of individual responses and benchmark progress. We develop a novel two-person chat data-collection protocol to curate a large-scale Visual Dialog dataset (VisDial). VisDial contains 1 dialog (10 question-answer pairs) on ~140k images from the COCO dataset, with a total of ~1.4M dialog question-answer pairs. We introduce a family of neural encoder-decoder models for Visual Dialog with 3 encoders (Late Fusion, Hierarchical Recurrent Encoder and Memory Network) and 2 decoders (generative and discriminative), which outperform a number of sophisticated baselines. We propose a retrieval-based evaluation protocol for Visual Dialog where the AI agent is asked to sort a set of candidate answers and evaluated on metrics such as mean-reciprocal-rank of human response. We quantify gap between machine and human performance on the Visual Dialog task via human studies. Our dataset, code, and trained models will be released publicly at https://visualdialog.org. Putting it all together, we demonstrate the first visual chatbot!.\",\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\",\"url\":\"https://www.semanticscholar.org/author/145497716\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\",\"url\":\"https://www.semanticscholar.org/author/2150275\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\",\"url\":\"https://www.semanticscholar.org/author/39855500\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\",\"url\":\"https://www.semanticscholar.org/author/1899992\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\",\"url\":\"https://www.semanticscholar.org/author/24508084\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\",\"url\":\"https://www.semanticscholar.org/author/144915495\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\",\"url\":\"https://www.semanticscholar.org/author/1746610\"}],\"citationVelocity\":98,\"citations\":[{\"arxivId\":\"2002.06484\",\"authors\":[{\"authorId\":\"2081195\",\"name\":\"Tzu-Hsiang Lin\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"153586399\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"255d135eefd7a21c53cf0230d1ef7d765d00dc89\",\"title\":\"A Multimodal Dialogue System for Conversational Image Editing\",\"url\":\"https://www.semanticscholar.org/paper/255d135eefd7a21c53cf0230d1ef7d765d00dc89\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152176221\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"33201965\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"1410148565\",\"name\":\"Karina Kanjaria\"},{\"authorId\":\"1388126424\",\"name\":\"Adam Coy\"},{\"authorId\":\"13403287\",\"name\":\"D. Ballah\"},{\"authorId\":\"2230103\",\"name\":\"Yufan Guo\"},{\"authorId\":\"33348864\",\"name\":\"J. Wu\"},{\"authorId\":\"46474962\",\"name\":\"A. Karargyris\"},{\"authorId\":\"1740300\",\"name\":\"D. Beymer\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"},{\"authorId\":\"80257800\",\"name\":\"Vandana Mukherjee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc71a905ca132999a158857823606cd979b9080e\",\"title\":\"Visual Dialog for Radiology: Data Curation and FirstSteps\",\"url\":\"https://www.semanticscholar.org/paper/cc71a905ca132999a158857823606cd979b9080e\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2200cb5e584288f1cef8f83d5a746d2df86e322f\",\"title\":\"NIPS 2018 Competition Track Day 1\",\"url\":\"https://www.semanticscholar.org/paper/2200cb5e584288f1cef8f83d5a746d2df86e322f\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2486c41d1ec20dd53de912c77035743816638b6\",\"title\":\"An Active Information Seeking Model for Goal-oriented Vision-and-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/c2486c41d1ec20dd53de912c77035743816638b6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.03322\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"9072379\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"336cad600d15832243f4228b351c638630d64cb7\",\"title\":\"Learning to Respond with Your Favorite Stickers: A Framework of Unifying Multi-Modality and User Preference in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/336cad600d15832243f4228b351c638630d64cb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144343783\",\"name\":\"Stacy Black\"}],\"doi\":\"10.18122/td/1708/boisestate\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e476e4528ec8b6314dbc02b3bc3d2c00d39d999a\",\"title\":\"TOWARDS UNIFYING GROUNDED AND DISTRIBUTIONAL SEMANTICS USING THE WORDS-AS-CLASSIFIERS MODEL OF LEXICAL SEMANTICS\",\"url\":\"https://www.semanticscholar.org/paper/e476e4528ec8b6314dbc02b3bc3d2c00d39d999a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.05639\",\"authors\":[{\"authorId\":\"150324514\",\"name\":\"Tejas Srinivasan\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053397\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cefadbc725429f43700bba049782541595a0ce34\",\"title\":\"Looking Enhances Listening: Recovering Missing Speech Using Images\",\"url\":\"https://www.semanticscholar.org/paper/cefadbc725429f43700bba049782541595a0ce34\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1909.10470\",\"authors\":[{\"authorId\":\"46258988\",\"name\":\"Vishvak S. Murahari\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"}],\"doi\":\"10.18653/v1/D19-1152\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2f4a35e0beeed69799cd9418387e109d64f50c81\",\"title\":\"Improving Generative Visual Dialog by Answering Diverse Questions\",\"url\":\"https://www.semanticscholar.org/paper/2f4a35e0beeed69799cd9418387e109d64f50c81\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1694585\",\"name\":\"Fanglin Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"title\":\"Referring Expression Grounding by Marginalizing Scene Graph Likelihood\",\"url\":\"https://www.semanticscholar.org/paper/4989328e24f9b405a082ae6f99dd2ec9bad2c015\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1703.05423\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1808897\",\"name\":\"B. Piot\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.24963/ijcai.2017/385\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2cf792165eed4c0bfb25548f5dd63f43dca67a4\",\"title\":\"End-to-end optimization of goal-driven and visually grounded dialogue systems\",\"url\":\"https://www.semanticscholar.org/paper/e2cf792165eed4c0bfb25548f5dd63f43dca67a4\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2008177645\",\"name\":\"Hisashi Kamezawa\"},{\"authorId\":\"8058716\",\"name\":\"Noriki Nishida\"},{\"authorId\":\"3037066\",\"name\":\"N. Shimizu\"},{\"authorId\":\"47615106\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.267\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"88288c5ebea5da91bb699ec0cd2d9806f06955c1\",\"title\":\"A Visually-grounded First-person Dialogue Dataset with Verbal and Non-verbal Responses\",\"url\":\"https://www.semanticscholar.org/paper/88288c5ebea5da91bb699ec0cd2d9806f06955c1\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714708\",\"name\":\"S. Lee\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"975af82c9ce82a1fad760d58ba0a661217689aa9\",\"title\":\"Answerer in Questioner's Mind for Goal-Oriented Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/975af82c9ce82a1fad760d58ba0a661217689aa9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.07036\",\"authors\":[{\"authorId\":\"2890423\",\"name\":\"Eunsol Choi\"},{\"authorId\":\"144533687\",\"name\":\"He He\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"},{\"authorId\":\"144105277\",\"name\":\"Wen-tau Yih\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":\"10.18653/v1/D18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e734da43eb8c72e9549b42e96760545036f8e5\",\"title\":\"QuAC : Question Answering in Context\",\"url\":\"https://www.semanticscholar.org/paper/39e734da43eb8c72e9549b42e96760545036f8e5\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1807810\",\"name\":\"Gemma Boleda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0434b16a363d88e27a1b36fc68e04451cc3725b9\",\"title\":\"Object Naming in Language and Vision: A Survey and a New Dataset\",\"url\":\"https://www.semanticscholar.org/paper/0434b16a363d88e27a1b36fc68e04451cc3725b9\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1807.03367\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56a0ead811a1bf15e42be8a9a007b0299636f213\",\"title\":\"Talk the Walk: Navigating New York City through Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/56a0ead811a1bf15e42be8a9a007b0299636f213\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430216\",\"name\":\"Y. Tamaazousti\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"619404bf9fd0f55eeabb94f0cebf190399c57f0a\",\"title\":\"Vers l\\u2019universalit\\u00e9 des repr\\u00e9sentations visuelle et multimodales\",\"url\":\"https://www.semanticscholar.org/paper/619404bf9fd0f55eeabb94f0cebf190399c57f0a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"title\":\"Visual Question Answering and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/42afa9a0166eeb45cb2e9b37e0a8eec482f78fe0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.02234\",\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"},{\"authorId\":\"1924996\",\"name\":\"S. Herbin\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-20890-5_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"title\":\"Semantic bottleneck for computer vision tasks\",\"url\":\"https://www.semanticscholar.org/paper/ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"title\":\"Learning Latent Graph Representations for Relational VQA\",\"url\":\"https://www.semanticscholar.org/paper/6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.01494\",\"authors\":[{\"authorId\":\"2073055\",\"name\":\"Marzieh Saeidi\"},{\"authorId\":\"153408953\",\"name\":\"Max Bartolo\"},{\"authorId\":\"145222654\",\"name\":\"Patrick Lewis\"},{\"authorId\":\"34650964\",\"name\":\"Sameer Singh\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"},{\"authorId\":\"40490461\",\"name\":\"M. Sheldon\"},{\"authorId\":\"1684865\",\"name\":\"Guillaume Bouchard\"},{\"authorId\":\"145941664\",\"name\":\"S. Riedel\"}],\"doi\":\"10.18653/v1/D18-1233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd832f7081ab7b83240140c4e5e58b4fb1f8e0e6\",\"title\":\"Interpretation of Natural Language Rules in Conversational Machine Reading\",\"url\":\"https://www.semanticscholar.org/paper/cd832f7081ab7b83240140c4e5e58b4fb1f8e0e6\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1911.03768\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.222\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3066ec95113636ca546cf4339772fbd495c27e4\",\"title\":\"The Dialogue Dodecathlon: Open-Domain Knowledge and Image Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/d3066ec95113636ca546cf4339772fbd495c27e4\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"32113652\",\"name\":\"G. Gandolfi\"},{\"authorId\":\"2008208159\",\"name\":\"Eleonora Gualdoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"title\":\"Be Different to Be Better! A Benchmark to Leverage the Complementarity of Language and Vision\",\"url\":\"https://www.semanticscholar.org/paper/caba4881b921c43f4562ed6b6aa8f07b971a6fa2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2008.00397\",\"authors\":[{\"authorId\":\"51115516\",\"name\":\"L. Yang\"},{\"authorId\":\"49435166\",\"name\":\"Fanqi Meng\"},{\"authorId\":\"31395194\",\"name\":\"Ming-Kuang Daniel Wu\"},{\"authorId\":\"1850625173\",\"name\":\"Vicent Ying\"},{\"authorId\":\"150345115\",\"name\":\"Xianchao Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c711f0b0f9e214d6ee462cffcac733221bf07026\",\"title\":\"SeqDialN: Sequential Visual Dialog Networks in Joint Visual-Linguistic Representation Space\",\"url\":\"https://www.semanticscholar.org/paper/c711f0b0f9e214d6ee462cffcac733221bf07026\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2715920\",\"name\":\"Malihe Alikhani\"},{\"authorId\":\"144884556\",\"name\":\"Matthew Stone\"}],\"doi\":\"10.18653/v1/2020.acl-tutorials.3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204efba21762723e1f7f64487dba545222ccef36\",\"title\":\"Achieving Common Ground in Multi-modal Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/204efba21762723e1f7f64487dba545222ccef36\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4009206\",\"name\":\"O. Kovaleva\"},{\"authorId\":\"1866532\",\"name\":\"Chaitanya Shivade\"},{\"authorId\":\"33201965\",\"name\":\"Satyananda Kashyap\"},{\"authorId\":\"1410148565\",\"name\":\"Karina Kanjaria\"},{\"authorId\":\"40346984\",\"name\":\"Joy T. Wu\"},{\"authorId\":\"13403287\",\"name\":\"D. Ballah\"},{\"authorId\":\"1388126424\",\"name\":\"Adam Coy\"},{\"authorId\":\"2308391\",\"name\":\"Alexandros Karargyris\"},{\"authorId\":\"2230103\",\"name\":\"Yufan Guo\"},{\"authorId\":\"1768272818\",\"name\":\"David James Beymer\"},{\"authorId\":\"1681193\",\"name\":\"Anna Rumshisky\"},{\"authorId\":\"80257800\",\"name\":\"Vandana Mukherjee\"}],\"doi\":\"10.18653/v1/2020.bionlp-1.6\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"title\":\"Towards Visual Dialog for Radiology\",\"url\":\"https://www.semanticscholar.org/paper/6609489a0f800a9ef411efdcfca4c014c4e86aa8\",\"venue\":\"BioNLP\",\"year\":2020},{\"arxivId\":\"2008.04858\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"1643931890\",\"name\":\"Siyi Du\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"}],\"doi\":\"10.1145/3394171.3413826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"title\":\"KBGN: Knowledge-Bridge Graph Network for Adaptive Vision-Text Reasoning in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5c03ca2e4c26e868b7405e6782c72b85b16db8e4\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"title\":\"Bilinear Graph Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.00185\",\"authors\":[{\"authorId\":\"50811366\",\"name\":\"Haojie Pan\"},{\"authorId\":\"4645572\",\"name\":\"Junpei Zhou\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"49420788\",\"name\":\"Y. Liu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144346838\",\"name\":\"Min Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c682ff7a573082c5b69880c4bf84cdd464b70ae5\",\"title\":\"Dial2Desc: End-to-end Dialogue Description Generation\",\"url\":\"https://www.semanticscholar.org/paper/c682ff7a573082c5b69880c4bf84cdd464b70ae5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.06960\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"51190347\",\"name\":\"Tim Baumg\\u00e4rtner\"},{\"authorId\":\"46176433\",\"name\":\"Aashish Venkatesh\"},{\"authorId\":\"2552871\",\"name\":\"Elia Bruni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f59c20298f25bebda3f98eeb41f16ce9abb5f35a\",\"title\":\"Ask No More: Deciding when to guess in referential visual dialogue\",\"url\":\"https://www.semanticscholar.org/paper/f59c20298f25bebda3f98eeb41f16ce9abb5f35a\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1808.07042\",\"authors\":[{\"authorId\":\"145732771\",\"name\":\"Siva Reddy\"},{\"authorId\":\"50536468\",\"name\":\"Danqi Chen\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.1162/tacl_a_00266\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"990a7b4eceedb6e053e6386269481bdfc42a1094\",\"title\":\"CoQA: A Conversational Question Answering Challenge\",\"url\":\"https://www.semanticscholar.org/paper/990a7b4eceedb6e053e6386269481bdfc42a1094\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2019},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50704161\",\"name\":\"Lingxuan Li\"},{\"authorId\":\"11232438\",\"name\":\"Yihong Zhao\"},{\"authorId\":\"96515479\",\"name\":\"Zhaorui Zhang\"},{\"authorId\":\"1733076573\",\"name\":\"Tianrui Niu\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"48631332\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-60457-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c0d407899b7c535ce90fa798309214902ae0cba\",\"title\":\"Referring Expression Generation via Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0c0d407899b7c535ce90fa798309214902ae0cba\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"49336556\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3350923\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7b13eff8ecec771e91a814b598fa33a24980f03\",\"title\":\"Multimodal Dialog System: Generating Responses via Adaptive Decoders\",\"url\":\"https://www.semanticscholar.org/paper/f7b13eff8ecec771e91a814b598fa33a24980f03\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9431441\",\"name\":\"Tran Duc Chung\"},{\"authorId\":\"1741027808\",\"name\":\"Ha Hong Son\"},{\"authorId\":\"9193538\",\"name\":\"A. Khalyasmaa\"}],\"doi\":\"10.1145/3385209.3385230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"618199043dbcc94eb2351f0f812cc0cca87e2d53\",\"title\":\"A Question Detection Algorithm for Text Analysis\",\"url\":\"https://www.semanticscholar.org/paper/618199043dbcc94eb2351f0f812cc0cca87e2d53\",\"venue\":\"ICIIT\",\"year\":2020},{\"arxivId\":\"1812.08352\",\"authors\":[{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":null,\"name\":\"Yitong Li\"},{\"authorId\":\"31617773\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8f2ba261756ca551ba68940e08a9466c2602f79\",\"title\":\"Sequential Attention GAN for Interactive Image Editing via Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/b8f2ba261756ca551ba68940e08a9466c2602f79\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2004.05595\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"217d80b1425c24996dafbe539a1e976a1e790ac0\",\"title\":\"Which visual questions are difficult to answer? Analysis with Entropy of Answer Distributions\",\"url\":\"https://www.semanticscholar.org/paper/217d80b1425c24996dafbe539a1e976a1e790ac0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10796\",\"authors\":[{\"authorId\":\"4868335\",\"name\":\"J. Park\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1007/978-3-030-58558-7_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4aacd623a46adc6a03c925fe3ac007c271c9c6ab\",\"title\":\"VisualCOMET: Reasoning About the Dynamic Context of a Still Image\",\"url\":\"https://www.semanticscholar.org/paper/4aacd623a46adc6a03c925fe3ac007c271c9c6ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.12794\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"2926307\",\"name\":\"Yupeng Gao\"},{\"authorId\":\"2071376\",\"name\":\"Steven J. Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f472b819ce521337c01e4ebf91714f93413d9997\",\"title\":\"Fashion IQ: A New Dataset towards Retrieving Images by Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/f472b819ce521337c01e4ebf91714f93413d9997\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.09151\",\"authors\":[{\"authorId\":\"29956361\",\"name\":\"Jyoti Aneja\"},{\"authorId\":\"113001756\",\"name\":\"A. Deshpande\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"title\":\"Convolutional Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9fb5e3db385588f671b11cfc8bf18efb90ee7b19\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.11649\",\"authors\":[{\"authorId\":\"39957046\",\"name\":\"U. Garg\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"80155427\",\"name\":\"Ram Ramrakhya\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"127759fc41d62b516298fff2706dfcc754ff1ee8\",\"title\":\"Fabrik: An Online Collaborative Neural Network Editor\",\"url\":\"https://www.semanticscholar.org/paper/127759fc41d62b516298fff2706dfcc754ff1ee8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.08824\",\"authors\":[{\"authorId\":\"2799898\",\"name\":\"Andreas Veit\"},{\"authorId\":\"29950139\",\"name\":\"K. Wilber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb37f62511aa4e4398223655e02a8682b0876ca9\",\"title\":\"Improving Calibration in Deep Metric Learning With Cross-Example Softmax\",\"url\":\"https://www.semanticscholar.org/paper/cb37f62511aa4e4398223655e02a8682b0876ca9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.14435\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdabd8bc1009e3ef2764a4e1dde20938aecad84\",\"title\":\"Towards Ecologically Valid Research on Language User Interfaces\",\"url\":\"https://www.semanticscholar.org/paper/6bdabd8bc1009e3ef2764a4e1dde20938aecad84\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.02194\",\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"46507139\",\"name\":\"Haibo Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.01007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0d2ea210c9bd21676605682a76cec1a4004320a\",\"title\":\"Iterative Context-Aware Graph Inference for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/a0d2ea210c9bd21676605682a76cec1a4004320a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1706.00130\",\"authors\":[{\"authorId\":\"18900686\",\"name\":\"Huan Ling\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7a9fe5781220cca6ca600833015f200a9c03d50e\",\"title\":\"Teaching Machines to Describe Images with Natural Language Feedback\",\"url\":\"https://www.semanticscholar.org/paper/7a9fe5781220cca6ca600833015f200a9c03d50e\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48071615\",\"name\":\"Huda Alamri\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"title\":\"Audio Visual Scene-aware dialog (AVSD) Track for Natural Language Generation in DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1706.05125\",\"authors\":[{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"13759615\",\"name\":\"Denis Yarats\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D17-1259\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a8dbea5e40831bd6e987c03b76487f45ac49599\",\"title\":\"Deal or No Deal? End-to-End Learning of Negotiation Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/6a8dbea5e40831bd6e987c03b76487f45ac49599\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11165439\",\"name\":\"Y. Yao\"},{\"authorId\":\"1396239754\",\"name\":\"Ver\\u00f3nica P\\u00e9rez-Rosas\"},{\"authorId\":\"1898814\",\"name\":\"Mohamed Abouelenien\"},{\"authorId\":\"1803815\",\"name\":\"Mihai Burzo\"}],\"doi\":\"10.1145/3382507.3418821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fab0028cab9949f7924241b922998811218882a0\",\"title\":\"MORSE: MultimOdal sentiment analysis for Real-life SEttings\",\"url\":\"https://www.semanticscholar.org/paper/fab0028cab9949f7924241b922998811218882a0\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405511901\",\"name\":\"Luis Fernando D'Haro\"},{\"authorId\":\"2237192\",\"name\":\"Koichiro Yoshino\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1725498\",\"name\":\"L. Polymenakos\"},{\"authorId\":\"1727211\",\"name\":\"Jonathan K. Kummerfeld\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"71886367\",\"name\":\"Xiang Gao\"}],\"doi\":\"10.1016/j.csl.2020.101068\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2da92688aef91371424f0e3ca5482c9f8dbe67b7\",\"title\":\"Overview of the seventh Dialog System Technology Challenge: DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/2da92688aef91371424f0e3ca5482c9f8dbe67b7\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3031950\",\"name\":\"Cecilia Mauceri\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"},{\"authorId\":\"40517238\",\"name\":\"C. Heckman\"}],\"doi\":\"10.1109/ICCVW.2019.00236\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ffddf6accc2c9696d6dbdf02dcc939bc1f81d8d\",\"title\":\"SUN-Spot: An RGB-D Dataset With Spatial Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/4ffddf6accc2c9696d6dbdf02dcc939bc1f81d8d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2007.03848\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03598364626c419d3a2578b5c22403f0dd246e99\",\"title\":\"Spatio-Temporal Scene Graphs for Video Dialog\",\"url\":\"https://www.semanticscholar.org/paper/03598364626c419d3a2578b5c22403f0dd246e99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.09034\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1007/978-3-030-58607-2_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29121a31e4d684839cfd0bb358f33ea1266cece5\",\"title\":\"Learning What Makes a Difference from Counterfactual Examples and Gradient Supervision\",\"url\":\"https://www.semanticscholar.org/paper/29121a31e4d684839cfd0bb358f33ea1266cece5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.11300\",\"authors\":[{\"authorId\":\"47183448\",\"name\":\"F. Lin\"},{\"authorId\":\"71819486\",\"name\":\"Rohit Mittapalli\"},{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"93728539\",\"name\":\"Daniel Bolya\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc9b3a04b0275f2cc28a5a432771cbd93850c496\",\"title\":\"Likelihood Landscapes: A Unifying Principle Behind Many Adversarial Defenses\",\"url\":\"https://www.semanticscholar.org/paper/bc9b3a04b0275f2cc28a5a432771cbd93850c496\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"title\":\"Engaging Image Chat: Modeling Personality in Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50627194\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"143924106\",\"name\":\"R. Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.3390/s20082281\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"779a14591ce143820a3d8c7661e04454329e3abc\",\"title\":\"Multi-View Visual Question Answering with Active Viewpoint Selection\",\"url\":\"https://www.semanticscholar.org/paper/779a14591ce143820a3d8c7661e04454329e3abc\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1904.09317\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.3389/frai.2019.00028\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"title\":\"Challenges and Prospects in Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/78f36f2acb0c88cfe74572933cb52c9cc75a1d50\",\"venue\":\"Front. Artif. Intell.\",\"year\":2019},{\"arxivId\":\"1812.08352\",\"authors\":[{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"40609859\",\"name\":\"Yitong Li\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.1145/3394171.3413551\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4630a4dc4015c68b5f802b62c963496a024e4843\",\"title\":\"Sequential Attention GAN for Interactive Image Editing\",\"url\":\"https://www.semanticscholar.org/paper/4630a4dc4015c68b5f802b62c963496a024e4843\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1812.06398\",\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2838646\",\"name\":\"I. Abbasnejad\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/cvpr42600.2020.01346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"524acde4aad3bcde1b2a90245ef25c4e4d17c849\",\"title\":\"Gold Seeker: Information Gain From Policy Distributions for Goal-Oriented Vision-and-Langauge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/524acde4aad3bcde1b2a90245ef25c4e4d17c849\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.10500\",\"authors\":[{\"authorId\":\"15028494\",\"name\":\"Yen-Wei Chang\"},{\"authorId\":\"1749122\",\"name\":\"Wen-Hsiao Peng\"}],\"doi\":\"10.1109/ICME.2019.00096\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8819217e05d1c7ef8efc62989c04235df6750fb5\",\"title\":\"Learning Goal-Oriented Visual Dialog Agents: Imitating and Surpassing Analytic Experts\",\"url\":\"https://www.semanticscholar.org/paper/8819217e05d1c7ef8efc62989c04235df6750fb5\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"title\":\"Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network\",\"url\":\"https://www.semanticscholar.org/paper/396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"2008241757\",\"name\":\"Arunav Pratap Shandeelya\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.1371/journal.pone.0241271\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f76b2bf0de083c77f8730809b2c01c28c388c41\",\"title\":\"More to diverse: Generating diversified responses in a task oriented multimodal dialog system\",\"url\":\"https://www.semanticscholar.org/paper/9f76b2bf0de083c77f8730809b2c01c28c388c41\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2010.08708\",\"authors\":[{\"authorId\":\"2728646\",\"name\":\"Hantao Huang\"},{\"authorId\":\"145421604\",\"name\":\"T. Han\"},{\"authorId\":\"72549949\",\"name\":\"Wei Han\"},{\"authorId\":\"48986588\",\"name\":\"D. Yap\"},{\"authorId\":\"32312400\",\"name\":\"C. Chiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"title\":\"Answer-checking in Context: A Multi-modal FullyAttention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91550d1490caa39f723d3efb5d1b78b6f8b7c6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1812.07617\",\"authors\":[{\"authorId\":\"144235909\",\"name\":\"Raymond Li\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"677aadb8171bd0633f465abe86ee3121abf407aa\",\"title\":\"Towards Deep Conversational Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/677aadb8171bd0633f465abe86ee3121abf407aa\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1910.06315\",\"authors\":[{\"authorId\":\"153636852\",\"name\":\"Soumik Ranjan Dasgupta\"},{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"title\":\"Dynamic Attention Networks for Task Oriented Grounding\",\"url\":\"https://www.semanticscholar.org/paper/361eca6c96fc354c2fd403249e1a915f403c2c3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.11949\",\"authors\":[{\"authorId\":\"1399665713\",\"name\":\"Mariona Caros\"},{\"authorId\":\"50754209\",\"name\":\"M. Garolera\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":\"10.1145/3372278.3391927\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85c2edc74ac3a5b7d53abe3d5c2767ac7c4a5d4f\",\"title\":\"Automatic Reminiscence Therapy for Dementia\",\"url\":\"https://www.semanticscholar.org/paper/85c2edc74ac3a5b7d53abe3d5c2767ac7c4a5d4f\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1909.00421\",\"authors\":[{\"authorId\":\"3257551\",\"name\":\"Xintong Yu\"},{\"authorId\":\"97885771\",\"name\":\"Hongming Zhang\"},{\"authorId\":\"95882703\",\"name\":\"Y. Song\"},{\"authorId\":\"145918926\",\"name\":\"Yan Song\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"}],\"doi\":\"10.18653/v1/D19-1516\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64f8fe204cd130035749c0ff110746580f04d7c3\",\"title\":\"What You See is What You Get: Visual Pronoun Coreference Resolution in Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/64f8fe204cd130035749c0ff110746580f04d7c3\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314993\",\"name\":\"Wei-ying Wang\"},{\"authorId\":\"1994473516\",\"name\":\"Jieting Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413890\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b116c8cd44a34f440f260a890e0600b61d92c262\",\"title\":\"VideoIC: A Video Interactive Comments Dataset and Multimodal Multitask Learning for Comments Generation\",\"url\":\"https://www.semanticscholar.org/paper/b116c8cd44a34f440f260a890e0600b61d92c262\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32543309\",\"name\":\"Tianling Jiang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"49046633\",\"name\":\"Chunping Liu\"},{\"authorId\":\"21633777\",\"name\":\"Hailin Shao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78c2f7520becde5e3bcd9b952791d67c33a48612\",\"title\":\"Visual-Textual Alignment for Graph Inference in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/78c2f7520becde5e3bcd9b952791d67c33a48612\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461583\",\"name\":\"Kun Zhang\"},{\"authorId\":\"2767360\",\"name\":\"Guangyi Lv\"},{\"authorId\":\"47767796\",\"name\":\"L. Wu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"50383774\",\"name\":\"Q. Liu\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"153710346\",\"name\":\"Xing Xie\"},{\"authorId\":\"2397264\",\"name\":\"Fangzhao Wu\"}],\"doi\":\"10.1109/tsmc.2019.2932410\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da0c294c84ef6d48822eeb383d36015a5bbc96eb\",\"title\":\"Multilevel Image-Enhanced Sentence Representation Net for Natural Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/da0c294c84ef6d48822eeb383d36015a5bbc96eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.01460\",\"authors\":[{\"authorId\":\"29072828\",\"name\":\"Seungwhan Moon\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"34963487\",\"name\":\"Paul A. Crook\"},{\"authorId\":\"1397387596\",\"name\":\"Ankita De\"},{\"authorId\":\"40346865\",\"name\":\"S. Poddar\"},{\"authorId\":\"46932359\",\"name\":\"T. Levin\"},{\"authorId\":\"143659729\",\"name\":\"D. Whitney\"},{\"authorId\":\"145740391\",\"name\":\"Daniel Difranco\"},{\"authorId\":\"1791052\",\"name\":\"A. Beirami\"},{\"authorId\":\"34685327\",\"name\":\"Eunjoon Cho\"},{\"authorId\":\"1751070\",\"name\":\"Rajen Subba\"},{\"authorId\":\"1979505\",\"name\":\"A. Geramifard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad6ae2086401a14bbf8ad7d028241a1776bc8248\",\"title\":\"Situated and Interactive Multimodal Conversations\",\"url\":\"https://www.semanticscholar.org/paper/ad6ae2086401a14bbf8ad7d028241a1776bc8248\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tarfah Alrashid\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70327c8228b508388f96bd70d7dbdf3943c8437e\",\"title\":\"Annotating and Recognising Visually Descriptive Language\",\"url\":\"https://www.semanticscholar.org/paper/70327c8228b508388f96bd70d7dbdf3943c8437e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1805.00145\",\"authors\":[{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"47585344\",\"name\":\"Yu Cheng\"},{\"authorId\":\"30126647\",\"name\":\"Steven Rennie\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7158bd1635bf7bb87c557c429774d5236703e64\",\"title\":\"Dialog-based Interactive Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f7158bd1635bf7bb87c557c429774d5236703e64\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2545727\",\"name\":\"T. S. Jayram\"},{\"authorId\":\"88000484\",\"name\":\"V. Albouy\"},{\"authorId\":\"2725083\",\"name\":\"T. Kornuta\"},{\"authorId\":\"13177954\",\"name\":\"E. Sevgen\"},{\"authorId\":\"50192121\",\"name\":\"A. Ozcan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73b5a24a033073142d895f81c4668d096a0896fb\",\"title\":\"Visually Grounded Video Reasoning in Selective Attention Memory\",\"url\":\"https://www.semanticscholar.org/paper/73b5a24a033073142d895f81c4668d096a0896fb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.02690\",\"authors\":[{\"authorId\":\"34963487\",\"name\":\"Paul A. Crook\"},{\"authorId\":\"40346865\",\"name\":\"S. Poddar\"},{\"authorId\":\"1397387596\",\"name\":\"Ankita De\"},{\"authorId\":\"2559195\",\"name\":\"S. Shafi\"},{\"authorId\":\"143659729\",\"name\":\"D. Whitney\"},{\"authorId\":\"1979505\",\"name\":\"A. Geramifard\"},{\"authorId\":\"1751070\",\"name\":\"Rajen Subba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7363e926d1b8fb14a56ec7a36f44852144c43c3f\",\"title\":\"SIMMC: Situated Interactive Multi-Modal Conversational Data Collection And Evaluation Platform\",\"url\":\"https://www.semanticscholar.org/paper/7363e926d1b8fb14a56ec7a36f44852144c43c3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.01011\",\"authors\":[{\"authorId\":\"28130078\",\"name\":\"P. P. Liang\"},{\"authorId\":\"2987266\",\"name\":\"Zhun Liu\"},{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"50543718\",\"name\":\"Qibin Zhao\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"}],\"doi\":\"10.18653/v1/P19-1152\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93deae7cfaba34066afa05a2b05162891b13e769\",\"title\":\"Learning Representations from Imperfect Time Series Data via Tensor Rank Regularization\",\"url\":\"https://www.semanticscholar.org/paper/93deae7cfaba34066afa05a2b05162891b13e769\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1811.09845\",\"authors\":[{\"authorId\":\"1388811741\",\"name\":\"Alaaeldin El-Nouby\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"88844399\",\"name\":\"Devon Hjelm\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1405620261\",\"name\":\"Graham W.Taylor\"}],\"doi\":\"10.1109/ICCV.2019.01040\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19f894ab29ed7895b9a0cc7435866da69e9a63c6\",\"title\":\"Tell, Draw, and Repeat: Generating and Modifying Images Based on Continual Linguistic Instruction\",\"url\":\"https://www.semanticscholar.org/paper/19f894ab29ed7895b9a0cc7435866da69e9a63c6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1701.08251\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"3130583\",\"name\":\"Georgios P. Spithourakis\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c880fca26169023a900c0f7d65d9b85abc5240a0\",\"title\":\"Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/c880fca26169023a900c0f7d65d9b85abc5240a0\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1943885\",\"name\":\"B. F. Yuksel\"},{\"authorId\":\"1710568\",\"name\":\"Pooyan Fazli\"},{\"authorId\":\"1666622832\",\"name\":\"Umang Mathur\"},{\"authorId\":\"80018107\",\"name\":\"Vaishali Bisht\"},{\"authorId\":\"49899969\",\"name\":\"S. Kim\"},{\"authorId\":\"153231420\",\"name\":\"J. J. Lee\"},{\"authorId\":\"1666224668\",\"name\":\"Seung Jung Jin\"},{\"authorId\":\"40027011\",\"name\":\"Yue-Ting Siu\"},{\"authorId\":\"144851350\",\"name\":\"Joshua A. Miele\"},{\"authorId\":\"40100223\",\"name\":\"I. Yoon\"}],\"doi\":\"10.1145/3357236.3395433\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12066c4db32a715ad7709889a142d294229936cd\",\"title\":\"Human-in-the-Loop Machine Learning to Increase Video Accessibility for Visually Impaired and Blind Users\",\"url\":\"https://www.semanticscholar.org/paper/12066c4db32a715ad7709889a142d294229936cd\",\"venue\":\"Conference on Designing Interactive Systems\",\"year\":2020},{\"arxivId\":\"2002.11894\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"title\":\"Unshuffling Data for Improved Generalization\",\"url\":\"https://www.semanticscholar.org/paper/fc3ab3767e40c3f5dd33263386f6177afdda4d23\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.09956\",\"authors\":[{\"authorId\":\"143804072\",\"name\":\"Y. Jiang\"},{\"authorId\":\"2311222\",\"name\":\"V. Natarajan\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"36c3972569a6949ecca90bfa6f8e99883e092845\",\"title\":\"Pythia v0.1: the Winning Entry to the VQA Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/36c3972569a6949ecca90bfa6f8e99883e092845\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.11954\",\"authors\":[{\"authorId\":\"144992211\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"2544049\",\"name\":\"Ondrej Dusek\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"1681799\",\"name\":\"Verena Rieser\"}],\"doi\":\"10.18653/v1/W18-5709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b2b41790d33770ba43c45ed2da89c644840debf0\",\"title\":\"A Knowledge-Grounded Multimodal Search-Based Conversational Agent\",\"url\":\"https://www.semanticscholar.org/paper/b2b41790d33770ba43c45ed2da89c644840debf0\",\"venue\":\"SCAI@EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3241910\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"title\":\"Images2Poem: Generating Chinese Poetry from Image Streams\",\"url\":\"https://www.semanticscholar.org/paper/c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1911.03826\",\"authors\":[{\"authorId\":\"2218741\",\"name\":\"Fuwen Tan\"},{\"authorId\":\"1399431057\",\"name\":\"Paola Cascante-Bonilla\"},{\"authorId\":\"121433787\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"47987329\",\"name\":\"H. Wu\"},{\"authorId\":\"145480862\",\"name\":\"S. Feng\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ec1906fbd2f34af88a987d381294e22a10c9165\",\"title\":\"Drill-down: Interactive Retrieval of Complex Scenes using Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/5ec1906fbd2f34af88a987d381294e22a10c9165\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1906.10169\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"41020827\",\"name\":\"Corentin Dancette\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"title\":\"RUBi: Reducing Unimodal Biases in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ab9cc2c6a8d35d7a145cf608ff9dd7af87213253\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"},{\"authorId\":\"1888638\",\"name\":\"Akihiro Tamura\"},{\"authorId\":\"49584970\",\"name\":\"T. Ninomiya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4174087859fb7e99e6f24cd7ae765e3b3011a4f9\",\"title\":\"A Visually-Grounded Parallel Corpus with Phrase-to-Region Linking\",\"url\":\"https://www.semanticscholar.org/paper/4174087859fb7e99e6f24cd7ae765e3b3011a4f9\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1902.09818\",\"authors\":[{\"authorId\":\"49724488\",\"name\":\"H. Zhang\"},{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"46819684\",\"name\":\"Larry Heck\"},{\"authorId\":\"145109280\",\"name\":\"S. Walsh\"},{\"authorId\":\"49051223\",\"name\":\"Junting Zhang\"},{\"authorId\":\"38791445\",\"name\":\"J. Zhang\"},{\"authorId\":\"9363144\",\"name\":\"C.-C. Jay Kuo\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"title\":\"Generative Visual Dialogue System via Adaptive Reasoning and Weighted Likelihood Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cb08a5d1ae9985ae3867780094c9a5e7074817d8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47540106\",\"name\":\"J. Zhang\"},{\"authorId\":\"50828249\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1016/j.ipm.2019.102152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ff7b42d8cc37acfc08210cff20983090a968308\",\"title\":\"Multi-Modal fusion with multi-level attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2ff7b42d8cc37acfc08210cff20983090a968308\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2011.00669\",\"authors\":[{\"authorId\":\"27831809\",\"name\":\"M. A. Shah\"},{\"authorId\":\"32251567\",\"name\":\"Shikib Mehri\"},{\"authorId\":\"150324514\",\"name\":\"Tejas Srinivasan\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"59f55d9a20ea5ba42406ba44699e671ee6437edf\",\"title\":\"Reasoning Over History: Context Aware Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/59f55d9a20ea5ba42406ba44699e671ee6437edf\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2012.10210\",\"authors\":[{\"authorId\":\"108630954\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"2455565\",\"name\":\"S. Xiao\"},{\"authorId\":\"115718758\",\"name\":\"A. Mclean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"title\":\"On modality bias in the TVQA dataset.\",\"url\":\"https://www.semanticscholar.org/paper/6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01981\",\"authors\":[{\"authorId\":\"143624053\",\"name\":\"Ze Yang\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"46353980\",\"name\":\"Huang Hu\"},{\"authorId\":\"46747953\",\"name\":\"Can Xu\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"69f8985cbbea69273d8003876d196adc9103d300\",\"title\":\"Open Domain Dialogue Generation with Latent Images\",\"url\":\"https://www.semanticscholar.org/paper/69f8985cbbea69273d8003876d196adc9103d300\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.09854\",\"authors\":[{\"authorId\":\"3832934\",\"name\":\"Indrani Bhattacharya\"},{\"authorId\":\"40272208\",\"name\":\"Arkabandhu Chowdhury\"},{\"authorId\":\"145769639\",\"name\":\"Vikas C. Raykar\"}],\"doi\":\"10.1145/3323873.3325036\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4d9ab090434c7e3812cdce51116822b6b8851ae\",\"title\":\"Multimodal Dialog for Browsing Large Visual Catalogs using Exploration-Exploitation Paradigm in a Joint Embedding Space\",\"url\":\"https://www.semanticscholar.org/paper/d4d9ab090434c7e3812cdce51116822b6b8851ae\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":\"1907.09273\",\"authors\":[{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"48417678\",\"name\":\"Jonathan Gray\"},{\"authorId\":\"27693639\",\"name\":\"Kavya Srinet\"},{\"authorId\":\"2262249\",\"name\":\"Yacine Jernite\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"2282478\",\"name\":\"Gabriel Synnaeve\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"2240134\",\"name\":\"Zhuoyuan Chen\"},{\"authorId\":\"3322061\",\"name\":\"S. Goyal\"},{\"authorId\":\"35578711\",\"name\":\"Demi Guo\"},{\"authorId\":\"150975114\",\"name\":\"Danielle Rothermel\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72220915a635e29ea7a9d3d8f5da5a2a6b2ab3f\",\"title\":\"Why Build an Assistant in Minecraft?\",\"url\":\"https://www.semanticscholar.org/paper/a72220915a635e29ea7a9d3d8f5da5a2a6b2ab3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1909.04800\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"1380338049\",\"name\":\"Anupriy\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.1016/j.patcog.2020.107586\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"title\":\"Probabilistic framework for solving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e281d8af3ec87fd893743afd6fb9d5ec3eaca924\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":\"2004.13278\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1785083\",\"name\":\"Michael R. Lyu\"},{\"authorId\":\"145310663\",\"name\":\"Irwin King\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.269\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"06c7269c10125589d2599f684b751b1640f7a0cc\",\"title\":\"VD-BERT: A Unified Vision and Dialog Transformer with BERT\",\"url\":\"https://www.semanticscholar.org/paper/06c7269c10125589d2599f684b751b1640f7a0cc\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.04679\",\"authors\":[{\"authorId\":\"2345018\",\"name\":\"Shen Gao\"},{\"authorId\":\"46772896\",\"name\":\"Xiuying Chen\"},{\"authorId\":\"73100429\",\"name\":\"Chang Liu\"},{\"authorId\":\"144073922\",\"name\":\"Li Liu\"},{\"authorId\":\"144060462\",\"name\":\"Dongyan Zhao\"},{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"}],\"doi\":\"10.1145/3366423.3380191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ab771b7431f5d3dce4372a18555f4216528ace7\",\"title\":\"Learning to Respond with Stickers: A Framework of Unifying Multi-Modality in Multi-Turn Dialog\",\"url\":\"https://www.semanticscholar.org/paper/3ab771b7431f5d3dce4372a18555f4216528ace7\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.1007/978-3-030-01225-0_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"title\":\"Scaling Egocentric Vision: The Dataset\",\"url\":\"https://www.semanticscholar.org/paper/443b1a20b30f09a2e4d6c47a8a9412a668f615fd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2001.08034\",\"authors\":[{\"authorId\":\"153060461\",\"name\":\"Darryl Hannan\"},{\"authorId\":\"50658802\",\"name\":\"Akshay Jain\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6294\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b578fe40abc9ec29424d342a8d676c88a98b921\",\"title\":\"ManyModalQA: Modality Disambiguation and QA over Diverse Inputs\",\"url\":\"https://www.semanticscholar.org/paper/6b578fe40abc9ec29424d342a8d676c88a98b921\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1901.06417\",\"authors\":[{\"authorId\":\"144599741\",\"name\":\"Matthew Guzdial\"},{\"authorId\":\"20985870\",\"name\":\"N. Liao\"},{\"authorId\":\"50762427\",\"name\":\"Jonathan L Chen\"},{\"authorId\":\"48847943\",\"name\":\"Shao-Yu Chen\"},{\"authorId\":\"51430972\",\"name\":\"Shukan Shah\"},{\"authorId\":\"144366365\",\"name\":\"Vishwa Shah\"},{\"authorId\":\"145221193\",\"name\":\"Joshua Reno\"},{\"authorId\":\"144320252\",\"name\":\"G. Smith\"},{\"authorId\":\"2757194\",\"name\":\"Mark O. Riedl\"}],\"doi\":\"10.1145/3290605.3300854\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"157592a892ee44dd5b3b6a06f9191ac5ec8407ac\",\"title\":\"Friend, Collaborator, Student, Manager: How Design of an AI-Driven Game Level Editor Affects Creators\",\"url\":\"https://www.semanticscholar.org/paper/157592a892ee44dd5b3b6a06f9191ac5ec8407ac\",\"venue\":\"CHI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.02442\",\"authors\":[{\"authorId\":\"115044425\",\"name\":\"Sho Maeoki\"},{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPRW50498.2020.00484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"title\":\"Interactive Video Retrieval with Dialog\",\"url\":\"https://www.semanticscholar.org/paper/1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1709.09816\",\"authors\":[{\"authorId\":\"9340968\",\"name\":\"Ben Krause\"},{\"authorId\":\"3451777\",\"name\":\"M. Damonte\"},{\"authorId\":\"32538144\",\"name\":\"M. Dobre\"},{\"authorId\":\"2876339\",\"name\":\"D. Duma\"},{\"authorId\":\"40561194\",\"name\":\"Joachim Fainberg\"},{\"authorId\":\"2364338\",\"name\":\"Federico Fancellu\"},{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"1941442\",\"name\":\"Jianpeng Cheng\"},{\"authorId\":\"1736049\",\"name\":\"B. Webber\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ca1f67803c73a76b7be6439394c6e4f3ace08e3\",\"title\":\"Edina: Building an Open Domain Socialbot with Self-dialogues\",\"url\":\"https://www.semanticscholar.org/paper/3ca1f67803c73a76b7be6439394c6e4f3ace08e3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49388046\",\"name\":\"J. Wu\"},{\"authorId\":\"3451315\",\"name\":\"K. Ahuja\"},{\"authorId\":\"2357317\",\"name\":\"Richard Li\"},{\"authorId\":null,\"name\":\"Victor Chen\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1145/3328934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5bb8c18493208e2bfa56ab5216f90a99bb09124e\",\"title\":\"ScratchThat: Supporting Command-Agnostic Speech Repair in Voice-Driven Assistants\",\"url\":\"https://www.semanticscholar.org/paper/5bb8c18493208e2bfa56ab5216f90a99bb09124e\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1954884\",\"name\":\"A. Gilbert\"},{\"authorId\":\"2463875\",\"name\":\"B. Thomee\"},{\"authorId\":\"41206897\",\"name\":\"M. Villegas\"}],\"doi\":\"10.1007/978-3-030-22948-1_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f475b7e0df4b64b5438f8527a736d2967e87eb36\",\"title\":\"Automatic Image Annotation at ImageCLEF\",\"url\":\"https://www.semanticscholar.org/paper/f475b7e0df4b64b5438f8527a736d2967e87eb36\",\"venue\":\"Information Retrieval Evaluation in a Changing World\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2248453\",\"name\":\"Subhro Roy\"},{\"authorId\":\"38107789\",\"name\":\"Michael Noseworthy\"},{\"authorId\":\"3619154\",\"name\":\"R. Paul\"},{\"authorId\":\"2037963\",\"name\":\"Daehyung Park\"},{\"authorId\":\"143724999\",\"name\":\"N. Roy\"}],\"doi\":\"10.18653/v1/K19-1040\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b897b2478dae27ed7e6175436257bad0ef968796\",\"title\":\"Leveraging Past References for Robust Language Grounding\",\"url\":\"https://www.semanticscholar.org/paper/b897b2478dae27ed7e6175436257bad0ef968796\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1904.05880\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"1885974\",\"name\":\"Seunghak Yu\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2019.00214\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"title\":\"Factor Graph Attention\",\"url\":\"https://www.semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.1016/j.csl.2020.101095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"661f04ecc734ced906e16980a6143c814ce085ed\",\"title\":\"Hierarchical multimodal attention for end-to-end audio-visual scene-aware dialogue response generation\",\"url\":\"https://www.semanticscholar.org/paper/661f04ecc734ced906e16980a6143c814ce085ed\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3390891\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb9fb10f604a196515e48ad90f217d33794f5991\",\"title\":\"Recurrent Attention Network with Reinforced Generator for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cb9fb10f604a196515e48ad90f217d33794f5991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1807.00082\",\"authors\":[{\"authorId\":\"1680510\",\"name\":\"Thomas Dean\"},{\"authorId\":\"51015662\",\"name\":\"Maurice Chiang\"},{\"authorId\":\"47700768\",\"name\":\"Marcus Gomez\"},{\"authorId\":\"13297813\",\"name\":\"Nate Gruver\"},{\"authorId\":\"51027620\",\"name\":\"Yousef Hindy\"},{\"authorId\":\"47772649\",\"name\":\"Michelle Lam\"},{\"authorId\":\"144714031\",\"name\":\"Peter Lu\"},{\"authorId\":\"46397247\",\"name\":\"Sophia Sanchez\"},{\"authorId\":\"51031729\",\"name\":\"Rohun Saxena\"},{\"authorId\":\"48533892\",\"name\":\"Michael Smith\"},{\"authorId\":\"2130622\",\"name\":\"Lucy Wang\"},{\"authorId\":\"144379221\",\"name\":\"Catherine Wong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7750036de706d790ca70de1a2ae40327b6394264\",\"title\":\"Amanuensis: The Programmer's Apprentice\",\"url\":\"https://www.semanticscholar.org/paper/7750036de706d790ca70de1a2ae40327b6394264\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a5c3216f8aad40b17531e78df8cc18e2b5c73ff\",\"title\":\"The Devil is in the Details: A Magnifying Glass for the GuessWhich Visual Dialogue Game\",\"url\":\"https://www.semanticscholar.org/paper/4a5c3216f8aad40b17531e78df8cc18e2b5c73ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153389599\",\"name\":\"Junchao Zhang\"},{\"authorId\":\"1704081\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1109/TIP.2020.2988435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efb373e597cee2046d0616dd4a1d8a1d1e2c7ad3\",\"title\":\"Video Captioning With Object-Aware Spatio-Temporal Correlation and Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/efb373e597cee2046d0616dd4a1d8a1d1e2c7ad3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35526556\",\"name\":\"Anjali Narayan-Chen\"},{\"authorId\":\"3457456\",\"name\":\"Prashant Jayannavar\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/P19-1537\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aab6559007292d1d5823a5abbe4b75a7576c180\",\"title\":\"Collaborative Dialogue in Minecraft\",\"url\":\"https://www.semanticscholar.org/paper/4aab6559007292d1d5823a5abbe4b75a7576c180\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1811.00491\",\"authors\":[{\"authorId\":\"32849969\",\"name\":\"Alane Suhr\"},{\"authorId\":\"49219517\",\"name\":\"Stephanie Zhou\"},{\"authorId\":\"78244694\",\"name\":\"Iris D. Zhang\"},{\"authorId\":\"14271134\",\"name\":\"Huajun Bai\"},{\"authorId\":\"3167681\",\"name\":\"Yoav Artzi\"}],\"doi\":\"10.18653/v1/P19-1644\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf336d272a30d6ad6141db67faa64deb8791cd61\",\"title\":\"A Corpus for Reasoning About Natural Language Grounded in Photographs\",\"url\":\"https://www.semanticscholar.org/paper/cf336d272a30d6ad6141db67faa64deb8791cd61\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1902.09487\",\"authors\":[{\"authorId\":\"7535126\",\"name\":\"R\\u00e9mi Cad\\u00e8ne\"},{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"1728523\",\"name\":\"N. Thome\"}],\"doi\":\"10.1109/CVPR.2019.00209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"title\":\"MUREL: Multimodal Relational Reasoning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.12021\",\"authors\":[{\"authorId\":\"9267940\",\"name\":\"Pushkar Shukla\"},{\"authorId\":\"46185376\",\"name\":\"Carlos E. L. Elmadjian\"},{\"authorId\":\"32883757\",\"name\":\"Richika Sharan\"},{\"authorId\":\"144592382\",\"name\":\"Vivek Kulkarni\"},{\"authorId\":\"144097660\",\"name\":\"M. Turk\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.18653/v1/P19-1646\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"133d4278069bd3eba627611c51a388879e9eae46\",\"title\":\"What Should I Ask? Using Conversationally Informative Rewards for Goal-oriented Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/133d4278069bd3eba627611c51a388879e9eae46\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1805.11818\",\"authors\":[{\"authorId\":\"3149518\",\"name\":\"Volkan Cirik\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"1400419309\",\"name\":\"Taylor Berg-Kirkpatrick\"}],\"doi\":\"10.18653/v1/N18-2123\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72d7c465ef199a9670b3da7a318b0227f5cc3229\",\"title\":\"Visual Referring Expression Recognition: What Do Systems Actually Learn?\",\"url\":\"https://www.semanticscholar.org/paper/72d7c465ef199a9670b3da7a318b0227f5cc3229\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1808.04446\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"34675041\",\"name\":\"Mathieu Seurin\"},{\"authorId\":\"3439053\",\"name\":\"Ethan Perez\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"34682317\",\"name\":\"P. Preux\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.1007/978-3-030-01228-1_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0654e75bfea7af13e021a22a21422b36270c08b7\",\"title\":\"Visual Reasoning with Multi-hop Feature Modulation\",\"url\":\"https://www.semanticscholar.org/paper/0654e75bfea7af13e021a22a21422b36270c08b7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2006.13608\",\"authors\":[{\"authorId\":\"1739188006\",\"name\":\"Sheng-Yu Zhang\"},{\"authorId\":\"3856602\",\"name\":\"Ziqi Tan\"},{\"authorId\":\"145919748\",\"name\":\"Jin Yu\"},{\"authorId\":\"50144812\",\"name\":\"Z. Zhao\"},{\"authorId\":\"33870528\",\"name\":\"Kun Kuang\"},{\"authorId\":\"71328060\",\"name\":\"T. Jiang\"},{\"authorId\":\"1709595\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"38385080\",\"name\":\"Hongxia Yang\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3394486.3403325\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d271e93c7566b231e560c48b4cc4942077d762f9\",\"title\":\"Comprehensive Information Integration Modeling Framework for Video Titling\",\"url\":\"https://www.semanticscholar.org/paper/d271e93c7566b231e560c48b4cc4942077d762f9\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1737497\",\"name\":\"Karl J. Friston\"},{\"authorId\":\"47363526\",\"name\":\"T. Parr\"},{\"authorId\":\"2837396\",\"name\":\"Yan Yufik\"},{\"authorId\":\"6548073\",\"name\":\"Noor Sajid\"},{\"authorId\":\"50640007\",\"name\":\"Emma Holmes\"}],\"doi\":\"10.1016/j.neubiorev.2020.07.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42d5b2ff365f4353a4f1a069b024adaf701f0026\",\"title\":\"Generative models, linguistic communication and active inference\",\"url\":\"https://www.semanticscholar.org/paper/42d5b2ff365f4353a4f1a069b024adaf701f0026\",\"venue\":\"Neuroscience & Biobehavioral Reviews\",\"year\":2020},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1909.03409\",\"authors\":[{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"151260226\",\"name\":\"Y. Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Y. Sun\"},{\"authorId\":\"2256618\",\"name\":\"Z. Yu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"title\":\"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126416\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ICME.2019.00270\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"title\":\"Visual Dialog with Targeted Objects\",\"url\":\"https://www.semanticscholar.org/paper/16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116780600\",\"name\":\"S. Semenova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/089254dfb8fb0fbfac55696d1f9eba02e4079e97\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151901\",\"name\":\"Bernd Huber\"},{\"authorId\":\"1801452\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"66648221\",\"name\":\"Bill Dolan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c34787b4708b34742774ba3abba8ace39c6b9052\",\"title\":\"Input Image : Smile Intensity Generated Responses : Input Question : Input\",\"url\":\"https://www.semanticscholar.org/paper/c34787b4708b34742774ba3abba8ace39c6b9052\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.04284\",\"authors\":[{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d81b0a79558cabaaf3db22caf89454f4e012f21b\",\"title\":\"iParaphrasing: Extracting Visually Grounded Paraphrases via an Image\",\"url\":\"https://www.semanticscholar.org/paper/d81b0a79558cabaaf3db22caf89454f4e012f21b\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"3177281\",\"name\":\"Qinfeng Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"}],\"doi\":\"10.1109/CVPR.2019.01104\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2587270fb2c80e6e827eb10221528c4f45dfb760\",\"title\":\"A Generative Adversarial Density Estimator\",\"url\":\"https://www.semanticscholar.org/paper/2587270fb2c80e6e827eb10221528c4f45dfb760\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.03127\",\"authors\":[{\"authorId\":\"80927455\",\"name\":\"Takuma Udagawa\"},{\"authorId\":\"48342111\",\"name\":\"T. Yamazaki\"},{\"authorId\":\"1705519\",\"name\":\"A. Aizawa\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.67\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6ee340c37a60d20dd8ebe19bc6fa614b981c2060\",\"title\":\"A Linguistic Analysis of Visually Grounded Dialogues Based on Spatial Expressions\",\"url\":\"https://www.semanticscholar.org/paper/6ee340c37a60d20dd8ebe19bc6fa614b981c2060\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.04554\",\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"24068173\",\"name\":\"Mario Giulianelli\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"153915609\",\"name\":\"Arabella Sinclair\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.353\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"60eedf4faa04dd30f8c5769e0831268133549eb8\",\"title\":\"Refer, Reuse, Reduce: Generating Subsequent References in Visual and Conversational Contexts\",\"url\":\"https://www.semanticscholar.org/paper/60eedf4faa04dd30f8c5769e0831268133549eb8\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.07023\",\"authors\":[{\"authorId\":\"5298478\",\"name\":\"T. D. Nguyen\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d252759ea411343f274a92276bf7bd8f9d43db8c\",\"title\":\"From FiLM to Video: Multi-turn Question Answering with Multi-modal Context\",\"url\":\"https://www.semanticscholar.org/paper/d252759ea411343f274a92276bf7bd8f9d43db8c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"title\":\"A Simple Baseline for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1808.00171\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1007/978-3-030-01258-8_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8164ebc07f51c9e0db4902980b5ac3f5a8d8d48c\",\"title\":\"Shuffle-Then-Assemble: Learning Object-Agnostic Visual Relationship Features\",\"url\":\"https://www.semanticscholar.org/paper/8164ebc07f51c9e0db4902980b5ac3f5a8d8d48c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.11240\",\"authors\":[{\"authorId\":\"27629426\",\"name\":\"Shang-Yu Su\"},{\"authorId\":\"1725643\",\"name\":\"Yun-Nung (Vivian) Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75187014e7efd823eecfa833217ebb3ea7187107\",\"title\":\"Bridging Dialogue Generation and Facial Expression Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/75187014e7efd823eecfa833217ebb3ea7187107\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1802.08216\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"26412506\",\"name\":\"Dendi Suhubdy\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"174ddb6379b91a0e799e9988d0e522a5af18f91d\",\"title\":\"ChatPainter: Improving Text to Image Generation using Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/174ddb6379b91a0e799e9988d0e522a5af18f91d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2012.08148\",\"authors\":[{\"authorId\":\"8424042\",\"name\":\"M. Senese\"},{\"authorId\":\"6803422\",\"name\":\"A. Benincasa\"},{\"authorId\":\"1752593147\",\"name\":\"Barbara Caputo\"},{\"authorId\":\"145971067\",\"name\":\"G. Rizzo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d295dab25e6305b5bcabd140f2595d79b72f854\",\"title\":\"A Response Retrieval Approach for Dialogue Using a Multi-Attentive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/3d295dab25e6305b5bcabd140f2595d79b72f854\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.01166\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/P19-1564\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"title\":\"Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1709.10423\",\"authors\":[{\"authorId\":\"3362121\",\"name\":\"Yanchao Yu\"},{\"authorId\":\"2634217\",\"name\":\"A. Eshghi\"},{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"}],\"doi\":\"10.18653/v1/W17-2802\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39ea0301b2ee95dc127f6bd5918665b18d1a7915\",\"title\":\"Learning how to Learn: An Adaptive Dialogue Agent for Incrementally Learning Visually Grounded Word Meanings\",\"url\":\"https://www.semanticscholar.org/paper/39ea0301b2ee95dc127f6bd5918665b18d1a7915\",\"venue\":\"RoboNLP@ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71764998\",\"name\":\"Xuewen Shi\"},{\"authorId\":\"4590286\",\"name\":\"Heyan Huang\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"46302667\",\"name\":\"Ping Jian\"},{\"authorId\":\"7868673\",\"name\":\"Yi-Kun Tang\"}],\"doi\":\"10.18653/v1/K19-1025\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62259f76375a4d419fb02c04aaf1221ba2016785\",\"title\":\"Improving Neural Machine Translation by Achieving Knowledge Transfer with Sentence Alignment Learning\",\"url\":\"https://www.semanticscholar.org/paper/62259f76375a4d419fb02c04aaf1221ba2016785\",\"venue\":\"CoNLL\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.08874\",\"authors\":[{\"authorId\":\"3393384\",\"name\":\"Jong-Chyi Su\"},{\"authorId\":\"48251796\",\"name\":\"Chenyun Wu\"},{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2017.53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"title\":\"Reasoning About Fine-Grained Attribute Phrases Using Reference Games\",\"url\":\"https://www.semanticscholar.org/paper/956e2113fc30cf3f4c3e61ebcd10c8ca5f416d42\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1903.03094\",\"authors\":[{\"authorId\":\"39219656\",\"name\":\"Jack Urbanek\"},{\"authorId\":\"144270981\",\"name\":\"Angela Fan\"},{\"authorId\":\"10737060\",\"name\":\"Siddharth Karamcheti\"},{\"authorId\":\"82853009\",\"name\":\"Saachi Jain\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"2620211\",\"name\":\"Tim Rockt\\u00e4schel\"},{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/D19-1062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f7c455cc5a40d2a31b63ac2657c9d2d6c53b1be5\",\"title\":\"Learning to Speak and Act in a Fantasy Text Adventure Game\",\"url\":\"https://www.semanticscholar.org/paper/f7c455cc5a40d2a31b63ac2657c9d2d6c53b1be5\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2003.00403\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"97992296\",\"name\":\"P. Wang\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"title\":\"Cops-Ref: A New Dataset and Task on Compositional Referring Expression Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/d04e67e967c272d8d831bb3acaa75fb29607d4c7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.06401\",\"authors\":[{\"authorId\":\"9358910\",\"name\":\"Shrimai Prabhumoye\"},{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.18653/v1/W19-3402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e05c31fa936f6bbb30633597168b63b60d3f3e0\",\"title\":\"\\\"My Way of Telling a Story\\\": Persona based Grounded Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/9e05c31fa936f6bbb30633597168b63b60d3f3e0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67119290\",\"name\":\"N. Bodunkov\"},{\"authorId\":\"2006157666\",\"name\":\"V. I. Glushankova\"},{\"authorId\":\"67017598\",\"name\":\"N. Kim\"}],\"doi\":\"10.3103/s1068798x20070047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4a142453a7b47bfe1c4ac613365b9c726d10cb8\",\"title\":\"Organization of Robot\\u2013Human Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f4a142453a7b47bfe1c4ac613365b9c726d10cb8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1902.05715\",\"authors\":[{\"authorId\":\"1703558\",\"name\":\"S. Ghosh\"},{\"authorId\":\"69919463\",\"name\":\"Giedrius Burachas\"},{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"6052800\",\"name\":\"Avi Ziskind\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea0ea5e0ccfb2ccaaba2c9757f4ab5ac875965cc\",\"title\":\"Generating Natural Language Explanations for Visual Question Answering using Scene Graphs and Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/ea0ea5e0ccfb2ccaaba2c9757f4ab5ac875965cc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.00163\",\"authors\":[{\"authorId\":\"15401738\",\"name\":\"Zekang Li\"},{\"authorId\":\"115419547\",\"name\":\"Zongjia Li\"},{\"authorId\":\"27672597\",\"name\":\"Jinchao Zhang\"},{\"authorId\":\"49771779\",\"name\":\"Yang Feng\"},{\"authorId\":\"150954670\",\"name\":\"Cheng Niu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4e0723e048941ea73c77a7c69dbb731ef8de750\",\"title\":\"Bridging Text and Video: A Universal Multimodal Transformer for Video-Audio Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f4e0723e048941ea73c77a7c69dbb731ef8de750\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"title\":\"End-to-End Multimodal Dialog Systems with Hierarchical Multimodal Attention on Video Features\",\"url\":\"https://www.semanticscholar.org/paper/fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.03986\",\"authors\":[{\"authorId\":\"48494603\",\"name\":\"Badri N. Patro\"},{\"authorId\":\"49596229\",\"name\":\"S. Kumar\"},{\"authorId\":\"50975843\",\"name\":\"Vinod K. Kurmi\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":\"10.18653/v1/D18-1434\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"title\":\"Multimodal Differential Network for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/43e846b51e6d3d317c3f34e9fd6af87eacc2314e\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1812.06417\",\"authors\":[{\"authorId\":\"3469119\",\"name\":\"Daniela Massiceti\"},{\"authorId\":\"1943570\",\"name\":\"Puneet K. Dokania\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"abc57e5141a63fa12d0260752be3eeddaf755a69\",\"title\":\"Visual Dialogue without Vision or Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/abc57e5141a63fa12d0260752be3eeddaf755a69\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108358199\",\"name\":\"Viktar Atliha\"},{\"authorId\":\"1990294\",\"name\":\"D. Sesok\"}],\"doi\":\"10.1109/eStream50540.2020.9108880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08aa7d4d4e7fe6637ab83b8f8ae4144da517cdd6\",\"title\":\"Comparison of VGG and ResNet used as Encoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/08aa7d4d4e7fe6637ab83b8f8ae4144da517cdd6\",\"venue\":\"2020 IEEE Open Conference of Electrical, Electronic and Information Sciences (eStream)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2710492\",\"name\":\"Maike Paetzel\"},{\"authorId\":\"51135358\",\"name\":\"Deepthi Karkada\"},{\"authorId\":\"2175808\",\"name\":\"Ramesh R. Manuvinakurike\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9704d80249cf658c7edcf32594c760261db3ef0b\",\"title\":\"RDG-Map: A Multimodal Corpus of Pedagogical Human-Agent Spoken Interactions\",\"url\":\"https://www.semanticscholar.org/paper/9704d80249cf658c7edcf32594c760261db3ef0b\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"2007.07758\",\"authors\":[{\"authorId\":\"96544413\",\"name\":\"M. Guevara\"},{\"authorId\":\"98892257\",\"name\":\"C. George\"},{\"authorId\":\"1390483392\",\"name\":\"Akshat Gupta\"},{\"authorId\":\"145849407\",\"name\":\"D. Byrne\"},{\"authorId\":\"6613865\",\"name\":\"Ramesh Krishnamurti\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"28e613b415aa51a983fcaa8d9ffd3311a4a3dd41\",\"title\":\"Multimodal Word Sense Disambiguation in Creative Practice\",\"url\":\"https://www.semanticscholar.org/paper/28e613b415aa51a983fcaa8d9ffd3311a4a3dd41\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.05365\",\"authors\":[{\"authorId\":\"153094069\",\"name\":\"Mingyang Zhou\"},{\"authorId\":\"46939817\",\"name\":\"J. Arnold\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"}],\"doi\":\"10.18653/v1/D19-1014\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"95df56bc95da5e7ddbf1b089ec162ffba491d3de\",\"title\":\"Building Task-Oriented Visual Dialog Systems Through Alternative Optimization Between Dialog Policy and Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/95df56bc95da5e7ddbf1b089ec162ffba491d3de\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"144612044\",\"name\":\"H. Chauhan\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"},{\"authorId\":\"145532184\",\"name\":\"P. Bhattacharyya\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24cf3fc65e5c7cbd562db1ceb089f88331f9d8e2\",\"title\":\"MEISD: A Multimodal Multi-Label Emotion, Intensity and Sentiment Dialogue Dataset for Emotion Recognition and Sentiment Analysis in Conversations\",\"url\":\"https://www.semanticscholar.org/paper/24cf3fc65e5c7cbd562db1ceb089f88331f9d8e2\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2003.04641\",\"authors\":[{\"authorId\":\"1491142121\",\"name\":\"Yuhong Deng\"},{\"authorId\":\"31513628\",\"name\":\"N. Zhang\"},{\"authorId\":\"144393479\",\"name\":\"D. Guo\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"2323566\",\"name\":\"Fu-Chun Sun\"},{\"authorId\":\"152806333\",\"name\":\"Chen Pang\"},{\"authorId\":\"1490867745\",\"name\":\"Jing Pang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"88e8f7636a2a8d5d3d0a99708bea332770471eb3\",\"title\":\"MQA: Answering the Question via Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/88e8f7636a2a8d5d3d0a99708bea332770471eb3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13681\",\"authors\":[{\"authorId\":\"20657367\",\"name\":\"A. Mani\"},{\"authorId\":\"116122080\",\"name\":\"William Hinthorn\"},{\"authorId\":\"2029244392\",\"name\":\"Nobline Yoo\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"title\":\"Point and Ask: Incorporating Pointing into Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f20439db6285ae9812fb27e33d9e9d0fc8c20b4e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1802.08218\",\"authors\":[{\"authorId\":\"2028946\",\"name\":\"D. Gurari\"},{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"32027456\",\"name\":\"A. J. Stangl\"},{\"authorId\":\"2582404\",\"name\":\"Anhong Guo\"},{\"authorId\":\"47532530\",\"name\":\"Chi Lin\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"}],\"doi\":\"10.1109/CVPR.2018.00380\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"title\":\"VizWiz Grand Challenge: Answering Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/a9e19e8ab24071a085d1273b9f9d49aa0e4ba48c\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.08409\",\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICASSP.2019.8682583\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"title\":\"End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features\",\"url\":\"https://www.semanticscholar.org/paper/85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48441202\",\"name\":\"J. Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1561/1500000074\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/a94c0fc00c7a823cebd2d17094a2d7ab3652a5b6\",\"venue\":\"Found. Trends Inf. Retr.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47860328\",\"name\":\"Shagun Uppal\"},{\"authorId\":\"73368394\",\"name\":\"Sarthak Bhagat\"},{\"authorId\":\"8223433\",\"name\":\"Devamanyu Hazarika\"},{\"authorId\":\"1999177921\",\"name\":\"Navonil Majumdar\"},{\"authorId\":\"1746416\",\"name\":\"Soujanya Poria\"},{\"authorId\":\"153015119\",\"name\":\"R. Zimmermann\"},{\"authorId\":\"144802290\",\"name\":\"Amir Zadeh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"title\":\"Emerging Trends of Multimodal Research in Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/0f23b548ff7b3517f028164a30c8bf186f11a1a6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.11390\",\"authors\":[{\"authorId\":\"28964453\",\"name\":\"Van-Quang Nguyen\"},{\"authorId\":\"9114621\",\"name\":\"Masanori Suganuma\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1007/978-3-030-58586-0_14\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"468d5c15df63892ff06fb94c7b5cad0242685d02\",\"title\":\"Efficient Attention Mechanism for Visual Dialog that Can Handle All the Interactions Between Multiple Inputs\",\"url\":\"https://www.semanticscholar.org/paper/468d5c15df63892ff06fb94c7b5cad0242685d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32208823\",\"name\":\"S. H. Kumar\"},{\"authorId\":\"3442103\",\"name\":\"Eda Okur\"},{\"authorId\":\"38531701\",\"name\":\"S. Sahay\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"},{\"authorId\":\"1896095\",\"name\":\"L. Nachman\"}],\"doi\":\"10.1016/j.csl.2020.101102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a00a2b6eb505a172a36de81dc803a9d45597bc8a\",\"title\":\"Investigating topics, audio representations and attention for multimodal scene-aware dialog\",\"url\":\"https://www.semanticscholar.org/paper/a00a2b6eb505a172a36de81dc803a9d45597bc8a\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30043205\",\"name\":\"Ho\\u00e0\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"95daf004cb89e0d9e4056b08825867329927f9f9\",\"title\":\"Vu Grounding Natural Language Inference on Images\",\"url\":\"https://www.semanticscholar.org/paper/95daf004cb89e0d9e4056b08825867329927f9f9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.09844\",\"authors\":[{\"authorId\":\"2052119\",\"name\":\"Zhaoquan Yuan\"},{\"authorId\":\"47393013\",\"name\":\"Siyuan Sun\"},{\"authorId\":\"2055900\",\"name\":\"Lixin Duan\"},{\"authorId\":\"116155759\",\"name\":\"Xiao Wu\"},{\"authorId\":\"48258806\",\"name\":\"Changsheng Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"title\":\"Adversarial Multimodal Network for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b5b0228f4955add9bdf0edbf66e0d3df6f38a993\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.10796\",\"authors\":[{\"authorId\":\"4868335\",\"name\":\"J. Park\"},{\"authorId\":\"1857797\",\"name\":\"Chandra Bhagavatula\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6966b0018daffa49eb2c38e68eb8964d56440233\",\"title\":\"Visual Commonsense Graphs: Reasoning about the Dynamic Context of a Still Image\",\"url\":\"https://www.semanticscholar.org/paper/6966b0018daffa49eb2c38e68eb8964d56440233\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.01530\",\"authors\":[{\"authorId\":\"134167565\",\"name\":\"J. Haber\"},{\"authorId\":\"51190347\",\"name\":\"Tim Baumg\\u00e4rtner\"},{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"7805500\",\"name\":\"Lieke Gelderloos\"},{\"authorId\":\"2552871\",\"name\":\"Elia Bruni\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/P19-1184\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"76cb048a3571f71e191c9731c69644eec16eb1ed\",\"title\":\"The PhotoBook Dataset: Building Common Ground through Visually-Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/76cb048a3571f71e191c9731c69644eec16eb1ed\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1905.12255\",\"authors\":[{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"145181836\",\"name\":\"Gabriel Magalh\\u00e3es\"},{\"authorId\":\"31702389\",\"name\":\"Alexander Ku\"},{\"authorId\":\"40348417\",\"name\":\"Ashish Vaswani\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"1387994164\",\"name\":\"Jason Baldridge\"}],\"doi\":\"10.18653/v1/P19-1181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68ccecb380ecfc0a4b294b84e3d0b6ff6884c4df\",\"title\":\"Stay on the Path: Instruction Fidelity in Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/68ccecb380ecfc0a4b294b84e3d0b6ff6884c4df\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1911.07251\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"15586721\",\"name\":\"Yingying Zhuang\"},{\"authorId\":\"47958013\",\"name\":\"Xingxing Zhang\"},{\"authorId\":null,\"name\":\"Yue Hu\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1609/AAAI.V34I07.6769\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b42cb7889053f5c89380c82604aa33fd6270894\",\"title\":\"DualVD: An Adaptive Dual Encoding Model for Deep Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0b42cb7889053f5c89380c82604aa33fd6270894\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2004.09272\",\"authors\":[{\"authorId\":\"3469119\",\"name\":\"Daniela Massiceti\"},{\"authorId\":\"3468926\",\"name\":\"Viveka Kulharia\"},{\"authorId\":\"144679302\",\"name\":\"P. Dokania\"},{\"authorId\":\"40155668\",\"name\":\"N. Siddharth\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6ddbe134ed10abaf043d8bcb11343e5c7e7358bf\",\"title\":\"A Revised Generative Evaluation of Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/6ddbe134ed10abaf043d8bcb11343e5c7e7358bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1562995755\",\"name\":\"Shahi Dost\"},{\"authorId\":\"144077615\",\"name\":\"L. Serafini\"},{\"authorId\":\"1766782\",\"name\":\"M. Rospocher\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"1749815\",\"name\":\"A. Sperduti\"}],\"doi\":\"10.1145/3341105.3373958\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84afec744466b09959ce2ae44de642836ce704b4\",\"title\":\"VTKEL: a resource for visual-textual-knowledge entity linking\",\"url\":\"https://www.semanticscholar.org/paper/84afec744466b09959ce2ae44de642836ce704b4\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"1907.04957\",\"authors\":[{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"1925969\",\"name\":\"M. Murray\"},{\"authorId\":\"49258625\",\"name\":\"Maya Cakmak\"},{\"authorId\":\"1982950\",\"name\":\"Luke Zettlemoyer\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b9ce27801c077433245ad0f9e43e3c38441cecd\",\"title\":\"Vision-and-Dialog Navigation\",\"url\":\"https://www.semanticscholar.org/paper/1b9ce27801c077433245ad0f9e43e3c38441cecd\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"1708.05122\",\"authors\":[{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"60f432331abc0976cf236c738844f9427277b0de\",\"title\":\"Evaluating Visual Conversational Agents via Cooperative Human-AI Games\",\"url\":\"https://www.semanticscholar.org/paper/60f432331abc0976cf236c738844f9427277b0de\",\"venue\":\"HCOMP\",\"year\":2017},{\"arxivId\":\"2006.06026\",\"authors\":[{\"authorId\":\"1716325\",\"name\":\"M. Esk\\u00e9nazi\"},{\"authorId\":\"8200875\",\"name\":\"Tiancheng Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0dbf699bfec37a5f1615d10107f289dd041a7885\",\"title\":\"Report from the NSF Future Directions Workshop, Toward User-Oriented Agents: Research Directions and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/0dbf699bfec37a5f1615d10107f289dd041a7885\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc8020f05b18ed434009b5d56398c57456c7dcde\",\"title\":\"Disentangling neural network representations for improved generalization\",\"url\":\"https://www.semanticscholar.org/paper/dc8020f05b18ed434009b5d56398c57456c7dcde\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1707.00683\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"title\":\"Modulating early visual processing by language\",\"url\":\"https://www.semanticscholar.org/paper/feeb3a2aa35a02e06546d05d94bac9a2123fc0c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1705.03633\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/ICCV.2017.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e17cf6a339fd071ad222062f868e882ef4120a4\",\"title\":\"Inferring and Executing Programs for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2e17cf6a339fd071ad222062f868e882ef4120a4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40195882\",\"name\":\"M. Firdaus\"},{\"authorId\":\"6764364\",\"name\":\"Nidhi Thakur\"},{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.210\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59ee2e2ed78da75c356ba063c0a88466ffb62391\",\"title\":\"MultiDM-GCN: Aspect-Guided Response Generation in Multi-Domain Multi-Modal Dialogue System using Graph Convolution Network\",\"url\":\"https://www.semanticscholar.org/paper/59ee2e2ed78da75c356ba063c0a88466ffb62391\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2005.04790\",\"authors\":[{\"authorId\":\"1743722\",\"name\":\"Douwe Kiela\"},{\"authorId\":\"22593971\",\"name\":\"Hamed Firooz\"},{\"authorId\":\"152422011\",\"name\":\"Aravind Mohan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"50286460\",\"name\":\"Amanpreet Singh\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"1389630028\",\"name\":\"Davide Testuggine\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"51b461040c381cb1489e55ea4b9686c709818b10\",\"title\":\"The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes\",\"url\":\"https://www.semanticscholar.org/paper/51b461040c381cb1489e55ea4b9686c709818b10\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1809.04560\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D18-1012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"title\":\"Game-Based Video-Context Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1705.08759\",\"authors\":[{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.763\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cee733ee31e245dac4655a870fd9226163a52b5\",\"title\":\"Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-in-the-Blank Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1cee733ee31e245dac4655a870fd9226163a52b5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30670181\",\"name\":\"Thilini Cooray\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"153022029\",\"name\":\"W. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00479\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb8aea99913099a3496dcbc8af49d7f99edf77d2\",\"title\":\"Attention-Based Context Aware Reasoning for Situation Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb8aea99913099a3496dcbc8af49d7f99edf77d2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"1885250234\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"}],\"doi\":\"10.1007/s11263-020-01360-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7391db7c99c5b43428b093188a66a9e274d7ac08\",\"title\":\"GADE: A Generative Adversarial Approach to Density Estimation and its Applications\",\"url\":\"https://www.semanticscholar.org/paper/7391db7c99c5b43428b093188a66a9e274d7ac08\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2511091\",\"name\":\"X. Sun\"},{\"authorId\":\"1733077424\",\"name\":\"Xinwen Hu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1145/3372278.3390671\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6a23be9d6b7b353d567f298d55e2e60e14431e33\",\"title\":\"Human Object Interaction Detection via Multi-level Conditioned Network\",\"url\":\"https://www.semanticscholar.org/paper/6a23be9d6b7b353d567f298d55e2e60e14431e33\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46961137\",\"name\":\"Chen Cui\"},{\"authorId\":\"49336556\",\"name\":\"Wenjie Wang\"},{\"authorId\":\"33977299\",\"name\":\"X. Song\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"40620796\",\"name\":\"Xin-Shun Xu\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"}],\"doi\":\"10.1145/3331184.3331226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e92a32c45ccc0c933553d6f28b3551f0293bcd20\",\"title\":\"User Attention-guided Multimodal Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/e92a32c45ccc0c933553d6f28b3551f0293bcd20\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39214752\",\"name\":\"Z. Zhang\"},{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"1730108\",\"name\":\"Minlie Huang\"},{\"authorId\":\"145213540\",\"name\":\"Xiaoyan Zhu\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3308558.3313598\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"title\":\"Neural Multimodal Belief Tracker with Adaptive Attention for Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/56d49c44e66e8ae6b0b89b5b3207aaddc46ee12d\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34819738\",\"name\":\"Satoshi Akasaki\"},{\"authorId\":\"145766950\",\"name\":\"Nobuhiro Kaji\"}],\"doi\":\"10.18653/v1/N19-1400\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5ff5438ab187251d0e130013abd4d62b3c34dc8\",\"title\":\"Conversation Initiation by Diverse News Contents Introduction\",\"url\":\"https://www.semanticscholar.org/paper/d5ff5438ab187251d0e130013abd4d62b3c34dc8\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1016/j.csl.2020.101093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"title\":\"Transfer learning for multimodal dialog\",\"url\":\"https://www.semanticscholar.org/paper/9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":\"1908.05067\",\"authors\":[{\"authorId\":\"47999368\",\"name\":\"Yi-Ting Yeh\"},{\"authorId\":\"145514809\",\"name\":\"Tzu-Chuan Lin\"},{\"authorId\":\"152498628\",\"name\":\"Hsiao-Hua Cheng\"},{\"authorId\":\"152141374\",\"name\":\"Yu-Hsuan Deng\"},{\"authorId\":\"27629426\",\"name\":\"Shang-Yu Su\"},{\"authorId\":\"1725643\",\"name\":\"Yun-Nung (Vivian) Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2539fad727e1def50b87fc88d3a499b4fe1f393\",\"title\":\"Reactive Multi-Stage Feature Fusion for Multimodal Dialogue Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f2539fad727e1def50b87fc88d3a499b4fe1f393\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1734904\",\"name\":\"Asif Ekbal\"}],\"doi\":\"10.1007/s40012-020-00304-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f302691678e3c1a7c6ef1b7c808132cdbd1fe26\",\"title\":\"Towards building an affect-aware dialogue agent with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/6f302691678e3c1a7c6ef1b7c808132cdbd1fe26\",\"venue\":\"CSI Transactions on ICT\",\"year\":2020},{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2010.13944\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"152949573\",\"name\":\"Ruo-Ping Dong\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.93\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdb13721109c703486099522edb456a1fe6f44e\",\"title\":\"Reading Between the Lines: Exploring Infilling in Visual Narratives\",\"url\":\"https://www.semanticscholar.org/paper/1bdb13721109c703486099522edb456a1fe6f44e\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2011.08277\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"51050450\",\"name\":\"Jacob Krantz\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1606382599\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dab94f11874acdd5ffe63cfb22c5f93723dc519f\",\"title\":\"Where Are You? Localization from Embodied Dialog\",\"url\":\"https://www.semanticscholar.org/paper/dab94f11874acdd5ffe63cfb22c5f93723dc519f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1811.00945\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"title\":\"Image-Chat: Engaging Grounded Conversations\",\"url\":\"https://www.semanticscholar.org/paper/b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1016/j.neucom.2020.04.066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33cd369bbc8825a812d672b15e184ae43ca69352\",\"title\":\"Visually grounded paraphrase identification via gating and phrase localization\",\"url\":\"https://www.semanticscholar.org/paper/33cd369bbc8825a812d672b15e184ae43ca69352\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1911.02739\",\"authors\":[{\"authorId\":\"72871419\",\"name\":\"Zhihan Zhang\"},{\"authorId\":\"1770874\",\"name\":\"Zhiyi Yin\"},{\"authorId\":\"1906099\",\"name\":\"Shuhuai Ren\"},{\"authorId\":\"78145275\",\"name\":\"Xinhang Li\"},{\"authorId\":\"50341802\",\"name\":\"S. Li\"}],\"doi\":\"10.1007/978-3-030-60457-8_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"422f098e1e5b6fa34e73ad83557ba793ca3c0403\",\"title\":\"DCA: Diversified Co-Attention towards Informative Live Video Commenting\",\"url\":\"https://www.semanticscholar.org/paper/422f098e1e5b6fa34e73ad83557ba793ca3c0403\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b02dba59a087f16d8286aec5e6481d5952a37df5\",\"title\":\"CMU Sinbad\\u2019s Submission for the DSTC7 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b02dba59a087f16d8286aec5e6481d5952a37df5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37414303\",\"name\":\"C. Han\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"46949443\",\"name\":\"Woo-Young Kang\"},{\"authorId\":\"1960307\",\"name\":\"Jae-Hyun Jun\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7564dc01b0a191aa606bb7322ba28d92f4067ecc\",\"title\":\"Attention Memory for Locating an Object through Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/7564dc01b0a191aa606bb7322ba28d92f4067ecc\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1907.08584\",\"authors\":[{\"authorId\":\"48417678\",\"name\":\"Jonathan Gray\"},{\"authorId\":\"27693639\",\"name\":\"Kavya Srinet\"},{\"authorId\":\"2262249\",\"name\":\"Yacine Jernite\"},{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"2240134\",\"name\":\"Zhuoyuan Chen\"},{\"authorId\":\"35578711\",\"name\":\"Demi Guo\"},{\"authorId\":\"3322061\",\"name\":\"S. Goyal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5d8d6278ad32acee4d649f32766de90cf4d787eb\",\"title\":\"CraftAssist: A Framework for Dialogue-enabled Interactive Agents\",\"url\":\"https://www.semanticscholar.org/paper/5d8d6278ad32acee4d649f32766de90cf4d787eb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48380508\",\"name\":\"Sasa Arsovski\"},{\"authorId\":\"143699999\",\"name\":\"A. Cheok\"},{\"authorId\":\"1507030228\",\"name\":\"Kirthana Govindarajoo\"},{\"authorId\":\"1507091318\",\"name\":\"Nurizzaty Salehuddin\"},{\"authorId\":\"1507088977\",\"name\":\"Somaiyeh Vedadi\"}],\"doi\":\"10.1007/s10489-019-01621-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0311428e7aed5abce69adbfba3e8ee85409dc9\",\"title\":\"Artificial intelligence snapchat: Visual conversation agent\",\"url\":\"https://www.semanticscholar.org/paper/1c0311428e7aed5abce69adbfba3e8ee85409dc9\",\"venue\":\"Applied Intelligence\",\"year\":2020},{\"arxivId\":\"1902.09368\",\"authors\":[{\"authorId\":\"71119060\",\"name\":\"Gi-Cheon Kang\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.18653/v1/D19-1209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86754c8a22d5df5636aa5603db01835b5d4ee32c\",\"title\":\"Dual Attention Networks for Visual Reference Resolution in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/86754c8a22d5df5636aa5603db01835b5d4ee32c\",\"venue\":\"EMNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49483501\",\"name\":\"Yiqun Yao\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"49821282\",\"name\":\"Bo Xu\"}],\"doi\":\"10.18653/v1/N19-1266\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c880ad812f1195c1199a7e50fcedfca1c41a8e29\",\"title\":\"The World in My Mind: Visual Dialog with Adversarial Multi-modal Feature Encoding\",\"url\":\"https://www.semanticscholar.org/paper/c880ad812f1195c1199a7e50fcedfca1c41a8e29\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493849\",\"name\":\"Dejiang Kong\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1007/978-3-030-00776-8_56\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89e982f1a1cda786062f4044391a67d6739804cd\",\"title\":\"Visual Dialog with Multi-turn Attentional Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/89e982f1a1cda786062f4044391a67d6739804cd\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1805.00460\",\"authors\":[{\"authorId\":\"145568592\",\"name\":\"Andrew Shin\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2018.00930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09efde3bd0a380e8cbcd55a13694648276c2c166\",\"title\":\"Customized Image Narrative Generation via Interactive Visual Question Generation and Answering\",\"url\":\"https://www.semanticscholar.org/paper/09efde3bd0a380e8cbcd55a13694648276c2c166\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152673712\",\"name\":\"Youming Gao\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"47362529\",\"name\":\"T. Xu\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-30508-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"title\":\"Referring Expression Comprehension via Co-attention and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"2012.05567\",\"authors\":[{\"authorId\":\"9660848\",\"name\":\"Wencan Zhang\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"},{\"authorId\":\"1995703\",\"name\":\"B. Lim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c46271e99f7f38ce335ca45136de7e71603006e\",\"title\":\"Debiased-CAM for bias-agnostic faithful visual explanations of deep convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/4c46271e99f7f38ce335ca45136de7e71603006e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.08037\",\"authors\":[{\"authorId\":\"46507111\",\"name\":\"Hanqing Wang\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"1844358\",\"name\":\"Tianmin Shu\"},{\"authorId\":\"97233415\",\"name\":\"W. Liang\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1007/978-3-030-58542-6_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac7a4216c02b0cd1ccbd9aa95cb56a8fed25f146\",\"title\":\"Active Visual Information Gathering for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/ac7a4216c02b0cd1ccbd9aa95cb56a8fed25f146\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2006.12442\",\"authors\":[{\"authorId\":\"144745718\",\"name\":\"Stephen Roller\"},{\"authorId\":\"2656573\",\"name\":\"Y.-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"31461304\",\"name\":\"Emily Dinan\"},{\"authorId\":\"4861083\",\"name\":\"A. Fan\"},{\"authorId\":\"2121780\",\"name\":\"D. Gunning\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"6649233\",\"name\":\"Margaret Li\"},{\"authorId\":\"1753626755\",\"name\":\"Spencer Poff\"},{\"authorId\":\"1422035486\",\"name\":\"Pratik Ringshia\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"39219656\",\"name\":\"Jack Urbanek\"},{\"authorId\":\"49160304\",\"name\":\"M. Williamson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ebf79630966e36761f2275990075384fdcb8d3a7\",\"title\":\"Open-Domain Conversational Agents: Current Progress, Open Problems, and Future Directions\",\"url\":\"https://www.semanticscholar.org/paper/ebf79630966e36761f2275990075384fdcb8d3a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14700\",\"authors\":[{\"authorId\":\"7748443\",\"name\":\"Sangwoong Yoon\"},{\"authorId\":\"21152168\",\"name\":\"Woo Young Kang\"},{\"authorId\":\"97519074\",\"name\":\"Sungwook Jeon\"},{\"authorId\":\"50112156\",\"name\":\"Seong-Eun Lee\"},{\"authorId\":\"118727697\",\"name\":\"Changjin Han\"},{\"authorId\":\"30664924\",\"name\":\"Jonghun Park\"},{\"authorId\":\"1845794808\",\"name\":\"Eun-Sol Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e0570df4e56d51be58b53166e853d848ef767af\",\"title\":\"Image-to-Image Retrieval by Learning Similarity between Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/2e0570df4e56d51be58b53166e853d848ef767af\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1704.00200\",\"authors\":[{\"authorId\":\"2909575\",\"name\":\"Amrita Saha\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"},{\"authorId\":\"145590185\",\"name\":\"K. Sankaranarayanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f69fa423b076e19dc2ccf6bc9013f09ae39133c\",\"title\":\"Multimodal Dialogs (MMD): A large-scale dataset for studying multimodal domain-aware conversations\",\"url\":\"https://www.semanticscholar.org/paper/1f69fa423b076e19dc2ccf6bc9013f09ae39133c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2003.05995\",\"authors\":[{\"authorId\":\"28099920\",\"name\":\"Francisco Javier Chiyah Garcia\"},{\"authorId\":\"145532150\",\"name\":\"Jos\\u00e9 Lopes\"},{\"authorId\":\"120281143\",\"name\":\"Xingkun Liu\"},{\"authorId\":\"1691444\",\"name\":\"H. Hastie\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e253ad28fffed71936c4f2b0e4065a9790d31e6c\",\"title\":\"CRWIZ: A Framework for Crowdsourcing Real-Time Wizard-of-Oz Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/e253ad28fffed71936c4f2b0e4065a9790d31e6c\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"2005.07493\",\"authors\":[{\"authorId\":\"144992211\",\"name\":\"Shubham Agarwal\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2621022\",\"name\":\"Ioannis Konstas\"},{\"authorId\":\"1681799\",\"name\":\"Verena Rieser\"}],\"doi\":\"10.18653/v1/2020.acl-main.728\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c3baa99376fac050160c25a9c6d92d9baa5846c\",\"title\":\"History for Visual Dialog: Do we really need it?\",\"url\":\"https://www.semanticscholar.org/paper/8c3baa99376fac050160c25a9c6d92d9baa5846c\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29695322\",\"name\":\"Ben Fielding\"},{\"authorId\":\"1379588370\",\"name\":\"T. Lawrence\"},{\"authorId\":\"47058944\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1109/IJCNN.2019.8852369\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"714925429e8f1929b15b16098094de290928ae1e\",\"title\":\"Evolving and Ensembling Deep CNN Architectures for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/714925429e8f1929b15b16098094de290928ae1e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1808.10009\",\"authors\":[{\"authorId\":\"2110665\",\"name\":\"A. Padmakumar\"},{\"authorId\":\"144848112\",\"name\":\"P. Stone\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":\"10.18653/v1/D18-1165\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a41e4a01495030940abb623b38deadab1b4957c5\",\"title\":\"Learning a Policy for Opportunistic Active Learning\",\"url\":\"https://www.semanticscholar.org/paper/a41e4a01495030940abb623b38deadab1b4957c5\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50627194\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"143924106\",\"name\":\"R. Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.3390/s20174761\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4f1217919ef803a0549822039f5328ea78f80ff\",\"title\":\"Indoor Scene Change Captioning Based on Multimodality Data\",\"url\":\"https://www.semanticscholar.org/paper/c4f1217919ef803a0549822039f5328ea78f80ff\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1709.02314\",\"authors\":[{\"authorId\":\"1403974204\",\"name\":\"Daniel O\\u00f1oro-Rubio\"},{\"authorId\":\"2780262\",\"name\":\"Mathias Niepert\"},{\"authorId\":\"1405061488\",\"name\":\"Alberto Garc\\u00eda-Dur\\u00e1n\"},{\"authorId\":\"145904072\",\"name\":\"R. Gonzalez\"},{\"authorId\":\"1402973336\",\"name\":\"R. L\\u00f3pez-Sastre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4ee8e2fcbdf2b65ca39c28f36c81d4c56b82d0d\",\"title\":\"Representation Learning for Visual-Relational Knowledge Graphs\",\"url\":\"https://www.semanticscholar.org/paper/e4ee8e2fcbdf2b65ca39c28f36c81d4c56b82d0d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1709.07992\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"title\":\"Visual Reference Resolution using Attention Memory for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad8c0489d908d6bb4b48eb56c8c92b8f545216f5\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.12377\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb4e5d203efae1f0838bb59e31026ce3e7511f87\",\"title\":\"Perceive, Transform, and Act: Multi-Modal Attention Networks for Vision-and-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/bb4e5d203efae1f0838bb59e31026ce3e7511f87\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2007.03310\",\"authors\":[{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15087270\",\"name\":\"Yajing Sun\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"49659134\",\"name\":\"Zihao Zhu\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.24963/ijcai.2020/96\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acd1e52ec887f899bd59bf3ec36c744887fc43d7\",\"title\":\"DAM: Deliberation, Abandon and Memory Networks for Generating Detailed and Non-repetitive Responses in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/acd1e52ec887f899bd59bf3ec36c744887fc43d7\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1912.12394\",\"authors\":[{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"90841478\",\"name\":\"Y-Lan Boureau\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4aa5454addde1542e0d01cfc68e6f5129630964d\",\"title\":\"All-in-One Image-Grounded Conversational Agents\",\"url\":\"https://www.semanticscholar.org/paper/4aa5454addde1542e0d01cfc68e6f5129630964d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.04081\",\"authors\":[{\"authorId\":\"8135633\",\"name\":\"Xuwang Yin\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"145480862\",\"name\":\"S. Feng\"}],\"doi\":\"10.18653/v1/N19-4024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac81e14ab88a47d39e80b8927b3f37a1a0e588ed\",\"title\":\"Chat-crowd: A Dialog-based Platform for Visual Layout Composition\",\"url\":\"https://www.semanticscholar.org/paper/ac81e14ab88a47d39e80b8927b3f37a1a0e588ed\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1906.03561\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"32222907\",\"name\":\"Qianru Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"title\":\"Joint Visual Grounding with Language Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/3d84db9d0d21b0eae8cad741d16a74e7880c711c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.08977\",\"authors\":[{\"authorId\":\"7289061\",\"name\":\"Hyemin Ahn\"},{\"authorId\":\"98605657\",\"name\":\"O. Kwon\"},{\"authorId\":\"9086571\",\"name\":\"Kyoungdo Kim\"},{\"authorId\":\"30742686\",\"name\":\"Dongheui Lee\"},{\"authorId\":\"34184385\",\"name\":\"Songhwai Oh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"052fd049bc6a3cad1dd7d516c406b1d5d08c5d60\",\"title\":\"Visually Grounding Instruction for History-Dependent Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/052fd049bc6a3cad1dd7d516c406b1d5d08c5d60\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.10354\",\"authors\":[{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc4598d636b599c4752a376cc074541c5a0ec97a\",\"title\":\"Unsupervised Keyword Extraction for Full-sentence VQA\",\"url\":\"https://www.semanticscholar.org/paper/fc4598d636b599c4752a376cc074541c5a0ec97a\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2004.08299\",\"authors\":[{\"authorId\":\"2065332\",\"name\":\"H. Lee\"},{\"authorId\":\"152333274\",\"name\":\"Seunghyun Yoon\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"153586399\",\"name\":\"Doo Soon Kim\"},{\"authorId\":\"145262461\",\"name\":\"Trung Bui\"},{\"authorId\":\"1731707\",\"name\":\"K. Jung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccc78b88920a1f2825bcf969fc23f95aeb4bffc5\",\"title\":\"DSTC8-AVSD: Multimodal Semantic Transformer Network with Retrieval Style Word Generator\",\"url\":\"https://www.semanticscholar.org/paper/ccc78b88920a1f2825bcf969fc23f95aeb4bffc5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.00347\",\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"2934336\",\"name\":\"Lo\\u00efc Barrault\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f56cb5dc32b5b280546998418fda7769d0858629\",\"title\":\"How2: A Large-scale Dataset for Multimodal Language Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f56cb5dc32b5b280546998418fda7769d0858629\",\"venue\":\"NIPS 2018\",\"year\":2018},{\"arxivId\":\"1808.04359\",\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"title\":\"Community Regularization of Visually-Grounded Dialog\",\"url\":\"https://www.semanticscholar.org/paper/79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"1911.10496\",\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"title\":\"Two Causal Principles for Improving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.00443\",\"authors\":[{\"authorId\":\"48632281\",\"name\":\"X. Wang\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"1714932\",\"name\":\"Zornitsa Kozareva\"},{\"authorId\":\"120209444\",\"name\":\"S. Ravi\"}],\"doi\":\"10.1007/978-3-030-58586-0_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e301f4e6c8bceae340040aac159676cb2290ba3d\",\"title\":\"Environment-agnostic Multitask Learning for Natural Language Grounded Navigation\",\"url\":\"https://www.semanticscholar.org/paper/e301f4e6c8bceae340040aac159676cb2290ba3d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.02649\",\"authors\":[{\"authorId\":\"9202187\",\"name\":\"Chaoqun Duan\"},{\"authorId\":\"145500846\",\"name\":\"Lei Cui\"},{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2675365\",\"name\":\"Conghui Zhu\"},{\"authorId\":\"1856039\",\"name\":\"T. Zhao\"}],\"doi\":\"10.3233/FAIA200320\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"7bf0bf048b88c2bb5a7d53e34ec912907295be81\",\"title\":\"Multimodal Matching Transformer for Live Commenting\",\"url\":\"https://www.semanticscholar.org/paper/7bf0bf048b88c2bb5a7d53e34ec912907295be81\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1571683703\",\"name\":\"Duc Chung Tran\"},{\"authorId\":\"2000979890\",\"name\":\"Hong Son Ha\"},{\"authorId\":\"66901222\",\"name\":\"Luyl-Da Quach\"},{\"authorId\":\"2000967963\",\"name\":\"Mohd.Fadzil Hassan\"}],\"doi\":\"10.1109/ICSGRC49013.2020.9232496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b713257429773b40eb2423f12d63d990c7672e4d\",\"title\":\"An Email to Readable Vietnamese Text Conversion Algorithm for Use in TTS Application\",\"url\":\"https://www.semanticscholar.org/paper/b713257429773b40eb2423f12d63d990c7672e4d\",\"venue\":\"2020 11th IEEE Control and System Graduate Research Colloquium (ICSGRC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41071249\",\"name\":\"Ece Takmaz\"},{\"authorId\":\"24068173\",\"name\":\"Mario Giulianelli\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"153915609\",\"name\":\"Arabella Sinclair\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"35490092cd5295a4552a6b46b0ec8372beb87089\",\"title\":\"Refer, Reuse, Reduce: Grounding Subsequent References in Visual and Conversational Contexts\",\"url\":\"https://www.semanticscholar.org/paper/35490092cd5295a4552a6b46b0ec8372beb87089\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8f6dbe07a311cbc756eb6d38528d70eb66663311\",\"title\":\"Audio Visual Scene-Aware Dialog Track in DSTC8\",\"url\":\"https://www.semanticscholar.org/paper/8f6dbe07a311cbc756eb6d38528d70eb66663311\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.02985\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"40186452\",\"name\":\"M. Corsini\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64d1b545f586d930cbe67402e853ab26a8f6e18d\",\"title\":\"Embodied Vision-and-Language Navigation with Dynamic Convolutional Filters\",\"url\":\"https://www.semanticscholar.org/paper/64d1b545f586d930cbe67402e853ab26a8f6e18d\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1906.12188\",\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"title\":\"A Deep Decoder Structure Based on WordEmbedding Regression for An Encoder-Decoder Based Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.18653/v1/D19-1217\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"title\":\"Video Dialog via Progressive Inference and Cross-Transformer\",\"url\":\"https://www.semanticscholar.org/paper/142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2010.01082\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"title\":\"Multi-Modal Open-Domain Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3457456\",\"name\":\"Prashant Jayannavar\"},{\"authorId\":\"1414599717\",\"name\":\"Anjali Narayan-Chen\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.18653/v1/2020.acl-main.232\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15a1727324216573f8859b748e65d6ac5458822b\",\"title\":\"Learning to execute instructions in a Minecraft dialogue\",\"url\":\"https://www.semanticscholar.org/paper/15a1727324216573f8859b748e65d6ac5458822b\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1809.03408\",\"authors\":[{\"authorId\":\"145543514\",\"name\":\"Ravi Shekhar\"},{\"authorId\":\"46176433\",\"name\":\"Aashish Venkatesh\"},{\"authorId\":\"51190347\",\"name\":\"Tim Baumg\\u00e4rtner\"},{\"authorId\":\"2552871\",\"name\":\"Elia Bruni\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"144151273\",\"name\":\"R. Fern\\u00e1ndez\"}],\"doi\":\"10.18653/v1/N19-1265\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"69e0f26a178780eea1ad4cfebd2d0985a7ac54ed\",\"title\":\"Beyond task success: A closer look at jointly learning to see, ask, and GuessWhat\",\"url\":\"https://www.semanticscholar.org/paper/69e0f26a178780eea1ad4cfebd2d0985a7ac54ed\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1906.02738\",\"authors\":[{\"authorId\":\"3444092\",\"name\":\"Lianhui Qin\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"46522098\",\"name\":\"Xiaodong Liu\"},{\"authorId\":\"71886367\",\"name\":\"Xiang Gao\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P19-1539\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27033b8f72bf8cb7662c9f92b3ccb3c476db7135\",\"title\":\"Conversing by Reading: Contentful Neural Conversation with On-demand Machine Reading\",\"url\":\"https://www.semanticscholar.org/paper/27033b8f72bf8cb7662c9f92b3ccb3c476db7135\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1711.07280\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"12139064\",\"name\":\"Jake Bruce\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1771913\",\"name\":\"Niko S\\u00fcnderhauf\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00387\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6bd9642470ff8c2089427f7a6392cd17d213a334\",\"title\":\"Vision-and-Language Navigation: Interpreting Visually-Grounded Navigation Instructions in Real Environments\",\"url\":\"https://www.semanticscholar.org/paper/6bd9642470ff8c2089427f7a6392cd17d213a334\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2002.10340\",\"authors\":[{\"authorId\":\"144052839\",\"name\":\"Wei Pang\"},{\"authorId\":\"50142157\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-58517-4_40\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b7ba12958cb670442236accd5e0579728821ad7d\",\"title\":\"Guessing State Tracking for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/b7ba12958cb670442236accd5e0579728821ad7d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721364\",\"name\":\"Sina Zarrie\\u00df\"},{\"authorId\":\"1817455\",\"name\":\"David Schlangen\"}],\"doi\":\"10.18653/v1/P17-1023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"709f43392b4a30519f5f87630a573b0a51d40537\",\"title\":\"Obtaining referential word meanings from visual and distributional information: Experiments on object naming\",\"url\":\"https://www.semanticscholar.org/paper/709f43392b4a30519f5f87630a573b0a51d40537\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"51487414\",\"name\":\"Yunshan Ma\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240605\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8384387a3739280b15d38f39429aadb7c9bd620f\",\"title\":\"Knowledge-aware Multimodal Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/8384387a3739280b15d38f39429aadb7c9bd620f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"15246869\",\"name\":\"X. Jiang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"1581498565\",\"name\":\"Yue Hu\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TIP.2020.3034494\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"title\":\"Learning Dual Encoding Model for Adaptive Visual Understanding in Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/72c2a42e00131f63f4898e29f641c32f9cdd24a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1809.06641\",\"authors\":[{\"authorId\":\"40561194\",\"name\":\"Joachim Fainberg\"},{\"authorId\":\"9340968\",\"name\":\"Ben Krause\"},{\"authorId\":\"32538144\",\"name\":\"M. Dobre\"},{\"authorId\":\"3451777\",\"name\":\"M. Damonte\"},{\"authorId\":\"26432578\",\"name\":\"Emmanuel Kahembwe\"},{\"authorId\":\"2876339\",\"name\":\"D. Duma\"},{\"authorId\":\"1736049\",\"name\":\"B. Webber\"},{\"authorId\":\"2364338\",\"name\":\"Federico Fancellu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f3c356d2fc0132992137420b1486be658bc6088\",\"title\":\"Talking to myself: self-dialogues as data for conversational agents\",\"url\":\"https://www.semanticscholar.org/paper/7f3c356d2fc0132992137420b1486be658bc6088\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2003.06745\",\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhu\"},{\"authorId\":\"94228656\",\"name\":\"Fengda Zhu\"},{\"authorId\":\"83374215\",\"name\":\"Zhaohuan Zhan\"},{\"authorId\":\"16208574\",\"name\":\"Bingqian Lin\"},{\"authorId\":\"73416694\",\"name\":\"Jianbin Jiao\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"}],\"doi\":\"10.1109/cvpr42600.2020.01074\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07de32d212a2d712b43557b4977b2ac76556e1d6\",\"title\":\"Vision-Dialog Navigation by Exploring Cross-Modal Memory\",\"url\":\"https://www.semanticscholar.org/paper/07de32d212a2d712b43557b4977b2ac76556e1d6\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.08360\",\"authors\":[{\"authorId\":\"49102717\",\"name\":\"Feilong Chen\"},{\"authorId\":\"33427918\",\"name\":\"Fandong Meng\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"144326610\",\"name\":\"Peng Li\"},{\"authorId\":\"153260119\",\"name\":\"Bo Xu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I05.6248\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"title\":\"DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"113720743\",\"name\":\"Amin Parvaneh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR42600.2020.01006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"title\":\"Counterfactual Vision and Language Learning\",\"url\":\"https://www.semanticscholar.org/paper/046f1c5cc8c7b4f24ab62a536d8b0a989209824b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1562995755\",\"name\":\"Shahi Dost\"},{\"authorId\":\"48790273\",\"name\":\"L. Serafini\"},{\"authorId\":\"1766782\",\"name\":\"M. Rospocher\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"1749815\",\"name\":\"A. Sperduti\"}],\"doi\":\"10.1007/978-3-030-51310-8_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"215a291141722216a8682d58c38e4d3c17456324\",\"title\":\"Jointly Linking Visual and Textual Entity Mentions with Background Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/215a291141722216a8682d58c38e4d3c17456324\",\"venue\":\"NLDB\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23281164\",\"name\":\"Omar Adjali\"},{\"authorId\":\"1740190\",\"name\":\"R. Besan\\u00e7on\"},{\"authorId\":\"1679133\",\"name\":\"Olivier Ferret\"},{\"authorId\":\"2138418\",\"name\":\"H. Borgne\"},{\"authorId\":\"1704849\",\"name\":\"B. Grau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"860ff0f3639af33108b4ed1b50ae1f17133368e5\",\"title\":\"Building a Multimodal Entity Linking Dataset From Tweets\",\"url\":\"https://www.semanticscholar.org/paper/860ff0f3639af33108b4ed1b50ae1f17133368e5\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49319111\",\"name\":\"Dan Guo\"},{\"authorId\":\"39698901\",\"name\":\"H. Wang\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"}],\"doi\":\"10.1109/TIP.2020.2992888\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"de847c41c0b6c52e5fc770f364a19fed04a7b3ae\",\"title\":\"Textual-Visual Reference-Aware Attention Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/de847c41c0b6c52e5fc770f364a19fed04a7b3ae\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"144287919\",\"name\":\"Eric Nyberg\"},{\"authorId\":\"1690706\",\"name\":\"A. Black\"}],\"doi\":\"10.18653/v1/P19-1606\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"710d1b5d2662fd78dfb7904e64a1edbe1a671567\",\"title\":\"Storyboarding of Recipes: Grounded Contextual Generation\",\"url\":\"https://www.semanticscholar.org/paper/710d1b5d2662fd78dfb7904e64a1edbe1a671567\",\"venue\":\"DGS@ICLR\",\"year\":2019},{\"arxivId\":\"1812.06401\",\"authors\":[{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2019.00428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b15154b94fcaf857d8da2ad5b6d583d166d4234\",\"title\":\"What's to Know? Uncertainty as a Guide to Asking Goal-Oriented Questions\",\"url\":\"https://www.semanticscholar.org/paper/2b15154b94fcaf857d8da2ad5b6d583d166d4234\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1903.03166\",\"authors\":[{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/N19-1058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fb751f1d2ac984670a57663aec80ee8b4ac189d6\",\"title\":\"CLEVR-Dialog: A Diagnostic Dataset for Multi-Round Reasoning in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/fb751f1d2ac984670a57663aec80ee8b4ac189d6\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2012.07138\",\"authors\":[{\"authorId\":\"48212577\",\"name\":\"Hongming Zhang\"},{\"authorId\":\"2036553451\",\"name\":\"Yintong Huo\"},{\"authorId\":\"1500662261\",\"name\":\"Xinran Zhao\"},{\"authorId\":\"95882703\",\"name\":\"Y. Song\"},{\"authorId\":\"152567881\",\"name\":\"Dan Roth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2aa58cc59d3ce919ce1298ae9207f304587458f5\",\"title\":\"Learning Contextual Causality from Time-consecutive Images\",\"url\":\"https://www.semanticscholar.org/paper/2aa58cc59d3ce919ce1298ae9207f304587458f5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.09042\",\"authors\":[{\"authorId\":\"46398531\",\"name\":\"Yongfei Liu\"},{\"authorId\":\"47241555\",\"name\":\"Bo Wan\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"}],\"doi\":\"10.1609/aaai.v34i07.6833\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c6d410891bef95ce4240eaa6d4908feb493527c\",\"title\":\"Learning Cross-modal Context Graph for Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7c6d410891bef95ce4240eaa6d4908feb493527c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2004.14025\",\"authors\":[{\"authorId\":\"79778234\",\"name\":\"Sungjin Park\"},{\"authorId\":\"89016637\",\"name\":\"T. Whang\"},{\"authorId\":\"3037023\",\"name\":\"Y. Yoon\"},{\"authorId\":\"1450703435\",\"name\":\"Hueiseok Lim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"title\":\"Multi-View Attention Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/6a7c8371f6a0646a1ce04bc0c42f56ff1438f9ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90745780\",\"name\":\"Thomas Scialom\"},{\"authorId\":\"22710849\",\"name\":\"Patrick Bordes\"},{\"authorId\":\"1502219404\",\"name\":\"Paul-Alexis Dray\"},{\"authorId\":\"1767493\",\"name\":\"Jacopo Staiano\"},{\"authorId\":\"67192547\",\"name\":\"P. Gallinari\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b32d02d7f6fa954e7ae500f94f6a5efd113751a4\",\"title\":\"BERT Can See Out of the Box: On the Cross-modal Transferability of Text Representations\",\"url\":\"https://www.semanticscholar.org/paper/b32d02d7f6fa954e7ae500f94f6a5efd113751a4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"}],\"doi\":\"10.18653/v1/P18-5004\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"532837c431617d37c03361ba5a7d5fdb082c55f4\",\"title\":\"Connecting Language and Vision to Actions\",\"url\":\"https://www.semanticscholar.org/paper/532837c431617d37c03361ba5a7d5fdb082c55f4\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921879239\",\"name\":\"Shirong He\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20174897\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e52cae3e1df7ef76854645abf250db9282d01f27\",\"title\":\"An Effective Dense Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e52cae3e1df7ef76854645abf250db9282d01f27\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1804.02748\",\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc50c9392fd23b6c88915177c6ae904a498aacea\",\"title\":\"Scaling Egocentric Vision: The EPIC-KITCHENS Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fc50c9392fd23b6c88915177c6ae904a498aacea\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1806.05645\",\"authors\":[{\"authorId\":\"2112133\",\"name\":\"H. T. Vu\"},{\"authorId\":\"5975291\",\"name\":\"C. Greco\"},{\"authorId\":\"145095497\",\"name\":\"A. Erofeeva\"},{\"authorId\":\"51030589\",\"name\":\"Somayeh Jafaritazehjan\"},{\"authorId\":\"50816019\",\"name\":\"Guido Linders\"},{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1235dd37312cb20aced0e97d953f6379d8a0c7d4\",\"title\":\"Grounded Textual Entailment\",\"url\":\"https://www.semanticscholar.org/paper/1235dd37312cb20aced0e97d953f6379d8a0c7d4\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":\"1704.07121\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.18653/v1/N18-1040\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"title\":\"Being Negative but Constructively: Lessons Learnt from Creating Better Visual Question Answering Datasets\",\"url\":\"https://www.semanticscholar.org/paper/3374dfe0419cf452d2a60cdd750bdeb6e7433e59\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1809.08267\",\"authors\":[{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"28929337\",\"name\":\"L. Li\"}],\"doi\":\"10.1145/3209978.3210183\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83e567c2822aeda91006096a5d7ac0b34721d2a5\",\"title\":\"Neural Approaches to Conversational AI\",\"url\":\"https://www.semanticscholar.org/paper/83e567c2822aeda91006096a5d7ac0b34721d2a5\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":\"2004.06698\",\"authors\":[{\"authorId\":\"71119060\",\"name\":\"Gi-Cheon Kang\"},{\"authorId\":\"1755502\",\"name\":\"Junseok Park\"},{\"authorId\":\"2294014\",\"name\":\"Hwaran Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"},{\"authorId\":\"153188145\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"36642cb0c60047846ccc9bb670a63f6884e976d1\",\"title\":\"DialGraph: Sparse Graph Learning Networks for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/36642cb0c60047846ccc9bb670a63f6884e976d1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.02760\",\"authors\":[{\"authorId\":\"47002704\",\"name\":\"Y. Li\"},{\"authorId\":\"145544640\",\"name\":\"C. Huang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/ICCV.2017.370\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"title\":\"Learning to Disambiguate by Asking Discriminative Questions\",\"url\":\"https://www.semanticscholar.org/paper/acb1ffd5ba92b0c450ec63f36f4f67a972fc35ed\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1908.05391\",\"authors\":[{\"authorId\":\"50282546\",\"name\":\"Qibin Chen\"},{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"29343468\",\"name\":\"Yichang Zhang\"},{\"authorId\":\"145573463\",\"name\":\"M. Ding\"},{\"authorId\":\"83546711\",\"name\":\"Yukuo Cen\"},{\"authorId\":\"38385080\",\"name\":\"Hongxia Yang\"},{\"authorId\":\"40039047\",\"name\":\"J. Tang\"}],\"doi\":\"10.18653/v1/D19-1189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42ffd3a1ab4a139c5ec33b50bd7e5759077f03c4\",\"title\":\"Towards Knowledge-Based Recommender Dialog System\",\"url\":\"https://www.semanticscholar.org/paper/42ffd3a1ab4a139c5ec33b50bd7e5759077f03c4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1910.11301\",\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"2093485\",\"name\":\"Jiangtao Feng\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a273479d5ede7a27cf144a18cfbf0542b92fa12\",\"title\":\"Cross-Lingual Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/2a273479d5ede7a27cf144a18cfbf0542b92fa12\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3491491\",\"name\":\"Shiyang Yan\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"46406827\",\"name\":\"N. Robertson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"title\":\"SC-RANK: Improving Convolutional Image Captioning with Self-Critical Learning and Ranking Metric-based Reward\",\"url\":\"https://www.semanticscholar.org/paper/9f964bc4f8405491bc69c9e03e6f466ec609b9dd\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Tino Fuhrmann\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"845313c7e1949837770f3cf632cf18f71bccb530\",\"title\":\"Using Scene-Aware Voice Dialogs in Human-Drone Interaction\",\"url\":\"https://www.semanticscholar.org/paper/845313c7e1949837770f3cf632cf18f71bccb530\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50829868\",\"name\":\"A. Testoni\"},{\"authorId\":\"152741757\",\"name\":\"C. Greco\"},{\"authorId\":\"2008204693\",\"name\":\"Tobias Bianchi\"},{\"authorId\":\"1805994601\",\"name\":\"Mauricio Mazuecos\"},{\"authorId\":\"2008198429\",\"name\":\"Agata Marcante\"},{\"authorId\":\"3131683\",\"name\":\"Luciana Benotti\"},{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"}],\"doi\":\"10.18653/v1/2020.splu-1.4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"title\":\"They are not all alike: answering different spatial questions requires different grounding strategies\",\"url\":\"https://www.semanticscholar.org/paper/a864a6c1046523aed2b8565ccc2c55f7279a4c61\",\"venue\":\"SPLU\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":\"47120131\",\"name\":\"X. Wang\"},{\"authorId\":\"2093485\",\"name\":\"Jiangtao Feng\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a88e77a9574bcb20021d0dd4a4b8d729d85696f2\",\"title\":\"Beyond Monolingual Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/a88e77a9574bcb20021d0dd4a4b8d729d85696f2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.02379\",\"authors\":[{\"authorId\":\"46258988\",\"name\":\"Vishvak S. Murahari\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"}],\"doi\":\"10.1007/978-3-030-58523-5_20\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"604d7678235f5bb6039794e382d12058cecf8070\",\"title\":\"Large-scale Pretraining for Visual Dialog: A Simple State-of-the-Art Baseline\",\"url\":\"https://www.semanticscholar.org/paper/604d7678235f5bb6039794e382d12058cecf8070\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.02315\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.01045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"title\":\"12-in-1: Multi-Task Vision and Language Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5f3fe42548216cd93816b1bf5c437cf47bc5fbf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1811.10092\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00679\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"title\":\"Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation\",\"url\":\"https://www.semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1007/978-3-030-14657-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a9bae357bc63540cfbd630f4aaab4088edf2e0\",\"title\":\"Video Captioning Using Hierarchical LSTM and Text-Based Sliding Window\",\"url\":\"https://www.semanticscholar.org/paper/08a9bae357bc63540cfbd630f4aaab4088edf2e0\",\"venue\":\"IoTaaS\",\"year\":2018},{\"arxivId\":\"1907.03399\",\"authors\":[{\"authorId\":\"80927455\",\"name\":\"Takuma Udagawa\"},{\"authorId\":\"1705519\",\"name\":\"A. Aizawa\"}],\"doi\":\"10.1609/aaai.v33i01.33017120\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad7d5e5cea44c60605f742509eebe8a22502ffa9\",\"title\":\"A Natural Language Corpus of Common Grounding under Continuous and Partially-Observable Context\",\"url\":\"https://www.semanticscholar.org/paper/ad7d5e5cea44c60605f742509eebe8a22502ffa9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2010.10802\",\"authors\":[{\"authorId\":\"2239880\",\"name\":\"I. Gat\"},{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da5dde64865d7620079e0f50ef27b32bbebef7af\",\"title\":\"Removing Bias in Multi-modal Classifiers: Regularization by Maximizing Functional Entropies\",\"url\":\"https://www.semanticscholar.org/paper/da5dde64865d7620079e0f50ef27b32bbebef7af\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"title\":\"Mind Your Language: Learning Visually Grounded Dialog in a Multi-Agent Setting\",\"url\":\"https://www.semanticscholar.org/paper/bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1805.03257\",\"authors\":[{\"authorId\":\"50561583\",\"name\":\"J. Zhang\"},{\"authorId\":\"8200875\",\"name\":\"Tiancheng Zhao\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"}],\"doi\":\"10.18653/v1/W18-5015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"510d2879c03a2a0fa01ac6d6b95eb1067f2d1bf9\",\"title\":\"Multimodal Hierarchical Reinforcement Learning Policy for Task-Oriented Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/510d2879c03a2a0fa01ac6d6b95eb1067f2d1bf9\",\"venue\":\"SIGDIAL Conference\",\"year\":2018},{\"arxivId\":\"1810.03649\",\"authors\":[{\"authorId\":\"31448527\",\"name\":\"S. Ramakrishnan\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"title\":\"Overcoming Language Priors in Visual Question Answering with Adversarial Regularization\",\"url\":\"https://www.semanticscholar.org/paper/45ec1446f42c0a7c7fe74319118335c76e0f7b19\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1809.10735\",\"authors\":[{\"authorId\":\"2064210\",\"name\":\"Mark Yatskar\"}],\"doi\":\"10.18653/v1/N19-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a5606f0d56c618aa610cb1677e2788a3bd678fa\",\"title\":\"A Qualitative Comparison of CoQA, SQuAD 2.0 and QuAC\",\"url\":\"https://www.semanticscholar.org/paper/0a5606f0d56c618aa610cb1677e2788a3bd678fa\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1608.08974\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"title\":\"Towards Transparent AI Systems: Interpreting Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/f8645f298cc67a7ab751488f3945dc1beaffe8da\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1806.00525\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e7240d11872af602aabb103c4f2f307006250a0f\",\"title\":\"Audio Visual Scene-Aware Dialog (AVSD) Challenge at DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/e7240d11872af602aabb103c4f2f307006250a0f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37414303\",\"name\":\"Cheolho Han\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"32849162\",\"name\":\"W. Kang\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68c6df1249e1ee56835f79e1877506a16d8418f4\",\"title\":\"Criteria for Human-Compatible AI in Two-Player Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/68c6df1249e1ee56835f79e1877506a16d8418f4\",\"venue\":\"LaCATODA@IJCAI\",\"year\":2017},{\"arxivId\":\"2004.04963\",\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"47668008\",\"name\":\"T. Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"49969107\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1587/transinf.2020EDP7089\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"title\":\"Rephrasing visual questions by specifying the entropy of the answer distribution\",\"url\":\"https://www.semanticscholar.org/paper/d44be3e1158eb1b04e311479b17c0ff6f3fc06ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143718836\",\"name\":\"Ahmed Elgohary\"},{\"authorId\":\"21317593\",\"name\":\"D. Peskov\"},{\"authorId\":\"1389036863\",\"name\":\"Jordan L. Boyd-Graber\"}],\"doi\":\"10.18653/v1/D19-1605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdf13796e28639711a693e5410f06fa3b9b650f6\",\"title\":\"Can You Unpack That? Learning to Rewrite Questions-in-Context\",\"url\":\"https://www.semanticscholar.org/paper/cdf13796e28639711a693e5410f06fa3b9b650f6\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2006.04315\",\"authors\":[{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"},{\"authorId\":\"112957699\",\"name\":\"Ji-Rong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"title\":\"Counterfactual VQA: A Cause-Effect Look at Language Bias\",\"url\":\"https://www.semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.13922\",\"authors\":[{\"authorId\":\"1612421029\",\"name\":\"Yicong Hong\"},{\"authorId\":\"1509240145\",\"name\":\"Qi Wu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d16bce335338372c1927f69d4b1f667a330b59d2\",\"title\":\"A Recurrent Vision-and-Language BERT for Navigation\",\"url\":\"https://www.semanticscholar.org/paper/d16bce335338372c1927f69d4b1f667a330b59d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.14104\",\"authors\":[{\"authorId\":\"1423718676\",\"name\":\"Bj\\u00f6rn Bebensee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8684d9c94351f758af1a51ae0e93b9e5d76c354d\",\"title\":\"Co-attentional Transformers for Story-Based Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/8684d9c94351f758af1a51ae0e93b9e5d76c354d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08322\",\"authors\":[{\"authorId\":\"47196880\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"},{\"authorId\":\"49407982\",\"name\":\"Hui-min Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c87ed5765c51f3ed294a399d9d2384dc296c585\",\"title\":\"ORD: Object Relationship Discovery for Visual Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/6c87ed5765c51f3ed294a399d9d2384dc296c585\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00728\",\"authors\":[{\"authorId\":\"72471322\",\"name\":\"H. Roman\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"2665873\",\"name\":\"Jesse Thomason\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.157\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"645bc7a5347a299a1e8aa965867bd097f6f4bddd\",\"title\":\"RMM: A Recursive Mental Model for Dialog Navigation\",\"url\":\"https://www.semanticscholar.org/paper/645bc7a5347a299a1e8aa965867bd097f6f4bddd\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":1820614,\"doi\":\"10.1109/CVPR.2017.121\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":58,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1392331736\",\"name\":\"Andrei A. Rusu\"},{\"authorId\":\"144056327\",\"name\":\"J. Veness\"},{\"authorId\":\"1397980088\",\"name\":\"Marc G. Bellemare\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"3137672\",\"name\":\"Martin A. Riedmiller\"},{\"authorId\":\"1397979864\",\"name\":\"Andreas K. Fidjeland\"},{\"authorId\":\"2273072\",\"name\":\"Georg Ostrovski\"},{\"authorId\":\"145386761\",\"name\":\"S. Petersen\"},{\"authorId\":\"48878752\",\"name\":\"C. Beattie\"},{\"authorId\":\"49813280\",\"name\":\"A. Sadik\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"153907173\",\"name\":\"H. King\"},{\"authorId\":\"2106164\",\"name\":\"D. Kumaran\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"},{\"authorId\":\"34313265\",\"name\":\"S. Legg\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature14236\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"title\":\"Human-level control through deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/e0e9a94c4a6ba219e768b4e59f72c18f0a22e23d\",\"venue\":\"Nature\",\"year\":2015},{\"arxivId\":\"1606.04870\",\"authors\":[{\"authorId\":\"31801501\",\"name\":\"A. Kannan\"},{\"authorId\":\"2006889\",\"name\":\"Karol Kurach\"},{\"authorId\":\"35014893\",\"name\":\"Sujith Ravi\"},{\"authorId\":\"50034629\",\"name\":\"T. Kaufmann\"},{\"authorId\":\"49365095\",\"name\":\"A. Tomkins\"},{\"authorId\":\"2864102\",\"name\":\"B. Miklos\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"47322330\",\"name\":\"L. Luk\\u00e1cs\"},{\"authorId\":\"47175053\",\"name\":\"Marina Ganea\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"2525389\",\"name\":\"Vivek Ramavajjala\"}],\"doi\":\"10.1145/2939672.2939801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9506c39d560caabb3047f66e7ff7f2a0c0be58\",\"title\":\"Smart Reply: Automated Response Suggestion for Email\",\"url\":\"https://www.semanticscholar.org/paper/ab9506c39d560caabb3047f66e7ff7f2a0c0be58\",\"venue\":\"KDD\",\"year\":2016},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1708.05122\",\"authors\":[{\"authorId\":\"40424000\",\"name\":\"Prithvijit Chattopadhyay\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60f432331abc0976cf236c738844f9427277b0de\",\"title\":\"Evaluating Visual Conversational Agents via Cooperative Human-AI Games\",\"url\":\"https://www.semanticscholar.org/paper/60f432331abc0976cf236c738844f9427277b0de\",\"venue\":\"HCOMP\",\"year\":2017},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.149\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Das\"},{\"authorId\":null,\"name\":\"H. Agrawal\"},{\"authorId\":null,\"name\":\"C. L. Zitnick\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and D\",\"url\":\"\",\"venue\":\"Batra. Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions? In EMNLP\",\"year\":2016},{\"arxivId\":\"1603.06180\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1007/978-3-319-46448-0_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b133e361e2f8af22b823d25060b2e7c47f690985\",\"title\":\"Segmentation from Natural Language Expressions\",\"url\":\"https://www.semanticscholar.org/paper/b133e361e2f8af22b823d25060b2e7c47f690985\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1507.04808\",\"authors\":[{\"authorId\":\"35224828\",\"name\":\"I. Serban\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17f5c7411eeeeedf25b0db99a9130aa353aee4ba\",\"title\":\"Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models\",\"url\":\"https://www.semanticscholar.org/paper/17f5c7411eeeeedf25b0db99a9130aa353aee4ba\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3049377\",\"name\":\"Tim Paek\"}],\"doi\":\"10.3115/1118078.1118092\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15035f4b8137b358b73190a71542369170768aa2\",\"title\":\"Empirical Methods for Evaluating Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/15035f4b8137b358b73190a71542369170768aa2\",\"venue\":\"SIGDIAL Workshop\",\"year\":2001},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"R. Lowe\"},{\"authorId\":null,\"name\":\"I. V. Serban\"},{\"authorId\":null,\"name\":\"M. Noseworthy\"},{\"authorId\":null,\"name\":\"L. Charlin\"},{\"authorId\":null,\"name\":\"J. Pineau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common Objects in Context\",\"url\":\"\",\"venue\":\"In ECCV\",\"year\":null},{\"arxivId\":\"1511.05099\",\"authors\":[{\"authorId\":\"40409467\",\"name\":\"P. Zhang\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2016.542\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5fa973b8d284145bf0ced9acf2913a74674260f6\",\"title\":\"Yin and Yang: Balancing and Answering Binary Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/5fa973b8d284145bf0ced9acf2913a74674260f6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Antol\"},{\"authorId\":null,\"name\":\"M. Mitchell\"},{\"authorId\":null,\"name\":\"D. Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Yin and Yang : Balancing and Answering Binary Visual Questions Visual 7 W : Grounded Question Answering in Images\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S. Wu\"},{\"authorId\":null,\"name\":\"H. Pique\"},{\"authorId\":null,\"name\":\"J. Wieland\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Using Artificial Intelligence to Help Blind People \\u2018See\\u2019 Facebook\",\"url\":\"\",\"venue\":\"http://newsroom.fb.com/news/2016/04/using-artificialintelligence-to-help-blind-people-see-facebook/\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1701.08251\",\"authors\":[{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"3125776\",\"name\":\"Chris Brockett\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"3130583\",\"name\":\"Georgios P. Spithourakis\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c880fca26169023a900c0f7d65d9b85abc5240a0\",\"title\":\"Image-Grounded Conversations: Multimodal Context for Natural Question and Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/c880fca26169023a900c0f7d65d9b85abc5240a0\",\"venue\":\"IJCNLP\",\"year\":2017},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"W Liu\"},{\"authorId\":null,\"name\":\"D Anguelov\"},{\"authorId\":null,\"name\":\"D Erhan\"},{\"authorId\":null,\"name\":\"C Szegedy\"},{\"authorId\":null,\"name\":\"S Reed\"},{\"authorId\":null,\"name\":\"C.-Y Fu\"},{\"authorId\":null,\"name\":\"A C Berg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"SSD: Single Shot MultiBox Detector. In ECCV\",\"url\":\"\",\"venue\":\"SSD: Single Shot MultiBox Detector. In ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Kannan\"},{\"authorId\":null,\"name\":\"K Kurach\"},{\"authorId\":null,\"name\":\"S Ravi\"},{\"authorId\":null,\"name\":\"T Kaufmann\"},{\"authorId\":null,\"name\":\"A Tomkins\"},{\"authorId\":null,\"name\":\"B Miklos\"},{\"authorId\":null,\"name\":\"G Corrado\"},{\"authorId\":null,\"name\":\"L Luk\\u00e1cs\"},{\"authorId\":null,\"name\":\"M Ganea\"},{\"authorId\":null,\"name\":\"P Young\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Automated Response Suggestion for Email\",\"url\":\"\",\"venue\":\"KDD\",\"year\":2016},{\"arxivId\":\"1501.02530\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2015.7298940\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"title\":\"A dataset for Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/a5ea0da7b93452bec54b5034706f2255bfb5a8f3\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Das\"},{\"authorId\":null,\"name\":\"H. Agrawal\"},{\"authorId\":null,\"name\":\"C. L. Zitnick\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and D\",\"url\":\"\",\"venue\":\"Batra. Human Attention in Visual Question Answering: Do Humans and Deep Networks Look at the Same Regions? In EMNLP\",\"year\":2016},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1605.07683\",\"authors\":[{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f81be44000814e7bcb12ae04b4e2d9c01b6515b3\",\"title\":\"Learning End-to-End Goal-Oriented Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f81be44000814e7bcb12ae04b4e2d9c01b6515b3\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Microsoft\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Bing Spell Check API. https://www. microsoft.com/cognitive-services/en-us/ bing-spell-check-api/documentation\",\"url\":\"\",\"venue\":\"Bing Spell Check API. https://www. microsoft.com/cognitive-services/en-us/ bing-spell-check-api/documentation\",\"year\":null},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.06622\",\"authors\":[{\"authorId\":\"20686092\",\"name\":\"Arijit Ray\"},{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"143977265\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1090\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb859d4184476bd80d5f2090b3401c702f66135\",\"title\":\"Question Relevance in VQA: Identifying Non-Visual And False-Premise Questions\",\"url\":\"https://www.semanticscholar.org/paper/0eb859d4184476bd80d5f2090b3401c702f66135\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1106.3077\",\"authors\":[{\"authorId\":\"1388368997\",\"name\":\"Cristian Danescu-Niculescu-Mizil\"},{\"authorId\":\"145810617\",\"name\":\"Lillian Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea45438193cd724445d08cf3a1fa9137ffed54f6\",\"title\":\"Chameleons in Imagined Conversations: A New Approach to Understanding Coordination of Linguistic Style in Dialogs\",\"url\":\"https://www.semanticscholar.org/paper/ea45438193cd724445d08cf3a1fa9137ffed54f6\",\"venue\":\"CMCL@ACL\",\"year\":2011},{\"arxivId\":\"1604.02125\",\"authors\":[{\"authorId\":\"50005563\",\"name\":\"G. Christie\"},{\"authorId\":\"48222562\",\"name\":\"A. Laddha\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"98391857\",\"name\":\"K. Kochersberger\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eb2c900814707ae962184ad4173e754247a80a\",\"title\":\"Resolving Language and Vision Ambiguities Together: Joint Segmentation & Prepositional Attachment Resolution in Captioned Scenes\",\"url\":\"https://www.semanticscholar.org/paper/26eb2c900814707ae962184ad4173e754247a80a\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1608.08716\",\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1609/aimag.v37i1.2647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"title\":\"Measuring Machine Intelligence Through Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"venue\":\"AI Mag.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144332826\",\"name\":\"Chen Kong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2014.455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"title\":\"What Are You Talking About? Text-to-Image Coreference\",\"url\":\"https://www.semanticscholar.org/paper/13549b4e6fffbb7932b7a83a8eb6be27e6a60eca\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2449382\",\"name\":\"T. Hubert\"},{\"authorId\":\"144522726\",\"name\":\"L. Baker\"},{\"authorId\":\"40227832\",\"name\":\"Matthew Lai\"},{\"authorId\":\"34848283\",\"name\":\"A. Bolton\"},{\"authorId\":\"1519062204\",\"name\":\"Yutian Chen\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"88791868\",\"name\":\"F. Hui\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature24270\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c27db32efa8137cbf654902f8f728f338e55cd1c\",\"title\":\"Mastering the game of Go without human knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c27db32efa8137cbf654902f8f728f338e55cd1c\",\"venue\":\"Nature\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S Wu\"},{\"authorId\":null,\"name\":\"H Pique\"},{\"authorId\":null,\"name\":\"J Wieland\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Using Artificial Intelligence to Help Blind People 'See' Facebook. http://newsroom.fb.com/news/2016/04/using-artificial- intelligence-to-help-blind-people-see-facebook\",\"url\":\"\",\"venue\":\"Using Artificial Intelligence to Help Blind People 'See' Facebook. http://newsroom.fb.com/news/2016/04/using-artificial- intelligence-to-help-blind-people-see-facebook\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Lu\"},{\"authorId\":null,\"name\":\"X Lin\"},{\"authorId\":null,\"name\":\"D Batra\"},{\"authorId\":null,\"name\":\"D Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deeper LSTM and Normalized CNN Visual Question Answering model. https://github.com/VT-vision-lab/ VQA_LSTM_CNN\",\"url\":\"\",\"venue\":\"Deeper LSTM and Normalized CNN Visual Question Answering model. https://github.com/VT-vision-lab/ VQA_LSTM_CNN\",\"year\":2015},{\"arxivId\":\"1502.05698\",\"authors\":[{\"authorId\":\"145183709\",\"name\":\"J. Weston\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":null,\"name\":\"Tomas Mikolov\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"title\":\"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\"url\":\"https://www.semanticscholar.org/paper/abb33d75dc297993fcc3fb75e0f4498f413eb4f6\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.18653/v1/D16-1092\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/00158a3a5f00bce40d9e0711d78cd9a6b099c21b\",\"venue\":\"EMNLP 2016\",\"year\":2016},{\"arxivId\":\"1512.02325\",\"authors\":[{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"2667317\",\"name\":\"Cheng-Yang Fu\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1007/978-3-319-46448-0_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"title\":\"SSD: Single Shot MultiBox Detector\",\"url\":\"https://www.semanticscholar.org/paper/4d7a9197433acbfb24ef0e9d0f33ed1699e4a5b0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657391174\",\"name\":\"G.V.T.V. Weerasooriya\"},{\"authorId\":\"1657391179\",\"name\":\"D. N. Jayatissa\"},{\"authorId\":\"1657391068\",\"name\":\"M. Rambanda\"}],\"doi\":\"10.1515/9783111576855-012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f61efefa2a671529c4e6da4cb976d9437332f52e\",\"title\":\"G\",\"url\":\"https://www.semanticscholar.org/paper/f61efefa2a671529c4e6da4cb976d9437332f52e\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1603.06807\",\"authors\":[{\"authorId\":\"48190457\",\"name\":\"I. Serban\"},{\"authorId\":\"1405061488\",\"name\":\"Alberto Garc\\u00eda-Dur\\u00e1n\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3103594\",\"name\":\"Sungjin Ahn\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.18653/v1/P16-1056\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7eeffce7df899dd9ca35c541350ee6b690ec629\",\"title\":\"Generating Factoid Questions With Recurrent Neural Networks: The 30M Factoid Question-Answer Corpus\",\"url\":\"https://www.semanticscholar.org/paper/d7eeffce7df899dd9ca35c541350ee6b690ec629\",\"venue\":\"ACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87836796\",\"name\":\"S. Moss\"}],\"doi\":\"10.1080/20519842.2017.1271602\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e76fc42fa34104156d9d118b49d7e201da917a1f\",\"title\":\"Listen\",\"url\":\"https://www.semanticscholar.org/paper/e76fc42fa34104156d9d118b49d7e201da917a1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Q.V.L. Ilya Sutskever\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Oriol Vinyals\",\"url\":\"\",\"venue\":\"Sequence to Sequence Learning with Neural Networks. In NIPS\",\"year\":2014},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Maire\"},{\"authorId\":null,\"name\":\"S. Belongie\"},{\"authorId\":null,\"name\":\"J. Hays\"},{\"authorId\":null,\"name\":\"P. Perona\"},{\"authorId\":null,\"name\":\"D. Ra-manan\"},{\"authorId\":null,\"name\":\"P. Doll\\u00c3 \\u00a1 r\"},{\"authorId\":null,\"name\":\"C. L. Zitnick\"},{\"authorId\":null,\"name\":\"Microsoft COCO\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common Objects in Context\",\"url\":\"\",\"venue\":\"\",\"year\":2016},{\"arxivId\":\"1506.03340\",\"authors\":[{\"authorId\":\"2910877\",\"name\":\"K. Hermann\"},{\"authorId\":\"2367821\",\"name\":\"Tom\\u00e1s Kocisk\\u00fd\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"2311318\",\"name\":\"Lasse Espeholt\"},{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d1505c6123c102e53eb19dff312cb25cea840b72\",\"title\":\"Teaching Machines to Read and Comprehend\",\"url\":\"https://www.semanticscholar.org/paper/d1505c6123c102e53eb19dff312cb25cea840b72\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"P. Rajpurkar\"},{\"authorId\":null,\"name\":\"J. Zhang\"},{\"authorId\":null,\"name\":\"K. Lopyrev\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and P\",\"url\":\"\",\"venue\":\"Liang. SQuAD:  100,000+ Questions for Machine Comprehension of Text. In EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Mnih\"},{\"authorId\":null,\"name\":\"K. Kavukcuoglu\"},{\"authorId\":null,\"name\":\"D. Silver\"},{\"authorId\":null,\"name\":\"A. A. Rusu\"},{\"authorId\":null,\"name\":\"J. Veness\"},{\"authorId\":null,\"name\":\"M. G. Bellemare\"},{\"authorId\":null,\"name\":\"A. Graves\"},{\"authorId\":null,\"name\":\"M. Riedmiller\"},{\"authorId\":null,\"name\":\"A. K. Fidjeland\"},{\"authorId\":null,\"name\":\"G. Ostrovski\"},{\"authorId\":null,\"name\":\"S. Petersen\"},{\"authorId\":null,\"name\":\"C. Beattie\"},{\"authorId\":null,\"name\":\"A. Sadik\"},{\"authorId\":null,\"name\":\"I. Antonoglou\"},{\"authorId\":null,\"name\":\"H. King\"},{\"authorId\":null,\"name\":\"D. Kumaran\"},{\"authorId\":null,\"name\":\"D. Wierstra\"},{\"authorId\":null,\"name\":\"S. Legg\"},{\"authorId\":null,\"name\":\"D. Hassabis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Human-level control through deep rein- 334  forcement learning\",\"url\":\"\",\"venue\":\"Nature, 518(7540):529\\u2013533,\",\"year\":2015},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1308.6628\",\"authors\":[{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"143764552\",\"name\":\"M. Meng\"},{\"authorId\":\"2649483\",\"name\":\"M. Lee\"},{\"authorId\":\"2194804\",\"name\":\"T. E. Choe\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/MMUL.2014.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2935d8071583e46c5a895730c65d2bd213757c07\",\"title\":\"Joint Video and Text Parsing for Understanding Events and Answering Queries\",\"url\":\"https://www.semanticscholar.org/paper/2935d8071583e46c5a895730c65d2bd213757c07\",\"venue\":\"IEEE MultiMedia\",\"year\":2014},{\"arxivId\":\"1606.01541\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"145768639\",\"name\":\"Will Monroe\"},{\"authorId\":\"1863425\",\"name\":\"Alan Ritter\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/D16-1127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1298dae5751fb06184f6b067d1503bde8037bdb7\",\"title\":\"Deep Reinforcement Learning for Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/1298dae5751fb06184f6b067d1503bde8037bdb7\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1604.03968\",\"authors\":[{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3139/9783446448100.007\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"927987a48c2a519bbc097d8b6c925b64a85b7d8e\",\"title\":\"Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/927987a48c2a519bbc097d8b6c925b64a85b7d8e\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":\"1606.08390\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-319-46484-8_44\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"title\":\"Revisiting Visual Question Answering Baselines\",\"url\":\"https://www.semanticscholar.org/paper/3c1bbd2672c11a796f1e6e6aa787257498ec8bec\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1610.01119\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"143921503\",\"name\":\"S. Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2675339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c5ba685c319915711677743b31250c622fd47c4\",\"title\":\"Knowledge Guided Disambiguation for Large-Scale Scene Classification With Multi-Resolution CNNs\",\"url\":\"https://www.semanticscholar.org/paper/6c5ba685c319915711677743b31250c622fd47c4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1611.08481\",\"authors\":[{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"144631588\",\"name\":\"A. Chandar\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/CVPR.2017.475\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"bed7834ae7d371171977a590872f60d137c2f951\",\"title\":\"GuessWhat?! Visual Object Discovery through Multi-modal Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/bed7834ae7d371171977a590872f60d137c2f951\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Ramanathan\"},{\"authorId\":null,\"name\":\"A. Joulin\"},{\"authorId\":null,\"name\":\"P. Liang\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Linking people with \\\"their\\\" names using coreference resolution\",\"url\":\"\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1506.00278\",\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"title\":\"Visual Madlibs: Fill in the blank Image Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a58a582b95a07932cb248f1b739e4ad739ead6b9\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1605.06069\",\"authors\":[{\"authorId\":\"35224828\",\"name\":\"I. Serban\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"609e0f0e60ddfe83fdc71bf5397205323888289d\",\"title\":\"A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/609e0f0e60ddfe83fdc71bf5397205323888289d\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"144360239\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"2925245\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1866029.1866080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/8a960ea40fe7b32a1ee702a84f64ec1de5c3e7fe\",\"venue\":\"UIST '10\",\"year\":2010},{\"arxivId\":\"1506.05869\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85315b64a4c73cb86f156ef5b0a085d6ebc8a65d\",\"title\":\"A Neural Conversational Model\",\"url\":\"https://www.semanticscholar.org/paper/85315b64a4c73cb86f156ef5b0a085d6ebc8a65d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1603.08023\",\"authors\":[{\"authorId\":\"50557647\",\"name\":\"C. Liu\"},{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"35224828\",\"name\":\"I. Serban\"},{\"authorId\":\"38107789\",\"name\":\"Michael Noseworthy\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"}],\"doi\":\"10.18653/v1/D16-1230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"129cbad01be98ee88a930e31898cb76be79c41c1\",\"title\":\"How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation\",\"url\":\"https://www.semanticscholar.org/paper/129cbad01be98ee88a930e31898cb76be79c41c1\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1606.07493\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"34719258\",\"name\":\"Arjun Chandrasekaran\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D16-1091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cc0d9c1f690addd2c82e60f2a460e3c557ff242\",\"title\":\"Sort Story: Sorting Jumbled Images and Captions into Stories\",\"url\":\"https://www.semanticscholar.org/paper/3cc0d9c1f690addd2c82e60f2a460e3c557ff242\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"V. Mnih\"},{\"authorId\":null,\"name\":\"K. Kavukcuoglu\"},{\"authorId\":null,\"name\":\"D. Silver\"},{\"authorId\":null,\"name\":\"A. A. Rusu\"},{\"authorId\":null,\"name\":\"J. Veness\"},{\"authorId\":null,\"name\":\"M. G. Bellemare\"},{\"authorId\":null,\"name\":\"A. Graves\"},{\"authorId\":null,\"name\":\"M. Riedmiller\"},{\"authorId\":null,\"name\":\"A. K. Fidjeland\"},{\"authorId\":null,\"name\":\"G. Ostrovski\"},{\"authorId\":null,\"name\":\"S. Petersen\"},{\"authorId\":null,\"name\":\"C. Beattie\"},{\"authorId\":null,\"name\":\"A. Sadik\"},{\"authorId\":null,\"name\":\"I. Antonoglou\"},{\"authorId\":null,\"name\":\"H. King\"},{\"authorId\":null,\"name\":\"D. Kumaran\"},{\"authorId\":null,\"name\":\"D. Wierstra\"},{\"authorId\":null,\"name\":\"S. Legg\"},{\"authorId\":null,\"name\":\"D. Hassabis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Human-level control through deep rein- 1088  forcement learning\",\"url\":\"\",\"venue\":\"Nature, 518(7540):529\\u2013533,\",\"year\":2015},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Lu\"},{\"authorId\":null,\"name\":\"X. Lin\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Deeper LSTM and Normalized CNN Visual Question Answering model\",\"url\":\"\",\"venue\":\"https://github.com/VT-vision-lab/ VQA_LSTM_CNN\",\"year\":2015},{\"arxivId\":\"1606.05250\",\"authors\":[{\"authorId\":\"2706258\",\"name\":\"Pranav Rajpurkar\"},{\"authorId\":null,\"name\":\"Jian Zhang\"},{\"authorId\":\"2787620\",\"name\":\"Konstantin Lopyrev\"},{\"authorId\":\"145419642\",\"name\":\"Percy Liang\"}],\"doi\":\"10.18653/v1/D16-1264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05dd7254b632376973f3a1b4d39485da17814df5\",\"title\":\"SQuAD: 100, 000+ Questions for Machine Comprehension of Text\",\"url\":\"https://www.semanticscholar.org/paper/05dd7254b632376973f3a1b4d39485da17814df5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824029\",\"name\":\"D. Silver\"},{\"authorId\":\"1885349\",\"name\":\"Aja Huang\"},{\"authorId\":\"2772217\",\"name\":\"Chris J. Maddison\"},{\"authorId\":\"35099444\",\"name\":\"A. Guez\"},{\"authorId\":\"2175946\",\"name\":\"L. Sifre\"},{\"authorId\":\"47568983\",\"name\":\"George van den Driessche\"},{\"authorId\":\"4337102\",\"name\":\"Julian Schrittwieser\"},{\"authorId\":\"2460849\",\"name\":\"Ioannis Antonoglou\"},{\"authorId\":\"2749418\",\"name\":\"Vedavyas Panneershelvam\"},{\"authorId\":\"1975889\",\"name\":\"Marc Lanctot\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"2401609\",\"name\":\"Dominik Grewe\"},{\"authorId\":\"4111313\",\"name\":\"John Nham\"},{\"authorId\":\"2583391\",\"name\":\"Nal Kalchbrenner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"2542999\",\"name\":\"T. Lillicrap\"},{\"authorId\":\"40662181\",\"name\":\"M. Leach\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"48987704\",\"name\":\"Demis Hassabis\"}],\"doi\":\"10.1038/nature16961\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"846aedd869a00c09b40f1f1f35673cb22bc87490\",\"title\":\"Mastering the game of Go with deep neural networks and tree search\",\"url\":\"https://www.semanticscholar.org/paper/846aedd869a00c09b40f1f1f35673cb22bc87490\",\"venue\":\"Nature\",\"year\":2016},{\"arxivId\":\"1802.03803\",\"authors\":[{\"authorId\":\"3469119\",\"name\":\"Daniela Massiceti\"},{\"authorId\":\"145809603\",\"name\":\"N. Siddharth\"},{\"authorId\":\"144679302\",\"name\":\"P. Dokania\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"}],\"doi\":\"10.1109/CVPR.2018.00638\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7aa181fd7cadc7568d4fd87d2a1b12994ea1828\",\"title\":\"FLIPDIAL: A Generative Model for Two-Way Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/a7aa181fd7cadc7568d4fd87d2a1b12994ea1828\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1703.05423\",\"authors\":[{\"authorId\":\"3367628\",\"name\":\"Florian Strub\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"143716734\",\"name\":\"J. Mary\"},{\"authorId\":\"1808897\",\"name\":\"B. Piot\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"1721354\",\"name\":\"Olivier Pietquin\"}],\"doi\":\"10.24963/ijcai.2017/385\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e2cf792165eed4c0bfb25548f5dd63f43dca67a4\",\"title\":\"End-to-end optimization of goal-driven and visually grounded dialogue systems\",\"url\":\"https://www.semanticscholar.org/paper/e2cf792165eed4c0bfb25548f5dd63f43dca67a4\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1703.06585\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/ICCV.2017.321\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c18df1edc0a45891806d44896a8f666944e93d01\",\"title\":\"Learning Cooperative Visual Dialog Agents with Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/c18df1edc0a45891806d44896a8f666944e93d01\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.06931\",\"authors\":[{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"3071104\",\"name\":\"A. Gane\"},{\"authorId\":\"46447747\",\"name\":\"X. Zhang\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"143622869\",\"name\":\"Alexander H. Miller\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be3a65ef15f79ebb8296e6a0e8d1a9cb5c0f3638\",\"title\":\"Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems\",\"url\":\"https://www.semanticscholar.org/paper/be3a65ef15f79ebb8296e6a0e8d1a9cb5c0f3638\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782798\",\"name\":\"Oliver Lemon\"},{\"authorId\":\"3194430\",\"name\":\"Kallirroi Georgila\"},{\"authorId\":\"144915758\",\"name\":\"James Henderson\"},{\"authorId\":\"2568798\",\"name\":\"Matthew N. Stuttle\"}],\"doi\":\"10.3115/1608974.1608986\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74fb349706be2bc5cf95ef7469620dd2db4d5cc\",\"title\":\"An ISU Dialogue System Exhibiting Reinforcement Learning of Dialogue Policies: Generic Slot-Filling in the TALK In-car System\",\"url\":\"https://www.semanticscholar.org/paper/a74fb349706be2bc5cf95ef7469620dd2db4d5cc\",\"venue\":\"EACL\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4746730\",\"name\":\"J. Lackie\"}],\"doi\":\"10.1016/b978-0-12-384931-1.00016-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"title\":\"P\",\"url\":\"https://www.semanticscholar.org/paper/db750f063bc099e6d1d2d0a92a34d7c213a893e3\",\"venue\":\"The Dictionary of Cell & Molecular Biology\",\"year\":2013},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1506.02075\",\"authors\":[{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"1746841\",\"name\":\"Nicolas Usunier\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e565308c8081e807709cb4a917443b737e6cdb4\",\"title\":\"Large-scale Simple Question Answering with Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/6e565308c8081e807709cb4a917443b737e6cdb4\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.03745\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-319-46448-0_49\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14c2321851fb5ae580a19726dd2753a525d6ad76\",\"title\":\"Grounding of Textual Phrases in Images by Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/14c2321851fb5ae580a19726dd2753a525d6ad76\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1506.08909\",\"authors\":[{\"authorId\":\"2054294\",\"name\":\"Ryan Lowe\"},{\"authorId\":\"3236233\",\"name\":\"Nissan Pow\"},{\"authorId\":\"35224828\",\"name\":\"I. Serban\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"}],\"doi\":\"10.18653/v1/w15-4640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"916441619914101258c71669b5ccc36424b54a6c\",\"title\":\"The Ubuntu Dialogue Corpus: A Large Dataset for Research in Unstructured Multi-Turn Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/916441619914101258c71669b5ccc36424b54a6c\",\"venue\":\"SIGDIAL Conference\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1744846\",\"name\":\"Jeffrey P. Bigham\"},{\"authorId\":\"1712587\",\"name\":\"C. Jayant\"},{\"authorId\":\"1737220\",\"name\":\"H. Ji\"},{\"authorId\":\"48155668\",\"name\":\"G. Little\"},{\"authorId\":\"153472666\",\"name\":\"A. Miller\"},{\"authorId\":\"34205614\",\"name\":\"R. Miller\"},{\"authorId\":\"1715819\",\"name\":\"Aubrey Tatarowicz\"},{\"authorId\":\"37929982\",\"name\":\"B. White\"},{\"authorId\":\"144289340\",\"name\":\"Samuel White\"},{\"authorId\":\"1704158\",\"name\":\"T. Yeh\"}],\"doi\":\"10.1145/1805986.1806020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c668d1da866617ccfeee910d13eb14fa340bea\",\"title\":\"VizWiz: nearly real-time answers to visual questions\",\"url\":\"https://www.semanticscholar.org/paper/e0c668d1da866617ccfeee910d13eb14fa340bea\",\"venue\":\"W4A\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Gao\"},{\"authorId\":null,\"name\":\"J. Mao\"},{\"authorId\":null,\"name\":\"J. Zhou\"},{\"authorId\":null,\"name\":\"Z. Huang\"},{\"authorId\":null,\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"20 Figure 18: Selected examples of attention over history facts from our Memory Network encoder\",\"url\":\"\",\"venue\":\"The intensity of color in each row indicates the strength of attention placed on that round by the model. Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question Answering. In NIPS\",\"year\":2015},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Jabri\"},{\"authorId\":null,\"name\":\"A. Joulin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"van der Maaten. Revisiting visual question answering baselines. In ECCV\",\"year\":2016},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1506.04089\",\"authors\":[{\"authorId\":\"33344744\",\"name\":\"Hongyuan Mei\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1733702\",\"name\":\"Matthew R. Walter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80f15048f9774191c3ae2ab8950b6d49f2d05295\",\"title\":\"Listen, Attend, and Walk: Neural Mapping of Navigational Instructions to Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/80f15048f9774191c3ae2ab8950b6d49f2d05295\",\"venue\":\"AAAI\",\"year\":2016},{\"arxivId\":\"1601.01705\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.18653/v1/N16-1181\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"title\":\"Learning to Compose Neural Networks for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/75ddc7ee15be14013a3462c01b38b0548486fbcb\",\"venue\":\"HLT-NAACL\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C.-W. Liu\"},{\"authorId\":null,\"name\":\"R. Lowe\"},{\"authorId\":null,\"name\":\"I. V. Serban\"},{\"authorId\":null,\"name\":\"M. Noseworthy\"},{\"authorId\":null,\"name\":\"L. Charlin\"},{\"authorId\":null,\"name\":\"J. Pineau\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Common Objects in Context\",\"url\":\"\",\"venue\":\"In ECCV\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1707642\",\"name\":\"D. Geman\"},{\"authorId\":\"3194361\",\"name\":\"S. Geman\"},{\"authorId\":\"9588317\",\"name\":\"Neil Hallonquist\"},{\"authorId\":\"1721284\",\"name\":\"L. Younes\"}],\"doi\":\"10.1073/pnas.1422953112\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"050da5d159fb0dd96143948e1cffeb3dec814673\",\"title\":\"Visual Turing test for computer vision systems\",\"url\":\"https://www.semanticscholar.org/paper/050da5d159fb0dd96143948e1cffeb3dec814673\",\"venue\":\"Proceedings of the National Academy of Sciences\",\"year\":2015}],\"title\":\"Visual Dialog\",\"topics\":[{\"topic\":\"dialog\",\"topicId\":\"14876\",\"url\":\"https://www.semanticscholar.org/topic/14876\"},{\"topic\":\"CVPR\",\"topicId\":\"56892\",\"url\":\"https://www.semanticscholar.org/topic/56892\"},{\"topic\":\"ICCV\",\"topicId\":\"785155\",\"url\":\"https://www.semanticscholar.org/topic/785155\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"},{\"topic\":\"Reinforcement learning\",\"topicId\":\"2557\",\"url\":\"https://www.semanticscholar.org/topic/2557\"},{\"topic\":\"Encoder Device Component\",\"topicId\":\"55437\",\"url\":\"https://www.semanticscholar.org/topic/55437\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Human reliability\",\"topicId\":\"193661\",\"url\":\"https://www.semanticscholar.org/topic/193661\"},{\"topic\":\"Downstream (software development)\",\"topicId\":\"10055\",\"url\":\"https://www.semanticscholar.org/topic/10055\"},{\"topic\":\"Visual Basic[.NET]\",\"topicId\":\"251004\",\"url\":\"https://www.semanticscholar.org/topic/251004\"},{\"topic\":\"Decoder Device Component\",\"topicId\":\"197115\",\"url\":\"https://www.semanticscholar.org/topic/197115\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Curation\",\"topicId\":\"852593\",\"url\":\"https://www.semanticscholar.org/topic/852593\"},{\"topic\":\"Silo (dataset)\",\"topicId\":\"130506\",\"url\":\"https://www.semanticscholar.org/topic/130506\"},{\"topic\":\"Optic Nerve Glioma, Childhood\",\"topicId\":\"14069\",\"url\":\"https://www.semanticscholar.org/topic/14069\"},{\"topic\":\"Inference\",\"topicId\":\"744\",\"url\":\"https://www.semanticscholar.org/topic/744\"},{\"topic\":\"Artificial Intelligence\",\"topicId\":\"18264\",\"url\":\"https://www.semanticscholar.org/topic/18264\"},{\"topic\":\"Aortic Valve Insufficiency\",\"topicId\":\"27221\",\"url\":\"https://www.semanticscholar.org/topic/27221\"}],\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"