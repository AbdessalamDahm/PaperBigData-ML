"{\"abstract\":\"Vision and language understanding has emerged as a subject undergoing intense study in Artificial Intelligence. Among many tasks in this line of research, visual question answering (VQA) has been one of the most successful ones, where the goal is to learn a model that understands visual content at region-level details and finds their associations with pairs of questions and answers in the natural language form. Despite the rapid progress in the past few years, most existing work in VQA have focused primarily on images. In this paper, we focus on extending VQA to the video domain and contribute to the literature in three important ways. First, we propose three new tasks designed specifically for video VQA, which require spatio-temporal reasoning from videos to answer questions correctly. Next, we introduce a new large-scale dataset for video VQA named TGIF-QA that extends existing VQA work with our new tasks. Finally, we propose a dual-LSTM based approach with both spatial and temporal attention, and show its effectiveness over conventional VQA techniques through empirical evaluations.\",\"arxivId\":\"1704.04497\",\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\",\"url\":\"https://www.semanticscholar.org/author/2338742\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\",\"url\":\"https://www.semanticscholar.org/author/2317183\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\",\"url\":\"https://www.semanticscholar.org/author/7877122\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\",\"url\":\"https://www.semanticscholar.org/author/49170458\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\",\"url\":\"https://www.semanticscholar.org/author/1743920\"}],\"citationVelocity\":43,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3103159\",\"name\":\"M. I. H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"}],\"doi\":\"10.1109/ICIP.2018.8451103\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62504a1faaff417b275c6c68835ed024136a9eef\",\"title\":\"Hierarchical Relational Attention for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62504a1faaff417b275c6c68835ed024136a9eef\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143957784\",\"name\":\"M. Iqbal\"},{\"authorId\":\"119339025\",\"name\":\"H. Chowdhury\"},{\"authorId\":\"145025159\",\"name\":\"K. Nguyen\"},{\"authorId\":\"3140440\",\"name\":\"C. Fookes\"},{\"authorId\":\"1729760\",\"name\":\"S. Sridharan\"}],\"doi\":\"10.36227/techrxiv.12731945\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08dc9a1be26e6f87d26b69286bbc82686a4f5c90\",\"title\":\"VIDEO QUESTION ANSWERING FOR SURVEILLANCE\",\"url\":\"https://www.semanticscholar.org/paper/08dc9a1be26e6f87d26b69286bbc82686a4f5c90\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2511637\",\"name\":\"Hongyang Xue\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2017.2746267\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"title\":\"Unifying the Video and Question Attentions for Open-Ended Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1b94c49c119c7490d2df6a2dd093e5ddd8bfba14\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123024384\",\"name\":\"Liu Tian-liang\"},{\"authorId\":\"50708017\",\"name\":\"Wan Junwei\"},{\"authorId\":\"71916637\",\"name\":\"Dai Xiu-bin\"},{\"authorId\":\"1734409\",\"name\":\"Feng Liu\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TMM.2019.2936805\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59737509cf1c8d93a33ee7558f6492b7934b236f\",\"title\":\"Sentiment Recognition for Short Annotated GIFs Using Visual-Textual Fusion\",\"url\":\"https://www.semanticscholar.org/paper/59737509cf1c8d93a33ee7558f6492b7934b236f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1804.09412\",\"authors\":[{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"title\":\"Movie Question Answering: Remembering the Textual Cues for Layered Visual Contents\",\"url\":\"https://www.semanticscholar.org/paper/e5c7798293f8325bbe8d92b185c99a7c7662e330\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1609/AAAI.V33I01.33016391\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"524879e9a072489110e9578cf2689e50c5531f05\",\"title\":\"Structured Two-Stream Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/524879e9a072489110e9578cf2689e50c5531f05\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1809.07999\",\"authors\":[{\"authorId\":\"2593979\",\"name\":\"Kyung-Min Kim\"},{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":\"10.1007/978-3-030-01267-0_41\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b01ed5c62abdc37c7318c155e12e366238bdc2f5\",\"title\":\"Multimodal Dual Attention Memory for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b01ed5c62abdc37c7318c155e12e366238bdc2f5\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":null,\"name\":\"Mohammad Soleymani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"890935379e6fc3a724d2ef5bb22775bdcfd0888b\",\"title\":\"Supplementary Material for Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/890935379e6fc3a724d2ef5bb22775bdcfd0888b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2008.09849\",\"authors\":[{\"authorId\":\"31743563\",\"name\":\"A. Falcon\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"46887324\",\"name\":\"Giuseppe Serra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"926045fee007662f4365ef7e68ccc94776491899\",\"title\":\"Data augmentation techniques for the Video Question Answering task\",\"url\":\"https://www.semanticscholar.org/paper/926045fee007662f4365ef7e68ccc94776491899\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"}],\"doi\":\"10.1109/ICCVW.2019.00536\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"71f3a2632d924f29ca6eb2e789f8ff6d46250c82\",\"title\":\"EgoVQA - An Egocentric Video Question Answering Benchmark Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71f3a2632d924f29ca6eb2e789f8ff6d46250c82\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1910.10706\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"}],\"doi\":\"10.1609/AAAI.V34I07.6713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"title\":\"KnowIT VQA: Answering Knowledge-Based Questions about Videos\",\"url\":\"https://www.semanticscholar.org/paper/12f11d56a83516bfdd1f32f60e3695ab92a0f819\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.07231\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00877\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"title\":\"ActBERT: Learning Global-Local Video-Text Representations\",\"url\":\"https://www.semanticscholar.org/paper/8cda672bd5487ec2c67d5c217dc84ed8fb786640\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1804.04318\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd286954bba554035ea98946afdd02262b9bca45\",\"title\":\"Cross-Modal Retrieval with Implicit Concept Association\",\"url\":\"https://www.semanticscholar.org/paper/cd286954bba554035ea98946afdd02262b9bca45\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.00067\",\"authors\":[{\"authorId\":\"35789996\",\"name\":\"Kenneth Marino\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"}],\"doi\":\"10.1109/CVPR.2019.00331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"title\":\"OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1764470\",\"name\":\"Danh Le Phuoc\"},{\"authorId\":\"1733076\",\"name\":\"Manfred Hauswirth\"}],\"doi\":\"10.1007/978-3-319-63962-8_287-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b99d1a9494e19b36c8b70a3d7b49468d4a0fd80\",\"title\":\"Semantic Stream Processing\",\"url\":\"https://www.semanticscholar.org/paper/4b99d1a9494e19b36c8b70a3d7b49468d4a0fd80\",\"venue\":\"Encyclopedia of Big Data Technologies\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24545031\",\"name\":\"Jiayin Cai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"145280977\",\"name\":\"Cheng Shi\"},{\"authorId\":null,\"name\":\"Lei Li\"},{\"authorId\":\"150347046\",\"name\":\"Yangyang Cheng\"},{\"authorId\":\"1387190008\",\"name\":\"Ying Shan\"}],\"doi\":\"10.24963/ijcai.2020/139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bcf4c354f68d5e85ffcc6d69c1348e69d241857\",\"title\":\"Feature Augmented Memory with Global Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/3bcf4c354f68d5e85ffcc6d69c1348e69d241857\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1904.11574\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.730\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb1b368ca847846774ee41af6da906ab77013313\",\"title\":\"TVQA+: Spatio-Temporal Grounding for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb1b368ca847846774ee41af6da906ab77013313\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1712.06761\",\"authors\":[{\"authorId\":\"2039154\",\"name\":\"Paul Vicol\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"3436589\",\"name\":\"L. Castrej\\u00f3n\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2018.00895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523574aca71d8981b4122cce8d132f22391ef26e\",\"title\":\"MovieGraphs: Towards Understanding Human-Centric Situations from Videos\",\"url\":\"https://www.semanticscholar.org/paper/523574aca71d8981b4122cce8d132f22391ef26e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1809.01337\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.18653/v1/D18-1168\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b1ff82db09672656157874718860bee942483cf\",\"title\":\"Localizing Moments in Video with Temporal Language\",\"url\":\"https://www.semanticscholar.org/paper/0b1ff82db09672656157874718860bee942483cf\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1904.00623\",\"authors\":[{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"7236400\",\"name\":\"S. Choi\"},{\"authorId\":\"70262116\",\"name\":\"Jaeseo Lim\"},{\"authorId\":\"7951400\",\"name\":\"J. Kim\"},{\"authorId\":\"89496405\",\"name\":\"Jeh-Kwang Ryu\"},{\"authorId\":\"39171461\",\"name\":\"B. Bae\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b27b6df500b4fc50092f22727a90111b2010a588\",\"title\":\"Constructing Hierarchical Q&A Datasets for Video Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b27b6df500b4fc50092f22727a90111b2010a588\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2005.03356\",\"authors\":[{\"authorId\":\"117172343\",\"name\":\"Seongho Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"1679974562\",\"name\":\"Ahjeong Seo\"},{\"authorId\":\"1680054988\",\"name\":\"Youwon Jang\"},{\"authorId\":\"153311117\",\"name\":\"Seungchan Lee\"},{\"authorId\":\"1491775096\",\"name\":\"Minsu Lee\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d21241b930b005847cf4350294c61d6c29ccd9f\",\"title\":\"DramaQA: Character-Centered Video Story Understanding with Hierarchical QA\",\"url\":\"https://www.semanticscholar.org/paper/4d21241b930b005847cf4350294c61d6c29ccd9f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1906.04236\",\"authors\":[{\"authorId\":\"41079205\",\"name\":\"Oana Ignat\"},{\"authorId\":\"8003011\",\"name\":\"Laura Burdick\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.18653/v1/P19-1643\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0fe96f493334987589f8ccd55f2d1209df258449\",\"title\":\"Identifying Visible Actions in Lifestyle Vlogs\",\"url\":\"https://www.semanticscholar.org/paper/0fe96f493334987589f8ccd55f2d1209df258449\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"143761093\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"68ea8690a6e55c00bdf6df50af6d14a0ad08914f\",\"title\":\"Input Clips CNN Features Clip Representation How many times eyes ?\",\"url\":\"https://www.semanticscholar.org/paper/68ea8690a6e55c00bdf6df50af6d14a0ad08914f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"title\":\"A Simple Baseline for Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1d660fdc8e7b23b5fa877a735744d1323a196cdb\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1731750\",\"name\":\"Weining Wang\"},{\"authorId\":\"49866972\",\"name\":\"Y. Huang\"},{\"authorId\":\"97846606\",\"name\":\"L. Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107248\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"title\":\"Long video question answering: A Matching-guided Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/44225a35d3c5f6e5a98963a6428c22bfdd4586d4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1805.04668\",\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9a38263bb8db1abdc1aa28dcfc4d82b3f43c592\",\"title\":\"I Have Seen Enough: A Teacher Student Network for Video Classification Using Fewer Frames\",\"url\":\"https://www.semanticscholar.org/paper/b9a38263bb8db1abdc1aa28dcfc4d82b3f43c592\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51305348\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"123034558\",\"name\":\"Z. Xiao\"},{\"authorId\":\"145477645\",\"name\":\"X. Yan\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TIP.2019.2922062\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"title\":\"Long-Form Video Question Answering via Dynamic Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/80c67ece4198e3dd1ef88e6ddb81eb71bee5f3fa\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"121944615\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2018.00008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6868c233c2d0fe01ecf0eda01099f6c7a0f98fb9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.01046\",\"authors\":[{\"authorId\":\"1441128975\",\"name\":\"Anthony Colas\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":\"2462276\",\"name\":\"Franck Dernoncourt\"},{\"authorId\":\"1441127595\",\"name\":\"Siddhesh Gupte\"},{\"authorId\":\"1786275\",\"name\":\"D. Wang\"},{\"authorId\":\"2133420\",\"name\":\"Doo Soon Kim\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1b32cb6be81f67bba12e40a6f5bb9eae9da0214e\",\"title\":\"TutorialVQA: Question Answering Dataset for Tutorial Videos\",\"url\":\"https://www.semanticscholar.org/paper/1b32cb6be81f67bba12e40a6f5bb9eae9da0214e\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"2008.00544\",\"authors\":[{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"2047181\",\"name\":\"Seokhwan Kim\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.24963/ijcai.2020/148\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"fda45368ef87c7ac1da12a7303dedab0e779fd20\",\"title\":\"Video Question Answering on Screencast Tutorials\",\"url\":\"https://www.semanticscholar.org/paper/fda45368ef87c7ac1da12a7303dedab0e779fd20\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47141093\",\"name\":\"Gursimran Singh\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1710980\",\"name\":\"J. Little\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"title\":\"Spatio-temporal Relational Reasoning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/51fadc0803ee53c91eb4fcfb3777720496c9d91f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73312190\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3245182\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/TMM.2019.2935678\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8559c89a4df40ec6250cc8a04d1a5d5f3a84623e\",\"title\":\"Frame Augmented Alternating Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8559c89a4df40ec6250cc8a04d1a5d5f3a84623e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1911.03083\",\"authors\":[{\"authorId\":\"35923416\",\"name\":\"Bhavan Jasani\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCVW.2019.00235\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31c5eb6d5cab2df914f54eab9f2db942193e1be4\",\"title\":\"Are we Asking the Right Questions in MovieQA?\",\"url\":\"https://www.semanticscholar.org/paper/31c5eb6d5cab2df914f54eab9f2db942193e1be4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"2001.06206\",\"authors\":[{\"authorId\":\"9628638\",\"name\":\"Yun-Wei Chu\"},{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e885f1523349be48c884a4663d705487fde05b8a\",\"title\":\"Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/e885f1523349be48c884a4663d705487fde05b8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145295896\",\"name\":\"Y. Shen\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"46948132\",\"name\":\"Zefan Li\"},{\"authorId\":\"2492392\",\"name\":\"N. Zhuang\"}],\"doi\":\"10.1007/978-3-030-01216-8_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"title\":\"Egocentric Activity Prediction via Event Modulated Attention\",\"url\":\"https://www.semanticscholar.org/paper/4bc32b8c34b7d5b08496b9600b15596aa0a0aac1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1709.09345\",\"authors\":[{\"authorId\":\"19255603\",\"name\":\"Seil Na\"},{\"authorId\":\"35505557\",\"name\":\"S. Lee\"},{\"authorId\":\"49476855\",\"name\":\"Jisung Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/ICCV.2017.80\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d66bf8b883b85e72b98b75a87773281d86fed25\",\"title\":\"A Read-Write Memory Network for Movie Story Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6d66bf8b883b85e72b98b75a87773281d86fed25\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2007.03848\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03598364626c419d3a2578b5c22403f0dd246e99\",\"title\":\"Spatio-Temporal Scene Graphs for Video Dialog\",\"url\":\"https://www.semanticscholar.org/paper/03598364626c419d3a2578b5c22403f0dd246e99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.01696\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.18653/v1/D18-1167\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e7e1313061b0d56364bd2c41f017deb954bb05db\",\"title\":\"TVQA: Localized, Compositional Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e7e1313061b0d56364bd2c41f017deb954bb05db\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2005.06409\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"151270642\",\"name\":\"Zineng Tang\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.acl-main.435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"title\":\"Dense-Caption Matching and Frame-Selection Gating for Temporal Localization in VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/9a87c1f04bae4ab507ed0e03bfd10d870d733367\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2003.03186\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"title\":\"Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350971\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"title\":\"Learnable Aggregating Net with Diversity Learning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.04641\",\"authors\":[{\"authorId\":\"1491142121\",\"name\":\"Yuhong Deng\"},{\"authorId\":\"31513628\",\"name\":\"N. Zhang\"},{\"authorId\":\"144393479\",\"name\":\"D. Guo\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"2323566\",\"name\":\"Fu-Chun Sun\"},{\"authorId\":\"152806333\",\"name\":\"Chen Pang\"},{\"authorId\":\"1490867745\",\"name\":\"Jing Pang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88e8f7636a2a8d5d3d0a99708bea332770471eb3\",\"title\":\"MQA: Answering the Question via Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/88e8f7636a2a8d5d3d0a99708bea332770471eb3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9519140\",\"name\":\"Shi-tao Chen\"},{\"authorId\":\"27223428\",\"name\":\"Zhiqiang Jian\"},{\"authorId\":\"49866351\",\"name\":\"Yuhao Huang\"},{\"authorId\":\"9407280\",\"name\":\"Y. Chen\"},{\"authorId\":\"3080012\",\"name\":\"Zhuoli Zhou\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/s11432-018-9850-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e19f42d3b20fd0a43ba9bb3e3740e3be2d074235\",\"title\":\"Autonomous driving: cognitive construction and situation understanding\",\"url\":\"https://www.semanticscholar.org/paper/e19f42d3b20fd0a43ba9bb3e3740e3be2d074235\",\"venue\":\"Science China Information Sciences\",\"year\":2019},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.04402\",\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"152714397\",\"name\":\"M. Soleymani\"}],\"doi\":\"10.1109/CVPR.2019.00208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a39d5919531a56de0e36f6b76142041b5d508213\",\"title\":\"Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.02036\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"48920375\",\"name\":\"T. Pham\"},{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/cvpr42600.2020.01012\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"title\":\"Modality Shifting Attention Network for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1808.02559\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"153188107\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-01234-2_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8befcd91c24038e5c26df0238d26e2311b21719a\",\"title\":\"A Joint Sequence Fusion Model for Video Question Answering and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/8befcd91c24038e5c26df0238d26e2311b21719a\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2019.2916757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"title\":\"CAM-RNN: Co-Attention Model Based RNN for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2007.09470\",\"authors\":[{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"314f0cdcca7cdab68c92821c149786a876c116bb\",\"title\":\"Social Adaptive Module for Weakly-supervised Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/314f0cdcca7cdab68c92821c149786a876c116bb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1906.12158\",\"authors\":[{\"authorId\":\"47294375\",\"name\":\"Zhu Zhang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145510896\",\"name\":\"Z. Lin\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"}],\"doi\":\"10.24963/ijcai.2019/609\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b2ae2e1f9148e6a05128773c16868cae7e99dc2\",\"title\":\"Open-Ended Long-Form Video Question Answering via Hierarchical Convolutional Self-Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/1b2ae2e1f9148e6a05128773c16868cae7e99dc2\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7499906\",\"name\":\"Xiaomeng Song\"},{\"authorId\":\"46571755\",\"name\":\"Yucheng Shi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240563\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"title\":\"Explore Multi-Step Reasoning in Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b08c35f8e529f47a3fdc4f0713ffe77d94c57d87\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":\"2002.10695\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f771b7514664d2b5e4f7dc12400897db95b0e136\",\"title\":\"Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/f771b7514664d2b5e4f7dc12400897db95b0e136\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144361839\",\"name\":\"X. Lin\"},{\"authorId\":\"47003295\",\"name\":\"Yonggang Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"49499914\",\"name\":\"J. Yang\"}],\"doi\":\"10.1007/978-3-030-04179-3_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"337befcc1df242a903ac2b5c70cb1b99c7c2ddb1\",\"title\":\"Scene Graph Generation Based on Node-Relation Context Module\",\"url\":\"https://www.semanticscholar.org/paper/337befcc1df242a903ac2b5c70cb1b99c7c2ddb1\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1902.10640\",\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"34658653\",\"name\":\"M. Srinivasan\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1109/CVPR.2019.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58f32f1e294569f88d20892c11b389105da9c615\",\"title\":\"Efficient Video Classification Using Fewer Frames\",\"url\":\"https://www.semanticscholar.org/paper/58f32f1e294569f88d20892c11b389105da9c615\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50846763\",\"name\":\"W. Zhang\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"48696362\",\"name\":\"Yanpeng Cao\"},{\"authorId\":\"145974114\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894845\",\"name\":\"Fei Wu\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3394171.3413745\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"title\":\"Photo Stream Question Answer\",\"url\":\"https://www.semanticscholar.org/paper/a95d2cad9fd439831d1d0c05d6bf7d1731dcefe8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1711.11543\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPRW.2018.00279\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"title\":\"Embodied Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e5790afc079c6f36d6fe9235d6d253f3da631f51\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2151048\",\"name\":\"Taiki Miyanishi\"},{\"authorId\":\"34772057\",\"name\":\"Takuya Maekawa\"},{\"authorId\":\"1716788\",\"name\":\"M. Kawanabe\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"title\":\"Two-Stream Spatiotemporal Compositional Attention Network for VideoQA\",\"url\":\"https://www.semanticscholar.org/paper/b3fc587b83d8c6a28b2bc4f9a1f8770f42fb5658\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.05006\",\"authors\":[{\"authorId\":\"150065958\",\"name\":\"Chiwan Song\"},{\"authorId\":\"40506942\",\"name\":\"Woobin Im\"},{\"authorId\":\"144182454\",\"name\":\"Sung-eui Yoon\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"title\":\"Two-stream Spatiotemporal Feature for Video QA Task\",\"url\":\"https://www.semanticscholar.org/paper/b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1708.01641\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"39231399\",\"name\":\"O. Wang\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\"}],\"doi\":\"10.1109/ICCV.2017.618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"title\":\"Localizing Moments in Video with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/ee909ad489244016cf301bb7d7d8eeea423dbf35\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1809.04560\",\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/D18-1012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"title\":\"Game-Based Video-Context Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/667a6eea4c3039d4d1bde2ebf4f2fe8bcfa4af23\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46958543\",\"name\":\"T. Wang\"},{\"authorId\":\"49298611\",\"name\":\"J. Li\"},{\"authorId\":\"153501119\",\"name\":\"Zhaoning Kong\"},{\"authorId\":\"46333170\",\"name\":\"Liu Xin\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"2199558\",\"name\":\"H. Lv\"}],\"doi\":\"10.1016/j.jmsy.2020.07.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13ce2e837c067f759d0596037e7bdeec80397553\",\"title\":\"Digital twin improved via visual question answering for vision-language interactive mode in human\\u2013machine collaboration\",\"url\":\"https://www.semanticscholar.org/paper/13ce2e837c067f759d0596037e7bdeec80397553\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.03793\",\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"1397911258\",\"name\":\"Ali Movaghar-Rahimabadi\"}],\"doi\":\"10.36227/techrxiv.12928544\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f097e32ea304a14c8e26648b05f944d530b016\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/46f097e32ea304a14c8e26648b05f944d530b016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09105\",\"authors\":[{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V34I07.6737\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"title\":\"Location-Aware Graph Convolutional Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/982192e82f17876bf3f8703fbd90ba7e8e3a6e5c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"34658653\",\"name\":\"Mukundhan Srinivasan\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5f9d5be7561bb6eacee9012275b17c75696c388\",\"title\":\"A Teacher Student Network For Faster Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/b5f9d5be7561bb6eacee9012275b17c75696c388\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"143761093\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d89c0c6a1d5bc5cf06b0927976eaca350653301\",\"title\":\"Learning to Reason with Relational Video Representation for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5d89c0c6a1d5bc5cf06b0927976eaca350653301\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738318751\",\"name\":\"Sinan Tan\"},{\"authorId\":\"3449051\",\"name\":\"Weilai Xiang\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"1960245583\",\"name\":\"Di Guo\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"}],\"doi\":\"10.1007/978-3-030-58601-0_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ed523871586b0f883e4ec890155075b96291a13\",\"title\":\"Multi-agent Embodied Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/5ed523871586b0f883e4ec890155075b96291a13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2706269\",\"name\":\"Chengxiang Yin\"},{\"authorId\":\"152949437\",\"name\":\"Jian Tang\"},{\"authorId\":\"48559420\",\"name\":\"Zhiyuan Xu\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2938015\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"d796ff29f8798c418d5374a6632231f02233dbba\",\"title\":\"Memory Augmented Deep Recurrent Neural Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d796ff29f8798c418d5374a6632231f02233dbba\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":\"1905.02442\",\"authors\":[{\"authorId\":\"115044425\",\"name\":\"Sho Maeoki\"},{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPRW50498.2020.00484\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"title\":\"Interactive Video Retrieval with Dialog\",\"url\":\"https://www.semanticscholar.org/paper/1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2012.10285\",\"authors\":[{\"authorId\":\"14358891\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"7750732\",\"name\":\"S. Xiao\"},{\"authorId\":\"145147517\",\"name\":\"A. McLean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f06224d597451ce1d440ca0c8542dee4a5767afe\",\"title\":\"Trying Bilinear Pooling in Video-QA\",\"url\":\"https://www.semanticscholar.org/paper/f06224d597451ce1d440ca0c8542dee4a5767afe\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.08646\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"24263694\",\"name\":\"J. Zhang\"},{\"authorId\":\"2011378\",\"name\":\"Z. Fu\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"49724425\",\"name\":\"H. Zhang\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15fe6bb38c22a1d765bf57ffd7e6654edcfa4768\",\"title\":\"Character Matters: Video Story Understanding with Character-Aware Relations\",\"url\":\"https://www.semanticscholar.org/paper/15fe6bb38c22a1d765bf57ffd7e6654edcfa4768\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.13391\",\"authors\":[{\"authorId\":\"101261224\",\"name\":\"Armand Comas Massague\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"51882015\",\"name\":\"Zlatan Feric\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"},{\"authorId\":\"2023052\",\"name\":\"R. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f10b0c2a9f4e45aeefc8677fdb614a933c2fceb\",\"title\":\"Learning Disentangled Representations of Video with Missing Data\",\"url\":\"https://www.semanticscholar.org/paper/8f10b0c2a9f4e45aeefc8677fdb614a933c2fceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2008.12520\",\"authors\":[{\"authorId\":\"26385137\",\"name\":\"Noa Garcia\"},{\"authorId\":\"82729121\",\"name\":\"Chentao Ye\"},{\"authorId\":\"9071958\",\"name\":\"Zihua Liu\"},{\"authorId\":\"32104754\",\"name\":\"Qingtao Hu\"},{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"2427516\",\"name\":\"Chenhui Chu\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"1706595\",\"name\":\"T. Mitamura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"title\":\"A Dataset and Baselines for Visual Question Answering on Art\",\"url\":\"https://www.semanticscholar.org/paper/fb106fdc2d02b077c100bd0a653395bd6cffcded\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.11976\",\"authors\":[{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"46867282\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/978-3-030-58589-1_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"title\":\"Visual Question Answering on Image Sets\",\"url\":\"https://www.semanticscholar.org/paper/18ba4e542a5206a40e308f54ceffc6786b7d94d2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16726627\",\"name\":\"C. Liu\"},{\"authorId\":\"2785372\",\"name\":\"Ding-Jie Chen\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"1805102\",\"name\":\"Tyng-Luh Liu\"}],\"doi\":\"10.1007/978-3-030-20876-9_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1687d0120e937d5efe2022cbeab19b38edba0608\",\"title\":\"A2A: Attention to Attention Reasoning for Movie Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1687d0120e937d5efe2022cbeab19b38edba0608\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2004.12238\",\"authors\":[{\"authorId\":\"1424748326\",\"name\":\"A. Kumar\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"title\":\"MCQA: Multimodal Co-attention Based Network for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/43d992c17b53e75e46a29c9866ac1c0966bd5bf4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66935500\",\"name\":\"P. Deshmukh\"},{\"authorId\":\"51502239\",\"name\":\"Rani S. Lande\"}],\"doi\":\"10.1109/ICICT48043.2020.9112454\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"title\":\"Convolutional Neural Network based Review System for Automatic Past Event Search using Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8ce3c61b083ce5e66e34df3e1113cb603a6a6632\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1907.04553\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207580\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45a733dab9614611567209628a770b5fe19ad41f\",\"title\":\"Neural Reasoning, Fast and Slow, for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/45a733dab9614611567209628a770b5fe19ad41f\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1712.03316\",\"authors\":[{\"authorId\":\"152462964\",\"name\":\"Daniel Gordon\"},{\"authorId\":\"2684226\",\"name\":\"Aniruddha Kembhavi\"},{\"authorId\":\"143887493\",\"name\":\"M. Rastegari\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"145197953\",\"name\":\"D. Fox\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00430\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"title\":\"IQA: Visual Question Answering in Interactive Environments\",\"url\":\"https://www.semanticscholar.org/paper/b0cd469a06fb2eae3a5cc0c860aa592f71b13f6d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"46270526\",\"name\":\"Z. Liu\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053476\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dd133c6baed0b080687da0954754ea23abc8ba1\",\"title\":\"Video Question Generation via Semantic Rich Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/9dd133c6baed0b080687da0954754ea23abc8ba1\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"49298718\",\"name\":\"Jie Li\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3321505\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"title\":\"Video Question Answering via Knowledge-based Progressive Spatial-Temporal Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Weiying Wang\"},{\"authorId\":null,\"name\":\"Yongcheng Wang\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.18653/v1/D19-1517\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"34e7db6ffcdfeffc29eab0622384ed412d9b4558\",\"title\":\"YouMakeup: A Large-Scale Domain-Specific Multimodal Dataset for Fine-Grained Semantic Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/34e7db6ffcdfeffc29eab0622384ed412d9b4558\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2012.05710\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"title\":\"Look Before you Speak: Visually Contextualized Utterances\",\"url\":\"https://www.semanticscholar.org/paper/b1f6397717d3cbf84e89081a47205f8ed8395d22\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30793303\",\"name\":\"Amirhoshang Hoseinpour Dehkordi\"},{\"authorId\":\"153235768\",\"name\":\"M. Alizadeh\"},{\"authorId\":\"2005221955\",\"name\":\"Ali Movaghar\"}],\"doi\":\"10.36227/techrxiv.12928544.v1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b678835c5de86ebe2031da902957aead8de931aa\",\"title\":\"Linear Temporal Public Announcement Logic: a new perspective for reasoning the knowledge of multi-classifiers\",\"url\":\"https://www.semanticscholar.org/paper/b678835c5de86ebe2031da902957aead8de931aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.10019\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"title\":\"Hierarchical Conditional Relation Networks for Multimodal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/71e1821c1846f9b13ab97eba05f47bedfc3d76c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1811.10830\",\"authors\":[{\"authorId\":\"2545335\",\"name\":\"Rowan Zellers\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":\"10.1109/CVPR.2019.00688\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6dfc2ff03534a4325d06c6f88c3144831996629b\",\"title\":\"From Recognition to Cognition: Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.01801\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"46328947\",\"name\":\"B. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/WACV45572.2020.9093494\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"title\":\"Answering Questions about Data Visualizations using Efficient Bimodal Fusion\",\"url\":\"https://www.semanticscholar.org/paper/f59ae732612ce8c42035adfb47bd5739c6288ad6\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40295709\",\"name\":\"F. Liu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"120313754\",\"name\":\"Richang Hong\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3394171.3413649\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"063235546b312ee4cb5cc67578b6e879461c6d83\",\"title\":\"Dual Hierarchical Temporal Convolutional Network with QA-Aware Dynamic Normalization for Video Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/063235546b312ee4cb5cc67578b6e879461c6d83\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.24963/ijcai.2018/513\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"title\":\"Multi-Turn Video Question Answering via Multi-Stream Hierarchical Attention Context Network\",\"url\":\"https://www.semanticscholar.org/paper/396b9b7e7836632eb5e94ddb637c98b0d0cf34a3\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018658\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"565359aac8914505e6b02db05822ee63d3ffd03a\",\"title\":\"Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/565359aac8914505e6b02db05822ee63d3ffd03a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/TPAMI.2018.2828437\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c16428a0bae507d2a1785860f07168a807d8e59\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/4c16428a0bae507d2a1785860f07168a807d8e59\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234342\",\"name\":\"L. Hendricks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd7062e6f84750688fa96143209efc801e91f9bd\",\"title\":\"Visual Understanding through Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/dd7062e6f84750688fa96143209efc801e91f9bd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"1478185914\",\"name\":\"Zehan Song\"},{\"authorId\":\"153228843\",\"name\":\"Chujie Lu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1109/TIP.2020.2963950\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"title\":\"Open-Ended Video Question Answering via Multi-Modal Conditional Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/5b5de122d508518ecaae7c9e4cc627c36c96f2a9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2338742\",\"name\":\"Y. Jang\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"32821535\",\"name\":\"C. D. Kim\"},{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"49170458\",\"name\":\"Youngjin Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/s11263-019-01189-x\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"title\":\"Video Question Answering with Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/1e1bd132613866c176a8fc780cb1b9f9aa43feeb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2002.10698\",\"authors\":[{\"authorId\":\"47267313\",\"name\":\"T. Le\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"}],\"doi\":\"10.1109/cvpr42600.2020.00999\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"53de96cf981c9d58a86697d812484808945b47f5\",\"title\":\"Hierarchical Conditional Relation Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/53de96cf981c9d58a86697d812484808945b47f5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47897687\",\"name\":\"H. Tan\"},{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"1786343\",\"name\":\"Q. Xu\"},{\"authorId\":\"35718875\",\"name\":\"L. Li\"},{\"authorId\":\"2998031\",\"name\":\"F. Fang\"},{\"authorId\":\"2000269838\",\"name\":\"Yi Cheng\"},{\"authorId\":\"152765071\",\"name\":\"N. Gauthier\"},{\"authorId\":\"2000311149\",\"name\":\"Ying Sun\"},{\"authorId\":\"9183286\",\"name\":\"Joo-Hwee Lim\"}],\"doi\":\"10.1109/ICIP40778.2020.9190659\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"title\":\"Task-Oriented Multi-Modal Question Answering For Collaborative Applications\",\"url\":\"https://www.semanticscholar.org/paper/cf4d01d0c5dc4d351a96162a5387e56bc95e58ff\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/512\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"title\":\"Open-Ended Long-form Video Question Answering via Adaptive Hierarchical Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c6da8fdc68888296730dbeed0fd0624febbc16f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493665\",\"name\":\"Dafang He\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"1745900\",\"name\":\"Alexander N. Gorban\"},{\"authorId\":\"39099960\",\"name\":\"Derrall Heath\"},{\"authorId\":\"46920727\",\"name\":\"J. Ibarz\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1852261\",\"name\":\"D. Kifer\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"title\":\"Guided Attention for Large Scale Scene Text Verification\",\"url\":\"https://www.semanticscholar.org/paper/b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.15319\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.acl-main.518\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af73d7815f13794223384004096ff4fc62c3d4a9\",\"title\":\"Video-Grounded Dialogues with Pretrained Generation Language Models\",\"url\":\"https://www.semanticscholar.org/paper/af73d7815f13794223384004096ff4fc62c3d4a9\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10721120\",\"name\":\"Ramakanth Pasunuru\"},{\"authorId\":\"143977268\",\"name\":\"Mohit Bansal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8ad1c0d40b416ac52522d3cf110f574b71c0db6\",\"title\":\"DSTC 7-AVSD : Scene-Aware Video-Dialogue Systems with Dual Attention\",\"url\":\"https://www.semanticscholar.org/paper/c8ad1c0d40b416ac52522d3cf110f574b71c0db6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"1466481870\",\"name\":\"Bencheng Yan\"}],\"doi\":\"10.1007/978-3-030-36718-3_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77465a0ae333a9ce4cf3969b93e756772714fc63\",\"title\":\"Watch and Ask: Video Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/77465a0ae333a9ce4cf3969b93e756772714fc63\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1904.04357\",\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"49469577\",\"name\":\"X. Zhang\"},{\"authorId\":\"50202300\",\"name\":\"Shu Zhang\"},{\"authorId\":\"46314996\",\"name\":\"Wensheng Wang\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"46675463\",\"name\":\"Heng Huang\"}],\"doi\":\"10.1109/CVPR.2019.00210\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5c5d99eff1377e141be293336a14ffddb323c364\",\"title\":\"Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5c5d99eff1377e141be293336a14ffddb323c364\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.10210\",\"authors\":[{\"authorId\":\"108630954\",\"name\":\"T. Winterbottom\"},{\"authorId\":\"2455565\",\"name\":\"S. Xiao\"},{\"authorId\":\"115718758\",\"name\":\"A. Mclean\"},{\"authorId\":\"1875235\",\"name\":\"N. A. Moubayed\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"title\":\"On modality bias in the TVQA dataset.\",\"url\":\"https://www.semanticscholar.org/paper/6ebabf0479d3d6ccbd2febfb194fe1df75358190\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020}],\"corpusId\":3030826,\"doi\":\"10.1109/CVPR.2017.149\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":40,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.18653/v1/D15-1021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a98a8b3b28250cb77d99748bff15ddbd9351433\",\"title\":\"A Survey of Current Datasets for Vision and Language Research\",\"url\":\"https://www.semanticscholar.org/paper/4a98a8b3b28250cb77d99748bff15ddbd9351433\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Elliott\"},{\"authorId\":null,\"name\":\"A. Erdem\"},{\"authorId\":null,\"name\":\"E. Erdem\"},{\"authorId\":null,\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":null,\"name\":\"F. Keller\"},{\"authorId\":null,\"name\":\"A. Muscat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"tomatic Description Generation from Images : A Survey of Models , Datasets , and Evaluation Measures\",\"url\":\"\",\"venue\":\"JAIR\",\"year\":null},{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47624312\",\"name\":\"O. Levy\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/ICCV.2015.346\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13346a860ac22296bd7c78036a687584b31eb95c\",\"title\":\"Live Repetition Counting\",\"url\":\"https://www.semanticscholar.org/paper/13346a860ac22296bd7c78036a687584b31eb95c\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1605.03705\",\"authors\":[{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1721168\",\"name\":\"Niket Tandon\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/s11263-016-0987-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"title\":\"Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/154c22ca5eef149aedc8a986fa684ca1fd14e7dc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1506.06724\",\"authors\":[{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2015.11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e6824e137847be0599bb0032e37042ed2ef5045\",\"title\":\"Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\",\"url\":\"https://www.semanticscholar.org/paper/0e6824e137847be0599bb0032e37042ed2ef5045\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.02748\",\"authors\":[{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1739099\",\"name\":\"J. Tetreault\"},{\"authorId\":\"39420932\",\"name\":\"L. Goldberg\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.502\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"title\":\"TGIF: A New Dataset and Benchmark on Animated GIF Description\",\"url\":\"https://www.semanticscholar.org/paper/05f3f8f6f97db00bafa2efd2ac9aac570603c0c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. P. Kingma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"AMethod For Stochastic Optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1612.06890\",\"authors\":[{\"authorId\":\"153365679\",\"name\":\"J. Johnson\"},{\"authorId\":\"73710317\",\"name\":\"B. Hariharan\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2017.215\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03eb382e04cca8cca743f7799070869954f1402a\",\"title\":\"CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/03eb382e04cca8cca743f7799070869954f1402a\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1612.00837\",\"authors\":[{\"authorId\":\"37226164\",\"name\":\"Yash Goyal\"},{\"authorId\":\"7595427\",\"name\":\"Tejas Khot\"},{\"authorId\":\"1403432120\",\"name\":\"Douglas Summers-Stay\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2017.670\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"title\":\"Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a27ed1310b9c0832bde8f906e0fcd23d1f3aa79c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1605.04850\",\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"}],\"doi\":\"10.1109/CVPR.2016.114\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28f0e0d3783659bc9adb2cec56f19b1f90cdd2be\",\"title\":\"Video2GIF: Automatic Generation of Animated GIFs from Video\",\"url\":\"https://www.semanticscholar.org/paper/28f0e0d3783659bc9adb2cec56f19b1f90cdd2be\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1607.06450\",\"authors\":[{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97fb4e3d45bb098e27e0071448b6152217bd35a5\",\"title\":\"Layer Normalization\",\"url\":\"https://www.semanticscholar.org/paper/97fb4e3d45bb098e27e0071448b6152217bd35a5\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"145358192\",\"name\":\"E. Adelson\"}],\"doi\":\"10.1109/CVPR.2015.7298744\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0e6e543307679a1de67989b91777bc5b8c95462\",\"title\":\"Discovering states and transformations in image collections\",\"url\":\"https://www.semanticscholar.org/paper/b0e6e543307679a1de67989b91777bc5b8c95462\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Andreas\"},{\"authorId\":null,\"name\":\"M Rohrbach\"},{\"authorId\":null,\"name\":\"T Darrell\"},{\"authorId\":null,\"name\":\"D Klein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neural Module Networks. In CVPR\",\"url\":\"\",\"venue\":\"Neural Module Networks. In CVPR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143845796\",\"name\":\"Jeffrey Pennington\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":\"10.3115/v1/D14-1162\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"title\":\"Glove: Global Vectors for Word Representation\",\"url\":\"https://www.semanticscholar.org/paper/f37e1b62a767a307c046404ca96bc140b3e68cb5\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1506.06726\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"title\":\"Skip-Thought Vectors\",\"url\":\"https://www.semanticscholar.org/paper/6e795c6e9916174ae12349f5dc3f516570c17ce8\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Rohrbach\"},{\"authorId\":null,\"name\":\"A Torabi\"},{\"authorId\":null,\"name\":\"M Rohrbach\"},{\"authorId\":null,\"name\":\"N Tandon\"},{\"authorId\":null,\"name\":\"C Pal\"},{\"authorId\":null,\"name\":\"H Larochelle\"},{\"authorId\":null,\"name\":\"A Courville\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Schiele. Movie Description . IJCV\",\"url\":\"\",\"venue\":\"Schiele. Movie Description . IJCV\",\"year\":2017},{\"arxivId\":\"1502.08029\",\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1730844\",\"name\":\"Atousa Torabi\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1777528\",\"name\":\"H. Larochelle\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":\"10.1109/ICCV.2015.512\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f425b7abf2ed3172ed060df85bb1885860a297e\",\"title\":\"Describing Videos by Exploiting Temporal Structure\",\"url\":\"https://www.semanticscholar.org/paper/5f425b7abf2ed3172ed060df85bb1885860a297e\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1502.06108\",\"authors\":[{\"authorId\":\"9136919\",\"name\":\"X. Lin\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7298917\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"title\":\"Don't just listen, use your imagination: Leveraging visual common sense for non-visual tasks\",\"url\":\"https://www.semanticscholar.org/paper/e0cff50a6ce27a8cb2b26ca586dea8a0b7cd67bd\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.02902\",\"authors\":[{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/CVPR.2016.501\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"title\":\"MovieQA: Understanding Stories in Movies through Question-Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bdd75a37f7c601f01e9d31c2551fa9f2067ffd7\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39554008\",\"name\":\"Saeideh Bakhshi\"},{\"authorId\":\"1760364\",\"name\":\"D. Shamma\"},{\"authorId\":\"144557123\",\"name\":\"L. Kennedy\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"1893882\",\"name\":\"Paloma de Juan\"},{\"authorId\":\"143782217\",\"name\":\"J. Kaye\"}],\"doi\":\"10.1145/2858036.2858532\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"345413ede3e5743645d95140e74a73a86a96d7f8\",\"title\":\"Fast, Cheap, and Good: Why Animated GIFs Engage Us\",\"url\":\"https://www.semanticscholar.org/paper/345413ede3e5743645d95140e74a73a86a96d7f8\",\"venue\":\"CHI\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696803\",\"name\":\"Joachim Daiber\"},{\"authorId\":\"2144277\",\"name\":\"Max Jakob\"},{\"authorId\":\"82576134\",\"name\":\"Chris Hokamp\"},{\"authorId\":\"1692493\",\"name\":\"Pablo N. Mendes\"}],\"doi\":\"10.1145/2506182.2506198\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a97fe719f2f1e62169320e1c45e3f96e094ccd19\",\"title\":\"Improving efficiency and accuracy in multilingual entity extraction\",\"url\":\"https://www.semanticscholar.org/paper/a97fe719f2f1e62169320e1c45e3f96e094ccd19\",\"venue\":\"I-SEMANTICS '13\",\"year\":2013},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2135004\",\"name\":\"K. Schuler\"},{\"authorId\":\"145755155\",\"name\":\"Martha Palmer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bb6898d6041e97c4946661b3a3df0f82286a43b5\",\"title\":\"Verbnet: a broad-coverage, comprehensive verb lexicon\",\"url\":\"https://www.semanticscholar.org/paper/bb6898d6041e97c4946661b3a3df0f82286a43b5\",\"venue\":\"\",\"year\":2005},{\"arxivId\":\"1610.02947\",\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"7172307\",\"name\":\"Hyungjin Ko\"},{\"authorId\":\"1899119\",\"name\":\"Jongwook Choi\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/CVPR.2017.347\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3dc37dab102a0465098111b7ccf6f95b736397f2\",\"title\":\"End-to-End Concept Word Detection for Video Captioning, Retrieval, and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3dc37dab102a0465098111b7ccf6f95b736397f2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1410.0210\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"title\":\"A Multi-World Approach to Question Answering about Real-World Scenes based on Uncertain Input\",\"url\":\"https://www.semanticscholar.org/paper/ac64fb7e6d2ddf236332ec9f371fe85d308c114d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\",\"result\"],\"isInfluential\":true,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1312.4569\",\"authors\":[{\"authorId\":\"40094154\",\"name\":\"Vu Pham\"},{\"authorId\":\"2156685\",\"name\":\"Christopher Kermorvant\"},{\"authorId\":\"2373952\",\"name\":\"J. Louradour\"}],\"doi\":\"10.1109/ICFHR.2014.55\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c0b624c46b51920dfec5aa02cc86323c0beb0df5\",\"title\":\"Dropout Improves Recurrent Neural Networks for Handwriting Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c0b624c46b51920dfec5aa02cc86323c0beb0df5\",\"venue\":\"2014 14th International Conference on Frontiers in Handwriting Recognition\",\"year\":2014},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145040726\",\"name\":\"R. Bernardi\"},{\"authorId\":\"2588033\",\"name\":\"Ruken Cakici\"},{\"authorId\":\"50369944\",\"name\":\"Desmond Elliott\"},{\"authorId\":\"14364286\",\"name\":\"Aykut Erdem\"},{\"authorId\":\"152330322\",\"name\":\"Erkut Erdem\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1393020635\",\"name\":\"F. Keller\"},{\"authorId\":\"35347012\",\"name\":\"A. Muscat\"},{\"authorId\":\"2022124\",\"name\":\"Barbara Plank\"}],\"doi\":\"10.1613/jair.4900\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c162d791b63682d928c09578bd38c3dd61f78c8c\",\"title\":\"Automatic Description Generation from Images: A Survey of Models, Datasets, and Evaluation Measures\",\"url\":\"https://www.semanticscholar.org/paper/c162d791b63682d928c09578bd38c3dd61f78c8c\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2016},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/ICCV.2015.283\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"title\":\"Visual Madlibs: Fill in the Blank Description Generation and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ced9f7178f8032d3408fcba493c02eb48e8a8636\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1611.08669\",\"authors\":[{\"authorId\":\"145497716\",\"name\":\"A. Das\"},{\"authorId\":\"2150275\",\"name\":\"S. Kottur\"},{\"authorId\":\"39855500\",\"name\":\"K. Gupta\"},{\"authorId\":\"1899992\",\"name\":\"Avi Singh\"},{\"authorId\":\"24508084\",\"name\":\"Deshraj Yadav\"},{\"authorId\":\"144915495\",\"name\":\"Jos\\u00e9 M. F. Moura\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.121\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"title\":\"Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/2231f44be9a8472a46d8e8a628b4e52b9a8f44e0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. P. Kingma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A Method For Stochastic Optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015}],\"title\":\"TGIF-QA: Toward Spatio-Temporal Reasoning in Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Natural language processing\",\"topicId\":\"1914\",\"url\":\"https://www.semanticscholar.org/topic/1914\"},{\"topic\":\"CVPR\",\"topicId\":\"56892\",\"url\":\"https://www.semanticscholar.org/topic/56892\"},{\"topic\":\"Concatenation\",\"topicId\":\"2262\",\"url\":\"https://www.semanticscholar.org/topic/2262\"},{\"topic\":\"Spatial\\u2013temporal reasoning\",\"topicId\":\"3209\",\"url\":\"https://www.semanticscholar.org/topic/3209\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"QA & UX Manager\",\"topicId\":\"9716554\",\"url\":\"https://www.semanticscholar.org/topic/9716554\"},{\"topic\":\"Artificial intelligence\",\"topicId\":\"8286\",\"url\":\"https://www.semanticscholar.org/topic/8286\"},{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Big data\",\"topicId\":\"20355\",\"url\":\"https://www.semanticscholar.org/topic/20355\"},{\"topic\":\"Natural language understanding\",\"topicId\":\"18266\",\"url\":\"https://www.semanticscholar.org/topic/18266\"},{\"topic\":\"Google Questions and Answers\",\"topicId\":\"2898125\",\"url\":\"https://www.semanticscholar.org/topic/2898125\"},{\"topic\":\"Text-based user interface\",\"topicId\":\"328633\",\"url\":\"https://www.semanticscholar.org/topic/328633\"},{\"topic\":\"Baseline (configuration management)\",\"topicId\":\"3403\",\"url\":\"https://www.semanticscholar.org/topic/3403\"},{\"topic\":\"Software quality assurance\",\"topicId\":\"54373\",\"url\":\"https://www.semanticscholar.org/topic/54373\"},{\"topic\":\"Computer animation\",\"topicId\":\"102448\",\"url\":\"https://www.semanticscholar.org/topic/102448\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Bilinear filtering\",\"topicId\":\"1123309\",\"url\":\"https://www.semanticscholar.org/topic/1123309\"},{\"topic\":\"3D printing\",\"topicId\":\"120609\",\"url\":\"https://www.semanticscholar.org/topic/120609\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"}],\"url\":\"https://www.semanticscholar.org/paper/b2f521c02c6ed3080c5fe123e938cdf4555e6fd2\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"