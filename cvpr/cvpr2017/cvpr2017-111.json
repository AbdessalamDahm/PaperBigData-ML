"{\"abstract\":\"This paper addresses video summarization, or the problem of distilling a raw video into a shorter form while still capturing the original story. We show that visual representations supervised by freeform language make a good fit for this application by extending a recent submodular summarization approach [9] with representativeness and interestingness objectives computed on features from a joint vision-language embedding space. We perform an evaluation on two diverse datasets, UT Egocentric [18] and TV Episodes [45], and show that our new objectives give improved summarization ability compared to standard visual features alone. Our experiments also show that the vision-language embedding need not be trained on domainspecific data, but can be learned from standard still image vision-language datasets and transferred to video. A further benefit of our model is the ability to guide a summary using freeform text input at test time, allowing user customization.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\",\"url\":\"https://www.semanticscholar.org/author/2856622\"},{\"authorId\":\"144735789\",\"name\":\"M. Brown\",\"url\":\"https://www.semanticscholar.org/author/144735789\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\",\"url\":\"https://www.semanticscholar.org/author/1749609\"}],\"citationVelocity\":21,\"citations\":[{\"arxivId\":\"2005.03804\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7cd871b42efb42f507444386e4317efd7dfc10c\",\"title\":\"Text Synopsis Generation for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7cd871b42efb42f507444386e4317efd7dfc10c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.11228\",\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1145/3321408.3322622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"title\":\"DTR-GAN: dilated temporal relational adversarial network for video summarization\",\"url\":\"https://www.semanticscholar.org/paper/ee5e22fd01b4c8719e0b2df5830d21db8150477f\",\"venue\":\"ACM TUR-C\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1591133581\",\"name\":\"Yujia Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1007/s11042-019-08175-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"title\":\"Dilated temporal relational adversarial network for generic video summarization\",\"url\":\"https://www.semanticscholar.org/paper/5c6628a9b7ff29c113b1902e95267bd0614974c8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1811.12326\",\"authors\":[{\"authorId\":\"144692784\",\"name\":\"Mohsen Joneidi\"},{\"authorId\":\"2621521\",\"name\":\"Alireza Zaeemzadeh\"},{\"authorId\":\"1789219\",\"name\":\"N. Rahnavard\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2019.00556\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b\",\"title\":\"Iterative Projection and Matching: Finding Structure-Preserving Representatives and Its Application to Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.06677\",\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"8199702\",\"name\":\"Michael Kampffmeyer\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"143810339\",\"name\":\"M. Tan\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9beaabe21100c87757d703e657de6d3215a91e0\",\"title\":\"Query-Conditioned Three-Player Adversarial Network for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/c9beaabe21100c87757d703e657de6d3215a91e0\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.12.040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0adddb83eb89da8ecd14a296fa016773dc774646\",\"title\":\"Video summarization via spatio-temporal deep architecture\",\"url\":\"https://www.semanticscholar.org/paper/0adddb83eb89da8ecd14a296fa016773dc774646\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3206025.3206064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9dbca9da6a72ba3739813288b677888a6cf76272\",\"title\":\"Learning Joint Embedding with Multimodal Cues for Cross-Modal Video-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9dbca9da6a72ba3739813288b677888a6cf76272\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39478133\",\"name\":\"Paria Yousefi\"},{\"authorId\":\"2981733\",\"name\":\"C. Matthews\"},{\"authorId\":\"1743073\",\"name\":\"L. Kuncheva\"}],\"doi\":\"10.1007/978-3-030-03801-4_56\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d47659895df1b52ab984fc75610f667dca0ff715\",\"title\":\"Budget-Constrained Online Video Summarisation of Egocentric Video Using Control Charts\",\"url\":\"https://www.semanticscholar.org/paper/d47659895df1b52ab984fc75610f667dca0ff715\",\"venue\":\"ISVC\",\"year\":2018},{\"arxivId\":\"1808.07793\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"3000659\",\"name\":\"Evangelos E. Papalexakis\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3240508.3240712\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"title\":\"Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35367465\",\"name\":\"Iyiola E. Olatunji\"},{\"authorId\":\"48145735\",\"name\":\"Chun-Hung Cheng\"}],\"doi\":\"10.1007/978-3-030-15628-2_15\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b918b9a7573956d3d718e88e988bfa7d16856779\",\"title\":\"Video Analytics for Visual Surveillance and Applications: An Overview and Survey\",\"url\":\"https://www.semanticscholar.org/paper/b918b9a7573956d3d718e88e988bfa7d16856779\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"47521917\",\"name\":\"Q. Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e93c977025e2829f852fc8c1e8f9547c3588dbf0\",\"title\":\"vv 1 camping tent food fire Residual BRNN Input Video Visual Encoder ( CNN ) Video Encoder Sentence Encoder Word 2 Vecs Sentence Semantic Embedding vv 2 vv 3 vvNN \\u2212 1 vvNN vv Video Semantic Embedding xx\",\"url\":\"https://www.semanticscholar.org/paper/e93c977025e2829f852fc8c1e8f9547c3588dbf0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80491208\",\"name\":\"Vinay Rajpoot\"},{\"authorId\":\"2232488\",\"name\":\"S. Girase\"}],\"doi\":\"10.1109/ICECA.2018.8474699\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9bec3ecd6451b8c891bfbb85a3d39b3bda7ea14\",\"title\":\"A Study on Application Scenario of Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/c9bec3ecd6451b8c891bfbb85a3d39b3bda7ea14\",\"venue\":\"2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2f9b96c88d929b58d08cd2b2ec431555a018f8b\",\"title\":\"Contextually Customized Video Summaries Via Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/f2f9b96c88d929b58d08cd2b2ec431555a018f8b\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01240-3_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9925eb898e7484ae289b675785313ddb47bb20bd\",\"title\":\"Find and Focus: Retrieve and Localize Video Events with Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/9925eb898e7484ae289b675785313ddb47bb20bd\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.02843\",\"authors\":[{\"authorId\":\"2551640\",\"name\":\"Atsushi Kanehira\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPR.2018.00776\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"067abbecd4b98c2156d277c19bcdee0a6642cc71\",\"title\":\"Viewpoint-Aware Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/067abbecd4b98c2156d277c19bcdee0a6642cc71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1912.12655\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"51929166\",\"name\":\"Edson Roteia Araujo Junior\"},{\"authorId\":\"3360914\",\"name\":\"Alan C. Neves\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/WACV45572.2020.9093330\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0155df608af9c0024c6d557b16bdc15af78c5133\",\"title\":\"Personalizing Fast-Forward Videos Based on Visual and Textual Features from Social Network\",\"url\":\"https://www.semanticscholar.org/paper/0155df608af9c0024c6d557b16bdc15af78c5133\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2004.03661\",\"authors\":[{\"authorId\":\"50535497\",\"name\":\"Jiahong Huang\"},{\"authorId\":\"1717056\",\"name\":\"M. Worring\"}],\"doi\":\"10.1145/3372278.3390695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e7b49b1b50b57fdb5f68c9185edee1978569474\",\"title\":\"Query-controllable Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/9e7b49b1b50b57fdb5f68c9185edee1978569474\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1422036724\",\"name\":\"Peilun Zhou\"},{\"authorId\":\"41157498\",\"name\":\"T. Xu\"},{\"authorId\":\"1576197330\",\"name\":\"Zhizhuo Yin\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"},{\"authorId\":\"2767360\",\"name\":\"Guangyi Lv\"},{\"authorId\":\"2348067\",\"name\":\"Changliang Li\"}],\"doi\":\"10.1109/TMM.2019.2960594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7637740ade03e20933b0c80c98f14fba2eacd20b\",\"title\":\"Character-Oriented Video Summarization With Visual and Textual Cues\",\"url\":\"https://www.semanticscholar.org/paper/7637740ade03e20933b0c80c98f14fba2eacd20b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2009.11063\",\"authors\":[{\"authorId\":\"46464798\",\"name\":\"M. Silva\"},{\"authorId\":\"144151841\",\"name\":\"W. Ramos\"},{\"authorId\":\"152471790\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/TPAMI.2020.2983929\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ac374b7696e72c40c660c9dc5722d73b93667ec8\",\"title\":\"A Sparse Sampling-based framework for Semantic Fast-Forward of First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/ac374b7696e72c40c660c9dc5722d73b93667ec8\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.3929/ethz-b-000204633\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ef504d7e5c94b9f9b8bfd3d1c44c6aa0d0515f2\",\"title\":\"Interest-Based Video Summarization via Subset Selection\",\"url\":\"https://www.semanticscholar.org/paper/8ef504d7e5c94b9f9b8bfd3d1c44c6aa0d0515f2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"4661295\",\"name\":\"M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.5753/sibgrapi.est.2019.8302\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f1c2aa137332732a0ecc9b9818dee767896f4b0\",\"title\":\"Semantic Hyperlapse: a sparse coding based and multi-importance approach for first-person videos\",\"url\":\"https://www.semanticscholar.org/paper/9f1c2aa137332732a0ecc9b9818dee767896f4b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2008.09884\",\"authors\":[{\"authorId\":\"46245587\",\"name\":\"Geeticka Chauhan\"},{\"authorId\":\"1742480112\",\"name\":\"Ruizhi Liao\"},{\"authorId\":\"153671052\",\"name\":\"W. Wells\"},{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"35140763\",\"name\":\"S. Berkowitz\"},{\"authorId\":\"2986398\",\"name\":\"S. Horng\"},{\"authorId\":\"1679873\",\"name\":\"Peter Szolovits\"},{\"authorId\":\"1729630\",\"name\":\"P. Golland\"}],\"doi\":\"10.1007/978-3-030-59713-9_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aac5ce0dfd22f8d713e74b607ce849f632260023\",\"title\":\"Joint Modeling of Chest Radiographs and Radiology Reports for Pulmonary Edema Assessment\",\"url\":\"https://www.semanticscholar.org/paper/aac5ce0dfd22f8d713e74b607ce849f632260023\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51498614\",\"name\":\"A. Singh\"},{\"authorId\":\"49384307\",\"name\":\"D. Sharma\"}],\"doi\":\"10.1007/978-3-030-25797-2_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f1f9bc9ad74e6f7b9aada099aa81b7bdc4c6753\",\"title\":\"Image Collection Summarization: Past, Present and Future\",\"url\":\"https://www.semanticscholar.org/paper/6f1f9bc9ad74e6f7b9aada099aa81b7bdc4c6753\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.08854\",\"authors\":[{\"authorId\":\"3333118\",\"name\":\"Vishal Kaushal\"},{\"authorId\":\"152398665\",\"name\":\"R. Iyer\"},{\"authorId\":\"9745898\",\"name\":\"S. Kothawade\"},{\"authorId\":null,\"name\":\"Sandeep Subramanian\"},{\"authorId\":\"145799547\",\"name\":\"Ganesh Ramakrishnan\"}],\"doi\":\"10.1109/WACV.2019.00076\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a2637ae9b1c6eb35340a517af4cbebca9e92a98\",\"title\":\"A Framework Towards Domain Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/2a2637ae9b1c6eb35340a517af4cbebca9e92a98\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1901.10713\",\"authors\":[{\"authorId\":\"1965545\",\"name\":\"Chih-Yuan Yang\"},{\"authorId\":\"66663648\",\"name\":\"Heeseung Yun\"},{\"authorId\":\"1717095\",\"name\":\"J. Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0d59dedba3b38c1c2d0fb997dc2fcf901c353d0\",\"title\":\"Video Summarization through Human Detection on a Social Robot\",\"url\":\"https://www.semanticscholar.org/paper/f0d59dedba3b38c1c2d0fb997dc2fcf901c353d0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"119885701\",\"name\":\"Hong-Li Li\"},{\"authorId\":\"47754371\",\"name\":\"Yongsheng Dong\"}],\"doi\":\"10.1109/TIE.2019.2931283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58ecfafc77901f7347e37e4fb40386bce648b475\",\"title\":\"Meta Learning for Task-Driven Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/58ecfafc77901f7347e37e4fb40386bce648b475\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103678890\",\"name\":\"Humaira A. Ghafoor\"},{\"authorId\":\"144865166\",\"name\":\"A. Javed\"},{\"authorId\":\"2809162\",\"name\":\"Aun Irtaza\"},{\"authorId\":\"51260966\",\"name\":\"H. Dawood\"},{\"authorId\":\"145337997\",\"name\":\"H. Dawood\"},{\"authorId\":\"2823041\",\"name\":\"Ameen Banjar\"}],\"doi\":\"10.1155/2018/7586417\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"87da2e37fb6464e3664aa27625cf5e25ece8fe6f\",\"title\":\"Egocentric Video Summarization Based on People Interaction Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/87da2e37fb6464e3664aa27625cf5e25ece8fe6f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1802.08722\",\"authors\":[{\"authorId\":\"3461833\",\"name\":\"M. M. Silva\"},{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"143778673\",\"name\":\"Jo\\u00e3o P. K. Ferreira\"},{\"authorId\":\"29995743\",\"name\":\"Felipe C. Chamone\"},{\"authorId\":\"145875807\",\"name\":\"M. F. M. Campos\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR.2018.00253\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"title\":\"A Weighted Sparse Sampling and Smoothing Frame Transition Approach for Semantic Fast-Forward First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/14e9ee09765fcb99fd6ad2fd7360a90c94c9b5e2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145745762\",\"name\":\"Jharna Majumdar\"},{\"authorId\":\"52211315\",\"name\":\"Manish Awale\"},{\"authorId\":\"2917072\",\"name\":\"K. L. Kumar Santhosh\"}],\"doi\":\"10.1109/ICACCI.2018.8554662\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3446940fe506f691619081cb6c2a094491b17351\",\"title\":\"Video Shot Detection based on SIFT Features and Video Summarization using Expectation-Maximization\",\"url\":\"https://www.semanticscholar.org/paper/3446940fe506f691619081cb6c2a094491b17351\",\"venue\":\"2018 International Conference on Advances in Computing, Communications and Informatics (ICACCI)\",\"year\":2018},{\"arxivId\":\"1907.12342\",\"authors\":[{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"119885701\",\"name\":\"Hong-Li Li\"},{\"authorId\":\"47754371\",\"name\":\"Yongsheng Dong\"}],\"doi\":\"10.1109/TIE.2019.2931283.\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d6667a644da55a92c99509bae34946e376ff719\",\"title\":\"Meta Learning for Task-Driven Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/5d6667a644da55a92c99509bae34946e376ff719\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.00597\",\"authors\":[{\"authorId\":\"2007582232\",\"name\":\"Simon Ging\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80089ad641bae28b0e57771afef181b60011069e\",\"title\":\"COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/80089ad641bae28b0e57771afef181b60011069e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1807.09418\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/TMM.2019.2930041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92e02bd58b99ac17b475081611f091f4b0776482\",\"title\":\"Video Storytelling: Textual Summaries for Events\",\"url\":\"https://www.semanticscholar.org/paper/92e02bd58b99ac17b475081611f091f4b0776482\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28903267\",\"name\":\"Elo\\u00efse Berson\"},{\"authorId\":\"1996351\",\"name\":\"Claire-H\\u00e9l\\u00e8ne Demarty\"},{\"authorId\":\"1756744\",\"name\":\"Ngoc Q. K. Duong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0338520164a489461e26f93f6e9634b19793eba4\",\"title\":\"Multimodality and Deep Learning when Predicting Media Interestingness\",\"url\":\"https://www.semanticscholar.org/paper/0338520164a489461e26f93f6e9634b19793eba4\",\"venue\":\"MediaEval\",\"year\":2017},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.11328\",\"authors\":[{\"authorId\":\"3186326\",\"name\":\"Mayu Otani\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1109/CVPR.2019.00778\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9835a04f6e5cd8b4c70edda704fddce813d18339\",\"title\":\"Rethinking the Evaluation of Video Summaries\",\"url\":\"https://www.semanticscholar.org/paper/9835a04f6e5cd8b4c70edda704fddce813d18339\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66365027\",\"name\":\"K. Abdalla\"},{\"authorId\":\"4500702\",\"name\":\"I. Menezes\"},{\"authorId\":\"122740538\",\"name\":\"L. Oliveira\"}],\"doi\":\"10.1016/J.ESWA.2019.04.065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf75850944b2c66777192dce0afe3bdb3966f731\",\"title\":\"Modelling perceptions on the evaluation of video summarization\",\"url\":\"https://www.semanticscholar.org/paper/bf75850944b2c66777192dce0afe3bdb3966f731\",\"venue\":\"Expert Syst. Appl.\",\"year\":2019},{\"arxivId\":\"2007.14560\",\"authors\":[{\"authorId\":\"3333118\",\"name\":\"Vishal Kaushal\"},{\"authorId\":\"9745898\",\"name\":\"S. Kothawade\"},{\"authorId\":\"152398665\",\"name\":\"R. Iyer\"},{\"authorId\":\"150114500\",\"name\":\"G. Ramakrishnan\"}],\"doi\":\"10.1145/3422839.3423064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47591f52c1a38df650057d43efdeef5768b73cf9\",\"title\":\"Realistic Video Summarization through VISIOCITY: A New Benchmark and Evaluation Framework\",\"url\":\"https://www.semanticscholar.org/paper/47591f52c1a38df650057d43efdeef5768b73cf9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9335681\",\"name\":\"O. Gorokhovatskyi\"},{\"authorId\":\"73132208\",\"name\":\"O. Teslenko\"},{\"authorId\":\"150335021\",\"name\":\"V. Zatkhei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e8f92bb54428bda83b2dcb75b2d65c38547b64f\",\"title\":\"Online video summarization with the Kohonen SOM in real time\",\"url\":\"https://www.semanticscholar.org/paper/7e8f92bb54428bda83b2dcb75b2d65c38547b64f\",\"venue\":\"CMIS\",\"year\":2020},{\"arxivId\":\"2005.00706\",\"authors\":[{\"authorId\":\"40027632\",\"name\":\"F. F. Xu\"},{\"authorId\":\"144906579\",\"name\":\"Lei Ji\"},{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"3109653\",\"name\":\"Junyi Du\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"},{\"authorId\":\"3312309\",\"name\":\"Yonatan Bisk\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"title\":\"A Benchmark for Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/358d7d6333d3edd530e37efd8004cb9da8cfd5d4\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920099\",\"name\":\"S. Cai\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"36685537\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1007/978-3-030-01264-9_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"817a781e26c2eabb068973d3cc0bab9220fa401d\",\"title\":\"Weakly-Supervised Video Summarization Using Variational Encoder-Decoder and Web Prior\",\"url\":\"https://www.semanticscholar.org/paper/817a781e26c2eabb068973d3cc0bab9220fa401d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581863540\",\"name\":\"Aidean Sharghi Karganroodi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"550b08b659d3b8e7f45bdc09602af2184791d082\",\"title\":\"Visual-Textual Video Synopsis Generation\",\"url\":\"https://www.semanticscholar.org/paper/550b08b659d3b8e7f45bdc09602af2184791d082\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73919690\",\"name\":\"Nidhinandana Salian\"}],\"doi\":\"10.1007/978-981-13-2907-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2a0048e23a2e88768d155eac351443573cd4f5d\",\"title\":\"Visual Attention and Memory Augmented Activity Recognition and Behavioral Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b2a0048e23a2e88768d155eac351443573cd4f5d\",\"venue\":\"ATIS\",\"year\":2018},{\"arxivId\":\"1702.01528\",\"authors\":[{\"authorId\":\"1751687\",\"name\":\"J. Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f28e2bb46e49799589787e466c3ca966a0897bf7\",\"title\":\"Textually Customized Video Summaries\",\"url\":\"https://www.semanticscholar.org/paper/f28e2bb46e49799589787e466c3ca966a0897bf7\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152242255\",\"name\":\"Sekh Arif Ahmed\"},{\"authorId\":\"3320759\",\"name\":\"D. P. Dogra\"},{\"authorId\":\"32614479\",\"name\":\"S. Kar\"},{\"authorId\":\"31022314\",\"name\":\"R. Patnaik\"},{\"authorId\":\"121945412\",\"name\":\"Seung-Cheol Lee\"},{\"authorId\":\"10044795\",\"name\":\"H. Choi\"},{\"authorId\":\"2682079\",\"name\":\"Gi Pyo Nam\"},{\"authorId\":\"34905652\",\"name\":\"I. Kim\"}],\"doi\":\"10.1109/TITS.2019.2929618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"350de50b61c68ccfdfc49fecb46e720b0bed473c\",\"title\":\"Query-Based Video Synopsis for Intelligent Traffic Monitoring Applications\",\"url\":\"https://www.semanticscholar.org/paper/350de50b61c68ccfdfc49fecb46e720b0bed473c\",\"venue\":\"IEEE Transactions on Intelligent Transportation Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52184535\",\"name\":\"Rintaro Yanagi\"},{\"authorId\":\"3470264\",\"name\":\"R. Togo\"},{\"authorId\":\"144392699\",\"name\":\"T. Ogawa\"},{\"authorId\":\"144029207\",\"name\":\"M. Haseyama\"}],\"doi\":\"10.1109/ICIP.2019.8803177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25a15befd5ee1480cce1d91ff9d3901cc8655463\",\"title\":\"Scene Retrieval for Video Summarization Based on Text-to-Image gan\",\"url\":\"https://www.semanticscholar.org/paper/25a15befd5ee1480cce1d91ff9d3901cc8655463\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"22225647\",\"name\":\"Yaru Ma\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"}],\"doi\":\"10.1016/j.ins.2018.09.050\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"355f786c93cd5daaec9c73d220d73e0d0bb8fb88\",\"title\":\"Query-aware sparse coding for web multi-video summarization\",\"url\":\"https://www.semanticscholar.org/paper/355f786c93cd5daaec9c73d220d73e0d0bb8fb88\",\"venue\":\"Inf. Sci.\",\"year\":2019},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/TCSVT.2019.2898899\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50edb91e92955cedd9151c21716b848d921687ac\",\"title\":\"Construction of Diverse Image Datasets From Web Collections With Limited Labeling\",\"url\":\"https://www.semanticscholar.org/paper/50edb91e92955cedd9151c21716b848d921687ac\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2003.14229\",\"authors\":[{\"authorId\":\"3459502\",\"name\":\"Washington L. S. Ramos\"},{\"authorId\":\"46464798\",\"name\":\"M. Silva\"},{\"authorId\":\"152396628\",\"name\":\"E. Ara\\u00fajo\"},{\"authorId\":\"2211313\",\"name\":\"Leandro Soriano Marcolino\"},{\"authorId\":\"2310152\",\"name\":\"Erickson R. Nascimento\"}],\"doi\":\"10.1109/CVPR42600.2020.01094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"title\":\"Straight to the Point: Fast-Forwarding Videos via Reinforcement Learning Using Textual Data\",\"url\":\"https://www.semanticscholar.org/paper/bdb6f7e36d40d058e22eb7e5fd810a6ad54f057e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.02135\",\"authors\":[{\"authorId\":\"51310095\",\"name\":\"H. Rahmani\"},{\"authorId\":\"2532663\",\"name\":\"Dylan A. Shell\"},{\"authorId\":\"1401066304\",\"name\":\"J. O'Kane\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"ba9099ba78aae548aa5b0b8acd58578185d9f21f\",\"title\":\"Planning to Chronicle\",\"url\":\"https://www.semanticscholar.org/paper/ba9099ba78aae548aa5b0b8acd58578185d9f21f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.06604\",\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.1145/3240508.3240599\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"916218b7fd637d75f644c5ef5f7590c05fabca75\",\"title\":\"PHD-GIFs: Personalized Highlight Detection for Automatic GIF Creation\",\"url\":\"https://www.semanticscholar.org/paper/916218b7fd637d75f644c5ef5f7590c05fabca75\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1808.01575\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01264-9_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"title\":\"Video Re-localization\",\"url\":\"https://www.semanticscholar.org/paper/8619ce85b69e6164cb5bb32f225e510a0570bb37\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2009.05695\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"35260743\",\"name\":\"Han-Pang Chiu\"},{\"authorId\":\"1789477\",\"name\":\"S. Samarasekera\"},{\"authorId\":\"1557362763\",\"name\":\"Rakesh Kumar\"}],\"doi\":\"10.1145/3394171.3413647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"596fd6b55ca8e85b410e41360abd46f9f5373ee1\",\"title\":\"RGB2LIDAR: Towards Solving Large-Scale Cross-Modal Visual Localization\",\"url\":\"https://www.semanticscholar.org/paper/596fd6b55ca8e85b410e41360abd46f9f5373ee1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48056150\",\"name\":\"Huawei Wei\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"3460423\",\"name\":\"Yichao Yan\"},{\"authorId\":\"41030694\",\"name\":\"Huanyu Yu\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"145486463\",\"name\":\"C. Yao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ec09bad57cc81a71ef7596f57e94ee13b380ae3\",\"title\":\"Video Summarization via Semantic Attended Networks\",\"url\":\"https://www.semanticscholar.org/paper/6ec09bad57cc81a71ef7596f57e94ee13b380ae3\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"title\":\"Structured Procedural Knowledge Extraction from Cooking Videos\",\"url\":\"https://www.semanticscholar.org/paper/d2925b1a75c72728d2d90157c1d1057cbc5da8b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.03740\",\"authors\":[{\"authorId\":\"51055350\",\"name\":\"Shuwen Xiao\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1749272\",\"name\":\"Ziyu Guan\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2985868\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"title\":\"Query-Biased Self-Attentive Network for Query-Focused Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/dd93a358c7e441855ba7fd46872099da6dc23b5a\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2115104\",\"name\":\"Wenjia Niu\"},{\"authorId\":\"100613971\",\"name\":\"Gang Li\"},{\"authorId\":\"8190315\",\"name\":\"Jiqiang Liu\"},{\"authorId\":\"40062477\",\"name\":\"J. Tan\"},{\"authorId\":\"72055377\",\"name\":\"L. Guo\"},{\"authorId\":\"114687731\",\"name\":\"Zhen Han\"},{\"authorId\":\"1731028\",\"name\":\"L. Batten\"}],\"doi\":\"10.1007/978-3-662-48683-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"title\":\"Applications and Techniques in Information Security\",\"url\":\"https://www.semanticscholar.org/paper/58f4852816ffc8733c8a687a1b0e38a2c2ee2f2d\",\"venue\":\"Communications in Computer and Information Science\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"48947242\",\"name\":\"Fang Jiao\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1016/j.neucom.2020.04.132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e824b1cdd3e227933f18e7ebf54c4fa3cbcc2534\",\"title\":\"Deep attentive and semantic preserving video summarization\",\"url\":\"https://www.semanticscholar.org/paper/e824b1cdd3e227933f18e7ebf54c4fa3cbcc2534\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1908.03477\",\"authors\":[{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"},{\"authorId\":\"1808423\",\"name\":\"G. Csurka\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee3ea76cc54ffae2cdd9ef0e91e05f39c9810a15\",\"title\":\"Fine-Grained Action Retrieval Through Multiple Parts-of-Speech Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/ee3ea76cc54ffae2cdd9ef0e91e05f39c9810a15\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1909.12948\",\"authors\":[{\"authorId\":\"1405222115\",\"name\":\"K. VivekrajV.\"},{\"authorId\":\"144789994\",\"name\":\"D. Sen\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1145/3347712\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"title\":\"Video Skimming\",\"url\":\"https://www.semanticscholar.org/paper/8bb103f8c16e8342ad3fde754c662e88c7b4cba2\",\"venue\":\"ACM Comput. Surv.\",\"year\":2019}],\"corpusId\":12110031,\"doi\":\"10.1109/CVPR.2017.118\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"06dc33896f94554d67514c8a5e34cad5ff9749bc\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"34724702\",\"name\":\"Joydeep Ghosh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2012.6247820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"616a23ebf79e35033c84797993943013c5dde5a0\",\"title\":\"Discovering important people and objects for egocentric video summarization\",\"url\":\"https://www.semanticscholar.org/paper/616a23ebf79e35033c84797993943013c5dde5a0\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1605.08110\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-46478-7_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"title\":\"Video Summarization with Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/1dbc12e54ceb70f2022f956aa0a46e2706e99962\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"},{\"authorId\":\"1776374\",\"name\":\"Juho Kannala\"},{\"authorId\":\"50664676\",\"name\":\"Mikko Salo\"},{\"authorId\":\"3111194\",\"name\":\"J. Heikkil\\u00e4\"}],\"doi\":\"10.1007/978-3-642-15555-0_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c413d55baf1ee96df29256a879e96daf4c2cc072\",\"title\":\"Segmenting Salient Objects from Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/c413d55baf1ee96df29256a879e96daf4c2cc072\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145718481\",\"name\":\"Min Sun\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1679223\",\"name\":\"S. Seitz\"}],\"doi\":\"10.1007/978-3-319-10590-1_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c7adde982efb24c3786fa2d1f65f40a64e2afbf\",\"title\":\"Ranking Domain-Specific Highlights by Analyzing Edited Videos\",\"url\":\"https://www.semanticscholar.org/paper/5c7adde982efb24c3786fa2d1f65f40a64e2afbf\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1007/978-3-319-10602-1_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"title\":\"Detecting Snap Points in Egocentric Video with a Web Photo Prior\",\"url\":\"https://www.semanticscholar.org/paper/aea8047ec01c18fd3f279e9e7e55822cbd4b4d46\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143616798\",\"name\":\"Zheng Lu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2013.350\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"title\":\"Story-Driven Summarization for Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/996e8c706cc8e726963d3bbc4e761fc2ab68d396\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"2757535\",\"name\":\"Jordi Vallmitjana\"},{\"authorId\":\"1690152\",\"name\":\"Amanda Stent\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1109/CVPR.2015.7299154\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"title\":\"TVSum: Summarizing web videos using titles\",\"url\":\"https://www.semanticscholar.org/paper/cbf89cb4e107fb59e119ae619bcfe48e1964e033\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319574\",\"name\":\"D. Potapov\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-10599-4_35\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"title\":\"Category-Specific Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/558a7e14c7dfe3f65bd5a8ff7b4e59b635306a72\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/CVPR.2014.322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91ee61105749d187f980a1995ace548516969a83\",\"title\":\"Quasi Real-Time Summarization for Consumer Videos\",\"url\":\"https://www.semanticscholar.org/paper/91ee61105749d187f980a1995ace548516969a83\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8678448\",\"name\":\"M. Dorst\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcae70dce393c1796d4f15c7b8bbf0ed6f468be1\",\"title\":\"Distinctive Image Features from Scale-Invariant Keypoints\",\"url\":\"https://www.semanticscholar.org/paper/bcae70dce393c1796d4f15c7b8bbf0ed6f468be1\",\"venue\":\"\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1623397502\",\"name\":\"Saskia Bonjour\"},{\"authorId\":\"1623405226\",\"name\":\"Doutje Lettinga\"},{\"authorId\":\"1623397535\",\"name\":\"Christian Joppke\"}],\"doi\":\"10.1515/9783111576855-009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"776f6d45b38cf048ff30cea41f0cd3ceeefed622\",\"title\":\"D\",\"url\":\"https://www.semanticscholar.org/paper/776f6d45b38cf048ff30cea41f0cd3ceeefed622\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1705564\",\"name\":\"G. Nemhauser\"},{\"authorId\":\"1736128\",\"name\":\"L. Wolsey\"},{\"authorId\":\"143904924\",\"name\":\"M. L. Fisher\"}],\"doi\":\"10.1007/BF01588971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9e43395663f74c581982e9ca97a0d7057a0008c\",\"title\":\"An analysis of approximations for maximizing submodular set functions\\u2014I\",\"url\":\"https://www.semanticscholar.org/paper/b9e43395663f74c581982e9ca97a0d7057a0008c\",\"venue\":\"Math. Program.\",\"year\":1978},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145618952\",\"name\":\"M. A. Smith\"}],\"doi\":\"10.1109/CVPR.1997.609414\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d98302953046ebf4d574d05db26a90db95789cc\",\"title\":\"Video skimming and characterization through the combination of image and language understanding techniques\",\"url\":\"https://www.semanticscholar.org/paper/5d98302953046ebf4d574d05db26a90db95789cc\",\"venue\":\"Proceedings of IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1109/CVPR.2014.538\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2743180fa8b87b313f32a3ad37e9771da2234a1\",\"title\":\"Joint Summarization of Large-Scale Collections of Web Images and Videos for Storyline Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/e2743180fa8b87b313f32a3ad37e9771da2234a1\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33940122\",\"name\":\"Liangda Li\"},{\"authorId\":\"143904275\",\"name\":\"Ke Zhou\"},{\"authorId\":\"1701421\",\"name\":\"G. Xue\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"},{\"authorId\":\"1811427\",\"name\":\"Y. Yu\"}],\"doi\":\"10.1145/1963405.1963448\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3796b557ced6254ab8c96682b3357ef73176c159\",\"title\":\"Video summarization via transferrable structured learning\",\"url\":\"https://www.semanticscholar.org/paper/3796b557ced6254ab8c96682b3357ef73176c159\",\"venue\":\"WWW\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2630832\",\"name\":\"Ryan Gomes\"},{\"authorId\":\"145343838\",\"name\":\"Andreas Krause\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d84925e6b5e2bb88df226ffb267654d74d5a9115\",\"title\":\"Budgeted Nonparametric Learning from Data Streams\",\"url\":\"https://www.semanticscholar.org/paper/d84925e6b5e2bb88df226ffb267654d74d5a9115\",\"venue\":\"ICML\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47446553\",\"name\":\"M. Wang\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"1695820\",\"name\":\"Guangda Li\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TMM.2012.2185041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e9a943f6f0160fc868b77cdb95e35b53f455faa\",\"title\":\"Event Driven Web Video Summarization by Tag Localization and Key-Shot Identification\",\"url\":\"https://www.semanticscholar.org/paper/7e9a943f6f0160fc868b77cdb95e35b53f455faa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1607.05177\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-319-46484-8_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"083986588bdef41ce5f154f9decdd7dc6d39292e\",\"title\":\"Query-Focused Extractive Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/083986588bdef41ce5f154f9decdd7dc6d39292e\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34616723\",\"name\":\"Mehdi Ellouze\"},{\"authorId\":\"1741155\",\"name\":\"N. Boujemaa\"},{\"authorId\":\"144000830\",\"name\":\"A. Alimi\"}],\"doi\":\"10.1016/j.jvcir.2010.01.007\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c9de80bb4f532f2a039ad65fd2aadc3c965fed5\",\"title\":\"IM(S)2: Interactive movie summarization system\",\"url\":\"https://www.semanticscholar.org/paper/5c9de80bb4f532f2a039ad65fd2aadc3c965fed5\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5974329\",\"name\":\"Y. Li\"},{\"authorId\":\"1686820\",\"name\":\"B. M\\u00e9rialdo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"538ff681874c0fa28ccdfc5428560a5d3f8cd7b4\",\"title\":\"Multi-video summarization based on Video-MMR\",\"url\":\"https://www.semanticscholar.org/paper/538ff681874c0fa28ccdfc5428560a5d3f8cd7b4\",\"venue\":\"11th International Workshop on Image Analysis for Multimedia Interactive Services WIAMIS 10\",\"year\":2010},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2015.7298928\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"title\":\"Video summarization by learning submodular mixtures of objectives\",\"url\":\"https://www.semanticscholar.org/paper/cfcb9bcc1e8b4d3451578398aeb37f0fa5614632\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"143979267\",\"name\":\"R. Hamid\"},{\"authorId\":\"1711460\",\"name\":\"C. Lin\"},{\"authorId\":\"145507437\",\"name\":\"N. Sundaresan\"}],\"doi\":\"10.1109/CVPR.2013.348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4b1fd34dabc3bc37aad39279bae9fa06b4a9dac\",\"title\":\"Large-Scale Video Summarization Using Web-Image Priors\",\"url\":\"https://www.semanticscholar.org/paper/e4b1fd34dabc3bc37aad39279bae9fa06b4a9dac\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47376654\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCV.2015.514\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd1e7af7cc6d2dcac839848dd9efdbed87141df0\",\"title\":\"Storyline Representation of Egocentric Videos with an Applications to Story-Based Search\",\"url\":\"https://www.semanticscholar.org/paper/cd1e7af7cc6d2dcac839848dd9efdbed87141df0\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I Vendrov\"},{\"authorId\":null,\"name\":\"R Kiros\"},{\"authorId\":null,\"name\":\"S Fidler\"},{\"authorId\":null,\"name\":\"R Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Orderembeddings of images and language. ICLR\",\"url\":\"\",\"venue\":\"Orderembeddings of images and language. ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145702758\",\"name\":\"Yang Cong\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TMM.2011.2166951\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6f27e57cfcbd71aa01e2f91a314f84dd093b4bc\",\"title\":\"Towards Scalable Summarization of Consumer Videos Via Sparse Dictionary Selection\",\"url\":\"https://www.semanticscholar.org/paper/c6f27e57cfcbd71aa01e2f91a314f84dd093b4bc\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"},{\"authorId\":\"145551629\",\"name\":\"H. Grabner\"},{\"authorId\":\"1848930\",\"name\":\"Hayko Riemenschneider\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-10584-0_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"title\":\"Creating Summaries from User Videos\",\"url\":\"https://www.semanticscholar.org/paper/799bf307438ec2171e6f0bd5b8040f678d5b28da\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735717\",\"name\":\"M. Smith\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"}],\"doi\":\"10.1109/CAIVD.1998.646034\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"390d27ae3ffe41ff8781f09796c8b0c0f1dfd8fa\",\"title\":\"Video skimming and characterization through the combination of image and language understanding\",\"url\":\"https://www.semanticscholar.org/paper/390d27ae3ffe41ff8781f09796c8b0c0f1dfd8fa\",\"venue\":\"Proceedings 1998 IEEE International Workshop on Content-Based Access of Image and Video Database\",\"year\":1998},{\"arxivId\":\"1506.06724\",\"authors\":[{\"authorId\":\"2214033\",\"name\":\"Y. Zhu\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":\"10.1109/ICCV.2015.11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e6824e137847be0599bb0032e37042ed2ef5045\",\"title\":\"Aligning Books and Movies: Towards Story-Like Visual Explanations by Watching Movies and Reading Books\",\"url\":\"https://www.semanticscholar.org/paper/0e6824e137847be0599bb0032e37042ed2ef5045\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2110140\",\"name\":\"Junseok Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/CVPR.2012.6247810\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c06a89927e22f80f456e85de4afb6da6e71ac47e\",\"title\":\"A unified framework for event summarization and rare event detection\",\"url\":\"https://www.semanticscholar.org/paper/c06a89927e22f80f456e85de4afb6da6e71ac47e\",\"venue\":\"CVPR\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"3038150\",\"name\":\"Cherry Che\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2015.7298994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"title\":\"Multi-task deep visual-semantic embedding for video thumbnail selection\",\"url\":\"https://www.semanticscholar.org/paper/562fbe1f8b8a77fbeb2adea42476752246b610e7\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"title\":\"Diverse Sequential Subset Selection for Supervised Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/25da1b119ba1e0bb602be6ce8492d1e33dbac9ff\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1603.03369\",\"authors\":[{\"authorId\":\"47968942\",\"name\":\"K. Zhang\"},{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2016.120\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3db6c8086082acd55f6c95070ad309ecb834517\",\"title\":\"Summary Transfer: Exemplar-Based Subset Selection for Video Summarization\",\"url\":\"https://www.semanticscholar.org/paper/e3db6c8086082acd55f6c95070ad309ecb834517\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1310.1531\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"2368132\",\"name\":\"E. Tzeng\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b8de958fead0d8a9619b55c7299df3257c624a96\",\"title\":\"DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b8de958fead0d8a9619b55c7299df3257c624a96\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1406.5824\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"50706340\",\"name\":\"Alireza Fathi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3a31da018246f4d67c5702574b7c16e14d261541\",\"title\":\"VideoSET: Video Summary Evaluation through Text\",\"url\":\"https://www.semanticscholar.org/paper/3a31da018246f4d67c5702574b7c16e14d261541\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39336289\",\"name\":\"Wen-Sheng Chu\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"},{\"authorId\":\"144633617\",\"name\":\"A. Jaimes\"}],\"doi\":\"10.1109/CVPR.2015.7298981\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"12ac574da38a7ee39307c1eee44eefed727d5eda\",\"title\":\"Video co-summarization: Video summarization by visual co-occurrence\",\"url\":\"https://www.semanticscholar.org/paper/12ac574da38a7ee39307c1eee44eefed727d5eda\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620865361\",\"name\":\"Seguin Hen\"}],\"doi\":\"10.1515/9783111576855-015\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"title\":\"J\",\"url\":\"https://www.semanticscholar.org/paper/048ddf457ea7b87f5b7fadcc797ff35cefa7ffca\",\"venue\":\"Edinburgh Medical and Surgical Journal\",\"year\":1824},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738202556\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2034063\",\"name\":\"F. Ferraro\"},{\"authorId\":\"2400138\",\"name\":\"N. Mostafazadeh\"},{\"authorId\":\"1806773\",\"name\":\"I. Misra\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"50045602\",\"name\":\"Xiaodong He\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1738701211\",\"name\":\"C. Lawrence Zitnick\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"},{\"authorId\":\"1909300\",\"name\":\"Lucy Vanderwende\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"}],\"doi\":\"10.18653/v1/N16-1147\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba7694798333d4670722bb703b7922a0df9a7e7b\",\"title\":\"Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/ba7694798333d4670722bb703b7922a0df9a7e7b\",\"venue\":\"NAACL 2016\",\"year\":2016},{\"arxivId\":\"1511.06361\",\"authors\":[{\"authorId\":\"2210865\",\"name\":\"Ivan Vendrov\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"title\":\"Order-Embeddings of Images and Language\",\"url\":\"https://www.semanticscholar.org/paper/46b8cbcdff87b842c2c1d4a003c831f845096ba7\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119858851\",\"name\":\"J. Xu\"},{\"authorId\":\"144324490\",\"name\":\"Lopamudra Mukherjee\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"40450406\",\"name\":\"J. Warner\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"144711711\",\"name\":\"V. Singh\"}],\"doi\":\"10.1109/CVPR.2015.7298836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"title\":\"Gaze-enabled egocentric video summarization via constrained submodular maximization\",\"url\":\"https://www.semanticscholar.org/paper/2aacb2a897dfddd49bb162d87ca80863ca8ef1c2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3285716\",\"name\":\"Xinye Lin\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"1871246\",\"name\":\"X. Chang\"},{\"authorId\":\"1723807\",\"name\":\"X. Liu\"},{\"authorId\":\"47119262\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3161412\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"299b07ec255398c7f9d147cb39d113e4926cc51b\",\"title\":\"SHOW\",\"url\":\"https://www.semanticscholar.org/paper/299b07ec255398c7f9d147cb39d113e4926cc51b\",\"venue\":\"IMWUT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2955704\",\"name\":\"B. T. Truong\"},{\"authorId\":\"49337894\",\"name\":\"S. Venkatesh\"}],\"doi\":\"10.1145/1198302.1198305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"37e084cdf8b8704b497b2d8e7547380c09468c7b\",\"title\":\"Video abstraction: A systematic review and classification\",\"url\":\"https://www.semanticscholar.org/paper/37e084cdf8b8704b497b2d8e7547380c09468c7b\",\"venue\":\"TOMCCAP\",\"year\":2007},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Enhancing Video Summarization via Vision-Language Embedding\",\"topics\":[{\"topic\":\"Internet\",\"topicId\":\"7952\",\"url\":\"https://www.semanticscholar.org/topic/7952\"},{\"topic\":\"Emily Howell\",\"topicId\":\"1904104\",\"url\":\"https://www.semanticscholar.org/topic/1904104\"},{\"topic\":\"Submodular set function\",\"topicId\":\"86\",\"url\":\"https://www.semanticscholar.org/topic/86\"},{\"topic\":\"Closed-circuit television\",\"topicId\":\"34046\",\"url\":\"https://www.semanticscholar.org/topic/34046\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Instability\",\"topicId\":\"4779\",\"url\":\"https://www.semanticscholar.org/topic/4779\"},{\"topic\":\"Test data\",\"topicId\":\"10175\",\"url\":\"https://www.semanticscholar.org/topic/10175\"},{\"topic\":\"Uncompressed video\",\"topicId\":\"649403\",\"url\":\"https://www.semanticscholar.org/topic/649403\"},{\"topic\":\"UT-VPN\",\"topicId\":\"4390941\",\"url\":\"https://www.semanticscholar.org/topic/4390941\"},{\"topic\":\"Automatic summarization\",\"topicId\":\"36919\",\"url\":\"https://www.semanticscholar.org/topic/36919\"},{\"topic\":\"WAITS\",\"topicId\":\"1391890\",\"url\":\"https://www.semanticscholar.org/topic/1391890\"},{\"topic\":\"User Account Control\",\"topicId\":\"2258360\",\"url\":\"https://www.semanticscholar.org/topic/2258360\"},{\"topic\":\"Larry Laffer\",\"topicId\":\"3868660\",\"url\":\"https://www.semanticscholar.org/topic/3868660\"}],\"url\":\"https://www.semanticscholar.org/paper/06dc33896f94554d67514c8a5e34cad5ff9749bc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"