"{\"abstract\":\"This paper presents a general ConvNet architecture for video action recognition based on multiplicative interactions of spacetime features. Our model combines the appearance and motion pathways of a two-stream architecture by motion gating and is trained end-to-end. We theoretically motivate multiplicative gating functions for residual networks and empirically study their effect on classification accuracy. To capture long-term dependencies we inject identity mapping kernels for learning temporal relationships. Our architecture is fully convolutional in spacetime and able to evaluate a video in a single forward pass. Empirical investigation reveals that our model produces state-of-the-art results on two standard action recognition datasets.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\",\"url\":\"https://www.semanticscholar.org/author/2322150\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\",\"url\":\"https://www.semanticscholar.org/author/1718587\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\",\"url\":\"https://www.semanticscholar.org/author/1709096\"}],\"citationVelocity\":98,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"56f6f093403bafb9a051e20fa15e406c33872c49\",\"title\":\"Supplementary Material : Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/56f6f093403bafb9a051e20fa15e406c33872c49\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"}],\"doi\":\"10.1007/978-3-030-12177-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7f93e107e81125397652c5d2ae4535c5344612\",\"title\":\"Three-Stream Convolution Networks After Background Subtraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d7f93e107e81125397652c5d2ae4535c5344612\",\"venue\":\"FFER/DLPR@ICPR\",\"year\":2018},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/CVPR.2018.00127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"63f7760e25420803ec969dad25ce40c796a21915\",\"title\":\"Recognizing Human Actions as the Evolution of Pose Estimation Maps\",\"url\":\"https://www.semanticscholar.org/paper/63f7760e25420803ec969dad25ce40c796a21915\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.11064\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/CVPR.2018.00234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13d93feb5431eda200ac482b5230f51667c0146a\",\"title\":\"Non-linear Temporal Subspace Representations for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13d93feb5431eda200ac482b5230f51667c0146a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"title\":\"POLITECNICO DI TORINO Master of Science in Mathematical Engineering Deep Learning Algorithms for Video Classification: Application on Real-Time Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089367\",\"name\":\"P. Abreu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d5809d13e9de52ff113575533a029297f737468\",\"title\":\"Augmentation of Two-stream CNN architectures with context and attention for action detection and recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d5809d13e9de52ff113575533a029297f737468\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"2008.01148\",\"authors\":[{\"authorId\":\"2804902\",\"name\":\"M. M. Islam\"},{\"authorId\":\"32229358\",\"name\":\"Tariq Iqbal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab3f612125a13410373c33600abd3fccdf79ce31\",\"title\":\"HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/ab3f612125a13410373c33600abd3fccdf79ce31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.12919\",\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"152477216\",\"name\":\"P. Abreu\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"102c5f96b879de46921cfc1f589dbc364310cf54\",\"title\":\"Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/102c5f96b879de46921cfc1f589dbc364310cf54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144997028\",\"name\":\"L. Li\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"title\":\"Deep Temporal Feature Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2894025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"title\":\"Spatiotemporal Relation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48890447\",\"name\":\"Tauseef Ali\"},{\"authorId\":\"145677430\",\"name\":\"Eissa Jaber Alreshidi\"}],\"doi\":\"10.20944/PREPRINTS201905.0350.V1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"30f92e6e2e89377834df4f1332c640ad55efb743\",\"title\":\"Identifying Human Behavious Using Deep Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/30f92e6e2e89377834df4f1332c640ad55efb743\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"32281398\",\"name\":\"V. Q. Tran\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"}],\"doi\":\"10.1109/FG.2018.00076\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bb36c875754a2a8919f2f9b00a336c00006e453\",\"title\":\"Eigen-Evolution Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2bb36c875754a2a8919f2f9b00a336c00006e453\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48354916\",\"name\":\"Ze Chen\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3297097.3297107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9fff8a34942053fd93760c8c84a40849b9db734\",\"title\":\"Recurrent Spatiotemporal Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9fff8a34942053fd93760c8c84a40849b9db734\",\"venue\":\"ICRAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2698604\",\"name\":\"J. Miyao\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1007/978-981-15-4818-5_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b57e0f07d5752e30d8becd80d78dfeae3a1d62b2\",\"title\":\"Short-Term Action Recognition by 3D Convolutional Neural Network with Pixel-Wise Evidences\",\"url\":\"https://www.semanticscholar.org/paper/b57e0f07d5752e30d8becd80d78dfeae3a1d62b2\",\"venue\":\"IW-FCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"88728572\",\"name\":\"Yalong Jia\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00103\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"title\":\"Channel-wise Temporal Attention Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1903.01197\",\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.1109/CVPR.2019.00806\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"title\":\"Collaborative Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.02236\",\"authors\":[{\"authorId\":\"145677430\",\"name\":\"Eissa Jaber Alreshidi\"},{\"authorId\":\"46837214\",\"name\":\"Mohammad Bilal\"}],\"doi\":\"10.5121/sipij.2019.10102\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"382e1bbc50529175c1c2b9f17d9392ae7b7b1dda\",\"title\":\"Characterizing Human Behaviours Using Statistical Motion Descriptor\",\"url\":\"https://www.semanticscholar.org/paper/382e1bbc50529175c1c2b9f17d9392ae7b7b1dda\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49658876\",\"name\":\"Z. Zhu\"},{\"authorId\":\"153172093\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"73312165\",\"name\":\"Wen-bo Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.12.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"title\":\"Nonlinear gated channels networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1845915519\",\"name\":\"Eric Kasangu Lubamba\"},{\"authorId\":\"92581630\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3008848\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5c7c4556126f7219886cd28e4f33c85586f24955\",\"title\":\"Action Prediction Based on Partial Video Observation via Context and Temporal Sequential Network With Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/5c7c4556126f7219886cd28e4f33c85586f24955\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145382418\",\"name\":\"P. Narayana\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"title\":\"Improving gesture recognition through spatial focus of attention\",\"url\":\"https://www.semanticscholar.org/paper/a2cfa3c1ba5b607b3d1136beda4f5127f82a73a9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52224898\",\"name\":\"Patrick Weyers\"},{\"authorId\":\"1778586\",\"name\":\"David Schiebener\"},{\"authorId\":\"31335306\",\"name\":\"A. Kummert\"}],\"doi\":\"10.1109/ITSC.2019.8917139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aabe0e2ee00a25754f1549eeea0cfc2e2339f8a4\",\"title\":\"Action and Object Interaction Recognition for Driver Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/aabe0e2ee00a25754f1549eeea0cfc2e2339f8a4\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145505204\",\"name\":\"J. Guo\"},{\"authorId\":\"2245433\",\"name\":\"Hao Bai\"},{\"authorId\":\"2238603\",\"name\":\"Z. Tang\"},{\"authorId\":\"47569011\",\"name\":\"P. Xu\"},{\"authorId\":\"1723390275\",\"name\":\"Daguang Gan\"},{\"authorId\":\"50677991\",\"name\":\"B. Liu\"}],\"doi\":\"10.1007/s11042-020-08998-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3d45565c3dd515afdf7f90510a410e918b3c4d8\",\"title\":\"Multi modal human action recognition for video content matching\",\"url\":\"https://www.semanticscholar.org/paper/f3d45565c3dd515afdf7f90510a410e918b3c4d8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48147932\",\"name\":\"Zhengyu Zhu\"},{\"authorId\":\"39241333\",\"name\":\"Bing Liu\"},{\"authorId\":\"145782887\",\"name\":\"Y. Rao\"},{\"authorId\":\"50383679\",\"name\":\"Qiao Liu\"},{\"authorId\":\"144142364\",\"name\":\"R. Zhang\"}],\"doi\":\"10.1109/ACCESS.2019.2903161\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"be2e3d014bb93d3ad17b10d8ccd665b69fc8afa4\",\"title\":\"STResNet_CF Tracker: The Deep Spatiotemporal Features Learning for Correlation Filter Based Robust Visual Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/be2e3d014bb93d3ad17b10d8ccd665b69fc8afa4\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1905.13209\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"title\":\"AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures\",\"url\":\"https://www.semanticscholar.org/paper/a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738469\",\"name\":\"A. Tapus\"},{\"authorId\":\"32045772\",\"name\":\"A. Bandera\"},{\"authorId\":\"1754151\",\"name\":\"R. Mart\\u00edn\"},{\"authorId\":\"2258049\",\"name\":\"L. Calderita\"}],\"doi\":\"10.1016/j.patrec.2018.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4248b25edbfcfa3889c55e49d3576bed685168\",\"title\":\"Perceiving the person and their interactions with the others for social robotics - A review\",\"url\":\"https://www.semanticscholar.org/paper/3d4248b25edbfcfa3889c55e49d3576bed685168\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.03258\",\"authors\":[{\"authorId\":\"9179750\",\"name\":\"Omar Hommos\"},{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-030-11024-6_51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23dbada22825613e7c616eb60af0c8a812372f3b\",\"title\":\"Using phase instead of optical flow for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/23dbada22825613e7c616eb60af0c8a812372f3b\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1706.06905\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"title\":\"Learnable pooling with Context Gating for video classification\",\"url\":\"https://www.semanticscholar.org/paper/1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2253198\",\"name\":\"S. Mishra\"},{\"authorId\":\"2091875\",\"name\":\"T. K. Mishra\"},{\"authorId\":\"91464062\",\"name\":\"G. Sanyal\"},{\"authorId\":\"150031446\",\"name\":\"A. Sarkar\"},{\"authorId\":\"68993678\",\"name\":\"S. C. Satapathy\"}],\"doi\":\"10.1016/j.patrec.2020.04.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"314df7f1e314252c60fc8f9eb927a36e0abf7d6a\",\"title\":\"Real time human action recognition using triggered frame extraction and a typical CNN heuristic\",\"url\":\"https://www.semanticscholar.org/paper/314df7f1e314252c60fc8f9eb927a36e0abf7d6a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"2004.01225\",\"authors\":[{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":\"10.1109/ICCVW.2019.00164\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"title\":\"Temporal Accumulative Features for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8092281\",\"name\":\"Hai-Hong Phan\"},{\"authorId\":\"9923528\",\"name\":\"Chi Trung Ha\"},{\"authorId\":\"47523551\",\"name\":\"T. T. Nguy\\u1ec5n\"}],\"doi\":\"10.1109/MAPR49794.2020.9237772\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"title\":\"Improving the efficiency of human action recognition using deep compression\",\"url\":\"https://www.semanticscholar.org/paper/14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"venue\":\"2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30469750\",\"name\":\"Qiuxia Lai\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"145947590\",\"name\":\"Hanqiu Sun\"},{\"authorId\":\"11901550\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2019.2936112\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"title\":\"Video Saliency Prediction Using Spatiotemporal Residual Attentive Networks\",\"url\":\"https://www.semanticscholar.org/paper/be34dd48c374b0313db1f0b70347464cbe0b8f22\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"34765265\",\"name\":\"C. Yang\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2019.00013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcdf68e007737ebae40e27239b3340b236337f03\",\"title\":\"Video Action Recognition With an Additional End-to-End Trained Temporal Stream\",\"url\":\"https://www.semanticscholar.org/paper/dcdf68e007737ebae40e27239b3340b236337f03\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2205175\",\"name\":\"X. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e500d4cee87ef6b06cf9a22dd546d34ad05a66f\",\"title\":\"Spatio-Temporal Associative Representation for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/7e500d4cee87ef6b06cf9a22dd546d34ad05a66f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1804.10021\",\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"2404621\",\"name\":\"Hanlin Qin\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e03419db32dd1a68394a545dcc400653df58f5\",\"title\":\"Deep Keyframe Detection in Human Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/22e03419db32dd1a68394a545dcc400653df58f5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.13080\",\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019167\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3fc2a67967b1355609094175f19b2412dd4851d\",\"title\":\"Memory-Augmented Temporal Dynamic Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e3fc2a67967b1355609094175f19b2412dd4851d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631862\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/s11042-019-7700-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad6493b57050955d9686b3c1fc84a19195852f8c\",\"title\":\"Computer vision based working environment monitoring to analyze Generalized Anxiety Disorder (GAD)\",\"url\":\"https://www.semanticscholar.org/paper/ad6493b57050955d9686b3c1fc84a19195852f8c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381769372\",\"name\":\"D. Srihari\"},{\"authorId\":\"144186025\",\"name\":\"P. Kishore\"},{\"authorId\":\"79324299\",\"name\":\"Kiran Kumar Eepuri\"},{\"authorId\":\"41212177\",\"name\":\"D. Kumar\"},{\"authorId\":\"48387925\",\"name\":\"Maddala Teja Kiran Kumar\"},{\"authorId\":\"1477672383\",\"name\":\"M. D. Prasad\"},{\"authorId\":\"9177966\",\"name\":\"C. R. Prasad\"}],\"doi\":\"10.1007/s11042-019-08588-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ba232488d9082c0f14bc568d42d5a44a4e867a1\",\"title\":\"A four-stream ConvNet based on spatial and depth flow for human action classification using RGB-D data\",\"url\":\"https://www.semanticscholar.org/paper/4ba232488d9082c0f14bc568d42d5a44a4e867a1\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1912.01127\",\"authors\":[{\"authorId\":\"48511110\",\"name\":\"Tianqi Liu\"},{\"authorId\":\"1441128337\",\"name\":\"Qizhan Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7706ed62e51487ee1fab56f932f5274bdeaea171\",\"title\":\"BERT for Large-scale Video Segment Classification with Test-time Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/7706ed62e51487ee1fab56f932f5274bdeaea171\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.09892\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1007/978-3-030-03840-3_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"title\":\"Top-down Attention Recurrent VLAD Encoding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"venue\":\"AI*IA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3432961\",\"name\":\"Wukui Yang\"},{\"authorId\":\"145468103\",\"name\":\"S. Gao\"},{\"authorId\":\"38836749\",\"name\":\"Wenran Liu\"},{\"authorId\":\"7807689\",\"name\":\"Xiangyang Ji\"}],\"doi\":\"10.1109/MMSP.2018.8547088\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4761b47c3f259559740c90bd42ed8442249499d\",\"title\":\"3-Stream Convolutional Networks for Video Action Recognition with Hybrid Motion Field\",\"url\":\"https://www.semanticscholar.org/paper/c4761b47c3f259559740c90bd42ed8442249499d\",\"venue\":\"2018 IEEE 20th International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/DICTA.2018.8615804\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db86679d00baab8e21b436e05c17a661257ad8fd\",\"title\":\"Similar Gesture Recognition using Hierarchical Classification Approach in RGB Videos\",\"url\":\"https://www.semanticscholar.org/paper/db86679d00baab8e21b436e05c17a661257ad8fd\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"},{\"authorId\":\"143624101\",\"name\":\"R. Zhao\"},{\"authorId\":\"145974119\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144847940\",\"name\":\"K. Lam\"}],\"doi\":\"10.1109/LSP.2020.3011326\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c232519f402375a404ac74f02451807c3fa3aa3c\",\"title\":\"Progressive Motion Representation Distillation With Two-Branch Networks for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c232519f402375a404ac74f02451807c3fa3aa3c\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.15336\",\"authors\":[{\"authorId\":\"144850780\",\"name\":\"Haoyuan Zhang\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"151502410\",\"name\":\"Zihui Guo\"},{\"authorId\":\"1752792230\",\"name\":\"Wanqing Li\"}],\"doi\":\"10.1016/j.jvcir.2020.102942\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7997b15e6b91fba0f7af6596e12a303ff7de8223\",\"title\":\"SAR-NAS: Skeleton-based Action Recognition via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/7997b15e6b91fba0f7af6596e12a303ff7de8223\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":\"2008.10869\",\"authors\":[{\"authorId\":\"1405226912\",\"name\":\"D. Fern\\u00e1ndez-Llorca\"},{\"authorId\":\"24057066\",\"name\":\"Mahdi Biparva\"},{\"authorId\":\"1905637731\",\"name\":\"Rub'en Izquierdo-Gonzalo\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/ITSC45102.2020.9294326\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"184ac4dcd301ff465a2af83da7680f276647f2f1\",\"title\":\"Two-Stream Networks for Lane-Change Prediction of Surrounding Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/184ac4dcd301ff465a2af83da7680f276647f2f1\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"1811.11875\",\"authors\":[{\"authorId\":\"52121635\",\"name\":\"Nathan Inkawhich\"},{\"authorId\":\"52117082\",\"name\":\"Matthew Inkawhich\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"},{\"authorId\":\"47892815\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"title\":\"Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1453694581\",\"name\":\"Lubamba Kasangu Eric\"},{\"authorId\":\"49503455\",\"name\":\"Rabia Tahir\"},{\"authorId\":\"47605260\",\"name\":\"M. Li\"}],\"doi\":\"10.1007/978-3-030-32456-8_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4f8bccea93b03ceb7fbe38080a826a8f87a6dc8\",\"title\":\"Capsule Recurrent Neural Network with Weight Update Using Dynamic Routing by Agreement: A Unified Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e4f8bccea93b03ceb7fbe38080a826a8f87a6dc8\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICASSP.2019.8683035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52373cd152e2afdc7e8c75025b2c9a02509bb2c1\",\"title\":\"Deep Temporal Pyramid Design for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/52373cd152e2afdc7e8c75025b2c9a02509bb2c1\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":\"10.1109/WACV.2019.00128\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"db70e64fb69c64f174fd97ab86566373504fd702\",\"title\":\"Memory Warps for Long-Term Online Video Representations and Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/db70e64fb69c64f174fd97ab86566373504fd702\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"30477181\",\"name\":\"Yie-Tarng Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1007/978-3-030-58452-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f62e6f851da560037f1ed008d2eb51bb80f062\",\"title\":\"Empowering Relational Network by Self-attention Augmented Conditional Random Fields for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33f62e6f851da560037f1ed008d2eb51bb80f062\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403194286\",\"name\":\"Omar Costilla-Reyes\"},{\"authorId\":\"1402712530\",\"name\":\"R. Vera-Rodr\\u00edguez\"},{\"authorId\":\"151379036\",\"name\":\"Abdullah S. Alharthi\"},{\"authorId\":\"103667326\",\"name\":\"S. U. Yunas\"},{\"authorId\":\"3038893\",\"name\":\"K. Ozanyan\"}],\"doi\":\"10.1007/978-3-030-31760-7_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5d1ecd5378254a48c38a7c786efb23b9ad5feec\",\"title\":\"Deep learning in gait analysis for security and healthcare\",\"url\":\"https://www.semanticscholar.org/paper/d5d1ecd5378254a48c38a7c786efb23b9ad5feec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144230956\",\"name\":\"Bo Huang\"},{\"authorId\":\"28899830\",\"name\":\"Hualong Huang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-319-70090-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89b279005e08a4936365eadbaea3bba1477188fb\",\"title\":\"Convolutional Gated Recurrent Units Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89b279005e08a4936365eadbaea3bba1477188fb\",\"venue\":\"ICONIP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1803.08834\",\"authors\":[{\"authorId\":\"3314448\",\"name\":\"Isma Hadji\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"title\":\"What Do We Understand About Convolutional Networks?\",\"url\":\"https://www.semanticscholar.org/paper/5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"23911916\",\"name\":\"Mehrtash Harandi\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"},{\"authorId\":\"143775741\",\"name\":\"W. Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/TIP.2018.2877936\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"title\":\"Toward Efficient Action Recognition: Principal Backpropagation for Training Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/f5b8894cf0606b991a913b84a2a3e8b43e4c32de\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1908.03885\",\"authors\":[{\"authorId\":\"3471257\",\"name\":\"Xinqian Gu\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/ICCV.2019.00974\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"643eb627d2e25fa1281616d729d0b2bd0b483546\",\"title\":\"Temporal Knowledge Propagation for Image-to-Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/643eb627d2e25fa1281616d729d0b2bd0b483546\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7360d2f4d84ad6d43090810c9a0a2e0a071027b5\",\"title\":\"MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7360d2f4d84ad6d43090810c9a0a2e0a071027b5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14516821\",\"name\":\"Ganesh Yaparla\"},{\"authorId\":\"32339189\",\"name\":\"Allaparthi Sriteja\"},{\"authorId\":\"9585601\",\"name\":\"Sai Krishna Munnangi\"},{\"authorId\":\"143674379\",\"name\":\"G. R. Murthy\"}],\"doi\":\"10.1007/978-3-030-20518-8_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1899d96326b67dc222500b0d8689ebad7c8dafd\",\"title\":\"A Novel Framework for Fine Grained Action Recognition in Soccer\",\"url\":\"https://www.semanticscholar.org/paper/b1899d96326b67dc222500b0d8689ebad7c8dafd\",\"venue\":\"IWANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150340806\",\"name\":\"W. Yan\"},{\"authorId\":\"48146797\",\"name\":\"Yue Gao\"},{\"authorId\":\"92581619\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1109/ISASS.2019.8757767\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b14ffb6049bd5502a8a41e9a3b7bc7cf97e8f2cb\",\"title\":\"Human-object Interaction Recognition Using Multitask Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b14ffb6049bd5502a8a41e9a3b7bc7cf97e8f2cb\",\"venue\":\"2019 3rd International Symposium on Autonomous Systems (ISAS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2007.00822\",\"authors\":[{\"authorId\":\"3248862\",\"name\":\"Buyu Liu\"},{\"authorId\":\"1849328\",\"name\":\"Bingbing Zhuang\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50478588\",\"name\":\"P. Ji\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"}],\"doi\":\"10.1109/cvpr42600.2020.00447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fef9d2d44f380b937260f01b4453944273e08979\",\"title\":\"Understanding Road Layout From Videos as a Whole\",\"url\":\"https://www.semanticscholar.org/paper/fef9d2d44f380b937260f01b4453944273e08979\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.00380\",\"authors\":[{\"authorId\":\"47927774\",\"name\":\"S. Majumder\"},{\"authorId\":\"30567641\",\"name\":\"N. Kehtarnavaz\"}],\"doi\":\"10.1109/jsen.2020.3022326\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2ab20776490577cd274f3b0105250cba4084228\",\"title\":\"Vision and Inertial Sensing Fusion for Human Action Recognition : A Review\",\"url\":\"https://www.semanticscholar.org/paper/d2ab20776490577cd274f3b0105250cba4084228\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.13607\",\"authors\":[{\"authorId\":\"119413444\",\"name\":\"G. Storey\"},{\"authorId\":\"144725605\",\"name\":\"R. Jiang\"},{\"authorId\":\"32676664\",\"name\":\"Shelagh Keogh\"},{\"authorId\":\"1690116\",\"name\":\"A. Bouridane\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/ACCESS.2019.2937285\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"title\":\"3DPalsyNet: A Facial Palsy Grading and Motion Recognition Framework Using Fully 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/860927c6bda80ff6eb8ef4d6fdb8753c255def15\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2006.13608\",\"authors\":[{\"authorId\":\"1739188006\",\"name\":\"Sheng-Yu Zhang\"},{\"authorId\":\"3856602\",\"name\":\"Ziqi Tan\"},{\"authorId\":\"145919748\",\"name\":\"Jin Yu\"},{\"authorId\":\"50144812\",\"name\":\"Z. Zhao\"},{\"authorId\":\"33870528\",\"name\":\"Kun Kuang\"},{\"authorId\":\"71328060\",\"name\":\"T. Jiang\"},{\"authorId\":\"1709595\",\"name\":\"Jingren Zhou\"},{\"authorId\":\"38385080\",\"name\":\"Hongxia Yang\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3394486.3403325\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d271e93c7566b231e560c48b4cc4942077d762f9\",\"title\":\"Comprehensive Information Integration Modeling Framework for Video Titling\",\"url\":\"https://www.semanticscholar.org/paper/d271e93c7566b231e560c48b4cc4942077d762f9\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2012.10671\",\"authors\":[{\"authorId\":\"152957752\",\"name\":\"Shreyank N Gowda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"title\":\"SMART Frame Selection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.02632\",\"authors\":[{\"authorId\":\"52025559\",\"name\":\"Mahsa Ehsanpour\"},{\"authorId\":\"3447236\",\"name\":\"A. Abedin\"},{\"authorId\":\"19170799\",\"name\":\"F. Saleh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1007/978-3-030-58545-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81287e31f3e659aaedb5dce0646ba2b86377b282\",\"title\":\"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/81287e31f3e659aaedb5dce0646ba2b86377b282\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089882\",\"name\":\"Haiyang Jiang\"},{\"authorId\":\"7303419\",\"name\":\"Yaozong Pan\"},{\"authorId\":\"101594813\",\"name\":\"J. Zhang\"},{\"authorId\":\"145664195\",\"name\":\"H. Yang\"}],\"doi\":\"10.3390/SYM11060761\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"title\":\"Battlefield Target Aggregation Behavior Recognition Model Based on Multi-Scale Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1582379748\",\"name\":\"Lagunes Fortiz\"},{\"authorId\":\"1381305081\",\"name\":\"A Miguel\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"e7d2e0d31378ace9deeddbdc2b3623602e1c3e29\",\"title\":\"Deep in-situ learning for object recognition\",\"url\":\"https://www.semanticscholar.org/paper/e7d2e0d31378ace9deeddbdc2b3623602e1c3e29\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.07468\",\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1609/aaai.v33i01.33018618\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"title\":\"Multi-scale 3D Convolution Network for Video Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.3233/IA-190021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"title\":\"Top-down attention recurrent VLAD encoding for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"venue\":\"Intelligenza Artificiale\",\"year\":2019},{\"arxivId\":\"1712.08416\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2699340\",\"name\":\"Yiyi Liao\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"150013821\",\"name\":\"A. Geiger\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"title\":\"On the Integration of Optical Flow and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6486893\",\"name\":\"Chao Pu\"},{\"authorId\":null,\"name\":\"Hikvision\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88997434c3dcfe1b9355edae84c78429e423600c\",\"title\":\"Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88997434c3dcfe1b9355edae84c78429e423600c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134701532\",\"name\":\"Siddharth Buddhiraju\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef31237ffea3256c46db8a0227563f95c7c34721\",\"title\":\"Tennis Shot Recognition through Spatiotemporal Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ef31237ffea3256c46db8a0227563f95c7c34721\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23b737af93469efc4b7438377a3cec2e9c8febb\",\"title\":\"Ju l 2 01 8 Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f23b737af93469efc4b7438377a3cec2e9c8febb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1804.04810\",\"authors\":[{\"authorId\":\"143758901\",\"name\":\"Jungbeom Lee\"},{\"authorId\":\"2808551\",\"name\":\"Jangho Lee\"},{\"authorId\":\"47090426\",\"name\":\"Sungmin Lee\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3497be24bcecb698a700b02c12e23b305ea0c24c\",\"title\":\"MSnet: Mutual Suppression Network for Disentangled Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/3497be24bcecb698a700b02c12e23b305ea0c24c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.10950\",\"authors\":[{\"authorId\":\"1737817225\",\"name\":\"Zhen Yu\"},{\"authorId\":\"50004409\",\"name\":\"J. Nguyen\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"47623309\",\"name\":\"J. Kelly\"},{\"authorId\":\"143682056\",\"name\":\"C. Mclean\"},{\"authorId\":\"153824047\",\"name\":\"L. Zhang\"},{\"authorId\":\"153804224\",\"name\":\"V. Mar\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bca8cf9045acc94349bafe7d33a7a8aed4e8191\",\"title\":\"Melanoma Diagnosis with Spatio-Temporal Feature Learning on Sequential Dermoscopic Images\",\"url\":\"https://www.semanticscholar.org/paper/2bca8cf9045acc94349bafe7d33a7a8aed4e8191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48152327\",\"name\":\"Wei Liu\"},{\"authorId\":\"3213583\",\"name\":\"Xianglin Huang\"},{\"authorId\":\"144380740\",\"name\":\"Gang Cao\"},{\"authorId\":\"101594818\",\"name\":\"Jianglong Zhang\"},{\"authorId\":\"51235668\",\"name\":\"G. Song\"},{\"authorId\":\"49576045\",\"name\":\"Lifang Yang\"}],\"doi\":\"10.1109/ACCESS.2019.2922430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"adbbe2005c921a9486e880506b078960dd8caf8c\",\"title\":\"Joint Learning of NNeXtVLAD, CNN and Context Gating for Micro-Video Venue Classification\",\"url\":\"https://www.semanticscholar.org/paper/adbbe2005c921a9486e880506b078960dd8caf8c\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2006.15617\",\"authors\":[{\"authorId\":\"1390625723\",\"name\":\"Zhihao Liu\"},{\"authorId\":\"153010888\",\"name\":\"Hailiang Yin\"},{\"authorId\":\"1737825594\",\"name\":\"Y. Mi\"},{\"authorId\":\"51516578\",\"name\":\"Mengyang Pu\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b41b79d35605cec59f36642c375a18b58d45144\",\"title\":\"Shadow Removal by a Lightness-Guided Network with Training on Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/0b41b79d35605cec59f36642c375a18b58d45144\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71003925\",\"name\":\"Jusong Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"9100047\",\"name\":\"Hainan Li\"},{\"authorId\":\"1390900682\",\"name\":\"S. Wang\"},{\"authorId\":null,\"name\":\"Liang Liu\"}],\"doi\":\"10.1109/ICDMW.2019.00098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"title\":\"Dynamic Spatio-Temporal Feature Learning via Graph Convolution in 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7fc246181ac6c8b1eb9cb138dd34d35b7dde1a74\",\"venue\":\"2019 International Conference on Data Mining Workshops (ICDMW)\",\"year\":2019},{\"arxivId\":\"1708.06250\",\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"501bfe67683ddfecf3710f5946c3b77f1ffe9adf\",\"title\":\"Pillar Networks++: Distributed non-parametric deep and wide networks\",\"url\":\"https://www.semanticscholar.org/paper/501bfe67683ddfecf3710f5946c3b77f1ffe9adf\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491438016\",\"name\":\"Yuanye Fang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-030-39431-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"title\":\"Action Recognition in Videos with Temporal Segments Fusions\",\"url\":\"https://www.semanticscholar.org/paper/d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"46583677\",\"name\":\"J. Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"},{\"authorId\":\"1776581\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Global-Local Temporal Representations for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2083603\",\"name\":\"Tianfei Zhou\"},{\"authorId\":\"47785924\",\"name\":\"Jianwu Li\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"},{\"authorId\":\"47599902\",\"name\":\"R. Tao\"},{\"authorId\":\"145953515\",\"name\":\"J. Shen\"}],\"doi\":\"10.1109/TIP.2020.3013162\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"title\":\"MATNet: Motion-Attentive Transition Network for Zero-Shot Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a633a8537a0e5d0ac28ea3dec36caae5777d9ce7\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.15244\",\"authors\":[{\"authorId\":\"1841089935\",\"name\":\"Mahdi Davoodikakhki\"},{\"authorId\":\"153505292\",\"name\":\"KangKang Yin\"}],\"doi\":\"10.1007/978-3-030-64556-4_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0359520036f33beea638b979d515c170420ac37b\",\"title\":\"Hierarchical Action Classification with Network Pruning\",\"url\":\"https://www.semanticscholar.org/paper/0359520036f33beea638b979d515c170420ac37b\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2001.11657\",\"authors\":[{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/tip.2020.2967577\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"title\":\"Modality Compensation Network: Cross-Modal Adaptation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4d22e56c688b18b9e28fd20dc31a31c3594aad1f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"102868457\",\"name\":\"W. Li\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144410724\",\"name\":\"K. Jin\"}],\"doi\":\"10.1145/3234804.3234821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"title\":\"Local Feature Analysis for real-time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"venue\":\"ICDLT '18\",\"year\":2018},{\"arxivId\":\"1805.08484\",\"authors\":[{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"47539600\",\"name\":\"Jinjin Zhang\"},{\"authorId\":\"39927579\",\"name\":\"Chenyang Si\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d1694200f2fe0676985a8cfe467f9ae010eb3e57\",\"title\":\"Pose-Based Two-Stream Relational Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d1694200f2fe0676985a8cfe467f9ae010eb3e57\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3314448\",\"name\":\"Isma Hadji\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-01264-9_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d6b8ae4262a589f4d6bfaf91d0458e593a7a6fb1\",\"title\":\"A New Large Scale Dynamic Texture Dataset with Application to ConvNet Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d6b8ae4262a589f4d6bfaf91d0458e593a7a6fb1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.10700\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"144585402\",\"name\":\"Peng Zhang\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3343031.3351040\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"title\":\"Explainable Video Action Reasoning via Prior Knowledge and State Transitions\",\"url\":\"https://www.semanticscholar.org/paper/7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66148232\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":\"10.1109/ICCV.2019.00879\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70660cb3af4e19c74681238c7854e3d341654b2d\",\"title\":\"Hallucinating IDT Descriptors and I3D Optical Flow Features for Action Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/70660cb3af4e19c74681238c7854e3d341654b2d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"50695792\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ICME.2019.00182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdfcaf729fea332fc0a259143c406cee51303854\",\"title\":\"Recognizing Micro Actions in Videos: Learning Motion Details via Segment-Level Temporal Pyramid\",\"url\":\"https://www.semanticscholar.org/paper/fdfcaf729fea332fc0a259143c406cee51303854\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49663634\",\"name\":\"W. Liu\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"18318910\",\"name\":\"J. Zhang\"},{\"authorId\":\"10784631\",\"name\":\"Zhonghao Wu\"}],\"doi\":\"10.1109/ICIP.2018.8451095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"901aba97a30b6e7a7aa6093fa72f5b9f7cd9d896\",\"title\":\"Global for Coarse and Part for Fine: A Hierarchical Action Recognition Framework\",\"url\":\"https://www.semanticscholar.org/paper/901aba97a30b6e7a7aa6093fa72f5b9f7cd9d896\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49070466\",\"name\":\"Y. Chen\"},{\"authorId\":\"153533840\",\"name\":\"Y. Zhang\"},{\"authorId\":\"32726318\",\"name\":\"Jing Xin\"},{\"authorId\":\"153043045\",\"name\":\"G. Wang\"},{\"authorId\":\"50714320\",\"name\":\"Lingxia Mu\"},{\"authorId\":\"47108475\",\"name\":\"Yingmin Yi\"},{\"authorId\":\"101055746\",\"name\":\"Han Liu\"},{\"authorId\":\"1771885\",\"name\":\"Ding Liu\"}],\"doi\":\"10.1109/ICIEA.2019.8833958\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3139c9f6d1e09b4965fa5f78701b10a3851e4f\",\"title\":\"UAV Image-based Forest Fire Detection Approach Using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/0d3139c9f6d1e09b4965fa5f78701b10a3851e4f\",\"venue\":\"2019 14th IEEE Conference on Industrial Electronics and Applications (ICIEA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403243307\",\"name\":\"Maryam Asadi-Aghbolaghi\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"9762642\",\"name\":\"Marco Bellantonio\"},{\"authorId\":\"1742688\",\"name\":\"H. Escalante\"},{\"authorId\":\"1402295723\",\"name\":\"V\\u00edctor Ponce-L\\u00f3pez\"},{\"authorId\":\"46176857\",\"name\":\"X. Bar\\u00f3\"},{\"authorId\":\"51243976\",\"name\":\"Isabelle Guyon\"},{\"authorId\":\"1411108625\",\"name\":\"Shohreh Kasaei\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":\"10.1007/978-3-319-57021-1_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"title\":\"Deep Learning for Action and Gesture Recognition in Image Sequences: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/49961d6c2cc42276ff5c5af47687dd9b860bc578\",\"venue\":\"Gesture Recognition\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"2012.14426\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"title\":\"Deep Learning Towards Edge Computing: Neural Networks Straight from Compressed Data\",\"url\":\"https://www.semanticscholar.org/paper/1e8708dec2d5177956c2eb3d56162ffad11f85d2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"72399895\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"title\":\"Multi-kernel learning of deep convolutional features for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/368ce0bb4d4e8e11001857c367d51658fcb225a2\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"Mahmoud Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"46285941\",\"name\":\"Yanyan Yang\"},{\"authorId\":\"105033173\",\"name\":\"David Ndzi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"title\":\"UWS Academic Portal Deep learning of fuzzy weighted multi-resolution depth motion maps with spatial feature fusion for action recognition Al-Faris,\",\"url\":\"https://www.semanticscholar.org/paper/728ebcbb1064a54eaea6cb864056876ca41f3a7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.10553\",\"authors\":[{\"authorId\":\"1587802238\",\"name\":\"Ifrah Idrees\"},{\"authorId\":\"1684347\",\"name\":\"S. Reiss\"},{\"authorId\":\"2913681\",\"name\":\"Stefanie Tellex\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b59ad020f7393319f969399790ad584c4068fda3\",\"title\":\"RoboMem: Giving Long Term Memory to Robots\",\"url\":\"https://www.semanticscholar.org/paper/b59ad020f7393319f969399790ad584c4068fda3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01225-w\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43cbabdac51091773d1b003d76adaf8426d17b24\",\"title\":\"Deep Insights into Convolutional Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/43cbabdac51091773d1b003d76adaf8426d17b24\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.10049\",\"authors\":[{\"authorId\":\"47787021\",\"name\":\"J. Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TIP.2020.2972108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Multi-Scale Temporal Cues Learning for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81188084\",\"name\":\"Saima Nazir\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"},{\"authorId\":\"145643264\",\"name\":\"E. Izquierdo\"},{\"authorId\":\"30902466\",\"name\":\"Eduard Vazquez\"}],\"doi\":\"10.5220/0007371104200426\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"title\":\"Human Action Recognition using Multi-Kernel Learning for Temporal Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134464014\",\"name\":\"Mateus Roder\"},{\"authorId\":\"69853591\",\"name\":\"L. Passos\"},{\"authorId\":\"153777260\",\"name\":\"L. C. F. Ribeiro\"},{\"authorId\":\"145223553\",\"name\":\"Clayton R. Pereira\"},{\"authorId\":\"1759037\",\"name\":\"J. Papa\"}],\"doi\":\"10.1007/978-3-030-61401-0_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"866e59dc2b007571f4eee4102170a42ffd83d017\",\"title\":\"A Layer-Wise Information Reinforcement Approach to Improve Learning in Deep Belief Networks\",\"url\":\"https://www.semanticscholar.org/paper/866e59dc2b007571f4eee4102170a42ffd83d017\",\"venue\":\"ICAISC\",\"year\":2020},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":\"1805.02860\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f414a4f51748d548c2e72971f1e428ebb34754bd\",\"title\":\"Visual Attribute-augmented Three-dimensional Convolutional Neural Network for Enhanced Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f414a4f51748d548c2e72971f1e428ebb34754bd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29901316\",\"name\":\"Prateep Bhattacharjee\"},{\"authorId\":\"144009889\",\"name\":\"Sukhendu Das\"}],\"doi\":\"10.1007/978-3-319-69900-4_70\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"title\":\"Two-Stream Convolutional Network with Multi-level Feature Fusion for Categorization of Human Action from Videos\",\"url\":\"https://www.semanticscholar.org/paper/bf2eb77e9b795a4a0a38ed4b1c8dd4b2c9a74317\",\"venue\":\"PReMI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4210401\",\"name\":\"Junqing Yu\"},{\"authorId\":\"51048125\",\"name\":\"Aiping Lei\"},{\"authorId\":\"15429809\",\"name\":\"Yangliu Hu\"}],\"doi\":\"10.1007/978-3-030-05716-9_31\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"title\":\"Soccer Video Event Detection Based on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/168ebf77527329bc2dbd0ce82bddb9905c3aa7ee\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145883076\",\"name\":\"S. Rani\"},{\"authorId\":\"1416537783\",\"name\":\"G. Naidu\"},{\"authorId\":\"145394493\",\"name\":\"V. U. Shree\"}],\"doi\":\"10.35940/ijitee.a4677.119119\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef016ec90c41e30250e091051e183b80d891bd4e\",\"title\":\"A Fine Grainedresearch Over Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ef016ec90c41e30250e091051e183b80d891bd4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1810.09044\",\"authors\":[{\"authorId\":\"31906425\",\"name\":\"M. S. Aliakbarian\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"145007997\",\"name\":\"L. Andersson\"}],\"doi\":\"10.1007/978-3-030-20887-5_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"title\":\"VIENA2: A Driving Anticipation Dataset\",\"url\":\"https://www.semanticscholar.org/paper/44384fb1f20cea528f32c1c14c5a8400b65c1804\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2004.07711\",\"authors\":[{\"authorId\":\"1637242169\",\"name\":\"Guglielmo Camporese\"},{\"authorId\":\"29776698\",\"name\":\"Pasquale Coscia\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc24772bf84d9ff92166d8f228284c4079619ed0\",\"title\":\"Knowledge Distillation for Action Anticipation via Label Smoothing\",\"url\":\"https://www.semanticscholar.org/paper/dc24772bf84d9ff92166d8f228284c4079619ed0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145625558\",\"name\":\"Chuankun Li\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"},{\"authorId\":\"40508657\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.1016/j.jvcir.2019.102640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c960014ee78d90479d34f2a0c75e46f4f3a78c86\",\"title\":\"Learning attentive dynamic maps (ADMs) for Understanding Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/c960014ee78d90479d34f2a0c75e46f4f3a78c86\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1712.09374\",\"authors\":[{\"authorId\":\"49453213\",\"name\":\"Hang Zhao\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd9157331104a0708aa4f8ae79b7651a5be797c6\",\"title\":\"SLAC: A Sparsely Labeled Dataset for Action Classification and Localization\",\"url\":\"https://www.semanticscholar.org/paper/bd9157331104a0708aa4f8ae79b7651a5be797c6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41c21f12f6896c458004f26b1fd704f4058aaac1\",\"title\":\"CV-C3D: Action Recognition on Compressed Videos with Convolutional 3D Networks\",\"url\":\"https://www.semanticscholar.org/paper/41c21f12f6896c458004f26b1fd704f4058aaac1\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145791568\",\"name\":\"Y. Bo\"},{\"authorId\":\"9527255\",\"name\":\"Yixin Chen\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"},{\"authorId\":\"33276033\",\"name\":\"Jie Xiang\"}],\"doi\":\"10.1109/BigMM.2018.8499251\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"af13aae576f4d9ecc3de73a9ef8ff4396d057b8c\",\"title\":\"DVD: Constructing a Discriminative Video Descriptor by Convolving Frame Features\",\"url\":\"https://www.semanticscholar.org/paper/af13aae576f4d9ecc3de73a9ef8ff4396d057b8c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102300440\",\"name\":\"Jakob Wiesinger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"title\":\"Video Saliency Detection Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/90d8bec9414f1c9dbca3be1ef9ff0fd0cd7b4f36\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27687205\",\"name\":\"N. Efthymiou\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"30192180\",\"name\":\"P. P. Filntisis\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2018.8451146\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b56a568799a0dee06587d8ab54032f7bf7712008\",\"title\":\"Multi- View Fusion for Action Recognition in Child-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/b56a568799a0dee06587d8ab54032f7bf7712008\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"24638beb5e24c2df424dab16cd715ebce1dda9ab\",\"title\":\"Discriminative Subspace Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24638beb5e24c2df424dab16cd715ebce1dda9ab\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98294026\",\"name\":\"S. Liu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"32083314\",\"name\":\"Yi-bin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2979549\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"title\":\"An End to End Framework With Adaptive Spatio-Temporal Attention Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"26900125\",\"name\":\"Jinghao Lin\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"3945955\",\"name\":\"X. He\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3123266.3123364\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2411270f111a160c9289d56132651c896a5738f6\",\"title\":\"Video Question Answering via Hierarchical Dual-Level Attention Network Learning\",\"url\":\"https://www.semanticscholar.org/paper/2411270f111a160c9289d56132651c896a5738f6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825539\",\"name\":\"Wei Wang\"},{\"authorId\":\"152299675\",\"name\":\"Siyuan Hao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"3124720\",\"name\":\"Shengtao Xiao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ACCESS.2019.2936604\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"74195742093c489401ef8dc3d7f8639fd12c20e8\",\"title\":\"Temporal Spiking Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74195742093c489401ef8dc3d7f8639fd12c20e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7769579\",\"name\":\"Zhikang Liu\"},{\"authorId\":\"3238613\",\"name\":\"Zilei Wang\"},{\"authorId\":\"48467657\",\"name\":\"Yan Zhao\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1007/978-3-030-20890-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f7288fc2f8fe8f083853ea63f6b322fe6b10bd0\",\"title\":\"SMC: Single-Stage Multi-location Convolutional Network for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/8f7288fc2f8fe8f083853ea63f6b322fe6b10bd0\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145082678\",\"name\":\"G. Chen\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"}],\"doi\":\"10.1007/978-3-030-05710-7_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64a157d61e72b204013acb70bb5c16b55ce7ba09\",\"title\":\"STMP: Spatial Temporal Multi-level Proposal Network for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/64a157d61e72b204013acb70bb5c16b55ce7ba09\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"145684947\",\"name\":\"M. Yu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"}],\"doi\":\"10.1007/978-3-030-05716-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"title\":\"Action Recognition Using Visual Attention with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.08437\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1109/TPAMI.2019.2929038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67d0a881e0c580acc7770c212396171cc64aa76c\",\"title\":\"Learning with Privileged Information via Adversarial Discriminative Modality Distillation\",\"url\":\"https://www.semanticscholar.org/paper/67d0a881e0c580acc7770c212396171cc64aa76c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"1492113737\",\"name\":\"Jiani Li\"},{\"authorId\":\"50248679\",\"name\":\"Guanshuo Wang\"},{\"authorId\":\"46499930\",\"name\":\"Y. Yuan\"},{\"authorId\":\"116176284\",\"name\":\"X. Zhou\"}],\"doi\":\"10.1007/978-3-030-29894-4_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d8619695b651c52f8a847392588cc8911bb567bb\",\"title\":\"General Interaction-Aware Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d8619695b651c52f8a847392588cc8911bb567bb\",\"venue\":\"PRICAI\",\"year\":2019},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410755536\",\"name\":\"David Ivorra-Piqueres\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"10db9fc9107895a0705401cab89697f248d5eaed\",\"title\":\"Action segmentation and understanding in RGB videos with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/10db9fc9107895a0705401cab89697f248d5eaed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TPAMI.2018.2882805\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02c293bc06c580305c8b62a8ed90f37a75608493\",\"title\":\"Adversarial Action Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/02c293bc06c580305c8b62a8ed90f37a75608493\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"David A. Ross\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"Rahul Sukthankar\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"RoI Pooling DNN Classifier Person Bike Background 2 D Feature Map Input ImageMulti-scale Anchor Boxes Region Proposal Network Region Proposals 2 D ConvNet c DNN Classifier Dunk Background SoI Pooling\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1906.05910\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9a9965c013be1269c05a96857c78ad8c87ee517\",\"title\":\"Hallucinating Bag-of-Words and Fisher Vector IDT terms for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9a9965c013be1269c05a96857c78ad8c87ee517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3315036\",\"name\":\"S. Kang\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"3031838\",\"name\":\"Hyunsoo Choi\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1007/978-3-030-01264-9_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cdf8790a675037579bbe2ee4f39f731f7672fae\",\"title\":\"Pivot Correlational Neural Network for Multimodal Video Categorization\",\"url\":\"https://www.semanticscholar.org/paper/1cdf8790a675037579bbe2ee4f39f731f7672fae\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1906.09955\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1109/TIP.2019.2925285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"title\":\"A Comparative Review of Recent Kinect-Based Action Recognition Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"47557959\",\"name\":\"Y. Chen\"},{\"authorId\":\"47462870\",\"name\":\"Ruotao Xu\"},{\"authorId\":\"153172100\",\"name\":\"Hui Ji\"}],\"doi\":\"10.1016/J.CVIU.2019.102794\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"title\":\"Attention with structure regularization for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"2008.10534\",\"authors\":[{\"authorId\":\"2715566\",\"name\":\"K. Lai\"},{\"authorId\":\"1728290\",\"name\":\"S. Yanushkevich\"}],\"doi\":\"10.1109/SMC42975.2020.9283273\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d11d845f92cdbe63eb96a1d648e85abaa8a3f5d2\",\"title\":\"Decision Support for Video-based Detection of Flu Symptoms\",\"url\":\"https://www.semanticscholar.org/paper/d11d845f92cdbe63eb96a1d648e85abaa8a3f5d2\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1802.06724\",\"authors\":[{\"authorId\":\"32082024\",\"name\":\"Ali Javidani\"},{\"authorId\":\"2757076\",\"name\":\"Ahmad Mahmoudi Aznaveh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"075ec6ce86828da112558e4c73e7135e0a7a269f\",\"title\":\"Learning Representative Temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/075ec6ce86828da112558e4c73e7135e0a7a269f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92148538\",\"name\":\"Di Wu\"},{\"authorId\":\"2257498\",\"name\":\"N. Sharma\"},{\"authorId\":\"1801266\",\"name\":\"M. Blumenstein\"}],\"doi\":\"10.1109/IVCNZ.2018.8634660\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e9ba4e866862936cc49c4b762afd29367289fe31\",\"title\":\"An End-to-End Hierarchical Classification Approach for Similar Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e9ba4e866862936cc49c4b762afd29367289fe31\",\"venue\":\"2018 International Conference on Image and Vision Computing New Zealand (IVCNZ)\",\"year\":2018},{\"arxivId\":\"1905.10357\",\"authors\":[{\"authorId\":\"48890447\",\"name\":\"Tauseef Ali\"},{\"authorId\":\"4822752\",\"name\":\"Eissa Alreshidi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b8474fa16c4d4cc929cd26e4b82b0d52bce03b5\",\"title\":\"Deep Trajectory for Recognition of Human Behaviours\",\"url\":\"https://www.semanticscholar.org/paper/1b8474fa16c4d4cc929cd26e4b82b0d52bce03b5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3401831\",\"name\":\"G. Wu\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"144784813\",\"name\":\"S. Gong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9339168bbb1debe977fa85af7b143e87e01c6a47\",\"title\":\"Spatio-Temporal Associative Representation for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/9339168bbb1debe977fa85af7b143e87e01c6a47\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":\"1807.09380\",\"authors\":[{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"title\":\"Contrastive Video Representation Learning via Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13726\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00017\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"title\":\"Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021265\",\"name\":\"T. Yu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TIP.2019.2940677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"title\":\"Compositional Attention Networks With Two-Stream Fusion for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ef33aedbab68b0771f6dd7ca8ec2492f12d7ea51\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"147558190\",\"name\":\"Misa Ono\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2567ab620a9baef594a6b6a1753f0e2c96a8d3a5\",\"title\":\"Hand Detection in Egocentric Video and Investigation Towards Fine-grained Cooking Activities Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2567ab620a9baef594a6b6a1753f0e2c96a8d3a5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.12071\",\"authors\":[{\"authorId\":\"48523319\",\"name\":\"Yuanyuan Mi\"},{\"authorId\":\"35157281\",\"name\":\"Xiaohan Lin\"},{\"authorId\":\"46927650\",\"name\":\"Xiaolong Zou\"},{\"authorId\":\"49954218\",\"name\":\"Z. Ji\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"},{\"authorId\":\"143700216\",\"name\":\"S. Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"945e851313b85d4e2d2ed533c75c86c556696b87\",\"title\":\"Spatiotemporal Information Processing with a Reservoir Decision-making Network\",\"url\":\"https://www.semanticscholar.org/paper/945e851313b85d4e2d2ed533c75c86c556696b87\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1381480522\",\"name\":\"M. Al-Faris\"},{\"authorId\":\"145091554\",\"name\":\"John P. Chiverton\"},{\"authorId\":\"49308434\",\"name\":\"Y. Yang\"},{\"authorId\":\"2092709\",\"name\":\"D. Ndzi\"}],\"doi\":\"10.3390/jimaging5100082\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"title\":\"Deep Learning of Fuzzy Weighted Multi-Resolution Depth Motion Maps with Spatial Feature Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccf756d10bcaa51431f09dc1ef06e5efdcad1d07\",\"venue\":\"J. Imaging\",\"year\":2019},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40471656\",\"name\":\"Dong Li\"},{\"authorId\":\"145690246\",\"name\":\"T. Yao\"},{\"authorId\":\"7667912\",\"name\":\"L. Duan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/TMM.2018.2862341\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"title\":\"Unified Spatio-Temporal Attention Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0d8d0ce66eb661fbf12a04130dd7d51454f1f196\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":null,\"name\":\"Zhicheng Yan\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00876\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"title\":\"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.03266\",\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":\"10.1109/WACV45572.2020.9093283\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551536\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"title\":\"Enhanced Action Recognition With Visual Attribute-Augmented 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2269558\",\"name\":\"Q. Li\"},{\"authorId\":\"144854843\",\"name\":\"X. Zhao\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2923444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ff61d933f95bab4d0390b0372b0e6f1829251c6\",\"title\":\"Recurrent Prediction With Spatio-Temporal Attention for Crowd Attribute Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ff61d933f95bab4d0390b0372b0e6f1829251c6\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1803.10861\",\"authors\":[{\"authorId\":\"145583891\",\"name\":\"Tuan-Hung Vu\"},{\"authorId\":\"17132791\",\"name\":\"W. Choi\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"2099305\",\"name\":\"Manmohan Chandraker\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"title\":\"Memory Warps for Learning Long-Term Online Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/4c4a1a5eb968ffcc3fc549753edf19ab23c8a3d2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00191\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22031c69356c35909082613b84fe86b682291b8a\",\"title\":\"Enhancing Temporal Action Localization with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/22031c69356c35909082613b84fe86b682291b8a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1805.06749\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"89d7aa10ad97251089d0204916f784f137f3a1ec\",\"title\":\"Action Completion: A Temporal Model for Moment Detection\",\"url\":\"https://www.semanticscholar.org/paper/89d7aa10ad97251089d0204916f784f137f3a1ec\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1707.06923\",\"authors\":[{\"authorId\":\"39599054\",\"name\":\"B. Sengupta\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2227f978f084ebb18cb594c0cfaf124b0df6bf95\",\"title\":\"Pillar Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2227f978f084ebb18cb594c0cfaf124b0df6bf95\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113640471\",\"name\":\"Krishan Sharma\"},{\"authorId\":\"27089239\",\"name\":\"Renu Rameshan\"}],\"doi\":\"10.1109/ICASSP.2019.8682898\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae71c7d55a7aca04b29fb311ccd8d2b0ffb5e4b2\",\"title\":\"Linearized Kernel Representation Learning from Video Tensors by Exploiting Manifold Geometry for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae71c7d55a7aca04b29fb311ccd8d2b0ffb5e4b2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631782\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/S12652-019-01277-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f9337a88b22f0177727c20d3c8159b3e3af7392\",\"title\":\"An intelligent monitoring system for indoor safety of individuals suffering from Autism Spectrum Disorder (ASD)\",\"url\":\"https://www.semanticscholar.org/paper/8f9337a88b22f0177727c20d3c8159b3e3af7392\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d281b07ee152f6c1312297b71791d358f4dc88cb\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360$^{\\\\circ}$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/d281b07ee152f6c1312297b71791d358f4dc88cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67055826\",\"name\":\"Renfei Sun\"},{\"authorId\":\"48708295\",\"name\":\"Z. Wang\"},{\"authorId\":\"153321393\",\"name\":\"K. E. Martens\"},{\"authorId\":\"144506986\",\"name\":\"S. Lewis\"}],\"doi\":\"10.1109/DICTA.2018.8615791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22bce54fddaaf359f348badfb49b7a168ab53cc6\",\"title\":\"Convolutional 3D Attention Network for Video Based Freezing of Gait Recognition\",\"url\":\"https://www.semanticscholar.org/paper/22bce54fddaaf359f348badfb49b7a168ab53cc6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35286235\",\"name\":\"Erick Hendra Putra Alwando\"},{\"authorId\":\"1736618\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/TCSVT.2018.2887283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"title\":\"CNN-Based Multiple Path Search for Action Tube Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/728412cd6d7f2e7e6dcb2917751f8b40f4313008\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"49338773\",\"name\":\"Y. Zhan\"},{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"1410252832\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2019.2952088\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"title\":\"A Context Knowledge Map Guided Coarse-to-Fine Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1905.00745\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79795951498660c539ff440d2ddcb32f3132b97e\",\"title\":\"Human Action Recognition with Deep Temporal Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/79795951498660c539ff440d2ddcb32f3132b97e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410755536\",\"name\":\"David Ivorra-Piqueres\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"}],\"doi\":\"10.4018/IJCVIP.2019040102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2736ba902aaaf02cddcbb95db7117358786227c6\",\"title\":\"Accelerating Deep Action Recognition Networks for Real-Time Applications\",\"url\":\"https://www.semanticscholar.org/paper/2736ba902aaaf02cddcbb95db7117358786227c6\",\"venue\":\"Int. J. Comput. Vis. Image Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICIP40778.2020.9191360\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a15dbfca55605bd3a5769ada375433c216822e0e\",\"title\":\"Coarse-to-Fine Aggregation for Cross-Granularity Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a15dbfca55605bd3a5769ada375433c216822e0e\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.04473\",\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efcd92bd79eab5d4eeabcf5da8710b04b5bf2d50\",\"title\":\"Deep hierarchical pooling design for cross-granularity action recognition\",\"url\":\"https://www.semanticscholar.org/paper/efcd92bd79eab5d4eeabcf5da8710b04b5bf2d50\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.02529\",\"authors\":[{\"authorId\":\"1409812856\",\"name\":\"Meng Zhou\"},{\"authorId\":\"47781483\",\"name\":\"Ziyu Liu\"},{\"authorId\":\"1796260627\",\"name\":\"Pengwei Sui\"},{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"1798753\",\"name\":\"Y. Y. Chung\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"23f29794ba5beb0bddea4ba84004324f0c9aed62\",\"title\":\"Learning Implicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/23f29794ba5beb0bddea4ba84004324f0c9aed62\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"144350546\",\"name\":\"Y. Qian\"}],\"doi\":\"10.1007/978-3-030-00776-8_57\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"title\":\"DT-3DResNet-LSTM: An Architecture for Temporal Activity Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f094bd9360b59afc2880c20ad3a37ee640c6c6c9\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781560\",\"name\":\"Z. Liu\"},{\"authorId\":\"66454724\",\"name\":\"Zeya Li\"},{\"authorId\":\"150238936\",\"name\":\"Ming Zong\"},{\"authorId\":\"29790429\",\"name\":\"Wanting Ji\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"152714157\",\"name\":\"Y. Tian\"}],\"doi\":\"10.1007/978-981-15-3651-9_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9de826c60e7258e2a69b74836213fec465ef2601\",\"title\":\"Spatiotemporal Saliency Based Multi-stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9de826c60e7258e2a69b74836213fec465ef2601\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46584911\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"971c0ce8465905abb16126bf2c7cce5015dd13f3\",\"title\":\"Runtime Optimizations for Large-Scale Data Analytics\",\"url\":\"https://www.semanticscholar.org/paper/971c0ce8465905abb16126bf2c7cce5015dd13f3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471304742\",\"name\":\"Manh-Hung Lu\"},{\"authorId\":\"40429856\",\"name\":\"Thi-Oanh Nguyen\"}],\"doi\":\"10.1145/3368926.3369726\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2965fc1c8f97339cac4a5869b2a5ee56dbd27d6\",\"title\":\"Spatio-temporal Multi-level Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2965fc1c8f97339cac4a5869b2a5ee56dbd27d6\",\"venue\":\"SoICT 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2566189\",\"name\":\"Suguo Zhu\"},{\"authorId\":\"51188296\",\"name\":\"Zhenying Fang\"},{\"authorId\":\"40013369\",\"name\":\"Y. Wang\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"8491162\",\"name\":\"J. Du\"}],\"doi\":\"10.1016/J.JVCIR.2018.12.026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"title\":\"Multimodal activity recognition with local block CNN and attention-based spatial weighted CNN\",\"url\":\"https://www.semanticscholar.org/paper/74d70d4dae2c9bac0197cb25fac27ed4d3f626c7\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35429700\",\"name\":\"Panagiotis Giannakeris\"},{\"authorId\":\"1696389\",\"name\":\"G. Meditskos\"},{\"authorId\":\"2735095\",\"name\":\"Konstantinos Avgerinakis\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1007/978-3-030-37734-2_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f8bd23919c36db7e1f3eb9c57b7ef72e4632ed1\",\"title\":\"Real-Time Recognition of Daily Actions Based on 3D Joint Movements and Fisher Encoding\",\"url\":\"https://www.semanticscholar.org/paper/0f8bd23919c36db7e1f3eb9c57b7ef72e4632ed1\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00677\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"title\":\"Making Convolutional Networks Recurrent for Visual Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"46461307\",\"name\":\"S. Z. Gilani\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"},{\"authorId\":\"9493788\",\"name\":\"Han-lin Qin\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":\"10.3390/s20236941\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"title\":\"Self-Supervised Learning to Detect Key Frames in Videos\",\"url\":\"https://www.semanticscholar.org/paper/61de5563ca445cab30b9d4ae2a7112b730c269ce\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1573795785\",\"name\":\"B. Padmaja\"},{\"authorId\":\"70096504\",\"name\":\"Madhu Bala Myneni\"},{\"authorId\":\"1573896352\",\"name\":\"Epili Krishna Rao Patro\"}],\"doi\":\"10.1186/s40537-020-00296-8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be6d0ea71e2e2471b2bce4dcaf8b4ab0d7c2daa8\",\"title\":\"A comparison on visual prediction models for MAMO (multi activity-multi object) recognition using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/be6d0ea71e2e2471b2bce4dcaf8b4ab0d7c2daa8\",\"venue\":\"Journal of Big Data\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643682004\",\"name\":\"He Zhao\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-58526-6_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd941a3cb2664715269cbbd30a4df6828799ac01\",\"title\":\"On Diverse Asynchronous Activity Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/bd941a3cb2664715269cbbd30a4df6828799ac01\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527099865\",\"name\":\"Yiying Li\"},{\"authorId\":\"47003312\",\"name\":\"Y. Li\"},{\"authorId\":\"1894528779\",\"name\":\"Yanfei Gu\"}],\"doi\":\"10.1145/3404555.3404592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"539a59c0cee60a780ce0cc3f85781377e61356fb\",\"title\":\"Channel-Wise Spatial Attention with Spatiotemporal Heterogeneous Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/539a59c0cee60a780ce0cc3f85781377e61356fb\",\"venue\":\"ICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICPR.2018.8546325\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d45f7abeca184533ee0f0670c4946bcd34edda81\",\"title\":\"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/d45f7abeca184533ee0f0670c4946bcd34edda81\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20261417\",\"name\":\"H. Jiang\"},{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_17\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c8cafacad128b443470bed644b6f6cf93a31c236\",\"title\":\"Rethinking Fusion Baselines for Multi-modal Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8cafacad128b443470bed644b6f6cf93a31c236\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2006.04489\",\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"title\":\"Action Recognition with Deep Multiple Aggregation Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50081925\",\"name\":\"L. Zhang\"},{\"authorId\":\"2032648\",\"name\":\"J. Varadarajan\"},{\"authorId\":\"47332572\",\"name\":\"Yong Pei\"}],\"doi\":\"10.1007/978-3-030-56150-5_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"title\":\"Action Recognition Using Co-trained Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8b682a04b2e14dedc4de6e889ba641078bd9d64\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1910.06934\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a89c6d101ece92390b80b6196555fa22de0e458\",\"title\":\"Human Action Recognition with Multi-Laplacian Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3a89c6d101ece92390b80b6196555fa22de0e458\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.13979\",\"authors\":[{\"authorId\":\"48317098\",\"name\":\"Bruce X. B. Yu\"},{\"authorId\":\"49422024\",\"name\":\"Y. Liu\"},{\"authorId\":\"145003402\",\"name\":\"K. C. Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"title\":\"Skeleton Focused Human Activity Recognition in RGB Video\",\"url\":\"https://www.semanticscholar.org/paper/ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.11416\",\"authors\":[{\"authorId\":\"48084289\",\"name\":\"S. Kumar\"},{\"authorId\":\"1411543040\",\"name\":\"Ehsan Yaghoubi\"},{\"authorId\":\"1712429\",\"name\":\"Hugo Proen\\u00e7a\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb2bea2b34e7e67fd611924d10c06e4b70c6d016\",\"title\":\"A Symbolic Temporal Pooling method for Video-based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/bb2bea2b34e7e67fd611924d10c06e4b70c6d016\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.09184\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPR.2018.00044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"title\":\"Detect-and-Track: Efficient Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1808.05085\",\"authors\":[{\"authorId\":\"40192003\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1145/3240508.3240534\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"title\":\"Temporal Sequence Distillation: Towards Few-Frame Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47136049\",\"name\":\"Naofumi Tomita\"},{\"authorId\":\"2459267\",\"name\":\"Y. Cheung\"},{\"authorId\":\"145945685\",\"name\":\"Saeed Hassanpour\"}],\"doi\":\"10.1016/j.compbiomed.2018.05.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b480d06871beca08286402cac9196398ce35e9f\",\"title\":\"Deep neural networks for automatic detection of osteoporotic vertebral fractures on CT scans\",\"url\":\"https://www.semanticscholar.org/paper/2b480d06871beca08286402cac9196398ce35e9f\",\"venue\":\"Comput. Biol. Medicine\",\"year\":2018},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2003.06409\",\"authors\":[{\"authorId\":\"1909776\",\"name\":\"Anthony Hu\"},{\"authorId\":\"30467209\",\"name\":\"Fergal Cotter\"},{\"authorId\":\"145536619\",\"name\":\"N. Mohan\"},{\"authorId\":\"31618584\",\"name\":\"C. Gurau\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"}],\"doi\":\"10.1007/978-3-030-58517-4_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a79685e5b72e31405ded418abe8af86166313aa0\",\"title\":\"Probabilistic Future Prediction for Video Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a79685e5b72e31405ded418abe8af86166313aa0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.10469\",\"authors\":[{\"authorId\":\"1587627172\",\"name\":\"Aviv Shamsian\"},{\"authorId\":\"1587754052\",\"name\":\"Ofri Kleinfeld\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1007/978-3-030-58517-4_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b51d362a824851b4997903003746173fe41d348\",\"title\":\"Learning Object Permanence from Video\",\"url\":\"https://www.semanticscholar.org/paper/5b51d362a824851b4997903003746173fe41d348\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144864744\",\"name\":\"Wen-Jun Zeng\"}],\"doi\":\"10.1017/atsip.2019.26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e83046ed4d7c021b19801bc747c4cc1a6fb7df91\",\"title\":\"Toward human-centric deep video understanding\",\"url\":\"https://www.semanticscholar.org/paper/e83046ed4d7c021b19801bc747c4cc1a6fb7df91\",\"venue\":\"\",\"year\":2020}],\"corpusId\":23922674,\"doi\":\"10.1109/CVPR.2017.787\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":25,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1507.08750\",\"authors\":[{\"authorId\":\"2894414\",\"name\":\"Junhyuk Oh\"},{\"authorId\":\"1955964\",\"name\":\"Xiaoxiao Guo\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"},{\"authorId\":\"46328485\",\"name\":\"R. L. Lewis\"},{\"authorId\":\"1699868\",\"name\":\"Satinder Singh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4257bc131c36504a04382290cbc27ca8bb27813\",\"title\":\"Action-Conditional Video Prediction using Deep Networks in Atari Games\",\"url\":\"https://www.semanticscholar.org/paper/e4257bc131c36504a04382290cbc27ca8bb27813\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1762649\",\"name\":\"V. Rabaud\"},{\"authorId\":\"48524582\",\"name\":\"G. Cottrell\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":\"10.1109/VSPETS.2005.1570899\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1707caad72573633c2307fa26ec093e8f4bb03\",\"title\":\"Behavior recognition via sparse spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/9f1707caad72573633c2307fa26ec093e8f4bb03\",\"venue\":\"2005 IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance\",\"year\":2005},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150825\",\"name\":\"K. Derpanis\"},{\"authorId\":\"1768154\",\"name\":\"Mikhail Sizintsev\"},{\"authorId\":\"1922732\",\"name\":\"Kevin J. Cannons\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/TPAMI.2012.141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d506466c89c975c23c0c32271ea7718302791547\",\"title\":\"Action Spotting and Recognition Based on a Spatiotemporal Orientation Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d506466c89c975c23c0c32271ea7718302791547\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2016.333\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"title\":\"Regularizing Long Short Term Memory with 3D Human-Skeleton Sequences for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7854a9d1eaaac11047c22177b5ad5aa9ce2bf9e3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.4842\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"46641766\",\"name\":\"W. Liu\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"48840704\",\"name\":\"Scott Reed\"},{\"authorId\":\"1838674\",\"name\":\"Dragomir Anguelov\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"39863668\",\"name\":\"Andrew Rabinovich\"}],\"doi\":\"10.1109/CVPR.2015.7298594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"title\":\"Going deeper with convolutions\",\"url\":\"https://www.semanticscholar.org/paper/e15cf50aa89fee8535703b9f9512fca5bfc43327\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Goudreau\"},{\"authorId\":null,\"name\":\"C. Giles\"},{\"authorId\":null,\"name\":\"S. Chakradhar\"},{\"authorId\":null,\"name\":\"D. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Firstorder versus second-order single-layer recurrent neural networks\",\"url\":\"\",\"venue\":\"IEEE Transactions on Neural Networks,\",\"year\":1994},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1606.06630\",\"authors\":[{\"authorId\":\"3374063\",\"name\":\"Yuhuai Wu\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"48379623\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"136cf66392f1d6bf42da4cc070888996dc472b91\",\"title\":\"On Multiplicative Integration with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/136cf66392f1d6bf42da4cc070888996dc472b91\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1109/CVPR.2015.7298892\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9754872e151a69c32956497725a4f6f3881f18bb\",\"title\":\"Dynamically encoded actions based on spacetime saliency\",\"url\":\"https://www.semanticscholar.org/paper/9754872e151a69c32956497725a4f6f3881f18bb\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788202\",\"name\":\"M. Goudreau\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"},{\"authorId\":\"1752242\",\"name\":\"S. Chakradhar\"},{\"authorId\":\"20141813\",\"name\":\"Dong Chen\"}],\"doi\":\"10.1109/72.286928\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"160ad1b01973986944a5f9a17924711ee1861552\",\"title\":\"First-order versus second-order single-layer recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/160ad1b01973986944a5f9a17924711ee1861552\",\"venue\":\"IEEE Trans. Neural Networks\",\"year\":1994},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1162/neco.2010.01-09-953\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0eb2e4a205a628ab059cab41d3b772f614ad29f2\",\"title\":\"Learning to Represent Spatial Transformations with Factored Higher-Order Boltzmann Machines\",\"url\":\"https://www.semanticscholar.org/paper/0eb2e4a205a628ab059cab41d3b772f614ad29f2\",\"venue\":\"Neural Computation\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1607.06416\",\"authors\":[{\"authorId\":null,\"name\":\"Yilin Wang\"},{\"authorId\":\"2893721\",\"name\":\"Suhang Wang\"},{\"authorId\":\"1736632\",\"name\":\"Jiliang Tang\"},{\"authorId\":\"1401255262\",\"name\":\"N. O'Hare\"},{\"authorId\":\"120586587\",\"name\":\"Y. Chang\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f499948121abb47b31ca904030243e924585d5f\",\"title\":\"Hierarchical Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9f499948121abb47b31ca904030243e924585d5f\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.04119\",\"authors\":[{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"title\":\"Action Recognition using Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/7b8810ad8ef9ddd024583f95a51559e6c1b8c754\",\"venue\":\"NIPS 2015\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"2860351\",\"name\":\"Will Y. Zou\"},{\"authorId\":\"32408341\",\"name\":\"Serena Y. Yeung\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1109/CVPR.2011.5995496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42269d0438c0ae4ca892334946ed779999691074\",\"title\":\"Learning hierarchical invariant spatio-temporal features for action recognition with independent subspace analysis\",\"url\":\"https://www.semanticscholar.org/paper/42269d0438c0ae4ca892334946ed779999691074\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/1553374.1553505\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"346fbcffe4237aa60e8bcb3d4294a8b99436f1d0\",\"title\":\"Factored conditional restricted Boltzmann Machines for modeling motion style\",\"url\":\"https://www.semanticscholar.org/paper/346fbcffe4237aa60e8bcb3d4294a8b99436f1d0\",\"venue\":\"ICML '09\",\"year\":2009}],\"title\":\"Spatiotemporal Multiplier Networks for Video Action Recognition\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"Internationalization and localization\",\"topicId\":\"69706\",\"url\":\"https://www.semanticscholar.org/topic/69706\"},{\"topic\":\"Temporal logic\",\"topicId\":\"480\",\"url\":\"https://www.semanticscholar.org/topic/480\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"}],\"url\":\"https://www.semanticscholar.org/paper/265cd694e8886a7f8413dd334662f269c6ac2bfc\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"