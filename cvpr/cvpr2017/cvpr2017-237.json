"{\"abstract\":\"Video frame interpolation typically involves two steps: motion estimation and pixel synthesis. Such a two-step approach heavily depends on the quality of motion estimation. This paper presents a robust video frame interpolation method that combines these two steps into a single process. Specifically, our method considers pixel synthesis for the interpolated frame as local convolution over two input frames. The convolution kernel captures both the local motion between the input frames and the coefficients for pixel synthesis. Our method employs a deep fully convolutional neural network to estimate a spatially-adaptive convolution kernel for each pixel. This deep neural network can be directly trained end to end using widely available video data without any difficult-to-obtain ground-truth data like optical flow. Our experiments show that the formulation of video interpolation as a single convolution process allows our method to gracefully handle challenges like occlusion, blur, and abrupt brightness change and enables high-quality video frame interpolation.\",\"arxivId\":\"1703.07514\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\",\"url\":\"https://www.semanticscholar.org/author/39644974\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\",\"url\":\"https://www.semanticscholar.org/author/2712573\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\",\"url\":\"https://www.semanticscholar.org/author/40513795\"}],\"citationVelocity\":61,\"citations\":[{\"arxivId\":\"2012.08103\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"72551720\",\"name\":\"Hyeonjun Sim\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab4b179ed63441d49dbd903cb6bc06bd691ae137\",\"title\":\"KOALAnet: Blind Super-Resolution using Kernel-Oriented Adaptive Local Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/ab4b179ed63441d49dbd903cb6bc06bd691ae137\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.05193\",\"authors\":[{\"authorId\":\"102580872\",\"name\":\"Andr\\u00e9 Nortje\"},{\"authorId\":\"40021784\",\"name\":\"Herman A. Engelbrecht\"},{\"authorId\":\"2308553\",\"name\":\"H. Kamper\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1012d2e369d1bc0b49f201fad95fd851bc654467\",\"title\":\"Deep motion estimation for parallel inter-frame prediction in video compression\",\"url\":\"https://www.semanticscholar.org/paper/1012d2e369d1bc0b49f201fad95fd851bc654467\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2011.10185\",\"authors\":[{\"authorId\":\"2545360\",\"name\":\"Zhouyong Liu\"},{\"authorId\":\"1996150477\",\"name\":\"Shun Luo\"},{\"authorId\":\"3335945\",\"name\":\"Wubin Li\"},{\"authorId\":\"2027604839\",\"name\":\"Jingben Lu\"},{\"authorId\":\"1390683331\",\"name\":\"Yufan Wu\"},{\"authorId\":\"1726286\",\"name\":\"Chunguo Li\"},{\"authorId\":\"97745176\",\"name\":\"L. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43df53137dfaac590600c4c3dfe1fa0f54148774\",\"title\":\"ConvTransformer: A Convolutional Transformer Network for Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/43df53137dfaac590600c4c3dfe1fa0f54148774\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.11286\",\"authors\":[{\"authorId\":\"10796882\",\"name\":\"Beomjun Kim\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"38723538\",\"name\":\"Bumsub Ham\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72e7487cb723791fa55850ef9ef319975532cfa2\",\"title\":\"Deformable kernel networks for guided depth map upsampling\",\"url\":\"https://www.semanticscholar.org/paper/72e7487cb723791fa55850ef9ef319975532cfa2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.06045\",\"authors\":[{\"authorId\":\"3038326\",\"name\":\"Joost R. van Amersfoort\"},{\"authorId\":\"2700496\",\"name\":\"W. Shi\"},{\"authorId\":\"145987822\",\"name\":\"A. Acosta\"},{\"authorId\":\"35163474\",\"name\":\"Francisco Massa\"},{\"authorId\":\"1853456\",\"name\":\"J. Totz\"},{\"authorId\":\"34627233\",\"name\":\"Zehan Wang\"},{\"authorId\":\"145372820\",\"name\":\"J. Caballero\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d6569a94dd0a2446bfdbc4e026d69a0eb69743f\",\"title\":\"Frame Interpolation with Multi-Scale Deep Loss Functions and Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8d6569a94dd0a2446bfdbc4e026d69a0eb69743f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1811.00684\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"2457939\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"144391743\",\"name\":\"R. Kirby\"},{\"authorId\":\"32406400\",\"name\":\"J. Barker\"},{\"authorId\":\"2924393\",\"name\":\"D. Tarjan\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1007/978-3-030-01234-2_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"title\":\"SDC-Net: Video Prediction Using Spatially-Displaced Convolution\",\"url\":\"https://www.semanticscholar.org/paper/c165003060eeb01e05800a5ee4cd327f1e0bf5e3\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1807658969\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"1807805250\",\"name\":\"Muchen Li\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2999209\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c379cf37b936d43767e4e3a6bdde7f5022446a3\",\"title\":\"Learning Spatial and Spatio-Temporal Pixel Aggregations for Image and Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/4c379cf37b936d43767e4e3a6bdde7f5022446a3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.00779\",\"authors\":[{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"},{\"authorId\":\"9535762\",\"name\":\"Janghoon Choi\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00946\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"title\":\"Scene-Adaptive Video Frame Interpolation via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91926911\",\"name\":\"Minho Park\"},{\"authorId\":\"2909533\",\"name\":\"Sangmin Lee\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054744\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"title\":\"Video Frame Interpolation Via Exceptional Motion-Aware Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bf10a08700cda8de85650cb4a8c5762ed9c47a22\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153504847\",\"name\":\"H. Zhang\"},{\"authorId\":\"38690159\",\"name\":\"Linlin Li\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"11951590\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICIP.2019.8804199\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d0158716cd80b56c881e318e5014669170cbd6a\",\"title\":\"Advanced CNN Based Motion Compensation Fractional Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/2d0158716cd80b56c881e318e5014669170cbd6a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2007.02018\",\"authors\":[{\"authorId\":\"12771034\",\"name\":\"Jinxiu Liang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"},{\"authorId\":\"90137165\",\"name\":\"H. Ji\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06a4a6c34385aff144e4da5a7299f432703cf6e9\",\"title\":\"Deep Bilateral Retinex for Low-Light Image Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/06a4a6c34385aff144e4da5a7299f432703cf6e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.04149\",\"authors\":[{\"authorId\":\"1597361648\",\"name\":\"Xiaoyu Li\"},{\"authorId\":\"1723442179\",\"name\":\"Bo Zhang\"},{\"authorId\":\"1851024702\",\"name\":\"Jing Liao\"},{\"authorId\":\"145891472\",\"name\":\"Pedro V. Sander\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"title\":\"Deep Sketch-guided Cartoon Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/034300b0576f3291c8bb5f29bd9ef221d4244c6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.01692\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"40513795\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/ICCV.2017.37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed74b9390eda908060fa3501b8f20a836ec98d63\",\"title\":\"Video Frame Interpolation via Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/ed74b9390eda908060fa3501b8f20a836ec98d63\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2012.00253\",\"authors\":[{\"authorId\":\"144950354\",\"name\":\"C. Yan\"},{\"authorId\":\"51376876\",\"name\":\"X. Li\"},{\"authorId\":\"88059715\",\"name\":\"G. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe767ce67a7ff594b989cd194b10e61745890bdc\",\"title\":\"A New Action Recognition Framework for Video Highlights Summarization in Sporting Events\",\"url\":\"https://www.semanticscholar.org/paper/fe767ce67a7ff594b989cd194b10e61745890bdc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.07218\",\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-20893-6_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3819d2b6992be3e224e90371cc83bc5c60345e63\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/3819d2b6992be3e224e90371cc83bc5c60345e63\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1904.01693\",\"authors\":[{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"225dc18db507147de068710839941900996a7329\",\"title\":\"Multigrid Predictive Filter Flow for Unsupervised Learning on Videos\",\"url\":\"https://www.semanticscholar.org/paper/225dc18db507147de068710839941900996a7329\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48633955\",\"name\":\"Zhenghui Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"9125700\",\"name\":\"Jiansheng Yang\"}],\"doi\":\"10.1109/ISCAS.2018.8351189\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c4cf91a1c19d42eb4dbb16f420eb6434a9934db\",\"title\":\"CNN-Based Bi-Directional Motion Compensation for High Efficiency Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/4c4cf91a1c19d42eb4dbb16f420eb6434a9934db\",\"venue\":\"2018 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2018},{\"arxivId\":\"2009.12987\",\"authors\":[{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"71710083\",\"name\":\"Jaerin Lee\"},{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"51166756\",\"name\":\"R. Timofte\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"title\":\"AIM 2020 Challenge on Video Temporal Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a9e01b6bdab1407798c1fdd51defb27bc5b2d0a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.03095\",\"authors\":[{\"authorId\":\"51152279\",\"name\":\"Daniel Gehrig\"},{\"authorId\":\"8329387\",\"name\":\"M. Gehrig\"},{\"authorId\":\"1406402485\",\"name\":\"Javier Hidalgo-Carri'o\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":\"10.1109/cvpr42600.2020.00364\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d6d6f121e8dd049b1dee993599123c3e9852d07\",\"title\":\"Video to Events: Recycling Video Datasets for Event Cameras\",\"url\":\"https://www.semanticscholar.org/paper/7d6d6f121e8dd049b1dee993599123c3e9852d07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.06567\",\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"145772051\",\"name\":\"Sifeng Xia\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"}],\"doi\":\"10.1109/TMM.2019.2961504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d873fdfc43afd675432af22362283bf202837164\",\"title\":\"Deep Reference Generation With Multi-Domain Hierarchical Constraints for Inter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d873fdfc43afd675432af22362283bf202837164\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"48805613\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"47558508\",\"name\":\"Y. Chen\"},{\"authorId\":\"144515403\",\"name\":\"N. Ling\"}],\"doi\":\"10.1109/ICIP40778.2020.9191112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e20407c374e28254bd5fb41e007d0238a27ec6e\",\"title\":\"Deep Virtual Reference Frame Generation For Multiview Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/4e20407c374e28254bd5fb41e007d0238a27ec6e\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1914700964\",\"name\":\"Shurui Gui\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"47261253\",\"name\":\"Q. Chen\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/cvpr42600.2020.01402\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"title\":\"FeatureFlow: Robust Video Interpolation via Structure-to-Texture Generation\",\"url\":\"https://www.semanticscholar.org/paper/48d49e5e85a5659853f8ad2f31e05b8ba81866e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.13205\",\"authors\":[{\"authorId\":\"31719101\",\"name\":\"Karl Pertsch\"},{\"authorId\":\"40900227\",\"name\":\"Oleh Rybkin\"},{\"authorId\":\"27535721\",\"name\":\"Frederik Ebert\"},{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"144348441\",\"name\":\"Dinesh Jayaraman\"},{\"authorId\":\"152198491\",\"name\":\"Sergey Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"title\":\"Long-Horizon Visual Planning with Goal-Conditioned Hierarchical Predictors\",\"url\":\"https://www.semanticscholar.org/paper/8dd3ec3ca1b7400d998e747356d07763a7ac1fb0\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00434\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5981bb0678578dcf75536bdc476a38a7e501a301\",\"title\":\"PoSNet: 4x Video Frame Interpolation Using Position-Specific Flow\",\"url\":\"https://www.semanticscholar.org/paper/5981bb0678578dcf75536bdc476a38a7e501a301\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"103356373\",\"name\":\"Kunyi Lu\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/TPAMI.2019.2951667\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64dadf96304f65af96fc6b4f82c11bc69589f547\",\"title\":\"A Temporally-Aware Interpolation Network for Video Frame Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/64dadf96304f65af96fc6b4f82c11bc69589f547\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050685\",\"name\":\"N. Zeng\"},{\"authorId\":\"50579892\",\"name\":\"Y. Chen\"},{\"authorId\":\"66471163\",\"name\":\"Y. Gu\"},{\"authorId\":\"27630525\",\"name\":\"Dong-dong Liu\"},{\"authorId\":\"1430778430\",\"name\":\"Yunbing Xing\"}],\"doi\":\"10.1109/SMC42975.2020.9283193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"title\":\"Highly Fluent Sign Language Synthesis Based on Variable Motion Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6aa69d640c39e28f36386dee39a3bfae7a2d042e\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1904.00830\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"46658056\",\"name\":\"Chao Ma\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/CVPR.2019.00382\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"title\":\"Depth-Aware Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1909.04391\",\"authors\":[{\"authorId\":\"5168807\",\"name\":\"Soo Ye Kim\"},{\"authorId\":\"107606159\",\"name\":\"Jihyong Oh\"},{\"authorId\":\"123446757\",\"name\":\"M. Kim\"}],\"doi\":\"10.1609/AAAI.V34I07.6789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0fc2813735c4f089ba50aa71f73b6429597cb16\",\"title\":\"JSI-GAN: GAN-Based Joint Super-Resolution and Inverse Tone-Mapping with Pixel-Wise Task-Specific Filters for UHD HDR Video\",\"url\":\"https://www.semanticscholar.org/paper/c0fc2813735c4f089ba50aa71f73b6429597cb16\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10399052\",\"name\":\"Irene Viola\"},{\"authorId\":\"32111266\",\"name\":\"J. Mulder\"},{\"authorId\":\"36517415\",\"name\":\"F. Simone\"},{\"authorId\":\"144022557\",\"name\":\"P. C\\u00e9sar\"}],\"doi\":\"10.1109/AIVR46125.2019.00022\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"title\":\"Temporal Interpolation of Dynamic Digital Humans using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7d5101a12d7f38f23e92952dcdada2c8b79aeb3e\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Virtual Reality (AIVR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144489175\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49544454\",\"name\":\"X. Liu\"},{\"authorId\":\"49330176\",\"name\":\"Lei Chen\"},{\"authorId\":\"1728718\",\"name\":\"Jiying Zhao\"}],\"doi\":\"10.1109/GLOBALSIP.2018.8646501\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c26fecf281ec14d3c6a06081eb5e1623c35560d3\",\"title\":\"Video Super-Resolution via Dynamic Local Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/c26fecf281ec14d3c6a06081eb5e1623c35560d3\",\"venue\":\"2018 IEEE Global Conference on Signal and Information Processing (GlobalSIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845898483\",\"name\":\"Keito Suzuki\"},{\"authorId\":\"145990152\",\"name\":\"Masaaki Ikehara\"}],\"doi\":\"10.1109/ACCESS.2020.3010846\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"94a51246d971fae266384e94f518bf3be7578908\",\"title\":\"Residual Learning of Video Frame Interpolation Using Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/94a51246d971fae266384e94f518bf3be7578908\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8526699\",\"name\":\"Jean Begaint\"},{\"authorId\":\"1679157\",\"name\":\"Franck Galpin\"},{\"authorId\":\"1871505\",\"name\":\"Philippe Guillotel\"},{\"authorId\":\"1780587\",\"name\":\"Christine Guillemot\"}],\"doi\":\"10.1109/DCC.2019.00068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"866fd28fc5381032a96d45e81c551c1af99bdec9\",\"title\":\"Deep Frame Interpolation for Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/866fd28fc5381032a96d45e81c551c1af99bdec9\",\"venue\":\"2019 Data Compression Conference (DCC)\",\"year\":2019},{\"arxivId\":\"1807.01462\",\"authors\":[{\"authorId\":\"1886286\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"47902684\",\"name\":\"Woojae Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"48602162\",\"name\":\"Sanghoon Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d510492c0885d439ec6f9f40775f0b07694f3d9\",\"title\":\"Video Frame Interpolation by Plug-and-Play Deep Locally Linear Embedding\",\"url\":\"https://www.semanticscholar.org/paper/4d510492c0885d439ec6f9f40775f0b07694f3d9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98485019\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"title\":\"High-speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/bae152da213d90b378dd7d7037f8c6ce795b8fb9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.01037\",\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/WACV45572.2020.9093557\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"05c43f1791787e78e343536a65a2853af699fe68\",\"title\":\"TwoStreamVAN: Improving Motion Modeling in Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/05c43f1791787e78e343536a65a2853af699fe68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66747016\",\"name\":\"Ilia Sucholutsky\"},{\"authorId\":\"2174690\",\"name\":\"A. Narayan\"},{\"authorId\":\"1815604\",\"name\":\"Matthias Schonlau\"},{\"authorId\":\"1733430\",\"name\":\"Sebastian Fischmeister\"}],\"doi\":\"10.7717/PEERJ-CS.210\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d059c6a6345899ac018189d14e52067c07769fe9\",\"title\":\"Pay attention and you won't lose it: a deep learning approach to sequence imputation\",\"url\":\"https://www.semanticscholar.org/paper/d059c6a6345899ac018189d14e52067c07769fe9\",\"venue\":\"PeerJ Comput. Sci.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1818918\",\"name\":\"Sung-Jun Yoon\"},{\"authorId\":\"2029917\",\"name\":\"H. Kim\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":\"10.1109/TIP.2018.2861567\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9ee4d83403c76177bd434672bb3427944d4e054\",\"title\":\"Hierarchical Extended Bilateral Motion Estimation-Based Frame Rate Upconversion Using Learning-Based Linear Mapping\",\"url\":\"https://www.semanticscholar.org/paper/b9ee4d83403c76177bd434672bb3427944d4e054\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1902.05392\",\"authors\":[{\"authorId\":\"114986681\",\"name\":\"Talmaj Marinc\"},{\"authorId\":\"4365900\",\"name\":\"V. Srinivasan\"},{\"authorId\":\"51016259\",\"name\":\"S. G\\u00fcl\"},{\"authorId\":\"1691172\",\"name\":\"C. Hellge\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1109/ICIP.2019.8803335\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4b1fe8af2e320547e2d093f80a4bbc118e93b7b\",\"title\":\"Multi-Kernel Prediction Networks for Denoising of Burst Images\",\"url\":\"https://www.semanticscholar.org/paper/a4b1fe8af2e320547e2d093f80a4bbc118e93b7b\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2003.05534\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"98220548\",\"name\":\"F. Liu\"}],\"doi\":\"10.1109/CVPR42600.2020.00548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"title\":\"Softmax Splatting for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/82da38e2ddd8aebbc13d9e4505bc86ad83c0d6da\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.00080\",\"authors\":[{\"authorId\":\"40175280\",\"name\":\"Huaizu Jiang\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1389846455\",\"name\":\"E. Learned-Miller\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00938\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"title\":\"Super SloMo: High Quality Estimation of Multiple Intermediate Frames for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/baa1ae74fbf7ed6204f2f6364d51375ff81aabc1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2004.02432\",\"authors\":[{\"authorId\":\"2784241\",\"name\":\"Jaeyeon Kang\"},{\"authorId\":\"50008226\",\"name\":\"Younghyun Jo\"},{\"authorId\":\"3451982\",\"name\":\"S. Oh\"},{\"authorId\":\"48682997\",\"name\":\"P. Vajda\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-58607-2_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"title\":\"Deep Space-Time Video Upsampling Networks\",\"url\":\"https://www.semanticscholar.org/paper/fa3392f59cbf455a2083af5a4690903a0dbc15c8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1804.02684\",\"authors\":[{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2984787\",\"name\":\"Ronnachai Jaroensri\"},{\"authorId\":\"9340074\",\"name\":\"Changil Kim\"},{\"authorId\":\"1854465\",\"name\":\"M. Elgharib\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1007/978-3-030-01225-0_39\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07b8da845ff5b23428ad98307bb2d703d96eb337\",\"title\":\"Learning-based Video Motion Magnification\",\"url\":\"https://www.semanticscholar.org/paper/07b8da845ff5b23428ad98307bb2d703d96eb337\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491246951\",\"name\":\"Nour Hobloss\"},{\"authorId\":\"3150575\",\"name\":\"Andrei I. Purica\"},{\"authorId\":\"1768915\",\"name\":\"Attilio Fiandrotti\"},{\"authorId\":\"3129876\",\"name\":\"Marco Cagnazzo\"},{\"authorId\":\"1491246955\",\"name\":\"R\\u00e9mi Cozot\"},{\"authorId\":\"1931304\",\"name\":\"W. Hamidouche\"}],\"doi\":\"10.1109/IC3D48390.2019.8976000\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c888e6180bfbad01e65622f5fbdb1b4cdaac4846\",\"title\":\"A Hybrid Approach to Wide Baseline View Synthesis with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c888e6180bfbad01e65622f5fbdb1b4cdaac4846\",\"venue\":\"2019 International Conference on 3D Immersion (IC3D)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"title\":\"A Two-Stream Variational Adversarial Network for Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/99cd8f9920ba94ec9d85517f4975e1c4bee3c60a\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29846556\",\"name\":\"H. Yeo\"},{\"authorId\":\"81087377\",\"name\":\"Youngmok Jung\"},{\"authorId\":\"1684726\",\"name\":\"Jaehong Kim\"},{\"authorId\":\"143720148\",\"name\":\"Jinwoo Shin\"},{\"authorId\":\"1729324\",\"name\":\"D. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ffc06713436afc4e08bf4afa401ac52db674c5da\",\"title\":\"Neural Adaptive Content-aware Internet Video Delivery\",\"url\":\"https://www.semanticscholar.org/paper/ffc06713436afc4e08bf4afa401ac52db674c5da\",\"venue\":\"OSDI\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98f54360f4b3396523d130aab335ce757e37c6ec\",\"title\":\"Learning to Restore ssTEM Images from Deformation and Corruption\",\"url\":\"https://www.semanticscholar.org/paper/98f54360f4b3396523d130aab335ce757e37c6ec\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"title\":\"A Fast 4 K Video Frame Interpolation Using a Hybrid Task-Based Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/5c1e1e4fd2825d27033a4dcafa87580219d75e0a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145020198\",\"name\":\"L. Gao\"},{\"authorId\":\"30681669\",\"name\":\"Hongjie Jiang\"},{\"authorId\":\"1505461492\",\"name\":\"Kaiming Fu\"},{\"authorId\":\"96084589\",\"name\":\"Weikai He\"}],\"doi\":\"10.1109/BigData47090.2019.9005665\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"abbeea4bed73047308fee2fdc7fdc16e0f52e134\",\"title\":\"On Understanding Degradation Kinetics of Pharmaceutic Gelatin Matrices for Precision Medicine: A Deep Learning Approach\",\"url\":\"https://www.semanticscholar.org/paper/abbeea4bed73047308fee2fdc7fdc16e0f52e134\",\"venue\":\"2019 IEEE International Conference on Big Data (Big Data)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3035324\",\"name\":\"Tomer Peleg\"},{\"authorId\":\"15589668\",\"name\":\"P. Szekely\"},{\"authorId\":\"40462685\",\"name\":\"Doron Sabo\"},{\"authorId\":\"3059895\",\"name\":\"O. Sendik\"}],\"doi\":\"10.1109/CVPR.2019.00250\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"089f2072c95c244f3b7f4df404562bb4afe24448\",\"title\":\"IM-Net for High Resolution Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39110714\",\"name\":\"Thijs Vogels\"},{\"authorId\":\"1801097\",\"name\":\"F. Rousselle\"},{\"authorId\":\"2953855\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"51151761\",\"name\":\"Gerhard R\\u00f6thlin\"},{\"authorId\":\"144571055\",\"name\":\"A. Harvill\"},{\"authorId\":\"144576314\",\"name\":\"David Adler\"},{\"authorId\":\"145937851\",\"name\":\"M. Meyer\"},{\"authorId\":\"34011499\",\"name\":\"J. Nov\\u00e1k\"}],\"doi\":\"10.1145/3197517.3201388\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"30fe43dbdb09dfac6ce5c1d52164d9a95e3ed569\",\"title\":\"Denoising with kernel prediction and asymmetric loss functions\",\"url\":\"https://www.semanticscholar.org/paper/30fe43dbdb09dfac6ce5c1d52164d9a95e3ed569\",\"venue\":\"ACM Trans. Graph.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"6615978\",\"name\":\"Yang Zhao\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"}],\"doi\":\"10.1007/978-3-030-58595-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"title\":\"A Flexible Recurrent Residual Pyramid Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f291dd047bae0aa8d91921c3ae2f51e8d8effb61\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3220632\",\"name\":\"Hao Tao\"},{\"authorId\":\"144906876\",\"name\":\"L. Yu\"},{\"authorId\":\"121423004\",\"name\":\"Zhuo Kuang\"},{\"authorId\":\"1486522700\",\"name\":\"Hongkui Wang\"},{\"authorId\":\"46423009\",\"name\":\"Xiaofeng Huang\"}],\"doi\":\"10.1109/PCS48520.2019.8954532\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1941c4d5e50adcc7ba143b3d596e558e81bad000\",\"title\":\"An Extended Skip Strategy for Inter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1941c4d5e50adcc7ba143b3d596e558e81bad000\",\"venue\":\"2019 Picture Coding Symposium (PCS)\",\"year\":2019},{\"arxivId\":\"1904.12257\",\"authors\":[{\"authorId\":\"7523259\",\"name\":\"Shangchen Zhou\"},{\"authorId\":\"145345506\",\"name\":\"J. Zhang\"},{\"authorId\":\"9416881\",\"name\":\"J. Pan\"},{\"authorId\":\"3451627\",\"name\":\"Haozhe Xie\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46606038\",\"name\":\"Jimmy Ren\"}],\"doi\":\"10.1109/ICCV.2019.00257\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2227f3eeeb7d588b5647a4d599e69c154c66a73\",\"title\":\"Spatio-Temporal Filter Adaptive Network for Video Deblurring\",\"url\":\"https://www.semanticscholar.org/paper/a2227f3eeeb7d588b5647a4d599e69c154c66a73\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1909.12942\",\"authors\":[{\"authorId\":\"92403059\",\"name\":\"Zheyu Yang\"},{\"authorId\":\"72500851\",\"name\":\"Yujie Wu\"},{\"authorId\":\"80816621\",\"name\":\"Guanrui Wang\"},{\"authorId\":\"3365623\",\"name\":\"Y. Yang\"},{\"authorId\":\"1730243\",\"name\":\"Guoqi Li\"},{\"authorId\":\"144284633\",\"name\":\"Lei Deng\"},{\"authorId\":\"47055094\",\"name\":\"J. Zhu\"},{\"authorId\":\"29889772\",\"name\":\"Luping Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"636e62fc0b06c6e5b7d87e07a5bf088eb3ab711e\",\"title\":\"DashNet: A Hybrid Artificial and Spiking Neural Network for High-speed Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/636e62fc0b06c6e5b7d87e07a5bf088eb3ab711e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.04515\",\"authors\":[{\"authorId\":\"2033380760\",\"name\":\"Omer Dahary\"},{\"authorId\":\"2033358084\",\"name\":\"Matan Jacoby\"},{\"authorId\":\"121014776\",\"name\":\"A. M. Bronstein\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3dddbce4a7ef4e8e84d176707ec564602b6f025a\",\"title\":\"Digital Gimbal: End-to-end Deep Image Stabilization with Learnable Exposure Times\",\"url\":\"https://www.semanticscholar.org/paper/3dddbce4a7ef4e8e84d176707ec564602b6f025a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.00263\",\"authors\":[{\"authorId\":\"12601304\",\"name\":\"Qiangeng Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":null,\"name\":\"Weiyue Wang\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"},{\"authorId\":\"143840663\",\"name\":\"U. Neumann\"}],\"doi\":\"10.1109/WACV45572.2020.9093530\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"title\":\"Stochastic Dynamics for Video Infilling\",\"url\":\"https://www.semanticscholar.org/paper/56568a54bdb34d6164cf1267a94f07f81ca3a508\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2012.10066\",\"authors\":[{\"authorId\":\"143611184\",\"name\":\"Fan Lu\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"52532366\",\"name\":\"Sanqing Qu\"},{\"authorId\":\"46946977\",\"name\":\"Zhijun Li\"},{\"authorId\":\"2341727\",\"name\":\"Y. Liu\"},{\"authorId\":\"152948808\",\"name\":\"A. Knoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b7e6377d5d5d42c8b06a197465a281624dca8a4d\",\"title\":\"PointINet: Point Cloud Frame Interpolation Network\",\"url\":\"https://www.semanticscholar.org/paper/b7e6377d5d5d42c8b06a197465a281624dca8a4d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.05214\",\"authors\":[{\"authorId\":\"152298373\",\"name\":\"Sergiu Oprea\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"},{\"authorId\":\"1397392435\",\"name\":\"Alberto Garcia-Garcia\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1405686926\",\"name\":\"S. Orts-Escolano\"},{\"authorId\":\"1429069120\",\"name\":\"J. Garci\\u0301a-Rodri\\u0301guez\"},{\"authorId\":\"1689415\",\"name\":\"Antonis A. Argyros\"}],\"doi\":\"10.1109/TPAMI.2020.3045007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"title\":\"A Review on Deep Learning Techniques for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ded24959bbd7715073fa700d5898cdbb2b8353f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37310105\",\"name\":\"L. Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/ICIP.2018.8451465\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5ceb6240f266c2c1ab7aaef9c89f228b328b1c1a\",\"title\":\"Enhanced Ctu-Level Inter Prediction with Deep Frame Rate Up-Conversion for High Efficiency Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/5ceb6240f266c2c1ab7aaef9c89f228b328b1c1a\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1909.02641\",\"authors\":[{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1145/3363550\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1d6d8458ba00395159871106a0665403a00cfe5\",\"title\":\"Deep Iterative Frame Interpolation for Full-frame Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/c1d6d8458ba00395159871106a0665403a00cfe5\",\"venue\":\"ACM Trans. Graph.\",\"year\":2020},{\"arxivId\":\"2009.04642\",\"authors\":[{\"authorId\":\"49422053\",\"name\":\"Yihao Liu\"},{\"authorId\":\"1604613100\",\"name\":\"Liangbin Xie\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"},{\"authorId\":\"30459277\",\"name\":\"C. Dong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"title\":\"Enhanced Quadratic Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/091ffbd9852f9ba4f333af2ef9e77c0d70e6429a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65779048\",\"name\":\"Wenjun Wang\"},{\"authorId\":\"144533004\",\"name\":\"Chao Ren\"},{\"authorId\":\"2146255\",\"name\":\"X. He\"},{\"authorId\":\"6222832\",\"name\":\"Honggang Chen\"},{\"authorId\":\"3334291\",\"name\":\"Linbo Qing\"}],\"doi\":\"10.1109/ACCESS.2018.2829908\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c027c004925541dcc6072dcc296ec75acd9401f\",\"title\":\"Video Super-Resolution via Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/0c027c004925541dcc6072dcc296ec75acd9401f\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2004.11076\",\"authors\":[{\"authorId\":\"15678386\",\"name\":\"Z. Wang\"},{\"authorId\":\"49461394\",\"name\":\"Guoqing Li\"},{\"authorId\":\"46772427\",\"name\":\"X. Chen\"},{\"authorId\":\"78711732\",\"name\":\"H. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"74c7f393a7596c9b55b4fa5a2a73a32e3ce4b687\",\"title\":\"DAN: A Deformation-Aware Network for Consecutive Biomedical Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/74c7f393a7596c9b55b4fa5a2a73a32e3ce4b687\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.08373\",\"authors\":[{\"authorId\":\"10796882\",\"name\":\"Beomjun Kim\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"38723538\",\"name\":\"Bumsub Ham\"}],\"doi\":\"10.1007/S11263-020-01386-Z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e034c2a734690265134e339a2981a839c04e9e18\",\"title\":\"Deformable Kernel Networks for Joint Image Filtering\",\"url\":\"https://www.semanticscholar.org/paper/e034c2a734690265134e339a2981a839c04e9e18\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.13033\",\"authors\":[{\"authorId\":\"1389572577\",\"name\":\"Dario Fuoli\"},{\"authorId\":\"145314891\",\"name\":\"Z. Huang\"},{\"authorId\":\"35268081\",\"name\":\"D. Paudel\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c890b5ef847de07393526be4b6e337215e9dc1b6\",\"title\":\"An Efficient Recurrent Adversarial Framework for Unsupervised Real-Time Video Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/c890b5ef847de07393526be4b6e337215e9dc1b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145772051\",\"name\":\"Sifeng Xia\"},{\"authorId\":\"1898172\",\"name\":\"W. Yang\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803148\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae08cc53f2830f50d872433074c2dd747c18e011\",\"title\":\"Deep Inter Prediction Via Pixel-Wise Motion Oriented Reference Generation\",\"url\":\"https://www.semanticscholar.org/paper/ae08cc53f2830f50d872433074c2dd747c18e011\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49889937\",\"name\":\"Yimeng Zhang\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"1993581583\",\"name\":\"Bo Wu\"},{\"authorId\":\"30910424\",\"name\":\"A. Walid\"}],\"doi\":\"10.1145/3394171.3413527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"title\":\"Video Synthesis via Transform-Based Tensor Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/fe2437c17736da4b57791b0ce6d3084d4d3c4db7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143805731\",\"name\":\"L. Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TIP.2019.2913545\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47eea66c92a8e6f9fbb8497eb83f24540874eb70\",\"title\":\"Enhanced Motion-Compensated Video Coding With Deep Virtual Reference Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/47eea66c92a8e6f9fbb8497eb83f24540874eb70\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2007.12622\",\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"51268282\",\"name\":\"Keunsoo Ko\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1007/978-3-030-58568-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"title\":\"BMBC: Bilateral Motion Estimation with Bilateral Cost Volume for Video Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f38a0b306789afac22ed7f35291a17b8fbfa686f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32764534\",\"name\":\"Songnan Lin\"},{\"authorId\":\"50562044\",\"name\":\"J. Zhang\"},{\"authorId\":\"47739910\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Yongtian Wang\"},{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"46606038\",\"name\":\"Jimmy Ren\"}],\"doi\":\"10.1016/j.cviu.2020.103046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cffdc75d64f6a62a1c659a9354c7ad69bc418d4\",\"title\":\"Cross-spectral stereo matching for facial disparity estimation in the dark\",\"url\":\"https://www.semanticscholar.org/paper/2cffdc75d64f6a62a1c659a9354c7ad69bc418d4\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"2009.01005\",\"authors\":[{\"authorId\":\"150015249\",\"name\":\"Akash Gupta\"},{\"authorId\":\"2274692\",\"name\":\"Abhishek Aich\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3394171.3413686\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ed87dfe5ec1b3efa33016adf188d6d772aaef62\",\"title\":\"ALANET: Adaptive Latent Attention Network for Joint Video Deblurring and Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/3ed87dfe5ec1b3efa33016adf188d6d772aaef62\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.13784\",\"authors\":[{\"authorId\":\"49573957\",\"name\":\"D. Verma\"},{\"authorId\":\"1678985\",\"name\":\"A. Baghaie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17465f424f26b2a4861c283bebd4f86243e6de6b\",\"title\":\"Convolutional Neural Networks vs. Deformable Image Registration For Medical Slice Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/17465f424f26b2a4861c283bebd4f86243e6de6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00781\",\"authors\":[{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"1693096275\",\"name\":\"Lu Wang\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"47087084\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"28094546\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"88cc19540cd3785ae2225980220bfe8f91dd0015\",\"title\":\"Reducing the X-ray radiation exposure frequency in cardio-angiography via deep-learning based video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88cc19540cd3785ae2225980220bfe8f91dd0015\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668549\",\"name\":\"Y. Tanaka\"},{\"authorId\":\"144943482\",\"name\":\"Toshiaki Omori\"}],\"doi\":\"10.1145/3325773.3325777\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"37cbb412eac2eef8243facaabcdf85de85544e53\",\"title\":\"Spatio-Temporal Convolutional Neural Network for Frame Rate Up-Conversion\",\"url\":\"https://www.semanticscholar.org/paper/37cbb412eac2eef8243facaabcdf85de85544e53\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143668913\",\"name\":\"A. Kokaram\"},{\"authorId\":\"90126681\",\"name\":\"Davinder Singh\"},{\"authorId\":\"2000355837\",\"name\":\"Simon Robinson\"}],\"doi\":\"10.1109/ICIP40778.2020.9191152\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"74510e871016eb629b504bab5df12f8b4ca9e9ec\",\"title\":\"A Bayesian View of Frame Interpolation and a Comparison with Existing Motion Picture Effects Tools\",\"url\":\"https://www.semanticscholar.org/paper/74510e871016eb629b504bab5df12f8b4ca9e9ec\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1901.00062\",\"authors\":[{\"authorId\":\"3320198\",\"name\":\"Hyomin Choi\"},{\"authorId\":\"1730101\",\"name\":\"I. Bajic\"}],\"doi\":\"10.1109/TCSVT.2019.2924657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61d4062392f476edf0346900cef020ef18cd1760\",\"title\":\"Deep Frame Prediction for Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/61d4062392f476edf0346900cef020ef18cd1760\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358901\",\"name\":\"Zhifeng Zhang\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"},{\"authorId\":\"1381430536\",\"name\":\"Rang Xie\"},{\"authorId\":\"144423422\",\"name\":\"L. Chen\"}],\"doi\":\"10.1109/BigMM.2018.8499065\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c81bd3c7d9949daeba47f87dd439c48d8f1fdd19\",\"title\":\"Video Frame Interpolation Using Recurrent Convolutional Layers\",\"url\":\"https://www.semanticscholar.org/paper/c81bd3c7d9949daeba47f87dd439c48d8f1fdd19\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"2002.03500\",\"authors\":[{\"authorId\":\"49259808\",\"name\":\"Q. Guo\"},{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"49419199\",\"name\":\"Xiaofei Xie\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":null,\"name\":\"Jian Wang\"},{\"authorId\":\"1485043101\",\"name\":\"Bing Yu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"38057121\",\"name\":\"Yang Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62fc847ae50b004c114ce7f44861331fdce37e79\",\"title\":\"Watch out! Motion is Blurring the Vision of Your Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/62fc847ae50b004c114ce7f44861331fdce37e79\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93299623\",\"name\":\"Bumjun Park\"},{\"authorId\":\"150311567\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"1557273080\",\"name\":\"Jechang Jeong\"}],\"doi\":\"10.1109/ICCVW.2019.00433\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2141bb1226997c49123731d97b484ca19696485a\",\"title\":\"Robust Temporal Super-Resolution for Dynamic Motion Videos\",\"url\":\"https://www.semanticscholar.org/paper/2141bb1226997c49123731d97b484ca19696485a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51152279\",\"name\":\"Daniel Gehrig\"},{\"authorId\":\"8329387\",\"name\":\"M. Gehrig\"},{\"authorId\":\"1406402485\",\"name\":\"Javier Hidalgo-Carri'o\"},{\"authorId\":\"2075371\",\"name\":\"D. Scaramuzza\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f877010d390ea6ab73608637ba1f0865ba066f12\",\"title\":\"Video to Events: Bringing Modern Computer Vision Closer to Event Cameras\",\"url\":\"https://www.semanticscholar.org/paper/f877010d390ea6ab73608637ba1f0865ba066f12\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1825026\",\"name\":\"Yang Zhou\"},{\"authorId\":\"144204050\",\"name\":\"L. Chen\"},{\"authorId\":\"1728718\",\"name\":\"Jiying Zhao\"}],\"doi\":\"10.1109/PACRIM47961.2019.8985104\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b114ba0c42b77ea0f7def03e8431b506ade16cc\",\"title\":\"Video Super-Resolution with Compensation in Feature Extraction\",\"url\":\"https://www.semanticscholar.org/paper/9b114ba0c42b77ea0f7def03e8431b506ade16cc\",\"venue\":\"2019 IEEE Pacific Rim Conference on Communications, Computers and Signal Processing (PACRIM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8187964\",\"name\":\"R. Aoki\"},{\"authorId\":\"1800246\",\"name\":\"R. Miyamoto\"}],\"doi\":\"10.1109/MetroArchaeo43810.2018.13594\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5220c60d57f7a5889737c1a29a35693e946238dc\",\"title\":\"Problems in Three-Dimensional Measurement of Japanese Kenjutsu Using Existing Sensing Devices\",\"url\":\"https://www.semanticscholar.org/paper/5220c60d57f7a5889737c1a29a35693e946238dc\",\"venue\":\"2018 Metrology for Archaeology and Cultural Heritage (MetroArchaeo)\",\"year\":2018},{\"arxivId\":\"1904.02909\",\"authors\":[{\"authorId\":\"9757384\",\"name\":\"Woon-Sung Park\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b87df69011057c700f581798e8c13667f5205b8e\",\"title\":\"Deep Predictive Video Compression with Bi-directional Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b87df69011057c700f581798e8c13667f5205b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46398521\",\"name\":\"Y. Liu\"},{\"authorId\":\"66821424\",\"name\":\"Yi-Tung Liao\"},{\"authorId\":\"1744044\",\"name\":\"Yen-Yu Lin\"},{\"authorId\":\"143708263\",\"name\":\"Yung-Yu Chuang\"}],\"doi\":\"10.1609/AAAI.V33I01.33018794\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"92f3548ff323a65981aed274c0b124053dce2e73\",\"title\":\"Deep Video Frame Interpolation Using Cyclic Frame Generation\",\"url\":\"https://www.semanticscholar.org/paper/92f3548ff323a65981aed274c0b124053dce2e73\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20789359\",\"name\":\"Jung-Kyung Lee\"},{\"authorId\":\"1681225\",\"name\":\"Na-young Kim\"},{\"authorId\":\"49467251\",\"name\":\"Seunghyun Cho\"},{\"authorId\":\"153041302\",\"name\":\"Jewon Kang\"}],\"doi\":\"10.1109/ACCESS.2020.2993566\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7c7bc4ac7d28f3646e8fecf8c5e160d7c65442c5\",\"title\":\"Deep Video Prediction Network-ased Inter-Frame Coding in HEVC\",\"url\":\"https://www.semanticscholar.org/paper/7c7bc4ac7d28f3646e8fecf8c5e160d7c65442c5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"2512006\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1117/1.JEI.28.4.043002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"title\":\"Multiframe interpolation for video using phase features\",\"url\":\"https://www.semanticscholar.org/paper/579c0f9efe9932469f036bdf10c333455c2b3bd5\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9508145\",\"name\":\"Morten Hannemose\"},{\"authorId\":\"144454181\",\"name\":\"Janus N\\u00f8rtoft Jensen\"},{\"authorId\":\"48660142\",\"name\":\"G. Einarsson\"},{\"authorId\":\"2579225\",\"name\":\"J. Wilm\"},{\"authorId\":\"2253200\",\"name\":\"A. Dahl\"},{\"authorId\":\"2661305\",\"name\":\"J. Frisvad\"}],\"doi\":\"10.1007/978-3-030-20205-7_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"title\":\"Video Frame Interpolation via Cyclic Fine-Tuning and Asymmetric Reverse Flow\",\"url\":\"https://www.semanticscholar.org/paper/7eb50a9f19eefb7db02d5955edc6c681a5d23e72\",\"venue\":\"SCIA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90618143\",\"name\":\"Byung-Ju Choi\"},{\"authorId\":\"8289290\",\"name\":\"Jun-Hyung Park\"},{\"authorId\":\"3001565\",\"name\":\"Sangkeun Lee\"}],\"doi\":\"10.18653/v1/N19-1256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"596cf07d07dcf0159cf3fe06a60dd10f40b50b03\",\"title\":\"Adaptive Convolution for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/596cf07d07dcf0159cf3fe06a60dd10f40b50b03\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"1809.05286\",\"authors\":[{\"authorId\":\"80480198\",\"name\":\"Kian Ghodoussi\"},{\"authorId\":\"48253357\",\"name\":\"Nihar Sheth\"},{\"authorId\":\"80726083\",\"name\":\"Zane Durante\"},{\"authorId\":\"145472140\",\"name\":\"M. Wagner\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cc0d9e4478a444b170bbd3311dde7713e1debaf2\",\"title\":\"Deep CNN Frame Interpolation with Lessons Learned from Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/cc0d9e4478a444b170bbd3311dde7713e1debaf2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153690347\",\"name\":\"Yoonmo Yang\"},{\"authorId\":\"1831183\",\"name\":\"Byung Tae Oh\"}],\"doi\":\"10.1016/j.image.2020.115982\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"title\":\"Video frame interpolation using deep cascaded network structure\",\"url\":\"https://www.semanticscholar.org/paper/a18bd84728b5d9e3208dcc4ce9bbe11d2c0fca1c\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.11745\",\"authors\":[{\"authorId\":\"145661449\",\"name\":\"T. Brooks\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"}],\"doi\":\"10.1109/CVPR.2019.00700\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c945dfec0137bcd7886898fa61f46705e00173dc\",\"title\":\"Learning to Synthesize Motion Blur\",\"url\":\"https://www.semanticscholar.org/paper/c945dfec0137bcd7886898fa61f46705e00173dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.06244\",\"authors\":[{\"authorId\":\"30264154\",\"name\":\"Thierry Dumas\"},{\"authorId\":\"144023664\",\"name\":\"A. Roumy\"},{\"authorId\":\"1780587\",\"name\":\"C. Guillemot\"}],\"doi\":\"10.1109/TIP.2019.2934565\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"979766fa82a4757448d175bbf216f327ff87c07f\",\"title\":\"Context-Adaptive Neural Network-Based Prediction for Image Compression\",\"url\":\"https://www.semanticscholar.org/paper/979766fa82a4757448d175bbf216f327ff87c07f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2002.11616\",\"authors\":[{\"authorId\":\"48147750\",\"name\":\"Xiaoyu Xiang\"},{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2410227\",\"name\":\"Yulun Zhang\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"},{\"authorId\":\"1741931\",\"name\":\"J. Allebach\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00343\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"title\":\"Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a140ca6ac4847c13219bf9f4401153ad53fce71e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10796882\",\"name\":\"Beomjun Kim\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"},{\"authorId\":\"38723538\",\"name\":\"Bumsub Ham\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ddb6b7a77e8ae33224d82ae21f99c3ca3c496222\",\"title\":\"Weight : Reshape : Residual connection : Sigmoid : Mean subtraction\",\"url\":\"https://www.semanticscholar.org/paper/ddb6b7a77e8ae33224d82ae21f99c3ca3c496222\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561919\",\"name\":\"W. Xie\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1016/J.IMAGE.2018.12.002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2e66cb1f4140f93efd2e76a03bcda9fe7cd64c4\",\"title\":\"A survey of variational and CNN-based optical flow techniques\",\"url\":\"https://www.semanticscholar.org/paper/a2e66cb1f4140f93efd2e76a03bcda9fe7cd64c4\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15330679\",\"name\":\"Z. Gong\"},{\"authorId\":\"1390867127\",\"name\":\"Ziyi Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77606c3157c4e892a95a0982ca49cd20d7b9b3ab\",\"title\":\"Video Frame Interpolation and Extrapolation\",\"url\":\"https://www.semanticscholar.org/paper/77606c3157c4e892a95a0982ca49cd20d7b9b3ab\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1806.00088\",\"authors\":[{\"authorId\":\"145348186\",\"name\":\"J. Svoboda\"},{\"authorId\":\"2426718\",\"name\":\"J. Masci\"},{\"authorId\":\"2500309\",\"name\":\"Federico Monti\"},{\"authorId\":\"1732570\",\"name\":\"M. Bronstein\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfb0d179916c000d54f27e7a9ea18b6269963e74\",\"title\":\"PeerNets: Exploiting Peer Wisdom Against Adversarial Attacks\",\"url\":\"https://www.semanticscholar.org/paper/bfb0d179916c000d54f27e7a9ea18b6269963e74\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1803.10967\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"40405236\",\"name\":\"Feng Liu\"}],\"doi\":\"10.1109/CVPR.2018.00183\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"65fadccad0fc743876a259c2b779622636c2ffde\",\"title\":\"Context-Aware Synthesis for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/65fadccad0fc743876a259c2b779622636c2ffde\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.00718\",\"authors\":[{\"authorId\":\"1500723899\",\"name\":\"Mario Lino Valencia\"},{\"authorId\":\"12717675\",\"name\":\"C. Cantwell\"},{\"authorId\":\"123727301\",\"name\":\"Stathi Fotiadis\"},{\"authorId\":\"146646051\",\"name\":\"Eduardo Pignatelli\"},{\"authorId\":\"2815535\",\"name\":\"A. Bharath\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a0ba8f37186037ea4f12b52cdc8ea2c9cddb79d\",\"title\":\"Simulating Surface Wave Dynamics with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/9a0ba8f37186037ea4f12b52cdc8ea2c9cddb79d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144796690\",\"name\":\"Si Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"title\":\"High-speed Video from Asynchronous Camera Array Si\",\"url\":\"https://www.semanticscholar.org/paper/1e5e5788d2098d3be529caaa3cdf9e7f3e4a0749\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144324729\",\"name\":\"Jun Han\"},{\"authorId\":\"40505818\",\"name\":\"Chaoli Wang\"}],\"doi\":\"10.1109/TVCG.2019.2934255\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"107e9ea4a3ee66cfb85ec84dbe53e6831f793a8b\",\"title\":\"TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization\",\"url\":\"https://www.semanticscholar.org/paper/107e9ea4a3ee66cfb85ec84dbe53e6831f793a8b\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98080420\",\"name\":\"Hyeongmin Lee\"},{\"authorId\":\"48271129\",\"name\":\"Taeoh Kim\"},{\"authorId\":\"3305074\",\"name\":\"Tae-Young Chung\"},{\"authorId\":\"48322708\",\"name\":\"Daehyun Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"3055035\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"946a9a5d18a423de9c109087ecae818809276b9c\",\"title\":\"Learning Spatial Transform for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/946a9a5d18a423de9c109087ecae818809276b9c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48633955\",\"name\":\"Zhenghui Zhao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"46477671\",\"name\":\"Jiansheng Yang\"}],\"doi\":\"10.1109/TCSVT.2018.2876399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eca81541bf67741779bcb51760b43ecacc473d8f\",\"title\":\"Enhanced Bi-Prediction With Convolutional Neural Network for High-Efficiency Video Coding\",\"url\":\"https://www.semanticscholar.org/paper/eca81541bf67741779bcb51760b43ecacc473d8f\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101736874\",\"name\":\"Ignacio Reimat Corbella\"},{\"authorId\":\"1693381468\",\"name\":\"Irene Viola\"},{\"authorId\":\"1665018544\",\"name\":\"Pablo C\\u00e9sar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce84cb3209c0da9a250d64a78d91b937add0e84f\",\"title\":\"Temporal Interpolation of human point clouds using neural networks and body part segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ce84cb3209c0da9a250d64a78d91b937add0e84f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Qing Guo\"},{\"authorId\":null,\"name\":\"Felix Juefei-Xu\"},{\"authorId\":null,\"name\":\"Xiaofei Xie\"},{\"authorId\":null,\"name\":\"Lei Ma\"},{\"authorId\":null,\"name\":\"Jian Wang\"},{\"authorId\":null,\"name\":\"Bing Yu\"},{\"authorId\":null,\"name\":\"Wei Feng\"},{\"authorId\":null,\"name\":\"Yang Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3e3ab0ee7f9c7faa0501049ac50419b15b16e612\",\"title\":\"Watch out! Motion is Blurring Blurring the Vision of Your Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3e3ab0ee7f9c7faa0501049ac50419b15b16e612\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2943460\",\"name\":\"Thomas Vandal\"},{\"authorId\":\"153866793\",\"name\":\"R. Nemani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"003ef05f414b2eca59d2a04712138f75b4b4d318\",\"title\":\"Optical Flow for Intermediate Frame Interpolation of Multispectral Geostationary Satellite Data\",\"url\":\"https://www.semanticscholar.org/paper/003ef05f414b2eca59d2a04712138f75b4b4d318\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2744923\",\"name\":\"L. Zhou\"},{\"authorId\":\"2573672\",\"name\":\"Yaowu Chen\"},{\"authorId\":\"145037825\",\"name\":\"Xiang Tian\"},{\"authorId\":\"3115947\",\"name\":\"Rongxin Jiang\"}],\"doi\":\"10.1109/ICIP.2019.8803678\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a3078e39137a59af12f49a985c3b1e1765d51eba\",\"title\":\"Frame Interpolation Using Phase and Amplitude Feature Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/a3078e39137a59af12f49a985c3b1e1765d51eba\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1911.00627\",\"authors\":[{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"123100665\",\"name\":\"Q. Yin\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6296ec34c6e792729ec47195727d2ab17d27a50e\",\"title\":\"Quadratic video interpolation\",\"url\":\"https://www.semanticscholar.org/paper/6296ec34c6e792729ec47195727d2ab17d27a50e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5a964ea01b63f84ed4dc22a5412df3aaee8cba6\",\"title\":\"On the other hand , spatial formulations of graph CNNs operate on local neighborhoods on the graph\",\"url\":\"https://www.semanticscholar.org/paper/f5a964ea01b63f84ed4dc22a5412df3aaee8cba6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chance Hamilton\"},{\"authorId\":\"6439443\",\"name\":\"J. Ventura\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c0ca6a22a0b5a2e7ec1544e72a27758a3c790bc2\",\"title\":\"Video Frame Interpolation via Pixel Polynomial Modeling\",\"url\":\"https://www.semanticscholar.org/paper/c0ca6a22a0b5a2e7ec1544e72a27758a3c790bc2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.11698\",\"authors\":[{\"authorId\":\"1491292845\",\"name\":\"Zhaotao Wu\"},{\"authorId\":\"1471334007\",\"name\":\"J. Wei\"},{\"authorId\":\"150341007\",\"name\":\"Wenguang Yuan\"},{\"authorId\":\"2246972\",\"name\":\"J. Wang\"},{\"authorId\":\"3198175\",\"name\":\"T. Tasdizen\"}],\"doi\":\"10.3233/FAIA200314\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"title\":\"Inter-slice image augmentation based on frame interpolation for boosting medical image segmentation accuracy\",\"url\":\"https://www.semanticscholar.org/paper/f81d115ec43e49ec7f0eb8ed8f9afdfa65ded5c1\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358901\",\"name\":\"Zhifeng Zhang\"},{\"authorId\":\"144423422\",\"name\":\"L. Chen\"},{\"authorId\":\"1773394\",\"name\":\"Rong Xie\"},{\"authorId\":\"1391025682\",\"name\":\"L. Song\"}],\"doi\":\"10.1109/ICIP.2018.8451847\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0e3935a84c68cf4ddd696e09e56a2689a10957da\",\"title\":\"Frame Interpolation via Refined Deep Voxel Flow\",\"url\":\"https://www.semanticscholar.org/paper/0e3935a84c68cf4ddd696e09e56a2689a10957da\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993383158\",\"name\":\"Zeyu Xiao\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"},{\"authorId\":\"3061449\",\"name\":\"Xueyang Fu\"},{\"authorId\":\"153626238\",\"name\":\"D. Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1145/3394171.3413667\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"19b051580cb309ef990b77875d13ac7dd4e5950a\",\"title\":\"Space-Time Video Super-Resolution Using Temporal Profiles\",\"url\":\"https://www.semanticscholar.org/paper/19b051580cb309ef990b77875d13ac7dd4e5950a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46489265\",\"name\":\"Yu-Ying Yeh\"},{\"authorId\":\"1614039983\",\"name\":\"Y. Liu\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"},{\"authorId\":null,\"name\":\"Yu-Chiang Frank Wang\"}],\"doi\":\"10.1109/TETCI.2020.2968599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"title\":\"Static2Dynamic: Video Inference From a Deep Glimpse\",\"url\":\"https://www.semanticscholar.org/paper/d96db0e2164f464ef9dc5dd030672ea3e3c02d57\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2020},{\"arxivId\":\"1904.00523\",\"authors\":[{\"authorId\":\"22275884\",\"name\":\"Jianrui Cai\"},{\"authorId\":\"72910911\",\"name\":\"Hui Zeng\"},{\"authorId\":\"7906116\",\"name\":\"Hongwei Yong\"},{\"authorId\":\"2824404\",\"name\":\"Zisheng Cao\"},{\"authorId\":\"47058801\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00318\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a646c1e52c081a266638785134d3e6dc3a3e7068\",\"title\":\"Toward Real-World Single Image Super-Resolution: A New Benchmark and a New Model\",\"url\":\"https://www.semanticscholar.org/paper/a646c1e52c081a266638785134d3e6dc3a3e7068\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1762967\",\"name\":\"J. Munkberg\"},{\"authorId\":\"2266452\",\"name\":\"J. Hasselgren\"}],\"doi\":\"10.1111/cgf.14049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42f9541fa8d48370e87043450c8c4ab2a8d9c187\",\"title\":\"Neural Denoising with Layer Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/42f9541fa8d48370e87043450c8c4ab2a8d9c187\",\"venue\":\"Comput. Graph. Forum\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145746402\",\"name\":\"X. Jin\"},{\"authorId\":\"31482866\",\"name\":\"Zhibo Chen\"},{\"authorId\":\"2345721\",\"name\":\"S. Liu\"},{\"authorId\":\"1720145\",\"name\":\"Wei Zhou\"}],\"doi\":\"10.1007/978-3-030-03398-9_38\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8244984fb91dca8f24d3d8ded565586faf9ed9d8\",\"title\":\"Augmented Coarse-to-Fine Video Frame Synthesis with Semantic Loss\",\"url\":\"https://www.semanticscholar.org/paper/8244984fb91dca8f24d3d8ded565586faf9ed9d8\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"2011.01280\",\"authors\":[{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"title\":\"Revisiting Adaptive Convolutions for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/88b1113f94c0ab9521af358f4d9f7e9bff643e12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.02912\",\"authors\":[{\"authorId\":\"40897201\",\"name\":\"Tsun-Hsuan Wang\"},{\"authorId\":\"94288126\",\"name\":\"Y. Cheng\"},{\"authorId\":\"49044307\",\"name\":\"Chieh Hubert Lin\"},{\"authorId\":\"1803730\",\"name\":\"Hwann-Tzong Chen\"},{\"authorId\":\"145718481\",\"name\":\"Min Sun\"}],\"doi\":\"10.1109/ICCV.2019.01059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"title\":\"Point-to-Point Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/cb0a151cf8740c66b461ff809e086b91f14bd23b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.06348\",\"authors\":[{\"authorId\":\"2571876\",\"name\":\"H. Liu\"},{\"authorId\":\"11815649\",\"name\":\"H. Shen\"},{\"authorId\":\"47033130\",\"name\":\"Lichao Huang\"},{\"authorId\":\"98788334\",\"name\":\"Meining Lu\"},{\"authorId\":\"71628916\",\"name\":\"Tong Chen\"},{\"authorId\":\"1762531\",\"name\":\"Zhan Ma\"}],\"doi\":\"10.1609/AAAI.V34I07.6825\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"239f5664c65312b9baab166028918944d466553c\",\"title\":\"Learned Video Compression via Joint Spatial-Temporal Correlation Exploration\",\"url\":\"https://www.semanticscholar.org/paper/239f5664c65312b9baab166028918944d466553c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388359\",\"name\":\"C. Li\"},{\"authorId\":\"1987649\",\"name\":\"Youdong Ding\"},{\"authorId\":\"46806278\",\"name\":\"Ting Yu\"},{\"authorId\":\"145093161\",\"name\":\"M. Xu\"},{\"authorId\":\"1769443\",\"name\":\"Q. Zhang\"}],\"doi\":\"10.1109/ICALIP.2018.8455233\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd5ec545315814204d4aae64647347caa92493f6\",\"title\":\"Inpainting of Continuous Frames of Old Movies Based on Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/dd5ec545315814204d4aae64647347caa92493f6\",\"venue\":\"2018 International Conference on Audio, Language and Image Processing (ICALIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46293528\",\"name\":\"M. K. Lee\"},{\"authorId\":\"2866383\",\"name\":\"Dong-Yoon Choi\"},{\"authorId\":\"3835816\",\"name\":\"D. Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.1109/FG.2019.8756551\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0fbda098fb938dc61e6e3815242bd0f4c46bd731\",\"title\":\"Visual Scene-aware Hybrid Neural Network Architecture for Video-based Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0fbda098fb938dc61e6e3815242bd0f4c46bd731\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"2006.08070\",\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db79a9a20acb3c15256655d52bb40e8831bb2345\",\"title\":\"Multiple Video Frame Interpolation via Enhanced Deformable Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/db79a9a20acb3c15256655d52bb40e8831bb2345\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.09294\",\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.1109/LSP.2020.3008082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"540e02b0ec5fbc470ebecb58689a16aba49f848e\",\"title\":\"Self-Supervised Light Field Reconstruction Using Shearlet Transform and Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/540e02b0ec5fbc470ebecb58689a16aba49f848e\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50105307\",\"name\":\"Wenchao Hu\"},{\"authorId\":\"50218026\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1007/978-3-030-31723-2_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f9224ec46346e53aeaa5951906e48699f914b9f\",\"title\":\"A Multi-frame Video Interpolation Neural Network for Large Motion\",\"url\":\"https://www.semanticscholar.org/paper/7f9224ec46346e53aeaa5951906e48699f914b9f\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471436975\",\"name\":\"Anh-Duc Nguyen\"},{\"authorId\":\"2257525\",\"name\":\"W. Kim\"},{\"authorId\":\"2078790\",\"name\":\"Jongyoo Kim\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"},{\"authorId\":\"104009756\",\"name\":\"S. Lee\"}],\"doi\":\"10.1109/ACCESS.2019.2959019\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"title\":\"Video Frame Synthesis via Plug-and-Play Deep Locally Temporal Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6cf97ff4821d9af7e370e153fac865077d0f26f5\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2318546\",\"name\":\"Shiping Wen\"},{\"authorId\":\"49663634\",\"name\":\"W. Liu\"},{\"authorId\":\"46286125\",\"name\":\"Y. Yang\"},{\"authorId\":\"145582475\",\"name\":\"T. Huang\"},{\"authorId\":\"145043786\",\"name\":\"Z. Zeng\"}],\"doi\":\"10.1109/TCSVT.2018.2867934\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84e5e611baa362ccce571eef737c98de7a5331b5\",\"title\":\"Generating Realistic Videos From Keyframes With Concatenated GANs\",\"url\":\"https://www.semanticscholar.org/paper/84e5e611baa362ccce571eef737c98de7a5331b5\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1810.08768\",\"authors\":[{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"9117564\",\"name\":\"X. Zhang\"},{\"authorId\":\"145071557\",\"name\":\"Z. Gao\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/tpami.2019.2941941\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d833c48334e906537f21757b6f9fa44da66f6c76\",\"title\":\"MEMC-Net: Motion Estimation and Motion Compensation Driven Neural Network for Video Interpolation and Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d833c48334e906537f21757b6f9fa44da66f6c76\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70489777\",\"name\":\"Ha-Eun Ahn\"},{\"authorId\":\"1683954\",\"name\":\"Jinwoo Jeong\"},{\"authorId\":\"2433705\",\"name\":\"J. Kim\"},{\"authorId\":\"92733026\",\"name\":\"Soon-chul Kwon\"},{\"authorId\":\"1773696\",\"name\":\"Ji-Sang Yoo\"}],\"doi\":\"10.3390/sym11101251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"title\":\"A Fast 4K Video Frame Interpolation Using a Multi-Scale Optical Flow Reconstruction Network\",\"url\":\"https://www.semanticscholar.org/paper/20e1a4824df1cf8583e5d64f95ef6b3b0acae1cb\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5708b5345e42279b54fa213187120d878c0fdb7e\",\"title\":\"With Ground Truth Flows Case II : With Task-Oriented Flows Input frames TOFlow Warped by TOFlow Denoised frame Video Denoising ?\",\"url\":\"https://www.semanticscholar.org/paper/5708b5345e42279b54fa213187120d878c0fdb7e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93576086\",\"name\":\"H. Lin\"},{\"authorId\":\"1749408\",\"name\":\"P. Hsiu\"},{\"authorId\":\"145348862\",\"name\":\"T. Kuo\"},{\"authorId\":\"47905461\",\"name\":\"Yen-Yu Lin\"}],\"doi\":\"10.24963/ijcai.2020/86\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4876853ba05de357601750ac2708821ae146ad4\",\"title\":\"Spatiotemporal Super-Resolution with Cross-Task Consistency and Its Semi-supervised Extension\",\"url\":\"https://www.semanticscholar.org/paper/a4876853ba05de357601750ac2708821ae146ad4\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1910.08313\",\"authors\":[{\"authorId\":\"145585485\",\"name\":\"B. Zhang\"},{\"authorId\":\"1390749745\",\"name\":\"Shenyao Jin\"},{\"authorId\":\"1741540\",\"name\":\"Y. Xia\"},{\"authorId\":\"48355817\",\"name\":\"Y. Huang\"},{\"authorId\":\"144723535\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053332\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee6f2e0cc43424ec27cb7f0dd09b7b924dd4d975\",\"title\":\"Attention Mechanism Enhanced Kernel Prediction Networks for Denoising of Burst Images\",\"url\":\"https://www.semanticscholar.org/paper/ee6f2e0cc43424ec27cb7f0dd09b7b924dd4d975\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1907.10244\",\"authors\":[{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"3191728\",\"name\":\"T. Chung\"},{\"authorId\":\"48322708\",\"name\":\"D. Pak\"},{\"authorId\":\"2417978\",\"name\":\"Yuseok Ban\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00536\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"title\":\"AdaCoF: Adaptive Collaboration of Flows for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/af480bfec4eb0a8182ad52c0d0699fb86da8609b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115539898\",\"name\":\"J. Park\"},{\"authorId\":\"39876415\",\"name\":\"C. Lee\"},{\"authorId\":\"96521675\",\"name\":\"Chang-Su Kim\"}],\"doi\":\"10.1109/APSIPAASC47483.2019.9023270\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"title\":\"Deep Learning Approach to Video Frame Rate Up-Conversion Using Bilateral Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/dd5a32ee12e1d49b3c69863c583ef063b753a289\",\"venue\":\"2019 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)\",\"year\":2019},{\"arxivId\":\"2011.13084\",\"authors\":[{\"authorId\":\"8763474\",\"name\":\"Z. Li\"},{\"authorId\":\"39644974\",\"name\":\"Simon Niklaus\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"},{\"authorId\":\"1660745575\",\"name\":\"Oliver Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"13034a395d5c6728c9b11e777828d9998018cbf6\",\"title\":\"Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes\",\"url\":\"https://www.semanticscholar.org/paper/13034a395d5c6728c9b11e777828d9998018cbf6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384172999\",\"name\":\"Jiankai Zhuang\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1994473526\",\"name\":\"Jialu Chen\"},{\"authorId\":\"153482287\",\"name\":\"Tao Wan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3ea880503b53238fa6fcc4e4a1a24c230874999\",\"title\":\"A Lightweight Network Model For Video Frame Interpolation Using Spatial Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/e3ea880503b53238fa6fcc4e4a1a24c230874999\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2007.11762\",\"authors\":[{\"authorId\":\"35793956\",\"name\":\"Zhixiang Chi\"},{\"authorId\":\"49456126\",\"name\":\"R. Nasiri\"},{\"authorId\":\"2114344\",\"name\":\"Z. Liu\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"37864689\",\"name\":\"Jin Tang\"},{\"authorId\":\"37932469\",\"name\":\"K. Plataniotis\"}],\"doi\":\"10.1007/978-3-030-58583-9_7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e07d015d548162756e479934b245299e4aa737d0\",\"title\":\"All at Once: Temporally Adaptive Multi-Frame Interpolation with Advanced Motion Modeling\",\"url\":\"https://www.semanticscholar.org/paper/e07d015d548162756e479934b245299e4aa737d0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.12106\",\"authors\":[{\"authorId\":\"51308376\",\"name\":\"A. Paliwal\"},{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"}],\"doi\":\"10.1109/TPAMI.2020.2987316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c82944c88e0be99857a280d8246593842c515a0\",\"title\":\"Deep Slow Motion Video Reconstruction With Hybrid Imaging System\",\"url\":\"https://www.semanticscholar.org/paper/5c82944c88e0be99857a280d8246593842c515a0\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1486417554\",\"name\":\"Ren-Yu Tseng\"},{\"authorId\":\"1604961801\",\"name\":\"Yao-Kai Liu\"},{\"authorId\":\"37284667\",\"name\":\"Ju-Chin Chen\"},{\"authorId\":\"21754565\",\"name\":\"Kawuu W. Lin\"}],\"doi\":\"10.1109/TAAI48200.2019.8959822\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"title\":\"Adaptive Frame Interpolation using an End-to-End Deep Net with High Quality Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b96251b8666b1e4ed0eb2f309d559f3528e09710\",\"venue\":\"2019 International Conference on Technologies and Applications of Arti\\ufb01cial Intelligence (TAAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"}],\"doi\":\"10.1109/TMM.2019.2946475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0cd4513409f0e4942dc5890d2530ddeda1b800e\",\"title\":\"Uni-and-Bi-Directional Video Prediction via Learning Object-Centric Transformation\",\"url\":\"https://www.semanticscholar.org/paper/e0cd4513409f0e4942dc5890d2530ddeda1b800e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153269936\",\"name\":\"J. Xiao\"},{\"authorId\":\"49997317\",\"name\":\"Xiaojun Bi\"}],\"doi\":\"10.1109/ACCESS.2020.2995705\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"title\":\"Multi-Scale Attention Generative Adversarial Networks for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/da8b5876438d5c7f4caf6cfabc4252e0863dac8b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46179701\",\"name\":\"Yicun Liu\"},{\"authorId\":\"1500380173\",\"name\":\"Jimmy Ren\"},{\"authorId\":\"1519062623\",\"name\":\"Jiawei Zhang\"},{\"authorId\":\"120809851\",\"name\":\"Jianbo Liu\"},{\"authorId\":\"3388973\",\"name\":\"Mude Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00210\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b131d255bf8bff6c4bac765c57190e2f448b2b2b\",\"title\":\"Visually Imbalanced Stereo Matching\",\"url\":\"https://www.semanticscholar.org/paper/b131d255bf8bff6c4bac765c57190e2f448b2b2b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.1109/ICIP.2019.8803436\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de3680029069acdc287c62fa0b632f8140b1578a\",\"title\":\"Fast: Flow-Assisted Shearlet Transform for Densely-Sampled Light Field Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/de3680029069acdc287c62fa0b632f8140b1578a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144436744\",\"name\":\"Tao Hu\"},{\"authorId\":\"143869239\",\"name\":\"Chao Liang\"},{\"authorId\":\"1410621160\",\"name\":\"G. Min\"},{\"authorId\":\"153141874\",\"name\":\"Keqin Li\"},{\"authorId\":\"2420700\",\"name\":\"Chunxia Xiao\"}],\"doi\":\"10.1016/j.jvcir.2020.102812\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6602d8147380dfa3ba8d44662541f033de995c1\",\"title\":\"Generating video animation from single still image in social media based on intelligent computing\",\"url\":\"https://www.semanticscholar.org/paper/f6602d8147380dfa3ba8d44662541f033de995c1\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"34413938\",\"name\":\"Haichao Yu\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"48631088\",\"name\":\"Xinchao Wang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/MIPR.2019.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e20404e8cd2ccac389b1ce6ff4690f1fd29404e\",\"title\":\"Self-Reproducing Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/4e20404e8cd2ccac389b1ce6ff4690f1fd29404e\",\"venue\":\"2019 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2019},{\"arxivId\":\"1901.06034\",\"authors\":[{\"authorId\":\"144796690\",\"name\":\"S. Lu\"}],\"doi\":\"10.1109/WACV.2019.00237\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ed892e7787805e2202d006687ac69fea6bab0a5\",\"title\":\"High-Speed Video from Asynchronous Camera Array\",\"url\":\"https://www.semanticscholar.org/paper/9ed892e7787805e2202d006687ac69fea6bab0a5\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1712.02874\",\"authors\":[{\"authorId\":\"144869276\",\"name\":\"Zhe Hu\"},{\"authorId\":\"2191237\",\"name\":\"Y. Ma\"},{\"authorId\":\"8452947\",\"name\":\"L. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd60560a8e2e97e90a6a26e350f75ba7263966c8\",\"title\":\"Multi-Scale Video Frame-Synthesis Network with Transitive Consistency Loss\",\"url\":\"https://www.semanticscholar.org/paper/bd60560a8e2e97e90a6a26e350f75ba7263966c8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1711.09078\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"5114023\",\"name\":\"B. Chen\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1007/s11263-018-01144-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c1045435c208a20f65b79baaa2d79783c2409c09\",\"title\":\"Video Enhancement with Task-Oriented Flow\",\"url\":\"https://www.semanticscholar.org/paper/c1045435c208a20f65b79baaa2d79783c2409c09\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1910.12713\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea92a69b48287caa3a25ff3dfe727bed8888348\",\"title\":\"Few-shot Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/bea92a69b48287caa3a25ff3dfe727bed8888348\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30903985\",\"name\":\"Haoxian Zhang\"},{\"authorId\":\"49908329\",\"name\":\"Ronggang Wang\"},{\"authorId\":null,\"name\":\"Yang Zhao\"}],\"doi\":\"10.1109/ACCESS.2019.2940510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"title\":\"Multi-Frame Pyramid Refinement Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/9d01de72d62f89e9e7c1b691a1bd3ca2b67b2664\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2002.12259\",\"authors\":[{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/cvpr42600.2020.00516\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"title\":\"Blurry Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/34a51b7e4523a15f184fb05809a9c8ad6cfc6be0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1901.02840\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"3119608\",\"name\":\"Haibin Huang\"},{\"authorId\":\"47074942\",\"name\":\"Chuan Wang\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR.2019.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"title\":\"GIF2Video: Color Dequantization and Temporal Interpolation of GIF Images\",\"url\":\"https://www.semanticscholar.org/paper/75ab4f41c28bddefbd997744617e3ec6e3b478dc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.00884\",\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"1763523\",\"name\":\"Abdelaziz Djelouah\"},{\"authorId\":\"46936952\",\"name\":\"Brian McWilliams\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"},{\"authorId\":\"144877478\",\"name\":\"M. Gross\"},{\"authorId\":\"2604867\",\"name\":\"Christopher Schroers\"}],\"doi\":\"10.1109/CVPR.2018.00059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"title\":\"PhaseNet for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/b934bdaaaed7af7269a368a8c93c87c293f876f8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1902.09680\",\"authors\":[{\"authorId\":\"51495548\",\"name\":\"Zihao W. Wang\"},{\"authorId\":\"8385095\",\"name\":\"Weixin Jiang\"},{\"authorId\":\"144842935\",\"name\":\"A. Katsaggelos\"},{\"authorId\":\"1793812\",\"name\":\"O. Cossairt\"}],\"doi\":\"10.1109/ICCVW.2019.00532\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0ab864d234049df7745416cc0d2e9357842a6b11\",\"title\":\"Event-Driven Video Frame Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/0ab864d234049df7745416cc0d2e9357842a6b11\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1812.01210\",\"authors\":[{\"authorId\":\"36001694\",\"name\":\"Liangzhe Yuan\"},{\"authorId\":\"47557600\",\"name\":\"Yibo Chen\"},{\"authorId\":\"50855889\",\"name\":\"H. Liu\"},{\"authorId\":\"145868989\",\"name\":\"T. Kong\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/CVPR.2019.01246\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"152c11700a6924e94955f6cf00b5a7522b406ec3\",\"title\":\"Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.01233\",\"authors\":[{\"authorId\":\"40648435\",\"name\":\"Seungjun Nah\"},{\"authorId\":\"48206011\",\"name\":\"Hee-won Kim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"97866501\",\"name\":\"Bumjun Park\"},{\"authorId\":\"152283843\",\"name\":\"Songhyun Yu\"},{\"authorId\":\"48388801\",\"name\":\"S. Kim\"},{\"authorId\":\"46973317\",\"name\":\"J. Jeong\"},{\"authorId\":\"93263637\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"4640997\",\"name\":\"Sanghyun Son\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"1585142097\",\"name\":\"Zhiyong Gaon\"},{\"authorId\":\"2812984\",\"name\":\"G. Chen\"},{\"authorId\":\"7774660\",\"name\":\"Yunhua Lu\"},{\"authorId\":\"46585842\",\"name\":\"R. Duan\"},{\"authorId\":\"150321531\",\"name\":\"Tong Liu\"},{\"authorId\":\"47059427\",\"name\":\"L. Zhang\"},{\"authorId\":\"120878650\",\"name\":\"Woonsung Park\"},{\"authorId\":\"47596916\",\"name\":\"M. Kim\"},{\"authorId\":\"1387998946\",\"name\":\"George Pisha\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"},{\"authorId\":\"1557634128\",\"name\":\"Eyal Naor\"},{\"authorId\":\"104101992\",\"name\":\"L. Aloni\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"31060460\",\"name\":\"Li Si-Yao\"},{\"authorId\":\"116295634\",\"name\":\"Ze Pan\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"},{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"}],\"doi\":\"10.1109/ICCVW.2019.00421\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3247a8640db63c638a1386493a87202aa2a0b15b\",\"title\":\"AIM 2019 Challenge on Video Temporal Super-Resolution: Methods and Results\",\"url\":\"https://www.semanticscholar.org/paper/3247a8640db63c638a1386493a87202aa2a0b15b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1712.02327\",\"authors\":[{\"authorId\":\"2577533\",\"name\":\"Ben Mildenhall\"},{\"authorId\":\"50329510\",\"name\":\"J. Barron\"},{\"authorId\":\"1967685\",\"name\":\"Jiawen Chen\"},{\"authorId\":\"2665634\",\"name\":\"Dillon Sharlet\"},{\"authorId\":\"47383180\",\"name\":\"R. Ng\"},{\"authorId\":\"144264200\",\"name\":\"Robert Carroll\"}],\"doi\":\"10.1109/CVPR.2018.00265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84fc681efa7a7030098daf0c122ce6b770351c85\",\"title\":\"Burst Denoising with Kernel Prediction Networks\",\"url\":\"https://www.semanticscholar.org/paper/84fc681efa7a7030098daf0c122ce6b770351c85\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1452342289\",\"name\":\"Rumen P. Mironov\"}],\"doi\":\"10.1109/ICEST49890.2020.9232733\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"40c3e7af61ac608c4427d31fafe48003ad813fdd\",\"title\":\"Adaptive 3D Interpolation of Images\",\"url\":\"https://www.semanticscholar.org/paper/40c3e7af61ac608c4427d31fafe48003ad813fdd\",\"venue\":\"2020 55th International Scientific Conference on Information, Communication and Energy Systems and Technologies (ICEST)\",\"year\":2020},{\"arxivId\":\"2005.06684\",\"authors\":[{\"authorId\":\"31265269\",\"name\":\"R. Saha\"},{\"authorId\":\"1696513867\",\"name\":\"Abenezer Teklemariam\"},{\"authorId\":\"39007058\",\"name\":\"Ian Hsu\"},{\"authorId\":\"145497462\",\"name\":\"A. Moses\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"52a0df13066799d8774408fb576bb07802789764\",\"title\":\"W-Cell-Net: Multi-frame Interpolation of Cellular Microscopy Videos\",\"url\":\"https://www.semanticscholar.org/paper/52a0df13066799d8774408fb576bb07802789764\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.07759\",\"authors\":[{\"authorId\":\"84509959\",\"name\":\"Mart Kartasev\"},{\"authorId\":\"84650046\",\"name\":\"Carlo Rapisarda\"},{\"authorId\":\"47414172\",\"name\":\"Dominik Fay\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f1aed5cd540275f86b7019e494be57437c604715\",\"title\":\"Implementing Adaptive Separable Convolution for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/f1aed5cd540275f86b7019e494be57437c604715\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1961467739\",\"name\":\"M. Tseng\"},{\"authorId\":\"2007619711\",\"name\":\"Yen-Chung Chen\"},{\"authorId\":\"1959578097\",\"name\":\"Yi-Lun Lee\"},{\"authorId\":\"2268189\",\"name\":\"Wei-Sheng Lai\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37811787\",\"name\":\"Wei-Chen Chiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"title\":\"Dual-Stream Fusion Network for Spatiotemporal Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/a6614ebe57fff2dd31c8393ca16c22f84f27c132\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.06903\",\"authors\":[{\"authorId\":\"2291143\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"2692368\",\"name\":\"Muchen Li\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c29e8379f11afe7a5f4e4cde03ebea08a2420af8\",\"title\":\"Learning Deformable Kernels for Image and Video Denoising\",\"url\":\"https://www.semanticscholar.org/paper/c29e8379f11afe7a5f4e4cde03ebea08a2420af8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1753738047\",\"name\":\"Kshitija Pandya\"},{\"authorId\":\"1753737879\",\"name\":\"Disha Varshney\"},{\"authorId\":\"1753607722\",\"name\":\"Ashray Aggarwal\"},{\"authorId\":\"115827410\",\"name\":\"Anil Singh Parihar\"}],\"doi\":\"10.1109/ICICCS48265.2020.9120989\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"682e288a5870f182e0f92bb4735f5659dff8b94c\",\"title\":\"An Analytical Study of CNN-based Video Frame Interpolation Techniques\",\"url\":\"https://www.semanticscholar.org/paper/682e288a5870f182e0f92bb4735f5659dff8b94c\",\"venue\":\"2020 4th International Conference on Intelligent Computing and Control Systems (ICICCS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66152807\",\"name\":\"J. Lee\"},{\"authorId\":\"1731170\",\"name\":\"G. Wetzstein\"},{\"authorId\":\"34273166\",\"name\":\"Hoang M. Le\"},{\"authorId\":\"153035663\",\"name\":\"F. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"title\":\"/ Appearance Flow Completion for Novel View Synthesis Dense Flow Estimator Sparse Flow Estimator Sparse Flow Estimator Sparse Flow Estimator\",\"url\":\"https://www.semanticscholar.org/paper/55ce6d69f6b91d13e0da440e1864e6017ab614f8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1557382867\",\"name\":\"Siyao Li\"},{\"authorId\":\"48669892\",\"name\":\"Xiangyu Xu\"},{\"authorId\":\"98350705\",\"name\":\"Z. Pan\"},{\"authorId\":\"8397576\",\"name\":\"Wenxiu Sun\"}],\"doi\":\"10.1109/ICCVW.2019.00425\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"title\":\"Quadratic Video Interpolation for VTSR Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e83e0bb28817b7dde11c973e8efb8b1b7e0b2e92\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144667531\",\"name\":\"Jean B\\u00e9gaint\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"title\":\"Towards novel inter-prediction methods for image and video compression. (Nouvelles m\\u00e9thodes de pr\\u00e9diction inter-images pour la compression d'images et de vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/412a4ba6f1a8b525ece09963c39c5e6758056ba8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143792910\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"}],\"doi\":\"10.1109/ICMEW.2018.8551583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0fb770c1ca849e2f4762bbd98330939ab6f880f6\",\"title\":\"Parallax View Generation for Static Scenes Using Parallax-Interpolation Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/0fb770c1ca849e2f4762bbd98330939ab6f880f6\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72551720\",\"name\":\"Hyeonjun Sim\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":\"10.1109/CVPRW.2019.00267\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4dafcd3e0b03f68f8f031ea1bbc02d0d31b59d2\",\"title\":\"A Deep Motion Deblurring Network Based on Per-Pixel Adaptive Kernels With Residual Down-Up and Up-Down Modules\",\"url\":\"https://www.semanticscholar.org/paper/d4dafcd3e0b03f68f8f031ea1bbc02d0d31b59d2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1906.05928\",\"authors\":[{\"authorId\":\"3291967\",\"name\":\"F. Reda\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"2130620\",\"name\":\"A. Dundar\"},{\"authorId\":\"1911755\",\"name\":\"M. Shoeybi\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":\"10.1109/ICCV.2019.00098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"title\":\"Unsupervised Video Interpolation Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d0cacb90967827cb7bf1876dc49e6bd8881e4d81\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2002.03500\",\"authors\":[{\"authorId\":\"49259808\",\"name\":\"Q. Guo\"},{\"authorId\":\"1389940060\",\"name\":\"Felix Juefei-Xu\"},{\"authorId\":\"49419199\",\"name\":\"Xiaofei Xie\"},{\"authorId\":\"143828252\",\"name\":\"L. Ma\"},{\"authorId\":\"50814744\",\"name\":\"J. Wang\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e597736f1209a358c13c1d432883b6b4f720c0b\",\"title\":\"ABBA: Saliency-Regularized Motion-Based Adversarial Blur Attack\",\"url\":\"https://www.semanticscholar.org/paper/7e597736f1209a358c13c1d432883b6b4f720c0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384709008\",\"name\":\"Xianhang Cheng\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2939143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"title\":\"A Multi-Scale Position Feature Transform Network for Video Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/7229f4ba7d8fb287d9603095b166f5e1d3e6e590\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102510752\",\"name\":\"W. Shen\"},{\"authorId\":\"8613898\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"144826391\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"152875291\",\"name\":\"L. Chen\"},{\"authorId\":\"2246414\",\"name\":\"Xiongkuo Min\"},{\"authorId\":\"153731442\",\"name\":\"Zhiyong Gao\"}],\"doi\":\"10.1109/TIP.2020.3033617\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"title\":\"Video Frame Interpolation and Enhancement via Pyramid Recurrent Framework\",\"url\":\"https://www.semanticscholar.org/paper/a3f5ff974ab479ebbe3fa533522c12253204bec1\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":\"1912.04421\",\"authors\":[{\"authorId\":\"31384397\",\"name\":\"Zhihao Xia\"},{\"authorId\":\"2942259\",\"name\":\"Federico Perazzi\"},{\"authorId\":\"153348155\",\"name\":\"M. Gharbi\"},{\"authorId\":\"2454127\",\"name\":\"Kalyan Sunkavalli\"},{\"authorId\":\"38534744\",\"name\":\"A. Chakrabarti\"}],\"doi\":\"10.1109/cvpr42600.2020.01186\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa06a6dc92faf4b69e7905461aaa4baccb3d4cd2\",\"title\":\"Basis Prediction Networks for Effective Burst Denoising With Large Kernels\",\"url\":\"https://www.semanticscholar.org/paper/fa06a6dc92faf4b69e7905461aaa4baccb3d4cd2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.05084\",\"authors\":[{\"authorId\":\"145906067\",\"name\":\"Y. Chen\"},{\"authorId\":\"92493482\",\"name\":\"M. Alain\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/MMSP48831.2020.9287105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9456d33164705981170f0bd94ed6c93a1eeb792\",\"title\":\"Self-supervised Light Field View Synthesis Using Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/b9456d33164705981170f0bd94ed6c93a1eeb792\",\"venue\":\"2020 IEEE 22nd International Workshop on Multimedia Signal Processing (MMSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1412432168\",\"name\":\"Simone Schaub-Meyer\"}],\"doi\":\"10.3929/ethz-b-000315026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"971b2b96c43e5dc0bd2946a1de92e1072a36f82a\",\"title\":\"Video Frame Interpolation and Editing with Implicit Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/971b2b96c43e5dc0bd2946a1de92e1072a36f82a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.10680\",\"authors\":[{\"authorId\":\"49473017\",\"name\":\"Zhihao Shi\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"153250595\",\"name\":\"K. Shi\"},{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"title\":\"Video Interpolation via Generalized Deformable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/adc89874c2b2546850dcc1394c663fe22c3b4f6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145567286\",\"name\":\"Hoang Le\"},{\"authorId\":\"50208066\",\"name\":\"F. Liu\"}],\"doi\":\"10.1111/cgf.13860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"26d8da3d2f67e914aa564942d2721e89e221ef52\",\"title\":\"Appearance Flow Completion for Novel View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/26d8da3d2f67e914aa564942d2721e89e221ef52\",\"venue\":\"Comput. Graph. Forum\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2243964\",\"name\":\"C. Li\"},{\"authorId\":\"51210542\",\"name\":\"Donghao Gu\"},{\"authorId\":\"50088361\",\"name\":\"X. Ma\"},{\"authorId\":\"145164031\",\"name\":\"Kai Yang\"},{\"authorId\":\"1743348\",\"name\":\"S. Liu\"},{\"authorId\":\"144999037\",\"name\":\"Feng Jiang\"}],\"doi\":\"10.1109/DSC.2018.00089\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"26575ad9e75efb440a7dc4ef8e548eed4e19dbd1\",\"title\":\"Video Frame Interpolation Based on Multi-scale Convolutional Network and Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/26575ad9e75efb440a7dc4ef8e548eed4e19dbd1\",\"venue\":\"2018 IEEE Third International Conference on Data Science in Cyberspace (DSC)\",\"year\":2018},{\"arxivId\":\"2011.05532\",\"authors\":[{\"authorId\":\"14925412\",\"name\":\"Prasan A. Shedligeri\"},{\"authorId\":\"71834567\",\"name\":\"S. Anupama\"},{\"authorId\":\"1879114299\",\"name\":\"Kaushik Mitra\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"57cbe673125a9e6775e9e16c7355f062ce6eae82\",\"title\":\"A Unified Framework for Compressive Video Recovery from Coded Exposure Techniques\",\"url\":\"https://www.semanticscholar.org/paper/57cbe673125a9e6775e9e16c7355f062ce6eae82\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1706.03947\",\"authors\":[{\"authorId\":\"8082703\",\"name\":\"Xiongtao Chen\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"3258842\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/VCIP.2017.8305029\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60c699b9ec71f7dcbc06fa4fd98eeb08e915eb09\",\"title\":\"Long-term video interpolation with bidirectional predictive network\",\"url\":\"https://www.semanticscholar.org/paper/60c699b9ec71f7dcbc06fa4fd98eeb08e915eb09\",\"venue\":\"2017 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824256\",\"name\":\"S. Jin\"},{\"authorId\":\"80848808\",\"name\":\"Ruiynag Liu\"},{\"authorId\":\"145306197\",\"name\":\"Y. Ji\"},{\"authorId\":\"2431628\",\"name\":\"J. Ye\"},{\"authorId\":\"2152356\",\"name\":\"J. Yu\"}],\"doi\":\"10.1007/978-3-030-01264-9_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95249f6e5d5e1b25d307db6e82e224e09beb5775\",\"title\":\"Learning to Dodge A Bullet: Concyclic View Morphing via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/95249f6e5d5e1b25d307db6e82e224e09beb5775\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152128102\",\"name\":\"Yuan Gao\"},{\"authorId\":\"144839904\",\"name\":\"R. Koch\"},{\"authorId\":\"2340064\",\"name\":\"R. Bregovic\"},{\"authorId\":\"1799559\",\"name\":\"A. Gotchev\"}],\"doi\":\"10.23919/EUSIPCO.2019.8903168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"title\":\"IEST: Interpolation-Enhanced Shearlet Transform for Light Field Reconstruction Using Adaptive Separable Convolution\",\"url\":\"https://www.semanticscholar.org/paper/7dab3d6708d1032403a50d2a3202ae9aea4b94d2\",\"venue\":\"2019 27th European Signal Processing Conference (EUSIPCO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49404171\",\"name\":\"Haopeng Li\"},{\"authorId\":\"49521471\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2936549\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"title\":\"FI-Net: A Lightweight Video Frame Interpolation Network Using Feature-Level Flow\",\"url\":\"https://www.semanticscholar.org/paper/00b75d8ef0a8250a27e8dacedf8a6f4c4ca126d2\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1626101034\",\"name\":\"Nguyen Van Thang\"},{\"authorId\":\"1390764531\",\"name\":\"Kyujoong Lee\"},{\"authorId\":\"3090069\",\"name\":\"Hyuk-Jae Lee\"}],\"doi\":\"10.1109/ACCESS.2020.2982039\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"title\":\"A Stacked Deep MEMC Network for Frame Rate Up Conversion and its Application to HEVC\",\"url\":\"https://www.semanticscholar.org/paper/1a2edb287693a4c82bc3fd82ccf2f2544c127e5d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46294028\",\"name\":\"M. Lee\"},{\"authorId\":\"72657988\",\"name\":\"Dae Yu Kim\"},{\"authorId\":\"10774886\",\"name\":\"B. Song\"}],\"doi\":\"10.3390/s20185184\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99e5cbf00e3bf5e31b0d08980a059ed6310e4b21\",\"title\":\"Visual Scene-Aware Hybrid and Multi-Modal Feature Aggregation for Facial Expression Recognition \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/99e5cbf00e3bf5e31b0d08980a059ed6310e4b21\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2012.14796\",\"authors\":[{\"authorId\":null,\"name\":\"Glenn Herrou\"},{\"authorId\":null,\"name\":\"Charles Bonnineau\"},{\"authorId\":null,\"name\":\"Wassim Hamidouche\"},{\"authorId\":null,\"name\":\"Patrick Dumenil\"},{\"authorId\":null,\"name\":\"Jerome Fournier\"},{\"authorId\":null,\"name\":\"Luce Morin\"}],\"doi\":\"10.1109/TCSVT.2020.3046881\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fe1c060847f0823cbbae4202447854e962c34b5\",\"title\":\"Quality-driven Variable Frame-Rate for Green Video Coding in Broadcast Applications\",\"url\":\"https://www.semanticscholar.org/paper/6fe1c060847f0823cbbae4202447854e962c34b5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.06965\",\"authors\":[{\"authorId\":\"40946340\",\"name\":\"Yu-Syuan Xu\"},{\"authorId\":\"51119986\",\"name\":\"Shou-Yao Roy Tseng\"},{\"authorId\":\"47984199\",\"name\":\"Y. Tseng\"},{\"authorId\":\"2836806\",\"name\":\"Hsien-Kai Kuo\"},{\"authorId\":\"2033674\",\"name\":\"Yi-Min Tsai\"}],\"doi\":\"10.1109/CVPR42600.2020.01251\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff36187041e08237bd075ca56b8ad17347376784\",\"title\":\"Unified Dynamic Convolutional Network for Super-Resolution With Variational Degradations\",\"url\":\"https://www.semanticscholar.org/paper/ff36187041e08237bd075ca56b8ad17347376784\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020}],\"corpusId\":11191770,\"doi\":\"10.1109/CVPR.2017.244\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":29,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"841832fae29497f20ed795604ce76358ed7e51c3\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Alahi J. Johnson\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"namic filter networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1601.00706\",\"authors\":[{\"authorId\":\"1768964\",\"name\":\"Jimei Yang\"},{\"authorId\":\"144828948\",\"name\":\"S. Reed\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"1697141\",\"name\":\"H. Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3411535f7888a943853895e8eef2bb0b6d328c2a\",\"title\":\"Weakly-supervised Disentangling with Recurrent Transformations for 3D View Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/3411535f7888a943853895e8eef2bb0b6d328c2a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J. Ba. Adam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\": A method for stochastic optimization\",\"url\":\"\",\"venue\":\"British Machine Vision Conference\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"144031005\",\"name\":\"A. Bruhn\"},{\"authorId\":\"2188270\",\"name\":\"N. Papenberg\"},{\"authorId\":\"7789445\",\"name\":\"J. Weickert\"}],\"doi\":\"10.1007/978-3-540-24673-2_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91228e00fe33ed6072cfe849ab9e98160461549d\",\"title\":\"High Accuracy Optical Flow Estimation Based on a Theory for Warping\",\"url\":\"https://www.semanticscholar.org/paper/91228e00fe33ed6072cfe849ab9e98160461549d\",\"venue\":\"ECCV\",\"year\":2004},{\"arxivId\":\"1603.06041\",\"authors\":[{\"authorId\":\"1781631\",\"name\":\"Gucan Long\"},{\"authorId\":\"1727013\",\"name\":\"Laurent Kneip\"},{\"authorId\":\"2974008\",\"name\":\"Jose M. Alvarez\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"39045430\",\"name\":\"X. Zhang\"},{\"authorId\":\"9397915\",\"name\":\"Qifeng Yu\"}],\"doi\":\"10.1007/978-3-319-46466-4_26\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"f19108c55b7c1831566ce3250322e0f5637d44c9\",\"title\":\"Learning Image Matching by Simply Watching Video\",\"url\":\"https://www.semanticscholar.org/paper/f19108c55b7c1831566ce3250322e0f5637d44c9\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9667f8264745b626c6173b1310e2ff0298b09cfc\",\"title\":\"Learning Deep Features for Scene Recognition using Places Database\",\"url\":\"https://www.semanticscholar.org/paper/9667f8264745b626c6173b1310e2ff0298b09cfc\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1607.02586\",\"authors\":[{\"authorId\":\"3222730\",\"name\":\"Tianfan Xue\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"18555073\",\"name\":\"K. Bouman\"},{\"authorId\":\"36668046\",\"name\":\"B. Freeman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"397e9b56e46d3cc34af1525493e597facb104570\",\"title\":\"Visual Dynamics: Probabilistic Future Frame Synthesis via Cross Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/397e9b56e46d3cc34af1525493e597facb104570\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1501.00092\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/TPAMI.2015.2439281\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"title\":\"Image Super-Resolution Using Deep Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/66e9dc728b5041271bff0cd6ac0d7eadcd88442f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Alahi\"},{\"authorId\":null,\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"namic filter networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1512.01815\",\"authors\":[{\"authorId\":\"3117463\",\"name\":\"David Gadot\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2016.459\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cdae1edd4bd2c4c110f992cca57e88afecf5658a\",\"title\":\"PatchBatch: A Batch Augmented Loss for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/cdae1edd4bd2c4c110f992cca57e88afecf5658a\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779107\",\"name\":\"Andrea Fusiello\"}],\"doi\":\"10.1201/9781439864319-30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffe6ea1c06641c4f64a6c9612ce832f79344ff7e\",\"title\":\"Image-based Rendering *\",\"url\":\"https://www.semanticscholar.org/paper/ffe6ea1c06641c4f64a6c9612ce832f79344ff7e\",\"venue\":\"\",\"year\":2003},{\"arxivId\":\"1609.03552\",\"authors\":[{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2177801\",\"name\":\"E. Shechtman\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46454-1_36\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc7822f56dd255a872326b9536a0821bbf0277dd\",\"title\":\"Generative Visual Manipulation on the Natural Image Manifold\",\"url\":\"https://www.semanticscholar.org/paper/fc7822f56dd255a872326b9536a0821bbf0277dd\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1603.08155\",\"authors\":[{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-319-46475-6_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9fa3720371e78d04973ce9752781bc337480b68f\",\"title\":\"Perceptual Losses for Real-Time Style Transfer and Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/9fa3720371e78d04973ce9752781bc337480b68f\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1605.07157\",\"authors\":[{\"authorId\":\"46881670\",\"name\":\"Chelsea Finn\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"1736651\",\"name\":\"S. Levine\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"title\":\"Unsupervised Learning for Physical Interaction through Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f110cfdbe9ded7a384bcf5c0d56e536bd275a7eb\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1603.03417\",\"authors\":[{\"authorId\":\"145276680\",\"name\":\"D. Ulyanov\"},{\"authorId\":\"47606739\",\"name\":\"V. Lebedev\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"1740145\",\"name\":\"V. Lempitsky\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"title\":\"Texture Networks: Feed-forward Synthesis of Textures and Stylized Images\",\"url\":\"https://www.semanticscholar.org/paper/ed16b5a85e06fc0e6c81b3843a5bb2bb50a35ac1\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1504.06852\",\"authors\":[{\"authorId\":\"1382344214\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"152702479\",\"name\":\"P. Fischer\"},{\"authorId\":\"48105320\",\"name\":\"Eddy Ilg\"},{\"authorId\":\"2880264\",\"name\":\"Philip H\\u00e4usser\"},{\"authorId\":\"3322806\",\"name\":\"Caner Hazirbas\"},{\"authorId\":\"2943639\",\"name\":\"V. Golkov\"},{\"authorId\":\"1715782\",\"name\":\"P. V. D. Smagt\"},{\"authorId\":\"153685345\",\"name\":\"D. Cremers\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/ICCV.2015.316\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"title\":\"FlowNet: Learning Optical Flow with Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c2fb5b39428818d7ec8cc78e152e19c21b7db568\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/978-1-84882-935-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4282a344671189e17c9c9e00e329fe2d0fa71769\",\"title\":\"Computer Vision - Algorithms and Applications\",\"url\":\"https://www.semanticscholar.org/paper/4282a344671189e17c9c9e00e329fe2d0fa71769\",\"venue\":\"Texts in Computer Science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1849598\",\"name\":\"D. Butler\"},{\"authorId\":\"49820715\",\"name\":\"J. Wulff\"},{\"authorId\":\"2715753\",\"name\":\"G. Stanley\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-642-33783-3_44\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"title\":\"A Naturalistic Open Source Movie for Optical Flow Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/7d53f0c87c8ab0de6f3e74515e3ffaf3fab40c62\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":\"1511.06681\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPRW.2016.57\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7249091dd41c1c072b033f8327bbabb10ac20c82\",\"title\":\"Deep End2End Voxel2Voxel Prediction\",\"url\":\"https://www.semanticscholar.org/paper/7249091dd41c1c072b033f8327bbabb10ac20c82\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016},{\"arxivId\":\"1601.04589\",\"authors\":[{\"authorId\":\"153228286\",\"name\":\"Chuan Li\"},{\"authorId\":\"1723149\",\"name\":\"M. Wand\"}],\"doi\":\"10.1109/CVPR.2016.272\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526\",\"title\":\"Combining Markov Random Fields and Convolutional Neural Networks for Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/80d9a586c49ac6ec6a0b304ec1bb10d3f09fb526\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.1792\",\"authors\":[{\"authorId\":\"2965424\",\"name\":\"J. Yosinski\"},{\"authorId\":\"2552141\",\"name\":\"J. Clune\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1747909\",\"name\":\"Hod Lipson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"081651b38ff7533550a3adfc1c00da333a8fe86c\",\"title\":\"How transferable are features in deep neural networks?\",\"url\":\"https://www.semanticscholar.org/paper/081651b38ff7533550a3adfc1c00da333a8fe86c\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"145335572\",\"name\":\"J. Ren\"},{\"authorId\":\"1681442\",\"name\":\"Ce Liu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"750cc7813da3559dfd653cfbbf56ca3356b3162f\",\"title\":\"Deep Convolutional Neural Network for Image Deconvolution\",\"url\":\"https://www.semanticscholar.org/paper/750cc7813da3559dfd653cfbbf56ca3356b3162f\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Dosovitskiy Tatarchenko\"},{\"authorId\":null,\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multi - view 3 Dmodels from single images with a convolutional network Learning to extract motion from videos in convolutional neural networks\",\"url\":\"\",\"venue\":\"Computer Graphics Forum\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"X Jia\"},{\"authorId\":null,\"name\":\"B D Brabandere\"},{\"authorId\":null,\"name\":\"T Tuytelaars\"},{\"authorId\":null,\"name\":\"L V Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Dynamic filter networks. In NIPS\",\"url\":\"\",\"venue\":\"Dynamic filter networks. In NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1738740\",\"name\":\"S. B. Kang\"},{\"authorId\":\"143711233\",\"name\":\"Matthew Uyttendaele\"},{\"authorId\":\"2818882\",\"name\":\"S. Winder\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1145/1015706.1015766\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5d4aef53879770ce33e647264230b42ebaba1828\",\"title\":\"High-quality video view interpolation using a layered representation\",\"url\":\"https://www.semanticscholar.org/paper/5d4aef53879770ce33e647264230b42ebaba1828\",\"venue\":\"SIGGRAPH 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Dosovitskiy Tatarchenko\"},{\"authorId\":null,\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Multi - view 3 D models from single images with a convolutional network Learning to extract motion from videos in convolutional neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.05440\",\"authors\":[{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2341378\",\"name\":\"C. Couprie\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"title\":\"Deep multi-scale video prediction beyond mean square error\",\"url\":\"https://www.semanticscholar.org/paper/17fa1c2a24ba8f731c8b21f1244463bc4b465681\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":\"1511.06702\",\"authors\":[{\"authorId\":\"3332944\",\"name\":\"Maxim Tatarchenko\"},{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-319-46478-7_20\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8e002fbf85c8453d760aacc32225308d1514f8b6\",\"title\":\"Multi-view 3D Models from Single Images with a Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/8e002fbf85c8453d760aacc32225308d1514f8b6\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2886023\",\"name\":\"Manuel Werlberger\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"2443335\",\"name\":\"M. Unger\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-642-23094-3_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"title\":\"Optical Flow Guided TV-L1 Video Interpolation and Restoration\",\"url\":\"https://www.semanticscholar.org/paper/fd86cc929225d6a9a725e5f30aa918f3582b8960\",\"venue\":\"EMMCVPR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3307078\",\"name\":\"P. Didyk\"},{\"authorId\":\"1402956544\",\"name\":\"Pitchaya Sitthi-amorn\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"}],\"doi\":\"10.1145/2508363.2508376\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83e20d726ac829907082629b6fa1d60b378eaa83\",\"title\":\"Joint view expansion and filtering for automultiscopic 3D displays\",\"url\":\"https://www.semanticscholar.org/paper/83e20d726ac829907082629b6fa1d60b378eaa83\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"title\":\"Understanding the difficulty of training deep feedforward neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b71ac1e9fb49420d13e084ac67254a0bbd40f83f\",\"venue\":\"AISTATS\",\"year\":2010},{\"arxivId\":\"1610.07629\",\"authors\":[{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99542f614d7e4146cad17196e76c997e57a69e4d\",\"title\":\"A Learned Representation For Artistic Style\",\"url\":\"https://www.semanticscholar.org/paper/99542f614d7e4146cad17196e76c997e57a69e4d\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"K. Kavukcuoglu R. Collobert\"},{\"authorId\":null,\"name\":\"C.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Farabet . Torch 7 : A matlablike environment for machine learning\",\"url\":\"\",\"venue\":\"BigLearn , NIPS Workshop\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T D Kulkarni\"},{\"authorId\":null,\"name\":\"W F Whitney\"},{\"authorId\":null,\"name\":\"P Kohli\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Tenenbaum. Deep convolutional inverse graphics network\",\"url\":\"\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1601.07532\",\"authors\":[{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1007/978-3-319-54193-8_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3788cb8e73e1c0a62b762731da7769288a9098c9\",\"title\":\"Learning to Extract Motion from Videos in Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3788cb8e73e1c0a62b762731da7769288a9098c9\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":\"1609.02974\",\"authors\":[{\"authorId\":\"1717070\",\"name\":\"Nima Khademi Kalantari\"},{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"}],\"doi\":\"10.1145/2980179.2980251\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"title\":\"Learning-based view synthesis for light field cameras\",\"url\":\"https://www.semanticscholar.org/paper/8bc52fa1687bc8ef596a9b81d1b7c1d172a111e8\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":\"1311.3715\",\"authors\":[{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"1736851\",\"name\":\"Matthew Trentacoste\"},{\"authorId\":\"47412543\",\"name\":\"Helen Han\"},{\"authorId\":\"46260271\",\"name\":\"A. Agarwala\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"1747779\",\"name\":\"Aaron Hertzmann\"},{\"authorId\":\"2168852\",\"name\":\"H. Winnem\\u00f6ller\"}],\"doi\":\"10.5244/C.28.122\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c62a99e6491e14c32aac6bfea01ef3f943ce9129\",\"title\":\"Recognizing Image Style\",\"url\":\"https://www.semanticscholar.org/paper/c62a99e6491e14c32aac6bfea01ef3f943ce9129\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":\"1605.00366\",\"authors\":[{\"authorId\":\"47071858\",\"name\":\"P. Svoboda\"},{\"authorId\":\"1700956\",\"name\":\"Michal Hradi\\u0161\"},{\"authorId\":\"1977196\",\"name\":\"David Barina\"},{\"authorId\":\"1722571\",\"name\":\"P. Zem\\u010d\\u00edk\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d175d2bd607f7e749484be7696ca5f8f78d8b01d\",\"title\":\"Compression Artifacts Removal Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d175d2bd607f7e749484be7696ca5f8f78d8b01d\",\"venue\":\"J. WSCG\",\"year\":2016},{\"arxivId\":\"1406.5670\",\"authors\":[{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"3340170\",\"name\":\"Shuran Song\"},{\"authorId\":\"120643531\",\"name\":\"A. Khosla\"},{\"authorId\":\"1807197\",\"name\":\"F. Yu\"},{\"authorId\":\"3064662\",\"name\":\"Linguang Zhang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"40599257\",\"name\":\"J. Xiao\"}],\"doi\":\"10.1109/CVPR.2015.7298801\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c8a51d04522496c43db68f2582efd45eaf59fea\",\"title\":\"3D ShapeNets: A deep representation for volumetric shapes\",\"url\":\"https://www.semanticscholar.org/paper/7c8a51d04522496c43db68f2582efd45eaf59fea\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.06825\",\"authors\":[{\"authorId\":\"48001135\",\"name\":\"J. Flynn\"},{\"authorId\":\"1725327\",\"name\":\"Ivan Neulander\"},{\"authorId\":\"144781398\",\"name\":\"J. Philbin\"},{\"authorId\":\"1830653\",\"name\":\"Noah Snavely\"}],\"doi\":\"10.1109/CVPR.2016.595\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"title\":\"Deep Stereo: Learning to Predict New Views from the World's Imagery\",\"url\":\"https://www.semanticscholar.org/paper/73c8acd433c33e09916eaa1b0311c3ea7b2610d2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2369548\",\"name\":\"Junyuan Xie\"},{\"authorId\":\"2230211\",\"name\":\"Linli Xu\"},{\"authorId\":\"144378760\",\"name\":\"E. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2017ec2c60d542af5e9993176ba68f89529dbce\",\"title\":\"Image Denoising and Inpainting with Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a2017ec2c60d542af5e9993176ba68f89529dbce\",\"venue\":\"NIPS\",\"year\":2012},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3270016\",\"name\":\"Michael W. Tao\"},{\"authorId\":\"18798164\",\"name\":\"Jiamin Bai\"},{\"authorId\":\"143967473\",\"name\":\"Pushmeet Kohli\"},{\"authorId\":\"145799132\",\"name\":\"Sylvain Paris\"}],\"doi\":\"10.1111/j.1467-8659.2012.03013.x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09a54064c94475c042e24225531b45edc7542521\",\"title\":\"SimpleFlow: A Non\\u2010iterative, Sublinear Optical Flow Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/09a54064c94475c042e24225531b45edc7542521\",\"venue\":\"Comput. Graph. Forum\",\"year\":2012},{\"arxivId\":\"1412.6604\",\"authors\":[{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"143627859\",\"name\":\"Joan Bruna\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"title\":\"Video (language) modeling: a baseline for generative models of natural videos\",\"url\":\"https://www.semanticscholar.org/paper/355f98e4827a1b6ad3f29d07ea2bcf9ad078295c\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2939803\",\"name\":\"Ronan Collobert\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"},{\"authorId\":\"2256269\",\"name\":\"C. Farabet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3449b65008b27f6e60a73d80c1fd990f0481126b\",\"title\":\"Torch7: A Matlab-like Environment for Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/3449b65008b27f6e60a73d80c1fd990f0481126b\",\"venue\":\"NIPS 2011\",\"year\":2011},{\"arxivId\":\"1312.6229\",\"authors\":[{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2060028\",\"name\":\"D. Eigen\"},{\"authorId\":\"46447747\",\"name\":\"X. Zhang\"},{\"authorId\":\"143949035\",\"name\":\"Micha\\u00ebl Mathieu\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1109b663453e78a59e4f66446d71720ac58cec25\",\"title\":\"OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/1109b663453e78a59e4f66446d71720ac58cec25\",\"venue\":\"ICLR\",\"year\":2014},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50113176\",\"name\":\"S. Meyer\"},{\"authorId\":\"47520207\",\"name\":\"O. Wang\"},{\"authorId\":\"1405719070\",\"name\":\"H. Zimmer\"},{\"authorId\":\"3044090\",\"name\":\"M. Grosse\"},{\"authorId\":\"1388791172\",\"name\":\"Alexander Sorkine-Hornung\"}],\"doi\":\"10.1109/CVPR.2015.7298747\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"87b83fefb82216aad1c14cd1898d195722bcee42\",\"title\":\"Phase-based frame interpolation for video\",\"url\":\"https://www.semanticscholar.org/paper/87b83fefb82216aad1c14cd1898d195722bcee42\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1605.09673\",\"authors\":[{\"authorId\":\"40347509\",\"name\":\"Xu Jia\"},{\"authorId\":\"3384995\",\"name\":\"Bert De Brabandere\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"title\":\"Dynamic Filter Networks\",\"url\":\"https://www.semanticscholar.org/paper/aba48504f4f9563eafa44e0cfb22e1345d767c80\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1611.00850\",\"authors\":[{\"authorId\":\"1952002\",\"name\":\"A. Ranjan\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR.2017.291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"title\":\"Optical Flow Estimation Using a Spatial Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/a93d81c7f033f1e2b54d3288b60d214f55ccc010\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1504.06993\",\"authors\":[{\"authorId\":\"144964868\",\"name\":\"C. Dong\"},{\"authorId\":\"48362742\",\"name\":\"Yubin Deng\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/ICCV.2015.73\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09642681d46282e76fd9d1336001ef6473b72ec8\",\"title\":\"Compression Artifacts Reduction by a Deep Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/09642681d46282e76fd9d1336001ef6473b72ec8\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1302.1700\",\"authors\":[{\"authorId\":\"33354551\",\"name\":\"A. Giusti\"},{\"authorId\":\"1895356\",\"name\":\"Dan C. Ciresan\"},{\"authorId\":\"2426718\",\"name\":\"J. Masci\"},{\"authorId\":\"6803671\",\"name\":\"L. Gambardella\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1109/ICIP.2013.6738831\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68299ec9b72e3ac378a1fdc9d86039ebba203deb\",\"title\":\"Fast image scanning with deep max-pooling convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/68299ec9b72e3ac378a1fdc9d86039ebba203deb\",\"venue\":\"2013 IEEE International Conference on Image Processing\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1007/978-3-319-54190-7_13\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8d192bb3feae3e445b3b30948edee907a1d2324a\",\"title\":\"Deep Discrete Flow\",\"url\":\"https://www.semanticscholar.org/paper/8d192bb3feae3e445b3b30948edee907a1d2324a\",\"venue\":\"ACCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101841672\",\"name\":\"Moritz Menze\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"}],\"doi\":\"10.1109/CVPR.2015.7298925\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edf455c3b5b8d1c6337c72e39940125036354d03\",\"title\":\"Object scene flow for autonomous vehicles\",\"url\":\"https://www.semanticscholar.org/paper/edf455c3b5b8d1c6337c72e39940125036354d03\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35167546\",\"name\":\"H. Burger\"},{\"authorId\":\"1814533\",\"name\":\"C. Schuler\"},{\"authorId\":\"1734990\",\"name\":\"S. Harmeling\"}],\"doi\":\"10.1109/CVPR.2012.6247952\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d70937202d843664c5591fde4fb0d48627d1cf6\",\"title\":\"Image denoising: Can plain neural networks compete with BM3D?\",\"url\":\"https://www.semanticscholar.org/paper/1d70937202d843664c5591fde4fb0d48627d1cf6\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":\"1411.5928\",\"authors\":[{\"authorId\":\"2841331\",\"name\":\"A. Dosovitskiy\"},{\"authorId\":\"2060551\",\"name\":\"Jost Tobias Springenberg\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1109/CVPR.2015.7298761\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b437b5a0445f17b06b12791bc48aeb8110e95dc5\",\"title\":\"Learning to generate chairs with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b437b5a0445f17b06b12791bc48aeb8110e95dc5\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1411.4038\",\"authors\":[{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2572683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"317aee7fc081f2b137a85c4f20129007fd8e717e\",\"title\":\"Fully Convolutional Networks for Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/317aee7fc081f2b137a85c4f20129007fd8e717e\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153009621\",\"name\":\"Zhefei Yu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"},{\"authorId\":\"1694827\",\"name\":\"Zeng Hu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/TCSVT.2013.2242631\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c83b1573163b8794b85e35021a0650945e958da\",\"title\":\"Multi-Level Video Frame Interpolation: Exploiting the Interaction Among Different Levels\",\"url\":\"https://www.semanticscholar.org/paper/2c83b1573163b8794b85e35021a0650945e958da\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2013},{\"arxivId\":\"1412.1265\",\"authors\":[{\"authorId\":\"1681656\",\"name\":\"Y. Sun\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7298907\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e70d75454de81b05fed9b63a405bcd1229f20229\",\"title\":\"Deeply learned face representations are sparse, selective, and robust\",\"url\":\"https://www.semanticscholar.org/paper/e70d75454de81b05fed9b63a405bcd1229f20229\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"113130084\",\"name\":\"Zaid Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.175\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"title\":\"DeepFlow: Large Displacement Optical Flow with Deep Matching\",\"url\":\"https://www.semanticscholar.org/paper/56493a503eecb659bbef2fe4dd1fb915d251cac0\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1891828\",\"name\":\"Leon A. Gatys\"},{\"authorId\":\"1746183\",\"name\":\"Alexander S. Ecker\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1109/CVPR.2016.265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7568d13a82f7afa4be79f09c295940e48ec6db89\",\"title\":\"Image Style Transfer Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/7568d13a82f7afa4be79f09c295940e48ec6db89\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1503.03167\",\"authors\":[{\"authorId\":\"1954876\",\"name\":\"Tejas D. Kulkarni\"},{\"authorId\":\"3376546\",\"name\":\"William F. Whitney\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"687e80eb70c7bbad6001006d9269b202650a3354\",\"title\":\"Deep Convolutional Inverse Graphics Network\",\"url\":\"https://www.semanticscholar.org/paper/687e80eb70c7bbad6001006d9269b202650a3354\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"S B Kang\"},{\"authorId\":null,\"name\":\"Y Li\"},{\"authorId\":null,\"name\":\"X Tong\"},{\"authorId\":null,\"name\":\"H Shum\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Image-based rendering. Foundations and Trends in Computer Graphics and Vision\",\"url\":\"\",\"venue\":\"\",\"year\":2006},{\"arxivId\":\"1605.03557\",\"authors\":[{\"authorId\":\"1822702\",\"name\":\"Tinghui Zhou\"},{\"authorId\":\"2757335\",\"name\":\"Shubham Tulsiani\"},{\"authorId\":\"8397461\",\"name\":\"Weilun Sun\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46493-0_18\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b635705558b9ffcc973966371415b7124830007\",\"title\":\"View Synthesis by Appearance Flow\",\"url\":\"https://www.semanticscholar.org/paper/5b635705558b9ffcc973966371415b7124830007\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2188620\",\"name\":\"Yaniv Taigman\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"1706809\",\"name\":\"Marc'Aurelio Ranzato\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2014.220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"title\":\"DeepFace: Closing the Gap to Human-Level Performance in Face Verification\",\"url\":\"https://www.semanticscholar.org/paper/9f2efadf66817f1b38f58b3f50c7c8f34c69d89a\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706673\",\"name\":\"C. Zhang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1016/j.image.2003.07.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8763375466df13d5dddc4a29e3e827ad358d053f\",\"title\":\"A survey on image-based rendering - representation, sampling and compression\",\"url\":\"https://www.semanticscholar.org/paper/8763375466df13d5dddc4a29e3e827ad358d053f\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145347688\",\"name\":\"S. Baker\"},{\"authorId\":\"1709053\",\"name\":\"D. Scharstein\"},{\"authorId\":\"69395700\",\"name\":\"J. Lewis\"},{\"authorId\":\"145920814\",\"name\":\"S. Roth\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"1717841\",\"name\":\"R. Szeliski\"}],\"doi\":\"10.1007/s11263-010-0390-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"title\":\"A Database and Evaluation Methodology for Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/804836b8ad86ef8042e3dcbd45442a52f031ee03\",\"venue\":\"2007 IEEE 11th International Conference on Computer Vision\",\"year\":2007},{\"arxivId\":\"1503.00593\",\"authors\":[{\"authorId\":\"39838944\",\"name\":\"J. Sun\"},{\"authorId\":\"3102315\",\"name\":\"Wenfei Cao\"},{\"authorId\":\"7814629\",\"name\":\"Zongben Xu\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"}],\"doi\":\"10.1109/CVPR.2015.7298677\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"03eb5c9e91031b20f95ff9cf3f47013086fea9a2\",\"title\":\"Learning a convolutional neural network for non-uniform motion blur removal\",\"url\":\"https://www.semanticscholar.org/paper/03eb5c9e91031b20f95ff9cf3f47013086fea9a2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"37021642\",\"name\":\"F. Huang\"},{\"authorId\":\"1752521\",\"name\":\"W. Matusik\"},{\"authorId\":\"1752236\",\"name\":\"R. Ramamoorthi\"},{\"authorId\":\"1767767\",\"name\":\"P. Belhumeur\"}],\"doi\":\"10.1145/1576246.1531348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"title\":\"Moving gradients: a path-based method for plausible image interpolation\",\"url\":\"https://www.semanticscholar.org/paper/d746c54a1636c448e98c16bc6fb8ce07aeeb042e\",\"venue\":\"SIGGRAPH '09\",\"year\":2009},{\"arxivId\":\"1603.08511\",\"authors\":[{\"authorId\":\"2844849\",\"name\":\"Richard Zhang\"},{\"authorId\":\"2094770\",\"name\":\"Phillip Isola\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-319-46487-9_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"title\":\"Colorful Image Colorization\",\"url\":\"https://www.semanticscholar.org/paper/8201e6e687f2de477258e9be53ba7b73ee30d7de\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144574904\",\"name\":\"L. Xu\"},{\"authorId\":\"1729056\",\"name\":\"J. Jia\"},{\"authorId\":\"1774618\",\"name\":\"Yasuyuki Matsushita\"}],\"doi\":\"10.1109/TPAMI.2011.236\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"title\":\"Motion Detail Preserving Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/66f9ee80721a20b1d191e06c5f5ab42e542a1241\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34004812\",\"name\":\"N. Wadhwa\"},{\"authorId\":\"144544291\",\"name\":\"Michael Rubinstein\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1145/2461912.2461966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f835cbad5cf09601493df7fdfc0f310b4c1a5ed\",\"title\":\"Phase-based video motion processing\",\"url\":\"https://www.semanticscholar.org/paper/8f835cbad5cf09601493df7fdfc0f310b4c1a5ed\",\"venue\":\"ACM Trans. Graph.\",\"year\":2013}],\"title\":\"Video Frame Interpolation via Adaptive Convolution\",\"topics\":[{\"topic\":\"Motion interpolation\",\"topicId\":\"21402\",\"url\":\"https://www.semanticscholar.org/topic/21402\"},{\"topic\":\"Convolution\",\"topicId\":\"571\",\"url\":\"https://www.semanticscholar.org/topic/571\"},{\"topic\":\"Motion estimation\",\"topicId\":\"21398\",\"url\":\"https://www.semanticscholar.org/topic/21398\"},{\"topic\":\"Pixel\",\"topicId\":\"4254\",\"url\":\"https://www.semanticscholar.org/topic/4254\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Optical flow\",\"topicId\":\"26430\",\"url\":\"https://www.semanticscholar.org/topic/26430\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Coefficient\",\"topicId\":\"3129\",\"url\":\"https://www.semanticscholar.org/topic/3129\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Gaussian blur\",\"topicId\":\"384913\",\"url\":\"https://www.semanticscholar.org/topic/384913\"},{\"topic\":\"Ground truth\",\"topicId\":\"33313\",\"url\":\"https://www.semanticscholar.org/topic/33313\"}],\"url\":\"https://www.semanticscholar.org/paper/841832fae29497f20ed795604ce76358ed7e51c3\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"