"{\"abstract\":\"We propose Dual Attention Networks (DANs) which jointly leverage visual and textual attention mechanisms to capture fine-grained interplay between vision and language. DANs attend to specific regions in images and words in text through multiple steps and gather essential information from both modalities. Based on this framework, we introduce two types of DANs for multimodal reasoning and matching, respectively. The reasoning model allows visual and textual attentions to steer each other during collaborative inference, which is useful for tasks such as Visual Question Answering (VQA). In addition, the matching model exploits the two attention mechanisms to estimate the similarity between images and sentences by focusing on their shared semantics. Our extensive experiments validate the effectiveness of DANs in combining vision and language, achieving the state-of-the-art performance on public benchmarks for VQA and image-text matching.\",\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\",\"url\":\"https://www.semanticscholar.org/author/34758272\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\",\"url\":\"https://www.semanticscholar.org/author/2577039\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\",\"url\":\"https://www.semanticscholar.org/author/2947441\"}],\"citationVelocity\":104,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"86912250\",\"name\":\"Peixi Xiong\"},{\"authorId\":\"145074713\",\"name\":\"Ying Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"title\":\"TA-Student VQA: Multi-Agents Training by Self-Questioning\",\"url\":\"https://www.semanticscholar.org/paper/ed212b4c747d35e284e8874c38cd0b855cd98f66\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1804.05338\",\"authors\":[{\"authorId\":\"9952952\",\"name\":\"Jo Schlemper\"},{\"authorId\":\"2941969\",\"name\":\"O. Oktay\"},{\"authorId\":\"46308087\",\"name\":\"Liang Chen\"},{\"authorId\":\"33938383\",\"name\":\"J. Matthew\"},{\"authorId\":\"50693459\",\"name\":\"C. Knight\"},{\"authorId\":\"2015193\",\"name\":\"Bernhard Kainz\"},{\"authorId\":\"1709824\",\"name\":\"Ben Glocker\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f55cc2602a70d178ae8499c19d5bee80fa40133\",\"title\":\"Attention-Gated Networks for Improving Ultrasound Scan Plane Detection\",\"url\":\"https://www.semanticscholar.org/paper/2f55cc2602a70d178ae8499c19d5bee80fa40133\",\"venue\":\"MICCAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32543309\",\"name\":\"Tianling Jiang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"49046633\",\"name\":\"Chunping Liu\"},{\"authorId\":\"21633777\",\"name\":\"Hailin Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78c2f7520becde5e3bcd9b952791d67c33a48612\",\"title\":\"Visual-Textual Alignment for Graph Inference in Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/78c2f7520becde5e3bcd9b952791d67c33a48612\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2010.05537\",\"authors\":[{\"authorId\":\"143905569\",\"name\":\"Nian Liu\"},{\"authorId\":\"40456843\",\"name\":\"N. Zhang\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"661851292001d1702a9d790328996c6fb972f6cb\",\"title\":\"Learning Selective Mutual Attention and Contrast for RGB-D Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/661851292001d1702a9d790328996c6fb972f6cb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"51347989\",\"name\":\"W. Liu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"title\":\"Learnable Aggregating Net with Diversity Learning for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f133f3daed70c50d1828cc6a46bc2e8dbd7880de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1807.01448\",\"authors\":[{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce407c2899ac955fa67dc7f6ba3a7f07ecd18855\",\"title\":\"Understanding Visual Ads by Aligning Symbols and Objects using Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/ce407c2899ac955fa67dc7f6ba3a7f07ecd18855\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1712.05901\",\"authors\":[{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1711021\",\"name\":\"A. Kim\"},{\"authorId\":\"15797750\",\"name\":\"Chanju Kim\"},{\"authorId\":\"3141448\",\"name\":\"J. Park\"},{\"authorId\":\"6098375\",\"name\":\"S. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab28192e5b6a43bd4862a420ff2bbd46b0d5be96\",\"title\":\"Automatic Music Highlight Extraction using Convolutional Recurrent Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/ab28192e5b6a43bd4862a420ff2bbd46b0d5be96\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2010.03403\",\"authors\":[{\"authorId\":\"1490652152\",\"name\":\"Jiwei Wei\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1524912498\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":null,\"name\":\"Zheng Wang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/CVPR42600.2020.01302\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd860c3f8a195d06f64ecf36ef6a78397eb883bd\",\"title\":\"Universal Weighting Metric Learning for Cross-Modal Matching\",\"url\":\"https://www.semanticscholar.org/paper/dd860c3f8a195d06f64ecf36ef6a78397eb883bd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144286903\",\"name\":\"Q. Yang\"},{\"authorId\":\"51145694\",\"name\":\"Gaosheng Wu\"},{\"authorId\":\"47003385\",\"name\":\"Yujun Li\"},{\"authorId\":\"1773599\",\"name\":\"R. Li\"},{\"authorId\":\"70387082\",\"name\":\"Xiwu Gu\"},{\"authorId\":\"1720853808\",\"name\":\"Huicai Deng\"},{\"authorId\":\"1720822983\",\"name\":\"Junzhuang Wu\"}],\"doi\":\"10.1109/TCSS.2020.2986778\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f11d9836aa871891d40604e6a19fa8ed3dd2dc2\",\"title\":\"AMNN: Attention-Based Multimodal Neural Network Model for Hashtag Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/6f11d9836aa871891d40604e6a19fa8ed3dd2dc2\",\"venue\":\"IEEE Transactions on Computational Social Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152106513\",\"name\":\"Zehao Liu\"},{\"authorId\":\"2029667971\",\"name\":\"Emmanuel Osei-Brefo\"},{\"authorId\":\"122665402\",\"name\":\"Siyuan Chen\"},{\"authorId\":\"1596809242\",\"name\":\"Huizhi Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57df777f75c139967342d45a7894687d96748709\",\"title\":\"UoR at SemEval-2020 Task 8: Gaussian Mixture Modelling (GMM) Based Sampling Approach for Multi-modal Memotion Analysis\",\"url\":\"https://www.semanticscholar.org/paper/57df777f75c139967342d45a7894687d96748709\",\"venue\":\"SemEval@COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576818877\",\"name\":\"Kento Terao\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"1688940\",\"name\":\"B. Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"K. Kaneda\"},{\"authorId\":\"144404414\",\"name\":\"S. Satoh\"}],\"doi\":\"10.1109/ACCESS.2020.3022063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7583d58aec662313bd5b0082b656d9f44956dc3\",\"title\":\"An Entropy Clustering Approach for Assessing Visual Question Difficulty\",\"url\":\"https://www.semanticscholar.org/paper/c7583d58aec662313bd5b0082b656d9f44956dc3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"},{\"authorId\":\"46669153\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054758\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"517efc27e303d408e36bad4d376884ae87fbbf93\",\"title\":\"Exploring Entity-Level Spatial Relationships for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/517efc27e303d408e36bad4d376884ae87fbbf93\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40055538\",\"name\":\"C. Yang\"},{\"authorId\":\"144889898\",\"name\":\"Mengqi Jiang\"},{\"authorId\":\"144069314\",\"name\":\"Bin Jiang\"},{\"authorId\":\"46351963\",\"name\":\"Weixin Zhou\"},{\"authorId\":\"2181606\",\"name\":\"K. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2908035\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0734fd670605a578b9e4b908e58b63e4142625e\",\"title\":\"Co-Attention Network With Question Type for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f0734fd670605a578b9e4b908e58b63e4142625e\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40461528\",\"name\":\"Y. Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"46458102\",\"name\":\"L. Liu\"},{\"authorId\":\"143866184\",\"name\":\"E. Bakker\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/J.PATCOG.2019.05.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"title\":\"CycleMatch: A cycle-consistent embedding network for image-text matching\",\"url\":\"https://www.semanticscholar.org/paper/d1c6fb3a0b46ecfaa0b23b6a10ecd07b2cd4ab28\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1904.03282\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/CVPR.2019.01186\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"title\":\"Weakly Supervised Video Moment Retrieval From Text Queries\",\"url\":\"https://www.semanticscholar.org/paper/ca4d965ab8fd07fd236a2ec5b5c7a520077a3085\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.06514\",\"authors\":[{\"authorId\":\"6485607\",\"name\":\"Jongchan Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10bb4ef7a6719ea132e00f0ab5680919a4131d99\",\"title\":\"BAM: Bottleneck Attention Module\",\"url\":\"https://www.semanticscholar.org/paper/10bb4ef7a6719ea132e00f0ab5680919a4131d99\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1802.10419\",\"authors\":[{\"authorId\":\"1748099\",\"name\":\"Yibo Yang\"},{\"authorId\":\"49164901\",\"name\":\"Zhisheng Zhong\"},{\"authorId\":\"35925165\",\"name\":\"Tiancheng Shen\"},{\"authorId\":\"33383055\",\"name\":\"Zhouchen Lin\"}],\"doi\":\"10.1109/CVPR.2018.00256\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa46c05868d6ccb404f4f6378cc11ae77f702d45\",\"title\":\"Convolutional Neural Networks with Alternately Updated Clique\",\"url\":\"https://www.semanticscholar.org/paper/aa46c05868d6ccb404f4f6378cc11ae77f702d45\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47388902\",\"name\":\"T. Gui\"},{\"authorId\":\"145779142\",\"name\":\"Peng Liu\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"144061928\",\"name\":\"L. Zhu\"},{\"authorId\":\"24859244\",\"name\":\"Minlong Peng\"},{\"authorId\":\"2236658\",\"name\":\"Yunhua Zhou\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.1145/3331184.3331237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d484fc70d805bb622153f3fc66c69418929caf09\",\"title\":\"Mention Recommendation in Twitter with Cooperative Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d484fc70d805bb622153f3fc66c69418929caf09\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145986708\",\"name\":\"Bo Sun\"},{\"authorId\":\"14701865\",\"name\":\"Z. Yao\"},{\"authorId\":\"48380350\",\"name\":\"Yinghui Zhang\"},{\"authorId\":\"8834504\",\"name\":\"Lejun Yu\"}],\"doi\":\"10.1016/j.jvcir.2020.102762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86475be7965eebb5edba838788d26c9272f14a3b\",\"title\":\"Local relation network with multilevel attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/86475be7965eebb5edba838788d26c9272f14a3b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1809184\",\"name\":\"Z. Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2018.00601\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"356c211af3bd0ce664bc2369b8489a43dfcf98a6\",\"title\":\"End-to-End Convolutional Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/356c211af3bd0ce664bc2369b8489a43dfcf98a6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecc5cd01261cf9c396689121a3e8c1844c825775\",\"title\":\"Making History Matter: History-Advantage Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ecc5cd01261cf9c396689121a3e8c1844c825775\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"101084939\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/ACCESS.2020.2975594\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"284cd0512ecd5d7cec335b0038444085398ebaf5\",\"title\":\"Multi-Modal Memory Enhancement Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/284cd0512ecd5d7cec335b0038444085398ebaf5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1909.03493\",\"authors\":[{\"authorId\":\"31494849\",\"name\":\"D. Kim\"},{\"authorId\":\"2652444\",\"name\":\"K. Saito\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1609/AAAI.V34I07.6785\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77802591c3f5b3f654bb5b68ad62ed056769320f\",\"title\":\"MULE: Multimodal Universal Language Embedding\",\"url\":\"https://www.semanticscholar.org/paper/77802591c3f5b3f654bb5b68ad62ed056769320f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1903.11649\",\"authors\":[{\"authorId\":\"19200118\",\"name\":\"Samyak Datta\"},{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"145149308\",\"name\":\"A. Roy\"},{\"authorId\":\"40480894\",\"name\":\"Karuna Ahuja\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/ICCV.2019.00269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a89cd9056c0fb037d659215b121686ff3b454fd5\",\"title\":\"Align2Ground: Weakly Supervised Phrase Grounding Guided by Image-Caption Alignment\",\"url\":\"https://www.semanticscholar.org/paper/a89cd9056c0fb037d659215b121686ff3b454fd5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492115432\",\"name\":\"Juncheng Li\"},{\"authorId\":\"1557314997\",\"name\":\"Yiting Yuan\"},{\"authorId\":\"77733241\",\"name\":\"Kangfu Mei\"},{\"authorId\":\"152786529\",\"name\":\"F. Fang\"}],\"doi\":\"10.1109/ICCVW.2019.00474\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"848315d70022c0437300e15d2c7b1ee58d07a1e6\",\"title\":\"Lightweight and Accurate Recursive Fractal Network for Image Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/848315d70022c0437300e15d2c7b1ee58d07a1e6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2002.07993\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"39664510\",\"name\":\"W. Zhang\"},{\"authorId\":\"47130663\",\"name\":\"Shukai Liu\"},{\"authorId\":\"47362515\",\"name\":\"Qi Liu\"},{\"authorId\":\"34997537\",\"name\":\"B. Zhang\"},{\"authorId\":\"4950224\",\"name\":\"Leyu Lin\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1145/3366423.3380077\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ee369ac1bff352b885b94e6d7e2e6ce690165ed\",\"title\":\"Beyond Clicks: Modeling Multi-Relational Item Graph for Session-Based Target Behavior Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6ee369ac1bff352b885b94e6d7e2e6ce690165ed\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2004.12070\",\"authors\":[{\"authorId\":\"1564034697\",\"name\":\"Zhou Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":null,\"name\":\"Jun Yu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413977\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f40ed567148f724028952e5fe20a34a0b671dd2e\",\"title\":\"Deep Multimodal Neural Architecture Search\",\"url\":\"https://www.semanticscholar.org/paper/f40ed567148f724028952e5fe20a34a0b671dd2e\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1904.08607\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"4604969\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"2561991\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/CVPR.2019.00853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"title\":\"Progressive Attention Memory Network for Movie Story Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82849187\",\"name\":\"R. Beard\"},{\"authorId\":\"27408524\",\"name\":\"R. Das\"},{\"authorId\":\"2394130\",\"name\":\"Raymond W. M. Ng\"},{\"authorId\":\"144775910\",\"name\":\"P. Gopalakrishnan\"},{\"authorId\":\"51504808\",\"name\":\"Luka Eerens\"},{\"authorId\":\"3127347\",\"name\":\"P. Swietojanski\"},{\"authorId\":\"3336488\",\"name\":\"O. Miksik\"}],\"doi\":\"10.18653/v1/K18-1025\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6240321ad0632b39ba07d3e65ccdbee8c25c8b0a\",\"title\":\"Multi-Modal Sequence Fusion via Recursive Attention for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6240321ad0632b39ba07d3e65ccdbee8c25c8b0a\",\"venue\":\"CoNLL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/tcyb.2020.2985716\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"758890bef9a1a85a25a1f6831a58f00a462476af\",\"title\":\"SMAN: Stacked Multimodal Attention Network for Cross-Modal Image-Text Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/758890bef9a1a85a25a1f6831a58f00a462476af\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2020},{\"arxivId\":\"1812.07119\",\"authors\":[{\"authorId\":\"2221563\",\"name\":\"N. Vo\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"145601650\",\"name\":\"K. Murphy\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"}],\"doi\":\"10.1109/CVPR.2019.00660\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d\",\"title\":\"Composing Text and Image for Image Retrieval - an Empirical Odyssey\",\"url\":\"https://www.semanticscholar.org/paper/fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1693e1defad1cc8ec36b061add2afcd564013ff\",\"title\":\"Advancing Multi-Modal Deep Learning: Towards Language-Grounded Visual Understanding\",\"url\":\"https://www.semanticscholar.org/paper/c1693e1defad1cc8ec36b061add2afcd564013ff\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.10770\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"30513139\",\"name\":\"Yuhao Cui\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/CVPR.2019.00644\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"title\":\"Deep Modular Co-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.05556\",\"authors\":[{\"authorId\":\"144869806\",\"name\":\"Pedro Henrique Martins\"},{\"authorId\":\"2114966\",\"name\":\"Vlad Niculae\"},{\"authorId\":\"2566656\",\"name\":\"Zita Marinho\"},{\"authorId\":\"145644643\",\"name\":\"Andr\\u00e9 F. T. Martins\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e627eb9f17369770f2cef5d71360c93c8494785\",\"title\":\"Sparse and Structured Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4e627eb9f17369770f2cef5d71360c93c8494785\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"93374657\",\"name\":\"C. Xu\"},{\"authorId\":\"1490934465\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"title\":\"Bilinear Graph Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/22fa5a7f3f00737c1912cbd6b2cac248a7e734a4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f22058a3003cee6b17c6c25c8a635a653e78614c\",\"title\":\"Multimodal Attention in Recurrent Neural Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f22058a3003cee6b17c6c25c8a635a653e78614c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"1379526529\",\"name\":\"Qiankun Kong\"},{\"authorId\":null,\"name\":\"Haoran Wang\"},{\"authorId\":\"48278144\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1145/3343031.3351064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c54e587223099732a03c71bbe2b9b6e1b4ffc67\",\"title\":\"Small and Dense Commodity Object Detection with Multi-Scale Receptive Field Attention\",\"url\":\"https://www.semanticscholar.org/paper/6c54e587223099732a03c71bbe2b9b6e1b4ffc67\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1907.09748\",\"authors\":[{\"authorId\":null,\"name\":\"Yaxiong Wang\"},{\"authorId\":\"143727909\",\"name\":\"H. Yang\"},{\"authorId\":\"6468417\",\"name\":\"Xueming Qian\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"97486095\",\"name\":\"J. Lu\"},{\"authorId\":\"49730271\",\"name\":\"Biao Li\"},{\"authorId\":\"51952911\",\"name\":\"Xin Fan\"}],\"doi\":\"10.24963/ijcai.2019/526\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"title\":\"Position Focused Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/48a7873681c6aa88b9e0e22a25c2a8245eaeb45f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1810.06065\",\"authors\":[{\"authorId\":\"2000798\",\"name\":\"Lisa Fan\"},{\"authorId\":\"144580027\",\"name\":\"Dong Yu\"},{\"authorId\":\"48169643\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"357d331b258bd081373b3a876c58085d8a88e689\",\"title\":\"Robust Neural Abstractive Summarization Systems and Evaluation against Adversarial Information\",\"url\":\"https://www.semanticscholar.org/paper/357d331b258bd081373b3a876c58085d8a88e689\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.00168\",\"authors\":[{\"authorId\":\"74812117\",\"name\":\"H. Uppal\"},{\"authorId\":\"30849663\",\"name\":\"Alireza Sepas-Moghaddam\"},{\"authorId\":\"35019530\",\"name\":\"M. Greenspan\"},{\"authorId\":\"1379982213\",\"name\":\"Ali Etemad\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0e96fc937885a3bf883b55ba25932cbe804ec4f\",\"title\":\"Two-Level Attention-based Fusion Learning for RGB-D Face Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b0e96fc937885a3bf883b55ba25932cbe804ec4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30814238\",\"name\":\"W. Wei\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"49958606\",\"name\":\"Heng Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ACCESS.2020.2992187\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bdfb3fde985493fc53c379cb79ef4a5da2977a3\",\"title\":\"Boosting Cross-Modal Retrieval With MVSE++ and Reciprocal Neighbors\",\"url\":\"https://www.semanticscholar.org/paper/7bdfb3fde985493fc53c379cb79ef4a5da2977a3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1707.05612\",\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"title\":\"VSE++: Improved Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/faa093a53b83f0e9c35a0bfbcacee0a16f8eb6d1\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1708.02071\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"49339267\",\"name\":\"Yanpeng Zhao\"},{\"authorId\":\"24027493\",\"name\":\"Shuaiyi Huang\"},{\"authorId\":\"40341553\",\"name\":\"K. Tu\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1109/ICCV.2017.145\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5823d18cd378898b12de537862d996443ce9c9e8\",\"title\":\"Structured Attentions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/5823d18cd378898b12de537862d996443ce9c9e8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1711.05535\",\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"40a943746d3a6156f9ca477e437263c7841118ac\",\"title\":\"Dual-Path Convolutional Image-Text Embedding\",\"url\":\"https://www.semanticscholar.org/paper/40a943746d3a6156f9ca477e437263c7841118ac\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8599825\",\"name\":\"Jonatas Wehrmann\"},{\"authorId\":\"145987795\",\"name\":\"M. A. Lopes\"},{\"authorId\":\"145877010\",\"name\":\"Douglas M. Souza\"},{\"authorId\":\"1380051745\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/ICCV.2019.00590\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84010f883e9a7283666a6628226016ca4f8d28f1\",\"title\":\"Language-Agnostic Visual-Semantic Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/84010f883e9a7283666a6628226016ca4f8d28f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2006.14264\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b58adf956dfd71a756b8f98b726fdcd8e2552445\",\"title\":\"Self-Segregating and Coordinated-Segregating Transformer for Focused Deep Multi-Modular Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b58adf956dfd71a756b8f98b726fdcd8e2552445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"144663763\",\"name\":\"Q. Wu\"},{\"authorId\":\"41173169\",\"name\":\"W. Wang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TPAMI.2018.2883466\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"title\":\"Image and Sentence Matching via Semantic Concepts and Order Learning\",\"url\":\"https://www.semanticscholar.org/paper/c58fe4769e12bafa4e7dda5df9f1cc6111040c6d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xi Zhang\"},{\"authorId\":\"1781403\",\"name\":\"H. Zhang\"},{\"authorId\":\"37310105\",\"name\":\"L. Zhao\"}],\"doi\":\"10.1007/978-3-319-97304-3_62\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"474106f754ddc79ee7bb000e1dea75dcf47d7ae4\",\"title\":\"Reading More Efficiently: Multi-sentence Summarization with a Dual Attention and Copy-Generator Network\",\"url\":\"https://www.semanticscholar.org/paper/474106f754ddc79ee7bb000e1dea75dcf47d7ae4\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":\"1806.04655\",\"authors\":[{\"authorId\":\"47016316\",\"name\":\"Revanth Reddy Gangi Reddy\"},{\"authorId\":\"10081629\",\"name\":\"R. Ramesh\"},{\"authorId\":\"33341943\",\"name\":\"Ameet Deshpande\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1109/IJCNN.2019.8851830\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"220bb685271613781f8e5d8a8194b0e7488791d3\",\"title\":\"FigureNet : A Deep Learning model for Question-Answering on Scientific Plots\",\"url\":\"https://www.semanticscholar.org/paper/220bb685271613781f8e5d8a8194b0e7488791d3\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145662486\",\"name\":\"L. Zhang\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"49721678\",\"name\":\"J. Liu\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"20212496\",\"name\":\"Y. Yang\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1109/TMM.2019.2931352\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"93d4d2fabad7c7a7a5bbf8a767e07276f9384aa0\",\"title\":\"Deep Top-$k$ Ranking for Image\\u2013Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/93d4d2fabad7c7a7a5bbf8a767e07276f9384aa0\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47388902\",\"name\":\"T. Gui\"},{\"authorId\":\"144061928\",\"name\":\"L. Zhu\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"24859244\",\"name\":\"Minlong Peng\"},{\"authorId\":\"48559511\",\"name\":\"X. Zhou\"},{\"authorId\":\"40831417\",\"name\":\"Keyu Ding\"},{\"authorId\":\"48354552\",\"name\":\"Zhigang Chen\"}],\"doi\":\"10.1609/AAAI.V33I01.3301110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb048840cf915a1f9c2c451f3dd3432312c86326\",\"title\":\"Cooperative Multimodal Approach to Depression Detection in Twitter\",\"url\":\"https://www.semanticscholar.org/paper/eb048840cf915a1f9c2c451f3dd3432312c86326\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2018.00642\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"72c16ae6969eda304f76af139e000e4cec34d564\",\"title\":\"Focal Visual-Text Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72c16ae6969eda304f76af139e000e4cec34d564\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"2713947\",\"name\":\"Xinghao Ding\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1145/3394171.3413998\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72687e467b4ab4d4799cca976013c5936ccb74b1\",\"title\":\"K-armed Bandit based Multi-Modal Network Architecture Search for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72687e467b4ab4d4799cca976013c5936ccb74b1\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471463062\",\"name\":\"Qi Zhang\"},{\"authorId\":\"1522102572\",\"name\":\"Zhen Lei\"},{\"authorId\":\"1415720379\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00359\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"title\":\"Context-Aware Attention Network for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4307dce5b1dd4a6bdcd06d61eed5aa7c85fb59f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118023258\",\"name\":\"X. Wei\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"2694924\",\"name\":\"Y. Li\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"1684705122\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/CVPR42600.2020.01095\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"caabcf61499e00c78d8ee692b8939caf98544a9c\",\"title\":\"Multi-Modality Cross Attention Network for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/caabcf61499e00c78d8ee692b8939caf98544a9c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490899838\",\"name\":\"Jongchan Park\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1007/s11263-019-01283-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1d2b7ababd0ba4ca98d9a9970209948389fff446\",\"title\":\"A Simple and Light-Weight Attention Module for Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d2b7ababd0ba4ca98d9a9970209948389fff446\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134342162\",\"name\":\"Li Wen-jie\"},{\"authorId\":\"153697517\",\"name\":\"Y. Zheng\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"103245682\",\"name\":\"T. Zhang\"},{\"authorId\":\"1878750882\",\"name\":\"Weiguo Fan\"}],\"doi\":\"10.1002/asi.24373\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"title\":\"Cross\\u2010modal retrieval with dual multi\\u2010angle self\\u2010attention\",\"url\":\"https://www.semanticscholar.org/paper/fb9ab6eac8e06594a181d50d253171fb8a51cc8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50498297\",\"name\":\"Liang Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"}],\"doi\":\"10.1007/s11042-018-6389-3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"713dd629c183056202f31c2a98e5e37e0d83efa4\",\"title\":\"Word-to-region attention network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/713dd629c183056202f31c2a98e5e37e0d83efa4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47012336\",\"name\":\"Xin Fu\"},{\"authorId\":\"1517826311\",\"name\":\"Yao Zhao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"49339608\",\"name\":\"Yufeng Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"}],\"doi\":\"10.1109/TMM.2019.2957948\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c2195652dddf015880ceacefd811a3df7cae30c\",\"title\":\"Rich Features Embedding for Cross-Modal Retrieval: A Simple Baseline\",\"url\":\"https://www.semanticscholar.org/paper/7c2195652dddf015880ceacefd811a3df7cae30c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905569\",\"name\":\"Nian Liu\"},{\"authorId\":\"40456843\",\"name\":\"N. Zhang\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/cvpr42600.2020.01377\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f237473bba70ec13737dbd4ef8f0f67c3cb5c3ff\",\"title\":\"Learning Selective Self-Mutual Attention for RGB-D Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/f237473bba70ec13737dbd4ef8f0f67c3cb5c3ff\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":\"1911.08877\",\"authors\":[{\"authorId\":\"144719528\",\"name\":\"Lei Ding\"},{\"authorId\":\"145462888\",\"name\":\"Hao Tang\"},{\"authorId\":\"1698844\",\"name\":\"L. Bruzzone\"}],\"doi\":\"10.1109/TGRS.2020.2994150\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"005aacffcd3521e86f0ce4007ad2bd1de9189a62\",\"title\":\"Improving Semantic Segmentation of Aerial Images Using Patch-based Attention\",\"url\":\"https://www.semanticscholar.org/paper/005aacffcd3521e86f0ce4007ad2bd1de9189a62\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10441619\",\"name\":\"Rudong Xu\"},{\"authorId\":\"2617247\",\"name\":\"Yiting Tao\"},{\"authorId\":\"46951152\",\"name\":\"Z. Lu\"},{\"authorId\":\"2798207\",\"name\":\"Y. Zhong\"}],\"doi\":\"10.3390/rs10101602\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53d014b4b1e7ee7c875b7e261be3f554e02c349a\",\"title\":\"Attention-Mechanism-Containing Neural Networks for High-Resolution Remote Sensing Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/53d014b4b1e7ee7c875b7e261be3f554e02c349a\",\"venue\":\"Remote. Sens.\",\"year\":2018},{\"arxivId\":\"1909.13784\",\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"title\":\"LoGAN: Latent Graph Co-Attention Network for Weakly-Supervised Video Moment Retrieval.\",\"url\":\"https://www.semanticscholar.org/paper/3c0d69d243c08eaa1d9030c95541a2ae23e8eb85\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7882243\",\"name\":\"Seunghyun Park\"},{\"authorId\":\"3387820\",\"name\":\"Y. Kim\"},{\"authorId\":\"2417664\",\"name\":\"J. Kim\"},{\"authorId\":\"4308473\",\"name\":\"J. J. Park\"},{\"authorId\":\"1918779\",\"name\":\"Borim Ryu\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"}],\"doi\":\"10.1109/BIBE.2018.00028\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3045322d47df8c99941b76eef7422b09bb2f073\",\"title\":\"[Regular Paper] Interpretable Prediction of Vascular Diseases from Electronic Health Records via Deep Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/b3045322d47df8c99941b76eef7422b09bb2f073\",\"venue\":\"2018 IEEE 18th International Conference on Bioinformatics and Bioengineering (BIBE)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50077572\",\"name\":\"Zheng Yu\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682424\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2af1f3ef29f6e66a31b879eab5d58f5861394da4\",\"title\":\"Multi-step Self-attention Network for Cross-modal Retrieval Based on a Limited Text Space\",\"url\":\"https://www.semanticscholar.org/paper/2af1f3ef29f6e66a31b879eab5d58f5861394da4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1902.09326\",\"authors\":[{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"title\":\"Making History Matter: Gold-Critic Sequence Training for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/d83f41d394cb23a87685d7a69bac42a6e86a4641\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1574421683\",\"name\":\"Xi Zhu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":\"40282454\",\"name\":\"Y. Li\"},{\"authorId\":\"50218711\",\"name\":\"Z. Wang\"},{\"authorId\":\"15696552\",\"name\":\"Bin Wang\"}],\"doi\":\"10.1007/s11042-020-08790-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"title\":\"Object-difference drived graph convolutional networks for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/49c9921b5df66b421b5e6432d84a8eb699c6443b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1911.04470\",\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"49992877\",\"name\":\"Y. Song\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":\"10.1109/TCSVT.2019.2936710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4e31dde236698ee4085147832f5fecbe028df9d\",\"title\":\"Semi-Heterogeneous Three-Way Joint Embedding Network for Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b4e31dde236698ee4085147832f5fecbe028df9d\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121789307\",\"name\":\"W. Guo\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"144496860\",\"name\":\"Xiangwei Kong\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":\"10.1145/3343031.3351053\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"title\":\"Learning Disentangled Representation for Cross-Modal Retrieval with Deep Mutual Information Estimation\",\"url\":\"https://www.semanticscholar.org/paper/52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"1690665\",\"name\":\"Y. Liu\"},{\"authorId\":\"40062477\",\"name\":\"J. Tan\"},{\"authorId\":\"46846169\",\"name\":\"Li Guo\"},{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"}],\"doi\":\"10.1007/978-3-319-99365-2_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87391a79e0c984b07093c1c51b78ea8997e3ca3b\",\"title\":\"Fine-Grained Correlation Learning with Stacked Co-attention Networks for Cross-Modal Information Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/87391a79e0c984b07093c1c51b78ea8997e3ca3b\",\"venue\":\"KSEM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1705203\",\"name\":\"C. Grana\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICPR.2018.8545064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ad37f14f42125cd3cdc0326d59e4d227a2468ed\",\"title\":\"Aligning Text and Document Illustrations: Towards Visually Explainable Digital Humanities\",\"url\":\"https://www.semanticscholar.org/paper/5ad37f14f42125cd3cdc0326d59e4d227a2468ed\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2011.02164\",\"authors\":[{\"authorId\":\"49172303\",\"name\":\"T. Rahman\"},{\"authorId\":\"6937593\",\"name\":\"Shih-Han Chou\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1387254703\",\"name\":\"Giuseppe Carenini\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"title\":\"An Improved Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e1cf7e279abc4301729c24cb7f888b2df42f7644\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1109/DSAA.2019.00029\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"title\":\"Cross-Media Image-Text Retrieval Combined with Global Similarity and Local Similarity\",\"url\":\"https://www.semanticscholar.org/paper/6cce8fc497e5c780bb3e8068541ae16b969b1042\",\"venue\":\"2019 IEEE International Conference on Data Science and Advanced Analytics (DSAA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2707832\",\"name\":\"Geonmo Gu\"},{\"authorId\":\"49899378\",\"name\":\"S. T. Kim\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1109/ICME.2017.8019540\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb8f1f77a8b19d99dfe0c7b50dae3978cf646aa9\",\"title\":\"Adaptive attention fusion network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/cb8f1f77a8b19d99dfe0c7b50dae3978cf646aa9\",\"venue\":\"2017 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2017},{\"arxivId\":\"1808.02373\",\"authors\":[{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf836282b6e39e7c252a278a8d5397701230703\",\"title\":\"Troy: Give Attention to Saliency and for Saliency\",\"url\":\"https://www.semanticscholar.org/paper/1cf836282b6e39e7c252a278a8d5397701230703\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"1819532\",\"name\":\"Shengjia Li\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1016/j.patrec.2018.10.020\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d520fdeca59b53b09e1f516bc6cf7179dc7b3ea5\",\"title\":\"Fusion-Attention Network for person search with free-form natural language\",\"url\":\"https://www.semanticscholar.org/paper/d520fdeca59b53b09e1f516bc6cf7179dc7b3ea5\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1801.04334\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2018.00943\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b1b2402dcd85b81381fde40d0b971b510471ef23\",\"title\":\"TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays\",\"url\":\"https://www.semanticscholar.org/paper/b1b2402dcd85b81381fde40d0b971b510471ef23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2004.07018\",\"authors\":[{\"authorId\":\"51248991\",\"name\":\"Clint Sebastian\"},{\"authorId\":\"84612591\",\"name\":\"Raffaele Imbriaco\"},{\"authorId\":\"143742944\",\"name\":\"E. Bondarev\"},{\"authorId\":\"8582219\",\"name\":\"P. H. With\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47a12437137a6d7df16c30baf944bd5e88bf1761\",\"title\":\"Contextual Pyramid Attention Network for Building Segmentation in Aerial Imagery\",\"url\":\"https://www.semanticscholar.org/paper/47a12437137a6d7df16c30baf944bd5e88bf1761\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49330480\",\"name\":\"Lifu Chen\"},{\"authorId\":\"3851162\",\"name\":\"Xianliang Cui\"},{\"authorId\":\"46947997\",\"name\":\"Zhenhong Li\"},{\"authorId\":\"47292570\",\"name\":\"Zhihui Yuan\"},{\"authorId\":\"48462604\",\"name\":\"Jin Xing\"},{\"authorId\":\"2617210\",\"name\":\"Xuemin Xing\"},{\"authorId\":\"26667398\",\"name\":\"Zhiwei Jia\"}],\"doi\":\"10.3390/s19112479\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71a99a25c3809a1a4e3e5afad702adda7efa0996\",\"title\":\"A New Deep Learning Algorithm for SAR Scene Classification Based on Spatial Statistical Modeling and Features Re-Calibration\",\"url\":\"https://www.semanticscholar.org/paper/71a99a25c3809a1a4e3e5afad702adda7efa0996\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"1909.09953\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"93400474\",\"name\":\"X. Chen\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b488019592d8e0c08e6cd011ae0543a6ac451357\",\"title\":\"Learning Visual Relation Priors for Image-Text Matching and Image Captioning with Neural Scene Graph Generators\",\"url\":\"https://www.semanticscholar.org/paper/b488019592d8e0c08e6cd011ae0543a6ac451357\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"title\":\"ACMM: Aligned Cross-Modal Memory for Few-Shot Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/54f5c5e1f80000e1da9c6b182e0e76f6e61c0ad5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/ICCV.2019.00472\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5abe916562fad8306e3f4e571f83015047f0be1d\",\"title\":\"Robust Change Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5abe916562fad8306e3f4e571f83015047f0be1d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152968916\",\"name\":\"Tianhao Yang\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1145/3343031.3350969\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2af3819e12239162525259295111d2114d7e3072\",\"title\":\"Question-Aware Tube-Switch Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2af3819e12239162525259295111d2114d7e3072\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2726914\",\"name\":\"Shuren Zhou\"},{\"authorId\":\"49435489\",\"name\":\"X. Zeng\"}],\"doi\":\"10.1007/978-981-15-8083-3_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"title\":\"Spatial-Temporal Co-attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b40980a4a9cc4535e8578b22e09487ad2ca8206\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/j.patcog.2020.107351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a26d15d75febf100209cd5d198e8046be9c51f9\",\"title\":\"Re-ranking image-text matching by adaptive metric fusion\",\"url\":\"https://www.semanticscholar.org/paper/4a26d15d75febf100209cd5d198e8046be9c51f9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868596\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-01246-5_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a86eb42952412ee02e3f6da06f874f1946eff6b\",\"title\":\"Deep Cross-Modal Projection Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a86eb42952412ee02e3f6da06f874f1946eff6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2012.04329\",\"authors\":[{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"147961332\",\"name\":\"R. S. Rezende\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"2295553\",\"name\":\"Diane Larlus\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23f74eff7453a31f75cd34abc04167c4b1ac9acb\",\"title\":\"StacMR: Scene-Text Aware Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23f74eff7453a31f75cd34abc04167c4b1ac9acb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2538306\",\"name\":\"S. Wang\"},{\"authorId\":\"40702813\",\"name\":\"Yangyu Chen\"},{\"authorId\":\"26973936\",\"name\":\"Junbao Zhuo\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3240508.3240535\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0d5fa2e57646f2cc7dbb9633261af7d20f8a51e\",\"title\":\"Joint Global and Co-Attentive Representation Learning for Image-Sentence Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c0d5fa2e57646f2cc7dbb9633261af7d20f8a51e\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":\"10.1016/j.cviu.2019.05.001\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"title\":\"DRAU: Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cb32b338023f9deb1eb2fb89d33784e12bdb5653\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48677815\",\"name\":\"Xinyan Yu\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"143758471\",\"name\":\"Rui Zhang\"}],\"doi\":\"10.1007/978-3-030-30671-7_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62afe2605541f485bbd2bfe89b41161ce08a5977\",\"title\":\"Cross-Modality Video Segment Retrieval with Ensemble Learning\",\"url\":\"https://www.semanticscholar.org/paper/62afe2605541f485bbd2bfe89b41161ce08a5977\",\"venue\":\"Domain Adaptation for Visual Understanding\",\"year\":2020},{\"arxivId\":\"1904.09471\",\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"}],\"doi\":\"10.1109/ICCV.2019.00585\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3d2d1f64a11ca9234716a777dedc962586930a9\",\"title\":\"Saliency-Guided Attention Network for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/a3d2d1f64a11ca9234716a777dedc962586930a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"51431789\",\"name\":\"Dan Shiebler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"title\":\"Learning what and where to attend\",\"url\":\"https://www.semanticscholar.org/paper/136c96810238657bf0c6f0d4b56b0e40e24f3c47\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"2004.00277\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"143994657\",\"name\":\"Hongtao Xie\"},{\"authorId\":null,\"name\":\"Bin Wang\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01093\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"title\":\"Graph Structured Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/84a65d4b4d966fae04cd95e34d12c09719be93f1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576152870\",\"name\":\"Xiaopeng Gong\"},{\"authorId\":\"1752239\",\"name\":\"Xiabi Liu\"},{\"authorId\":\"152998528\",\"name\":\"Yushuo Li\"},{\"authorId\":\"1471524979\",\"name\":\"Huiyu Li\"}],\"doi\":\"10.1016/j.imavis.2020.103973\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e87977613880444a029137a11ca04675a4cacb48\",\"title\":\"A novel co-attention computation block for deep learning based image co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e87977613880444a029137a11ca04675a4cacb48\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"70332987\",\"name\":\"J. Lamare\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3206025.3206079\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3a4b9de0fac8d318d4ec580ec57b0d173f78d8c\",\"title\":\"Multimodal Filtering of Social Media for Temporal Monitoring and Event Analysis\",\"url\":\"https://www.semanticscholar.org/paper/f3a4b9de0fac8d318d4ec580ec57b0d173f78d8c\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240687\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"title\":\"Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA\",\"url\":\"https://www.semanticscholar.org/paper/97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47320028\",\"name\":\"Shuya Li\"},{\"authorId\":\"48267418\",\"name\":\"F. Wan\"},{\"authorId\":\"1576505413\",\"name\":\"Hantao Shu\"},{\"authorId\":\"1387833921\",\"name\":\"T. Jiang\"},{\"authorId\":\"1387833921\",\"name\":\"T. Jiang\"},{\"authorId\":\"47783184\",\"name\":\"Dan Zhao\"},{\"authorId\":\"90424501\",\"name\":\"J. Zeng\"}],\"doi\":\"10.1016/j.cels.2020.03.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d441c443cd19387f3c5d48b24591fc4da6bd340\",\"title\":\"MONN: A Multi-objective Neural Network for Predicting Compound-Protein Interactions and Affinities\",\"url\":\"https://www.semanticscholar.org/paper/8d441c443cd19387f3c5d48b24591fc4da6bd340\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wenhui Li\"},{\"authorId\":null,\"name\":\"Song Yang\"},{\"authorId\":null,\"name\":\"Yan Wang\"},{\"authorId\":null,\"name\":\"Dan Song\"},{\"authorId\":null,\"name\":\"Xuanya Li\"}],\"doi\":\"10.1016/j.ipm.2020.102432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"title\":\"Multi-level similarity learning for image-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/5d8eabe60d1e128057bcf2ea04007defd1b205c9\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/s11042-020-09251-4\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"af92381f95f28701396abeecaf715383b26ca354\",\"title\":\"A unified cycle-consistent neural model for text and image retrieval\",\"url\":\"https://www.semanticscholar.org/paper/af92381f95f28701396abeecaf715383b26ca354\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"11179553\",\"name\":\"Zhigang Lin\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"}],\"doi\":\"10.1016/j.patcog.2020.107359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"title\":\"Stacked squeeze-and-excitation recurrent residual network for visual-semantic matching\",\"url\":\"https://www.semanticscholar.org/paper/124f42e4787a81eba2fc6311b11a3afec60c4f57\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152758697\",\"name\":\"Feiran Huang\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"8419850\",\"name\":\"Z. Zhao\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1109/TIP.2018.2882225\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d6807368ab0c87a9cfbb34237704c7019b404a21\",\"title\":\"Bi-Directional Spatial-Semantic Attention Networks for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/d6807368ab0c87a9cfbb34237704c7019b404a21\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816766ae8d708d088d64403c5fb278e56dc82bb3\",\"title\":\"Grounding natural language phrases in images and video\",\"url\":\"https://www.semanticscholar.org/paper/816766ae8d708d088d64403c5fb278e56dc82bb3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1907.09815\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"145371954\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"title\":\"Graph Reasoning Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/87b60156ac40e9b1f404e785cec7aa7b4365a489\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3082469\",\"name\":\"Cosmin Dragomir\"},{\"authorId\":null,\"name\":\"Cristian Ojog\"},{\"authorId\":\"2796756\",\"name\":\"Traian Rebedea\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"553ccc62bd1e0d98f2efa2e153f04c5ec26a8db5\",\"title\":\"Combining Visual and Textual Attention in Neural Models for Enhanced Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/553ccc62bd1e0d98f2efa2e153f04c5ec26a8db5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40538912\",\"name\":\"Wei Zhang\"},{\"authorId\":\"46314731\",\"name\":\"W. Wang\"},{\"authorId\":null,\"name\":\"Jun Wang\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1145/3178876.3186026\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"43bb4b073f7b2b9b626c7f3263cc61932271ab74\",\"title\":\"User-guided Hierarchical Attention Network for Multi-modal Social Image Popularity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/43bb4b073f7b2b9b626c7f3263cc61932271ab74\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3370925\",\"name\":\"X. Mei\"},{\"authorId\":\"114444284\",\"name\":\"Erting Pan\"},{\"authorId\":\"143616533\",\"name\":\"Y. Ma\"},{\"authorId\":\"31966950\",\"name\":\"X. Dai\"},{\"authorId\":\"144284510\",\"name\":\"Jun Huang\"},{\"authorId\":\"40513331\",\"name\":\"F. Fan\"},{\"authorId\":\"9357420\",\"name\":\"Q. Du\"},{\"authorId\":\"145735878\",\"name\":\"Hong Zheng\"},{\"authorId\":\"8555475\",\"name\":\"Jiayi Ma\"}],\"doi\":\"10.3390/rs11080963\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d2d78ea1ba6967eee257e9eac89fc1c9fded70d\",\"title\":\"Spectral-Spatial Attention Networks for Hyperspectral Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/4d2d78ea1ba6967eee257e9eac89fc1c9fded70d\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"1907.13487\",\"authors\":[{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"title\":\"Use What You Have: Video retrieval using representations from collaborative experts\",\"url\":\"https://www.semanticscholar.org/paper/b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"92790579\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-13969-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50d8da795bd50ebd14c4635116c159354409c9c\",\"title\":\"Automatic Classification and Reporting of Multiple Common Thorax Diseases Using Chest Radiographs\",\"url\":\"https://www.semanticscholar.org/paper/d50d8da795bd50ebd14c4635116c159354409c9c\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47121309\",\"name\":\"Wenping Ma\"},{\"authorId\":\"47492162\",\"name\":\"Qifan Yang\"},{\"authorId\":\"46220633\",\"name\":\"Yue Wu\"},{\"authorId\":\"145675285\",\"name\":\"W. Zhao\"},{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"}],\"doi\":\"10.3390/RS11111307\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0565198f6b8ca7117616b05fb2d6409693b526e9\",\"title\":\"Double-Branch Multi-Attention Mechanism Network for Hyperspectral Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/0565198f6b8ca7117616b05fb2d6409693b526e9\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"2010.01725\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1859082176\",\"name\":\"Salman Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"title\":\"Attention Guided Semantic Relationship Parsing for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4e5ffb9d473b195a9f0f159dca8bdbebce531ff6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03772\",\"authors\":[{\"authorId\":\"67228310\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"46522306\",\"name\":\"Xudong Liu\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"102551205\",\"name\":\"J. Liu\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/cvpr42600.2020.01267\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a\",\"title\":\"IMRAM: Iterative Matching With Recurrent Attention Memory for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/79c5ace95f0bcd33c1e02b7e83a2e0cdadb6b50a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1705.00464\",\"authors\":[{\"authorId\":\"9586147\",\"name\":\"Ted Zhang\"},{\"authorId\":\"1778526\",\"name\":\"Dengxin Dai\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dc3b8a5fdceaea4b32df8552cbb5a22ef83c197\",\"title\":\"Speech-Based Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6dc3b8a5fdceaea4b32df8552cbb5a22ef83c197\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47172737\",\"name\":\"A. Sain\"},{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86d0e140dafbf112a8884b195a335a61585ea01e\",\"title\":\"SAIN, BHUNIA, SONG: CROSS-MODAL HIERARCHICAL MODELLING FOR FG-SBIR 1 Cross-Modal Hierarchical Modelling for Fine-Grained Sketch Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/86d0e140dafbf112a8884b195a335a61585ea01e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47016316\",\"name\":\"Revanth Reddy Gangi Reddy\"},{\"authorId\":\"10081629\",\"name\":\"R. Ramesh\"},{\"authorId\":\"33341943\",\"name\":\"Ameet Deshpande\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f9e109dc039be6869c58d56d878cc4990f0f4c86\",\"title\":\"A Question-Answering framework for plots using Deep learning\",\"url\":\"https://www.semanticscholar.org/paper/f9e109dc039be6869c58d56d878cc4990f0f4c86\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1711.04323\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"799537fa855caf53a6a3a7cf20301a81e90da127\",\"title\":\"High-Order Attention Models for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/799537fa855caf53a6a3a7cf20301a81e90da127\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1909.11416\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3343031.3350869\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"2d149507610400ddc2f2b29d9a39f7688b613039\",\"title\":\"Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2d149507610400ddc2f2b29d9a39f7688b613039\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40219418\",\"name\":\"R. Milner\"},{\"authorId\":\"51257800\",\"name\":\"Md Asif Jalal\"},{\"authorId\":\"2394130\",\"name\":\"Raymond W. M. Ng\"},{\"authorId\":\"2171861\",\"name\":\"Thomas Hain\"}],\"doi\":\"10.1109/ASRU46091.2019.9003838\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea07906fa0d9a2710ed3b1fb44d43e4a65f2c06\",\"title\":\"A Cross-Corpus Study on Speech Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cea07906fa0d9a2710ed3b1fb44d43e4a65f2c06\",\"venue\":\"2019 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)\",\"year\":2019},{\"arxivId\":\"1906.01205\",\"authors\":[{\"authorId\":\"144097210\",\"name\":\"Fangyu Liu\"},{\"authorId\":\"22198846\",\"name\":\"Rongtian Ye\"}],\"doi\":\"10.18653/v1/P19-2023\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"edd200e1e18794202c3a55a810717e87be7b7dba\",\"title\":\"A Strong and Robust Baseline for Text-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/edd200e1e18794202c3a55a810717e87be7b7dba\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1987725399\",\"name\":\"Jianhang Shuai\"},{\"authorId\":\"153152486\",\"name\":\"Ling Xu\"},{\"authorId\":\"47536010\",\"name\":\"Chao Liu\"},{\"authorId\":\"1491644251\",\"name\":\"Meng Yan\"},{\"authorId\":\"1516124572\",\"name\":\"Xin Xia\"},{\"authorId\":\"1664969571\",\"name\":\"Yan Lei\"}],\"doi\":\"10.1145/3387904.3389269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a8869b543e46ed50d403658c6a05d6fb4c9601e4\",\"title\":\"Improving Code Search with Co-Attentive Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a8869b543e46ed50d403658c6a05d6fb4c9601e4\",\"venue\":\"ICPC\",\"year\":2020},{\"arxivId\":\"1803.08024\",\"authors\":[{\"authorId\":\"1863953\",\"name\":\"Kuang-Huei Lee\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"35431603\",\"name\":\"H. Hu\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"}],\"doi\":\"10.1007/978-3-030-01225-0_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"title\":\"Stacked Cross Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/45dd2a3cd7c27f2e9509b023d702408f5ac11c9d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-319-75928-9_52\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51280870657c72400b5de46ba56ee18b9891ab40\",\"title\":\"Multimodal Attention Agents in Visual Conversation\",\"url\":\"https://www.semanticscholar.org/paper/51280870657c72400b5de46ba56ee18b9891ab40\",\"venue\":\"EIDWT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52152408\",\"name\":\"Zihan Guo\"},{\"authorId\":\"9100598\",\"name\":\"Dezhi Han\"}],\"doi\":\"10.3390/s20236758\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"title\":\"Multi-Modal Explicit Sparse Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ea04b05c82087771b905fbdedd5ce6dfe48de097\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2012.09408\",\"authors\":[{\"authorId\":\"7390205\",\"name\":\"Chengyu Zheng\"},{\"authorId\":\"3050945\",\"name\":\"X. Peng\"},{\"authorId\":\"40491350\",\"name\":\"Yeliang Zhang\"},{\"authorId\":\"152383694\",\"name\":\"S. Srinivasan\"},{\"authorId\":\"1500380529\",\"name\":\"Y. Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d918e6b84101e7a3071f5196e45e79cc68d5dee8\",\"title\":\"Interactive Speech and Noise Modeling for Speech Enhancement\",\"url\":\"https://www.semanticscholar.org/paper/d918e6b84101e7a3071f5196e45e79cc68d5dee8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713590317\",\"name\":\"Chen Li\"},{\"authorId\":\"41015494\",\"name\":\"Z. Liu\"},{\"authorId\":\"1557382871\",\"name\":\"Sijie Li\"},{\"authorId\":\"2035530092\",\"name\":\"Ziniu Lin\"},{\"authorId\":\"50167971\",\"name\":\"L. Tian\"}],\"doi\":\"10.1007/s11276-020-02500-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9209b21e7aece218d5da1e9e6b414997e2fe5ca3\",\"title\":\"Variable length deep cross-modal hashing based on Cauchy probability function\",\"url\":\"https://www.semanticscholar.org/paper/9209b21e7aece218d5da1e9e6b414997e2fe5ca3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3440249\",\"name\":\"Ruozi Huang\"},{\"authorId\":\"46353980\",\"name\":\"Huang Hu\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"2505139\",\"name\":\"K. Sawada\"},{\"authorId\":\"144315664\",\"name\":\"Mi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b210d4594f19342ff625cf50d8d4bccfdc0d2ae5\",\"title\":\"Dance Revolution: Long Sequence Dance Generation with Music via Curriculum Learning\",\"url\":\"https://www.semanticscholar.org/paper/b210d4594f19342ff625cf50d8d4bccfdc0d2ae5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7314814\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1435766877\",\"name\":\"Gu Xiao-peng\"}],\"doi\":\"10.1145/3362065\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d39fb70393e9a17e5556708852829743380eeed\",\"title\":\"ACMNet: Adaptive Confidence Matching Network for Human Behavior Analysis via Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0d39fb70393e9a17e5556708852829743380eeed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.14487\",\"authors\":[{\"authorId\":\"94314731\",\"name\":\"Matthew Purri\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-58583-9_1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"title\":\"Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images\",\"url\":\"https://www.semanticscholar.org/paper/dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"31023725\",\"name\":\"Sheng-jia Li\"}],\"doi\":\"10.1109/JIOT.2020.2995148\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fcc33447e81661a5f463b59035c3082d6095cf24\",\"title\":\"Multimodal Alignment and Attention-Based Person Search via Natural Language Description\",\"url\":\"https://www.semanticscholar.org/paper/fcc33447e81661a5f463b59035c3082d6095cf24\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93762952\",\"name\":\"W. Li\"},{\"authorId\":\"1423419337\",\"name\":\"Jianhui Sun\"},{\"authorId\":\"48574046\",\"name\":\"Ge Liu\"},{\"authorId\":\"1657444300\",\"name\":\"Linglan Zhao\"},{\"authorId\":\"35680253\",\"name\":\"Xiangzhong Fang\"}],\"doi\":\"10.1016/j.patrec.2020.02.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"471e503f93c86b9c99e34d0f175b69f1db77f395\",\"title\":\"Visual question answering with attention transfer and a cross-modal gating mechanism\",\"url\":\"https://www.semanticscholar.org/paper/471e503f93c86b9c99e34d0f175b69f1db77f395\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"143715293\",\"name\":\"W. Zhang\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"145203884\",\"name\":\"H. Zha\"}],\"doi\":\"10.1007/978-3-030-59419-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a4ac7948360be7e55605c52a282d31af94280be0\",\"title\":\"Sequential Multi-fusion Network for Multi-channel Video CTR Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a4ac7948360be7e55605c52a282d31af94280be0\",\"venue\":\"DASFAA\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"80526284\",\"name\":\"Yanyuan Qiao\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"47002702\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3240508.3240662\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a1f1a06b840558c4433f0e06a4e9172539469e21\",\"title\":\"Enhancing Visual Question Answering Using Dropout\",\"url\":\"https://www.semanticscholar.org/paper/a1f1a06b840558c4433f0e06a4e9172539469e21\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1805.08819\",\"authors\":[{\"authorId\":\"4045460\",\"name\":\"Drew Linsley\"},{\"authorId\":\"46242703\",\"name\":\"Dan Scheibler\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.32470/CCN.2018.1113-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"title\":\"Global-and-local attention networks for visual recognition\",\"url\":\"https://www.semanticscholar.org/paper/36ab504f16b6ac49194da43d03171f5d32b80a9f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.08697\",\"authors\":[{\"authorId\":\"37619618\",\"name\":\"Khyathi Raghavi Chandu\"},{\"authorId\":\"51007384\",\"name\":\"Mary Arpita Pyreddy\"},{\"authorId\":\"40895015\",\"name\":\"Matthieu Felix\"},{\"authorId\":\"50745535\",\"name\":\"Narendra Nath Joshi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"title\":\"Textually Enriched Neural Module Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ad5950257e053b08657ea298f7b89ba358b8bfcf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31469067\",\"name\":\"Jia-Ming Wang\"},{\"authorId\":\"153140559\",\"name\":\"Jun Du\"},{\"authorId\":\"47539230\",\"name\":\"Jian-Shu Zhang\"},{\"authorId\":\"50219146\",\"name\":\"Zi-Rui Wang\"}],\"doi\":\"10.1109/ICDAR.2019.00191\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8231c3a1bfbb2ef309ba7b41abab9b8d6306bba\",\"title\":\"Multi-modal Attention Network for Handwritten Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8231c3a1bfbb2ef309ba7b41abab9b8d6306bba\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144454465\",\"name\":\"L. Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"153028349\",\"name\":\"Xiao Wu\"},{\"authorId\":\"83672162\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3343031.3350925\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"title\":\"CRA-Net: Composed Relation Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9927990\",\"name\":\"Armand Vilalta\"},{\"authorId\":\"1389953200\",\"name\":\"Dario Garcia-Gasulla\"},{\"authorId\":\"144954447\",\"name\":\"Ferran Par\\u00e9s\"},{\"authorId\":\"1744495\",\"name\":\"E. Ayguad\\u00e9\"},{\"authorId\":\"1699563\",\"name\":\"J. Labarta\"},{\"authorId\":\"1401454398\",\"name\":\"Eduardo Ulises Moya-S\\u00e1nchez\"},{\"authorId\":\"1742700\",\"name\":\"U. Cort\\u00e9s\"}],\"doi\":\"10.3233/SW-180341\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0d7662d98dc9e10d5496a55c0f77461285351a8\",\"title\":\"Studying the impact of the Full-Network embedding on multimodal pipelines\",\"url\":\"https://www.semanticscholar.org/paper/e0d7662d98dc9e10d5496a55c0f77461285351a8\",\"venue\":\"Semantic Web\",\"year\":2019},{\"arxivId\":\"1610.01465\",\"authors\":[{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1016/j.cviu.2017.06.005\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"title\":\"Visual question answering: Datasets, algorithms, and future challenges\",\"url\":\"https://www.semanticscholar.org/paper/6d92ce1c4f7f0ccfe068e663903e4dd614a15ede\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2017},{\"arxivId\":\"1806.01873\",\"authors\":[{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TPAMI.2018.2890628\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"title\":\"Focal Visual-Text Attention for Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/aee265f6a19f9774c65d296cf9ec0e169365dda5\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"2012.03308\",\"authors\":[{\"authorId\":\"50875615\",\"name\":\"W. Xia\"},{\"authorId\":\"3001727\",\"name\":\"Yujiu Yang\"},{\"authorId\":\"102528982\",\"name\":\"Jing-Hao Xue\"},{\"authorId\":\"143905981\",\"name\":\"Baoyuan Wu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faed82f8980af7ee8dbdb8bea732422f81e638e5\",\"title\":\"TediGAN: Text-Guided Diverse Image Generation and Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/faed82f8980af7ee8dbdb8bea732422f81e638e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.06892\",\"authors\":[{\"authorId\":\"49289638\",\"name\":\"Yaxian Xia\"},{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"},{\"authorId\":\"40445654\",\"name\":\"Jie Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"80a56c659dd1ab8675f01560ac5757a7f872ffa2\",\"title\":\"ParNet: Position-aware Aggregated Relation Network for Image-Text matching\",\"url\":\"https://www.semanticscholar.org/paper/80a56c659dd1ab8675f01560ac5757a7f872ffa2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"title\":\"wMAN: Weakly-supervised Moment Alignment Network for Text-based Video Segment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1145/3126686.3126695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"title\":\"Generative Attention Model with Adversarial Self-learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c315a0109b67cda1f55dee7967f570f0579a8ee8\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1715020\",\"name\":\"Elke A. Rundensteiner\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e3ce29c9b4af2ed8e82f3534c51ca5eacba68b7\",\"title\":\"AMAS : Attention Model for Attributed Sequence Classification Zhongfang Zhuang\",\"url\":\"https://www.semanticscholar.org/paper/4e3ce29c9b4af2ed8e82f3534c51ca5eacba68b7\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.10460\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143672098\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"35119829\",\"name\":\"R. Song\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"7474269\",\"name\":\"Ping-Ping Lin\"},{\"authorId\":\"47099153\",\"name\":\"Xiaoyu Qi\"},{\"authorId\":\"50096056\",\"name\":\"C. Wang\"},{\"authorId\":\"97807965\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1145/3343031.3350571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0779bca8faec33918338f98c0014e387993d388\",\"title\":\"Neural Storyboard Artist: Visualizing Stories with Coherent Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/e0779bca8faec33918338f98c0014e387993d388\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3343031.3350894\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"title\":\"Annotation Efficient Cross-Modal Retrieval with Adversarial Attentive Alignment\",\"url\":\"https://www.semanticscholar.org/paper/b8fd269ab69a974eaf057c0e4bcaf0be2b8ee55f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1805.07932\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"29818400\",\"name\":\"Jaehyun Jun\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"title\":\"Bilinear Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/a5d10341717c0519cf63151b496a6d2ed67aa05f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"2010.12126\",\"authors\":[{\"authorId\":\"35432059\",\"name\":\"L. Ren\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"1390771606\",\"name\":\"Liqiang Wang\"},{\"authorId\":\"1730455\",\"name\":\"K. Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"065af7ecb52354be79f538dac3ca210bf57e7739\",\"title\":\"Beyond the Deep Metric Learning: Enhance the Cross-Modal Matching with Adversarial Discriminative Domain Regularization\",\"url\":\"https://www.semanticscholar.org/paper/065af7ecb52354be79f538dac3ca210bf57e7739\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08596\",\"authors\":[{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"3425380\",\"name\":\"Zewei Xu\"},{\"authorId\":\"1722734\",\"name\":\"Y. Fu\"},{\"authorId\":\"1510729713\",\"name\":\"Haozhe Huang\"},{\"authorId\":\"2989265\",\"name\":\"Shi-Ku Wang\"},{\"authorId\":\"145270364\",\"name\":\"Haifeng Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c39b2974ad36bf4a66bdef8c923f07a0a5a8e9d\",\"title\":\"DAPnet: A double self-attention convolutional network for segmentation of point clouds\",\"url\":\"https://www.semanticscholar.org/paper/9c39b2974ad36bf4a66bdef8c923f07a0a5a8e9d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1910.14671\",\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1743587c272c36dbda0adc50496bf7f34b8148f1\",\"title\":\"TAB-VCR: Tags and Attributes based Visual Commonsense Reasoning Baselines\",\"url\":\"https://www.semanticscholar.org/paper/1743587c272c36dbda0adc50496bf7f34b8148f1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653799\",\"name\":\"W. Choi\"},{\"authorId\":\"2943489\",\"name\":\"Kyoung-Woon On\"},{\"authorId\":\"15353659\",\"name\":\"Yu-Jung Heo\"},{\"authorId\":\"152705134\",\"name\":\"B. Zhang\"}],\"doi\":\"10.18653/v1/2020.alvr-1.2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30f86e15b4fd7936b9812d476976a6ff579b9036\",\"title\":\"Toward General Scene Graph: Integration of Visual Semantic Knowledge with Entity Synset Alignment\",\"url\":\"https://www.semanticscholar.org/paper/30f86e15b4fd7936b9812d476976a6ff579b9036\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.05881\",\"authors\":[{\"authorId\":\"115003962\",\"name\":\"Marko Smilevski\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"401915cc8ac773e69223df42768083d53e10aa8d\",\"title\":\"Applying recent advances in Visual Question Answering to Record Linkage\",\"url\":\"https://www.semanticscholar.org/paper/401915cc8ac773e69223df42768083d53e10aa8d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3174935\",\"name\":\"Wenshan Wang\"},{\"authorId\":\"1470685911\",\"name\":\"Pengfei Liu\"},{\"authorId\":\"117785369\",\"name\":\"Su Yang\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.10.103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae1deb2efe99eea114fcde95ccd92a29af232c5a\",\"title\":\"Dynamic interaction networks for image-text multimodal learning\",\"url\":\"https://www.semanticscholar.org/paper/ae1deb2efe99eea114fcde95ccd92a29af232c5a\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47056886\",\"name\":\"Xiangpeng Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018658\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"565359aac8914505e6b02db05822ee63d3ffd03a\",\"title\":\"Beyond RNNs: Positional Self-Attention with Co-Attention for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/565359aac8914505e6b02db05822ee63d3ffd03a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10405058\",\"name\":\"Chenfei Wu\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"143672034\",\"name\":\"X. Dong\"}],\"doi\":\"10.1145/3240508.3240513\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"title\":\"Object-Difference Attention: A Simple Relational Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/34c9753893fe4713568542e7d96dc9a9e6545ec8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1733076657\",\"name\":\"Chenhao Lin\"},{\"authorId\":\"39765371\",\"name\":\"Pengwei Hu\"},{\"authorId\":\"145984785\",\"name\":\"H. Su\"},{\"authorId\":\"2980517\",\"name\":\"Shaochun Li\"},{\"authorId\":\"144562855\",\"name\":\"Jing Mei\"},{\"authorId\":\"145760827\",\"name\":\"J. Zhou\"},{\"authorId\":\"144801502\",\"name\":\"H. Leung\"}],\"doi\":\"10.1145/3372278.3391932\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"78a0a3494c6b223263ca56551501be9fb1b69556\",\"title\":\"SenseMood: Depression Detection on Social Media\",\"url\":\"https://www.semanticscholar.org/paper/78a0a3494c6b223263ca56551501be9fb1b69556\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1478822269\",\"name\":\"Jian Ke\"},{\"authorId\":\"46372566\",\"name\":\"Jianbo Xu\"},{\"authorId\":\"144164185\",\"name\":\"Xiangwei Meng\"},{\"authorId\":\"2031492283\",\"name\":\"Qixiong Huang\"}],\"doi\":\"10.1109/ICDSBA48748.2019.00020\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"709503d5fa9c418eb30428efcbf8731bbabe3771\",\"title\":\"Hybrid Collaborative Filtering with Attention CNN for Web Service Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/709503d5fa9c418eb30428efcbf8731bbabe3771\",\"venue\":\"2019 3rd International Conference on Data Science and Business Analytics (ICDSBA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1999410\",\"name\":\"Zhibin Hu\"},{\"authorId\":\"40132308\",\"name\":\"Yongsheng Luo\"},{\"authorId\":\"46698321\",\"name\":\"Jiong Lin\"},{\"authorId\":\"144761066\",\"name\":\"Yan Yan\"},{\"authorId\":\"5869774\",\"name\":\"J. Chen\"}],\"doi\":\"10.24963/ijcai.2019/111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10012e6a7a0ad10391533326b95bd1291df6f199\",\"title\":\"Multi-Level Visual-Semantic Alignments with Relation-Wise Dual Attention Network for Image and Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/10012e6a7a0ad10391533326b95bd1291df6f199\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41017837\",\"name\":\"Zhuobin Zheng\"},{\"authorId\":\"80414744\",\"name\":\"Youcheng Ben\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"title\":\"Multi-Scale Visual Semantics Aggregation with Self-Attention for End-to-End Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/0eb94f0229cd9548db3d19317a03a62cdcdd6f4e\",\"venue\":\"ACML\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"4495301\",\"name\":\"Yuan-Fang Li\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1609/AAAI.V33I01.33016391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"524879e9a072489110e9578cf2689e50c5531f05\",\"title\":\"Structured Two-Stream Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/524879e9a072489110e9578cf2689e50c5531f05\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1910.00058\",\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/D19-1154\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b3b563f6611f60af8ca96624191ff66b27a8f9\",\"title\":\"Multi-Head Attention with Diversity for Learning Grounded Multilingual Multimodal Representations\",\"url\":\"https://www.semanticscholar.org/paper/99b3b563f6611f60af8ca96624191ff66b27a8f9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"48079221\",\"name\":\"Sungho Park\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1016/j.neucom.2020.03.098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"72e48298519b5ff583e585a65eeea3ac10556adf\",\"title\":\"Selective residual learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/72e48298519b5ff583e585a65eeea3ac10556adf\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"46911598\",\"name\":\"Lin Zuo\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2020.2967597\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"title\":\"Cross-Modal Attention With Semantic Consistence for Image\\u2013Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/a87295dbea1256b99e4539f18c5fb73cd8b317aa\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9852531\",\"name\":\"J. Lin\"},{\"authorId\":\"10680632\",\"name\":\"Unnat Jain\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eefddfa610243968135726f9fddf4f69696863ed\",\"title\":\"TAB-VCR: Tags and Attributes based VCR Baselines\",\"url\":\"https://www.semanticscholar.org/paper/eefddfa610243968135726f9fddf4f69696863ed\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"49039449\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"7774960\",\"name\":\"Yuhang Lu\"},{\"authorId\":\"31055300\",\"name\":\"Zengchang Qin\"},{\"authorId\":\"1703234\",\"name\":\"Yue Hu\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/TMM.2020.2972830\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"title\":\"Reasoning on the Relation: Enhancing Visual Representation for Visual Question Answering and Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9ebcac11090f3c5a7b987c668d91c3e5fec0718b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3269206.3271765\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c67d62592ff24a25764e489a8a68672d40f50da7\",\"title\":\"Adversarial Learning of Answer-Related Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c67d62592ff24a25764e489a8a68672d40f50da7\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":\"1903.10829\",\"authors\":[{\"authorId\":\"49923549\",\"name\":\"Hyunjae Lee\"},{\"authorId\":\"3819366\",\"name\":\"H. Kim\"},{\"authorId\":\"34758272\",\"name\":\"H. Nam\"}],\"doi\":\"10.1109/ICCV.2019.00194\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"deb956b70eb93bb08eaabc18fb11aed9bd20d08f\",\"title\":\"SRM: A Style-Based Recalibration Module for Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/deb956b70eb93bb08eaabc18fb11aed9bd20d08f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.05541\",\"authors\":[{\"authorId\":\"32859304\",\"name\":\"Oytun Ulutan\"},{\"authorId\":\"145542943\",\"name\":\"A S M Iftekhar\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/cvpr42600.2020.01363\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a25ed60a891e228b829c9e0aa8b95aac3d04e11\",\"title\":\"VSGNet: Spatial Attention Network for Detecting Human Object Interactions Using Graph Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7a25ed60a891e228b829c9e0aa8b95aac3d04e11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.05573\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"47824843\",\"name\":\"W. Wang\"},{\"authorId\":\"1630359492\",\"name\":\"Ludan Ruan\"},{\"authorId\":\"49539732\",\"name\":\"Linli Yao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78605f537f6c4a8c5206bdd4f57cea22d9750703\",\"title\":\"YouMakeup VQA Challenge: Towards Fine-grained Action Understanding in Domain-Specific Videos\",\"url\":\"https://www.semanticscholar.org/paper/78605f537f6c4a8c5206bdd4f57cea22d9750703\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7435343\",\"name\":\"Zhedong Zheng\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"145908163\",\"name\":\"Michael Garrett\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"2285442\",\"name\":\"M. Xu\"},{\"authorId\":\"1744468\",\"name\":\"Y. Shen\"}],\"doi\":\"10.1145/3383184\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"title\":\"Dual-path Convolutional Image-Text Embeddings with Instance Loss\",\"url\":\"https://www.semanticscholar.org/paper/58555c7d168d1f50422ed9435d31ecd28d66eaa8\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5266981\",\"name\":\"S. Aggarwal\"},{\"authorId\":\"144682140\",\"name\":\"R. Venkatesh Babu\"},{\"authorId\":\"1429640900\",\"name\":\"Anirban Chakraborty\"}],\"doi\":\"10.1109/WACV45572.2020.9093640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9c79c80b6d04a623ea1ffebba1d6364f2887468\",\"title\":\"Text-based Person Search via Attribute-aided Matching\",\"url\":\"https://www.semanticscholar.org/paper/f9c79c80b6d04a623ea1ffebba1d6364f2887468\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2019.2916757\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"title\":\"CAM-RNN: Co-Attention Model Based RNN for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1904.01356\",\"authors\":[{\"authorId\":\"89373414\",\"name\":\"Omer Arshad\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"}],\"doi\":\"10.1109/ICDAR.2019.00061\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"add336dbad015f2f5ae0b3bd4525a9d7496adee5\",\"title\":\"Aiding Intra-Text Representations with Visual Context for Multimodal Named Entity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/add336dbad015f2f5ae0b3bd4525a9d7496adee5\",\"venue\":\"2019 International Conference on Document Analysis and Recognition (ICDAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51052405\",\"name\":\"H. Liu\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"50356714\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.2991/CMSA-18.2018.80\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"483828a82b26db7761a3a47fadc971b561b53615\",\"title\":\"Multimodal Cross-guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/483828a82b26db7761a3a47fadc971b561b53615\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2010.01082\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"51324296\",\"name\":\"Eric Michael Smith\"},{\"authorId\":\"3092435\",\"name\":\"Da Ju\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"title\":\"Multi-Modal Open-Domain Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/cf58cbdaf475109da7c528e6d5d390ed97fba6b2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1912074118\",\"name\":\"Jianfeng Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"title\":\"Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network\",\"url\":\"https://www.semanticscholar.org/paper/83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":\"2008.06581\",\"authors\":[{\"authorId\":\"1826395\",\"name\":\"Bin Duan\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"91913011\",\"name\":\"Wei Wang\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"47124958\",\"name\":\"Guowei Yang\"},{\"authorId\":null,\"name\":\"Yan Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"title\":\"Audio-Visual Event Localization via Recursive Fusion by Joint Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/17cf9e1a487ef8141192d6ec7d568c9823b34ac4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.00579\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"1877430\",\"name\":\"A. E. Kholy\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/P19-1648\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"title\":\"Multi-step Reasoning via Recurrent Dual Attention for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/8d9f1eaac344b7e6cc76396f576c5dc0bd0b34f4\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1812.00500\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2019.01074\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"title\":\"Multi-Task Learning of Hierarchical Vision-Language Representation\",\"url\":\"https://www.semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.11735\",\"authors\":[{\"authorId\":\"2028358638\",\"name\":\"Varnith Chordia\"},{\"authorId\":\"103911681\",\"name\":\"G. VijayKumarB.\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5b7ae762fa7f274651079699e5cd5912f314312\",\"title\":\"Large Scale Multimodal Classification Using an Ensemble of Transformer Models and Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/a5b7ae762fa7f274651079699e5cd5912f314312\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47320028\",\"name\":\"Shuya Li\"},{\"authorId\":\"48267418\",\"name\":\"F. Wan\"},{\"authorId\":\"1576505413\",\"name\":\"Hantao Shu\"},{\"authorId\":\"143872544\",\"name\":\"T. Jiang\"},{\"authorId\":\"47783184\",\"name\":\"Dan Zhao\"},{\"authorId\":\"90424501\",\"name\":\"J. Zeng\"}],\"doi\":\"10.1101/2019.12.30.891515\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"48026e47d6be771ac8e918b935e48fb5a2152561\",\"title\":\"MONN: a Multi-Objective Neural Network for Predicting Pairwise Non-Covalent Interactions and Binding Affinities between Compounds and Proteins\",\"url\":\"https://www.semanticscholar.org/paper/48026e47d6be771ac8e918b935e48fb5a2152561\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1806.04860\",\"authors\":[{\"authorId\":\"47008023\",\"name\":\"Z. Su\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"3431029\",\"name\":\"Y. Dong\"},{\"authorId\":\"1751449\",\"name\":\"Dongqi Cai\"},{\"authorId\":\"6060281\",\"name\":\"Y. Chen\"},{\"authorId\":\"46277052\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2018.00807\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f08157b959070ba802afbb135f4336c5a426fd\",\"title\":\"Learning Visual Knowledge Memory Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33f08157b959070ba802afbb135f4336c5a426fd\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9305072\",\"name\":\"Jifei Song\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.1109/ICCV.2017.592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1c808ed24684b734f137f8bb76524ddc5ed1b36\",\"title\":\"Deep Spatial-Semantic Attention for Fine-Grained Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f1c808ed24684b734f137f8bb76524ddc5ed1b36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7361508\",\"name\":\"Zhiqiang Wan\"},{\"authorId\":\"144996615\",\"name\":\"Haibo He\"}],\"doi\":\"10.1109/TBDATA.2018.2884486\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"title\":\"AnswerNet: Learning to Answer Questions\",\"url\":\"https://www.semanticscholar.org/paper/8524d0447d84c6b2dc41e4bca81e0daf6b1b67ac\",\"venue\":\"IEEE Transactions on Big Data\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66744747\",\"name\":\"Jangseong Bae\"},{\"authorId\":\"50520932\",\"name\":\"Choonsup Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1d5e6c1867d549e756bc6b4ef321957257787623\",\"title\":\"Korean VQA with Deep learning\",\"url\":\"https://www.semanticscholar.org/paper/1d5e6c1867d549e756bc6b4ef321957257787623\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2017.446\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"144898150\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"75409785b6b6e7fee81489cc5db731c1718dbd3e\",\"title\":\"GRU Encoder Word Embeddings Fusing with MLP Predicted Word : Vase\",\"url\":\"https://www.semanticscholar.org/paper/75409785b6b6e7fee81489cc5db731c1718dbd3e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.02036\",\"authors\":[{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00645\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f322eef6a4c965910e03f6997b1bc2acd413e273\",\"title\":\"Learning Semantic Concepts and Order for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/f322eef6a4c965910e03f6997b1bc2acd413e273\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150074679\",\"name\":\"Denis Dushi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"title\":\"Using Deep Learning to Answer Visual Questions from Blind People\",\"url\":\"https://www.semanticscholar.org/paper/d19ab1db4d8c60643bc2ce8334505acaadee84ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"144547315\",\"name\":\"E. Hovy\"}],\"doi\":\"10.1145/3372278.3390674\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"title\":\"Forward and Backward Multimodal NMT for Improved Monolingual and Multilingual Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/4d5018c8bdf61129ca06a333ddbbe32dd84e50c2\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1811.00945\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/2020.acl-main.219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"title\":\"Image-Chat: Engaging Grounded Conversations\",\"url\":\"https://www.semanticscholar.org/paper/b7216846c743d94fcd43e1b543c9d16ae11d3c48\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681049\",\"name\":\"Liyuan Wang\"},{\"authorId\":\"1519066969\",\"name\":\"Jing Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"48161494\",\"name\":\"C. Li\"},{\"authorId\":\"152134003\",\"name\":\"Li Zhuo\"}],\"doi\":\"10.1109/TCSVT.2019.2958871\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a26520ff1c497e9526f3533c7ef8b2b1c4425ac8\",\"title\":\"Porn Streamer Recognition in Live Video Streaming via Attention-Gated Multimodal Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/a26520ff1c497e9526f3533c7ef8b2b1c4425ac8\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"145310587\",\"name\":\"K. Wu\"},{\"authorId\":\"145880684\",\"name\":\"Hao Cheng\"},{\"authorId\":\"5494837\",\"name\":\"C. Gu\"},{\"authorId\":\"40977498\",\"name\":\"Rui Xu\"},{\"authorId\":\"152936756\",\"name\":\"X. Guan\"}],\"doi\":\"10.1007/978-3-030-04224-0_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8642efc51d262547994c4c8600cb5d021de4952b\",\"title\":\"A Pathology Image Diagnosis Network with Visual Interpretability and Structured Diagnostic Report\",\"url\":\"https://www.semanticscholar.org/paper/8642efc51d262547994c4c8600cb5d021de4952b\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"2010.02949\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.60\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"73068d13d6e53876c374ebd4c862ec01351c9f39\",\"title\":\"Learning to Represent Image and Text with Denotation Graph\",\"url\":\"https://www.semanticscholar.org/paper/73068d13d6e53876c374ebd4c862ec01351c9f39\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1708.01471\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2017.202\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"title\":\"Multi-modal Factorized Bilinear Pooling with Co-attention Learning for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8e9ad6f8b2bc97f0412fa0cc243ac6975864534a\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"1914578421\",\"name\":\"Sabarish Gopalakrishnan\"},{\"authorId\":\"1404315481\",\"name\":\"Raymond Ptucha\"}],\"doi\":\"10.1117/1.JEI.29.2.023013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"360d84f0649d80d3b96846c1cd958b6c54332835\",\"title\":\"Aligned attention for common multimodal embeddings\",\"url\":\"https://www.semanticscholar.org/paper/360d84f0649d80d3b96846c1cd958b6c54332835\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49544292\",\"name\":\"Xueliang Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"50025104\",\"name\":\"Yonghong Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3282469\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c74311cc5e18a120bebf331b0dd85c72426380d\",\"title\":\"BTDP: Toward Sparse Fusion with Block Term Decomposition Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c74311cc5e18a120bebf331b0dd85c72426380d\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"145863022\",\"name\":\"X. Zhang\"}],\"doi\":\"10.20944/PREPRINTS201804.0313.V1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1903.00366\",\"authors\":[{\"authorId\":\"153677280\",\"name\":\"Robik Shrestha\"},{\"authorId\":\"33315685\",\"name\":\"Kushal Kafle\"},{\"authorId\":\"3290098\",\"name\":\"Christopher Kanan\"}],\"doi\":\"10.1109/CVPR.2019.01072\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"title\":\"Answer Them All! Toward Universal Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2616738\",\"name\":\"Ruoyu Liu\"},{\"authorId\":\"145093507\",\"name\":\"Yao Zhao\"},{\"authorId\":\"46730712\",\"name\":\"S. Wei\"},{\"authorId\":\"144802394\",\"name\":\"L. Zheng\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3300939\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"70e80065c4db089c3792245535ecacdca3770577\",\"title\":\"Modality-Invariant Image-Text Embedding for Image-Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/70e80065c4db089c3792245535ecacdca3770577\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"title\":\"ENGAGING IMAGE CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1863856\",\"name\":\"Kaimin Wei\"},{\"authorId\":\"2392310\",\"name\":\"Z. Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2996407\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"title\":\"Adversarial Attentive Multi-Modal Embedding Learning for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/e1787f375ed8fb0f3aed021a161ff1171229b6fd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"},{\"authorId\":\"1686820\",\"name\":\"B. M\\u00e9rialdo\"}],\"doi\":\"10.1109/CBMI.2018.8516480\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"174812bf1d4718cdf0b5432d9df290153046afe7\",\"title\":\"Embedding Images and Sentences in a Common Space with a Recurrent Capsule Network\",\"url\":\"https://www.semanticscholar.org/paper/174812bf1d4718cdf0b5432d9df290153046afe7\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35301620\",\"name\":\"Katrien Laenen\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1016/j.ipm.2020.102316\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c04d535a0710cbe306a392e63c688ba71842bf93\",\"title\":\"A Comparative Study of Outfit Recommendation Methods with a Focus on Attention-based Fusion\",\"url\":\"https://www.semanticscholar.org/paper/c04d535a0710cbe306a392e63c688ba71842bf93\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1387712541\",\"name\":\"Zijin Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1145/3343031.3351055\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"42001225313e0f5376a8f4b1759e687225cd9d00\",\"title\":\"Cross-Modal Image-Text Retrieval with Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/42001225313e0f5376a8f4b1759e687225cd9d00\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2007.08883\",\"authors\":[{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"72095125\",\"name\":\"Y. Zhang\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"48278149\",\"name\":\"Y. Pang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"}],\"doi\":\"10.1007/978-3-030-58586-0_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe573437cbd4069556348ad28dfeae2df46e22a0\",\"title\":\"Consensus-Aware Visual-Semantic Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/fe573437cbd4069556348ad28dfeae2df46e22a0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"39937384\",\"name\":\"Yan Huang\"},{\"authorId\":\"145769446\",\"name\":\"L. Wang\"}],\"doi\":\"10.1145/3394171.3413895\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"98b354ddfa46ccf9fc604c751eb9deebf4c909f8\",\"title\":\"Textual Dependency Embedding for Person Search by Language\",\"url\":\"https://www.semanticscholar.org/paper/98b354ddfa46ccf9fc604c751eb9deebf4c909f8\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1709.06308\",\"authors\":[{\"authorId\":\"6002624\",\"name\":\"Tingting Qiao\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"7471918\",\"name\":\"Duanqing Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fafe70edc7067015ca2d49aef2773c22a71647d\",\"title\":\"Exploring Human-like Attention Supervision in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/3fafe70edc7067015ca2d49aef2773c22a71647d\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89373414\",\"name\":\"Omer Arshad\"},{\"authorId\":\"145116184\",\"name\":\"I. Gallo\"},{\"authorId\":\"144669071\",\"name\":\"Shah Nawaz\"},{\"authorId\":\"3457883\",\"name\":\"Alessandro Calefati\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b49ea26f61527f897cf7ea2d5cf1a32de6cfc83\",\"title\":\"EasyChair Preprint No 1375 Aiding Intra-Text Representations with Visual Context for Multimodal Named Entity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b49ea26f61527f897cf7ea2d5cf1a32de6cfc83\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1490937293\",\"name\":\"Feng Ling\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"46389488\",\"name\":\"H. Ma\"}],\"doi\":\"10.1109/ACCESS.2020.2969808\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"title\":\"Combining Global and Local Similarity for Cross-Media Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3b8b61c7ebe5aec472ee19962a4edb2b8b7e971a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1906.06620\",\"authors\":[{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"46397904\",\"name\":\"L. Fritz\"},{\"authorId\":\"36004650\",\"name\":\"Gabi Shalev\"},{\"authorId\":\"40135367\",\"name\":\"E. Oks\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4a9a87e2a49d7477c0a3fb371a1a211e597761\",\"title\":\"Joint Visual-Textual Embedding for Multimodal Style Search\",\"url\":\"https://www.semanticscholar.org/paper/ad4a9a87e2a49d7477c0a3fb371a1a211e597761\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103483742\",\"name\":\"Yuang Liu\"},{\"authorId\":\"143715293\",\"name\":\"W. Zhang\"},{\"authorId\":\"71563028\",\"name\":\"Jijie Wang\"}],\"doi\":\"10.1016/j.neucom.2020.07.048\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19477cbadc03fbbca4601a4588f21fab28edaf2e\",\"title\":\"Adaptive multi-teacher multi-level knowledge distillation\",\"url\":\"https://www.semanticscholar.org/paper/19477cbadc03fbbca4601a4588f21fab28edaf2e\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1732300163\",\"name\":\"Y. Guo\"},{\"authorId\":\"12564022\",\"name\":\"J. Chen\"},{\"authorId\":\"7214794\",\"name\":\"H. Zhang\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3372278.3390709\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d1ac5e2f4d70b26ee7e79ee30a38f64676b404a\",\"title\":\"Visual Relations Augmented Cross-modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/3d1ac5e2f4d70b26ee7e79ee30a38f64676b404a\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"50879442\",\"name\":\"E. Me\\u00e7e\"}],\"doi\":\"10.1007/978-3-030-01174-1_60\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"title\":\"Multimodal Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c2777a8ca7447764e51a4b2498a7a6157f76da37\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47908786\",\"name\":\"Y. Liu\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.patcog.2018.07.001\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96e05dd7f08df72f57b22ebf67a7bd5b5b797989\",\"title\":\"Learning visual and textual representations for multimodal matching and classification\",\"url\":\"https://www.semanticscholar.org/paper/96e05dd7f08df72f57b22ebf67a7bd5b5b797989\",\"venue\":\"Pattern Recognit.\",\"year\":2018},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"3374607\",\"name\":\"Vaibhav\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3323873.3325043\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"title\":\"Improving What Cross-Modal Retrieval Models Learn through Object-Oriented Inter- and Intra-Modal Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/ced9f3f05a780110a0a26549a45c4916cb16d3b1\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3430216\",\"name\":\"Y. Tamaazousti\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"619404bf9fd0f55eeabb94f0cebf190399c57f0a\",\"title\":\"Vers l\\u2019universalit\\u00e9 des repr\\u00e9sentations visuelle et multimodales\",\"url\":\"https://www.semanticscholar.org/paper/619404bf9fd0f55eeabb94f0cebf190399c57f0a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1911.10496\",\"authors\":[{\"authorId\":\"3167894\",\"name\":\"Jiaxin Qi\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"50560698\",\"name\":\"Jianqiang Huang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.01087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"title\":\"Two Causal Principles for Improving Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/ad99fef72abe84e6b5f194d4973ca824812dbb11\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120897486\",\"name\":\"Anwen Hu\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"title\":\"ICECAP: Information Concentrated Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92827207\",\"name\":\"Jiayou Chen\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"7661726\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"118150711\",\"name\":\"Junwei Liang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e523ce7431f15cabfefb4aa79fc6642708740948\",\"title\":\"Video to Text Description\",\"url\":\"https://www.semanticscholar.org/paper/e523ce7431f15cabfefb4aa79fc6642708740948\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1704.03162\",\"authors\":[{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"2544590\",\"name\":\"Ali Elqursh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d674b540dcd968bc302ea4360df3f4e85e994b55\",\"title\":\"Show, Ask, Attend, and Answer: A Strong Baseline For Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d674b540dcd968bc302ea4360df3f4e85e994b55\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1514929766\",\"name\":\"Chongqing Chen\"},{\"authorId\":\"1840771\",\"name\":\"D. Han\"},{\"authorId\":\"71563119\",\"name\":\"Jun Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2975093\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"title\":\"Multimodal Encoder-Decoder Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e75fa8852f5a4779cfdf2f22bd87e213f57b2d20\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1803.11185\",\"authors\":[{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"}],\"doi\":\"10.1109/CVPR.2018.00641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"021b08b823700f8053afc54356e8d0ce57a3df71\",\"title\":\"Unsupervised Textual Grounding: Linking Words to Image Concepts\",\"url\":\"https://www.semanticscholar.org/paper/021b08b823700f8053afc54356e8d0ce57a3df71\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2011.04305\",\"authors\":[{\"authorId\":\"1918424\",\"name\":\"Jiacheng Chen\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1491232360\",\"name\":\"Hao Wu\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":\"1906061249\",\"name\":\"Changhu Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"title\":\"Learning the Best Pooling Strategy for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/a27f4af07d73baccda94b5d2a2535b7dfdb58019\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145242717\",\"name\":\"H. Cheng\"},{\"authorId\":\"145310587\",\"name\":\"K. Wu\"},{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"145464144\",\"name\":\"J. Tian\"},{\"authorId\":\"143888056\",\"name\":\"R. Xu\"},{\"authorId\":\"2443214\",\"name\":\"Chao-Chen Gu\"},{\"authorId\":\"145394028\",\"name\":\"X. Guan\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206603\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"27e2197dbb2a4e3ec5eaaa9c94255c658e782b5e\",\"title\":\"Double Attention for Pathology Image Diagnosis Network with Visual Interpretability\",\"url\":\"https://www.semanticscholar.org/paper/27e2197dbb2a4e3ec5eaaa9c94255c658e782b5e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.10585\",\"authors\":[{\"authorId\":\"35301620\",\"name\":\"Katrien Laenen\"},{\"authorId\":\"145446752\",\"name\":\"Marie-Francine Moens\"}],\"doi\":\"10.1007/978-3-030-55218-3_4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89445545cbd7abd0e9588e8b80be9d0721c0e816\",\"title\":\"Attention-based Fusion for Outfit Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/89445545cbd7abd0e9588e8b80be9d0721c0e816\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.04011\",\"authors\":[{\"authorId\":\"134814700\",\"name\":\"T. Wang\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"}],\"doi\":\"10.1145/3343031.3350875\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"title\":\"Matching Images and Text with Multi-modal Tensor Fusion and Re-ranking\",\"url\":\"https://www.semanticscholar.org/paper/b4e1be8dd4d303e8e8ffe4343b2200d7952d16c4\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"title\":\"Engaging Image Chat: Modeling Personality in Grounded Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/5e138ae6499947cddf9d4f7fa04ba78e2af797af\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1905.13540\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"3549056\",\"name\":\"K. Kim\"},{\"authorId\":\"72108920\",\"name\":\"S. Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/IJCNN.2019.8852087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"title\":\"Gaining Extra Supervision via Multi-task learning for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1165b090e5ec6a9311ecba5be4f6aac0a1a4586b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25883189\",\"name\":\"Shanshan Lyu\"},{\"authorId\":\"8676190\",\"name\":\"Wentao Ouyang\"},{\"authorId\":\"30551196\",\"name\":\"Yongqing Wang\"},{\"authorId\":\"2476503\",\"name\":\"H. Shen\"},{\"authorId\":\"1717004\",\"name\":\"X. Cheng\"}],\"doi\":\"10.1145/3308558.3313510\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da95e8cc6c2e5f03299c67f5868274369b1e1b53\",\"title\":\"What We Vote for? Answer Selection from User Expertise View in Community Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/da95e8cc6c2e5f03299c67f5868274369b1e1b53\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":\"1908.10534\",\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"93809632\",\"name\":\"Xiang Xu\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1109/ICCV.2019.00591\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"title\":\"Adversarial Representation Learning for Text-to-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/ed3ed6458abdfb54fa1e3ce4434dfd9adb3b55ad\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597404\",\"name\":\"Z. Fang\"},{\"authorId\":\"7187373\",\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"Qu Tang\"},{\"authorId\":\"49112842\",\"name\":\"Y. Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-20887-5_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"title\":\"Answer Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8463ff93a6725017bd1875eeb7ae4d0f0e7df568\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1808.02632\",\"authors\":[{\"authorId\":\"144579867\",\"name\":\"P. Gao\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"88479495\",\"name\":\"S. Li\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01246-5_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"391af839051826ec317a6ea61010734baf536551\",\"title\":\"Question-Guided Hybrid Convolution for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/391af839051826ec317a6ea61010734baf536551\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1802.00209\",\"authors\":[{\"authorId\":\"143757036\",\"name\":\"Ahmed Osman\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b66dababebd800e95d23a1fde299d44a52e98ed\",\"title\":\"Dual Recurrent Attention Units for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7b66dababebd800e95d23a1fde299d44a52e98ed\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.01720\",\"authors\":[{\"authorId\":\"35376394\",\"name\":\"Martin Engilberge\"},{\"authorId\":\"39255836\",\"name\":\"Louis Chevallier\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1109/CVPR.2018.00419\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9645e8b4829c04879a642d8dd6b3cdf5cf264afb\",\"title\":\"Finding Beans in Burgers: Deep Semantic-Visual Embedding with Localization\",\"url\":\"https://www.semanticscholar.org/paper/9645e8b4829c04879a642d8dd6b3cdf5cf264afb\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.00584\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6e390a6a6d783bc0898915dc48f7f1844db5137c\",\"title\":\"A Simple Loss Function for Improving the Convergence and Accuracy of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/6e390a6a6d783bc0898915dc48f7f1844db5137c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144560801\",\"name\":\"Wenzhong Guo\"},{\"authorId\":\"120465682\",\"name\":\"J. Wang\"},{\"authorId\":\"49183986\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2916887\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff\",\"title\":\"Deep Multimodal Representation Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145268319\",\"name\":\"Qiang Sun\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"}],\"doi\":\"10.1145/3323873.3325044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33c6f05eac12622146fec4868735daa78f79f80a\",\"title\":\"Stacked Self-Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/33c6f05eac12622146fec4868735daa78f79f80a\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50820276\",\"name\":\"Yunzhao Li\"},{\"authorId\":\"3419487\",\"name\":\"H. Xu\"},{\"authorId\":\"150166782\",\"name\":\"Junsheng Xiao\"}],\"doi\":\"10.3390/s20185279\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e32b4f161d10a15a53df599a58dca74e5c51f17b\",\"title\":\"Hybrid Attention Network for Language-Based Person Search\",\"url\":\"https://www.semanticscholar.org/paper/e32b4f161d10a15a53df599a58dca74e5c51f17b\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145406475\",\"name\":\"R. Ma\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"48094184\",\"name\":\"Jiawen Wang\"},{\"authorId\":\"1732687\",\"name\":\"L. Cui\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.1145/3209978.3210026\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50f3587a6316ae59493f4c408eadefe3bbf891fe\",\"title\":\"Mention Recommendation for Multimodal Microblog with Cross-attention Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/50f3587a6316ae59493f4c408eadefe3bbf891fe\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":\"1906.02467\",\"authors\":[{\"authorId\":\"48567197\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1720236\",\"name\":\"J. Yu\"},{\"authorId\":\"144478231\",\"name\":\"T. Yu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1609/aaai.v33i01.33019127\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f2c1af57c056102806a184517313804f66e7447\",\"title\":\"ActivityNet-QA: A Dataset for Understanding Complex Web Videos via Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4f2c1af57c056102806a184517313804f66e7447\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1990265392\",\"name\":\"Leigang Qu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"145479818\",\"name\":\"D. Cao\"},{\"authorId\":\"143982887\",\"name\":\"L. Nie\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413961\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"922d677867e1aa2a7cca05241af4746a0be04dd0\",\"title\":\"Context-Aware Multi-View Summarization Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/922d677867e1aa2a7cca05241af4746a0be04dd0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145112305\",\"name\":\"Chunxiao Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"3181822\",\"name\":\"Wenyu Zang\"},{\"authorId\":null,\"name\":\"Bin Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8683869\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"title\":\"A Neighbor-aware Approach for Image-text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1a2bc5dd106fdc62101c4a42286877da0e7606ed\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058862\",\"name\":\"L. Zhang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"153580417\",\"name\":\"M. Prakash\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1016/j.patcog.2020.107348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"title\":\"Few-shot activity recognition with cross-modal memory network\",\"url\":\"https://www.semanticscholar.org/paper/c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1903.00839\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"50218594\",\"name\":\"Z. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/CVPR.2019.00205\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"title\":\"Improving Referring Expression Grounding With Cross-Modal Attention-Guided Erasing\",\"url\":\"https://www.semanticscholar.org/paper/cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973718\",\"name\":\"L. Kodra\"},{\"authorId\":\"51252244\",\"name\":\"Elinda Kajo Me\\u00e7e\"}],\"doi\":\"10.1145/3230467.3230476\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3efd4cc31527d5d8fc27aad27b140042f5f7561\",\"title\":\"Visual Question Answering Agent with Visual and Textual Attention\",\"url\":\"https://www.semanticscholar.org/paper/f3efd4cc31527d5d8fc27aad27b140042f5f7561\",\"venue\":\"ICEMC '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"153028537\",\"name\":\"X. Wu\"},{\"authorId\":\"36263371\",\"name\":\"Shen Ge\"},{\"authorId\":\"93249636\",\"name\":\"W. Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1609/AAAI.V34I07.6824\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"title\":\"Federated Learning for Vision-and-Language Grounding Problems\",\"url\":\"https://www.semanticscholar.org/paper/d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1808.08114\",\"authors\":[{\"authorId\":\"9952952\",\"name\":\"Jo Schlemper\"},{\"authorId\":\"2941969\",\"name\":\"O. Oktay\"},{\"authorId\":\"144932484\",\"name\":\"M. Schaap\"},{\"authorId\":\"1825371\",\"name\":\"M. Heinrich\"},{\"authorId\":\"2015193\",\"name\":\"Bernhard Kainz\"},{\"authorId\":\"1709824\",\"name\":\"Ben Glocker\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"}],\"doi\":\"10.1016/j.media.2019.01.012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a2bdf5cf0d73bc333423a8fd246593f4bf65322\",\"title\":\"Attention gated networks: Learning to leverage salient regions in medical images\",\"url\":\"https://www.semanticscholar.org/paper/2a2bdf5cf0d73bc333423a8fd246593f4bf65322\",\"venue\":\"Medical Image Anal.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1717592\",\"name\":\"W. Zhang\"},{\"authorId\":\"1792246\",\"name\":\"C. Zhang\"},{\"authorId\":\"3114205\",\"name\":\"P. Liu\"},{\"authorId\":\"2035942\",\"name\":\"Zhiqiang Zhan\"},{\"authorId\":\"34985964\",\"name\":\"Xiaofeng Qiu\"}],\"doi\":\"10.1109/BIGCOM.2017.17\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3f24a03b9b55327704fba3aed182323137113c2\",\"title\":\"Two-Step Joint Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a3f24a03b9b55327704fba3aed182323137113c2\",\"venue\":\"2017 3rd International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5141773\",\"name\":\"S. Mishra\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"},{\"authorId\":\"2156276\",\"name\":\"N. B. Puhan\"}],\"doi\":\"10.1109/LSP.2019.2949388\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c296980d7fa848cd458ef51c6fe3f434c527228\",\"title\":\"Multi-Level Dual-Attention Based CNN for Macular Optical Coherence Tomography Classification\",\"url\":\"https://www.semanticscholar.org/paper/7c296980d7fa848cd458ef51c6fe3f434c527228\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49483501\",\"name\":\"Yiqun Yao\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"49821282\",\"name\":\"Bo Xu\"}],\"doi\":\"10.18653/v1/N19-1266\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c880ad812f1195c1199a7e50fcedfca1c41a8e29\",\"title\":\"The World in My Mind: Visual Dialog with Adversarial Multi-modal Feature Encoding\",\"url\":\"https://www.semanticscholar.org/paper/c880ad812f1195c1199a7e50fcedfca1c41a8e29\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":\"2009.07335\",\"authors\":[{\"authorId\":\"16286752\",\"name\":\"Md. Mushfiqur Rahman\"},{\"authorId\":\"1945520590\",\"name\":\"Thasin Abedin\"},{\"authorId\":\"1945917684\",\"name\":\"Khondokar S. S. Prottoy\"},{\"authorId\":\"1945917586\",\"name\":\"Ayana Moshruba\"},{\"authorId\":\"32826273\",\"name\":\"F. H. Siddiqui\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2a0c5a1d5ae87ae734da2ef9c5eac6b2146536b\",\"title\":\"Semantically Sensible Video Captioning (SSVC)\",\"url\":\"https://www.semanticscholar.org/paper/e2a0c5a1d5ae87ae734da2ef9c5eac6b2146536b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"1935044135\",\"name\":\"Wenbo Zheng\"},{\"authorId\":\"151486225\",\"name\":\"L. Yan\"},{\"authorId\":\"1491637173\",\"name\":\"Chao Gou\"},{\"authorId\":\"143754347\",\"name\":\"F. Wang\"}],\"doi\":\"10.1016/j.inffus.2020.10.007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"title\":\"KM4: Visual reasoning via Knowledge Embedding Memory Model with Mutual Modulation\",\"url\":\"https://www.semanticscholar.org/paper/03a8f5098e8ffeed7a38f1ae8705f71b18d24e0e\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66880635\",\"name\":\"Angelo Carraggi\"},{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1007/978-3-030-11024-6_47\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"316a266fa464d0963a6156854bac57deac71f586\",\"title\":\"Visual-Semantic Alignment Across Domains Using a Semi-Supervised Approach\",\"url\":\"https://www.semanticscholar.org/paper/316a266fa464d0963a6156854bac57deac71f586\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1811.08170\",\"authors\":[{\"authorId\":\"143900009\",\"name\":\"Lei Li\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"1842335\",\"name\":\"Q. Su\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"},{\"authorId\":\"38705735\",\"name\":\"C. Tai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5619152331d49bde96ae9f51fffac931ca37a500\",\"title\":\"Sketch-R2CNN: An Attentive Network for Vector Sketch Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5619152331d49bde96ae9f51fffac931ca37a500\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1712.06228\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"Jin-Hwa Kim\"},{\"authorId\":\"1692756\",\"name\":\"Byoung-Tak Zhang\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9479771f1acf98a10e1627f6bc2ad431285e01bd\",\"title\":\"Visual Explanations from Hadamard Product in Multimodal Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/9479771f1acf98a10e1627f6bc2ad431285e01bd\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"3436470\",\"name\":\"Kimin Lee\"},{\"authorId\":\"143720148\",\"name\":\"Jinwoo Shin\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7adef3d0200207baec75e39bbb852cacfaf8268b\",\"title\":\"Learning to Specialize with Knowledge Distillation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7adef3d0200207baec75e39bbb852cacfaf8268b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1901.02527\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"17420047ab3c64ebbb63dcf21931d26fa77955d6\",\"title\":\"Viewpoint Invariant Change Captioning\",\"url\":\"https://www.semanticscholar.org/paper/17420047ab3c64ebbb63dcf21931d26fa77955d6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978170\",\"name\":\"Fartash Faghri\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"51131802\",\"name\":\"J. Kiros\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"title\":\"VSE++: Improving Visual-Semantic Embeddings with Hard Negatives\",\"url\":\"https://www.semanticscholar.org/paper/f7ab6c52be9351ac3f6cf8fe6ad5efba1c1595e8\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685878\",\"name\":\"B. Sahiner\"},{\"authorId\":\"48238569\",\"name\":\"Aria Pezeshk\"},{\"authorId\":\"2591670\",\"name\":\"L. Hadjiiski\"},{\"authorId\":\"51126635\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2728244\",\"name\":\"K. Drukker\"},{\"authorId\":\"4767498\",\"name\":\"Kenny H. Cha\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"},{\"authorId\":\"144692532\",\"name\":\"M. Giger\"}],\"doi\":\"10.1002/mp.13264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb2fcb003541b29f727588da1183bf1ca289cb73\",\"title\":\"Deep learning in medical imaging and radiation therapy.\",\"url\":\"https://www.semanticscholar.org/paper/eb2fcb003541b29f727588da1183bf1ca289cb73\",\"venue\":\"Medical physics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/s13735-018-00166-3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6305115f393d96df92f9044b8951969e28aa7114\",\"title\":\"Joint embeddings with multimodal cues for video-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6305115f393d96df92f9044b8951969e28aa7114\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":\"1808.07793\",\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"21496852\",\"name\":\"R. Panda\"},{\"authorId\":\"3000659\",\"name\":\"Evangelos E. Papalexakis\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3240508.3240712\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"title\":\"Webly Supervised Joint Embedding for Cross-Modal Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/082d339e29b1b1a9a800a1d72b401f69b6a157c5\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72445881\",\"name\":\"Xinhong Ma\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/TMM.2020.2969792\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d68c359a76b9efb3bedf85cdc915bcf49dbd55db\",\"title\":\"Multi-Level Correlation Adversarial Hashing for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d68c359a76b9efb3bedf85cdc915bcf49dbd55db\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2507886\",\"name\":\"L. Zhu\"},{\"authorId\":\"145994426\",\"name\":\"S. Zhan\"},{\"authorId\":\"40259910\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2018.12.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"79f0d4e4d71c514b62734a49ede957963336f6f7\",\"title\":\"Stacked U-shape networks with channel-wise attention for image super-resolution\",\"url\":\"https://www.semanticscholar.org/paper/79f0d4e4d71c514b62734a49ede957963336f6f7\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1806.10348\",\"authors\":[{\"authorId\":\"8815141\",\"name\":\"Haoyue Shi\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"1691963\",\"name\":\"Yuning Jiang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e16de062b9cdeecfcbda0de022f1fc4e741a2e6\",\"title\":\"Learning Visually-Grounded Semantics from Contrastive Adversarial Samples\",\"url\":\"https://www.semanticscholar.org/paper/3e16de062b9cdeecfcbda0de022f1fc4e741a2e6\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"1915664\",\"name\":\"Di Chen\"},{\"authorId\":\"1521935487\",\"name\":\"Feng Wu\"}],\"doi\":\"10.1109/TMM.2020.2972168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1016eb1f2517418e48727417e14590f04eb8a96\",\"title\":\"Adversarial Attribute-Text Embedding for Person Search With Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/c1016eb1f2517418e48727417e14590f04eb8a96\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121961512\",\"name\":\"Yi-Ling Wu\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"2847159\",\"name\":\"Guoli Song\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3343031.3350940\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1830b5c741aa93b417e15ca1e26e56dfe83d3ce9\",\"title\":\"Learning Fragment Self-Attention Embeddings for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/1830b5c741aa93b417e15ca1e26e56dfe83d3ce9\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35376394\",\"name\":\"Martin Engilberge\"},{\"authorId\":\"65814201\",\"name\":\"L. Chevallier\"},{\"authorId\":\"1799777\",\"name\":\"P. Perez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"662431c0876fd54adc7bbe3c7858d9e412e4f56a\",\"title\":\"Deep semantic-visual embedding with localization\",\"url\":\"https://www.semanticscholar.org/paper/662431c0876fd54adc7bbe3c7858d9e412e4f56a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1612.03628\",\"authors\":[{\"authorId\":\"38950290\",\"name\":\"Marc Bola\\u00f1os\"},{\"authorId\":\"2853157\",\"name\":\"\\u00c1lvaro Peris\"},{\"authorId\":\"1696761\",\"name\":\"F. Casacuberta\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"}],\"doi\":\"10.1007/978-3-319-58838-4_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9af9fa7727df11b86301a252db8a916c3a516a8d\",\"title\":\"VIBIKNet: Visual Bidirectional Kernelized Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/9af9fa7727df11b86301a252db8a916c3a516a8d\",\"venue\":\"IbPRIA\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"71876111\",\"name\":\"Chengqin Ye\"},{\"authorId\":\"48691506\",\"name\":\"Shanzhuo Zhang\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"},{\"authorId\":\"1711542\",\"name\":\"Kuanquan Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2961410\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71ebe13ec445c0522463de6f45f6d6747d68b934\",\"title\":\"Improving Whole-Heart CT Image Segmentation by Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/71ebe13ec445c0522463de6f45f6d6747d68b934\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1708.03619\",\"authors\":[{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"50812077\",\"name\":\"J. Yu\"},{\"authorId\":\"24071345\",\"name\":\"Chenchao Xiang\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/TNNLS.2018.2817340\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c0f41d3162e76500d4639557ff4463bd246e395\",\"title\":\"Beyond Bilinear: Generalized Multimodal Factorized High-Order Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0c0f41d3162e76500d4639557ff4463bd246e395\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2018},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.06420\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"39298199\",\"name\":\"Li Niu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00750\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"724b253a55e86ad230ba05c7eb78f249e09258d9\",\"title\":\"Look, Imagine and Match: Improving Textual-Visual Cross-Modal Retrieval with Generative Models\",\"url\":\"https://www.semanticscholar.org/paper/724b253a55e86ad230ba05c7eb78f249e09258d9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"4909159\",\"name\":\"J. Wu\"},{\"authorId\":\"3025397\",\"name\":\"K. Hoashi\"}],\"doi\":\"10.1145/3340555.3355720\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f784ca9a654948de60343c667a4ba1b25fb66e3b\",\"title\":\"Multi-Attention Fusion Network for Video-based Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f784ca9a654948de60343c667a4ba1b25fb66e3b\",\"venue\":\"ICMI '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3206025.3206064\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dbca9da6a72ba3739813288b677888a6cf76272\",\"title\":\"Learning Joint Embedding with Multimodal Cues for Cross-Modal Video-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9dbca9da6a72ba3739813288b677888a6cf76272\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":\"1809.01943\",\"authors\":[{\"authorId\":\"49483501\",\"name\":\"Yiqun Yao\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"47939010\",\"name\":\"Feng Wang\"},{\"authorId\":\"49821282\",\"name\":\"Bo Xu\"}],\"doi\":\"10.18653/v1/D18-1118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"64c4d52c783425a501ce69eb34eccace4f257419\",\"title\":\"Cascaded Mutual Modulation for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/64c4d52c783425a501ce69eb34eccace4f257419\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2001.03712\",\"authors\":[{\"authorId\":\"1435907961\",\"name\":\"Geondo Park\"},{\"authorId\":\"3472799\",\"name\":\"Chihye Han\"},{\"authorId\":\"2570901\",\"name\":\"W. Yoon\"},{\"authorId\":\"30595492\",\"name\":\"Dae-Shik Kim\"}],\"doi\":\"10.1109/WACV45572.2020.9093548\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af60c7ea01a5fc0ff48bfbf3dd8b3bf69f86ff48\",\"title\":\"MHSAN: Multi-Head Self-Attention Network for Visual Semantic Embedding\",\"url\":\"https://www.semanticscholar.org/paper/af60c7ea01a5fc0ff48bfbf3dd8b3bf69f86ff48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117133855\",\"name\":\"Hossein Rajaby Faghihi\"},{\"authorId\":\"1805995461\",\"name\":\"Roshanak Mirzaee\"},{\"authorId\":\"1805991829\",\"name\":\"Sudarshan Paliwal\"},{\"authorId\":\"2190934\",\"name\":\"Parisa Kordjamshidi\"}],\"doi\":\"10.18653/v1/2020.alvr-1.5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93614a127d125b0c3a4dca5be5c4af20539313d4\",\"title\":\"Latent Alignment of Procedural Concepts in Multimodal Recipes\",\"url\":\"https://www.semanticscholar.org/paper/93614a127d125b0c3a4dca5be5c4af20539313d4\",\"venue\":\"ALVR\",\"year\":2020},{\"arxivId\":\"2010.11550\",\"authors\":[{\"authorId\":\"1453661830\",\"name\":\"Keyu Wen\"},{\"authorId\":\"1649999106\",\"name\":\"Xiaodong Gu\"},{\"authorId\":\"48561436\",\"name\":\"Q. Cheng\"}],\"doi\":\"10.1109/TCSVT.2020.3030656\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2740a2308d9f9b867cd54cdf04da82c82c417481\",\"title\":\"Learning Dual Semantic Relations with Graph Attention for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2740a2308d9f9b867cd54cdf04da82c82c417481\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1806.00523\",\"authors\":[{\"authorId\":\"31352445\",\"name\":\"Kashyap Chitta\"}],\"doi\":\"10.1007/978-3-030-11018-5_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"title\":\"Targeted Kernel Networks: Faster Convolutions with Attentive Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2007.15103\",\"authors\":[{\"authorId\":\"47172737\",\"name\":\"A. Sain\"},{\"authorId\":\"3046649\",\"name\":\"A. Bhunia\"},{\"authorId\":\"2653152\",\"name\":\"Yongxin Yang\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c78094362d566c3411dc7b7dcbd70b4527bcc974\",\"title\":\"Cross-Modal Hierarchical Modelling for Fine-Grained Sketch Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c78094362d566c3411dc7b7dcbd70b4527bcc974\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03669\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58601-0_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"title\":\"Adaptive Offline Quintuplet Loss for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50987563\",\"name\":\"Sangmin Park\"},{\"authorId\":\"97243906\",\"name\":\"Young-gab Kim\"}],\"doi\":\"10.1016/j.inffus.2020.10.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65dc69953ef141871f1701d68196aa278566fc16\",\"title\":\"Survey and challenges of story generation models - A multimodal perspective with five steps: Data embedding, topic modeling, storyline generation, draft story generation, and story evaluation\",\"url\":\"https://www.semanticscholar.org/paper/65dc69953ef141871f1701d68196aa278566fc16\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"1811.00692\",\"authors\":[{\"authorId\":\"48513197\",\"name\":\"Y. Li\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"},{\"authorId\":null,\"name\":\"Jianyu Wang\"},{\"authorId\":\"47210419\",\"name\":\"Wei Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"09fb53961e9a4e3c172c3e3b726ebf94961528e1\",\"title\":\"Zero-Shot Transfer VQA Dataset\",\"url\":\"https://www.semanticscholar.org/paper/09fb53961e9a4e3c172c3e3b726ebf94961528e1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"58f5a58e715afad8499d90c4855824c6967dbf39\",\"title\":\"Learning Visually Grounded and Multilingual Representations\",\"url\":\"https://www.semanticscholar.org/paper/58f5a58e715afad8499d90c4855824c6967dbf39\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47166189\",\"name\":\"Xiaojing Yu\"},{\"authorId\":\"2648459\",\"name\":\"Tianlong Chen\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1516504563\",\"name\":\"M. Mugo\"},{\"authorId\":\"2969311\",\"name\":\"Zhangyang Wang\"}],\"doi\":\"10.1109/ICCVW.2019.00223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5522c0d74d37ee5e0bca6aae9026cb5994bf7a7d\",\"title\":\"Cross-Modal Person Search: A Coarse-to-Fine Framework using Bi-Directional Text-Image Matching\",\"url\":\"https://www.semanticscholar.org/paper/5522c0d74d37ee5e0bca6aae9026cb5994bf7a7d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Guohao Li\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3350922\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"title\":\"Perceptual Visual Reasoning with Knowledge Propagation\",\"url\":\"https://www.semanticscholar.org/paper/35074d64a1d70172cab24a1343ae08ea3c078ce2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2397961\",\"name\":\"Qiyue Yin\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"50425438\",\"name\":\"S. Wu\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1007/978-981-10-7302-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1c54b6e34e10b7bb74a6811091822f1daf9426a\",\"title\":\"Learning Shared and Specific Factors for Multi-modal Data\",\"url\":\"https://www.semanticscholar.org/paper/f1c54b6e34e10b7bb74a6811091822f1daf9426a\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1709.08203\",\"authors\":[{\"authorId\":\"7351931\",\"name\":\"Supriya Pandhre\"},{\"authorId\":\"2462516\",\"name\":\"Shagun Sodhani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0e23229289b1fbea14bc425718bc0a227d100b8e\",\"title\":\"Survey of Recent Advances in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0e23229289b1fbea14bc425718bc0a227d100b8e\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1907.00661\",\"authors\":[{\"authorId\":\"32185652\",\"name\":\"Yusuke Yamaura\"},{\"authorId\":\"150246288\",\"name\":\"Nobuya Kanemaki\"},{\"authorId\":\"3184895\",\"name\":\"Yukihiro Tsuboshita\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"75952cb7d5945d001d0758a994eb8017ddca3733\",\"title\":\"The Resale Price Prediction of Secondhand Jewelry Items Using a Multi-modal Deep Model with Iterative Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/75952cb7d5945d001d0758a994eb8017ddca3733\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Dan Shiebler Drew Linsley\"},{\"authorId\":\"35664095\",\"name\":\"S. Eberhardt\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a23fe7786f969de21be8541e87259a4d0807a47\",\"title\":\"L EARNING WHAT AND WHERE TO ATTEND\",\"url\":\"https://www.semanticscholar.org/paper/8a23fe7786f969de21be8541e87259a4d0807a47\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.13516\",\"authors\":[{\"authorId\":\"2389866\",\"name\":\"Yao Wan\"},{\"authorId\":\"1380223985\",\"name\":\"Jingdong Shu\"},{\"authorId\":\"34296085\",\"name\":\"Yulei Sui\"},{\"authorId\":\"1747560\",\"name\":\"Guandong Xu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"97569165\",\"name\":\"Jian Wu\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":\"10.1109/ASE.2019.00012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0998353a6a342143c08e152650c0146adc61d94b\",\"title\":\"Multi-modal Attention Network Learning for Semantic Source Code Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/0998353a6a342143c08e152650c0146adc61d94b\",\"venue\":\"2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE)\",\"year\":2019},{\"arxivId\":\"2012.08939\",\"authors\":[{\"authorId\":\"70171830\",\"name\":\"D. Kothandaraman\"},{\"authorId\":\"1562037323\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"624f723d3b830fbb6d0118743006295b9acb2e92\",\"title\":\"SAfE: Self-Attention Based Unsupervised Road Safety Classification in Hazardous Environments\",\"url\":\"https://www.semanticscholar.org/paper/624f723d3b830fbb6d0118743006295b9acb2e92\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1908.06327\",\"authors\":[{\"authorId\":\"38727845\",\"name\":\"A. Burns\"},{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":\"10.1109/ICCV.2019.00757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71634edd80ce000b3d1e462137fcfa8c2b377943\",\"title\":\"Language Features Matter: Effective Language Representations for Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/71634edd80ce000b3d1e462137fcfa8c2b377943\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1698967708\",\"name\":\"Y. Ma\"},{\"authorId\":\"2985328\",\"name\":\"Yulan Guo\"},{\"authorId\":\"11937782\",\"name\":\"Huapeng Liu\"},{\"authorId\":\"46359335\",\"name\":\"Y. Lei\"},{\"authorId\":\"2602650\",\"name\":\"Gong-Jian Wen\"}],\"doi\":\"10.1109/WACV45572.2020.9093411\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a3e402a5e24aa96f0fa8318d74a2c5e823fdea1\",\"title\":\"Global Context Reasoning for Semantic Segmentation of 3D Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/6a3e402a5e24aa96f0fa8318d74a2c5e823fdea1\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2006.00923\",\"authors\":[{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"134682605\",\"name\":\"Ruben Tito\"},{\"authorId\":\"51238351\",\"name\":\"Andr\\u00e9s Mafla\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16fd23b6c6661cfba01c3b9624e6a2617e45bee9\",\"title\":\"Multimodal grid features and cell pointers for Scene Text Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/16fd23b6c6661cfba01c3b9624e6a2617e45bee9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1708.01988\",\"authors\":[{\"authorId\":\"2944920\",\"name\":\"Shaomeng Li\"},{\"authorId\":null,\"name\":\"Tong Xiao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"47718789\",\"name\":\"Wei Yang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.209\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f222282574666658dc0408176805cbe21348477d\",\"title\":\"Identity-Aware Textual-Visual Matching with Latent Co-attention\",\"url\":\"https://www.semanticscholar.org/paper/f222282574666658dc0408176805cbe21348477d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90972764\",\"name\":\"Jianan Chen\"},{\"authorId\":\"47058808\",\"name\":\"L. Zhang\"},{\"authorId\":\"151495118\",\"name\":\"Cong Bai\"},{\"authorId\":\"1748777\",\"name\":\"K. Kpalma\"}],\"doi\":\"10.1109/MIPR49039.2020.00042\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c8b4be88ae38f1e7d035b808e351650d3de7435c\",\"title\":\"Review of Recent Deep Learning Based Methods for Image-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c8b4be88ae38f1e7d035b808e351650d3de7435c\",\"venue\":\"2020 IEEE Conference on Multimedia Information Processing and Retrieval (MIPR)\",\"year\":2020},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1997177\",\"name\":\"Ercheng Pei\"},{\"authorId\":\"153763368\",\"name\":\"Dong-mei Jiang\"},{\"authorId\":\"151486921\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1016/j.neucom.2019.09.037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"817f717412614675aee6e7e0e3e25af68a0b1219\",\"title\":\"An efficient model-level fusion approach for continuous affect recognition from audiovisual signals\",\"url\":\"https://www.semanticscholar.org/paper/817f717412614675aee6e7e0e3e25af68a0b1219\",\"venue\":\"Neurocomputing\",\"year\":2020}],\"corpusId\":945386,\"doi\":\"10.1109/CVPR.2017.232\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":38,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"references\":[{\"arxivId\":\"1511.02799\",\"authors\":[{\"authorId\":\"2112400\",\"name\":\"Jacob Andreas\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"38666915\",\"name\":\"D. Klein\"}],\"doi\":\"10.1109/CVPR.2016.12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"title\":\"Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/21c99706bb26e9012bfb4d8d48009a3d45af59b2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.07285\",\"authors\":[{\"authorId\":\"31910999\",\"name\":\"A. Kumar\"},{\"authorId\":\"2329943\",\"name\":\"Ozan Irsoy\"},{\"authorId\":\"3214791\",\"name\":\"Peter Ondruska\"},{\"authorId\":\"2136562\",\"name\":\"Mohit Iyyer\"},{\"authorId\":\"34963602\",\"name\":\"J. Bradbury\"},{\"authorId\":\"2708454\",\"name\":\"Ishaan Gulrajani\"},{\"authorId\":\"3428769\",\"name\":\"Victor Zhong\"},{\"authorId\":\"2896063\",\"name\":\"Romain Paulus\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"452059171226626718eb677358836328f884298e\",\"title\":\"Ask Me Anything: Dynamic Memory Networks for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/452059171226626718eb677358836328f884298e\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1109/CVPR.2015.7299073\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"51239b320c73f3f2219286bf62f24d6763379328\",\"title\":\"Associating neural word embeddings with deep image representations using Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/51239b320c73f3f2219286bf62f24d6763379328\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1505.04870\",\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/s11263-016-0965-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612745dbd292fc0a548a16d39cd73e127faedde\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/0612745dbd292fc0a548a16d39cd73e127faedde\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.5679\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2319608\",\"name\":\"Armand Joulin\"},{\"authorId\":\"153196308\",\"name\":\"F. Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"title\":\"Deep Fragment Embeddings for Bidirectional Image Sentence Mapping\",\"url\":\"https://www.semanticscholar.org/paper/7f1b111f0bb703b0bd97aba505728a9b0d9b2a54\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1504.06063\",\"authors\":[{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"11955007\",\"name\":\"Z. Lu\"},{\"authorId\":\"50812138\",\"name\":\"L. Shang\"},{\"authorId\":\"49404233\",\"name\":\"Hang Li\"}],\"doi\":\"10.1109/ICCV.2015.301\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"153d6feb7149e063b33e8ee437b74e4a2def8057\",\"title\":\"Multimodal Convolutional Neural Networks for Matching Image and Sentence\",\"url\":\"https://www.semanticscholar.org/paper/153d6feb7149e063b33e8ee437b74e4a2def8057\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1509.00685\",\"authors\":[{\"authorId\":\"2531268\",\"name\":\"Alexander M. Rush\"},{\"authorId\":\"3295092\",\"name\":\"S. Chopra\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.18653/v1/D15-1044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5082a1a13daea5c7026706738f8528391a1e6d59\",\"title\":\"A Neural Attention Model for Abstractive Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/5082a1a13daea5c7026706738f8528391a1e6d59\",\"venue\":\"EMNLP\",\"year\":2015},{\"arxivId\":\"1606.03647\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b58e08741fb9803fa2a870eee139137d3bade332\",\"title\":\"Training Recurrent Answering Units with Joint Loss Minimization for VQA\",\"url\":\"https://www.semanticscholar.org/paper/b58e08741fb9803fa2a870eee139137d3bade332\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1613/jair.3994\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"title\":\"Framing Image Description as a Ranking Task: Data, Models and Evaluation Metrics (Extended Abstract)\",\"url\":\"https://www.semanticscholar.org/paper/9814df8bd00ba999c4d1e305a7e9bca579dc7c75\",\"venue\":\"IJCAI\",\"year\":2013},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"J Andreas\"},{\"authorId\":null,\"name\":\"M Rohrbach\"},{\"authorId\":null,\"name\":\"T Darrell\"},{\"authorId\":null,\"name\":\"D Klein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Neural module networks. In CVPR\",\"url\":\"\",\"venue\":\"Neural module networks. In CVPR\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.6247\",\"authors\":[{\"authorId\":\"3255983\",\"name\":\"V. Mnih\"},{\"authorId\":\"2801204\",\"name\":\"N. Heess\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"2645384\",\"name\":\"K. Kavukcuoglu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a756d4d25511d92a45d0f4545fa819de993851d\",\"title\":\"Recurrent Models of Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/8a756d4d25511d92a45d0f4545fa819de993851d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144535340\",\"name\":\"Fei Yan\"},{\"authorId\":\"1712041\",\"name\":\"K. Mikolajczyk\"}],\"doi\":\"10.1109/CVPR.2015.7298966\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"title\":\"Deep correlation for matching images and text\",\"url\":\"https://www.semanticscholar.org/paper/efb0e69bc640171d1f115bb286d865bec6f21a7f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.02167\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"2265067\",\"name\":\"Sainbayar Sukhbaatar\"},{\"authorId\":\"3149531\",\"name\":\"Arthur Szlam\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"title\":\"Simple Baseline for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/267fb4ac632449dbe84f7acf17c8c7527cb25b0d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"2133220\",\"name\":\"C. Cervantes\"},{\"authorId\":\"145507543\",\"name\":\"Juan C. Caicedo\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/ICCV.2015.303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"title\":\"Flickr30k Entities: Collecting Region-to-Phrase Correspondences for Richer Image-to-Sentence Models\",\"url\":\"https://www.semanticscholar.org/paper/11c9c31dff70de92ada9160c78ff8bb46b2912d6\",\"venue\":\"ICCV\",\"year\":2015},{\"arxivId\":\"1502.04623\",\"authors\":[{\"authorId\":\"144717963\",\"name\":\"K. Gregor\"},{\"authorId\":\"1841008\",\"name\":\"Ivo Danihelka\"},{\"authorId\":\"1753223\",\"name\":\"A. Graves\"},{\"authorId\":\"1748523\",\"name\":\"Danilo Jimenez Rezende\"},{\"authorId\":\"1688276\",\"name\":\"Daan Wierstra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"title\":\"DRAW: A Recurrent Neural Network For Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/a2785f66c20fbdf30ec26c0931584c6d6a0f4fca\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.06078\",\"authors\":[{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1109/CVPR.2016.541\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b27e791e843c924ef052981b79490ab59fc0433d\",\"title\":\"Learning Deep Structure-Preserving Image-Text Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/b27e791e843c924ef052981b79490ab59fc0433d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.01455\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"3226948\",\"name\":\"Sang-Woo Lee\"},{\"authorId\":\"3422869\",\"name\":\"Dong-Hyun Kwak\"},{\"authorId\":\"2939188\",\"name\":\"Min-Oh Heo\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"title\":\"Multimodal Residual Learning for Visual QA\",\"url\":\"https://www.semanticscholar.org/paper/1afb710a5b35a2352a6495e4bf6eef66808daf1b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1506.01057\",\"authors\":[{\"authorId\":\"5183779\",\"name\":\"J. Li\"},{\"authorId\":\"1707242\",\"name\":\"Minh-Thang Luong\"},{\"authorId\":\"1746807\",\"name\":\"Dan Jurafsky\"}],\"doi\":\"10.3115/v1/P15-1107\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b21c78a62fbb945a19ae9a8935933711647e7d70\",\"title\":\"A Hierarchical Neural Autoencoder for Paragraphs and Documents\",\"url\":\"https://www.semanticscholar.org/paper/b21c78a62fbb945a19ae9a8935933711647e7d70\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1407.3068\",\"authors\":[{\"authorId\":\"1997185\",\"name\":\"M. Stollenga\"},{\"authorId\":\"2426718\",\"name\":\"J. Masci\"},{\"authorId\":\"145842938\",\"name\":\"F. Gomez\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70155488a49d51755c1dfea728e03a6dd72703a1\",\"title\":\"Deep Networks with Internal Selective Attention through Feedback Connections\",\"url\":\"https://www.semanticscholar.org/paper/70155488a49d51755c1dfea728e03a6dd72703a1\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1511.04164\",\"authors\":[{\"authorId\":\"2874347\",\"name\":\"Ronghang Hu\"},{\"authorId\":\"3286703\",\"name\":\"Huazhe Xu\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.493\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d696a1923288e6c15422660de9553f6fdb6a4fae\",\"title\":\"Natural Language Object Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d696a1923288e6c15422660de9553f6fdb6a4fae\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Multimodal interaction\",\"topicId\":\"42592\",\"url\":\"https://www.semanticscholar.org/topic/42592\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"