"{\"abstract\":\"Inspired by the recent success of text-based question answering, visual question answering (VQA) is proposed to automatically answer natural language questions with the reference to a given image. Compared with text-based QA, VQA is more challenging because the reasoning process on visual domain needs both effective semantic embedding and fine-grained visual understanding. Existing approaches predominantly infer answers from the abstract low-level visual features, while neglecting the modeling of high-level image semantics and the rich spatial context of regions. To solve the challenges, we propose a multi-level attention network for visual question answering that can simultaneously reduce the semantic gap by semantic attention and benefit fine-grained spatial inference by visual attention. First, we generate semantic concepts from high-level semantics in convolutional neural networks (CNN) and select those question-related concepts as semantic attention. Second, we encode region-based middle-level outputs from CNN into spatially-embedded representation by a bidirectional recurrent neural network, and further pinpoint the answer-related regions by multiple layer perceptron as visual attention. Third, we jointly optimize semantic attention, visual attention and question embedding by a softmax classifier to infer the final answer. Extensive experiments show the proposed approach outperforms the-state-of-arts on two challenging VQA datasets.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\",\"url\":\"https://www.semanticscholar.org/author/2846025\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\",\"url\":\"https://www.semanticscholar.org/author/3247966\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\",\"url\":\"https://www.semanticscholar.org/author/144025741\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\",\"url\":\"https://www.semanticscholar.org/author/145459057\"}],\"citationVelocity\":43,\"citations\":[{\"arxivId\":\"2001.06354\",\"authors\":[{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"47300698\",\"name\":\"Hao Tan\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1609/AAAI.V34I05.6320\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0cad92e34323aa135d13d692c759246a8da54d05\",\"title\":\"Modality-Balanced Models for Visual Dialogue\",\"url\":\"https://www.semanticscholar.org/paper/0cad92e34323aa135d13d692c759246a8da54d05\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"27329137\",\"name\":\"Jiatong Zhou\"}],\"doi\":\"10.1109/CVPR.2018.00118\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"135c71101af5d030f8cf470c454e7b655d699920\",\"title\":\"Stacked Latent Attention for Multimodal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/135c71101af5d030f8cf470c454e7b655d699920\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1905.12243\",\"authors\":[{\"authorId\":\"50080046\",\"name\":\"Xuelong Li\"},{\"authorId\":\"12122088\",\"name\":\"Aihong Yuan\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TCYB.2019.2914351\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"title\":\"Vision-to-Language Tasks Based on Attributes and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/e5f46d314bcdbe55183cbe7e0852887c148eb807\",\"venue\":\"IEEE transactions on cybernetics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1801.04334\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2018.00943\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b1b2402dcd85b81381fde40d0b971b510471ef23\",\"title\":\"TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays\",\"url\":\"https://www.semanticscholar.org/paper/b1b2402dcd85b81381fde40d0b971b510471ef23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735739\",\"name\":\"Weifeng Zhang\"},{\"authorId\":\"119883573\",\"name\":\"J. Yu\"},{\"authorId\":\"47864783\",\"name\":\"H. Hu\"},{\"authorId\":\"144645443\",\"name\":\"H. Hu\"},{\"authorId\":\"70565757\",\"name\":\"Zengchang Qin\"}],\"doi\":\"10.1016/J.INFFUS.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"title\":\"Multimodal feature fusion by relational reasoning and attention for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/04afa0417dc2a4555c15243a69e6a54ce44ecf63\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":\"1910.04964\",\"authors\":[{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"},{\"authorId\":\"72541452\",\"name\":\"X. Wang\"},{\"authorId\":\"1786871\",\"name\":\"Hongzhi Li\"}],\"doi\":\"10.1109/TCSVT.2019.2940647\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"title\":\"Multi-Modal Deep Analysis for Multimedia\",\"url\":\"https://www.semanticscholar.org/paper/3d92574b3eb8a90736afb0d6a56f581eee79bdea\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"}],\"doi\":\"10.7282/T3-KA2Q-B984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b198f5cb09446433a8d3a181107f408d26d5a34\",\"title\":\"Scene graph parsing and its application in cross-modal reasoning tasks\",\"url\":\"https://www.semanticscholar.org/paper/7b198f5cb09446433a8d3a181107f408d26d5a34\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9323684\",\"name\":\"J. Hu\"},{\"authorId\":\"9258873\",\"name\":\"Wendong Zheng\"}],\"doi\":\"10.1016/j.neucom.2019.11.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9db76d1b57cd330f4461e73e942bc817277ab525\",\"title\":\"Multistage attention network for multivariate time series prediction\",\"url\":\"https://www.semanticscholar.org/paper/9db76d1b57cd330f4461e73e942bc817277ab525\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1911.06531\",\"authors\":[{\"authorId\":\"1860829\",\"name\":\"Yunfan Liu\"},{\"authorId\":\"48934313\",\"name\":\"Q. Li\"},{\"authorId\":\"1757186\",\"name\":\"Z. Sun\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1103611cb1c6172333221916b55da73147ca9228\",\"title\":\"A3GAN: An Attribute-aware Attentive Generative Adversarial Network for Face Aging\",\"url\":\"https://www.semanticscholar.org/paper/1103611cb1c6172333221916b55da73147ca9228\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1956364176\",\"name\":\"G. Chen\"},{\"authorId\":\"50201675\",\"name\":\"Shiqing Zhang\"},{\"authorId\":\"37983219\",\"name\":\"X. Tao\"},{\"authorId\":\"48551029\",\"name\":\"Xiaoming Zhao\"}],\"doi\":\"10.1109/ACCESS.2020.3038493\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4e4e1a7953a0b21eafd61e669cbb35fbba92771\",\"title\":\"Speech Emotion Recognition by Combining a Unified First-Order Attention Network With Data Balance\",\"url\":\"https://www.semanticscholar.org/paper/e4e4e1a7953a0b21eafd61e669cbb35fbba92771\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1909.11874\",\"authors\":[{\"authorId\":\"52220768\",\"name\":\"T. Do\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"134083550\",\"name\":\"Huy Tran\"},{\"authorId\":\"1387964524\",\"name\":\"Erman Tjiputra\"},{\"authorId\":\"20135953\",\"name\":\"Q. D. Tran\"}],\"doi\":\"10.1109/ICCV.2019.00048\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"title\":\"Compact Trilinear Interaction for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/27cb0b42e0573c4891ae2ca444776dee57bfe2ac\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007920878\",\"name\":\"Walead Kaled Sleaman\"},{\"authorId\":\"2684904\",\"name\":\"S. Yavuz\"}],\"doi\":\"10.3233/jifs-189030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d94fd570dcb655e3a4a95651394068e67c9b3229\",\"title\":\"Indoor mobile robot navigation using deep convolutional neural network\",\"url\":\"https://www.semanticscholar.org/paper/d94fd570dcb655e3a4a95651394068e67c9b3229\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2020},{\"arxivId\":\"1909.08153\",\"authors\":[{\"authorId\":\"1571779654\",\"name\":\"Ahmad Khaliq\"},{\"authorId\":\"1490449601\",\"name\":\"Shoaib Ehsan\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1389942491\",\"name\":\"K. McDonald-Maier\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"94e6a044d9cb6a4f5cbfe134e741dc426d388cc9\",\"title\":\"CAMAL: Context-Aware Multi-layer Attention framework for Lightweight Environment Invariant Visual Place Recognition.\",\"url\":\"https://www.semanticscholar.org/paper/94e6a044d9cb6a4f5cbfe134e741dc426d388cc9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1608.03410\",\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.5244/C.30.77\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"title\":\"Solving VIsual Madlibs with Multiple Cues\",\"url\":\"https://www.semanticscholar.org/paper/95f0125e6dda6c0028e09e814a7aaae5ef4922a4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"46172451\",\"name\":\"B. Wang\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"32996440\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2897604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb2f25b32344888d644dc3a3e729275a8abee07a\",\"title\":\"Movie Question Answering via Textual Memory and Plot Graph\",\"url\":\"https://www.semanticscholar.org/paper/cb2f25b32344888d644dc3a3e729275a8abee07a\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314205\",\"name\":\"Zhong Qian\"},{\"authorId\":\"47470867\",\"name\":\"Peifeng Li\"},{\"authorId\":\"7703092\",\"name\":\"Qiaoming Zhu\"},{\"authorId\":\"143740945\",\"name\":\"Guodong Zhou\"}],\"doi\":\"10.18653/v1/N19-1287\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7267bb5901a9b6662e90899dcecc816105a5ce50\",\"title\":\"Document-Level Event Factuality Identification via Adversarial Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/7267bb5901a9b6662e90899dcecc816105a5ce50\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144689860\",\"name\":\"Wei Deng\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"},{\"authorId\":\"2690741\",\"name\":\"Shengbei Wang\"},{\"authorId\":\"1809607\",\"name\":\"G. Jin\"}],\"doi\":\"10.1145/3278198.3278207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09f1980e370fd5f4e1974baf7b943d26971ea219\",\"title\":\"Flexible Sentence Analysis Model for Visual Question Answering Network\",\"url\":\"https://www.semanticscholar.org/paper/09f1980e370fd5f4e1974baf7b943d26971ea219\",\"venue\":\"ICBEB 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151496750\",\"name\":\"Surgan Jandial\"},{\"authorId\":\"9551558\",\"name\":\"Ayush Chopra\"},{\"authorId\":\"10357841\",\"name\":\"Pinkesh Badjatiya\"},{\"authorId\":\"1946040746\",\"name\":\"Pranit Chawla\"},{\"authorId\":\"39230373\",\"name\":\"Mausoom Sarkar\"},{\"authorId\":\"1557631185\",\"name\":\"Balaji Krishnamurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dcf55ad1e7b3b59c72159a51806cee543fbd6574\",\"title\":\"TRACE: Transform Aggregate and Compose Visiolinguistic Representations for Image Search with Text Feedback\",\"url\":\"https://www.semanticscholar.org/paper/dcf55ad1e7b3b59c72159a51806cee543fbd6574\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"151423308\",\"name\":\"Qirong Mao\"},{\"authorId\":\"3309006\",\"name\":\"Heping Song\"},{\"authorId\":\"153719921\",\"name\":\"H. Jia\"},{\"authorId\":\"1384379379\",\"name\":\"Ming Dong\"}],\"doi\":\"10.1016/j.cviu.2019.102829\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9572e232d33aba1b765ef90924d8662707cc2a01\",\"title\":\"Triple attention network for sentimental visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/9572e232d33aba1b765ef90924d8662707cc2a01\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3126238\",\"name\":\"Shuzhe Wu\"},{\"authorId\":\"1693589\",\"name\":\"M. Kan\"},{\"authorId\":\"145455919\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/s11263-019-01157-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8a4201641a541babfefe66851a1d06b0d3b3a5b\",\"title\":\"Hierarchical Attention for Part-Aware Face Detection\",\"url\":\"https://www.semanticscholar.org/paper/c8a4201641a541babfefe66851a1d06b0d3b3a5b\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50498297\",\"name\":\"Liang Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"}],\"doi\":\"10.1007/s11042-018-6389-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"713dd629c183056202f31c2a98e5e37e0d83efa4\",\"title\":\"Word-to-region attention network for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/713dd629c183056202f31c2a98e5e37e0d83efa4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2552746\",\"name\":\"L. Zhang\"},{\"authorId\":\"144625807\",\"name\":\"V. Singh\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1846624\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/WACV.2019.00017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"941f459f674a5ebc05c9570a3cd97dc80d2ef203\",\"title\":\"Cascade Attention Machine for Occluded Landmark Detection in 2D X-Ray Angiography\",\"url\":\"https://www.semanticscholar.org/paper/941f459f674a5ebc05c9570a3cd97dc80d2ef203\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1911.07623\",\"authors\":[{\"authorId\":\"30322058\",\"name\":\"Md. Jahidul Islam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"163128fbc0178369224fd2aa0bbe103140cb1f80\",\"title\":\"Machine Vision for Improved Human-Robot Cooperation in Adverse Underwater Conditions\",\"url\":\"https://www.semanticscholar.org/paper/163128fbc0178369224fd2aa0bbe103140cb1f80\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1707.09700\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"48884894\",\"name\":\"K. Wang\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/ICCV.2017.142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf2de559e5a6235783e0762862f6e42192f142a8\",\"title\":\"Scene Graph Generation from Objects, Phrases and Region Captions\",\"url\":\"https://www.semanticscholar.org/paper/cf2de559e5a6235783e0762862f6e42192f142a8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121704393\",\"name\":\"Yanan Li\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"13fbe1c9ab92b2941a9fb4f2854d595aaea0dc13\",\"title\":\"Joint Learning of Attended Zero-Shot Features and Visual-Semantic Mapping\",\"url\":\"https://www.semanticscholar.org/paper/13fbe1c9ab92b2941a9fb4f2854d595aaea0dc13\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1909.07583\",\"authors\":[{\"authorId\":\"1388780256\",\"name\":\"Yaser Alwatter\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"}],\"doi\":\"10.22215/etd/2019-13929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48795928eb87d1e8a038063b3aebee180e424d04\",\"title\":\"Inverse Visual Question Answering with Multi-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/48795928eb87d1e8a038063b3aebee180e424d04\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":\"2011.06252\",\"authors\":[{\"authorId\":\"30322058\",\"name\":\"Md. Jahidul Islam\"},{\"authorId\":\"1490773142\",\"name\":\"Ruobing Wang\"},{\"authorId\":\"1379508347\",\"name\":\"Karin de Langis\"},{\"authorId\":\"1765604\",\"name\":\"Junaed Sattar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d1f92acc38e39e8c919a85d13f9565b26ee5cee\",\"title\":\"SVAM: Saliency-guided Visual Attention Modeling by Autonomous Underwater Robots\",\"url\":\"https://www.semanticscholar.org/paper/6d1f92acc38e39e8c919a85d13f9565b26ee5cee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.1155/2020/8567271\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3900d795a4914f0e8c346397c3dff4038d41591\",\"title\":\"Visual Experience-Based Question Answering with Complex Multimodal Environments\",\"url\":\"https://www.semanticscholar.org/paper/a3900d795a4914f0e8c346397c3dff4038d41591\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"21148831\",\"name\":\"Zhong Ji\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"102853472\",\"name\":\"Jichang Guo\"},{\"authorId\":\"48278008\",\"name\":\"Yan-Wei Pang\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffbff2edb9994ceac5d7b08d0049424974d20eae\",\"title\":\"CNN Region featuresInput image Guided loss SGA SGA Class semantic features Semantic embedding label Attention features Attention features Embedded loss Softm\",\"url\":\"https://www.semanticscholar.org/paper/ffbff2edb9994ceac5d7b08d0049424974d20eae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1709.07192\",\"authors\":[{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"47353404\",\"name\":\"X. Chu\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2018.00640\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47aff6477f05ec32fc163e1943fe9464a8379552\",\"title\":\"Visual Question Generation as Dual Task of Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47aff6477f05ec32fc163e1943fe9464a8379552\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b09f952de35e1ce98b01e14c2be036430ecace43\",\"title\":\"Exploiting hierarchical visual features for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/b09f952de35e1ce98b01e14c2be036430ecace43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"title\":\"Preserved Knowledge Embedding Question : Why does the person have an umbrella ? Answer : It is raining . Knowledge Incorporated Open-Domain VQA Candidate Knowledge Retrieval Dynamic Memory Network Memory Updating Attention Machanisim Query\",\"url\":\"https://www.semanticscholar.org/paper/db6ad1e242c31c2fbd514cd71df904a8f96fba5f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"2008.08012\",\"authors\":[{\"authorId\":\"9748140\",\"name\":\"K. Gouthaman\"},{\"authorId\":\"3265714\",\"name\":\"A. Nambiar\"},{\"authorId\":\"1882516497\",\"name\":\"Kancheti Sai Srinivas\"},{\"authorId\":\"50853059\",\"name\":\"Anurag Mittal\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"title\":\"Linguistically-aware Attention for Reducing the Semantic-Gap in Vision-Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/b46ce08535c728cc690852a7c63a9bb211ff25ab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.10906\",\"authors\":[{\"authorId\":\"3029956\",\"name\":\"J. Gao\"},{\"authorId\":\"40899706\",\"name\":\"Runzhou Ge\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"}],\"doi\":\"10.1109/CVPR.2018.00688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"title\":\"Motion-Appearance Co-memory Networks for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f45c3a83e5c6276c6655c5df5833ab6b75e17bdf\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152924581\",\"name\":\"Jicheng Wang\"},{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1438588470\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"47957556\",\"name\":\"X. Zhang\"},{\"authorId\":\"31048669\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/s11042-019-08439-7\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c48de74a40736498d6443f84ecdddc08275359f\",\"title\":\"Sequential image encoding for vision-to-language problems\",\"url\":\"https://www.semanticscholar.org/paper/0c48de74a40736498d6443f84ecdddc08275359f\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384259000\",\"name\":\"Muchao Ye\"},{\"authorId\":\"47353599\",\"name\":\"M. Dai\"},{\"authorId\":\"50251617\",\"name\":\"Z. Zhou\"},{\"authorId\":\"19183333\",\"name\":\"Ruzheng Zhao\"}],\"doi\":\"10.23919/ChiCC.2019.8866119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd194a673633fb0e68f8827e172edf62e1c03257\",\"title\":\"Local Statistical Active Contour Energy Functional based on Cauchy-Schwarz Divergence for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/cd194a673633fb0e68f8827e172edf62e1c03257\",\"venue\":\"2019 Chinese Control Conference (CCC)\",\"year\":2019},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145406475\",\"name\":\"R. Ma\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"48094184\",\"name\":\"Jiawen Wang\"},{\"authorId\":\"1732687\",\"name\":\"L. Cui\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.1145/3209978.3210026\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"50f3587a6316ae59493f4c408eadefe3bbf891fe\",\"title\":\"Mention Recommendation for Multimodal Microblog with Cross-attention Memory Network\",\"url\":\"https://www.semanticscholar.org/paper/50f3587a6316ae59493f4c408eadefe3bbf891fe\",\"venue\":\"SIGIR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"46447759\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"2548662\",\"name\":\"X. Tang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/J.ASOC.2019.105584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"title\":\"Visual question answering via Attention-based syntactic structure tree-LSTM\",\"url\":\"https://www.semanticscholar.org/paper/a78477728a184a80cdfcfb97d5023f37961c3b6a\",\"venue\":\"Appl. Soft Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39603708\",\"name\":\"Q. Truong\"},{\"authorId\":\"3309003\",\"name\":\"Hady W. Lauw\"}],\"doi\":\"10.1609/AAAI.V33I01.3301305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09a9c787111c2deb97e5431d490046b887a027b7\",\"title\":\"VistaNet: Visual Aspect Attention Network for Multimodal Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/09a9c787111c2deb97e5431d490046b887a027b7\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51052405\",\"name\":\"H. Liu\"},{\"authorId\":\"32986779\",\"name\":\"Shengrong Gong\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"50356714\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.2991/CMSA-18.2018.80\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"483828a82b26db7761a3a47fadc971b561b53615\",\"title\":\"Multimodal Cross-guided Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/483828a82b26db7761a3a47fadc971b561b53615\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2007.07051\",\"authors\":[{\"authorId\":\"48162270\",\"name\":\"Chongyi Li\"},{\"authorId\":\"3409475\",\"name\":\"Runmin Cong\"},{\"authorId\":\"70520135\",\"name\":\"Yongri Piao\"},{\"authorId\":\"34679664\",\"name\":\"Q. Xu\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/978-3-030-58598-3_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fa59970f27a2d169114cac28be5139fbeac71d02\",\"title\":\"RGB-D Salient Object Detection with Cross-Modality Modulation and Selection\",\"url\":\"https://www.semanticscholar.org/paper/fa59970f27a2d169114cac28be5139fbeac71d02\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"145117690\",\"name\":\"B. Liu\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e18c022c6b7300a920c839fed531c7655353a27d\",\"title\":\"Disentangling for Text-to-Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/e18c022c6b7300a920c839fed531c7655353a27d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.08153\",\"authors\":[{\"authorId\":\"1410397846\",\"name\":\"Ahmad Khaliq\"},{\"authorId\":\"144429572\",\"name\":\"S. Ehsan\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1389942491\",\"name\":\"K. McDonald-Maier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"54e899b59b00541fe6c8e1c2bc2d70a979a3b871\",\"title\":\"CAMAL: Context-Aware Multi-scale Attention framework for Lightweight Visual Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/54e899b59b00541fe6c8e1c2bc2d70a979a3b871\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143645712\",\"name\":\"Y. Yeboah\"},{\"authorId\":\"51520727\",\"name\":\"Cai Yan-guang\"},{\"authorId\":\"145717892\",\"name\":\"Wei Wu\"},{\"authorId\":\"145794027\",\"name\":\"S. He\"}],\"doi\":\"10.1145/3268866.3268886\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae0d16df4a2fd0372be38cfb9d20c1bbeeee88a6\",\"title\":\"Autonomous Indoor Robot Navigation via Siamese Deep Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/ae0d16df4a2fd0372be38cfb9d20c1bbeeee88a6\",\"venue\":\"AIPR 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"1765710\",\"name\":\"Sai Wu\"}],\"doi\":\"10.1016/J.INFFUS.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"91118408f8192c2addade2a0401a32c3bbd47818\",\"title\":\"Information fusion in visual question answering: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/91118408f8192c2addade2a0401a32c3bbd47818\",\"venue\":\"Inf. Fusion\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39771170\",\"name\":\"Andeep S. Toor\"},{\"authorId\":\"143979395\",\"name\":\"H. Wechsler\"},{\"authorId\":\"144759484\",\"name\":\"M. Nappi\"}],\"doi\":\"10.1007/s11042-018-6097-z\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bddf7da5a21a5d1915cc9ee784223adadbe0aec4\",\"title\":\"Question action relevance and editing for visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/bddf7da5a21a5d1915cc9ee784223adadbe0aec4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674186\",\"name\":\"R. Karthik\"},{\"authorId\":\"1916290748\",\"name\":\"Menaka Radhakrishnan\"},{\"authorId\":\"151192185\",\"name\":\"R. Rajalakshmi\"},{\"authorId\":\"1491520719\",\"name\":\"Joel Raymann\"}],\"doi\":\"10.1007/s13534-020-00178-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d314e3c0ef2062b56fcf98f0a61944b0892cb82\",\"title\":\"Delineation of ischemic lesion from brain MRI using attention gated fully convolutional network\",\"url\":\"https://www.semanticscholar.org/paper/4d314e3c0ef2062b56fcf98f0a61944b0892cb82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.07677\",\"authors\":[{\"authorId\":\"143804836\",\"name\":\"Ruibing Hou\"},{\"authorId\":\"145375324\",\"name\":\"H. Chang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5f21bccbc65af943ce4c12c6eee7ae7d7d680a2a\",\"title\":\"Cross Attention Network for Few-shot Classification\",\"url\":\"https://www.semanticscholar.org/paper/5f21bccbc65af943ce4c12c6eee7ae7d7d680a2a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPR.2019.00203\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"80bb60b737b53b23f5eb1f56cd145153d4581330\",\"title\":\"It's Not About the Journey; It's About the Destination: Following Soft Paths Under Question-Guidance for Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/80bb60b737b53b23f5eb1f56cd145153d4581330\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1712.00733\",\"authors\":[{\"authorId\":\"6051714\",\"name\":\"G. Li\"},{\"authorId\":\"144904238\",\"name\":\"H. Su\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23ed7f18100717ba814b2859196e10c5d4fed216\",\"title\":\"Incorporating External Knowledge to Answer Open-Domain Visual Questions with Dynamic Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/23ed7f18100717ba814b2859196e10c5d4fed216\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2008.06597\",\"authors\":[{\"authorId\":\"47773127\",\"name\":\"S. Yuan\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"48378494\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"1807489212\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1af06d2c4a129f9335159db8bb1455414705bed1\",\"title\":\"Weakly supervised cross-domain alignment with optimal transport\",\"url\":\"https://www.semanticscholar.org/paper/1af06d2c4a129f9335159db8bb1455414705bed1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1571779654\",\"name\":\"Ahmad Khaliq\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a65fdef02cffaacab5ed87fde7ddded3a8db85ac\",\"title\":\"Visual Place Recognition under Severe Viewpoint and Appearance Changes\",\"url\":\"https://www.semanticscholar.org/paper/a65fdef02cffaacab5ed87fde7ddded3a8db85ac\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"3261071\",\"name\":\"M. Shah\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":\"10.1109/CVPR.2019.00438\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83f500cc63c446a2c897122008e3d9295cad21bd\",\"title\":\"Pay Attention! - Robustifying a Deep Visuomotor Policy Through Task-Focused Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/83f500cc63c446a2c897122008e3d9295cad21bd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.03032\",\"authors\":[{\"authorId\":\"51179519\",\"name\":\"A. Khaliq\"},{\"authorId\":\"144429572\",\"name\":\"S. Ehsan\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"},{\"authorId\":\"1740803\",\"name\":\"K. McDonald-Maier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28495db7b8a854521cbb4c27b6f0c68460d9718e\",\"title\":\"A Holistic Visual Place Recognition Approach using Lightweight CNNs for Severe ViewPoint and Appearance Changes\",\"url\":\"https://www.semanticscholar.org/paper/28495db7b8a854521cbb4c27b6f0c68460d9718e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"49298718\",\"name\":\"Jie Li\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3321505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"title\":\"Video Question Answering via Knowledge-based Progressive Spatial-Temporal Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/99b722fc4e168eddea69521f26c77e31e56fc9f4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"92790579\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-13969-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50d8da795bd50ebd14c4635116c159354409c9c\",\"title\":\"Automatic Classification and Reporting of Multiple Common Thorax Diseases Using Chest Radiographs\",\"url\":\"https://www.semanticscholar.org/paper/d50d8da795bd50ebd14c4635116c159354409c9c\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034270322\",\"name\":\"Liyana Sahir Kallooriyakath\"},{\"authorId\":\"2034269084\",\"name\":\"Jithin M V\"},{\"authorId\":\"81431088\",\"name\":\"B. V\"},{\"authorId\":\"2034269088\",\"name\":\"Adith P P\"}],\"doi\":\"10.1109/ICSTCEE49637.2020.9277374\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ea0ab46474037363b0a52b758538e61ccb90ecec\",\"title\":\"Visual Question Answering: Methodologies and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/ea0ab46474037363b0a52b758538e61ccb90ecec\",\"venue\":\"2020 International Conference on Smart Technologies in Computing, Electrical and Electronics (ICSTCEE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"}],\"doi\":\"10.1145/3390891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb9fb10f604a196515e48ad90f217d33794f5991\",\"title\":\"Recurrent Attention Network with Reinforced Generator for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cb9fb10f604a196515e48ad90f217d33794f5991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1017/ATSIP.2017.12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2653257faa6d1b718a4cff004f4c7ad66d89c55\",\"title\":\"Advances in deep learning approaches for image tagging\",\"url\":\"https://www.semanticscholar.org/paper/f2653257faa6d1b718a4cff004f4c7ad66d89c55\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1809.04344\",\"authors\":[{\"authorId\":\"51228129\",\"name\":\"Shailza Jolly\"},{\"authorId\":\"3422247\",\"name\":\"Sandro Pezzelle\"},{\"authorId\":\"35660331\",\"name\":\"T. Klein\"},{\"authorId\":\"145279674\",\"name\":\"A. Dengel\"},{\"authorId\":\"1848946\",\"name\":\"Moin Nabi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"610e0bee525a6573932e077f091505f54a5c4ede\",\"title\":\"The Wisdom of MaSSeS: Majority, Subjectivity, and Semantic Similarity in the Evaluation of VQA\",\"url\":\"https://www.semanticscholar.org/paper/610e0bee525a6573932e077f091505f54a5c4ede\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48981982\",\"name\":\"Peizhao Li\"},{\"authorId\":\"6985750\",\"name\":\"Anran Zhang\"},{\"authorId\":\"49693266\",\"name\":\"L. Yue\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"40916581\",\"name\":\"Xianbin Cao\"}],\"doi\":\"10.1109/WACV.2019.00233\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a98056a408d729b620b1a4c148de7005d7777aa2\",\"title\":\"Multi-Scale Aggregation Network for Direct Face Alignment\",\"url\":\"https://www.semanticscholar.org/paper/a98056a408d729b620b1a4c148de7005d7777aa2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47388902\",\"name\":\"T. Gui\"},{\"authorId\":\"145779142\",\"name\":\"Peng Liu\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"144061928\",\"name\":\"L. Zhu\"},{\"authorId\":\"24859244\",\"name\":\"Minlong Peng\"},{\"authorId\":\"2236658\",\"name\":\"Yunhua Zhou\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.1145/3331184.3331237\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d484fc70d805bb622153f3fc66c69418929caf09\",\"title\":\"Mention Recommendation in Twitter with Cooperative Multi-Agent Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/d484fc70d805bb622153f3fc66c69418929caf09\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1810.06859\",\"authors\":[{\"authorId\":\"47666554\",\"name\":\"H. Chen\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"48731103\",\"name\":\"Hideki Nakayama\"}],\"doi\":\"10.1007/978-3-030-20870-7_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5122fe2ece8157ff53870a59c6c842f21d6a8a34\",\"title\":\"Semantic Aware Attention Based Deep Object Co-segmentation\",\"url\":\"https://www.semanticscholar.org/paper/5122fe2ece8157ff53870a59c6c842f21d6a8a34\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240687\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"title\":\"Examine before You Answer: Multi-task Learning with Adaptive-attentions for Multiple-choice VQA\",\"url\":\"https://www.semanticscholar.org/paper/97add9744ae63c5e7af9d9861ecc18a2734d3f0c\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"79927338\",\"name\":\"L. Wang\"},{\"authorId\":\"37233332\",\"name\":\"J. Gou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.046\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"title\":\"Affective question answering on video\",\"url\":\"https://www.semanticscholar.org/paper/1b6ce7e65130431eecf98db2e6c162893bbe5127\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1805.08113\",\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2910007\",\"name\":\"J. Guo\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0694beaf14f558a75f2dc32f64d151e505dbee17\",\"title\":\"Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/0694beaf14f558a75f2dc32f64d151e505dbee17\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1904.01480\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00243\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4308c530613ea437fe8224cc65720adf28b1a589\",\"title\":\"Semantics Disentangling for Text-To-Image Generation\",\"url\":\"https://www.semanticscholar.org/paper/4308c530613ea437fe8224cc65720adf28b1a589\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51021338\",\"name\":\"Nelson Ruwa\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"2054737\",\"name\":\"Liangjun Wang\"},{\"authorId\":\"38978232\",\"name\":\"J. Gou\"},{\"authorId\":\"144964053\",\"name\":\"M. Dong\"}],\"doi\":\"10.1016/j.neucom.2018.11.049\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e3e4954e40f33b503f7fe220be90917124a09c43\",\"title\":\"Mood-aware visual question answering\",\"url\":\"https://www.semanticscholar.org/paper/e3e4954e40f33b503f7fe220be90917124a09c43\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2003.03669\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58601-0_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"title\":\"Adaptive Offline Quintuplet Loss for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"},{\"authorId\":\"1741866\",\"name\":\"H. Li\"},{\"authorId\":\"1706784\",\"name\":\"Fanman Meng\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-01231-1_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"title\":\"Key-Word-Aware Network for Referring Expression Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":\"2004.01241\",\"authors\":[{\"authorId\":\"30322058\",\"name\":\"Md. Jahidul Islam\"},{\"authorId\":\"80746476\",\"name\":\"Chelsey Edge\"},{\"authorId\":\"11633285\",\"name\":\"Yuyang Xiao\"},{\"authorId\":\"1381723743\",\"name\":\"Peigen Luo\"},{\"authorId\":\"1610937294\",\"name\":\"Muntaqim Mehtaz\"},{\"authorId\":\"4268242\",\"name\":\"C. Morse\"},{\"authorId\":\"1387900209\",\"name\":\"Sadman Sakib Enan\"},{\"authorId\":\"1765604\",\"name\":\"Junaed Sattar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f94ca9afc8584c0d7d23364cd7af0e0efeb6e038\",\"title\":\"Semantic Segmentation of Underwater Imagery: Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/f94ca9afc8584c0d7d23364cd7af0e0efeb6e038\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"101266543\",\"name\":\"Shifeng Zhang\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"1774936\",\"name\":\"Siliang Tang\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"153269968\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1016/j.ipm.2020.102265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"title\":\"Video question answering via grounded cross-attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/32589847320c3c783e6eaf512e7723b8d5f5fb0a\",\"venue\":\"Inf. Process. Manag.\",\"year\":2020},{\"arxivId\":\"2012.01211\",\"authors\":[{\"authorId\":\"10025861\",\"name\":\"Chaofeng Chen\"},{\"authorId\":\"2856494\",\"name\":\"Dihong Gong\"},{\"authorId\":\"3705643\",\"name\":\"H. Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":\"10.1109/TIP.2020.3043093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40096a032691b5cd6372be50aefed57f1dd9949c\",\"title\":\"Learning Spatial Attention for Face Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/40096a032691b5cd6372be50aefed57f1dd9949c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2957309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c0acaec480993efb5f882cea44879545dd5687c\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Multi-Modal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1c0acaec480993efb5f882cea44879545dd5687c\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9140474\",\"name\":\"Yan Dan-feng\"},{\"authorId\":\"145920088\",\"name\":\"Wang Jing\"}],\"doi\":\"10.1109/ACCESS.2019.2914239\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e11c62c4e4c77ac41f0b91ec08d2681d43fdd81\",\"title\":\"Subway Passenger Flow Forecasting With Multi-Station and External Factors\",\"url\":\"https://www.semanticscholar.org/paper/2e11c62c4e4c77ac41f0b91ec08d2681d43fdd81\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"97583812\",\"name\":\"J. Yu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.1145/3343031.3351065\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"title\":\"Multi-interaction Network with Object Relation for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7a162f189c9c553438b83a8a8ec7de4a6fa59069\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144454465\",\"name\":\"L. Peng\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"32518385\",\"name\":\"Z. Wang\"},{\"authorId\":\"153028349\",\"name\":\"Xiao Wu\"},{\"authorId\":\"83672162\",\"name\":\"Zi Huang\"}],\"doi\":\"10.1145/3343031.3350925\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"title\":\"CRA-Net: Composed Relation Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/eb488ee07fc078eb0200c3a4ca119bc67303e507\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100715052\",\"name\":\"Yi Tang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"151472634\",\"name\":\"Y. Hua\"},{\"authorId\":\"98466827\",\"name\":\"Z. Jin\"},{\"authorId\":\"15524303\",\"name\":\"Xia Li\"}],\"doi\":\"10.1016/j.neucom.2019.09.064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a015dba578ac82532c0968053dc2fd109a6ea73f\",\"title\":\"Video salient object detection via spatiotemporal attention neural networks\",\"url\":\"https://www.semanticscholar.org/paper/a015dba578ac82532c0968053dc2fd109a6ea73f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1903.12314\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"38079056\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.1109/ICCV.2019.01041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d379ba96b8f400b23b2cd72c428af67e578959ea\",\"title\":\"Relation-Aware Graph Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d379ba96b8f400b23b2cd72c428af67e578959ea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3431194\",\"name\":\"Yuxuan Liang\"},{\"authorId\":\"51056293\",\"name\":\"Songyu Ke\"},{\"authorId\":\"8214994\",\"name\":\"J. Zhang\"},{\"authorId\":\"2098291\",\"name\":\"Xiuwen Yi\"},{\"authorId\":\"145473095\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.24963/ijcai.2018/476\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"134b77182981451c456ad0a02c1d61f67906f892\",\"title\":\"GeoMAN: Multi-level Attention Networks for Geo-sensory Time Series Prediction\",\"url\":\"https://www.semanticscholar.org/paper/134b77182981451c456ad0a02c1d61f67906f892\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2784591\",\"name\":\"Zetao Chen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1867220\",\"name\":\"I. Sa\"},{\"authorId\":\"144062687\",\"name\":\"Zongyuan Ge\"},{\"authorId\":\"1885768\",\"name\":\"M. Chli\"}],\"doi\":\"10.1109/LRA.2018.2859916\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c452daa8766e1438835d4f664e4feef7fd8e5e01\",\"title\":\"Learning Context Flexible Attention Model for Long-Term Visual Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c452daa8766e1438835d4f664e4feef7fd8e5e01\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40907231\",\"name\":\"Jixiu Wu\"},{\"authorId\":\"48500310\",\"name\":\"N. Cai\"},{\"authorId\":\"7279728\",\"name\":\"Feiyang Li\"},{\"authorId\":\"13809030\",\"name\":\"Huiwen Jiang\"},{\"authorId\":null,\"name\":\"Han Wang\"}],\"doi\":\"10.1016/j.eswa.2019.113121\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"888f153d80cb90d26df9a926810e996ee266462d\",\"title\":\"Automatic detonator code recognition via deep neural network\",\"url\":\"https://www.semanticscholar.org/paper/888f153d80cb90d26df9a926810e996ee266462d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3316767\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"title\":\"Multi-source Multi-level Attention Networks for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b0ce44270916fd6e254fd9e75dd77ee1cf9f212a\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2010.14095\",\"authors\":[{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.417\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"title\":\"MMFT-BERT: Multimodal Fusion Transformer with BERT Encodings for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bf8a0cda4f26c889d1b6d16fe070fa3d907a8686\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1806.03726\",\"authors\":[{\"authorId\":\"38784892\",\"name\":\"Wei-Lun Chao\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"}],\"doi\":\"10.1109/CVPR.2018.00599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"title\":\"Cross-Dataset Adaptation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1bfc74bad04b407d1792a70d73a3f5dc0be0506d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"31081539\",\"name\":\"Pengpeng Zeng\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.24963/ijcai.2018/126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"title\":\"From Pixels to Objects: Cubic Visual Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b18d7ce3e7514fdae89ff410e2e122382c3d10a9\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1796706\",\"name\":\"Daojian Zeng\"},{\"authorId\":\"1400347434\",\"name\":\"Guanhong Zhou\"},{\"authorId\":\"9491882\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/ICECIE47765.2019.8974765\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01163764edf888ded242e992845badaaf6c6ec6e\",\"title\":\"Residual Self-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/01163764edf888ded242e992845badaaf6c6ec6e\",\"venue\":\"2019 1st International Conference on Electrical, Control and Instrumentation Engineering (ICECIE)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"144894849\",\"name\":\"Fei Wu\"},{\"authorId\":\"48566761\",\"name\":\"Jiang Zhu\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3240876.3240885\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e4e599fa3ca042d30321aa5502a135c1de87e688\",\"title\":\"Video question answering via multi-granularity temporal attention network learning\",\"url\":\"https://www.semanticscholar.org/paper/e4e599fa3ca042d30321aa5502a135c1de87e688\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-030-33676-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d631106df52df0f47b5669e5b6547267a9756164\",\"title\":\"DynGraph: Visual Question Answering via Dynamic Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d631106df52df0f47b5669e5b6547267a9756164\",\"venue\":\"GCPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1478822269\",\"name\":\"Jian Ke\"},{\"authorId\":\"46372566\",\"name\":\"Jianbo Xu\"},{\"authorId\":\"144164185\",\"name\":\"Xiangwei Meng\"},{\"authorId\":\"2031492283\",\"name\":\"Qixiong Huang\"}],\"doi\":\"10.1109/ICDSBA48748.2019.00020\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"709503d5fa9c418eb30428efcbf8731bbabe3771\",\"title\":\"Hybrid Collaborative Filtering with Attention CNN for Web Service Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/709503d5fa9c418eb30428efcbf8731bbabe3771\",\"venue\":\"2019 3rd International Conference on Data Science and Business Analytics (ICDSBA)\",\"year\":2019},{\"arxivId\":\"1804.00775\",\"authors\":[{\"authorId\":\"41022273\",\"name\":\"Duy-Kien Nguyen\"},{\"authorId\":\"1718872\",\"name\":\"Takayuki Okatani\"}],\"doi\":\"10.1109/CVPR.2018.00637\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"title\":\"Improved Fusion of Visual and Language Representations by Dense Symmetric Co-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f7cc85bed2a3d0b0ef1c0e0258f5b60ee4bb4622\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.07464\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3392051\",\"name\":\"Qingyi Tao\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01234-2_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"title\":\"VQA-E: Explaining, Elaborating, and Enhancing Your Answers for Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/06ba3492e3a9a2e98df2c81b91ec94787e3f97fb\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":\"51208710\",\"name\":\"Haoran Mo\"},{\"authorId\":\"2971945\",\"name\":\"Chengying Gao\"},{\"authorId\":\"152272089\",\"name\":\"R. Du\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"}],\"doi\":\"10.1145/3355089.3356561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98c1715b17db5a992b4e2e99f55957e70f3e51b7\",\"title\":\"Language-based colorization of scene sketches\",\"url\":\"https://www.semanticscholar.org/paper/98c1715b17db5a992b4e2e99f55957e70f3e51b7\",\"venue\":\"ACM Trans. Graph.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50096204\",\"name\":\"Chunlin Wang\"},{\"authorId\":\"1706546\",\"name\":\"J. Sun\"},{\"authorId\":\"46772675\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3318299.3318305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f0a08e6485fefab90fc7c56a3ebbf4409c93022\",\"title\":\"Feature Fusion Attention Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7f0a08e6485fefab90fc7c56a3ebbf4409c93022\",\"venue\":\"ICMLC '19\",\"year\":2019},{\"arxivId\":\"1801.09041\",\"authors\":[{\"authorId\":\"48933900\",\"name\":\"Q. Li\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"2846025\",\"name\":\"D. Yu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.18653/v1/D18-1164\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd2f8bb5fa881797fad0448547e307a18bf897da\",\"title\":\"Tell-and-Answer: Towards Explainable Visual Question Answering using Attributes and Captions\",\"url\":\"https://www.semanticscholar.org/paper/dd2f8bb5fa881797fad0448547e307a18bf897da\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2002.01155\",\"authors\":[{\"authorId\":\"30322058\",\"name\":\"Md. Jahidul Islam\"},{\"authorId\":\"1381723743\",\"name\":\"Peigen Luo\"},{\"authorId\":\"1765604\",\"name\":\"Junaed Sattar\"}],\"doi\":\"10.15607/rss.2020.xvi.018\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26f278d4d3af8ef7e64325caf09308fec618d9f2\",\"title\":\"Simultaneous Enhancement and Super-Resolution of Underwater Imagery for Improved Visual Perception\",\"url\":\"https://www.semanticscholar.org/paper/26f278d4d3af8ef7e64325caf09308fec618d9f2\",\"venue\":\"RSS 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005245\",\"name\":\"Hanqian Wu\"},{\"authorId\":\"1832864247\",\"name\":\"Siliang Cheng\"},{\"authorId\":\"1519283536\",\"name\":\"Jingjing Wang\"},{\"authorId\":\"2988614\",\"name\":\"S. Li\"},{\"authorId\":\"47289090\",\"name\":\"L. Chi\"}],\"doi\":\"10.1007/978-3-030-60450-9_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d149788902115823cb79d7b910525356399db68\",\"title\":\"Multimodal Aspect Extraction with Region-Aware Alignment Network\",\"url\":\"https://www.semanticscholar.org/paper/0d149788902115823cb79d7b910525356399db68\",\"venue\":\"NLPCC\",\"year\":2020},{\"arxivId\":\"1805.04247\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"144812766\",\"name\":\"Salman Khan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7605857f551d128e7c3babfc019950250f81bca9\",\"title\":\"Reciprocal Attention Fusion for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7605857f551d128e7c3babfc019950250f81bca9\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2008.05865\",\"authors\":[{\"authorId\":\"49720954\",\"name\":\"M. Tao\"},{\"authorId\":\"1491092462\",\"name\":\"Hao Tang\"},{\"authorId\":\"1649368283\",\"name\":\"Songsong Wu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"49737751\",\"name\":\"Xiaoyuan Jing\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efa82cc293ab3c700d86f987395d5c4f7479558f\",\"title\":\"DF-GAN: Deep Fusion Generative Adversarial Networks for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/efa82cc293ab3c700d86f987395d5c4f7479558f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"},{\"authorId\":\"49807919\",\"name\":\"Furu Wei\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":\"10.18653/v1/D19-1217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"title\":\"Video Dialog via Progressive Inference and Cross-Transformer\",\"url\":\"https://www.semanticscholar.org/paper/142aa769440eebcd93fd0ff54404ad0bdcb3e854\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152553572\",\"name\":\"Huan Shao\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"47535378\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-36802-9_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f21cba46085eba47b299fbff283515284bed7189\",\"title\":\"Intra-Modality Feature Interaction Using Self-attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f21cba46085eba47b299fbff283515284bed7189\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"143663452\",\"name\":\"Huimin Lu\"},{\"authorId\":\"144780837\",\"name\":\"Li He\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1109/ICME.2018.8486475\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"title\":\"Dual Learning for Visual Question Generation\",\"url\":\"https://www.semanticscholar.org/paper/d353b30b9ca3124fad08e3bdc8167dfe994efb34\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145242717\",\"name\":\"H. Cheng\"},{\"authorId\":\"145310587\",\"name\":\"K. Wu\"},{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"145464144\",\"name\":\"J. Tian\"},{\"authorId\":\"143888056\",\"name\":\"R. Xu\"},{\"authorId\":\"2443214\",\"name\":\"Chao-Chen Gu\"},{\"authorId\":\"145394028\",\"name\":\"X. Guan\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206603\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"27e2197dbb2a4e3ec5eaaa9c94255c658e782b5e\",\"title\":\"Double Attention for Pathology Image Diagnosis Network with Visual Interpretability\",\"url\":\"https://www.semanticscholar.org/paper/27e2197dbb2a4e3ec5eaaa9c94255c658e782b5e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1805.09701\",\"authors\":[{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"50688017\",\"name\":\"L. Ji\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"29943965\",\"name\":\"Nan Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"2447408\",\"name\":\"Jianyong Wang\"}],\"doi\":\"10.1145/3219819.3220036\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"title\":\"R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/d2de5d94461d66e6b97e6825ae0fea3d6d925382\",\"venue\":\"KDD\",\"year\":2018},{\"arxivId\":\"2001.07059\",\"authors\":[{\"authorId\":\"6328564\",\"name\":\"M. Farazi\"},{\"authorId\":\"1931655\",\"name\":\"S. Khan\"},{\"authorId\":\"1712576\",\"name\":\"N. Barnes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"title\":\"Accuracy vs. Complexity: A Trade-off in Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8527a2f65eaaf0c96b2ac9430185b0e12d8973a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47002278\",\"name\":\"Yikuan Li\"},{\"authorId\":\"51464971\",\"name\":\"Hanyin Wang\"},{\"authorId\":\"1830568527\",\"name\":\"Yuan Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"title\":\"A Comparison of Pre-trained Vision-and-Language Models for Multimodal Representation Learning across Medical Images and Reports\",\"url\":\"https://www.semanticscholar.org/paper/ff554f6228cf1f939a0e9e44ada06ef9cd28be15\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b32459b8ebed74efed3d29fa6703fff855ea365\",\"title\":\"Task Focused Robotic Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7b32459b8ebed74efed3d29fa6703fff855ea365\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783507\",\"name\":\"Anni Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1016/j.neucom.2020.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"title\":\"Multi-attention guided feature fusion network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963976\",\"name\":\"Weidong Tian\"},{\"authorId\":\"145380213\",\"name\":\"B. He\"},{\"authorId\":\"1977865899\",\"name\":\"Nan-Xun Wang\"},{\"authorId\":\"33698309\",\"name\":\"Zhong-Qiu Zhao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99a01a687f7959de4c86102342d4bcfec6382aa8\",\"title\":\"Multi-Channel Co-Attention Network for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/99a01a687f7959de4c86102342d4bcfec6382aa8\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144493079\",\"name\":\"Z. Hu\"},{\"authorId\":\"1754240987\",\"name\":\"Jielong Wei\"},{\"authorId\":\"2639734\",\"name\":\"Qingbao Huang\"},{\"authorId\":\"1904290800\",\"name\":\"Hanyu Liang\"},{\"authorId\":\"1908173213\",\"name\":\"Xingmao Zhang\"},{\"authorId\":\"1901543027\",\"name\":\"Qingguang Liu\"}],\"doi\":\"10.1109/DSC50466.2020.00040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"title\":\"Graph Convolutional Network for Visual Question Answering Based on Fine-grained Question Representation\",\"url\":\"https://www.semanticscholar.org/paper/2ad3b719a1a0868c29dbf72e81c8c3d226196c28\",\"venue\":\"2020 IEEE Fifth International Conference on Data Science in Cyberspace (DSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47909637\",\"name\":\"Yun Liu\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3269206.3271765\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"c67d62592ff24a25764e489a8a68672d40f50da7\",\"title\":\"Adversarial Learning of Answer-Related Representation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/c67d62592ff24a25764e489a8a68672d40f50da7\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144598359\",\"name\":\"Qianli Ma\"},{\"authorId\":\"1390509382\",\"name\":\"Liuhong Yu\"},{\"authorId\":\"49674890\",\"name\":\"Shuai Tian\"},{\"authorId\":\"22649813\",\"name\":\"Enhuan Chen\"},{\"authorId\":\"38218996\",\"name\":\"W. Ng\"}],\"doi\":\"10.1109/TASLP.2019.2942160\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b6bddea92d26622b97564c73219aa3916c6b55a\",\"title\":\"Global-Local Mutual Attention Model for Text Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b6bddea92d26622b97564c73219aa3916c6b55a\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"145527707\",\"name\":\"Zhe L. Lin\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"1720987\",\"name\":\"X. Shen\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41523cfd9773df271cf66002cc36afbe1e06d4ea\",\"title\":\"Progressive Attention Networks for Visual Attribute Prediction\",\"url\":\"https://www.semanticscholar.org/paper/41523cfd9773df271cf66002cc36afbe1e06d4ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410397846\",\"name\":\"Ahmad Khaliq\"},{\"authorId\":\"144429572\",\"name\":\"S. Ehsan\"},{\"authorId\":\"2784591\",\"name\":\"Zetao Chen\"},{\"authorId\":\"144479513\",\"name\":\"M. Milford\"},{\"authorId\":\"1389942491\",\"name\":\"K. McDonald-Maier\"}],\"doi\":\"10.1109/TRO.2019.2956352\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ee6893142b8e6027ae375f139c2e97f69a4f3ef2\",\"title\":\"A Holistic Visual Place Recognition Approach Using Lightweight CNNs for Significant ViewPoint and Appearance Changes\",\"url\":\"https://www.semanticscholar.org/paper/ee6893142b8e6027ae375f139c2e97f69a4f3ef2\",\"venue\":\"IEEE Transactions on Robotics\",\"year\":2020},{\"arxivId\":\"1809.10093\",\"authors\":[{\"authorId\":\"3389590\",\"name\":\"P. Abolghasemi\"},{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"},{\"authorId\":\"1701593\",\"name\":\"Ladislau B\\u00f6l\\u00f6ni\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"676d624c7b8642acde0bc70e06b462e93fd83e64\",\"title\":\"Pay attention! - Robustifying a Deep Visuomotor Policy through Task-Focused Attention\",\"url\":\"https://www.semanticscholar.org/paper/676d624c7b8642acde0bc70e06b462e93fd83e64\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48440873\",\"name\":\"Jun Feng\"},{\"authorId\":\"40757796\",\"name\":\"L. Yan\"},{\"authorId\":\"123887192\",\"name\":\"T. Hang\"}],\"doi\":\"10.1109/ACCESS.2019.2941799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fdeefafc7e11f89665c1394ee40fcb61757f710\",\"title\":\"Stream-Flow Forecasting Based on Dynamic Spatio-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/1fdeefafc7e11f89665c1394ee40fcb61757f710\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1909.11416\",\"authors\":[{\"authorId\":\"123266794\",\"name\":\"C. Liu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"152602127\",\"name\":\"Tianzhu Zhang\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3343031.3350869\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d149507610400ddc2f2b29d9a39f7688b613039\",\"title\":\"Focus Your Attention: A Bidirectional Focal Attention Network for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/2d149507610400ddc2f2b29d9a39f7688b613039\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087226\",\"name\":\"T. Tommasi\"},{\"authorId\":\"36508529\",\"name\":\"Arun Mallya\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1007/s11263-018-1096-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"title\":\"Combining Multiple Cues for Visual Madlibs Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/6f8ea6c3d195b92a92005f993aa98b98b069d10d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3493665\",\"name\":\"Dafang He\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"1745900\",\"name\":\"Alexander N. Gorban\"},{\"authorId\":\"39099960\",\"name\":\"Derrall Heath\"},{\"authorId\":\"46920727\",\"name\":\"J. Ibarz\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1852261\",\"name\":\"D. Kifer\"},{\"authorId\":\"145157784\",\"name\":\"C. Lee Giles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"title\":\"Guided Attention for Large Scale Scene Text Verification\",\"url\":\"https://www.semanticscholar.org/paper/b9953824b3d4cd2be77ecbc5db3f7dec3dfa031e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"48515305\",\"name\":\"Yimeng Li\"},{\"authorId\":\"22228139\",\"name\":\"Yunan Ye\"},{\"authorId\":null,\"name\":\"Long Chen\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"2549731\",\"name\":\"Jian Shao\"},{\"authorId\":\"145974112\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1007/s11063-019-10003-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8bf0b37ed005285b6cbef70a78434978ca065120\",\"title\":\"Hierarchical Temporal Fusion of Multi-grained Attention Features for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8bf0b37ed005285b6cbef70a78434978ca065120\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50133856\",\"name\":\"Y. Yu\"},{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2910007\",\"name\":\"J. Guo\"},{\"authorId\":\"145134722\",\"name\":\"Y. Pang\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f67d8ee105634fc614005b7c7b2e212e9da2fcc4\",\"title\":\"Stacked Semantic-Guided Attention Model for Fine-Grained Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/f67d8ee105634fc614005b7c7b2e212e9da2fcc4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"145310587\",\"name\":\"K. Wu\"},{\"authorId\":\"145880684\",\"name\":\"Hao Cheng\"},{\"authorId\":\"5494837\",\"name\":\"C. Gu\"},{\"authorId\":\"40977498\",\"name\":\"Rui Xu\"},{\"authorId\":\"152936756\",\"name\":\"X. Guan\"}],\"doi\":\"10.1007/978-3-030-04224-0_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8642efc51d262547994c4c8600cb5d021de4952b\",\"title\":\"A Pathology Image Diagnosis Network with Visual Interpretability and Structured Diagnostic Report\",\"url\":\"https://www.semanticscholar.org/paper/8642efc51d262547994c4c8600cb5d021de4952b\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150337817\",\"name\":\"Weike Jin\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"67144160\",\"name\":\"Mao Gu\"},{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1145/3331184.3331240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"title\":\"Video Dialog via Multi-Grained Convolutional Self-Attention Context Networks\",\"url\":\"https://www.semanticscholar.org/paper/f8954b3f74373e953b4449efca71e5ec6be46fb6\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":758237,\"doi\":\"10.1109/CVPR.2017.446\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":8,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"d740d0a960368633ed32fc84877b8391993acdca\",\"references\":[{\"arxivId\":\"1505.05612\",\"authors\":[{\"authorId\":\"2345388\",\"name\":\"Haoyuan Gao\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":null,\"name\":\"Lei Wang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"title\":\"Are You Talking to a Machine? Dataset and Methods for Multilingual Image Question\",\"url\":\"https://www.semanticscholar.org/paper/2fcd5cff2b4743ea640c4af68bf4143f4a2cccb1\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1604.03249\",\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.1007/978-3-319-50077-5_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"title\":\"Attributes as Semantic Units between Natural Language and Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd73d1956163a4160ec2c96b3ab256f79fc92e8\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1606.01847\",\"authors\":[{\"authorId\":\"50599725\",\"name\":\"A. Fukui\"},{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"3422876\",\"name\":\"Daylen Yang\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"}],\"doi\":\"10.18653/v1/D16-1044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fddc15480d086629b960be5bff96232f967f2252\",\"title\":\"Multimodal Compact Bilinear Pooling for Visual Question Answering and Visual Grounding\",\"url\":\"https://www.semanticscholar.org/paper/fddc15480d086629b960be5bff96232f967f2252\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1505.01121\",\"authors\":[{\"authorId\":\"145478807\",\"name\":\"Mateusz Malinowski\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"}],\"doi\":\"10.1109/ICCV.2015.9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"title\":\"Ask Your Neurons: A Neural-Based Approach to Answering Questions about Images\",\"url\":\"https://www.semanticscholar.org/paper/bd7bd1d2945a58cdcc1797ba9698b8810fe68f60\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.01485\",\"authors\":[{\"authorId\":\"3393294\",\"name\":\"Ilija Ilievski\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7214daf035ab005b3d1e739750dd597b4f4513fa\",\"title\":\"A Focused Dynamic Attention Model for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7214daf035ab005b3d1e739750dd597b4f4513fa\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.00468\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"118707418\",\"name\":\"M. Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"51472503\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-016-0966-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"title\":\"VQA: Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/97ad70a9fa3f99adf18030e5e38ebe3d90daa2db\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1608.08716\",\"authors\":[{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1963421\",\"name\":\"Stanislaw Antol\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1609/aimag.v37i1.2647\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"title\":\"Measuring Machine Intelligence Through Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/caf912b716905ccbf46d6d00d6a0b622834a7cd9\",\"venue\":\"AI Mag.\",\"year\":2016},{\"arxivId\":\"1611.07675\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2017.111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"title\":\"Video Captioning with Transferred Semantic Attributes\",\"url\":\"https://www.semanticscholar.org/paper/0d3b5ffff118326fea73341a86a7c29423eb95f0\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1511.05234\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1007/978-3-319-46478-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"title\":\"Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1cf6bc0866226c1f8e282463adc8b75d92fba9bb\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1735300\",\"name\":\"S. Haykin\"},{\"authorId\":\"35299277\",\"name\":\"B. Kosko\"}],\"doi\":\"10.1109/9780470544976.CH9\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f42b865e20e61a954239f421b42007236e671f19\",\"title\":\"GradientBased Learning Applied to Document Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f42b865e20e61a954239f421b42007236e671f19\",\"venue\":\"\",\"year\":2001},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Agrawal\"},{\"authorId\":null,\"name\":\"S. Antol\"},{\"authorId\":null,\"name\":\"M. Mitchell\"},{\"authorId\":null,\"name\":\"D. Batra\"},{\"authorId\":null,\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Boost - ing image captioning with attributes Image captioning with semantic attention\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1511.03416\",\"authors\":[{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2016.540\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"def584565d05d6a8ba94de6621adab9e301d375d\",\"title\":\"Visual7W: Grounded Question Answering in Images\",\"url\":\"https://www.semanticscholar.org/paper/def584565d05d6a8ba94de6621adab9e301d375d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dde84862e2a2b1c11d27d695e47e41db0f2eb06d\",\"title\":\"Beyond Object Recognition: Visual Sentiment Analysis with Deep Coupled Adjective and Noun Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dde84862e2a2b1c11d27d695e47e41db0f2eb06d\",\"venue\":\"IJCAI\",\"year\":2016},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1511.05756\",\"authors\":[{\"authorId\":\"2018393\",\"name\":\"Hyeonwoo Noh\"},{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2016.11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"title\":\"Image Question Answering Using Convolutional Neural Network with Dynamic Parameter Prediction\",\"url\":\"https://www.semanticscholar.org/paper/385c18cc4024a3b3206c508c512e037b9c00b8f3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1511.07394\",\"authors\":[{\"authorId\":\"143953573\",\"name\":\"K. Shih\"},{\"authorId\":\"37415643\",\"name\":\"S. Singh\"},{\"authorId\":\"2433269\",\"name\":\"Derek Hoiem\"}],\"doi\":\"10.1109/CVPR.2016.499\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"title\":\"Where to Look: Focus Regions for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/175e9bb50cc062c6c1742a5d90c8dfe31d2e4e22\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1611.00471\",\"authors\":[{\"authorId\":\"34758272\",\"name\":\"H. Nam\"},{\"authorId\":\"2577039\",\"name\":\"Jung-Woo Ha\"},{\"authorId\":\"2947441\",\"name\":\"J. Kim\"}],\"doi\":\"10.1109/CVPR.2017.232\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f651593fa6c83d717fc961482696a53b6fca5ab5\",\"title\":\"Dual Attention Networks for Multimodal Reasoning and Matching\",\"url\":\"https://www.semanticscholar.org/paper/f651593fa6c83d717fc961482696a53b6fca5ab5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1606.07356\",\"authors\":[{\"authorId\":\"2801949\",\"name\":\"Aishwarya Agrawal\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/D16-1203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"title\":\"Analyzing the Behavior of Visual Question Answering Models\",\"url\":\"https://www.semanticscholar.org/paper/8e759195eb4b4f0f480a8a2cf1c629bfd881d4e5\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":\"1505.02074\",\"authors\":[{\"authorId\":\"2540599\",\"name\":\"Mengye Ren\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"62a956d7600b10ca455076cd56e604dfd106072a\",\"title\":\"Exploring Models and Data for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/62a956d7600b10ca455076cd56e604dfd106072a\",\"venue\":\"NIPS\",\"year\":2015},{\"arxivId\":\"1602.07332\",\"authors\":[{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"50499889\",\"name\":\"O. Groth\"},{\"authorId\":\"122867187\",\"name\":\"J. Johnson\"},{\"authorId\":\"1382195702\",\"name\":\"Kenji Hata\"},{\"authorId\":\"40591424\",\"name\":\"J. Kravitz\"},{\"authorId\":\"6000646\",\"name\":\"Stephanie Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"1388344504\",\"name\":\"David A. Shamma\"},{\"authorId\":\"1379506718\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-016-0981-7\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"title\":\"Visual Genome: Connecting Language and Vision Using Crowdsourced Dense Image Annotations\",\"url\":\"https://www.semanticscholar.org/paper/afcf4dbd2ef300e5c4b35043d4fbe516807cdf7d\",\"venue\":\"International Journal of Computer Vision\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"52184096\",\"name\":\"L. Bottou\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"1721248\",\"name\":\"P. Haffner\"}],\"doi\":\"10.1109/5.726791\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"162d958ff885f1462aeda91cd72582323fd6a1f4\",\"title\":\"Gradient-based learning applied to document recognition\",\"url\":\"https://www.semanticscholar.org/paper/162d958ff885f1462aeda91cd72582323fd6a1f4\",\"venue\":\"\",\"year\":1998},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"31c8f1f728df2cfea5d0a9dda67a27de82f5a879\",\"title\":\"Let Your Photos Talk: Generating Narrative Paragraph for Photo Stream via Bidirectional Attention Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/31c8f1f728df2cfea5d0a9dda67a27de82f5a879\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1511.06973\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"48319305\",\"name\":\"P. Wang\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.500\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"title\":\"Ask Me Anything: Free-Form Visual Question Answering Based on Knowledge from External Sources\",\"url\":\"https://www.semanticscholar.org/paper/20dbdf02497aa84510970d0f5e8b599073bca1bc\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1606.03556\",\"authors\":[{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1016/j.cviu.2017.10.001\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"title\":\"Human Attention in Visual Question Answering: Do Humans and Deep Networks look at the same regions?\",\"url\":\"https://www.semanticscholar.org/paper/58cb0c24c936b8a14ca7b2d56ba80de733c545b3\",\"venue\":\"EMNLP\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"47096713\",\"name\":\"Y. Wu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/ICCV.2015.230\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dcc7c59ed04c63e5e5fa0f980d703e3888266a2\",\"title\":\"Relaxing from Vocabulary: Robust Weakly-Supervised Deep Learning for Vocabulary-Free Image Tagging\",\"url\":\"https://www.semanticscholar.org/paper/1dcc7c59ed04c63e5e5fa0f980d703e3888266a2\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"},{\"authorId\":\"3349534\",\"name\":\"X. Wang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TCSVT.2014.2380211\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d0371a8d4bf4670a843f2516cd3f30b263e3e5b\",\"title\":\"Image Tag Refinement With View-Dependent Concept Representations\",\"url\":\"https://www.semanticscholar.org/paper/2d0371a8d4bf4670a843f2516cd3f30b263e3e5b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73597804\",\"name\":\"J. Haji\\u010d\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8eb77cfbe31e7ff27c38518865cce4804c767055\",\"title\":\"Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8eb77cfbe31e7ff27c38518865cce4804c767055\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016}],\"title\":\"Multi-level Attention Networks for Visual Question Answering\",\"topics\":[{\"topic\":\"Question answering\",\"topicId\":\"18817\",\"url\":\"https://www.semanticscholar.org/topic/18817\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Recurrent neural network\",\"topicId\":\"16115\",\"url\":\"https://www.semanticscholar.org/topic/16115\"},{\"topic\":\"High- and low-level\",\"topicId\":\"33507\",\"url\":\"https://www.semanticscholar.org/topic/33507\"},{\"topic\":\"Perceptron\",\"topicId\":\"5842\",\"url\":\"https://www.semanticscholar.org/topic/5842\"},{\"topic\":\"Natural language\",\"topicId\":\"1911\",\"url\":\"https://www.semanticscholar.org/topic/1911\"},{\"topic\":\"Text-based (computing)\",\"topicId\":\"75487\",\"url\":\"https://www.semanticscholar.org/topic/75487\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Complementarity theory\",\"topicId\":\"73931\",\"url\":\"https://www.semanticscholar.org/topic/73931\"},{\"topic\":\"Softmax function\",\"topicId\":\"966784\",\"url\":\"https://www.semanticscholar.org/topic/966784\"},{\"topic\":\"Artificial neural network\",\"topicId\":\"6213\",\"url\":\"https://www.semanticscholar.org/topic/6213\"},{\"topic\":\"Multi-level cell\",\"topicId\":\"332765\",\"url\":\"https://www.semanticscholar.org/topic/332765\"},{\"topic\":\"Embedded system\",\"topicId\":\"4423\",\"url\":\"https://www.semanticscholar.org/topic/4423\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Multi-level governance\",\"topicId\":\"933159\",\"url\":\"https://www.semanticscholar.org/topic/933159\"},{\"topic\":\"Software quality assurance\",\"topicId\":\"54373\",\"url\":\"https://www.semanticscholar.org/topic/54373\"}],\"url\":\"https://www.semanticscholar.org/paper/d740d0a960368633ed32fc84877b8391993acdca\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"