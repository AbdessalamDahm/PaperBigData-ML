"{\"abstract\":\"The paucity of videos in current action classification datasets (UCF-101 and HMDB-51) has made it difficult to identify good video architectures, as most methods obtain similar performance on existing small-scale benchmarks. This paper re-evaluates state-of-the-art architectures in light of the new Kinetics Human Action Video dataset. Kinetics has two orders of magnitude more data, with 400 human action classes and over 400 clips per class, and is collected from realistic, challenging YouTube videos. We provide an analysis on how current architectures fare on the task of action classification on this dataset and how much performance improves on the smaller benchmark datasets after pre-training on Kinetics. We also introduce a new Two-Stream Inflated 3D ConvNet (I3D) that is based on 2D ConvNet inflation: filters and pooling kernels of very deep image classification ConvNets are expanded into 3D, making it possible to learn seamless spatio-temporal feature extractors from video while leveraging successful ImageNet architecture designs and even their parameters. We show that, after pre-training on Kinetics, I3D models considerably improve upon the state-of-the-art in action classification, reaching 80.2% on HMDB-51 and 97.9% on UCF-101.\",\"arxivId\":\"1705.07750\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\",\"url\":\"https://www.semanticscholar.org/author/35681810\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\",\"url\":\"https://www.semanticscholar.org/author/1688869\"}],\"citationVelocity\":676,\"citations\":[{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"title\":\"Learning to Recognize Actions with Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/baa7f5ce8fd59da4e70944a0e77b3cf18534b2e8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.07236\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"47873182\",\"name\":\"S. Gould\"}],\"doi\":\"10.1109/WACV45572.2020.9093328\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"title\":\"Proposal-free Temporal Moment Localization of a Natural-Language Query in Video using Guided Attention\",\"url\":\"https://www.semanticscholar.org/paper/03df26255781ebb71d9430e1b2aaabf8e1af9990\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1807.11794\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"title\":\"Attention is All We Need: Nailing Down Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75fac714ccc1b616048c9bb6ca918c58317c56a1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409464809\",\"name\":\"Pin-Jui Hwang\"},{\"authorId\":\"40689527\",\"name\":\"Chen-Chien Hsu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c3ff598d1b2e163899b03684fd004adb67850f7\",\"title\":\"Robot Learning from Demonstration Based on Action and Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c3ff598d1b2e163899b03684fd004adb67850f7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"153142893\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1109/ICCV.2019.00767\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"title\":\"View-LSTM: Novel-View Video Synthesis Through View Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/7a1f7dd6c85c4c53b05ae6833ee5541f29a24946\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1803.11264\",\"authors\":[{\"authorId\":\"1916516\",\"name\":\"M. Khodabandeh\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"15623770\",\"name\":\"I. Zharkov\"},{\"authorId\":\"3811436\",\"name\":\"V. Pradeep\"}],\"doi\":\"10.1109/CVPRW.2018.00194\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"title\":\"DIY Human Action Dataset Generation\",\"url\":\"https://www.semanticscholar.org/paper/74b8f8e27450891985df8ac8e083e81a8a922cd9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"title\":\"Iterative Alignment Network for Continuous Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/413a354acbc42a0455ce1bbbd5d5c75cc38bc53d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1807.00458\",\"authors\":[{\"authorId\":\"50341269\",\"name\":\"S. Li\"},{\"authorId\":\"1718484\",\"name\":\"Ajaya Neupane\"},{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"51222066\",\"name\":\"C. Song\"},{\"authorId\":\"38774813\",\"name\":\"S. Krishnamurthy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"},{\"authorId\":\"144231976\",\"name\":\"A. Swami\"}],\"doi\":\"10.14722/ndss.2019.23202\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"119a62a685aed7e94234a2ac4b16636c744b04a6\",\"title\":\"Adversarial Perturbations Against Real-Time Video Classification Systems\",\"url\":\"https://www.semanticscholar.org/paper/119a62a685aed7e94234a2ac4b16636c744b04a6\",\"venue\":\"NDSS\",\"year\":2019},{\"arxivId\":\"1906.01028\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/TPAMI.2018.2884469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25edae7a44dc4f26adc04693199595a12a3b1eec\",\"title\":\"A Hybrid RNN-HMM Approach for Weakly Supervised Temporal Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/25edae7a44dc4f26adc04693199595a12a3b1eec\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147627782\",\"name\":\"Marc Roig Vilamala\"},{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"1721540\",\"name\":\"F. Cerutti\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a21755ee535c52a1759149c7159987e9d2ba939\",\"title\":\"A Pilot Study on Detecting Violence in Videos Fusing Proxy Models\",\"url\":\"https://www.semanticscholar.org/paper/2a21755ee535c52a1759149c7159987e9d2ba939\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"49024484\",\"name\":\"J. Huang\"},{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICIP.2018.8451741\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de82346e5df5ca7e7bbfc84bbae1c1a9922e71b5\",\"title\":\"An Active Action Proposal Method Based on Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/de82346e5df5ca7e7bbfc84bbae1c1a9922e71b5\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153008120\",\"name\":\"Zineng Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6eee0fd08e8b33bf2affb355a6ecd3523860aa11\",\"title\":\"Action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6eee0fd08e8b33bf2affb355a6ecd3523860aa11\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.09035\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/ICCV.2019.00635\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"792829f263a523eedf1a8748ec23d25cf664c2b4\",\"title\":\"What Would You Expect? Anticipating Egocentric Actions With Rolling-Unrolling LSTMs and Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/792829f263a523eedf1a8748ec23d25cf664c2b4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410755536\",\"name\":\"David Ivorra-Piqueres\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10db9fc9107895a0705401cab89697f248d5eaed\",\"title\":\"Action segmentation and understanding in RGB videos with convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/10db9fc9107895a0705401cab89697f248d5eaed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1787699\",\"name\":\"K. Kato\"},{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01264-9_15\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d26ecaeb0181c73e89bc3e94f317dbc150a98480\",\"title\":\"Compositional Learning for Human Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/d26ecaeb0181c73e89bc3e94f317dbc150a98480\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.05770\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"47775885\",\"name\":\"Liang Xu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"143864262\",\"name\":\"Manyu Chang\"},{\"authorId\":null,\"name\":\"Junjie Huang\"},{\"authorId\":\"143986385\",\"name\":\"G. Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38d0dd93755b83b2390815fda926866f7ec624ce\",\"title\":\"Action Machine: Rethinking Action Recognition in Trimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/38d0dd93755b83b2390815fda926866f7ec624ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669712931\",\"name\":\"Arpan Gupta\"},{\"authorId\":\"3247309\",\"name\":\"Sakthi Balan Muthiah\"}],\"doi\":\"10.1145/3293353.3293415\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8889beea3ae4e529f888525e33bd2160559f9153\",\"title\":\"Temporal Cricket Stroke Localization from Untrimmed Highlight Videos\",\"url\":\"https://www.semanticscholar.org/paper/8889beea3ae4e529f888525e33bd2160559f9153\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"46728598\",\"name\":\"Xue Mei\"},{\"authorId\":\"46968435\",\"name\":\"Yi He\"},{\"authorId\":\"48180876\",\"name\":\"Jin Zhang\"}],\"doi\":\"10.1007/978-3-030-36189-1_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f05fa8951324b2f603360a845a610d2596d60aa4\",\"title\":\"Soft Transferring and Progressive Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f05fa8951324b2f603360a845a610d2596d60aa4\",\"venue\":\"IScIDE\",\"year\":2019},{\"arxivId\":\"1802.08362\",\"authors\":[{\"authorId\":\"1388811741\",\"name\":\"Alaaeldin El-Nouby\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CRV.2018.00015\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6e9099320eca16c6959194d6d9113649ba88a2a\",\"title\":\"Real-Time End-to-End Action Detection with Two-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/b6e9099320eca16c6959194d6d9113649ba88a2a\",\"venue\":\"2018 15th Conference on Computer and Robot Vision (CRV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485702259\",\"name\":\"Wenqi Shao\"},{\"authorId\":\"1486442460\",\"name\":\"Tianjian Meng\"},{\"authorId\":\"1492114275\",\"name\":\"Jingyu Li\"},{\"authorId\":\"2247393\",\"name\":\"Ruimao Zhang\"},{\"authorId\":\"47003052\",\"name\":\"Y. Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"}],\"doi\":\"10.1109/CVPR.2019.00053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"290f8c3ef889ac73103c977d2b855e0caa580f7f\",\"title\":\"SSN: Learning Sparse Switchable Normalization via SparsestMax\",\"url\":\"https://www.semanticscholar.org/paper/290f8c3ef889ac73103c977d2b855e0caa580f7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.07846\",\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00190\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75662c7ab05db37c52a2d750af2a8b712bbf3d53\",\"title\":\"Temporal Cycle-Consistency Learning\",\"url\":\"https://www.semanticscholar.org/paper/75662c7ab05db37c52a2d750af2a8b712bbf3d53\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2010.11188\",\"authors\":[{\"authorId\":\"103750709\",\"name\":\"Ha Thi Phuong Thao\"},{\"authorId\":\"2000596981\",\"name\":\"Balamurali B.T.\"},{\"authorId\":\"3320845\",\"name\":\"Dorien Herremans\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"278adad9d5c85becc7dd077477f484a864b553d9\",\"title\":\"AttendAffectNet: Self-Attention based Networks for Predicting Affective Responses from Movies\",\"url\":\"https://www.semanticscholar.org/paper/278adad9d5c85becc7dd077477f484a864b553d9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.00230\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/2e057a9b195f0ea2d1c5a1e88ff9606f9b67ef8b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491598459\",\"name\":\"Yun-Zhu Song\"},{\"authorId\":\"2028219138\",\"name\":\"Zhi Rui Tam\"},{\"authorId\":\"50688798\",\"name\":\"Hung-Jen Chen\"},{\"authorId\":\"2028221080\",\"name\":\"Huiao-Han Lu\"},{\"authorId\":\"2426757\",\"name\":\"Hong-Han Shuai\"}],\"doi\":\"10.1007/978-3-030-58520-4_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea35d2594e8f84fb0073893c19903da80914b8c7\",\"title\":\"Character-Preserving Coherent Story Visualization\",\"url\":\"https://www.semanticscholar.org/paper/ea35d2594e8f84fb0073893c19903da80914b8c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10247\",\"authors\":[{\"authorId\":\"5764695\",\"name\":\"Y. Zeng\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1007/978-3-030-58517-4_31\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7f89feee68b6856c0a980a5888b42d18231be07\",\"title\":\"Learning Joint Spatial-Temporal Transformations for Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/f7f89feee68b6856c0a980a5888b42d18231be07\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720763872\",\"name\":\"P. Wilhelm\"},{\"authorId\":\"2498635\",\"name\":\"J. Reinhardt\"},{\"authorId\":\"16894682\",\"name\":\"D. V. Daele\"}],\"doi\":\"10.1109/ISBI45749.2020.9098510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"53a4513ccf8e6194c70746e9bae867be486231a7\",\"title\":\"A Deep Learning Approach to Video Fluoroscopic Swallowing Exam Classification\",\"url\":\"https://www.semanticscholar.org/paper/53a4513ccf8e6194c70746e9bae867be486231a7\",\"venue\":\"2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004228925\",\"name\":\"Jinhao Duan\"},{\"authorId\":\"40463478\",\"name\":\"H. Xu\"},{\"authorId\":\"48030229\",\"name\":\"Xiaozhu Lin\"},{\"authorId\":\"2004346653\",\"name\":\"Shangchao Zhu\"},{\"authorId\":\"115394762\",\"name\":\"Y. Du\"}],\"doi\":\"10.1016/j.imavis.2020.103988\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"68e1892f95de0a982571c0c5df1c12c42364ee11\",\"title\":\"Multi-semantic long-range dependencies capturing for efficient video representation learning\",\"url\":\"https://www.semanticscholar.org/paper/68e1892f95de0a982571c0c5df1c12c42364ee11\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752810295\",\"name\":\"Tianyu Li\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-030-60636-7_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"348d92b6b491fdeb641ca40d89ab56782825a6e1\",\"title\":\"Hierarchical Matching and Reasoning for Action Localization via Language Query\",\"url\":\"https://www.semanticscholar.org/paper/348d92b6b491fdeb641ca40d89ab56782825a6e1\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":\"2006.11747\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"34362536\",\"name\":\"S. Kong\"},{\"authorId\":\"1521319166\",\"name\":\"Zhe Wang\"},{\"authorId\":\"143800213\",\"name\":\"Charless C. Fowlkes\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a792ff56eeed530fab1935168510cbb16b0f1b68\",\"title\":\"Weak Supervision and Referring Attention for Temporal-Textual Association Learning\",\"url\":\"https://www.semanticscholar.org/paper/a792ff56eeed530fab1935168510cbb16b0f1b68\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87971957\",\"name\":\"I. Harsono\"}],\"doi\":\"10.21512/commit.v13i2.5995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b885a8c8a7c1fbd855b00ed69e5458e3b7cd9808\",\"title\":\"Lung Nodule Texture Detection and Classification Using 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/b885a8c8a7c1fbd855b00ed69e5458e3b7cd9808\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48021090\",\"name\":\"B. Zhu\"},{\"authorId\":\"50290087\",\"name\":\"T. Li\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/978-3-030-31726-3_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46c899e661ed9c0bef182b8019035bf5a68cd61d\",\"title\":\"Exploiting Human Pose for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/46c899e661ed9c0bef182b8019035bf5a68cd61d\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1910.02806\",\"authors\":[{\"authorId\":\"41019737\",\"name\":\"Hyojin Bahng\"},{\"authorId\":\"2647582\",\"name\":\"Sanghyuk Chun\"},{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4f3f946498e8af471596f89dde2168f87cc9861\",\"title\":\"Learning De-biased Representations with Biased Representations\",\"url\":\"https://www.semanticscholar.org/paper/f4f3f946498e8af471596f89dde2168f87cc9861\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"1908.04013\",\"authors\":[{\"authorId\":\"145079398\",\"name\":\"Kun Cheng\"},{\"authorId\":\"2711717\",\"name\":\"Haozhi Huang\"},{\"authorId\":\"144204922\",\"name\":\"C. Yuan\"},{\"authorId\":\"152131383\",\"name\":\"Lingyiqing Zhou\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"01e7f4a72bb7b4747b171764c499f126317b45f2\",\"title\":\"Multi-Frame Content Integration with a Spatio-Temporal Attention Mechanism for Person Video Motion Transfer\",\"url\":\"https://www.semanticscholar.org/paper/01e7f4a72bb7b4747b171764c499f126317b45f2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1812.05538\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.00805\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86f6fda61a6d778055ba20daf486697d933a220e\",\"title\":\"The Pros and Cons: Rank-Aware Temporal Attention for Skill Determination in Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/86f6fda61a6d778055ba20daf486697d933a220e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.00910\",\"authors\":[{\"authorId\":\"143902541\",\"name\":\"Philip Bachman\"},{\"authorId\":\"40482726\",\"name\":\"R. Devon Hjelm\"},{\"authorId\":\"134859150\",\"name\":\"William Buchwalter\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9b09d296059909490096e34e9df2d95314787ad5\",\"title\":\"Learning Representations by Maximizing Mutual Information Across Views\",\"url\":\"https://www.semanticscholar.org/paper/9b09d296059909490096e34e9df2d95314787ad5\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37095078\",\"name\":\"J. T. Lee\"},{\"authorId\":\"2059257\",\"name\":\"E. Park\"}],\"doi\":\"10.1007/978-3-030-00919-9_38\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d0617944becc23b2aeb539495bc8d8e9edfdfc0\",\"title\":\"Detection of the Pharyngeal Phase in the Videofluoroscopic Swallowing Study Using Inflated 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3d0617944becc23b2aeb539495bc8d8e9edfdfc0\",\"venue\":\"MLMI@MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"46246550\",\"name\":\"W. Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413618\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1f26caf22fd05659802db690c7e6c9db289be340\",\"title\":\"Modeling Temporal Concept Receptive Field Dynamically for Untrimmed Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1f26caf22fd05659802db690c7e6c9db289be340\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.14478\",\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"2437353\",\"name\":\"Shanghang Zhang\"},{\"authorId\":\"2004342113\",\"name\":\"Guangyao Chen\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"},{\"authorId\":\"51283515\",\"name\":\"Jos\\u00e9 M. F. Moura\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efa758ff318dec043c1e331962c068ba4eb54722\",\"title\":\"Annotation-Efficient Untrimmed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efa758ff318dec043c1e331962c068ba4eb54722\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.06246\",\"authors\":[{\"authorId\":\"10458138\",\"name\":\"P. Ghosh\"},{\"authorId\":\"1742295175\",\"name\":\"Md. Abrar Istiak\"},{\"authorId\":\"1742267771\",\"name\":\"Nayeeb Rashid\"},{\"authorId\":\"1742267920\",\"name\":\"Ahsan Habib Akash\"},{\"authorId\":\"1742295458\",\"name\":\"Ridwan Abrar\"},{\"authorId\":\"1557399421\",\"name\":\"Ankan Ghosh Dastider\"},{\"authorId\":\"50841913\",\"name\":\"Asif Shahriyar Sushmit\"},{\"authorId\":\"144782474\",\"name\":\"T. Hasan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0703a0553169caadf46061c9cc9d47bbadee75a\",\"title\":\"Privacy-Aware Activity Classification from First Person Office Videos\",\"url\":\"https://www.semanticscholar.org/paper/f0703a0553169caadf46061c9cc9d47bbadee75a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.05367\",\"authors\":[{\"authorId\":\"47412750\",\"name\":\"Huaying Hao\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"98271873\",\"name\":\"Yanwu Xu\"},{\"authorId\":\"91139526\",\"name\":\"J. Yang\"},{\"authorId\":\"144695373\",\"name\":\"F. Li\"},{\"authorId\":\"47957630\",\"name\":\"Xingding Zhang\"},{\"authorId\":\"87383538\",\"name\":\"J. Liu\"},{\"authorId\":\"1956017\",\"name\":\"Yitian Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef5bd583b8e7fbe2e2a92d9754e98239b684e2b4\",\"title\":\"Open-Narrow-Synechiae Anterior Chamber Angle Classification in AS-OCT Sequences\",\"url\":\"https://www.semanticscholar.org/paper/ef5bd583b8e7fbe2e2a92d9754e98239b684e2b4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27720832\",\"name\":\"T. Long\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"1647395777\",\"name\":\"Cees Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00122\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"title\":\"Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/2f614f15b8ce225e7385a5427dd6cc2949b3d92f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.01598\",\"authors\":[{\"authorId\":\"151504088\",\"name\":\"X. Ding\"},{\"authorId\":\"151488319\",\"name\":\"N. Wang\"},{\"authorId\":\"49779747\",\"name\":\"Xinbo Gao\"},{\"authorId\":\"1492114961\",\"name\":\"Jie Li\"},{\"authorId\":\"72541556\",\"name\":\"X. Wang\"},{\"authorId\":\"121698214\",\"name\":\"Tongliang Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"title\":\"Weakly Supervised Temporal Action Localization with Segment-Level Labels\",\"url\":\"https://www.semanticscholar.org/paper/5e80e52517b1d4cfe02c9c01e74b3aca28c6b8ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05614\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"594163df647890f47e6ab0b0b426363f7175c9a0\",\"title\":\"Beyond the Camera: Neural Networks in World Coordinates\",\"url\":\"https://www.semanticscholar.org/paper/594163df647890f47e6ab0b0b426363f7175c9a0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Zhensheng Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"144803009\",\"name\":\"Z. Yu\"},{\"authorId\":\"49721778\",\"name\":\"B. Zheng\"}],\"doi\":\"10.1109/ACCESS.2020.2968024\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"title\":\"Learning Attention-Enhanced Spatiotemporal Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c8744061c96cbcf492d5e504d3f6cfc7d0059643\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.02106\",\"authors\":[{\"authorId\":\"67200092\",\"name\":\"S. Broom\\u00e9\"},{\"authorId\":\"4786695\",\"name\":\"K. Gleerup\"},{\"authorId\":\"27868767\",\"name\":\"P. Andersen\"},{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"}],\"doi\":\"10.1109/CVPR.2019.01295\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e59e9d8b361c7e66c8635f3a0795c81a38ae66bd\",\"title\":\"Dynamics Are Important for the Recognition of Equine Pain in Video\",\"url\":\"https://www.semanticscholar.org/paper/e59e9d8b361c7e66c8635f3a0795c81a38ae66bd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1805.07813\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145825349\",\"name\":\"Alan Wu\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/IROS40897.2019.8967559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e7fe8c0b2ce03bef0a1e67e10f2df5ff099fc3d6\",\"title\":\"Learning Real-World Robot Policies by Dreaming\",\"url\":\"https://www.semanticscholar.org/paper/e7fe8c0b2ce03bef0a1e67e10f2df5ff099fc3d6\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"1707752\",\"name\":\"E. F. Ersi\"},{\"authorId\":\"1734678\",\"name\":\"A. Harati\"}],\"doi\":\"10.1016/j.imavis.2019.08.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da6e00eeee9c068e081e24836b230024eaa2eeae\",\"title\":\"A component-based video content representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/da6e00eeee9c068e081e24836b230024eaa2eeae\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":\"1905.11575\",\"authors\":[{\"authorId\":\"144045444\",\"name\":\"R. Su\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"6578587\",\"name\":\"L. Zhou\"},{\"authorId\":\"145481070\",\"name\":\"D. Xu\"}],\"doi\":\"10.1109/CVPR.2019.01229\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c3d445c883a396501acf3b5f2cd7680b2b953903\",\"title\":\"Improving Action Localization by Progressive Cross-Stream Cooperation\",\"url\":\"https://www.semanticscholar.org/paper/c3d445c883a396501acf3b5f2cd7680b2b953903\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"}],\"doi\":\"10.1109/ICCVW.2019.00536\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71f3a2632d924f29ca6eb2e789f8ff6d46250c82\",\"title\":\"EgoVQA - An Egocentric Video Question Answering Benchmark Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71f3a2632d924f29ca6eb2e789f8ff6d46250c82\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1908.07410\",\"authors\":[{\"authorId\":\"1403953272\",\"name\":\"Giorgos Kordopatis-Zilos\"},{\"authorId\":\"48594399\",\"name\":\"S. Papadopoulos\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"},{\"authorId\":\"1715604\",\"name\":\"Y. Kompatsiaris\"}],\"doi\":\"10.1109/ICCV.2019.00645\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1167b93dbe428b5a59452af658f652f16653034b\",\"title\":\"ViSiL: Fine-Grained Spatio-Temporal Video Similarity Learning\",\"url\":\"https://www.semanticscholar.org/paper/1167b93dbe428b5a59452af658f652f16653034b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"}],\"doi\":\"10.1109/IPAS.2018.8708877\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"title\":\"Learning to Represent Spatio-Temporal Features for Fine Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a367717713174d18b3adc4a90d7af7d171dd8ce7\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":\"2008.09234\",\"authors\":[{\"authorId\":\"8842741\",\"name\":\"Romero Morais\"},{\"authorId\":\"144672395\",\"name\":\"Vuong Le\"},{\"authorId\":\"6254479\",\"name\":\"T. Tran\"},{\"authorId\":\"144162181\",\"name\":\"S. Venkatesh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"be1d3bc257bedcab177ae3f75c373219de81902d\",\"title\":\"Learning to Abstract and Predict Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/be1d3bc257bedcab177ae3f75c373219de81902d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8556451\",\"name\":\"F. Angelini\"},{\"authorId\":\"144403678\",\"name\":\"S. Naqvi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74419700e48dbbe4cbbb73cde965787ae26178d4\",\"title\":\"Joint RGB-Pose Based Human Action Recognition for Anomaly Detection Applications\",\"url\":\"https://www.semanticscholar.org/paper/74419700e48dbbe4cbbb73cde965787ae26178d4\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39042074\",\"name\":\"Ian Tu\"},{\"authorId\":\"145901092\",\"name\":\"A. Bhalerao\"},{\"authorId\":\"144482645\",\"name\":\"N. Griffiths\"},{\"authorId\":\"49625872\",\"name\":\"M. Delgado\"},{\"authorId\":\"2059974\",\"name\":\"Alasdair Thomason\"},{\"authorId\":\"2568126\",\"name\":\"T. Popham\"},{\"authorId\":\"2261735\",\"name\":\"A. Mouzakitis\"}],\"doi\":\"10.1109/IVS.2018.8500564\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"27b06d8d09b0190f44597214627f0e8c65031ad9\",\"title\":\"Dual Viewpoint Passenger State Classification Using 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/27b06d8d09b0190f44597214627f0e8c65031ad9\",\"venue\":\"2018 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2452552\",\"name\":\"S. Alletto\"},{\"authorId\":\"151494757\",\"name\":\"Casey Carlin\"},{\"authorId\":\"33434606\",\"name\":\"L. Rigazio\"},{\"authorId\":\"2740479\",\"name\":\"Y. Ishii\"},{\"authorId\":\"2328731\",\"name\":\"S. Tsukizawa\"}],\"doi\":\"10.1109/ICCVW.2019.00286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d342ec645cfe1113d0fd9d45b5ff199abcba1fc6\",\"title\":\"Adherent Raindrop Removal with Self-Supervised Attention Maps and Spatio-Temporal Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d342ec645cfe1113d0fd9d45b5ff199abcba1fc6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50021838\",\"name\":\"Tingting Liu\"},{\"authorId\":\"72050817\",\"name\":\"Zengzhao Chen\"},{\"authorId\":\"1907530\",\"name\":\"Xiangwei Wang\"}],\"doi\":\"10.1145/3338147.3338163\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1322930a4e062793f127e7e685e78375090adfbd\",\"title\":\"Automatic Instructional Pointing Gesture Recognition by Machine Learning in the Intelligent Learning Environment\",\"url\":\"https://www.semanticscholar.org/paper/1322930a4e062793f127e7e685e78375090adfbd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681049\",\"name\":\"Liyuan Wang\"},{\"authorId\":\"1519066969\",\"name\":\"Jing Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"48161494\",\"name\":\"C. Li\"},{\"authorId\":\"152134003\",\"name\":\"Li Zhuo\"}],\"doi\":\"10.1109/TCSVT.2019.2958871\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a26520ff1c497e9526f3533c7ef8b2b1c4425ac8\",\"title\":\"Porn Streamer Recognition in Live Video Streaming via Attention-Gated Multimodal Deep Features\",\"url\":\"https://www.semanticscholar.org/paper/a26520ff1c497e9526f3533c7ef8b2b1c4425ac8\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33950551\",\"name\":\"I. Karlin\"},{\"authorId\":\"1792526\",\"name\":\"Y. Park\"},{\"authorId\":\"144348312\",\"name\":\"B. Supinski\"},{\"authorId\":\"40156219\",\"name\":\"P. Wang\"},{\"authorId\":\"47443774\",\"name\":\"B. Still\"},{\"authorId\":\"2309393\",\"name\":\"D. Beckingsale\"},{\"authorId\":\"31964034\",\"name\":\"R. Blake\"},{\"authorId\":\"71628916\",\"name\":\"Tong Chen\"},{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"6418294\",\"name\":\"Carlos H. A. Costa\"},{\"authorId\":\"1403361261\",\"name\":\"Johann Dahm\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"34380436\",\"name\":\"T. Epperly\"},{\"authorId\":\"144129416\",\"name\":\"A. Fisher\"},{\"authorId\":\"41124303\",\"name\":\"S. K. Schumacher\"},{\"authorId\":\"2075002\",\"name\":\"S. Langer\"},{\"authorId\":\"153174617\",\"name\":\"Hai Le\"},{\"authorId\":\"48777113\",\"name\":\"E. Lee\"},{\"authorId\":\"3264280\",\"name\":\"N. Maruyama\"},{\"authorId\":\"3100511\",\"name\":\"Xinyu Que\"},{\"authorId\":\"47256492\",\"name\":\"D. Richards\"},{\"authorId\":\"101944103\",\"name\":\"Bj\\u00f6rn Sj\\u00f6green\"},{\"authorId\":\"35491434\",\"name\":\"J. Wong\"},{\"authorId\":\"37622776\",\"name\":\"C. Woodward\"},{\"authorId\":\"145040858\",\"name\":\"U. M. Yang\"},{\"authorId\":\"49469193\",\"name\":\"X. Zhang\"},{\"authorId\":\"122303280\",\"name\":\"Bob Anderson\"},{\"authorId\":\"2667113\",\"name\":\"David Appelhans\"},{\"authorId\":\"73460322\",\"name\":\"L. Barnes\"},{\"authorId\":\"29915878\",\"name\":\"P. D. Barnes\"},{\"authorId\":\"50631179\",\"name\":\"S. Bastea\"},{\"authorId\":\"50550715\",\"name\":\"D. B\\u00f6hme\"},{\"authorId\":\"1403895360\",\"name\":\"Jamie A. Bramwell\"},{\"authorId\":\"40495647\",\"name\":\"J. Brase\"},{\"authorId\":\"2983082\",\"name\":\"J. Brunheroto\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"},{\"authorId\":\"1406260339\",\"name\":\"Charway R. Cooper\"},{\"authorId\":\"1404327144\",\"name\":\"Tony Degroot\"},{\"authorId\":\"2060916\",\"name\":\"R. Falgout\"},{\"authorId\":\"144895818\",\"name\":\"T. Gamblin\"},{\"authorId\":\"36513789\",\"name\":\"D. Gardner\"},{\"authorId\":\"3193951\",\"name\":\"J. Glosli\"},{\"authorId\":\"1875652\",\"name\":\"John A. Gunnels\"},{\"authorId\":\"144085439\",\"name\":\"M. Katz\"},{\"authorId\":\"2601874\",\"name\":\"T. Kolev\"},{\"authorId\":\"1937066\",\"name\":\"I. Kuo\"},{\"authorId\":\"32839616\",\"name\":\"M. LeGendre\"},{\"authorId\":\"47370428\",\"name\":\"Ruipeng Li\"},{\"authorId\":\"1905021\",\"name\":\"P. Lin\"},{\"authorId\":\"103230999\",\"name\":\"S. Lockhart\"},{\"authorId\":\"47150626\",\"name\":\"K. McCandless\"},{\"authorId\":\"2563307\",\"name\":\"Claudia Misale\"},{\"authorId\":\"144853146\",\"name\":\"J. Moreno\"},{\"authorId\":\"97493203\",\"name\":\"R. Neely\"},{\"authorId\":\"153162874\",\"name\":\"J. Nelson\"},{\"authorId\":\"1404327113\",\"name\":\"Rao Nimmakayala\"},{\"authorId\":\"1409618000\",\"name\":\"Kathryn M. O'Brien\"},{\"authorId\":\"1409617947\",\"name\":\"K. O'Brien\"},{\"authorId\":\"3771981\",\"name\":\"R. Pankajakshan\"},{\"authorId\":\"3999849\",\"name\":\"R. Pearce\"},{\"authorId\":\"39165349\",\"name\":\"S. Peles\"},{\"authorId\":\"1403392548\",\"name\":\"Phil Regier\"},{\"authorId\":\"1404327100\",\"name\":\"Steve Rennich\"},{\"authorId\":\"152268934\",\"name\":\"M. Schulz\"},{\"authorId\":\"89416195\",\"name\":\"Hammond Scott\"},{\"authorId\":\"48393879\",\"name\":\"J. Sexton\"},{\"authorId\":\"19265505\",\"name\":\"Kathleen Shoga\"},{\"authorId\":\"152646827\",\"name\":\"S. Sundram\"},{\"authorId\":\"1404327044\",\"name\":\"G. Thomas-Collignon\"},{\"authorId\":\"32977294\",\"name\":\"B. V. Essen\"},{\"authorId\":\"145161896\",\"name\":\"A. Voronin\"},{\"authorId\":\"3078972\",\"name\":\"Bob Walkup\"},{\"authorId\":\"31706152\",\"name\":\"L. Wang\"},{\"authorId\":\"144934811\",\"name\":\"Chris Ward\"},{\"authorId\":\"93152777\",\"name\":\"Hui-Fang Wen\"},{\"authorId\":\"122186733\",\"name\":\"D. A. White\"},{\"authorId\":\"39010343\",\"name\":\"C. Young\"},{\"authorId\":\"1404327273\",\"name\":\"Cyril Zeller\"},{\"authorId\":\"3075721\",\"name\":\"E. Zywicz\"}],\"doi\":\"10.1145/3295500.3356192\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96bea1ee2d552cbddb44c1f9ca60745bcdee9707\",\"title\":\"Preparation and optimization of a diverse workload for a large-scale heterogeneous system\",\"url\":\"https://www.semanticscholar.org/paper/96bea1ee2d552cbddb44c1f9ca60745bcdee9707\",\"venue\":\"SC\",\"year\":2019},{\"arxivId\":\"1907.12865\",\"authors\":[{\"authorId\":\"1486455596\",\"name\":\"Pau Panareda Busto\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/TPAMI.2018.2880750\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d18127d6a2f54cf04fec0f852bb87850def20007\",\"title\":\"Open Set Domain Adaptation for Image and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d18127d6a2f54cf04fec0f852bb87850def20007\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1806.10779\",\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"2201921\",\"name\":\"Z. Peng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e936def63d29c8e3d4b99788ee7290ff6274911a\",\"title\":\"Differentiable Learning-to-Normalize via Switchable Normalization\",\"url\":\"https://www.semanticscholar.org/paper/e936def63d29c8e3d4b99788ee7290ff6274911a\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1806.01810\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-030-01228-1_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"title\":\"Videos as Space-Time Region Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d7cbf2d3ea63d97b699cc04af98fea521459ee75\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2011.05358\",\"authors\":[{\"authorId\":\"49262921\",\"name\":\"Di Yang\"},{\"authorId\":\"1478813684\",\"name\":\"Rui Dai\"},{\"authorId\":null,\"name\":\"Yaohui Wang\"},{\"authorId\":\"116791593\",\"name\":\"Rupayan Mallick\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1096eac74cc81621e84de169163bb239a05c946\",\"title\":\"Selective Spatio-Temporal Aggregation Based Pose Refinement System: Towards Understanding Human Activities in Real-World Videos\",\"url\":\"https://www.semanticscholar.org/paper/e1096eac74cc81621e84de169163bb239a05c946\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.00179\",\"authors\":[{\"authorId\":\"1708502\",\"name\":\"R. Tolosana\"},{\"authorId\":\"1402712530\",\"name\":\"R. Vera-Rodr\\u00edguez\"},{\"authorId\":\"1701431\",\"name\":\"Julian Fierrez\"},{\"authorId\":\"144083995\",\"name\":\"A. Morales\"},{\"authorId\":\"1397258551\",\"name\":\"J. Ortega-Garcia\"}],\"doi\":\"10.1016/j.inffus.2020.06.014\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"96bcd003424aa4b2f9d6e8ade013a3a4293fecf5\",\"title\":\"DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection\",\"url\":\"https://www.semanticscholar.org/paper/96bcd003424aa4b2f9d6e8ade013a3a4293fecf5\",\"venue\":\"Inf. Fusion\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46868809\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1720627\",\"name\":\"Lai Man Po\"},{\"authorId\":\"49354358\",\"name\":\"Mengyang Liu\"},{\"authorId\":\"6260845\",\"name\":\"Yasar Abbas Ur Rehman\"},{\"authorId\":\"144981001\",\"name\":\"W. Ou\"},{\"authorId\":\"103425198\",\"name\":\"Yuzhi Zhao\"}],\"doi\":\"10.1016/j.eswa.2020.113203\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70ee88042c9bd87903b40b535973afecb6c2a49d\",\"title\":\"Data-level information enhancement: Motion-patch-based Siamese Convolutional Neural Networks for human activity recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/70ee88042c9bd87903b40b535973afecb6c2a49d\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"2006.05683\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"48513370\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"2692368\",\"name\":\"Muchen Li\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00634\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d92827d0c62ce499e199caadb83e5ba457bc8869\",\"title\":\"TubeTK: Adopting Tubes to Track Multi-Object in a One-Step Training Model\",\"url\":\"https://www.semanticscholar.org/paper/d92827d0c62ce499e199caadb83e5ba457bc8869\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726005\",\"name\":\"Ruibin Feng\"},{\"authorId\":\"13992566\",\"name\":\"Zongwei Zhou\"},{\"authorId\":\"143751204\",\"name\":\"Michael B. Gotway\"},{\"authorId\":\"50685341\",\"name\":\"Jianming Liang\"}],\"doi\":\"10.1007/978-3-030-60548-3_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39705e4a749981d0f88dc830cb2f23034af63d65\",\"title\":\"Parts2Whole: Self-supervised Contrastive Learning via Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/39705e4a749981d0f88dc830cb2f23034af63d65\",\"venue\":\"DART/DCL@MICCAI\",\"year\":2020},{\"arxivId\":\"2007.06643\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1007/978-3-030-58568-6_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"title\":\"Adversarial Background-Aware Loss for Weakly-supervised Temporal Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/5e8c230a7241836aeeb7f4c901cc8503ccdd9710\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.07524\",\"authors\":[{\"authorId\":\"47513307\",\"name\":\"Junjie Huang\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"123357350\",\"name\":\"F. Guo\"},{\"authorId\":\"143986385\",\"name\":\"G. Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.00574\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"378a320a78686acf3377ffebc05a7b9e878f80f2\",\"title\":\"The Devil Is in the Details: Delving Into Unbiased Data Processing for Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/378a320a78686acf3377ffebc05a7b9e878f80f2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.08483\",\"authors\":[{\"authorId\":\"145714956\",\"name\":\"Joshua A. Robinson\"},{\"authorId\":\"2594093\",\"name\":\"S. Jegelka\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"62f78de9b5bf2bfd074c0212cc22b94d759e2228\",\"title\":\"Strength from Weakness: Fast Learning Using Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/62f78de9b5bf2bfd074c0212cc22b94d759e2228\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2006.07665\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1749325163\",\"name\":\"Zanlin Ni\"},{\"authorId\":\"2415109\",\"name\":\"Jiahuan Zhou\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"115957649\",\"name\":\"Y. Wu\"},{\"authorId\":\"49178343\",\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00986\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d47e67c04e884cc83fff781ee9157f07acc0a558\",\"title\":\"Uncertainty-Aware Score Distribution Learning for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/d47e67c04e884cc83fff781ee9157f07acc0a558\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35723063\",\"name\":\"Md. Jamil-Ur Rahman\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CRV50864.2020.00035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"title\":\"Single-Stage End-to-End Temporal Activity Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"venue\":\"2020 17th Conference on Computer and Robot Vision (CRV)\",\"year\":2020},{\"arxivId\":\"1912.10405\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1609/AAAI.V34I07.6854\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"title\":\"Adversarial Cross-Domain Action Recognition with Co-Attention\",\"url\":\"https://www.semanticscholar.org/paper/94536d1a30f83bd0327b3a7e9f3ed1a66a9a3cdc\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2003.03749\",\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1109/CVPR42600.2020.01090\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96485bda4f4118da249cc8a898230281ac8040a7\",\"title\":\"Better Captioning With Sequence-Level Exploration\",\"url\":\"https://www.semanticscholar.org/paper/96485bda4f4118da249cc8a898230281ac8040a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7550195\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"1753356\",\"name\":\"Lele Chen\"},{\"authorId\":\"47474011\",\"name\":\"M. Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":\"10.1145/3394171.3414003\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"title\":\"Self-Paced Video Data Augmentation by Generative Adversarial Networks with Insufficient Samples\",\"url\":\"https://www.semanticscholar.org/paper/1635be0f2b8d2043c4f17973f8d12cd6c936a821\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"100468488\",\"name\":\"Z. Liu\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"46511118\",\"name\":\"Bin Zhu\"},{\"authorId\":\"1742506579\",\"name\":\"J. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"}],\"doi\":\"10.1145/3394171.3416276\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0b8cb284b37718375ff9f134f5c61b8fa098243\",\"title\":\"Person-level Action Recognition in Complex Events via TSD-TSM Networks\",\"url\":\"https://www.semanticscholar.org/paper/c0b8cb284b37718375ff9f134f5c61b8fa098243\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR42600.2020.00125\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"370298c893ebb3f55c0d869ea68c5ffa1805ca08\",\"title\":\"ActionBytes: Learning From Trimmed Videos to Localize Actions\",\"url\":\"https://www.semanticscholar.org/paper/370298c893ebb3f55c0d869ea68c5ffa1805ca08\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"13384075\",\"name\":\"Minzhi Zhu\"},{\"authorId\":\"2513605\",\"name\":\"Huiyuan Fu\"},{\"authorId\":\"40013029\",\"name\":\"Hua-Dong Ma\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3394171.3416298\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eaf34194a0e86fc5ed29a258594fa580b828e997\",\"title\":\"Enhancing Anomaly Detection in Surveillance Videos with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eaf34194a0e86fc5ed29a258594fa580b828e997\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48568841\",\"name\":\"Xuhong Li\"},{\"authorId\":\"1802711\",\"name\":\"Yves Grandvalet\"},{\"authorId\":\"1742818\",\"name\":\"F. Davoine\"},{\"authorId\":\"26329506\",\"name\":\"Jingchun Cheng\"},{\"authorId\":\"152586266\",\"name\":\"Yin Cui\"},{\"authorId\":\"1484726515\",\"name\":\"Han Zhang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"2580349\",\"name\":\"Yi-Hsuan Tsai\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1016/j.imavis.2019.103853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7eb789a31f05931d1d48c32fae459074fe19cb9c\",\"title\":\"Transfer learning in computer vision tasks: Remember where you come from\",\"url\":\"https://www.semanticscholar.org/paper/7eb789a31f05931d1d48c32fae459074fe19cb9c\",\"venue\":\"Image Vis. Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48321132\",\"name\":\"Y. Zou\"},{\"authorId\":\"9641665\",\"name\":\"X. Ren\"}],\"doi\":\"10.1007/978-981-15-8458-9_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"title\":\"An Efficient Action Recognition Framework Based on ELM and 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/a960a1e5184f5a90a7779cb7ffcc2d33140ec68f\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739631130\",\"name\":\"Fanjia Li\"},{\"authorId\":\"49298921\",\"name\":\"Juanjuan Li\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"50125448\",\"name\":\"Yonggang Xu\"},{\"authorId\":\"1826167\",\"name\":\"Hongsheng Yin\"},{\"authorId\":\"49195402\",\"name\":\"Gang Hua\"}],\"doi\":\"10.3390/s20185260\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"119e639868b3c0e1e9c3c8a1d5456cfbeb516eaa\",\"title\":\"Enhanced Spatial and Extended Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/119e639868b3c0e1e9c3c8a1d5456cfbeb516eaa\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2008.02448\",\"authors\":[{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1855095179\",\"name\":\"Pengwei Tang\"},{\"authorId\":\"3008849\",\"name\":\"Zhikang Zhou\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":\"10.1145/3394171.3414053\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"title\":\"Fine-grained Iterative Attention Network for Temporal Language Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/a4d78df0b175e3cbf811e652184f6b1e9d11caca\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"title\":\"Knowledge Fusion Transformers for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/5624963548a28f00a3aef20dca3bdbfe3d394d9d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1909523920\",\"name\":\"Jen-Kai Tsai\"},{\"authorId\":\"144926927\",\"name\":\"Chen-Chien Hsu\"},{\"authorId\":\"2653046\",\"name\":\"W. Wang\"},{\"authorId\":\"2814144\",\"name\":\"Shao-Kang Huang\"}],\"doi\":\"10.3390/s20174758\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9923da669485dfa56e69e4b8f4bb5620ea2161ba\",\"title\":\"Deep Learning-Based Real-Time Multiple-Person Action Recognition System\",\"url\":\"https://www.semanticscholar.org/paper/9923da669485dfa56e69e4b8f4bb5620ea2161ba\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2007.15841\",\"authors\":[{\"authorId\":\"1846789641\",\"name\":\"Maxat Alibayev\"},{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"97862006\",\"name\":\"Yu Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc46f865bd0cd6d7fc408a16dfdb04ad6c521654\",\"title\":\"Estimating Motion Codes from Demonstration Videos\",\"url\":\"https://www.semanticscholar.org/paper/cc46f865bd0cd6d7fc408a16dfdb04ad6c521654\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2275441\",\"name\":\"K. C. Yow\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00138-018-0961-8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"21f013c42c6b92903e462cc01a3f8e7068ae71be\",\"title\":\"Joint representation learning of appearance and motion for abnormal event detection\",\"url\":\"https://www.semanticscholar.org/paper/21f013c42c6b92903e462cc01a3f8e7068ae71be\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6624871\",\"name\":\"Dmytro Tkachenko\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b305ba8ae5ae48c86a3ba93073151f21382ccd39\",\"title\":\"EasyChair Preprint No 336 Human action recognition using fusion of modern deep convolutional and recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/b305ba8ae5ae48c86a3ba93073151f21382ccd39\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40930518\",\"name\":\"Nakul Agarwal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b345b1d902b2ca940c6e87f8ed41d05b674b32d\",\"title\":\"Exploring Action Recognition without using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/5b345b1d902b2ca940c6e87f8ed41d05b674b32d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413105978\",\"name\":\"Mounir Bendali-Braham\"},{\"authorId\":\"152947675\",\"name\":\"Jonathan Weber\"},{\"authorId\":\"2318564\",\"name\":\"G. Forestier\"},{\"authorId\":\"3482237\",\"name\":\"L. Idoumghar\"},{\"authorId\":\"145344693\",\"name\":\"Pierre-Alain Muller\"}],\"doi\":\"10.1109/ISPA.2019.8868704\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"846273f4e526022fd611dce55af1393ca1c84554\",\"title\":\"Transfer learning for the classification of video-recorded crowd movements\",\"url\":\"https://www.semanticscholar.org/paper/846273f4e526022fd611dce55af1393ca1c84554\",\"venue\":\"2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46696524\",\"name\":\"Lei Zhou\"},{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"47903936\",\"name\":\"Yali Wang\"},{\"authorId\":\"143970609\",\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"093da3310d98b3c09e2770c2a6aa49eeca58cebe\",\"title\":\"Trimmed Event Recognition : submission to ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/093da3310d98b3c09e2770c2a6aa49eeca58cebe\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121213082\",\"name\":\"Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"title\":\"Few-Shot Video Classification via Temporal Alignment Kaidi\",\"url\":\"https://www.semanticscholar.org/paper/03f33ad3f994e03b87ee2d1f711087c9efcd8cf6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.02419\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"20868803\",\"name\":\"Xiao-Bai Li\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"364ec52bba0bcd43c6deb588bf7f1d8269be84b9\",\"title\":\"Remote Photoplethysmograph Signal Measurement from Facial Videos Using Spatio-Temporal Networks\",\"url\":\"https://www.semanticscholar.org/paper/364ec52bba0bcd43c6deb588bf7f1d8269be84b9\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9024867\",\"name\":\"Jongkwang Hong\"},{\"authorId\":\"70374238\",\"name\":\"Bora Cho\"},{\"authorId\":\"49058762\",\"name\":\"Yongwon Hong\"},{\"authorId\":\"144036125\",\"name\":\"H. Byun\"}],\"doi\":\"10.3390/s19061382\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"title\":\"Contextual Action Cues from Camera Sensor for Multi-Stream Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17d77c03c2b552f2046e8c4674db64a3ef9b915b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"1384716902\",\"name\":\"Jin Bai\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"265010019d3d95568d237973b5d957c6aa80d7dd\",\"title\":\"SAFER : Fine-grained Activity Detection by Compositional Hypothesis Testing\",\"url\":\"https://www.semanticscholar.org/paper/265010019d3d95568d237973b5d957c6aa80d7dd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153065698\",\"name\":\"Yinghan Long\"},{\"authorId\":\"153181248\",\"name\":\"G. Srinivasan\"},{\"authorId\":\"9352814\",\"name\":\"Priyadarshini Panda\"},{\"authorId\":\"39703133\",\"name\":\"K. Roy\"}],\"doi\":\"10.1109/JETCAS.2019.2935004\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"212784b86f1bc4ddd43b621e35630579070a1b92\",\"title\":\"Structured Learning for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/212784b86f1bc4ddd43b621e35630579070a1b92\",\"venue\":\"IEEE Journal on Emerging and Selected Topics in Circuits and Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"title\":\"Rethinking Spatiotemporal Feature Learning For Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4fa0d73b8ba114578744c2ebaf610d2ca9694f45\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1903.09868\",\"authors\":[{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00564\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"db439bcc9088fb9a05c2777cf39a99eeb4e4c5cd\",\"title\":\"StartNet: Online Detection of Action Start in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/db439bcc9088fb9a05c2777cf39a99eeb4e4c5cd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46395663\",\"name\":\"Yong Wang\"},{\"authorId\":\"49185049\",\"name\":\"Shasha Wang\"},{\"authorId\":\"5510802\",\"name\":\"M. Zhou\"},{\"authorId\":\"144157223\",\"name\":\"Q. Jiang\"},{\"authorId\":\"1866334\",\"name\":\"Z. Tian\"}],\"doi\":\"10.1109/ACCESS.2019.2897060\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0a3a8730f5ce2c01c69f459452cfbbf6673f244\",\"title\":\"TS-I3D Based Hand Gesture Recognition Method With Radar Sensor\",\"url\":\"https://www.semanticscholar.org/paper/b0a3a8730f5ce2c01c69f459452cfbbf6673f244\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50241967\",\"name\":\"P. Huang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38283e35371f2a426305dee60e80cd28abb4f349\",\"title\":\"CMU-AML Submission to Moments in Time Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/38283e35371f2a426305dee60e80cd28abb4f349\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384279038\",\"name\":\"Shenqiang Yuan\"},{\"authorId\":\"145832297\",\"name\":\"Mei Xue\"},{\"authorId\":\"14875040\",\"name\":\"He Yi\"},{\"authorId\":\"1770701\",\"name\":\"Zhang Jin\"}],\"doi\":\"10.1109/ARSO46408.2019.8948745\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48e2cb007411d965b5ed323405e7148ea3fb0bd4\",\"title\":\"Attention alignment by linear space projection for video features extraction\",\"url\":\"https://www.semanticscholar.org/paper/48e2cb007411d965b5ed323405e7148ea3fb0bd4\",\"venue\":\"2019 IEEE International Conference on Advanced Robotics and its Social Impacts (ARSO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"148336006\",\"name\":\"Weisong Che\"},{\"authorId\":\"9391708\",\"name\":\"Shuhua Peng\"}],\"doi\":\"10.1109/IAEAC47372.2019.8997745\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d67b6135393720b4629c0eca95a16bf67e3f0364\",\"title\":\"3D Dual Path Networks and Multi-scale Feature Fusion for Human Motion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d67b6135393720b4629c0eca95a16bf67e3f0364\",\"venue\":\"2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"title\":\"Weakly Supervised EM Process For Temporal Localization Within Video\",\"url\":\"https://www.semanticscholar.org/paper/aaa5e03a926af11472a6c47dcbfe3941a0f2004b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"Shiwen Zhang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a19185b1cbb6588682318bb9ce649a611e889162\",\"title\":\"VIDEO-LEVEL REPRESENTATION LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/a19185b1cbb6588682318bb9ce649a611e889162\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"}],\"doi\":\"10.1184/R1/9823919\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"title\":\"Learning and Reasoning with Visual Correspondence in Time\",\"url\":\"https://www.semanticscholar.org/paper/dcd6c05a5ef1e6d9247f3eb0bff91ac0c3d7ac01\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.02872\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2149345\",\"name\":\"Chenxiao Guan\"},{\"authorId\":\"48616329\",\"name\":\"J. Goodman\"},{\"authorId\":\"50583301\",\"name\":\"Marc Moore\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5328a7024f820fafdab4165777807c2ecb855fe4\",\"title\":\"An Attempt towards Interpretable Audio-Visual Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5328a7024f820fafdab4165777807c2ecb855fe4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.13942\",\"authors\":[{\"authorId\":\"52170427\",\"name\":\"Boxiao Pan\"},{\"authorId\":\"30017683\",\"name\":\"Haoye Cai\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01088\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"title\":\"Spatio-Temporal Graph for Video Captioning With Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/a444d32f30d38fb0cb811fa1a9b601511244fb5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.06761\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882447\",\"name\":\"L. Noldus\"},{\"authorId\":\"47329105\",\"name\":\"Remco C. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00540\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"title\":\"Multitask Learning to Improve Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cca4d9e7831cad9d7b4e9693a1be9b6eaea8805\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564581635\",\"name\":\"Bassel S. Chawkv\"},{\"authorId\":\"37370786\",\"name\":\"Mohammed Marey\"},{\"authorId\":\"2382767\",\"name\":\"H. A. Shedeed\"}],\"doi\":\"10.1109/ICICIS46948.2019.9014841\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"title\":\"OA18: A New Office Actions Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/d28a487e0bf59d1f9bf0b27799ff0fbeb699a2e2\",\"venue\":\"2019 Ninth International Conference on Intelligent Computing and Information Systems (ICICIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445655\",\"name\":\"C. Zhang\"},{\"authorId\":\"49663261\",\"name\":\"W. Liu\"},{\"authorId\":\"91945776\",\"name\":\"J. Wu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/BigMM.2019.00-27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de265804b8a955308f42fee71d01dfe45fe83f3b\",\"title\":\"Improving Action Recognition with Valued Patches Exploiting\",\"url\":\"https://www.semanticscholar.org/paper/de265804b8a955308f42fee71d01dfe45fe83f3b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":\"1912.01373\",\"authors\":[{\"authorId\":\"2633472\",\"name\":\"Sung-Kwon Choo\"},{\"authorId\":\"69411484\",\"name\":\"Won-Kyo Seo\"},{\"authorId\":\"1707645\",\"name\":\"N. I. Cho\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"147c0ce7d67bf1274e3ab48791f0502983368296\",\"title\":\"Automatic Video Object Segmentation via Motion-Appearance-Stream Fusion and Instance-aware Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/147c0ce7d67bf1274e3ab48791f0502983368296\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47591075\",\"name\":\"F. Chen\"},{\"authorId\":\"2470289\",\"name\":\"Jinan Liu\"},{\"authorId\":\"49469656\",\"name\":\"Xin-ran Zhang\"},{\"authorId\":\"47405681\",\"name\":\"Hongen Liao\"}],\"doi\":\"10.1049/htl.2019.0072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1dae672830cec26901a175eb69be138dec8b197\",\"title\":\"Probability analysis of axillary lymph node metastasis in breast cancer patients using particle space-time distribution model\",\"url\":\"https://www.semanticscholar.org/paper/c1dae672830cec26901a175eb69be138dec8b197\",\"venue\":\"Healthcare technology letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144577\",\"name\":\"C. Wu\"},{\"authorId\":\"83483083\",\"name\":\"Jiayue Han\"},{\"authorId\":\"1723274\",\"name\":\"X. Li\"}],\"doi\":\"10.1109/ICIP.2019.8802910\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a1bc41a048a30919ba79fa88d9c4a03cb2942b47\",\"title\":\"Time-Asymmetric 3d Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a1bc41a048a30919ba79fa88d9c4a03cb2942b47\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1911.07757\",\"authors\":[{\"authorId\":\"67228021\",\"name\":\"Vivien Sainte Fare Garnot\"},{\"authorId\":\"115987954\",\"name\":\"Loic Landrieu\"},{\"authorId\":\"12465445\",\"name\":\"S. Giordano\"},{\"authorId\":\"2710204\",\"name\":\"Nesrine Chehata\"}],\"doi\":\"10.1109/cvpr42600.2020.01234\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e32d1023b01e122cf4b00580b8b21782ab33455\",\"title\":\"Satellite Image Time Series Classification With Pixel-Set Encoders and Temporal Self-Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e32d1023b01e122cf4b00580b8b21782ab33455\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151488176\",\"name\":\"B. Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"98482059\",\"name\":\"Shan Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/ICME.2019.00150\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d255b0ba6a3f6142a0c0402f28a8b1494861108\",\"title\":\"Affective Video Content Analyses by Using Cross-Modal Embedding Learning Features\",\"url\":\"https://www.semanticscholar.org/paper/7d255b0ba6a3f6142a0c0402f28a8b1494861108\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94300325\",\"name\":\"Myeongjun Kim\"},{\"authorId\":\"152952936\",\"name\":\"Taehun Kim\"},{\"authorId\":\"1942436\",\"name\":\"D. Kim\"}],\"doi\":\"10.1109/ICIP40778.2020.9191290\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d72bc2da13951086cc8c392d6e38722c44951c1\",\"title\":\"Spatio-Temporal Slowfast Self-Attention Network For Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d72bc2da13951086cc8c392d6e38722c44951c1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"174d1b037e62ab7ae5f73b597b025d5faf0fadb4\",\"title\":\"Deep Reinforcement Sequence Learning for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/174d1b037e62ab7ae5f73b597b025d5faf0fadb4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.06959\",\"authors\":[{\"authorId\":\"1401781990\",\"name\":\"F. Haghighi\"},{\"authorId\":\"21811029\",\"name\":\"M. R. Taher\"},{\"authorId\":\"1389392654\",\"name\":\"Zongwei Zhou\"},{\"authorId\":\"143751204\",\"name\":\"Michael B. Gotway\"},{\"authorId\":\"1485304039\",\"name\":\"Jianming Liang\"}],\"doi\":\"10.1007/978-3-030-59710-8_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a370d5a874d0ced8c3ae1e8cdd4aea6f1d321859\",\"title\":\"Learning Semantics-enriched Representation via Self-discovery, Self-classification, and Self-restoration\",\"url\":\"https://www.semanticscholar.org/paper/a370d5a874d0ced8c3ae1e8cdd4aea6f1d321859\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31595791\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"150341144\",\"name\":\"Wenxuan Zhang\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/TMM.2020.2965434\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"title\":\"Spatio-Temporal Attention Networks for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/2ea173f972d39b8631e9ac8fe59a947c70ba31e3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143838039\",\"name\":\"J. Quiroga\"},{\"authorId\":\"1388438702\",\"name\":\"H. Carrillo\"},{\"authorId\":\"50424329\",\"name\":\"E. Maldonado\"},{\"authorId\":\"153833567\",\"name\":\"J. Ruiz\"},{\"authorId\":\"101207901\",\"name\":\"L. M. Zapata\"}],\"doi\":\"10.1109/CVPRW50498.2020.00455\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6957b1881a3ffad8fce745d0bc003ba117c01101\",\"title\":\"As Seen on TV: Automatic Basketball Video Production using Gaussian-based Actionness and Game States Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6957b1881a3ffad8fce745d0bc003ba117c01101\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2007.14937\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"title\":\"Learning Video Representations from Textual Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/a1e68a2ec3a813576e2a2ba7845214862d94815e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"1491642326\",\"name\":\"Qingzhe Pan\"},{\"authorId\":\"122210974\",\"name\":\"Yu-Han Cao\"},{\"authorId\":\"32273141\",\"name\":\"Z. Zhao\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"}],\"doi\":\"10.1016/j.patcog.2020.107356\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"title\":\"SGM-Net: Skeleton-guided multimodal network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6cd1d88ab7439d73d1163c2eca77ce7134c908f\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2006.14749\",\"authors\":[{\"authorId\":\"144377735\",\"name\":\"O. Lima\"},{\"authorId\":\"145062167\",\"name\":\"S. Franklin\"},{\"authorId\":\"1768842012\",\"name\":\"Shreshtha Basu\"},{\"authorId\":\"1768848143\",\"name\":\"Blake Karwoski\"},{\"authorId\":\"1768817523\",\"name\":\"Annet George\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"54d71afa5ec350958a920b637e37f78e2654563d\",\"title\":\"Deepfake Detection using Spatiotemporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/54d71afa5ec350958a920b637e37f78e2654563d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b217f438697476c3fbffd3f1595c17fd05ee89\",\"title\":\"Adapting computer vision models to limitations on input dimensionality and model complexity\",\"url\":\"https://www.semanticscholar.org/paper/38b217f438697476c3fbffd3f1595c17fd05ee89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.02639\",\"authors\":[{\"authorId\":\"2031911039\",\"name\":\"Edward Fish\"},{\"authorId\":\"2014512338\",\"name\":\"Andrew Gilbert\"},{\"authorId\":\"47371758\",\"name\":\"Jon Weinbren\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffe1f5c2d579cc63a785023f4df11207504fbc1c\",\"title\":\"Rethinking movie genre classification with fine-grained semantic clustering\",\"url\":\"https://www.semanticscholar.org/paper/ffe1f5c2d579cc63a785023f4df11207504fbc1c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49051296\",\"name\":\"J. Zhang\"},{\"authorId\":\"2077989\",\"name\":\"Rahul C. Deo\"}],\"doi\":\"10.1161/CIRCULATIONAHA.119.039291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2cb1878b5138e5cd0d14ee7fe3e2debb27609121\",\"title\":\"Response by Zhang and Deo to Letter Regarding Article, \\\"Fully Automated Echocardiogram Interpretation in Clinical Practice: Feasibility and Diagnostic Accuracy\\\".\",\"url\":\"https://www.semanticscholar.org/paper/2cb1878b5138e5cd0d14ee7fe3e2debb27609121\",\"venue\":\"Circulation\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"title\":\"Multi-Modal Sensor Fusion: A Principled Approach to Optimality.\",\"url\":\"https://www.semanticscholar.org/paper/c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66148232\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":\"10.1109/ICCV.2019.00879\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70660cb3af4e19c74681238c7854e3d341654b2d\",\"title\":\"Hallucinating IDT Descriptors and I3D Optical Flow Features for Action Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/70660cb3af4e19c74681238c7854e3d341654b2d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8549944\",\"name\":\"J. Li\"},{\"authorId\":\"6820648\",\"name\":\"Xianglong Liu\"},{\"authorId\":\"47473953\",\"name\":\"Mingyuan Zhang\"},{\"authorId\":\"47859105\",\"name\":\"De-qing Wang\"}],\"doi\":\"10.1016/j.patcog.2019.107037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7d8bd083690391c0a40800321554f3a55a2125\",\"title\":\"Spatio-temporal deformable 3D ConvNets with attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec7d8bd083690391c0a40800321554f3a55a2125\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1912.06617\",\"authors\":[{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR42600.2020.00095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1bc01f26b29282855e7cc997a737aa72697a4cac\",\"title\":\"Action Modifiers: Learning From Adverbs in Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1bc01f26b29282855e7cc997a737aa72697a4cac\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1909.09272\",\"authors\":[{\"authorId\":\"46651496\",\"name\":\"Chengxi Li\"},{\"authorId\":\"144098758\",\"name\":\"Yue Meng\"},{\"authorId\":\"1717715\",\"name\":\"S. Chan\"},{\"authorId\":\"27018486\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICRA40945.2020.9197057\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a92cad15e8e4c03b524455a21da6dcc80d425274\",\"title\":\"Learning 3D-aware Egocentric Spatial-Temporal Interaction via Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/a92cad15e8e4c03b524455a21da6dcc80d425274\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"1805.00932\",\"authors\":[{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"7769997\",\"name\":\"Y. Li\"},{\"authorId\":\"46208883\",\"name\":\"Ashwin Bharambe\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":\"10.1007/978-3-030-01216-8_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f885fd46064d271d4404cf9bb3d758e1a6f8d55\",\"title\":\"Exploring the Limits of Weakly Supervised Pretraining\",\"url\":\"https://www.semanticscholar.org/paper/0f885fd46064d271d4404cf9bb3d758e1a6f8d55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1712.00108\",\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-01264-9_11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8a990e81436422ebdf5de97c01c98b511dd4192c\",\"title\":\"Graph Distillation for Action Detection with Privileged Modalities\",\"url\":\"https://www.semanticscholar.org/paper/8a990e81436422ebdf5de97c01c98b511dd4192c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2577842\",\"name\":\"R. An\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"50444385\",\"name\":\"Q. Li\"}],\"doi\":\"10.1109/ICSP.2018.8652415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"751df4b242cddabdf9c4a542de15e90e79036ce9\",\"title\":\"Joint Embedding with Multi-Task Learning for Multi-Label Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/751df4b242cddabdf9c4a542de15e90e79036ce9\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":\"2012.09434\",\"authors\":[{\"authorId\":\"48031771\",\"name\":\"X. Liu\"},{\"authorId\":\"72285615\",\"name\":\"Yao Hu\"},{\"authorId\":\"98807701\",\"name\":\"Song Bai\"},{\"authorId\":\"1430778662\",\"name\":\"Fei Ding\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"2038266421\",\"name\":\"Philip H.S. Torr Huazhong University of Science\"},{\"authorId\":\"103081934\",\"name\":\"Technology\"},{\"authorId\":\"2038266423\",\"name\":\"Alibaba Group\"},{\"authorId\":\"51909023\",\"name\":\"U. O. Oxford\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"title\":\"Multi-shot Temporal Event Localization: a Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/db1b0d0e70f29b0018d1a9462d98dd39559f3e4a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.02540\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"607048b431cea997ae9dd01f029a73c502d0273f\",\"title\":\"Learning Spatio-Temporal Features with Two-Stream Deep 3D CNNs for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/607048b431cea997ae9dd01f029a73c502d0273f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1904.02422\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00240\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"title\":\"Resource Efficient 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b4f307750b6e192239dff6f80f203dcf9e05cb5d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1904.07774\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"102575548\",\"name\":\"Cheston Tan Yin Chet\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":\"10.1109/WACV45572.2020.9093263\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cf8d2362335ffd9706f61e70b65478517ce7f560\",\"title\":\"Weakly Supervised Gaussian Networks for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/cf8d2362335ffd9706f61e70b65478517ce7f560\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2012.05342\",\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"title\":\"3D attention mechanism for fine-grained classification of table tennis strokes using a Twin Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6b7bc12da85925efeb297cadf0a47c6c6ec7ea\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94385031\",\"name\":\"Sd Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e41271876ea38ae51c6fae7822e4c1b4b4542df5\",\"title\":\"SEMI-SUPERVISED DEEP LEARNING WITH APPLICATIONS IN SURGICAL VIDEO ANALYSIS AND BIOINFORMATICS\",\"url\":\"https://www.semanticscholar.org/paper/e41271876ea38ae51c6fae7822e4c1b4b4542df5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.06582\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"3468296\",\"name\":\"Iuliia Kotseruba\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"472b3df8920f0939dda0a80bdc51e293130c1124\",\"title\":\"Pedestrian Action Anticipation using Contextual Feature Fusion in Stacked RNNs\",\"url\":\"https://www.semanticscholar.org/paper/472b3df8920f0939dda0a80bdc51e293130c1124\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004671930\",\"name\":\"Zhenzhi Wang\"},{\"authorId\":\"152536294\",\"name\":\"Ziteng Gao\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"1911510\",\"name\":\"Z. Li\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff80201906d5534dc186e0821ada754dd9ab34e2\",\"title\":\"Boundary-Aware Cascade Networks for Temporal Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ff80201906d5534dc186e0821ada754dd9ab34e2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.10967\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-58452-8_41\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"994481d46df92709b61614f5e756e40df4117622\",\"title\":\"Forecasting Human-Object Interaction: Joint Prediction of Motor Attention and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/994481d46df92709b61614f5e756e40df4117622\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.07999\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.706\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"title\":\"What is More Likely to Happen Next? Video-and-Language Future Event Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9f2a7a912624d850cf9e0587263b4fcd88d44f18\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1987325669\",\"name\":\"Juana Gonz\\u00e1lez-Bueno Puyal\"},{\"authorId\":\"34601420\",\"name\":\"K. Bhatia\"},{\"authorId\":\"34753746\",\"name\":\"Patrick Brandao\"},{\"authorId\":\"49613586\",\"name\":\"O. Ahmad\"},{\"authorId\":\"49943518\",\"name\":\"D. Toth\"},{\"authorId\":\"87234114\",\"name\":\"Rawen Kader\"},{\"authorId\":\"2906727\",\"name\":\"L. Lovat\"},{\"authorId\":\"1690641\",\"name\":\"Peter Mountney\"},{\"authorId\":\"1750941734\",\"name\":\"D. Stoyanov\"}],\"doi\":\"10.1007/978-3-030-59725-2_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd51b549e6fcbcaabfb6b464d5bce3b2797f4c6\",\"title\":\"Endoscopic Polyp Segmentation Using a Hybrid 2D/3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/ebd51b549e6fcbcaabfb6b464d5bce3b2797f4c6\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.09046\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"40600020\",\"name\":\"Sheide Chammas\"},{\"authorId\":\"20048351\",\"name\":\"Vihan Jain\"},{\"authorId\":\"2042413\",\"name\":\"E. Ie\"},{\"authorId\":\"39543696\",\"name\":\"Fei Sha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe21d30afa60f8ab72da309ca0a80eee1ac07a66\",\"title\":\"A Hierarchical Multi-Modal Encoder for Moment Localization in Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/fe21d30afa60f8ab72da309ca0a80eee1ac07a66\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00945\",\"authors\":[{\"authorId\":\"10384643\",\"name\":\"Yong-Lu Li\"},{\"authorId\":\"151484848\",\"name\":\"Liang Xu\"},{\"authorId\":\"2128016\",\"name\":\"Xinpeng Liu\"},{\"authorId\":\"49444914\",\"name\":\"X. Huang\"},{\"authorId\":\"1409933106\",\"name\":\"Yue Xu\"},{\"authorId\":\"3826706\",\"name\":\"S. Wang\"},{\"authorId\":\"122851212\",\"name\":\"Haoshu Fang\"},{\"authorId\":\"145136705\",\"name\":\"Ze Ma\"},{\"authorId\":\"48622851\",\"name\":\"Mingyang Chen\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.00046\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"title\":\"PaStaNet: Toward Human Activity Knowledge Engine\",\"url\":\"https://www.semanticscholar.org/paper/37d2e1c24e4da0021504667cf528f1d7ef2291dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-030-01228-1_38\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"title\":\"In the Eye of Beholder: Joint Learning of Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/fa1723b216b1f41b085b62b450b7b0bd9f2fd281\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73774503\",\"name\":\"Adrian MeidellFiorito\"},{\"authorId\":\"30631464\",\"name\":\"Andreas \\u00d8stvik\"},{\"authorId\":\"1789250\",\"name\":\"E. Smistad\"},{\"authorId\":\"145251037\",\"name\":\"S. Leclerc\"},{\"authorId\":\"145288087\",\"name\":\"O. Bernard\"},{\"authorId\":\"52348537\",\"name\":\"L. L\\u00f8vstakken\"}],\"doi\":\"10.1109/ULTSYM.2018.8580137\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbf646404e642792f6c7d56b1aa7d20b30d77679\",\"title\":\"Detection of Cardiac Events in Echocardiography Using 3D Convolutional Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cbf646404e642792f6c7d56b1aa7d20b30d77679\",\"venue\":\"2018 IEEE International Ultrasonics Symposium (IUS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47535039\",\"name\":\"Chenchen Liu\"},{\"authorId\":\"152804227\",\"name\":\"Y. Jin\"},{\"authorId\":\"46321208\",\"name\":\"K. Xu\"},{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/cvpr42600.2020.01085\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"72e10d154869adbe98c0f7301ad50d92fbf69420\",\"title\":\"Beyond Short-Term Snippet: Video Relation Detection With Spatio-Temporal Global Context\",\"url\":\"https://www.semanticscholar.org/paper/72e10d154869adbe98c0f7301ad50d92fbf69420\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.12737\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"35663637\",\"name\":\"R. Sanford\"},{\"authorId\":\"145556010\",\"name\":\"M. Javan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/cvpr42600.2020.00092\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"title\":\"Actor-Transformers for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c4668668c3b9f0bda4d207b3e6d397034977f0e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1906.02634\",\"authors\":[{\"authorId\":\"3319373\",\"name\":\"Dirk Weissenborn\"},{\"authorId\":\"2556289\",\"name\":\"Oscar T\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e763fdc9ae56826ff799163ea035b29bffd8ea6f\",\"title\":\"Scaling Autoregressive Video Models\",\"url\":\"https://www.semanticscholar.org/paper/e763fdc9ae56826ff799163ea035b29bffd8ea6f\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0008958003510358\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e9213f65145533551043f36b542ee549b08089d3\",\"title\":\"Multi-stream Architecture with Symmetric Extended Visual Rhythms for Deep Learning Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e9213f65145533551043f36b542ee549b08089d3\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":\"1812.05038\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"}],\"doi\":\"10.1109/CVPR.2019.00037\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"title\":\"Long-Term Feature Banks for Detailed Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.11195\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1007/978-3-030-01246-5_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe82d072a8d13cfefcd575db893f3374251f04a8\",\"title\":\"Multi-Fiber Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe82d072a8d13cfefcd575db893f3374251f04a8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1007/978-3-030-01225-0_42\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c7a962e1076949d8395e8de6aaae026f673b184\",\"title\":\"Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/8c7a962e1076949d8395e8de6aaae026f673b184\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1806.06157\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"2759569\",\"name\":\"N. Neverova\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-01261-8_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"49615e80bac044b92d2edec8b053965e846486f2\",\"title\":\"Object Level Visual Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/49615e80bac044b92d2edec8b053965e846486f2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2001.03905\",\"authors\":[{\"authorId\":\"2849892\",\"name\":\"Hongguang Zhang\"},{\"authorId\":\"48571183\",\"name\":\"Liyong Zhang\"},{\"authorId\":\"50844674\",\"name\":\"Xiaojuan Qi\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1007/978-3-030-58558-7_31\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"161ecde59203eaaa5347cdead5a1090f2a1669a2\",\"title\":\"Few-Shot Action Recognition with Permutation-Invariant Attention\",\"url\":\"https://www.semanticscholar.org/paper/161ecde59203eaaa5347cdead5a1090f2a1669a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.07514\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR42600.2020.01082\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"title\":\"Local-Global Video-Text Interactions for Temporal Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7e3d5b20e5df692deb80d9e100e4f34c1a8f8031\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.06130\",\"authors\":[{\"authorId\":\"19310335\",\"name\":\"Sagie Benaim\"},{\"authorId\":\"2077454\",\"name\":\"A. Ephrat\"},{\"authorId\":\"49618488\",\"name\":\"Oran Lang\"},{\"authorId\":\"2138834\",\"name\":\"Inbar Mosseri\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"},{\"authorId\":\"3829997\",\"name\":\"M. Rubinstein\"},{\"authorId\":\"144611617\",\"name\":\"M. Irani\"},{\"authorId\":\"2112779\",\"name\":\"Tali Dekel\"}],\"doi\":\"10.1109/cvpr42600.2020.00994\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1708ca69799e5ae2614cc61f79ff164fd6d6baa4\",\"title\":\"SpeedNet: Learning the Speediness in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1708ca69799e5ae2614cc61f79ff164fd6d6baa4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1812.10328\",\"authors\":[{\"authorId\":\"51264689\",\"name\":\"S. Azar\"},{\"authorId\":\"51443392\",\"name\":\"Mina Ghadimi Atigh\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fbd67c047fdcec3ec157173b4dd28b44cdb3589\",\"title\":\"A Multi-Stream Convolutional Neural Network Framework for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fbd67c047fdcec3ec157173b4dd28b44cdb3589\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.03116\",\"authors\":[{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0450f376334b8c4bd57d34a35ab060ddc3595ee\",\"title\":\"Weakly Supervised Action Segmentation Using Mutual Consistency\",\"url\":\"https://www.semanticscholar.org/paper/c0450f376334b8c4bd57d34a35ab060ddc3595ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500658657\",\"name\":\"Khaled Saleh\"},{\"authorId\":\"1922050\",\"name\":\"M. Hossny\"},{\"authorId\":\"1743136\",\"name\":\"S. Nahavandi\"}],\"doi\":\"10.1016/j.neucom.2019.12.091\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0969dca07d83e6df682cd804c3dc7e9e3dacffe\",\"title\":\"Spatio-temporal DenseNet for real-time intent prediction of pedestrians in urban traffic environments\",\"url\":\"https://www.semanticscholar.org/paper/a0969dca07d83e6df682cd804c3dc7e9e3dacffe\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2003.07514\",\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60e02426feb3ca9345659f54deaf5070110f530a\",\"title\":\"Predictively Encoded Graph Convolutional Network for Noise-Robust Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60e02426feb3ca9345659f54deaf5070110f530a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2698604\",\"name\":\"J. Miyao\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":\"10.1007/978-981-15-4818-5_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b57e0f07d5752e30d8becd80d78dfeae3a1d62b2\",\"title\":\"Short-Term Action Recognition by 3D Convolutional Neural Network with Pixel-Wise Evidences\",\"url\":\"https://www.semanticscholar.org/paper/b57e0f07d5752e30d8becd80d78dfeae3a1d62b2\",\"venue\":\"IW-FCV\",\"year\":2020},{\"arxivId\":\"1910.06934\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a89c6d101ece92390b80b6196555fa22de0e458\",\"title\":\"Human Action Recognition with Multi-Laplacian Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3a89c6d101ece92390b80b6196555fa22de0e458\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89417685\",\"name\":\"Snehashis Majhi\"},{\"authorId\":\"151182511\",\"name\":\"Ratnaka Dash\"},{\"authorId\":\"1715343\",\"name\":\"P. K. Sa\"}],\"doi\":\"10.1109/ICCCNT49239.2020.9225378\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"929812032381034940b9d79d3035d1de8efe144a\",\"title\":\"Temporal Pooling in Inflated 3DCNN for Weakly-supervised Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/929812032381034940b9d79d3035d1de8efe144a\",\"venue\":\"2020 11th International Conference on Computing, Communication and Networking Technologies (ICCCNT)\",\"year\":2020},{\"arxivId\":\"1811.07468\",\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"34097174\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1609/aaai.v33i01.33018618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"title\":\"Multi-scale 3D Convolution Network for Video Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/242e19b95f1cf77a74f1a99a899a8dc7d34f7c10\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"2453402\",\"name\":\"Meng-Yao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53ea5e0448c309c3614bba25bac58f46f06690c7\",\"title\":\"Zero-Shot Generation of Human-Object Interaction Videos\",\"url\":\"https://www.semanticscholar.org/paper/53ea5e0448c309c3614bba25bac58f46f06690c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.10319\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"2273005\",\"name\":\"Qijie Zhao\"},{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"145413801\",\"name\":\"Y. Fu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10370545ea747c6adec26142dbfc499681876570\",\"title\":\"Exploiting Spatial-Temporal Modelling and Multi-Modal Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10370545ea747c6adec26142dbfc499681876570\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30075877\",\"name\":\"W. Ye\"},{\"authorId\":\"120971374\",\"name\":\"J. Cheng\"},{\"authorId\":\"145976802\",\"name\":\"F. Yang\"},{\"authorId\":\"48615395\",\"name\":\"Y. Xu\"}],\"doi\":\"10.1109/access.2019.2918808\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"title\":\"Two-Stream Convolutional Network for Improving Activity Recognition Using Convolutional Long Short-Term Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/12849c0cd645ec587b34bec4c7d961c69c91bd11\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"},{\"authorId\":\"7135663\",\"name\":\"Y. Wang\"},{\"authorId\":\"144563871\",\"name\":\"Gang Pan\"}],\"doi\":\"10.1109/TIP.2019.2901707\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"title\":\"Deep Attention Network for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/355f769cc896ff3ea302423587c9a1b7c2301c4e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"879eca33fa23688eb0b586e6b84a3a30351541c5\",\"title\":\"Dynamic Pattern Synthesis by Spatial-Temporal Generative ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/879eca33fa23688eb0b586e6b84a3a30351541c5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.00303\",\"authors\":[{\"authorId\":\"144282337\",\"name\":\"B. McIntosh\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"title\":\"Multi-modal Capsule Routing for Actor and Action Video Segmentation Conditioned on Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b181ae8ed315ceb8f03332ba02ef0849adbe5b4c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. J. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"Anelia Angelova\"},{\"authorId\":\"1766489\",\"name\":\"Michael S. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d18b3dcdc27c4dd75cb95003800a3c3da4816686\",\"title\":\"Learning Differentiable Grammars for Continuous Data\",\"url\":\"https://www.semanticscholar.org/paper/d18b3dcdc27c4dd75cb95003800a3c3da4816686\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1909.03252\",\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"145913039\",\"name\":\"Y. Rong\"},{\"authorId\":\"144259957\",\"name\":\"P. Zhao\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/ICCV.2019.00719\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd8e725159159ca2169d302f6cb510e3b1cc1a4b\",\"title\":\"Graph Convolutional Networks for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/fd8e725159159ca2169d302f6cb510e3b1cc1a4b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"}],\"doi\":\"10.25781/KAUST-VR909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"title\":\"Efficient Localization of Human Actions and Moments in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5c549fd9172f2d1be80cc77b0de9e90d3416463\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"title\":\"End-to-End Multimodal Dialog Systems with Hierarchical Multimodal Attention on Video Features\",\"url\":\"https://www.semanticscholar.org/paper/fd6a2c7bbb54ad5c1350eb02718211fe86e125e5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.09570\",\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8ca231a21c28c57d15ace1d9057879046a7f08c\",\"title\":\"EgoReID: Person re-identification in Egocentric Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/c8ca231a21c28c57d15ace1d9057879046a7f08c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1808.09892\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1007/978-3-030-03840-3_28\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"title\":\"Top-down Attention Recurrent VLAD Encoding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"venue\":\"AI*IA\",\"year\":2018},{\"arxivId\":\"1905.08586\",\"authors\":[{\"authorId\":\"34567611\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"8020375\",\"name\":\"Yueming Lyu\"},{\"authorId\":\"145821440\",\"name\":\"X. Shen\"},{\"authorId\":\"1807998\",\"name\":\"I. Tsang\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c97556edbc192896cc55395f8f21fe0ff148580\",\"title\":\"Marginalized Average Attentional Network for Weakly-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/6c97556edbc192896cc55395f8f21fe0ff148580\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1909.05426\",\"authors\":[{\"authorId\":\"3308345\",\"name\":\"Siyuan Dong\"},{\"authorId\":\"152532021\",\"name\":\"A. Rodr\\u00edguez\"}],\"doi\":\"10.1109/IROS40897.2019.8968204\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31c0525e2e4dd88d97fa76995e553ed1dc171f9d\",\"title\":\"Tactile-Based Insertion for Dense Box-Packing\",\"url\":\"https://www.semanticscholar.org/paper/31c0525e2e4dd88d97fa76995e553ed1dc171f9d\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21240743\",\"name\":\"Yongqiang Kong\"},{\"authorId\":\"49025023\",\"name\":\"J. Huang\"},{\"authorId\":\"2898447\",\"name\":\"Shanshan Huang\"},{\"authorId\":\"2999650\",\"name\":\"Zhengang Wei\"},{\"authorId\":\"3050837\",\"name\":\"Shengke Wang\"}],\"doi\":\"10.1109/SmartWorld.2018.00089\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"title\":\"Dynamic Representation Learning for Video Action Recognition Using Temporal Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/427be2984bc0ff3831480c6dd6ae9c59c25603e7\",\"venue\":\"2018 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46697879\",\"name\":\"Jing Zhang\"},{\"authorId\":\"47095832\",\"name\":\"Yuting Wu\"},{\"authorId\":\"1712224652\",\"name\":\"Jinghui Liu\"},{\"authorId\":\"2989256\",\"name\":\"Peiguang Jing\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1109/ACCESS.2020.2992436\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33ca6b2f3c9de6db4587fc83bcc8a934c527fc5\",\"title\":\"Low-Rank Regularized Multimodal Representation for Micro-Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/b33ca6b2f3c9de6db4587fc83bcc8a934c527fc5\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.08708\",\"authors\":[{\"authorId\":\"50227009\",\"name\":\"Uttaran Bhattacharya\"},{\"authorId\":\"1385119825\",\"name\":\"Christian Roncal\"},{\"authorId\":\"9214782\",\"name\":\"Trisha Mittal\"},{\"authorId\":\"30144577\",\"name\":\"Rohan Chandra\"},{\"authorId\":\"2979367\",\"name\":\"Aniket Bera\"},{\"authorId\":\"1699159\",\"name\":\"D. Manocha\"}],\"doi\":\"10.1007/978-3-030-58607-2_9\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a718341f5db00071de408a4bd52e92541052e13\",\"title\":\"Take an Emotion Walk: Perceiving Emotions from Gaits Using Hierarchical Attention Pooling and Affective Mapping\",\"url\":\"https://www.semanticscholar.org/paper/3a718341f5db00071de408a4bd52e92541052e13\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.09982\",\"authors\":[{\"authorId\":\"1993669388\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"31267246\",\"name\":\"L. Zhang\"},{\"authorId\":\"1993529318\",\"name\":\"Junke Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"title\":\"Depth Guided Adaptive Meta-Fusion Network for Few-shot Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8abe9a4d432cc4c43a11f9336cd105d1be30ae92\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1804.09235\",\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"143673251\",\"name\":\"D. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"title\":\"ON THE EFFECTIVENESS OF TASK GRANULARITY FOR TRANSFER LEARNING\",\"url\":\"https://www.semanticscholar.org/paper/26106bcf799c66d719e0cdde6d9fbd3f7eb55e13\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"153197501\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2020.03.066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a84ef229e2349fcd59e7f235acf9e697b31462ff\",\"title\":\"Gated forward refinement network for action segmentation\",\"url\":\"https://www.semanticscholar.org/paper/a84ef229e2349fcd59e7f235acf9e697b31462ff\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84388107\",\"name\":\"Tam\\u00e1s Kar\\u00e1csony\"},{\"authorId\":\"1404459862\",\"name\":\"Anna Mira Loesch-Biffar\"},{\"authorId\":\"3108588\",\"name\":\"C. Vollmar\"},{\"authorId\":\"3484936\",\"name\":\"S. Noachtar\"},{\"authorId\":\"120779070\",\"name\":\"J. P. Cunha\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054649\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3987c48f65cf3e358ca58d75f10cd9a6a88ff24b\",\"title\":\"A Deep Learning Architecture for Epileptic Seizure Classification Based on Object and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3987c48f65cf3e358ca58d75f10cd9a6a88ff24b\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9521309\",\"name\":\"Reem Alfaifi\"},{\"authorId\":\"46845102\",\"name\":\"A M Artoli\"}],\"doi\":\"10.1007/s42979-020-00293-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"title\":\"Human Action Prediction with 3D-CNN\",\"url\":\"https://www.semanticscholar.org/paper/582f942b2e34efdd2cf7843d09417e2cf43677a7\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3894528\",\"name\":\"C. Ozer\"},{\"authorId\":\"34930176\",\"name\":\"F. Gurkan\"},{\"authorId\":\"1747583\",\"name\":\"Bilge G\\u00fcnsel\"}],\"doi\":\"10.1007/978-3-030-27272-2_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcab3f2ecda8e00314eb74f46d82c06d1d627f7f\",\"title\":\"Target Aware Visual Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/bcab3f2ecda8e00314eb74f46d82c06d1d627f7f\",\"venue\":\"ICIAR\",\"year\":2019},{\"arxivId\":\"1904.04231\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"title\":\"Relational Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/6edfe8350da54cd563158b0d7d0c664f16cb91a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2001.04627\",\"authors\":[{\"authorId\":\"38403207\",\"name\":\"L. Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"title\":\"Hallucinating Statistical Moment and Subspace Descriptors from Object and Saliency Detectors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8e35dc0f90a721d819f74633c8d0d7e4c5a7973e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31745469\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/s11263-019-01211-2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/9c643f3d4d7d52ab9b64911bb085438ca096275a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2003.08275\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2975022cb314045d1471c407454bcdf8b7cb5fef\",\"title\":\"PIC: Permutation Invariant Convolution for Recognizing Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/2975022cb314045d1471c407454bcdf8b7cb5fef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71039664\",\"name\":\"Hiroaki Ishioka\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"48087997\",\"name\":\"Y. Man\"},{\"authorId\":\"1665822545\",\"name\":\"Kris Kitani\"}],\"doi\":\"10.22260/isarc2020/0092\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b116e130b3fa9ee7c007f02c3d19ed35180aec8d\",\"title\":\"Single Camera Worker Detection, Tracking and Action Recognition in Construction Site\",\"url\":\"https://www.semanticscholar.org/paper/b116e130b3fa9ee7c007f02c3d19ed35180aec8d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/TCSVT.2018.2864148\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"title\":\"Action Recognition With Spatio\\u2013Temporal Visual Attention on Skeleton Image Sequences\",\"url\":\"https://www.semanticscholar.org/paper/08cc8c38c25f2bc87d44e35abbccd6a88eb5103b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"2012.08512\",\"authors\":[{\"authorId\":\"2655351\",\"name\":\"Tarun Kalluri\"},{\"authorId\":\"2004879394\",\"name\":\"Deepak Pathak\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"title\":\"FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/5ca230da787b25643150c8b2df474e2d6d8ec7c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.01639\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"98758720\",\"name\":\"I. Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00594\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"title\":\"Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/5f0c8b5be40518b0ce7876ab152c2b9696ef713e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720766162\",\"name\":\"Shadi Albarqouni\"},{\"authorId\":\"3199900\",\"name\":\"S. Bakas\"},{\"authorId\":\"3371321\",\"name\":\"K. Kamnitsas\"}],\"doi\":\"10.1007/978-3-030-60548-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57046218c192493c55cf0aa09fc8921aed1bea9d\",\"title\":\"Domain Adaptation and Representation Transfer, and Distributed and Collaborative Learning: Second MICCAI Workshop, DART 2020, and First MICCAI Workshop, DCL 2020, Held in Conjunction with MICCAI 2020, Lima, Peru, October 4\\u20138, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/57046218c192493c55cf0aa09fc8921aed1bea9d\",\"venue\":\"DART/DCL@MICCAI\",\"year\":2020},{\"arxivId\":\"1903.11779\",\"authors\":[{\"authorId\":\"32197655\",\"name\":\"B. A. Griffin\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/CVPR.2019.00912\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"605d275acfff55996c672339f4a21ff639a3640f\",\"title\":\"BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames\",\"url\":\"https://www.semanticscholar.org/paper/605d275acfff55996c672339f4a21ff639a3640f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2007.12131\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"1828765893\",\"name\":\"Liliane Momeni\"},{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"2863890\",\"name\":\"Joon Son Chung\"},{\"authorId\":\"144863998\",\"name\":\"Neil Fox\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58621-8_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d49e8b79dbc16d8d3ed2bb3e8c96c6f26ab928\",\"title\":\"BSL-1K: Scaling up co-articulated sign language recognition using mouthing cues\",\"url\":\"https://www.semanticscholar.org/paper/58d49e8b79dbc16d8d3ed2bb3e8c96c6f26ab928\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10250\",\"authors\":[{\"authorId\":\"41131768\",\"name\":\"Zhenhua Wang\"},{\"authorId\":\"31170827\",\"name\":\"J. Meng\"},{\"authorId\":\"2019493593\",\"name\":\"Jin Zhou\"},{\"authorId\":\"2004175\",\"name\":\"Dongyan Guo\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"1739956171\",\"name\":\"Jianhua Zhang\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"1739189491\",\"name\":\"Shengyong Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"title\":\"LAGNet: Logic-Aware Graph Network for Human Interaction Understanding\",\"url\":\"https://www.semanticscholar.org/paper/2551e6c592fb43818238ba274a8cafbf0d148ae4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11557\",\"authors\":[{\"authorId\":\"40625288\",\"name\":\"Martin Kolar\\u00edk\"},{\"authorId\":\"1723587\",\"name\":\"R. Burget\"},{\"authorId\":\"1393611837\",\"name\":\"C. Travieso-Gonz\\u00e1lez\"},{\"authorId\":\"89461298\",\"name\":\"J. Ko\\u010dica\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7baeddf6310ccd476feaab1f381323bb736466a\",\"title\":\"Planar 3D Transfer Learning for End to End Unimodal MRI Unbalanced Data Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b7baeddf6310ccd476feaab1f381323bb736466a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.12021\",\"authors\":[{\"authorId\":\"145986671\",\"name\":\"Xudong Wang\"},{\"authorId\":\"117217536\",\"name\":\"Stella X. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8de987b2baafd4a873351528787c60fb9af77e97\",\"title\":\"Tied Block Convolution: Leaner and Better CNNs with Shared Thinner Filters\",\"url\":\"https://www.semanticscholar.org/paper/8de987b2baafd4a873351528787c60fb9af77e97\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05381\",\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"46200183\",\"name\":\"Chaoxi Xu\"},{\"authorId\":\"145789906\",\"name\":\"G. Yang\"},{\"authorId\":\"48632140\",\"name\":\"Xun Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be749fb4719cfc56d689ab11a27a9a6f8fd76570\",\"title\":\"Hybrid Space Learning for Language-based Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/be749fb4719cfc56d689ab11a27a9a6f8fd76570\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.02531\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1145/3394171.3413694\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"title\":\"Self-supervised Video Representation Learning Using Inter-intra Contrastive Framework\",\"url\":\"https://www.semanticscholar.org/paper/de4e13d7fa8de21e7a09b4ce3f6245ee4e13102c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2004.04730\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":\"10.1109/cvpr42600.2020.00028\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"908cca0abefc35acc38033603714fbb1bcadc49d\",\"title\":\"X3D: Expanding Architectures for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908cca0abefc35acc38033603714fbb1bcadc49d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47629724\",\"name\":\"D. M. Nguyen\"},{\"authorId\":\"67294118\",\"name\":\"Michael L. Iuzzolino\"},{\"authorId\":\"1726056948\",\"name\":\"Aaron Mankel\"},{\"authorId\":\"2223645\",\"name\":\"K. Bozek\"},{\"authorId\":\"3096034\",\"name\":\"G. Stephens\"},{\"authorId\":\"39464329\",\"name\":\"O. Peleg\"}],\"doi\":\"10.1101/2020.05.23.112540\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5d1a33514e856e819d8091be64bc90d79ab835f8\",\"title\":\"Flow-Mediated Olfactory Communication in Honey Bee Swarms\",\"url\":\"https://www.semanticscholar.org/paper/5d1a33514e856e819d8091be64bc90d79ab835f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.06111\",\"authors\":[{\"authorId\":\"2465856\",\"name\":\"Yen-Chia Hsu\"},{\"authorId\":\"144188081\",\"name\":\"Ting-Hao Kenneth Huang\"},{\"authorId\":\"2998709\",\"name\":\"Ting-yao Hu\"},{\"authorId\":\"6336229\",\"name\":\"P. Dille\"},{\"authorId\":\"1693980281\",\"name\":\"Sean Prendi\"},{\"authorId\":\"12628113\",\"name\":\"R. Hoffman\"},{\"authorId\":\"1693976434\",\"name\":\"Anastasia Tsuhlares\"},{\"authorId\":\"144669295\",\"name\":\"R. Sargent\"},{\"authorId\":\"84502304\",\"name\":\"Illah Nourbakhsh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe9d1eca471ff7298e0f0aacd605873e25c15d9e\",\"title\":\"Project RISE: Recognizing Industrial Smoke Emissions\",\"url\":\"https://www.semanticscholar.org/paper/fe9d1eca471ff7298e0f0aacd605873e25c15d9e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2005.04490\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"66442329\",\"name\":\"H. Liu\"},{\"authorId\":\"1689307375\",\"name\":\"Shizhan Liu\"},{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"49502400\",\"name\":\"G. Qi\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"168f08358c2740b3ffec396f037939f9a0edda9d\",\"title\":\"Human in Events: A Large-Scale Benchmark for Human-centric Video Analysis in Complex Events\",\"url\":\"https://www.semanticscholar.org/paper/168f08358c2740b3ffec396f037939f9a0edda9d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04755\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"title\":\"Generalized Many-Way Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.08352\",\"authors\":[{\"authorId\":\"49061635\",\"name\":\"V. Mehta\"},{\"authorId\":\"1735697\",\"name\":\"Abhinav Dhall\"},{\"authorId\":\"2556975\",\"name\":\"Sujata Pal\"},{\"authorId\":\"145123077\",\"name\":\"Shehroz Khan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52ab1e80d7a7a73d9cea73238c5f8d51e24fcf49\",\"title\":\"Motion and Region Aware Adversarial Learning for Fall Detection with Thermal Imaging\",\"url\":\"https://www.semanticscholar.org/paper/52ab1e80d7a7a73d9cea73238c5f8d51e24fcf49\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13260\",\"authors\":[{\"authorId\":\"1508389232\",\"name\":\"Junyi Feng\"},{\"authorId\":\"47319889\",\"name\":\"Songyuan Li\"},{\"authorId\":\"92384987\",\"name\":\"X. Li\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"}],\"doi\":\"10.1109/TPAMI.2020.3024646\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f86bfe5174aa24a33087a4456b1a9734ffb68f8c\",\"title\":\"TapLab: A Fast Framework for Semantic Video Segmentation Tapping into Compressed-Domain Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/f86bfe5174aa24a33087a4456b1a9734ffb68f8c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2012.14950\",\"authors\":[{\"authorId\":\"26959701\",\"name\":\"Hengduo Li\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":null,\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f434d65e76041d3417715791e052255f924d4efc\",\"title\":\"2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f434d65e76041d3417715791e052255f924d4efc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"145684947\",\"name\":\"M. Yu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"}],\"doi\":\"10.1007/978-3-030-05716-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"title\":\"Action Recognition Using Visual Attention with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"title\":\"Person Re-identification in Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.11631\",\"authors\":[{\"authorId\":\"32859304\",\"name\":\"Oytun Ulutan\"},{\"authorId\":\"34889835\",\"name\":\"S. Rallapalli\"},{\"authorId\":\"1718467\",\"name\":\"M. Srivatsa\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":\"10.1109/WACV45572.2020.9093617\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"title\":\"Actor Conditioned Attention Maps for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/057d5e304f1f2f2bd6c35d5c861961ce102fcc48\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2010.10270\",\"authors\":[{\"authorId\":\"1999771611\",\"name\":\"Smail Ait Bouhsain\"},{\"authorId\":\"52154910\",\"name\":\"Saeed Saadatnejad\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9360c475683e3feeb53137d7fa5e2eec0a4f821\",\"title\":\"Pedestrian Intention Prediction: A Multi-task Perspective\",\"url\":\"https://www.semanticscholar.org/paper/e9360c475683e3feeb53137d7fa5e2eec0a4f821\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"143629371\",\"name\":\"L. Song\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1109/TMM.2019.2959425\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8006397de84196e07ee4b520100940f2fd46483\",\"title\":\"GLNet: Global Local Network for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b8006397de84196e07ee4b520100940f2fd46483\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153504672\",\"name\":\"Hong Zhang\"},{\"authorId\":\"2000677733\",\"name\":\"Jiexiong Rong\"}],\"doi\":\"10.1007/S11042-020-09564-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe960aebd7429164f20643301456b06fadb89165\",\"title\":\"Enhanced 3D residual network for video event recognition in shipping monitoring\",\"url\":\"https://www.semanticscholar.org/paper/fe960aebd7429164f20643301456b06fadb89165\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2001.11091\",\"authors\":[{\"authorId\":\"1491169373\",\"name\":\"Mohamad Ballout\"},{\"authorId\":\"1381681564\",\"name\":\"Mohammad Tuqan\"},{\"authorId\":\"1790873\",\"name\":\"Daniel C. Asmar\"},{\"authorId\":\"48810394\",\"name\":\"Elie Shammas\"},{\"authorId\":\"1768700\",\"name\":\"George E. Sakr\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"title\":\"The benefits of synthetic data for action categorization\",\"url\":\"https://www.semanticscholar.org/paper/7e01b0c04fd493db4422087a67082a4e3cc4e354\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2006.07976\",\"authors\":[{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"30733670\",\"name\":\"S. Chen\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f46458babf6ec837ff829e54c110d1c71f0945eb\",\"title\":\"Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f46458babf6ec837ff829e54c110d1c71f0945eb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.04366\",\"authors\":[{\"authorId\":\"1471722186\",\"name\":\"Miao Yin\"},{\"authorId\":\"145657535\",\"name\":\"Siyu Liao\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"48632004\",\"name\":\"X. Wang\"},{\"authorId\":\"1471729588\",\"name\":\"Bo Yuan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"title\":\"Compressing Recurrent Neural Networks Using Hierarchical Tucker Tensor Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/d2f5c589662c42b0956d2b410f8dcbfaf174bf5b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46276482\",\"name\":\"J. Li\"},{\"authorId\":\"145708711\",\"name\":\"Ping Wei\"},{\"authorId\":\"1978363545\",\"name\":\"Yongchi Zhang\"},{\"authorId\":\"153873673\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1145/3394171.3413641\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"05444a5a49f717dc199957b66e9c472219171f88\",\"title\":\"A Slow-I-Fast-P Architecture for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/05444a5a49f717dc199957b66e9c472219171f88\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9306731\",\"name\":\"O. Gune\"},{\"authorId\":\"49124777\",\"name\":\"Biplab Banerjee\"},{\"authorId\":\"144527832\",\"name\":\"S. Chaudhuri\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1145/3394171.3413657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb67c4bbba0d4ed86f1d1f266403af291e09eeaa\",\"title\":\"Generalized Zero-Shot Learning using Generated Proxy Unseen Samples and Entropy Separation\",\"url\":\"https://www.semanticscholar.org/paper/cb67c4bbba0d4ed86f1d1f266403af291e09eeaa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"title\":\"Explorer Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/1bbec7190ac3ba34ca91d28f145e356a11418b67\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151495731\",\"name\":\"Huaizheng Zhang\"},{\"authorId\":\"11453764\",\"name\":\"Linsen Dong\"},{\"authorId\":\"143853502\",\"name\":\"Guanyu Gao\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"},{\"authorId\":\"145868453\",\"name\":\"Yonggang Wen\"},{\"authorId\":\"1800055\",\"name\":\"K. Guan\"}],\"doi\":\"10.1109/TMM.2020.2973828\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9edfd38396c10cabf7a0297261ec6446fc9088d0\",\"title\":\"DeepQoE: A Multimodal Learning Framework for Video Quality of Experience (QoE) Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9edfd38396c10cabf7a0297261ec6446fc9088d0\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"},{\"authorId\":\"1790643\",\"name\":\"S. Schulter\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-58610-2_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"19d574a2238ad11142de1d6f2713315880b2d218\",\"title\":\"Shuffle and Attend: Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/19d574a2238ad11142de1d6f2713315880b2d218\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"40913232\",\"name\":\"P. Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"K. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"D. Slezak\"},{\"authorId\":\"1704749\",\"name\":\"T. Washio\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"},{\"authorId\":\"145337089\",\"name\":\"S. Barbosa\"},{\"authorId\":\"2977267\",\"name\":\"A. P. Cl\\u00e1udio\"},{\"authorId\":\"1767919\",\"name\":\"K. Bouatouch\"},{\"authorId\":\"2571670\",\"name\":\"Manuela Chessa\"},{\"authorId\":\"1717982\",\"name\":\"A. Paljic\"},{\"authorId\":\"2569160\",\"name\":\"A. Kerren\"},{\"authorId\":\"2433007\",\"name\":\"C. Hurter\"},{\"authorId\":\"1704567\",\"name\":\"A. Tr\\u00e9meau\"}],\"doi\":\"10.1007/978-3-030-41590-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfd34a5453210cfd476d9ba8e2be5c47fcb7eaf7\",\"title\":\"Computer Vision, Imaging and Computer Graphics Theory and Applications: 14th International Joint Conference, VISIGRAPP 2019, Prague, Czech Republic, February 25\\u201327, 2019, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/bfd34a5453210cfd476d9ba8e2be5c47fcb7eaf7\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510708346\",\"name\":\"Jianbang Qin\"},{\"authorId\":\"1510665624\",\"name\":\"S. Hu\"},{\"authorId\":\"153301546\",\"name\":\"W. Guo\"}],\"doi\":\"10.1117/12.2559286\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"title\":\"Global evaluate-and-rescale network: an efficient model for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/80f0280a05f10f0d95ceb0bc4c435315acfef5bb\",\"venue\":\"International Conference on Machine Vision\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47412750\",\"name\":\"Huaying Hao\"},{\"authorId\":\"1929093\",\"name\":\"Huazhu Fu\"},{\"authorId\":\"48615817\",\"name\":\"Yanwu Xu\"},{\"authorId\":\"91139526\",\"name\":\"J. Yang\"},{\"authorId\":\"46494313\",\"name\":\"Fei Li\"},{\"authorId\":\"47957630\",\"name\":\"Xingding Zhang\"},{\"authorId\":\"87383538\",\"name\":\"J. Liu\"},{\"authorId\":\"1956017\",\"name\":\"Yitian Zhao\"}],\"doi\":\"10.1007/978-3-030-59722-1_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef8224b8c2100d42a9f01a66df6b8402331269b9\",\"title\":\"Open-Appositional-Synechial Anterior Chamber Angle Classification in AS-OCT Sequences\",\"url\":\"https://www.semanticscholar.org/paper/ef8224b8c2100d42a9f01a66df6b8402331269b9\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2009399\",\"name\":\"Igor L. O. Bastos\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1109/ICIP40778.2020.9190769\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"35e703f6ad6551cdbe5c58d22010d26662211d02\",\"title\":\"Bubblenet: A Disperse Recurrent Structure To Recognize Activities\",\"url\":\"https://www.semanticscholar.org/paper/35e703f6ad6551cdbe5c58d22010d26662211d02\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2012.06440\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2951229\",\"name\":\"Hisham Cholakkal\"},{\"authorId\":\"145684318\",\"name\":\"Munawar Hayat\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"43166698fd0fc13c1fe70a1f6249413559a9dcf3\",\"title\":\"D2-Net: Weakly-Supervised Action Localization via Discriminative Embeddings and Denoised Activations\",\"url\":\"https://www.semanticscholar.org/paper/43166698fd0fc13c1fe70a1f6249413559a9dcf3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145268563\",\"name\":\"S. Amini\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2019.2959426\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"title\":\"Spatio-Temporal VLAD Encoding of Visual Events Using Temporal Ordering of the Mid-Level Deep Semantics\",\"url\":\"https://www.semanticscholar.org/paper/fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7466378\",\"name\":\"Jia-xin Cai\"},{\"authorId\":\"34651153\",\"name\":\"J. Hu\"},{\"authorId\":\"1737903652\",\"name\":\"Xin Tang\"},{\"authorId\":\"34985695\",\"name\":\"Tzu-Yi Hung\"},{\"authorId\":\"30915941\",\"name\":\"Y. Tan\"}],\"doi\":\"10.1016/j.neucom.2020.03.111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46463edcb809186ca8cd003d02c67567235b3317\",\"title\":\"Deep historical long short-term memory network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/46463edcb809186ca8cd003d02c67567235b3317\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396300636\",\"name\":\"Avital Meshi\"},{\"authorId\":\"34963191\",\"name\":\"Angus G. Forbes\"}],\"doi\":\"10.1145/3386567.3388566\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c76b5f65e6674136c6e1cdf0857ccdbe265d627\",\"title\":\"Stepping inside the classification cube: an intimate interaction with an AI system\",\"url\":\"https://www.semanticscholar.org/paper/8c76b5f65e6674136c6e1cdf0857ccdbe265d627\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3045512\",\"name\":\"R. Granada\"},{\"authorId\":\"10684139\",\"name\":\"J. Aires\"},{\"authorId\":\"40235962\",\"name\":\"J. Monteiro\"},{\"authorId\":\"2920773\",\"name\":\"Felipe Meneguzzi\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9545da8b7194dd2172d2827f59a90d191336a637\",\"title\":\"Improving Action Recognition using Temporal Regions\",\"url\":\"https://www.semanticscholar.org/paper/9545da8b7194dd2172d2827f59a90d191336a637\",\"venue\":\"J. Inf. Data Manag.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"1804.00892\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00560\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"title\":\"When will you do what? - Anticipating Temporal Occurrences of Activities\",\"url\":\"https://www.semanticscholar.org/paper/33b1843afc8b76314c9fbe11ca11c23fa0966c08\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.03918\",\"authors\":[{\"authorId\":\"2442124\",\"name\":\"Gaurvi Goyal\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1712692\",\"name\":\"Francesca Odone\"},{\"authorId\":\"1923910\",\"name\":\"Alessandra Sciutti\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c622c520ebe8f15384367ea4ebefd92115238bbe\",\"title\":\"The role of ego vision in view-invariant action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c622c520ebe8f15384367ea4ebefd92115238bbe\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":\"1907.05092\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"40280182\",\"name\":\"Yuqing Song\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"50678073\",\"name\":\"Bei Liu\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b7bf64b2c7372aa82d32424aacc6f4a86215433\",\"title\":\"Activitynet 2019 Task 3: Exploring Contexts for Dense Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8b7bf64b2c7372aa82d32424aacc6f4a86215433\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144963124\",\"name\":\"Huanan Dong\"},{\"authorId\":\"48960121\",\"name\":\"Ming Yang Wen\"},{\"authorId\":\"2016529\",\"name\":\"Zhouwang Yang\"}],\"doi\":\"10.3390/FI11060123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df8b25ac1a6cc8777b975bc9f5bee37c0c36de2f\",\"title\":\"Vehicle Speed Estimation Based on 3D ConvNets and Non-Local Blocks\",\"url\":\"https://www.semanticscholar.org/paper/df8b25ac1a6cc8777b975bc9f5bee37c0c36de2f\",\"venue\":\"Future Internet\",\"year\":2019},{\"arxivId\":\"1903.09616\",\"authors\":[{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"title\":\"On the Importance of Video Action Recognition for Visual Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/27dd4c88b990f54f8b2c6039b98fa1de72d27150\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"title\":\"Temporal Reasoning in Videos Using Convolutional Gated Recurrent Units\",\"url\":\"https://www.semanticscholar.org/paper/2e927d0a2dc4b69fc03124ad876329b22a61f1b0\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"102868457\",\"name\":\"W. Li\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144410724\",\"name\":\"K. Jin\"}],\"doi\":\"10.1145/3234804.3234821\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"title\":\"Local Feature Analysis for real-time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"venue\":\"ICDLT '18\",\"year\":2018},{\"arxivId\":\"1903.00859\",\"authors\":[{\"authorId\":\"50398746\",\"name\":\"B. Xiong\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"title\":\"Less Is More: Learning Highlight Detection From Video Duration\",\"url\":\"https://www.semanticscholar.org/paper/85a3cd627540fea7ef5c195ee1bd2cc9697e413a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"},{\"authorId\":\"1686820\",\"name\":\"B. M\\u00e9rialdo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4535891852c58d992305ee440391cfa1ba33cb69\",\"title\":\"EURECOM participation in TrecVid VTT 2018\",\"url\":\"https://www.semanticscholar.org/paper/4535891852c58d992305ee440391cfa1ba33cb69\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":\"1905.04668\",\"authors\":[{\"authorId\":\"2133342\",\"name\":\"Mohammadreza Babaee\"},{\"authorId\":\"119389363\",\"name\":\"David Full\"},{\"authorId\":\"145512909\",\"name\":\"Gerhard Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"138aedf23346d7d5a4a8c38c935735a436f7c839\",\"title\":\"On Flow Profile Image for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/138aedf23346d7d5a4a8c38c935735a436f7c839\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.02602\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"title\":\"Human Action Sequence Classification\",\"url\":\"https://www.semanticscholar.org/paper/42b7b4bb2f96b21c33541a83606917be5eb6abbb\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7360d2f4d84ad6d43090810c9a0a2e0a071027b5\",\"title\":\"MLGCN: Multi-Laplacian Graph Convolutional Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7360d2f4d84ad6d43090810c9a0a2e0a071027b5\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"3735710\",\"name\":\"Baopu Li\"},{\"authorId\":\"66440341\",\"name\":\"Yingze Bao\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1109/WACV45572.2020.9093535\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7255bb1c611a0eb30daedae34ffc5447a0957973\",\"title\":\"Action Segmentation with Mixed Temporal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/7255bb1c611a0eb30daedae34ffc5447a0957973\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409464809\",\"name\":\"Pin-Jui Hwang\"},{\"authorId\":\"144926927\",\"name\":\"Chen-Chien Hsu\"},{\"authorId\":\"2653046\",\"name\":\"W. Wang\"}],\"doi\":\"10.1109/MCE.2019.2956202\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e239fbf261b2128996e6173ee9795041d096171d\",\"title\":\"Development of a Mimic Robot\\u2014Learning From Demonstration Incorporating Object Detection and Multiaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e239fbf261b2128996e6173ee9795041d096171d\",\"venue\":\"IEEE Consumer Electronics Magazine\",\"year\":2020},{\"arxivId\":\"1710.10330\",\"authors\":[{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1874505\",\"name\":\"Xiaowei Zhao\"},{\"authorId\":\"1681842\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71f38f8f524de2001f41d28a8cb67236f5d1d587\",\"title\":\"Multi-modal Aggregation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/71f38f8f524de2001f41d28a8cb67236f5d1d587\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153552006\",\"name\":\"A. Franco\"},{\"authorId\":\"31649620\",\"name\":\"A. Magnani\"},{\"authorId\":\"1747625\",\"name\":\"D. Maio\"}],\"doi\":\"10.1016/j.patrec.2020.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bebb0afdcc3e4c5a95e4b0b659569c096f2894c\",\"title\":\"A multimodal approach for human activity recognition based on skeleton and RGB data\",\"url\":\"https://www.semanticscholar.org/paper/2bebb0afdcc3e4c5a95e4b0b659569c096f2894c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993679831\",\"name\":\"Bojia Zi\"},{\"authorId\":\"1993705762\",\"name\":\"Minghao Chang\"},{\"authorId\":\"12564022\",\"name\":\"J. Chen\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3394171.3413769\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2060fa23185747294541f428c39640177450b8fb\",\"title\":\"WildDeepfake: A Challenging Real-World Dataset for Deepfake Detection\",\"url\":\"https://www.semanticscholar.org/paper/2060fa23185747294541f428c39640177450b8fb\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46758783\",\"name\":\"Jiawei Yan\"},{\"authorId\":\"8556451\",\"name\":\"F. Angelini\"},{\"authorId\":\"144403678\",\"name\":\"S. Naqvi\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054456\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"39e4c98a180c115684fce2caf3f86a0bf804c06a\",\"title\":\"Image Segmentation Based Privacy-Preserving Human Action Recognition for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/39e4c98a180c115684fce2caf3f86a0bf804c06a\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"3185592\",\"name\":\"Yevgeny Yaroker\"},{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"46189009\",\"name\":\"U. Barzelay\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"}],\"doi\":\"10.1145/3394171.3413612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e775197d3d836d23d87e2d2b6a8a238c81d0eb44\",\"title\":\"Learnable Optimal Sequential Grouping for Video Scene Detection\",\"url\":\"https://www.semanticscholar.org/paper/e775197d3d836d23d87e2d2b6a8a238c81d0eb44\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1709.06447\",\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"12387007\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"939232314d39b26c89cd190c005b2ca71f14220a\",\"title\":\"Human Activity Recognition Using Robust Adaptive Privileged Probabilistic Learning\",\"url\":\"https://www.semanticscholar.org/paper/939232314d39b26c89cd190c005b2ca71f14220a\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2465856\",\"name\":\"Yen-Chia Hsu\"},{\"authorId\":\"40324443\",\"name\":\"Ting-Hao Huang\"},{\"authorId\":\"2998709\",\"name\":\"Ting-yao Hu\"},{\"authorId\":\"6336229\",\"name\":\"P. Dille\"},{\"authorId\":\"1693980281\",\"name\":\"Sean Prendi\"},{\"authorId\":\"12628113\",\"name\":\"R. Hoffman\"},{\"authorId\":\"1693976434\",\"name\":\"Anastasia Tsuhlares\"},{\"authorId\":\"144669295\",\"name\":\"R. Sargent\"},{\"authorId\":\"84502304\",\"name\":\"Illah Nourbakhsh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ffeb6a9d4cad479b61ed72807d42eb9ea29d811\",\"title\":\"RISE Video Dataset: Recognizing Industrial Smoke Emissions\",\"url\":\"https://www.semanticscholar.org/paper/2ffeb6a9d4cad479b61ed72807d42eb9ea29d811\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09861\",\"authors\":[{\"authorId\":\"9096071\",\"name\":\"Jianchao Wu\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58595-2_27\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cf0bc1e97049ece897db97ba605594a89df50c34\",\"title\":\"Context-Aware RCNN: A Baseline for Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cf0bc1e97049ece897db97ba605594a89df50c34\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2006270114\",\"name\":\"Michael Dorkenwald\"},{\"authorId\":\"21408156\",\"name\":\"U. B\\u00fcchler\"},{\"authorId\":\"1796707\",\"name\":\"B. Ommer\"}],\"doi\":\"10.1109/cvpr42600.2020.00828\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f919769924e603833b96682f0fe0ebf4d7f2a1f\",\"title\":\"Unsupervised Magnification of Posture Deviations Across Subjects\",\"url\":\"https://www.semanticscholar.org/paper/7f919769924e603833b96682f0fe0ebf4d7f2a1f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2007.04687\",\"authors\":[{\"authorId\":\"2678268\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"9754502\",\"name\":\"Yujia Shi\"},{\"authorId\":\"5264927\",\"name\":\"Yujia Sun\"},{\"authorId\":\"1802542506\",\"name\":\"Fangtao Shao\"},{\"authorId\":\"48551946\",\"name\":\"Zhaoyang Wu\"},{\"authorId\":\"40615725\",\"name\":\"Zhiwei Yang\"}],\"doi\":\"10.1007/978-3-030-58577-8_20\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f28873be3601c5a2736996eba543cf51950a381\",\"title\":\"Not only Look, but also Listen: Learning Multimodal Violence Detection under Weak Supervision\",\"url\":\"https://www.semanticscholar.org/paper/8f28873be3601c5a2736996eba543cf51950a381\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1905.04225\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145872624\",\"name\":\"Yao Rong\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/ICCVW.2019.00345\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3a4787b4123d0928e08ec79412e2626d9e3adbea\",\"title\":\"Talking With Your Hands: Scaling Hand Gestures and Recognition With CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3a4787b4123d0928e08ec79412e2626d9e3adbea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1912.01127\",\"authors\":[{\"authorId\":\"48511110\",\"name\":\"Tianqi Liu\"},{\"authorId\":\"1441128337\",\"name\":\"Qizhan Shao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7706ed62e51487ee1fab56f932f5274bdeaea171\",\"title\":\"BERT for Large-scale Video Segment Classification with Test-time Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/7706ed62e51487ee1fab56f932f5274bdeaea171\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27648874\",\"name\":\"Changmao Cheng\"},{\"authorId\":\"2832147\",\"name\":\"C. Zhang\"},{\"authorId\":\"1732264\",\"name\":\"Y. Wei\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9f18e562481538493d71d7b36eb12270f03d6339\",\"title\":\"Sparse Temporal Causal Convolution for Efficient Action Modeling\",\"url\":\"https://www.semanticscholar.org/paper/9f18e562481538493d71d7b36eb12270f03d6339\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1109/ICSP.2018.8652359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"494f3f390442c622fd47d3c75316c3f9737bfa97\",\"title\":\"Temporal Pyramid Pooling Based Relation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/494f3f390442c622fd47d3c75316c3f9737bfa97\",\"venue\":\"2018 14th IEEE International Conference on Signal Processing (ICSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48760802\",\"name\":\"D. Kumar\"},{\"authorId\":\"153264095\",\"name\":\"C. Kumar\"},{\"authorId\":\"71665304\",\"name\":\"Chun Wei. Seah\"},{\"authorId\":\"50019156\",\"name\":\"Si-Yu Xia\"},{\"authorId\":\"144197068\",\"name\":\"M. Shao\"}],\"doi\":\"10.1145/3394171.3413531\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2c5b58c3aa283518b4cbd483584e936ca0d3884\",\"title\":\"Finding Achilles' Heel: Adversarial Attack on Multi-modal Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2c5b58c3aa283518b4cbd483584e936ca0d3884\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"93782401659fe26faef7e5f3b84ff632a12da47f\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Forged Videos\",\"url\":\"https://www.semanticscholar.org/paper/93782401659fe26faef7e5f3b84ff632a12da47f\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"2012.04983\",\"authors\":[{\"authorId\":\"1405301761\",\"name\":\"Hedi Ben-younes\"},{\"authorId\":\"2034015064\",\"name\":\"'Eloi Zablocki\"},{\"authorId\":\"1398301486\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"44194713255b6ee890ce1a2d2b727d30e0b71cdb\",\"title\":\"Driving Behavior Explanation with Multi-level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/44194713255b6ee890ce1a2d2b727d30e0b71cdb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13852\",\"authors\":[{\"authorId\":\"72384163\",\"name\":\"Vincent Jacquot\"},{\"authorId\":\"1601443232\",\"name\":\"Zhuofan Ying\"},{\"authorId\":\"1852992\",\"name\":\"G. Kreiman\"}],\"doi\":\"10.1109/CVPR42600.2020.01425\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25c3cd273a332d8ba21355e347cba58de861c091\",\"title\":\"Can Deep Learning Recognize Subtle Human Activities?\",\"url\":\"https://www.semanticscholar.org/paper/25c3cd273a332d8ba21355e347cba58de861c091\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40413834\",\"name\":\"J. Imran\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1007/s00371-019-01725-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"812cfc1f88008476dc2ae90d0117065a4001a81b\",\"title\":\"Deep motion templates and extreme learning machine for sign language recognition\",\"url\":\"https://www.semanticscholar.org/paper/812cfc1f88008476dc2ae90d0117065a4001a81b\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"47454520\",\"name\":\"S. Schwarcz\"},{\"authorId\":\"1492122369\",\"name\":\"R. Ranjan\"},{\"authorId\":\"145586343\",\"name\":\"Carlos D. Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"}],\"doi\":\"10.1109/WACVW50321.2020.9096912\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"789cf1e1e4018b629973f7b4ba8864b71f501518\",\"title\":\"Activity Detection in Untrimmed Videos Using Chunk-based Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/789cf1e1e4018b629973f7b4ba8864b71f501518\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":\"2012.08041\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"50557221\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"title\":\"NUTA: Non-uniform Temporal Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f0d55ca0b8f1639372e88479516a573e2bf2250b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1809.04094\",\"authors\":[{\"authorId\":\"1403953272\",\"name\":\"Giorgos Kordopatis-Zilos\"},{\"authorId\":\"144178604\",\"name\":\"S. Papadopoulos\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"},{\"authorId\":\"119661806\",\"name\":\"I. Kompatsiaris\"}],\"doi\":\"10.1109/TMM.2019.2905741\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"820db37272e0d76f554f16a3a9cbbf1ebad6539d\",\"title\":\"FIVR: Fine-Grained Incident Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/820db37272e0d76f554f16a3a9cbbf1ebad6539d\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1907.13487\",\"authors\":[{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"title\":\"Use What You Have: Video retrieval using representations from collaborative experts\",\"url\":\"https://www.semanticscholar.org/paper/b16eeb1e975e8e6ea9450c78fd12da05cfd1375f\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2234579\",\"name\":\"N. Ta\"}],\"doi\":\"10.1007/S10586-019-02912-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dcb171b245b1e6fa9306a5d0e884516bdc86041\",\"title\":\"$$FC^{2}$$FC2: cloud-based cluster provisioning for distributed machine learning\",\"url\":\"https://www.semanticscholar.org/paper/4dcb171b245b1e6fa9306a5d0e884516bdc86041\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2012.13375\",\"authors\":[{\"authorId\":null,\"name\":\"Yue Cao\"},{\"authorId\":\"1690418794\",\"name\":\"Jiarui Xu\"},{\"authorId\":\"48639986\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1825704806\",\"name\":\"Han Hu\"}],\"doi\":\"10.1109/TPAMI.2020.3047209\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"title\":\"Global Context Networks.\",\"url\":\"https://www.semanticscholar.org/paper/e1da715b8ae4436c5224e9b573309a3b72c7a53c\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1910.03579\",\"authors\":[{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2820254\",\"name\":\"Eirina Bourtsoulatze\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3023597\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"title\":\"Graph-Based Spatio-Temporal Feature Learning for Neuromorphic Vision Sensing\",\"url\":\"https://www.semanticscholar.org/paper/5a5cf60486c7bf1937e7725ccccbdd95c4eb1f1b\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.04585\",\"authors\":[{\"authorId\":\"78145301\",\"name\":\"Xiao-dan Li\"},{\"authorId\":\"51243809\",\"name\":\"Yining Lang\"},{\"authorId\":\"47557806\",\"name\":\"YueFeng Chen\"},{\"authorId\":\"2652946\",\"name\":\"Xiaofeng Mao\"},{\"authorId\":\"2503459\",\"name\":\"Yu'an He\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1645209767\",\"name\":\"H. Xue\"},{\"authorId\":\"1618167236\",\"name\":\"Quan Lu\"}],\"doi\":\"10.1145/3394171.3414034\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"72158d16aba68c3f05a2307370f777af27657633\",\"title\":\"Sharp Multiple Instance Learning for DeepFake Video Detection\",\"url\":\"https://www.semanticscholar.org/paper/72158d16aba68c3f05a2307370f777af27657633\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2009.05224\",\"authors\":[{\"authorId\":\"3795834\",\"name\":\"J. Chung\"},{\"authorId\":\"1940024152\",\"name\":\"C. Wuu\"},{\"authorId\":\"1940708423\",\"name\":\"Hsuan-ru Yang\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5635ee061af4321d5de2076d4834a4f96012551\",\"title\":\"HAA500: Human-Centric Atomic Action Dataset with Curated Videos\",\"url\":\"https://www.semanticscholar.org/paper/d5635ee061af4321d5de2076d4834a4f96012551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06317\",\"authors\":[{\"authorId\":\"3458134\",\"name\":\"Gyeongsik Moon\"},{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8230c73193abe9f42306a311d75557a902e785f6\",\"title\":\"IntegralAction: Pose-driven Feature Integration for Robust Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8230c73193abe9f42306a311d75557a902e785f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.12292\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"1502872895\",\"name\":\"Xiaobai Li\"},{\"authorId\":\"35649732\",\"name\":\"Xuesong Niu\"},{\"authorId\":\"2473859\",\"name\":\"J. Shi\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/LSP.2020.3007086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e886a80e4bb673f5bc2cc582fc2ec432f9f8d34\",\"title\":\"AutoHR: A Strong End-to-End Baseline for Remote Heart Rate Measurement With Neural Searching\",\"url\":\"https://www.semanticscholar.org/paper/3e886a80e4bb673f5bc2cc582fc2ec432f9f8d34\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2008.01403\",\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"4029028\",\"name\":\"Xiao-Yang Liu\"},{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"},{\"authorId\":\"2956815\",\"name\":\"Zichuan Xu\"}],\"doi\":\"10.1145/3394171.3414026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b632209923bfe3452ac19f23b46c70455fae465\",\"title\":\"Jointly Cross- and Self-Modal Graph Attention Network for Query-Based Moment Localization\",\"url\":\"https://www.semanticscholar.org/paper/2b632209923bfe3452ac19f23b46c70455fae465\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.03920\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e61ed06f8778d03f0f32d7a94f01627b8557733e\",\"title\":\"Integrating Human Gaze into Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e61ed06f8778d03f0f32d7a94f01627b8557733e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659125162\",\"name\":\"Danfeng Zhuang\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1007/s13042-020-01204-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"title\":\"Spatiotemporal attention enhanced features fusion network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/88f3b42b45e5f5ee60a22eb30cd41e7acc8662c9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.02948\",\"authors\":[{\"authorId\":\"1384028873\",\"name\":\"Guyue Hu\"},{\"authorId\":\"8566649\",\"name\":\"B. Cui\"},{\"authorId\":\"145357370\",\"name\":\"Yuan He\"},{\"authorId\":\"14216506\",\"name\":\"S. Yu\"}],\"doi\":\"10.1109/cvpr42600.2020.00106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72adb2f669aaa9bfd3c6113255e5a0d63af4a88d\",\"title\":\"Progressive Relation Learning for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72adb2f669aaa9bfd3c6113255e5a0d63af4a88d\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738178502\",\"name\":\"Matheus Gutoski\"},{\"authorId\":\"3225435\",\"name\":\"A. E. Lazzaretti\"},{\"authorId\":\"1806302\",\"name\":\"H. Lopes\"}],\"doi\":\"10.1007/s00521-020-05009-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1f449b6f662a729b045b7bed80254b5bd30505d1\",\"title\":\"Deep metric learning for open-set human action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/1f449b6f662a729b045b7bed80254b5bd30505d1\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35564381\",\"name\":\"Mahnaz Parian\"},{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"145717652\",\"name\":\"H. Schuldt\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.1145/3372278.3390723\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4da69e1cf5506637dd6c0cf23dc27a5c0b76b38e\",\"title\":\"Are You Watching Closely? Content-based Retrieval of Hand Gestures\",\"url\":\"https://www.semanticscholar.org/paper/4da69e1cf5506637dd6c0cf23dc27a5c0b76b38e\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":\"2009.13782\",\"authors\":[{\"authorId\":\"1577678641\",\"name\":\"Ganesh Samarth\"},{\"authorId\":\"1974345797\",\"name\":\"Sheetal Ojha\"},{\"authorId\":\"96566998\",\"name\":\"N. Pareek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"29df95ddda4e52ada0564458fe6f438f462b5651\",\"title\":\"Knowledge Fusion Transformers for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29df95ddda4e52ada0564458fe6f438f462b5651\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.01142\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"title\":\"Long-Term Anticipation of Activities with Cycle Consistency\",\"url\":\"https://www.semanticscholar.org/paper/d39c1a6ba3083510d9f697458a6bfdca1be27340\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122822134\",\"name\":\"Gregory Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"145901595\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2b840276017c04e090058e281431379d35de88b\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Security Video\",\"url\":\"https://www.semanticscholar.org/paper/a2b840276017c04e090058e281431379d35de88b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2006.07526\",\"authors\":[{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"1749563254\",\"name\":\"Baiteng Ma\"},{\"authorId\":\"1750375688\",\"name\":\"Zhiwu Qing\"},{\"authorId\":\"1749375503\",\"name\":\"Yongpeng Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"306b6a6bf831b204e8b4f63ba9717504b1d17f7f\",\"title\":\"CBR-Net: Cascade Boundary Refinement Network for Action Detection: Submission to ActivityNet Challenge 2020 (Task 1)\",\"url\":\"https://www.semanticscholar.org/paper/306b6a6bf831b204e8b4f63ba9717504b1d17f7f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.00722\",\"authors\":[{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/CVPRW.2019.00109\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e330af2d061ade245622b9445d5be9717f66b60f\",\"title\":\"SUSiNet: See, Understand and Summarize It\",\"url\":\"https://www.semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398366\",\"name\":\"E. Ghaleb\"},{\"authorId\":\"143728689\",\"name\":\"M. Popa\"},{\"authorId\":\"1753719\",\"name\":\"S. Asteriadis\"}],\"doi\":\"10.1109/ACII.2019.8925444\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"56b48a9a73b5b2777ff511eac0755b608241346b\",\"title\":\"Multimodal and Temporal Perception of Audio-visual Cues for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/56b48a9a73b5b2777ff511eac0755b608241346b\",\"venue\":\"2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)\",\"year\":2019},{\"arxivId\":\"1904.03308\",\"authors\":[{\"authorId\":\"51264689\",\"name\":\"S. Azar\"},{\"authorId\":\"51443392\",\"name\":\"Mina Ghadimi Atigh\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"3304525\",\"name\":\"Alexandre Alahi\"}],\"doi\":\"10.1109/CVPR.2019.00808\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c147261ad2a359865d5780607816c05dc4b48b56\",\"title\":\"Convolutional Relational Machine for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c147261ad2a359865d5780607816c05dc4b48b56\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.12042\",\"authors\":[{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"51479145\",\"name\":\"Shailaja Keyur Sampat\"},{\"authorId\":null,\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8dad416f6ff606441c4dd236fba9685c3d0386c7\",\"title\":\"Blocksworld Revisited: Learning and Reasoning to Generate Event-Sequences from Image Pairs\",\"url\":\"https://www.semanticscholar.org/paper/8dad416f6ff606441c4dd236fba9685c3d0386c7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.12539\",\"authors\":[{\"authorId\":\"9209679\",\"name\":\"Seongjae Kang\"},{\"authorId\":\"7951756\",\"name\":\"Jae-Yoon Kim\"},{\"authorId\":\"49460338\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"47989fc18bf0e3feddc8a29a6bc855bc727fb6a6\",\"title\":\"Virtual Piano using Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/47989fc18bf0e3feddc8a29a6bc855bc727fb6a6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"8559994\",\"name\":\"Qingchao Chen\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9c745de44b2e69f9209819ef72e6488d4cdb530\",\"title\":\"Team SPEEDY Multi Moments in Time Challenge 2019 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/b9c745de44b2e69f9209819ef72e6488d4cdb530\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49724000\",\"name\":\"H. Zhang\"},{\"authorId\":\"46867310\",\"name\":\"Yi-Xiang Zhang\"},{\"authorId\":\"40296597\",\"name\":\"B. Zhong\"},{\"authorId\":\"2619654\",\"name\":\"Qing Lei\"},{\"authorId\":\"48064117\",\"name\":\"Lijie Yang\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19051005\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c0e55d740d07b16a50b5eb491117b92965d315c9\",\"title\":\"A Comprehensive Survey of Vision-Based Human Action Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/c0e55d740d07b16a50b5eb491117b92965d315c9\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2019.01016\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"title\":\"Time-Conditioned Action Anticipation in One Shot\",\"url\":\"https://www.semanticscholar.org/paper/3fa9269c973c70fb64c5ebafeb7e120e323a7472\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1806.11328\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a230350dc8a135fc390f9bb634249d08a07cea4e\",\"title\":\"A flexible model for training action localization with varying levels of supervision\",\"url\":\"https://www.semanticscholar.org/paper/a230350dc8a135fc390f9bb634249d08a07cea4e\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1881509\",\"name\":\"Vicky Kalogeiton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40dd2b9aace337467c6e1e269d0cb813442313d7\",\"title\":\"Localizing spatially and temporally objects and actions in videos. (Localiser spatio-temporallement des objets et des actions dans des vid\\u00e9os)\",\"url\":\"https://www.semanticscholar.org/paper/40dd2b9aace337467c6e1e269d0cb813442313d7\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350413\",\"name\":\"Zijian Kang\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-19823-7_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"title\":\"Extracting Action Sensitive Features to Facilitate Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d3ce1869ac6627e79643ac64a8ae7b2358cbe58a\",\"venue\":\"AIAI\",\"year\":2019},{\"arxivId\":\"2004.06180\",\"authors\":[{\"authorId\":\"49296185\",\"name\":\"Neha Bhargava\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"054a27eb34260abfd51bc66b7d56e2d675aa9f85\",\"title\":\"Challenges and Opportunities for Computer Vision in Real-life Soccer Analytics\",\"url\":\"https://www.semanticscholar.org/paper/054a27eb34260abfd51bc66b7d56e2d675aa9f85\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.07793\",\"authors\":[{\"authorId\":\"145724888\",\"name\":\"Ashraful Islam\"},{\"authorId\":\"1772337\",\"name\":\"R. Radke\"}],\"doi\":\"10.1109/WACV45572.2020.9093620\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"145c15e10967f9eb598b62ab547312571ec3ac3c\",\"title\":\"Weakly Supervised Temporal Action Localization Using Deep Metric Learning\",\"url\":\"https://www.semanticscholar.org/paper/145c15e10967f9eb598b62ab547312571ec3ac3c\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367803\",\"name\":\"Jinhyeok Jang\"},{\"authorId\":null,\"name\":\"Dohyung Kim\"},{\"authorId\":\"2944780\",\"name\":\"Cheonshu Park\"},{\"authorId\":\"145416765\",\"name\":\"M. Jang\"},{\"authorId\":\"46663405\",\"name\":\"Jaeyeon Lee\"},{\"authorId\":\"37079663\",\"name\":\"Jae-Hong Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"942ea97dae84cc94083b6de89b5ac79e6378ff37\",\"title\":\"A new visual dataset based on observations of the daily activities of the elderly: A close understanding of what the elderly actually do in their daily lives\",\"url\":\"https://www.semanticscholar.org/paper/942ea97dae84cc94083b6de89b5ac79e6378ff37\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8303994\",\"name\":\"Honggang Xie\"},{\"authorId\":\"144033365\",\"name\":\"Jinsheng Xiao\"},{\"authorId\":\"3389703\",\"name\":\"Junfeng Lei\"},{\"authorId\":\"2268470\",\"name\":\"Wenjuan Xie\"},{\"authorId\":\"1729664\",\"name\":\"Reinhard Klette\"}],\"doi\":\"10.1007/978-981-15-3651-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"title\":\"Pattern Recognition: ACPR 2019 Workshops, Auckland, New Zealand, November 26, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/42636140273d2a8bdeed36df1cd4d8b56f62270c\",\"venue\":\"ACPR Workshops\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102320235\",\"name\":\"Hao Yang\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"47059008\",\"name\":\"L. Zhang\"},{\"authorId\":\"2545705\",\"name\":\"Yunda Sun\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2020.2984904\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"title\":\"STA-CNN: Convolutional Spatial-Temporal Attention Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c900e452bdb47ed6083ce2651ac32afb211f9fc6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46598954\",\"name\":\"Dan Li\"},{\"authorId\":\"1656176919\",\"name\":\"Kaifeng Zhang\"},{\"authorId\":\"40388829\",\"name\":\"Z. Li\"},{\"authorId\":\"97042247\",\"name\":\"Y. Chen\"}],\"doi\":\"10.3390/s20082381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"title\":\"A Spatiotemporal Convolutional Network for Multi-Behavior Recognition of Pigs\",\"url\":\"https://www.semanticscholar.org/paper/a3d3f0d1546018493cfa3a7c502a420e260a791f\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9191972\",\"name\":\"Xin Men\"},{\"authorId\":\"50813206\",\"name\":\"F. Zhou\"},{\"authorId\":\"33899331\",\"name\":\"Xiaoyong Li\"}],\"doi\":\"10.2312/PG.20181287\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f19c5d8116fbd3e7f9a4e2b078d4a09de9fdcdc\",\"title\":\"A Deep Learned Method for Video Indexing and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7f19c5d8116fbd3e7f9a4e2b078d4a09de9fdcdc\",\"venue\":\"PG\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b71d3f30238cb6621021a95543cce3aab96a21b\",\"title\":\"Fine-grained Video Classification and Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1b71d3f30238cb6621021a95543cce3aab96a21b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98294026\",\"name\":\"S. Liu\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"32083314\",\"name\":\"Yi-bin Li\"}],\"doi\":\"10.1109/ACCESS.2020.2979549\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"title\":\"An End to End Framework With Adaptive Spatio-Temporal Attention Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b2a5d27304a17f1b613e8816613e3deb3992ab3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00191\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"22031c69356c35909082613b84fe86b682291b8a\",\"title\":\"Enhancing Temporal Action Localization with Transfer Learning from Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/22031c69356c35909082613b84fe86b682291b8a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1811.09908\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"50024592\",\"name\":\"Y. Li\"},{\"authorId\":\"40486936\",\"name\":\"Peng Wang\"},{\"authorId\":null,\"name\":\"Yu Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"title\":\"RGB-D Based Action Recognition with Light-weight 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/01cb3f168a2cc811f6a79c4f0508f769002a49d5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.09087\",\"authors\":[{\"authorId\":\"50619476\",\"name\":\"Minjee Kim\"},{\"authorId\":\"7629657\",\"name\":\"Joonmyeong Choi\"},{\"authorId\":\"145979407\",\"name\":\"N. Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b324999ef8d4ff5977ae02f145b7257b1638071a\",\"title\":\"Fully Automated Hand Hygiene Monitoring\\\\\\\\in Operating Room using 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/b324999ef8d4ff5977ae02f145b7257b1638071a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.05234\",\"authors\":[{\"authorId\":\"48451631\",\"name\":\"S. Nguyen\"},{\"authorId\":\"46721265\",\"name\":\"B. Ng\"},{\"authorId\":\"1630291978\",\"name\":\"Alan K. Kaplan\"},{\"authorId\":\"48874255\",\"name\":\"P. Ray\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e570df30206bfcdad63fe74636858bc4ebd318c\",\"title\":\"Attend and Decode: 4D fMRI Task State Decoding Using Attention Models\",\"url\":\"https://www.semanticscholar.org/paper/3e570df30206bfcdad63fe74636858bc4ebd318c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"title\":\"Discovering Multi-Label Actor-Action Association in a Weakly Supervised Setting\",\"url\":\"https://www.semanticscholar.org/paper/1f2bd6effe8666d2843f66bcaae9724f7c453290\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"Aayush Jung Rana\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4b8626336566f34c7e1d17ddf7b144636812c18\",\"title\":\"An Online System for Real-Time Activity Detection in Untrimmed Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/d4b8626336566f34c7e1d17ddf7b144636812c18\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1846234260\",\"name\":\"Xiaoyan Meng\"},{\"authorId\":\"1845981156\",\"name\":\"Guoliang Zhang\"},{\"authorId\":\"143835806\",\"name\":\"S. Jia\"},{\"authorId\":\"47057083\",\"name\":\"Xiuzhi Li\"},{\"authorId\":\"1846054590\",\"name\":\"Xiangyin Zhang\"}],\"doi\":\"10.1007/s00371-020-01931-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"625829da4b74fbcf217615eadd852e5ff4387a17\",\"title\":\"Auxiliary criterion conversion via spatiotemporal semantic encoding and feature entropy for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/625829da4b74fbcf217615eadd852e5ff4387a17\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"2010.03016\",\"authors\":[{\"authorId\":\"1490732820\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a2101cacd22060882e1ec6e787774e6b04f531e0\",\"title\":\"Online Action Detection in Streaming Videos with Time Buffers\",\"url\":\"https://www.semanticscholar.org/paper/a2101cacd22060882e1ec6e787774e6b04f531e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588999\",\"name\":\"J. Pan\"},{\"authorId\":null,\"name\":\"Jibin Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a4fdb3b0c3c3ee2ec3fe128e815f95ef0532bbf\",\"title\":\"\\u201cUncertainty-aware Score Distribution Learning for Action Quality Assessment\\u201d Supplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/8a4fdb3b0c3c3ee2ec3fe128e815f95ef0532bbf\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.08814\",\"authors\":[{\"authorId\":\"72066761\",\"name\":\"Jun-Bin Xiao\"},{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"72347323\",\"name\":\"X. Yang\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1007/978-3-030-58539-6_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13ee363f71e07112210ac2ff27d46625f6f8edab\",\"title\":\"Visual Relation Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/13ee363f71e07112210ac2ff27d46625f6f8edab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49527668\",\"name\":\"Haonan Wang\"},{\"authorId\":\"95163406\",\"name\":\"Y. Mei\"},{\"authorId\":\"95339157\",\"name\":\"J. Lin\"},{\"authorId\":\"2539310\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1109/SiPS50750.2020.9195240\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0612a6a61f26dc9d8cd50dfa9c6f83e268e2ae58\",\"title\":\"Temporal Residual Feature Learning for Efficient 3D Convolutional Neural Network on Action Recognition Task\",\"url\":\"https://www.semanticscholar.org/paper/0612a6a61f26dc9d8cd50dfa9c6f83e268e2ae58\",\"venue\":\"2020 IEEE Workshop on Signal Processing Systems (SiPS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1953994\",\"name\":\"J. Kim\"},{\"authorId\":\"1723666\",\"name\":\"S. Cho\"}],\"doi\":\"10.1007/978-3-030-20055-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5624c5e4dd2432792d19e16aea83423d929dbb42\",\"title\":\"Classifying Excavator Operations with Fusion Network of Multi-modal Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/5624c5e4dd2432792d19e16aea83423d929dbb42\",\"venue\":\"SOCO\",\"year\":2019},{\"arxivId\":\"1912.04608\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b99ef13af9802bc77fb1b51dc68538ef7a01a5e1\",\"title\":\"Forecasting Future Sequence of Actions to Complete an Activity\",\"url\":\"https://www.semanticscholar.org/paper/b99ef13af9802bc77fb1b51dc68538ef7a01a5e1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.08854\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"46970799\",\"name\":\"Y. Song\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"10713620\",\"name\":\"J. Qiu\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a9c92a56e388997adb513305a4259798506b7f5\",\"title\":\"RUC+CMU: System Report for Dense Captioning Events in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9a9c92a56e388997adb513305a4259798506b7f5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153384782\",\"name\":\"Yuhui Wen\"},{\"authorId\":\"144614909\",\"name\":\"L. Gao\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"},{\"authorId\":\"3326435\",\"name\":\"Fang-Lue Zhang\"},{\"authorId\":\"2314567\",\"name\":\"S. Xia\"}],\"doi\":\"10.1609/AAAI.V33I01.33018989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2b308ea24adfae53ce655ab7d12b362f647756e\",\"title\":\"Graph CNNs with Motif and Variable Temporal Block for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b2b308ea24adfae53ce655ab7d12b362f647756e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1912.03538\",\"authors\":[{\"authorId\":\"31937047\",\"name\":\"Sara Beery\"},{\"authorId\":\"3490569\",\"name\":\"Guanhang Wu\"},{\"authorId\":\"40303375\",\"name\":\"V. Rathod\"},{\"authorId\":\"69423660\",\"name\":\"Ronny Votel\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.01309\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ac36b31c7c4ea9dc8b1962ea80ed5f117430cee\",\"title\":\"Context R-CNN: Long Term Temporal Context for Per-Camera Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/9ac36b31c7c4ea9dc8b1962ea80ed5f117430cee\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49694933\",\"name\":\"Ziheng Guo\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47504563\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Junhao Zhang\"}],\"doi\":\"10.1007/978-3-030-30508-6_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"title\":\"An Efficient 3D-NAS Method for Video-Based Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICCVW.2019.00184\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"273407d793c8ebcdb72d039be2e5c1c575a28048\",\"title\":\"Level Selector Network for Optimizing Accuracy-Specificity Trade-Offs\",\"url\":\"https://www.semanticscholar.org/paper/273407d793c8ebcdb72d039be2e5c1c575a28048\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2112794\",\"name\":\"M. Inaba\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1007/978-3-030-11012-3_42\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9b97dd5fc8d79a9e18f283bf9a5644eaf6676ea\",\"title\":\"Recognizing People in Blind Spots Based on Surrounding Behavior\",\"url\":\"https://www.semanticscholar.org/paper/a9b97dd5fc8d79a9e18f283bf9a5644eaf6676ea\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1909.05165\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"title\":\"Comparative Analysis of CNN-based Spatiotemporal Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6dbf4b5b49ccfa082a3b3c8a3d42713784d3ef1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"49901469\",\"name\":\"G. Chen\"},{\"authorId\":\"49750905\",\"name\":\"Chong Chen\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"51470719\",\"name\":\"Xuanlu Xiang\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":\"10.1109/ICCVW.2019.00234\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9a841017d4da8382841d1216ebeed8605bfaafaf\",\"title\":\"Instance-Based Video Search via Multi-Task Retrieval and Re-Ranking\",\"url\":\"https://www.semanticscholar.org/paper/9a841017d4da8382841d1216ebeed8605bfaafaf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1911.11462\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"35869086\",\"name\":\"A. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/cvpr42600.2020.01017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"title\":\"G-TAD: Sub-Graph Localization for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/720abe3b7a1cbec9e9a14c65e67ee5ec58679893\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.13931\",\"authors\":[{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"},{\"authorId\":\"1735962\",\"name\":\"Aixin Sun\"},{\"authorId\":\"1492128584\",\"name\":\"Wei Jing\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"}],\"doi\":\"10.18653/v1/2020.acl-main.585\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"title\":\"Span-based Localizing Network for Natural Language Video Localization\",\"url\":\"https://www.semanticscholar.org/paper/5a975dcd3dba2a11830e5595d4c4659441cb6836\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2011.00597\",\"authors\":[{\"authorId\":\"2007582232\",\"name\":\"Simon Ging\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"1835025\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"80089ad641bae28b0e57771afef181b60011069e\",\"title\":\"COOT: Cooperative Hierarchical Transformer for Video-Text Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/80089ad641bae28b0e57771afef181b60011069e\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152991070\",\"name\":\"Yanyan Song\"},{\"authorId\":\"144539547\",\"name\":\"L. Tan\"},{\"authorId\":\"1691036\",\"name\":\"L. Zhou\"},{\"authorId\":\"153010694\",\"name\":\"Xinyue Lv\"},{\"authorId\":\"1481816621\",\"name\":\"Zihao Ma\"}],\"doi\":\"10.1007/978-3-030-57881-7_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13095711fbcd69d1a9897392b465ab2a25eab81d\",\"title\":\"Video Action Recognition Based on Hybrid Convolutional Network\",\"url\":\"https://www.semanticscholar.org/paper/13095711fbcd69d1a9897392b465ab2a25eab81d\",\"venue\":\"ICAIS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50570717\",\"name\":\"M. Yuan\"},{\"authorId\":\"13800522\",\"name\":\"L. Zhang\"},{\"authorId\":\"27068208\",\"name\":\"Zheng-tao Wu\"},{\"authorId\":\"2131811\",\"name\":\"D. Zheng\"}],\"doi\":\"10.1109/IWQoS49365.2020.9212956\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae4d0accae0a556efcfd158273b40f5d4e0b7309\",\"title\":\"High-quality Activity-Level Video Advertising\",\"url\":\"https://www.semanticscholar.org/paper/ae4d0accae0a556efcfd158273b40f5d4e0b7309\",\"venue\":\"2020 IEEE/ACM 28th International Symposium on Quality of Service (IWQoS)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102846737\",\"name\":\"Guilherme Vieira Leite\"},{\"authorId\":\"1410369120\",\"name\":\"Gabriel Pellegrino da Silva\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-981-15-6759-9_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d8498a9ac2f848a63cc63d3a33736fdd3a0e6ae\",\"title\":\"Three-Stream Convolutional Neural Network for Human Fall Detection\",\"url\":\"https://www.semanticscholar.org/paper/8d8498a9ac2f848a63cc63d3a33736fdd3a0e6ae\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2008.12432\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"19173161\",\"name\":\"Nirat Saini\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"117595877c1fca610f94c8d07009105092939ecc\",\"title\":\"All About Knowledge Graphs for Actions\",\"url\":\"https://www.semanticscholar.org/paper/117595877c1fca610f94c8d07009105092939ecc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10095\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.145\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"title\":\"BiST: Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues\",\"url\":\"https://www.semanticscholar.org/paper/f4a2acfeb1705df3f430cc53ace26e1dbbbcbd16\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":\"10.1007/s11042-020-08917-3\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"title\":\"Fine grained sport action recognition with Twin spatio-temporal convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/621c1061cc70d9291c03a9d7d0f3a4f9f0127532\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2011.14585\",\"authors\":[{\"authorId\":\"66946727\",\"name\":\"Jaehui Hwang\"},{\"authorId\":\"3098768\",\"name\":\"Junhyuk Kim\"},{\"authorId\":\"1704860\",\"name\":\"J. Choi\"},{\"authorId\":\"11623715\",\"name\":\"J. Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"60a4fc6dc28ab47f517c53fb7440995a0a932505\",\"title\":\"Just One Moment: Inconspicuous One Frame Attack on Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60a4fc6dc28ab47f517c53fb7440995a0a932505\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98579574\",\"name\":\"Daizong Liu\"},{\"authorId\":\"51912474\",\"name\":\"Xiaoye Qu\"},{\"authorId\":\"1912074118\",\"name\":\"Jianfeng Dong\"},{\"authorId\":\"145232778\",\"name\":\"Pan Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"title\":\"Reasoning Step-by-Step: Temporal Sentence Localization in Videos via Deep Rectification-Modulation Network\",\"url\":\"https://www.semanticscholar.org/paper/83d2f3b57aa07c499c3a19d22fe4f4ef655e9030\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.02753\",\"authors\":[{\"authorId\":\"1612061859\",\"name\":\"Joshua Knights\"},{\"authorId\":\"1612351216\",\"name\":\"Anthony Vanderkop\"},{\"authorId\":\"143679553\",\"name\":\"D. Ward\"},{\"authorId\":\"1612210724\",\"name\":\"Olivia Mackenzie-Ross\"},{\"authorId\":\"145136889\",\"name\":\"P. Moghadam\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"195a51f9e4be3537f930d87f5200e63a51b9a226\",\"title\":\"Temporally Coherent Embeddings for Self-Supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/195a51f9e4be3537f930d87f5200e63a51b9a226\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.04743\",\"authors\":[{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/ICCV.2019.00402\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"title\":\"Reasoning About Human-Object Interactions Through Dual Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.03493\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"47739808\",\"name\":\"Junkun Chen\"},{\"authorId\":\"46255707\",\"name\":\"Lei Li\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/ICCV.2019.00468\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"title\":\"VaTeX: A Large-Scale, High-Quality Multilingual Dataset for Video-and-Language Research\",\"url\":\"https://www.semanticscholar.org/paper/28b74bb7c8b08cceb2430ec2d54dfa0f3225d796\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144149597\",\"name\":\"Tianshu Yu\"},{\"authorId\":\"2180892\",\"name\":\"Yikang Li\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1007/978-3-030-58607-2_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"title\":\"RhyRNN: Rhythmic RNN for Recognizing Events in Long and Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/b9ff84d2d45ec704d5680119d0ea0faa01f016be\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.04863\",\"authors\":[{\"authorId\":\"2160469\",\"name\":\"Y. Cao\"},{\"authorId\":\"1394232864\",\"name\":\"Qingfei Tang\"},{\"authorId\":\"50084994\",\"name\":\"X. Lu\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"},{\"authorId\":\"103151133\",\"name\":\"Jin-de Cao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"56c41a9f797cf1a23beb93b7571359fbc061397d\",\"title\":\"STCNet: Spatio-Temporal Cross Network for Industrial Smoke Detection\",\"url\":\"https://www.semanticscholar.org/paper/56c41a9f797cf1a23beb93b7571359fbc061397d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0bd7b15c7ae060eb029490d5b18617977eb28812\",\"title\":\"Learnable Gated Temporal Shift Module for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/0bd7b15c7ae060eb029490d5b18617977eb28812\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117618700\",\"name\":\"Thi Nhat Anh Nguyen\"},{\"authorId\":\"1692174\",\"name\":\"A. Bouzerdoum\"},{\"authorId\":\"1690887\",\"name\":\"S. Phung\"}],\"doi\":\"10.1109/TSP.2019.2911251\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fe7881dc3f15a96e4f7bba63057bbc8594dbbf3d\",\"title\":\"A Scalable Hierarchical Gaussian Process Classifier\",\"url\":\"https://www.semanticscholar.org/paper/fe7881dc3f15a96e4f7bba63057bbc8594dbbf3d\",\"venue\":\"IEEE Transactions on Signal Processing\",\"year\":2019},{\"arxivId\":\"1905.08711\",\"authors\":[{\"authorId\":\"48085995\",\"name\":\"A. Kozlov\"},{\"authorId\":\"117171023\",\"name\":\"V. Andronov\"},{\"authorId\":\"122388064\",\"name\":\"Y. Gritsenko\"}],\"doi\":\"10.1145/3341105.3373906\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4262413c55cf0319922c42b796c74879a0632a8\",\"title\":\"Lightweight network architecture for real-time action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d4262413c55cf0319922c42b796c74879a0632a8\",\"venue\":\"SAC\",\"year\":2020},{\"arxivId\":\"1811.12326\",\"authors\":[{\"authorId\":\"144692784\",\"name\":\"Mohsen Joneidi\"},{\"authorId\":\"2621521\",\"name\":\"Alireza Zaeemzadeh\"},{\"authorId\":\"1789219\",\"name\":\"N. Rahnavard\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/CVPR.2019.00556\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b\",\"title\":\"Iterative Projection and Matching: Finding Structure-Preserving Representatives and Its Application to Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1903.03793\",\"authors\":[{\"authorId\":\"49637157\",\"name\":\"W. Shao\"},{\"authorId\":\"47786834\",\"name\":\"Jingyu Li\"},{\"authorId\":\"2126876\",\"name\":\"Jia-Min Ren\"},{\"authorId\":\"2247393\",\"name\":\"Ruimao Zhang\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"}],\"doi\":\"10.1007/s11263-019-01269-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8eabed69bbebd83d90c7c27b731ff76edcd6b0a9\",\"title\":\"SSN: Learning Sparse Switchable Normalization via SparsestMax\",\"url\":\"https://www.semanticscholar.org/paper/8eabed69bbebd83d90c7c27b731ff76edcd6b0a9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1810.06807\",\"authors\":[{\"authorId\":\"145490315\",\"name\":\"Kartik Hegde\"},{\"authorId\":\"50843533\",\"name\":\"R. Agrawal\"},{\"authorId\":\"51463024\",\"name\":\"Yulun Yao\"},{\"authorId\":\"2012099\",\"name\":\"Christopher W. Fletcher\"}],\"doi\":\"10.1109/MICRO.2018.00080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"title\":\"Morph: Flexible Acceleration for 3D CNN-Based Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5a77877689e44e3ed48250f53e05b0d37bd901d7\",\"venue\":\"2018 51st Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)\",\"year\":2018},{\"arxivId\":\"1712.08416\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2699340\",\"name\":\"Yiyi Liao\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"150013821\",\"name\":\"A. Geiger\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"title\":\"On the Integration of Optical Flow and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":\"2011.14598\",\"authors\":[{\"authorId\":\"1753647133\",\"name\":\"Chen Zhao\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b19e442f6d313c211b522a791252de2c2468063b\",\"title\":\"Video Self-Stitching Graph Network for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b19e442f6d313c211b522a791252de2c2468063b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14139\",\"authors\":[{\"authorId\":\"1976656211\",\"name\":\"\\u00c7agri G\\u00f6k\\u00e7e\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"title\":\"Score-level Multi Cue Fusion for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/591a11dedfb9190ec66b3cd45c67cee824187a6d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.05769\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"01637f04eac8523b6c4887d419bd718f65860982\",\"title\":\"Removing the Background by Adding the Background: Towards Background Robust Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/01637f04eac8523b6c4887d419bd718f65860982\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1771623\",\"name\":\"G. Grossi\"},{\"authorId\":\"144750464\",\"name\":\"Raffaella Lanzarotti\"},{\"authorId\":\"91059725\",\"name\":\"P. Napoletano\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"}],\"doi\":\"10.1016/J.PATREC.2019.03.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33dad602f521318ff6be7c9c9a26fc1a5390fb86\",\"title\":\"Positive technology for elderly well-being: A review\",\"url\":\"https://www.semanticscholar.org/paper/33dad602f521318ff6be7c9c9a26fc1a5390fb86\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"2006.07397\",\"authors\":[{\"authorId\":\"8277405\",\"name\":\"Brian Dolhansky\"},{\"authorId\":\"1749686057\",\"name\":\"Joanna Bitton\"},{\"authorId\":\"1417654107\",\"name\":\"Ben Pflaum\"},{\"authorId\":\"119590112\",\"name\":\"Jikuo Lu\"},{\"authorId\":\"1410913697\",\"name\":\"Russ Howes\"},{\"authorId\":\"51202149\",\"name\":\"Menglin Wang\"},{\"authorId\":\"1958793545\",\"name\":\"Cristian Canton Ferrer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9790f95dc3ba6ecc516d8aca6f5cdff5dfcd5f35\",\"title\":\"The DeepFake Detection Challenge (DFDC) Dataset.\",\"url\":\"https://www.semanticscholar.org/paper/9790f95dc3ba6ecc516d8aca6f5cdff5dfcd5f35\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120899385\",\"name\":\"Ruolin Huang\"},{\"authorId\":\"2488122\",\"name\":\"Hongbin Dong\"},{\"authorId\":\"1775866\",\"name\":\"Guisheng Yin\"},{\"authorId\":\"145142015\",\"name\":\"Q. Fu\"}],\"doi\":\"10.1109/IJCNN.2019.8852054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d05d78ebc53fad692942e84cc80d260131a2618\",\"title\":\"Ensembling 3D CNN Framework for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d05d78ebc53fad692942e84cc80d260131a2618\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"563734713a37f3db7d37eabde24e6184495a1567\",\"title\":\"AutoLoc: Weakly-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/563734713a37f3db7d37eabde24e6184495a1567\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144809605\",\"name\":\"Xiaolong Liu\"},{\"authorId\":\"9177510\",\"name\":\"Y. Sun\"},{\"authorId\":\"2034194541\",\"name\":\"Jianghu Lu\"},{\"authorId\":\"2034240637\",\"name\":\"Cong Yao\"},{\"authorId\":\"47943518\",\"name\":\"Y. Zhou\"}],\"doi\":\"10.1109/LSP.2020.3037796\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"title\":\"Self-Similarity Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/0f7ee124e37bc0e4102f2f1e113b68a1cefee978\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"1905.13290\",\"authors\":[{\"authorId\":\"134142704\",\"name\":\"Jennifer L. Cardona\"},{\"authorId\":\"1937596\",\"name\":\"Michael F. Howland\"},{\"authorId\":\"5258799\",\"name\":\"J. Dabiri\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25244d056119a58dc45ad11c60e6f1648d0cedb4\",\"title\":\"Seeing the Wind: Visual Wind Speed Prediction with a Coupled Convolutional and Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/25244d056119a58dc45ad11c60e6f1648d0cedb4\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144740100\",\"name\":\"M. Kong\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"}],\"doi\":\"10.1007/978-3-030-32456-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"title\":\"Global Features of Fused Frame Relationships Help Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ac887b31488b78f9e6e1a98f3a1859454828a3ba\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":\"1910.02533\",\"authors\":[{\"authorId\":\"1384812397\",\"name\":\"Haoyuan Cao\"},{\"authorId\":\"48932880\",\"name\":\"Shining Yu\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"title\":\"Compressed Video Action Recognition with Refined Motion Vector\",\"url\":\"https://www.semanticscholar.org/paper/1b18e1431e96f32d152f49127c70a7dbc2a3061f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.04465\",\"authors\":[{\"authorId\":\"50262695\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"1500377539\",\"name\":\"Leilei Chen\"},{\"authorId\":\"152745066\",\"name\":\"Can-jin Wang\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3422844.3423051\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"189895b7f56f39d9e4ae5edf85eda866dd0412ff\",\"title\":\"SoccerDB: A Large-Scale Database for Comprehensive Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/189895b7f56f39d9e4ae5edf85eda866dd0412ff\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1390851600\",\"name\":\"Sixian Zhang\"},{\"authorId\":\"80513410\",\"name\":\"Yuyun Hua\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1145/3343031.3351051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a523e5333d30c9ad784e59fb857fa34b833925c3\",\"title\":\"Aberrance-aware Gradient-sensitive Attentions for Scene Recognition with RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/a523e5333d30c9ad784e59fb857fa34b833925c3\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80741236\",\"name\":\"J. Han\"},{\"authorId\":\"34668647\",\"name\":\"Z. Zuo\"}],\"doi\":\"10.1117/12.2539241\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"911195a1e69f0ac1df90ee483df05c2df6651e61\",\"title\":\"Anti-interference recognition using 3D convolutional network with improved attention block\",\"url\":\"https://www.semanticscholar.org/paper/911195a1e69f0ac1df90ee483df05c2df6651e61\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2020},{\"arxivId\":\"1911.11306\",\"authors\":[{\"authorId\":\"2537286\",\"name\":\"H. Eun\"},{\"authorId\":\"50112704\",\"name\":\"Sumin Lee\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"2024203\",\"name\":\"Chanho Jung\"},{\"authorId\":\"145568138\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1109/TCSVT.2019.2953187\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13aa627f35de78af64d1861fceb97c834a769b05\",\"title\":\"SRG: Snippet Relatedness-Based Temporal Action Proposal Generator\",\"url\":\"https://www.semanticscholar.org/paper/13aa627f35de78af64d1861fceb97c834a769b05\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2004.05573\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"47824843\",\"name\":\"W. Wang\"},{\"authorId\":\"1630359492\",\"name\":\"Ludan Ruan\"},{\"authorId\":\"49539732\",\"name\":\"Linli Yao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"78605f537f6c4a8c5206bdd4f57cea22d9750703\",\"title\":\"YouMakeup VQA Challenge: Towards Fine-grained Action Understanding in Domain-Specific Videos\",\"url\":\"https://www.semanticscholar.org/paper/78605f537f6c4a8c5206bdd4f57cea22d9750703\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1007/s11263-019-01191-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abd8cd4596accf16962c8ea324e229f765bf1200\",\"title\":\"A Spatiotemporal Convolutional Neural Network for Automatic Pain Intensity Estimation from Facial Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/abd8cd4596accf16962c8ea324e229f765bf1200\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1812.09041\",\"authors\":[{\"authorId\":\"153198570\",\"name\":\"Guoyun Tu\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"1728712\",\"name\":\"Boyang Li\"},{\"authorId\":\"11004839\",\"name\":\"Jiarui Gao\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":\"10.1109/TMM.2019.2922129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41b76703b03ecb40dbcc00e9fbf6a73b0b808778\",\"title\":\"A Multi-Task Neural Approach for Emotion Attribution, Classification, and Summarization\",\"url\":\"https://www.semanticscholar.org/paper/41b76703b03ecb40dbcc00e9fbf6a73b0b808778\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50341802\",\"name\":\"S. Li\"},{\"authorId\":\"87046280\",\"name\":\"H. Yang\"},{\"authorId\":\"1560347965\",\"name\":\"Jun Sun\"}],\"doi\":\"10.1109/ICIP40778.2020.9191071\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"title\":\"Multilevel Interaction Reasoning For Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8a4b39edaf6ca123705d2f77cba77753154a0a64\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20992076\",\"name\":\"Timothy Callemein\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"74922038\",\"name\":\"Floris De Feyter\"},{\"authorId\":\"73664580\",\"name\":\"Wim Boes\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2003472752\",\"name\":\"Tinne Tuytelaars\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1007/s11042-020-09616-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32921da55d7127169e901c4b3e5d6e2333185561\",\"title\":\"Show me where the action is!: Automatic capturing and timeline generation for reality TV.\",\"url\":\"https://www.semanticscholar.org/paper/32921da55d7127169e901c4b3e5d6e2333185561\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145798691\",\"name\":\"T. Han\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144323097\",\"name\":\"W. Yu\"}],\"doi\":\"10.1016/J.NEUCOM.2019.03.099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9695232daa85651937569d1b7b2541faf2633dc\",\"title\":\"Actionness-pooled Deep-convolutional Descriptor for fine-grained action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9695232daa85651937569d1b7b2541faf2633dc\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51218290\",\"name\":\"C. Baloescu\"},{\"authorId\":\"2003819296\",\"name\":\"Grzegorz Toporek\"},{\"authorId\":\"2003814777\",\"name\":\"Seungsoo Kim\"},{\"authorId\":\"119822592\",\"name\":\"Katelyn McNamara\"},{\"authorId\":\"2231904\",\"name\":\"R. Liu\"},{\"authorId\":\"2252427\",\"name\":\"M. Shaw\"},{\"authorId\":\"152948677\",\"name\":\"R.L. McNamara\"},{\"authorId\":\"46514947\",\"name\":\"Balasundar I. Raju\"},{\"authorId\":\"2515409\",\"name\":\"C. Moore\"}],\"doi\":\"10.1109/TUFFC.2020.3002249\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"32377f7e8d1cea7026567e7fc61171d000f92222\",\"title\":\"Automated Lung Ultrasound B-Line Assessment Using a Deep Learning Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/32377f7e8d1cea7026567e7fc61171d000f92222\",\"venue\":\"IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58539-6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part VI\",\"url\":\"https://www.semanticscholar.org/paper/72eb837c0d113dcdd51e57958e58d48e1759ea0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7245576\",\"name\":\"Qi Rao\"},{\"authorId\":\"153185012\",\"name\":\"G. Li\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"47190894\",\"name\":\"F. Zhang\"},{\"authorId\":\"1500519009\",\"name\":\"Ziwei Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b984875c3cf6b7dcaafc078fbab12d54c023ca40\",\"title\":\"UTS ISA Submission at the TRECVID 2019 Video to Text Description Task\",\"url\":\"https://www.semanticscholar.org/paper/b984875c3cf6b7dcaafc078fbab12d54c023ca40\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121866018\",\"name\":\"Guiyu Liu\"},{\"authorId\":\"2795127\",\"name\":\"J. Qian\"},{\"authorId\":\"144356873\",\"name\":\"Fei Wen\"},{\"authorId\":\"40491969\",\"name\":\"Xiaoguang Zhu\"},{\"authorId\":\"66717324\",\"name\":\"R. Ying\"},{\"authorId\":\"47478788\",\"name\":\"P. Liu\"}],\"doi\":\"10.1109/IROS40897.2019.8967570\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76209561db759fe8595b1f92056968564238e892\",\"title\":\"Action Recognition Based on 3D Skeleton and RGB Frame Fusion\",\"url\":\"https://www.semanticscholar.org/paper/76209561db759fe8595b1f92056968564238e892\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"1912.00869\",\"authors\":[{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"134455051\",\"name\":\"Marco Pistoia\"},{\"authorId\":\"66305116\",\"name\":\"D. Cox\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"title\":\"More Is Less: Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/9c77ffc223e47388155a6e3bf58ae294f51f9ccb\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"9297627\",\"name\":\"N. Balachandar\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3147852\",\"name\":\"Guido Pusiol\"},{\"authorId\":\"4421380\",\"name\":\"J. Luxenberg\"},{\"authorId\":\"49461537\",\"name\":\"Grace Li\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"3472674\",\"name\":\"A. Milstein\"},{\"authorId\":\"1435579960\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"9628d7ae049ff763626f1f3a4f33ebcacd746b15\",\"title\":\"Vision-Based Descriptive Analytics of Seniors \\u2019 Daily Activities for Long-Term Health Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/9628d7ae049ff763626f1f3a4f33ebcacd746b15\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47837986\",\"name\":\"An Yan\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"9247990\",\"name\":\"Zhifeng Li\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2019.00811\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"title\":\"PA3D: Pose-Action 3D Machine for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"}],\"doi\":\"10.21437/interspeech.2019-3143\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f78c136471778771c29fb385d3a8c1a1def28de1\",\"title\":\"Joint Student-Teacher Learning for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f78c136471778771c29fb385d3a8c1a1def28de1\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235962\",\"name\":\"Juarez Monteiro\"},{\"authorId\":\"3045512\",\"name\":\"Roger Granada\"},{\"authorId\":\"10684139\",\"name\":\"Jo\\u00e3o Paulo Aires\"},{\"authorId\":\"143914916\",\"name\":\"Rodrigo C. Barros\"}],\"doi\":\"10.1109/IJCNN.2018.8489297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eee24e29b1b73bbd1e75ad3cebe28c360f4aab84\",\"title\":\"Evaluating the Feasibility of Deep Learning for Action Recognition in Small Datasets\",\"url\":\"https://www.semanticscholar.org/paper/eee24e29b1b73bbd1e75ad3cebe28c360f4aab84\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588999\",\"name\":\"J. Pan\"},{\"authorId\":\"49952482\",\"name\":\"J. Gao\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a2eb49b9c14075b35b33db7640085ce785e40223\",\"title\":\"Supplementary Material for \\u201cAction Assessment by Joint Relation Graphs\\u201d\",\"url\":\"https://www.semanticscholar.org/paper/a2eb49b9c14075b35b33db7640085ce785e40223\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1812.01233\",\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"title\":\"Classifying Collisions with Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/09dc45f036781ccfc51cdc7a6f2057aba8b5ff10\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2006.16367\",\"authors\":[{\"authorId\":\"1901361\",\"name\":\"Pramit Saha\"},{\"authorId\":\"46398931\",\"name\":\"Y. Liu\"},{\"authorId\":\"2160324\",\"name\":\"B. Gick\"},{\"authorId\":\"23111666\",\"name\":\"S. Fels\"}],\"doi\":\"10.1007/978-3-030-59716-0_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11809d6c31e471fb45569c5f40f3f4e7566ee3ce\",\"title\":\"Ultra2Speech - A Deep Learning Framework for Formant Frequency Estimation and Tracking from Ultrasound Tongue Images\",\"url\":\"https://www.semanticscholar.org/paper/11809d6c31e471fb45569c5f40f3f4e7566ee3ce\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2d5d85a741f7926d8774e037c57a245ae6c94356\",\"title\":\"Online Action Detection in Untrimmed, Streaming Videos - Modeling and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/2d5d85a741f7926d8774e037c57a245ae6c94356\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1809.03258\",\"authors\":[{\"authorId\":\"9179750\",\"name\":\"Omar Hommos\"},{\"authorId\":\"37041694\",\"name\":\"S. L. Pintea\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1007/978-3-030-11024-6_51\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"23dbada22825613e7c616eb60af0c8a812372f3b\",\"title\":\"Using phase instead of optical flow for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/23dbada22825613e7c616eb60af0c8a812372f3b\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1811.10811\",\"authors\":[{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"1409219085\",\"name\":\"Paulo Lopez-Meyer\"},{\"authorId\":\"1798616\",\"name\":\"Omesh Tickoo\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1cca57d2532a4085fb357c10237bdded69541310\",\"title\":\"Uncertainty aware multimodal activity recognition with Bayesian inference\",\"url\":\"https://www.semanticscholar.org/paper/1cca57d2532a4085fb357c10237bdded69541310\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"47067803\",\"name\":\"Hao Jiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"title\":\"Action 4 D : Online Action Recognition in the Crowd and Clutter Quanzeng\",\"url\":\"https://www.semanticscholar.org/paper/53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49969948\",\"name\":\"Zhihui Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c66eb0e17076bff559d8f94a8f967d52db2bab01\",\"title\":\"Video Classification System for Moments in Time Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/c66eb0e17076bff559d8f94a8f967d52db2bab01\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3830276\",\"name\":\"M. Briedis\"},{\"authorId\":\"2295280\",\"name\":\"Karlis Freivalds\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ddca2815ec94ed66ddc5cf08220e2fc1f232343\",\"title\":\"On-line Television Stream Classification by Genre Karlis\",\"url\":\"https://www.semanticscholar.org/paper/3ddca2815ec94ed66ddc5cf08220e2fc1f232343\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/TIP.2019.2922826\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"title\":\"Compact and Low-Complexity Binary Feature Descriptor and Fisher Vectors for Video Analytics\",\"url\":\"https://www.semanticscholar.org/paper/9b7d9e2ba591b2b298a63a13ecf08433193704fd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/CVPR.2019.00429\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"714df3e97817ec56b8dbc7217155adadf2a0487f\",\"title\":\"Iterative Alignment Network for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/714df3e97817ec56b8dbc7217155adadf2a0487f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41185832\",\"name\":\"Xiaochun Luo\"},{\"authorId\":\"5342346\",\"name\":\"H. Li\"},{\"authorId\":\"32676626\",\"name\":\"Yan-tao Yu\"},{\"authorId\":\"144143222\",\"name\":\"C. Zhou\"},{\"authorId\":\"46690737\",\"name\":\"Dongping Cao\"}],\"doi\":\"10.1111/mice.12538\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"452fa24781dfbed3de50a0a5af416a4e5bc0de93\",\"title\":\"Combining deep features and activity context to improve recognition of activities of workers in groups\",\"url\":\"https://www.semanticscholar.org/paper/452fa24781dfbed3de50a0a5af416a4e5bc0de93\",\"venue\":\"Comput. Aided Civ. Infrastructure Eng.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103887800\",\"name\":\"Rose Rustowicz\"},{\"authorId\":\"113983041\",\"name\":\"Robin Cheong\"},{\"authorId\":\"51471745\",\"name\":\"Lijing Wang\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"49240687\",\"name\":\"M. Burke\"},{\"authorId\":\"2465182\",\"name\":\"D. Lobell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87f0cffad2d7527273a25a945736c1e813c08312\",\"title\":\"Semantic Segmentation of Crop Type in Africa: A Novel Dataset and Analysis of Deep Learning Methods\",\"url\":\"https://www.semanticscholar.org/paper/87f0cffad2d7527273a25a945736c1e813c08312\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1908.04519\",\"authors\":[{\"authorId\":\"97765655\",\"name\":\"J. Xia\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82614927db94b233415975ab98f92e9468e6492\",\"title\":\"Three Branches: Detecting Actions With Richer Features\",\"url\":\"https://www.semanticscholar.org/paper/a82614927db94b233415975ab98f92e9468e6492\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.00308\",\"authors\":[{\"authorId\":\"121310313\",\"name\":\"Yiyi Zhang\"},{\"authorId\":\"1716055\",\"name\":\"Li Niu\"},{\"authorId\":\"13944031\",\"name\":\"Ziqi Pan\"},{\"authorId\":\"1438947172\",\"name\":\"Meichao Luo\"},{\"authorId\":\"49051251\",\"name\":\"Jianfu Zhang\"},{\"authorId\":\"2476347\",\"name\":\"Dawei Cheng\"},{\"authorId\":\"48571700\",\"name\":\"L. Zhang\"}],\"doi\":\"10.1609/AAAI.V34I07.6990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"223eba328e72650eda1cc85817f4d396cc116eb4\",\"title\":\"Exploiting Motion Information from Unlabeled Videos for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/223eba328e72650eda1cc85817f4d396cc116eb4\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2011.10974\",\"authors\":[{\"authorId\":\"39431125\",\"name\":\"Shuyang Gu\"},{\"authorId\":\"9324504\",\"name\":\"Jian-min Bao\"},{\"authorId\":\"2013406166\",\"name\":\"Dong Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"title\":\"Learnable Sampling 3D Convolution for Video Enhancement and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/906c0c47fea0842a6dc5d1301c916eae025a2d90\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2012.00822\",\"authors\":[{\"authorId\":\"1387720883\",\"name\":\"Haozheng Luo\"},{\"authorId\":\"1443782482\",\"name\":\"Ruiyang Qin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1fe97e5fd1b7151d5ab6565bfe3ca6efe034575\",\"title\":\"Open-Ended Multi-Modal Relational Reason for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b1fe97e5fd1b7151d5ab6565bfe3ca6efe034575\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"}],\"doi\":\"10.1007/978-3-030-58520-4_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e8a596261cfd846538811edf7db7d5f754b1159\",\"title\":\"Is Sharing of Egocentric Video Giving Away Your Biometric Signature?\",\"url\":\"https://www.semanticscholar.org/paper/5e8a596261cfd846538811edf7db7d5f754b1159\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.05637\",\"authors\":[{\"authorId\":\"144449335\",\"name\":\"H. Huang\"},{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"15908912ce3943fc5ec281c1cbf062722cb114d7\",\"title\":\"Dynamic Graph Modules for Modeling Higher-Order Interactions in Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/15908912ce3943fc5ec281c1cbf062722cb114d7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2011.08410\",\"authors\":[{\"authorId\":\"70407208\",\"name\":\"Xiaoyuan Ni\"},{\"authorId\":\"95437724\",\"name\":\"S. Song\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6351a42c1ddf9f13163b55c49a8c05caf48a0169\",\"title\":\"Semi-Supervised Few-Shot Atomic Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6351a42c1ddf9f13163b55c49a8c05caf48a0169\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978810071\",\"name\":\"Konstantinos Bacharidis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45c8d29798aa423f2cadde1b9b177b6a2edc52aa\",\"title\":\"Extracting Action Hierarchies from Action Labels and their Use in Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45c8d29798aa423f2cadde1b9b177b6a2edc52aa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.09280\",\"authors\":[{\"authorId\":\"145921274\",\"name\":\"Thomas Teixeira\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"},{\"authorId\":\"1808179\",\"name\":\"Alessandro Lameiras Koerich\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6378b4350e6cfe969692bf83e6b5c7675f56491c\",\"title\":\"Continuous Emotion Recognition with Spatiotemporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6378b4350e6cfe969692bf83e6b5c7675f56491c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.07256\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/CVPR.2019.00133\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a03bda078490e8ee991a1f86b53f27df7cf93a14\",\"title\":\"Graph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/a03bda078490e8ee991a1f86b53f27df7cf93a14\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2006.09220\",\"authors\":[{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.00369\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4673e744d0ded47fe6df3b6314f79a41359578b\",\"title\":\"MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b4673e744d0ded47fe6df3b6314f79a41359578b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.02422\",\"authors\":[{\"authorId\":\"1737602\",\"name\":\"C. Zhang\"},{\"authorId\":\"47103450\",\"name\":\"Yunlu Xu\"},{\"authorId\":\"2398015\",\"name\":\"Zhanzhan Cheng\"},{\"authorId\":\"2760746\",\"name\":\"Yi Niu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"},{\"authorId\":\"47586475\",\"name\":\"Futai Zou\"}],\"doi\":\"10.1145/3343031.3351044\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc4ce2dff0b386dbe28a67db78314c00926c79a8\",\"title\":\"Adversarial Seeded Sequence Growing for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/cc4ce2dff0b386dbe28a67db78314c00926c79a8\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1908.01536\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144353457\",\"name\":\"A. D. Marshall\"},{\"authorId\":\"113727107\",\"name\":\"Harrison B Taylor\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7242dfc1d8124cf8c91bcc7d8c62fee7d274198\",\"title\":\"Discriminating Spatial and Temporal Relevance in Deep Taylor Decompositions for Explainable Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e7242dfc1d8124cf8c91bcc7d8c62fee7d274198\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"47672151\",\"name\":\"Ning Xu\"},{\"authorId\":\"153576780\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"},{\"authorId\":\"121310224\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TIP.2018.2872879\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6f96d433e91ddf46d8a7b174dfbdd8eed1087d40\",\"title\":\"Multi-Domain and Multi-Task Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f96d433e91ddf46d8a7b174dfbdd8eed1087d40\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1912.10982\",\"authors\":[{\"authorId\":\"145223169\",\"name\":\"N. C. Garcia\"},{\"authorId\":\"16040476\",\"name\":\"S. A. Bargal\"},{\"authorId\":\"1852308\",\"name\":\"Vitaly Ablavsky\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"846fca8fa98753223f464b187cb59b02a8a1ccae\",\"title\":\"DMCL: Distillation Multiple Choice Learning for Multimodal Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/846fca8fa98753223f464b187cb59b02a8a1ccae\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.00497\",\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/ICCVW.2019.00552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5769318fd67d1104e561b7382b305b5ca810d6d2\",\"title\":\"Two-Stream Video Classification with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/5769318fd67d1104e561b7382b305b5ca810d6d2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.3233/IA-190021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"title\":\"Top-down attention recurrent VLAD encoding for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"venue\":\"Intelligenza Artificiale\",\"year\":2019},{\"arxivId\":\"1812.01717\",\"authors\":[{\"authorId\":\"2465270\",\"name\":\"Thomas Unterthiner\"},{\"authorId\":\"3440930\",\"name\":\"Sjoerd van Steenkiste\"},{\"authorId\":\"2006889\",\"name\":\"Karol Kurach\"},{\"authorId\":\"52153018\",\"name\":\"Rapha\\u00ebl Marinier\"},{\"authorId\":\"144859281\",\"name\":\"M. Michalski\"},{\"authorId\":\"1802148\",\"name\":\"S. Gelly\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b59233aab8364186603967bc12d88af48cc0992d\",\"title\":\"Towards Accurate Generative Models of Video: A New Metric & Challenges\",\"url\":\"https://www.semanticscholar.org/paper/b59233aab8364186603967bc12d88af48cc0992d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2007.06866\",\"authors\":[{\"authorId\":\"150348841\",\"name\":\"Yuchi Ishikawa\"},{\"authorId\":\"1381411615\",\"name\":\"Seito Kasai\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"title\":\"Alleviating Over-segmentation Errors by Detecting Action Boundaries\",\"url\":\"https://www.semanticscholar.org/paper/4fed0235614df46fa0c53e05b71e9939b53a1bdf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":\"7296530\",\"name\":\"Hongyu Zhu\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1751179\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"title\":\"Reversing Two-Stream Networks with Decoding Discrepancy Penalty for Robust Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10f7551bb9f6fa992660e70cb2896b8d5bdcc406\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2882156\",\"name\":\"B. Ayhan\"},{\"authorId\":\"143689616\",\"name\":\"C. Kwan\"},{\"authorId\":\"18098724\",\"name\":\"Bence Budavari\"},{\"authorId\":\"66991683\",\"name\":\"J. Larkin\"},{\"authorId\":\"66931183\",\"name\":\"David Gribben\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"}],\"doi\":\"10.1109/ACCESS.2020.3033190\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b02c4b808b4b9a13fcb5eaf6140e55a0b1247a2\",\"title\":\"Video Activity Recognition With Varying Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/4b02c4b808b4b9a13fcb5eaf6140e55a0b1247a2\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1912.03647\",\"authors\":[{\"authorId\":\"1452735766\",\"name\":\"Dingheng Wang\"},{\"authorId\":\"8278873\",\"name\":\"Guang-She Zhao\"},{\"authorId\":\"47949360\",\"name\":\"Guoqi Li\"},{\"authorId\":\"143895325\",\"name\":\"L. Deng\"},{\"authorId\":\"50741340\",\"name\":\"Yang Wu\"}],\"doi\":\"10.1016/j.neunet.2020.07.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64b889ae5e703e1a89590288b0292eec8e5b7f83\",\"title\":\"Lossless Compression for 3DCNNs Based on Tensor Train Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/64b889ae5e703e1a89590288b0292eec8e5b7f83\",\"venue\":\"Neural networks : the official journal of the International Neural Network Society\",\"year\":2020},{\"arxivId\":\"2012.02109\",\"authors\":[{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72b19a0125ddda2752cfcf8c5758a13c52275665\",\"title\":\"SAFCAR: Structured Attention Fusion for Compositional Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b19a0125ddda2752cfcf8c5758a13c52275665\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11118\",\"authors\":[{\"authorId\":\"1825785725\",\"name\":\"Ollie Matthews\"},{\"authorId\":\"1825814505\",\"name\":\"Koki Ryu\"},{\"authorId\":\"121319612\",\"name\":\"Tarun Srivastava\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"725c15261a57eca5a4207f63aa217c97ad75dfda\",\"title\":\"Creating a Large-scale Synthetic Dataset for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/725c15261a57eca5a4207f63aa217c97ad75dfda\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1007/978-3-030-58523-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b26d5d20b073828898087f99b81736c0629c1798\",\"title\":\"Learning Trailer Moments in Full-Length Movies with Co-Contrastive Attention\",\"url\":\"https://www.semanticscholar.org/paper/b26d5d20b073828898087f99b81736c0629c1798\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_32\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"44e8ddac792f35105dd4db176345515f531a0b71\",\"title\":\"Bottom-Up Temporal Action Localization with Mutual Regularization\",\"url\":\"https://www.semanticscholar.org/paper/44e8ddac792f35105dd4db176345515f531a0b71\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.02824\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"3735710\",\"name\":\"Baopu Li\"},{\"authorId\":\"40106915\",\"name\":\"Sid Ying-Ze Bao\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"}],\"doi\":\"10.1109/cvpr42600.2020.00947\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc55547093065ce808d13c55c8baff334d197493\",\"title\":\"Action Segmentation With Joint Self-Supervised Temporal Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/bc55547093065ce808d13c55c8baff334d197493\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.10457\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1390538450\",\"name\":\"Xun Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"title\":\"Language Guided Networks for Cross-modal Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/60e3cc7a1ba3e8617269b801b41692ed5f613b3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Iuliia Kotseruba\"},{\"authorId\":null,\"name\":\"Amir Rasouli\"},{\"authorId\":null,\"name\":\"John K. Tsotsos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6eed01d812c9355f2ee0f5737f8718b3ecbb17f9\",\"title\":\"Benchmark for Evaluating Pedestrian Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6eed01d812c9355f2ee0f5737f8718b3ecbb17f9\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122572973\",\"name\":\"Md. Moniruzzaman\"},{\"authorId\":\"1993660364\",\"name\":\"Zhaozheng Yin\"},{\"authorId\":\"1700714\",\"name\":\"Z. He\"},{\"authorId\":\"2777406\",\"name\":\"R. Qin\"},{\"authorId\":\"2281499\",\"name\":\"Ming C. Leu\"}],\"doi\":\"10.1145/3394171.3413687\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"393aaa45767018e184499556f078640fb016475b\",\"title\":\"Action Completeness Modeling with Background Aware Networks for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/393aaa45767018e184499556f078640fb016475b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.04002\",\"authors\":[{\"authorId\":\"1828765893\",\"name\":\"Liliane Momeni\"},{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"2285516\",\"name\":\"Triantafyllos Afouras\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"631bbcce16387e76e4780d7c84b07b2a37d6bfc4\",\"title\":\"Watch, read and lookup: learning to spot signs from multiple supervisors\",\"url\":\"https://www.semanticscholar.org/paper/631bbcce16387e76e4780d7c84b07b2a37d6bfc4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1923065213\",\"name\":\"Qinghongya Shi\"},{\"authorId\":\"46702837\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"89616898\",\"name\":\"Haotian Ren\"},{\"authorId\":\"3721965\",\"name\":\"Ji-Xiang Du\"},{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"}],\"doi\":\"10.1186/s13640-020-00519-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"title\":\"Consistent constraint-based video-level learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b76ca4e12247ed63f98b0c1949a4eb9105ec1407\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/cvpr42600.2020.00440\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be775b7c6c59d40a7437f1ca49f3697b4d2f6d97\",\"title\":\"Inflated Episodic Memory With Region Self-Attention for Long-Tailed Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be775b7c6c59d40a7437f1ca49f3697b4d2f6d97\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395615456\",\"name\":\"Elena Nicora\"},{\"authorId\":\"2442124\",\"name\":\"Gaurvi Goyal\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"}],\"doi\":\"10.1007/978-3-030-30642-7_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"64b3de3c043cc84ffa6d12ad3eb4e77592305e36\",\"title\":\"The Effects of Data Sources: A Baseline Evaluation of the MoCA Dataset\",\"url\":\"https://www.semanticscholar.org/paper/64b3de3c043cc84ffa6d12ad3eb4e77592305e36\",\"venue\":\"ICIAP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145294961\",\"name\":\"L. Chi\"},{\"authorId\":\"9443552\",\"name\":\"G. Tian\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3343031.3351029\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"933f2a39e35018db2442c08f7603a14a70efb06b\",\"title\":\"Fast Non-Local Neural Networks with Spectral Residual Learning\",\"url\":\"https://www.semanticscholar.org/paper/933f2a39e35018db2442c08f7603a14a70efb06b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3451806\",\"name\":\"A. Caterini\"},{\"authorId\":\"34386345\",\"name\":\"D. E. Chang\"}],\"doi\":\"10.1007/978-3-319-75304-1_5\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f9b23a7270939136872d5e170b4a80aad68a4e66\",\"title\":\"Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f9b23a7270939136872d5e170b4a80aad68a4e66\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1808.04234\",\"authors\":[{\"authorId\":\"22246693\",\"name\":\"Shitao Tang\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"9407393\",\"name\":\"Y. Chen\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1007/978-3-030-20887-5_36\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c5a784d96aaf6cd41f1460d58259480503df7270\",\"title\":\"Fast Video Shot Transition Localization with Deep Structured Models\",\"url\":\"https://www.semanticscholar.org/paper/c5a784d96aaf6cd41f1460d58259480503df7270\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50750258\",\"name\":\"T. Okawara\"},{\"authorId\":\"80809027\",\"name\":\"M. Yoshida\"},{\"authorId\":\"145800886\",\"name\":\"H. Nagahara\"},{\"authorId\":\"1715071\",\"name\":\"Y. Yagi\"}],\"doi\":\"10.1109/ICCP48838.2020.9105176\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"title\":\"Action Recognition from a Single Coded Image\",\"url\":\"https://www.semanticscholar.org/paper/90ccdae5898712d2cb59d52f6aad0aeb64066eb6\",\"venue\":\"2020 IEEE International Conference on Computational Photography (ICCP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51471751\",\"name\":\"L. Wang\"},{\"authorId\":\"1750908328\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"1750919212\",\"name\":\"Xiaolei Yin\"},{\"authorId\":\"1749687892\",\"name\":\"Jing Qiu\"},{\"authorId\":\"50109694\",\"name\":\"Z. Yang\"},{\"authorId\":\"8262648\",\"name\":\"Junhui Xing\"},{\"authorId\":\"28094546\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"9249638\",\"name\":\"Zhao-yuan Ma\"}],\"doi\":\"10.1186/s12880-020-00509-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3edbb47db70ec1243530c0efd4257e138a99a959\",\"title\":\"Coronary artery segmentation in angiographic videos utilizing spatial-temporal information\",\"url\":\"https://www.semanticscholar.org/paper/3edbb47db70ec1243530c0efd4257e138a99a959\",\"venue\":\"BMC Medical Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"153146470\",\"name\":\"Dan Yang\"},{\"authorId\":\"3160299\",\"name\":\"Martin J\\u00e4gersand\"}],\"doi\":\"10.1016/J.PATCOG.2020.107686\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc5af1aff1839364b448a29dedd06e43bd133ea2\",\"title\":\"Deep snippet selective network for weakly supervised temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/fc5af1aff1839364b448a29dedd06e43bd133ea2\",\"venue\":\"Pattern Recognit.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"2010.01343\",\"authors\":[{\"authorId\":\"153257128\",\"name\":\"A. Srivastava\"},{\"authorId\":\"83923404\",\"name\":\"O. Dutta\"},{\"authorId\":\"2988091\",\"name\":\"A. Prathosh\"},{\"authorId\":\"47208444\",\"name\":\"Sumeet Agarwal\"},{\"authorId\":\"66286585\",\"name\":\"J. Gupta\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b4a545203ed195f77bb2fa4fcb90199ff7784f74\",\"title\":\"A Variational Information Bottleneck Based Method to Compress Sequential Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4a545203ed195f77bb2fa4fcb90199ff7784f74\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02646\",\"authors\":[{\"authorId\":\"1992634637\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"2027130177\",\"name\":\"J. Fu\"},{\"authorId\":\"38534822\",\"name\":\"Y. Lu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"261582574b9e039be1518bc7c8e405a4af75a41a\",\"title\":\"Multi-Scale 2D Temporal Adjacent Networks for Moment Localization with Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/261582574b9e039be1518bc7c8e405a4af75a41a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.05884\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/ICCV.2019.00829\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a\",\"title\":\"GODS: Generalized One-Class Discriminative Subspaces for Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/9a9e4c1052401ed1a7231cf30a05a5c26e5ee37a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1911.08446\",\"authors\":[{\"authorId\":\"144930542\",\"name\":\"D. Gil\"},{\"authorId\":\"145931119\",\"name\":\"W. Green\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c74747d0ec71c96de23fc1873d07bd6d70e7ebd\",\"title\":\"The Future of Computing: Bits + Neurons + Qubits\",\"url\":\"https://www.semanticscholar.org/paper/1c74747d0ec71c96de23fc1873d07bd6d70e7ebd\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.09805\",\"authors\":[{\"authorId\":\"1491401265\",\"name\":\"Shuang Ma\"},{\"authorId\":\"46490565\",\"name\":\"Zhaoyang Zeng\"},{\"authorId\":\"1381192475\",\"name\":\"Daniel McDuff\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7df5dd31f2ce600a4be589dff4d6a758be262324\",\"title\":\"Learning Audio-Visual Representations with Active Contrastive Coding\",\"url\":\"https://www.semanticscholar.org/paper/7df5dd31f2ce600a4be589dff4d6a758be262324\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.08895\",\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"},{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65961eb0380182c32ab3d018c83010aa80969d8a\",\"title\":\"An Efficient 3D CNN for Action/Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/65961eb0380182c32ab3d018c83010aa80969d8a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1906.03327\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/ICCV.2019.00272\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9311779489e597315488749ee6c386bfa3f3512e\",\"title\":\"HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips\",\"url\":\"https://www.semanticscholar.org/paper/9311779489e597315488749ee6c386bfa3f3512e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"49984779\",\"name\":\"Chih-Chieh Yang\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"32168186\",\"name\":\"F. Zhou\"},{\"authorId\":\"1795283\",\"name\":\"B. Chen\"}],\"doi\":\"10.1016/j.jpdc.2019.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d0f0e835a46a7a7938f0eab4e2234a5d2c3bb15\",\"title\":\"Fast neural network training on a cluster of GPUs for action recognition with high accuracy\",\"url\":\"https://www.semanticscholar.org/paper/1d0f0e835a46a7a7938f0eab4e2234a5d2c3bb15\",\"venue\":\"J. Parallel Distributed Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12761053\",\"name\":\"Alexandre Szenicer\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"1410303188\",\"name\":\"A. Munoz-Jaramillo\"},{\"authorId\":\"1410819294\",\"name\":\"P. Wright\"},{\"authorId\":\"3022450\",\"name\":\"R. Thomas\"},{\"authorId\":\"83778338\",\"name\":\"R. Galvez\"},{\"authorId\":\"1709007\",\"name\":\"M. Jin\"},{\"authorId\":\"144177645\",\"name\":\"M. C. M. Cheung\"}],\"doi\":\"10.1126/sciadv.aaw6548\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5d42cbd5650fa27b543acd52d55f74157cb0f669\",\"title\":\"A deep learning virtual instrument for monitoring extreme UV solar spectral irradiance\",\"url\":\"https://www.semanticscholar.org/paper/5d42cbd5650fa27b543acd52d55f74157cb0f669\",\"venue\":\"Science Advances\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7516588\",\"name\":\"Faramarz Ataollahi\"},{\"authorId\":\"145086905\",\"name\":\"M. Suarez\"}],\"doi\":\"10.1145/3369114.3369142\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6b2a405f0e0a2b9ef63088c3fc4c88731758b87\",\"title\":\"Laughter Classification Using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d6b2a405f0e0a2b9ef63088c3fc4c88731758b87\",\"venue\":\"ICAAI 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000519679\",\"name\":\"Cheng Ming\"},{\"authorId\":\"2024215885\",\"name\":\"Cai Kunjing\"},{\"authorId\":\"143740589\",\"name\":\"Li Ming\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"091a6ac9f23460f91bda48084a608b51280e5be1\",\"title\":\"RWF-2000: An Open Large Scale Video Database for Violence Detection\",\"url\":\"https://www.semanticscholar.org/paper/091a6ac9f23460f91bda48084a608b51280e5be1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651877\",\"name\":\"Changlin Li\"},{\"authorId\":\"49969948\",\"name\":\"Zhihui Li\"},{\"authorId\":\"1808390\",\"name\":\"ZongYuan Ge\"},{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"}],\"doi\":\"10.1016/j.jvcir.2019.102628\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2afb75192852c9bc56727070fbd3f0c502bebdf6\",\"title\":\"Knowledge driven temporal activity localization\",\"url\":\"https://www.semanticscholar.org/paper/2afb75192852c9bc56727070fbd3f0c502bebdf6\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1902.10640\",\"authors\":[{\"authorId\":\"34971636\",\"name\":\"Shweta Bhardwaj\"},{\"authorId\":\"34658653\",\"name\":\"M. Srinivasan\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1109/CVPR.2019.00044\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"58f32f1e294569f88d20892c11b389105da9c615\",\"title\":\"Efficient Video Classification Using Fewer Frames\",\"url\":\"https://www.semanticscholar.org/paper/58f32f1e294569f88d20892c11b389105da9c615\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2011.00826\",\"authors\":[{\"authorId\":null,\"name\":\"Zihao Wang\"},{\"authorId\":\"5739094\",\"name\":\"Chen Lin\"},{\"authorId\":\"1999541581\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"316931202b0d02d37672a976f43bb1ed479c6877\",\"title\":\"PV-NAS: Practical Neural Architecture Search for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/316931202b0d02d37672a976f43bb1ed479c6877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2205770\",\"name\":\"Tackgeun You\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1007/978-3-030-58571-6_32\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39fad4820b9a1d5186c915e171e8ef307f6ef98d\",\"title\":\"Traffic Accident Benchmark for Causality Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39fad4820b9a1d5186c915e171e8ef307f6ef98d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.05757\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"151470972\",\"name\":\"Yuting Gao\"},{\"authorId\":\"104106360\",\"name\":\"Ke Li\"},{\"authorId\":\"2046022\",\"name\":\"X. Jiang\"},{\"authorId\":\"152978186\",\"name\":\"Xiao-wei Guo\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"143900241\",\"name\":\"Xing Sun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cfff32dd150ee568384d60708622e2a3917fd6cf\",\"title\":\"Enhancing Unsupervised Video Representation Learning by Decoupling the Scene and the Motion\",\"url\":\"https://www.semanticscholar.org/paper/cfff32dd150ee568384d60708622e2a3917fd6cf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.00367\",\"authors\":[{\"authorId\":\"152509251\",\"name\":\"Joonatan M\\u00e4ntt\\u00e4ri\"},{\"authorId\":\"67200092\",\"name\":\"S. Broom\\u00e9\"},{\"authorId\":\"3248522\",\"name\":\"John Folkesson\"},{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab78636736e978b814af4ecbe42d116bbfbbac1f\",\"title\":\"Interpreting video features: a comparison of 3D convolutional networks and convolutional LSTM networks\",\"url\":\"https://www.semanticscholar.org/paper/ab78636736e978b814af4ecbe42d116bbfbbac1f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65773211\",\"name\":\"Carlos Ant\\u00f4nio Caetano J\\u00fanior\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"title\":\"Motion-based representations for activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/21f42f737204ab5a8a0e9dbf1417b1bb26a07273\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.09102\",\"authors\":[{\"authorId\":\"39576371\",\"name\":\"A. Manglik\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"11e677e2721f0196c7ab93d15cc59047bfa3ff17\",\"title\":\"Future Near-Collision Prediction from Monocular Video: Feasibility, Dataset, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/11e677e2721f0196c7ab93d15cc59047bfa3ff17\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2003.04145\",\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"49473137\",\"name\":\"Zhixiang Shi\"},{\"authorId\":\"1492113737\",\"name\":\"Jiani Li\"},{\"authorId\":\"50248679\",\"name\":\"Guanshuo Wang\"},{\"authorId\":\"46499930\",\"name\":\"Y. Yuan\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"},{\"authorId\":\"50177639\",\"name\":\"Xiaoping Zhou\"}],\"doi\":\"10.1609/AAAI.V34I07.6711\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36e38dbfee27f7a34d184dd58186944636de5258\",\"title\":\"Accurate Temporal Action Proposal Generation with Relation-Aware Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/36e38dbfee27f7a34d184dd58186944636de5258\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1907.08340\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"28554843\",\"name\":\"Vedanuj Goswami\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"title\":\"Only Time Can Tell: Discovering Temporal Data for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/8e79a677855462aa55ea252ffb35c8cac1fed26e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"143868490\",\"name\":\"G. Berger\"},{\"authorId\":\"1557638138\",\"name\":\"Ingo Bax\"},{\"authorId\":\"1557636479\",\"name\":\"Roland Memisevic\"}],\"doi\":\"10.1109/ICCVW.2019.00349\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ef708ce97183dc9a0e9514a80fc8dacf7ca29c5\",\"title\":\"The Jester Dataset: A Large-Scale Video Dataset of Human Gestures\",\"url\":\"https://www.semanticscholar.org/paper/8ef708ce97183dc9a0e9514a80fc8dacf7ca29c5\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30801168\",\"name\":\"Hugo A. L. F. Chaves\"},{\"authorId\":\"1637447474\",\"name\":\"Kevyn Swhants Ribeiro\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"47379712\",\"name\":\"A. S. Cerqueira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0008957606850694\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67116d16fc8959e2eb5e7428aaf96ac02c0feed6\",\"title\":\"Filter Learning from Deep Descriptors of a Fully Convolutional Siamese Network for Tracking in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67116d16fc8959e2eb5e7428aaf96ac02c0feed6\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3530540\",\"name\":\"Yunbo Wang\"},{\"authorId\":\"144811736\",\"name\":\"L. Jiang\"},{\"authorId\":\"1715634\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"3216322\",\"name\":\"L. Fei-Fei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2eb604863b671763de17905ad715a225d9fe43e9\",\"title\":\"Unit Frame 3 : T + 2 Frame 1 : T Frame 2 : T + 1 FrameT + 1 FrameT + 2 FrameT + 3\",\"url\":\"https://www.semanticscholar.org/paper/2eb604863b671763de17905ad715a225d9fe43e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1903.01197\",\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"1842317\",\"name\":\"Qiaoyong Zhong\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"}],\"doi\":\"10.1109/CVPR.2019.00806\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"title\":\"Collaborative Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.09862\",\"authors\":[{\"authorId\":\"50264698\",\"name\":\"K. Saleh\"},{\"authorId\":\"1922050\",\"name\":\"M. Hossny\"},{\"authorId\":\"1743136\",\"name\":\"S. Nahavandi\"}],\"doi\":\"10.1109/ICRA.2019.8793991\",\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c454cbf9d6711cbfa9eb5813455c6c3dada85ab\",\"title\":\"Real-time Intent Prediction of Pedestrians for Autonomous Ground Vehicles via Spatio-Temporal DenseNet\",\"url\":\"https://www.semanticscholar.org/paper/5c454cbf9d6711cbfa9eb5813455c6c3dada85ab\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"48278763\",\"name\":\"J. Morlier\"}],\"doi\":\"10.1109/ICIP.2019.8803780\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"3eb7533610afea095afd443bac0d20565d6a66df\",\"title\":\"Optimal Choice of Motion Estimation Methods for Fine-Grained Action Classification with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/3eb7533610afea095afd443bac0d20565d6a66df\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51181811\",\"name\":\"J. Zhang\"},{\"authorId\":\"47779342\",\"name\":\"Yutong Xie\"},{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":null,\"name\":\"Hao Chen\"},{\"authorId\":\"49289855\",\"name\":\"Y. Xia\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.24963/ijcai.2019/593\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f07486a42470219d8e08e764a9c988e5eeea7622\",\"title\":\"Light-Weight Hybrid Convolutional Network for Liver Tumor Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f07486a42470219d8e08e764a9c988e5eeea7622\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2596486\",\"name\":\"Zhijian Hou\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec28b73028e7651894323e33409b82d235d2be39\",\"title\":\"VireoJD-MM @ TRECVid 2019: Activities in Extended Video (ActEV)\",\"url\":\"https://www.semanticscholar.org/paper/ec28b73028e7651894323e33409b82d235d2be39\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"46651877\",\"name\":\"Changlin Li\"},{\"authorId\":\"94228656\",\"name\":\"Fengda Zhu\"},{\"authorId\":\"2326853\",\"name\":\"Mingfei Han\"},{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"},{\"authorId\":\"90802639\",\"name\":\"Meng-yuan Ma\"},{\"authorId\":\"4443613\",\"name\":\"Siyi Hu\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"1970583\",\"name\":\"Liangke Gui\"},{\"authorId\":\"8547960\",\"name\":\"Lijun Yu\"},{\"authorId\":\"72399893\",\"name\":\"Yijun Qian\"},{\"authorId\":\"32058482\",\"name\":\"Jing Wen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"27c72dae01efd85a3823fbce3ef4a4fd3bc80586\",\"title\":\"MMVG-INF-Etrol@TRECVID 2019: Activities in Extended Video\",\"url\":\"https://www.semanticscholar.org/paper/27c72dae01efd85a3823fbce3ef4a4fd3bc80586\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":\"1905.13209\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2554604\",\"name\":\"M. Tan\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"title\":\"AssembleNet: Searching for Multi-Stream Neural Connectivity in Video Architectures\",\"url\":\"https://www.semanticscholar.org/paper/a7afd4fdc9388b94ae5ff6aee062f8c5a9270ec1\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1007/978-3-030-05716-9_40\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aec8dde46fe52105ff0642a905373c97ee7eced9\",\"title\":\"A New Hybrid Architecture for Human Activity Recognition from RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/aec8dde46fe52105ff0642a905373c97ee7eced9\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16173039\",\"name\":\"Katy Blanc\"},{\"authorId\":\"1745498\",\"name\":\"D. Lingrand\"},{\"authorId\":\"1411576044\",\"name\":\"Antonio Paladini\"},{\"authorId\":\"1387885788\",\"name\":\"L. Coviello\"},{\"authorId\":\"1419465548\",\"name\":\"Dane Mitrev\"},{\"authorId\":\"1417383755\",\"name\":\"Emily S\\u00f6hler\"},{\"authorId\":\"143959256\",\"name\":\"L. Guzman\"},{\"authorId\":\"150103589\",\"name\":\"F. Precioso\"}],\"doi\":\"10.1109/FG.2019.8756622\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c2bdd51585f3b14116b31387ea93ed7cf0b1ca69\",\"title\":\"Analysis of temporal alignment for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/c2bdd51585f3b14116b31387ea93ed7cf0b1ca69\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144364295\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"title\":\"TVT: Two-View Transformer Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151493680\",\"name\":\"Jingjun Chen\"},{\"authorId\":\"1682580\",\"name\":\"Y. Song\"},{\"authorId\":\"1591129121\",\"name\":\"Yuanlin Zhang\"}],\"doi\":\"10.1109/ICME.2019.00185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"title\":\"Spatial Mask ConvLSTM Network and Intra-Class Joint Training Method for Human Action Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/1bbeaa4279bd31729d718c76d62c0b314fe7b20b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1907.03049\",\"authors\":[{\"authorId\":null,\"name\":\"Yu-Siang Wang\"},{\"authorId\":\"71309591\",\"name\":\"Hung-Ting Su\"},{\"authorId\":\"150053992\",\"name\":\"Chen-Hsi Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"091ad302f5381bd131b41a57e16d802ff4ab9668\",\"title\":\"Video Question Generation via Cross-Modal Self-Attention Networks Learning\",\"url\":\"https://www.semanticscholar.org/paper/091ad302f5381bd131b41a57e16d802ff4ab9668\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"},{\"authorId\":\"145509096\",\"name\":\"Y. Tian\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"1709073\",\"name\":\"Trac D. Tran\"}],\"doi\":\"10.1109/ICIP.2018.8451364\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"bd5b26509ae667cf65fdd6db7c6ac9b578870e3e\",\"title\":\"S3D: Stacking Segmental P3D for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/bd5b26509ae667cf65fdd6db7c6ac9b578870e3e\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"title\":\"ops Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/cc6b00a4f43370644f410330ed6d065f7fa38d5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6624871\",\"name\":\"Dmytro Tkachenko\"}],\"doi\":\"10.1109/saic.2018.8516860\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"355cea44e2d40409a7a5be72b12511e43d259cb9\",\"title\":\"Human Action Recognition Using Fusion of Modern Deep Convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/355cea44e2d40409a7a5be72b12511e43d259cb9\",\"venue\":\"2018 IEEE First International Conference on System Analysis & Intelligent Computing (SAIC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1824088\",\"name\":\"V. Campos\"},{\"authorId\":\"2447185\",\"name\":\"B. Jou\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"144345280\",\"name\":\"J. Torres\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"19841b721bfe31899e238982a22257287b9be66a\",\"title\":\"S KIP RNN : L EARNING TO S KIP S TATE U PDATES IN R ECURRENT N EURAL N ETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/19841b721bfe31899e238982a22257287b9be66a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1712.02310\",\"authors\":[{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"7987770\",\"name\":\"Weicheng Kuo\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2018.00524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"title\":\"From Lifestyle Vlogs to Everyday Interactions\",\"url\":\"https://www.semanticscholar.org/paper/729fb92afe3cf7faaae1b079f7c7a2cd39c01dad\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2018.00677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"title\":\"Making Convolutional Networks Recurrent for Visual Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/13f1a38bc8542eb7d9d5d3b13d326fbec1f01783\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151471179\",\"name\":\"Nasim Khani\"},{\"authorId\":\"1917506\",\"name\":\"M. Rezaeian\"}],\"doi\":\"10.1109/PRIA.2019.8785989\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"615f2ff53e297c753b323df4a1550a68953c0260\",\"title\":\"Three-stream Very Deep Neural Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/615f2ff53e297c753b323df4a1550a68953c0260\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":\"2007.00394\",\"authors\":[{\"authorId\":\"1410307807\",\"name\":\"Yizhak Ben-Shabat\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"9120887\",\"name\":\"F. Saleh\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"947b868aa1c38940df280ebeb8077d4e729fb988\",\"title\":\"The IKEA ASM Dataset: Understanding People Assembling Furniture through Actions, Objects and Pose\",\"url\":\"https://www.semanticscholar.org/paper/947b868aa1c38940df280ebeb8077d4e729fb988\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.03063\",\"authors\":[{\"authorId\":\"3200442\",\"name\":\"A. Tsiami\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/cvpr42600.2020.00482\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"title\":\"STAViS: Spatio-Temporal AudioVisual Saliency Network\",\"url\":\"https://www.semanticscholar.org/paper/e296a1f529d9caa125e8c6a56cac61423e04b41b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1807.08291\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"50433510\",\"name\":\"Takio Kurita\"}],\"doi\":\"10.1016/j.image.2019.115731\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"title\":\"Correlation Net: Spatiotemporal multimodal deep learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/08129fdd46ea4dce31c435613ab70b6c35dd60b0\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2020},{\"arxivId\":\"2008.08502\",\"authors\":[{\"authorId\":\"2670195\",\"name\":\"L. Wang\"},{\"authorId\":\"50439333\",\"name\":\"DongSheng Liu\"},{\"authorId\":\"3246780\",\"name\":\"Rohit Puri\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"76e71fe84643b72ffb61afe54c9034be824604e3\",\"title\":\"Learning Trailer Moments in Full-Length Movies\",\"url\":\"https://www.semanticscholar.org/paper/76e71fe84643b72ffb61afe54c9034be824604e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40290798\",\"name\":\"T. Suzuki\"},{\"authorId\":\"21583404\",\"name\":\"Takahiro Itazuri\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.1007/978-3-030-11012-3_45\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72446b34abdd68469eb6045b3958bb10d8b2cfd4\",\"title\":\"Learning Spatiotemporal 3D Convolution with Video Order Self-supervision\",\"url\":\"https://www.semanticscholar.org/paper/72446b34abdd68469eb6045b3958bb10d8b2cfd4\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1393588876\",\"name\":\"Fei Han\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"2846159\",\"name\":\"Yiqi Wu\"},{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"1562396274\",\"name\":\"Longyong Wu\"},{\"authorId\":\"49015700\",\"name\":\"W. Huang\"}],\"doi\":\"10.1007/978-981-15-3651-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"title\":\"Human Action Recognition Based on Dual Correlation Network\",\"url\":\"https://www.semanticscholar.org/paper/d4fd6a090c2e098ff21e2b09015328c7c898035b\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1909.07725\",\"authors\":[{\"authorId\":\"40809222\",\"name\":\"Luxuan Li\"},{\"authorId\":\"145868988\",\"name\":\"Tao Kong\"},{\"authorId\":\"143823065\",\"name\":\"F. Sun\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1007/978-3-030-36718-3_40\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8f27170bf174d81e646492173ba9e9c97753853c\",\"title\":\"Deep Point-wise Prediction for Action Temporal Proposal\",\"url\":\"https://www.semanticscholar.org/paper/8f27170bf174d81e646492173ba9e9c97753853c\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"2001.09099\",\"authors\":[{\"authorId\":\"46665218\",\"name\":\"Jie Lei\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"143977266\",\"name\":\"Mohit Bansal\"}],\"doi\":\"10.1007/978-3-030-58589-1_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"title\":\"TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/37dd9c725cb800fd5f336a5227f02c160b8723cb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.00707\",\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"9693996\",\"name\":\"Liangfeng Zheng\"},{\"authorId\":\"144654776\",\"name\":\"Kun Bai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1109/icme46284.2020.9102850\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"title\":\"Scale Matters: Temporal Scale Aggregation Network For Precise Action Localization In Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/3bba21a50bdd896cc4ebddcb8b6ce807f4a26287\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2005.13402\",\"authors\":[{\"authorId\":\"31222412\",\"name\":\"Pratik Mazumder\"},{\"authorId\":\"144377059\",\"name\":\"Pravendra Singh\"},{\"authorId\":\"50811450\",\"name\":\"Kranti K. Parida\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91aea8435a9aa2409f9b279edacbfbb3fd19587b\",\"title\":\"AVGZSLNet: Audio-Visual Generalized Zero-Shot Learning by Reconstructing Label Features from Multi-Modal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/91aea8435a9aa2409f9b279edacbfbb3fd19587b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03703\",\"authors\":[{\"authorId\":\"2981509\",\"name\":\"Dongxu Li\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"49770180\",\"name\":\"Chenchen Xu\"},{\"authorId\":\"47773335\",\"name\":\"L. Petersson\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1109/cvpr42600.2020.00624\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"efe28238909dc5c1877297fa830d85e9daecc29f\",\"title\":\"Transferring Cross-Domain Knowledge for Video Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/efe28238909dc5c1877297fa830d85e9daecc29f\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Gao Peng\"},{\"authorId\":null,\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2bf569fbf3e407f4b60567a94d45880d35c2a3d\",\"title\":\"Efficient 3D Video Engine Using Frame Redundancy\",\"url\":\"https://www.semanticscholar.org/paper/d2bf569fbf3e407f4b60567a94d45880d35c2a3d\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2007.08213\",\"authors\":[{\"authorId\":\"35649732\",\"name\":\"Xuesong Niu\"},{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"1405915001\",\"name\":\"Hu Han\"},{\"authorId\":\"1502872895\",\"name\":\"Xiaobai Li\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1007/978-3-030-58536-5_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"000f47c6bb00732dfe5302f85b64bc8896fc5457\",\"title\":\"Video-based Remote Physiological Measurement via Cross-verified Feature Disentangling\",\"url\":\"https://www.semanticscholar.org/paper/000f47c6bb00732dfe5302f85b64bc8896fc5457\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.09158\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"97773539\",\"name\":\"Jiajie Wang\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"98049755\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1471647358\",\"name\":\"Qi Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42b6d63416f46e9ac2bcdda9a7065f4682f18e93\",\"title\":\"Privileged Knowledge Distillation for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/42b6d63416f46e9ac2bcdda9a7065f4682f18e93\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49616241\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"146441151\",\"name\":\"Carlos Torres\"},{\"authorId\":\"145631625\",\"name\":\"S. Chandrasekaran\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bde073561cd1df85cf546fca443190fc0beb2a53\",\"title\":\"Complex Pairwise Activity Analysis Via Instance Level Evolution Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/bde073561cd1df85cf546fca443190fc0beb2a53\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"2001.06680\",\"authors\":[{\"authorId\":\"71170299\",\"name\":\"J. Wu\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"101219260\",\"name\":\"Si Liu\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1609/AAAI.V34I07.6924\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"title\":\"Tree-Structured Policy based Progressive Reinforcement Learning for Temporally Language Grounding in Video\",\"url\":\"https://www.semanticscholar.org/paper/b8e744b1f33b1f3f53fcffb1dafd592e992694ff\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"}],\"doi\":\"10.1016/j.jneumeth.2019.108536\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5b40697a874e09a123ed7da97323da27662e0028\",\"title\":\"Deep Learning Improves Automated Rodent Behavior Recognition Within a Specific Experimental Setup\",\"url\":\"https://www.semanticscholar.org/paper/5b40697a874e09a123ed7da97323da27662e0028\",\"venue\":\"Journal of Neuroscience Methods\",\"year\":2019},{\"arxivId\":\"1909.09602\",\"authors\":[{\"authorId\":\"1388016741\",\"name\":\"Chris Careaga\"},{\"authorId\":\"144156036\",\"name\":\"Brian Hutchinson\"},{\"authorId\":\"47312946\",\"name\":\"Nathan Hodas\"},{\"authorId\":\"21785345\",\"name\":\"L. Phillips\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"title\":\"Metric-Based Few-Shot Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.03530\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"150352016\",\"name\":\"Yanzhou Su\"},{\"authorId\":\"144941515\",\"name\":\"Y. Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"2de59074948bca0c0a4919bba03229477f65e821\",\"title\":\"TTPP: Temporal Transformer with Progressive Prediction for Efficient Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/2de59074948bca0c0a4919bba03229477f65e821\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286259\",\"name\":\"JianYu Wang\"},{\"authorId\":\"51235164\",\"name\":\"Jianxin Chen\"},{\"authorId\":\"1768588917\",\"name\":\"Yihao Cai\"}],\"doi\":\"10.1117/12.2574424\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d279c051e5884041e66e1c5411415d74081effa3\",\"title\":\"A framework for multimodal sign language recognition under small sample based on key-frame sampling\",\"url\":\"https://www.semanticscholar.org/paper/d279c051e5884041e66e1c5411415d74081effa3\",\"venue\":\"International Workshop on Pattern Recognition\",\"year\":2020},{\"arxivId\":\"2010.10258\",\"authors\":[{\"authorId\":\"9205129\",\"name\":\"Ruihan Yang\"},{\"authorId\":\"119607790\",\"name\":\"Y. Yang\"},{\"authorId\":\"47798677\",\"name\":\"J. Marino\"},{\"authorId\":\"1387982287\",\"name\":\"Stephan Mandt\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"8a5442824f73efb99ad14e7fedf30ff60eee0e8d\",\"title\":\"Hierarchical Autoregressive Modeling for Neural Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/8a5442824f73efb99ad14e7fedf30ff60eee0e8d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.11189\",\"authors\":[{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"145681036\",\"name\":\"Xiao Tan\"},{\"authorId\":\"145649748\",\"name\":\"F. Zhou\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"39826117\",\"name\":\"Kaiyu Yue\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"},{\"authorId\":\"50032031\",\"name\":\"Yi Ma\"}],\"doi\":\"10.1007/978-3-030-01228-1_9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1102250a0fae62263979b32ad3c25749be9bca6b\",\"title\":\"Fine-Grained Video Categorization with Redundancy Reduction Attention\",\"url\":\"https://www.semanticscholar.org/paper/1102250a0fae62263979b32ad3c25749be9bca6b\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1807.10037\",\"authors\":[{\"authorId\":\"2647624\",\"name\":\"Myunggi Lee\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"9044475\",\"name\":\"Sung Joon Son\"},{\"authorId\":\"51136389\",\"name\":\"G. Park\"},{\"authorId\":\"3160425\",\"name\":\"N. Kwak\"}],\"doi\":\"10.1007/978-3-030-01249-6_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"title\":\"Motion Feature Network: Fixed Motion Filter for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10a1dcbe52547146fa4735274e8c89ae01e70a55\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1803.11556\",\"authors\":[{\"authorId\":\"10805888\",\"name\":\"Zhongzheng Ren\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/978-3-030-01246-5_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211\",\"title\":\"Learning to Anonymize Faces for Privacy Preserving Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/1b0cc9f0ffd8df93c8006da9c525ca9b84fb1211\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.08249\",\"authors\":[{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/WACV45572.2020.9093274\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2766379db5d9907766dab034a52867d7394a265e\",\"title\":\"D3D: Distilled 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2766379db5d9907766dab034a52867d7394a265e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1608.02318\",\"authors\":[{\"authorId\":\"39707211\",\"name\":\"Karan Sikka\"},{\"authorId\":\"2515597\",\"name\":\"Gaurav Sharma\"}],\"doi\":\"10.1109/TPAMI.2017.2741482\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b66d0afa540720bc656aa534c83d685421a077d\",\"title\":\"Discriminatively Trained Latent Ordinal Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/4b66d0afa540720bc656aa534c83d685421a077d\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038538869\",\"name\":\"Kazi Ahmed Asif Fuad\"},{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1574465512\",\"name\":\"Romain Giot\"},{\"authorId\":\"151470458\",\"name\":\"R. Bourqui\"},{\"authorId\":\"1401651727\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1677641701\",\"name\":\"Akka Zemmari\"}],\"doi\":\"10.1109/IPTA50016.2020.9286629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72a489d2185e08e296b9559fb7837324d2ab282b\",\"title\":\"Features Understanding in 3D CNNs for Actions Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/72a489d2185e08e296b9559fb7837324d2ab282b\",\"venue\":\"2020 Tenth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34041171\",\"name\":\"Akshaya Ramaswamy\"},{\"authorId\":\"3339923\",\"name\":\"K. Seemakurthy\"},{\"authorId\":\"49294154\",\"name\":\"J. Gubbi\"},{\"authorId\":\"21432550\",\"name\":\"B. Purushothaman\"}],\"doi\":\"10.1109/CVPRW50498.2020.00390\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"001ab97faa6b224b52aac252a003e223325e70a2\",\"title\":\"Spatio-temporal action detection and localization using a hierarchical LSTM\",\"url\":\"https://www.semanticscholar.org/paper/001ab97faa6b224b52aac252a003e223325e70a2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50141950\",\"name\":\"Xionghui Wang\"},{\"authorId\":\"67331131\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/CVPR.2019.00367\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48c601d0029c25ba02480c473d1bd31960acb2e2\",\"title\":\"Progressive Teacher-Student Learning for Early Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/48c601d0029c25ba02480c473d1bd31960acb2e2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1810.10519\",\"authors\":[{\"authorId\":\"31711745\",\"name\":\"Murilo Varges da Silva\"},{\"authorId\":\"1683019\",\"name\":\"A. N. Marana\"}],\"doi\":\"10.1007/978-3-030-13469-3_64\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0155c2921f060a95c0eca8c64bf62a1eaac591e4\",\"title\":\"Spatiotemporal CNNs for Pornography Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/0155c2921f060a95c0eca8c64bf62a1eaac591e4\",\"venue\":\"CIARP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cc4618ce3811d2d14f23ec28ee462fa040f469c9\",\"title\":\"Interpretable representation learning for visual intelligence\",\"url\":\"https://www.semanticscholar.org/paper/cc4618ce3811d2d14f23ec28ee462fa040f469c9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.13130\",\"authors\":[{\"authorId\":\"153918891\",\"name\":\"Chenxu Luo\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/ICCV.2019.00561\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b8fe4727c8094b17e61886e69a602f8d0403091\",\"title\":\"Grouped Spatial-Temporal Aggregation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b8fe4727c8094b17e61886e69a602f8d0403091\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7163243\",\"name\":\"Yogatheesan Varatharajah\"},{\"authorId\":\"1600722680\",\"name\":\"Sujeeth Baradwaj\"},{\"authorId\":\"48057821\",\"name\":\"A. Kiraly\"},{\"authorId\":\"91433101\",\"name\":\"Diego Ardila\"},{\"authorId\":\"1686653\",\"name\":\"R. Iyer\"},{\"authorId\":\"2894170\",\"name\":\"S. Shetty\"},{\"authorId\":\"3414330\",\"name\":\"Kai Kohlhoff\"}],\"doi\":\"10.1101/497925\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"affcd05c3b3d42d4710d1d08c4c618981124479b\",\"title\":\"Predicting Brain Age Using Structural Neuroimaging and Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/affcd05c3b3d42d4710d1d08c4c618981124479b\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"}],\"doi\":\"10.1109/ICIP.2019.8803382\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"47867e8529b2ce2c315598f4cf0c066b51e619a8\",\"title\":\"Fine-Grained Action Detection and Classification in Table Tennis with Siamese Spatio-Temporal Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/47867e8529b2ce2c315598f4cf0c066b51e619a8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4786d50855d9685edcd8642fd11e445a6f84b04\",\"title\":\"I NTERPRETING VIDEO FEATURES : A COMPARISON OF 3 D C ONVOLUTIONAL NETWORKS AND C ONVOLU-TIONAL LSTM NETWORKS\",\"url\":\"https://www.semanticscholar.org/paper/d4786d50855d9685edcd8642fd11e445a6f84b04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34394988\",\"name\":\"A. Javer\"},{\"authorId\":\"50713410\",\"name\":\"Andr\\u00e9 E. X. Brown\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1695351\",\"name\":\"J. Rittscher\"}],\"doi\":\"10.1101/433052\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a31172fe1c4b55e622090dfc3e2c97bf9f8b9e3c\",\"title\":\"Identification of C. elegans strains using a fully convolutional neural network on behavioural dynamics\",\"url\":\"https://www.semanticscholar.org/paper/a31172fe1c4b55e622090dfc3e2c97bf9f8b9e3c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2005.06536\",\"authors\":[{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"9359529\",\"name\":\"K. Wang\"},{\"authorId\":\"1492126129\",\"name\":\"Dan Zeng\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6dc0bf7bfc8d72959245178a54cc1243b1e7d267\",\"title\":\"Robust Visual Object Tracking with Two-Stream Residual Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/6dc0bf7bfc8d72959245178a54cc1243b1e7d267\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134649559\",\"name\":\"R. Kiziltepe\"},{\"authorId\":\"3000774\",\"name\":\"J. Gan\"},{\"authorId\":\"3361843\",\"name\":\"J. J. Escobar\"}],\"doi\":\"10.1007/978-3-030-20518-8_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9a51bfd7be0aeb061f318c3d9201e07aa8c7d6\",\"title\":\"Combining Very Deep Convolutional Neural Networks and Recurrent Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/bb9a51bfd7be0aeb061f318c3d9201e07aa8c7d6\",\"venue\":\"IWANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"2020817\",\"name\":\"Ming Zeng\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":\"10.1109/ICCEA50009.2020.00132\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b27c9dc2c2d4ed237d9b0c0605d25e76ff650609\",\"title\":\"Temporal Recursive Propagation Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b27c9dc2c2d4ed237d9b0c0605d25e76ff650609\",\"venue\":\"2020 International Conference on Computer Engineering and Application (ICCEA)\",\"year\":2020},{\"arxivId\":\"2010.01824\",\"authors\":[{\"authorId\":\"144943440\",\"name\":\"Saptarshi Sinha\"},{\"authorId\":\"1743276\",\"name\":\"H. Ohashi\"},{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1516fe9eeca6e8bd3d26723f725d222107cb2551\",\"title\":\"Class-Wise Difficulty-Balanced Loss for Solving Class-Imbalance\",\"url\":\"https://www.semanticscholar.org/paper/1516fe9eeca6e8bd3d26723f725d222107cb2551\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.07023\",\"authors\":[{\"authorId\":\"5298478\",\"name\":\"T. D. Nguyen\"},{\"authorId\":\"145478041\",\"name\":\"Shikhar Sharma\"},{\"authorId\":\"1944614\",\"name\":\"Hannes Schulz\"},{\"authorId\":\"3349496\",\"name\":\"Layla El Asri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d252759ea411343f274a92276bf7bd8f9d43db8c\",\"title\":\"From FiLM to Video: Multi-turn Question Answering with Multi-modal Context\",\"url\":\"https://www.semanticscholar.org/paper/d252759ea411343f274a92276bf7bd8f9d43db8c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2008.02086\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"title\":\"Self-supervised learning using consistency regularization of spatio-temporal data augmentation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c9ae916c89a804742a382a5eb095030a0db9eb5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1406426904\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"2236496\",\"name\":\"Boris Mansencal\"},{\"authorId\":\"1639895183\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"3027952\",\"name\":\"L. Mascarilla\"},{\"authorId\":\"1959267293\",\"name\":\"Jordan Calandre\"},{\"authorId\":\"1639983772\",\"name\":\"Julien Morlier\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c1a0739b37b2ee0bab8e2281a13d29e60de6332\",\"title\":\"Sports Video Annotation: Detection of Strokes in Table Tennis Task for MediaEval 2019\",\"url\":\"https://www.semanticscholar.org/paper/0c1a0739b37b2ee0bab8e2281a13d29e60de6332\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1933641578\",\"name\":\"Kai Zhao\"},{\"authorId\":\"120026144\",\"name\":\"Y. Zhou\"},{\"authorId\":\"46772290\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/ACCESS.2020.3018131\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1c5f7babcbe7abe62781c6444c167b06e91b9e71\",\"title\":\"Object Detection: Training From Scratch\",\"url\":\"https://www.semanticscholar.org/paper/1c5f7babcbe7abe62781c6444c167b06e91b9e71\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1801.08712\",\"authors\":[{\"authorId\":\"3293265\",\"name\":\"Atanas Mirchev\"},{\"authorId\":\"145774206\",\"name\":\"Seyed-Ahmad Ahmadi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3c7f8947e8b1c85775732d2ae59fb6c680a807c\",\"title\":\"Classification of sparsely labeled spatio-temporal data through semi-supervised adversarial learning\",\"url\":\"https://www.semanticscholar.org/paper/b3c7f8947e8b1c85775732d2ae59fb6c680a807c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1804.00413\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2978255\",\"name\":\"Wen-bing Huang\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2490652\",\"name\":\"S. Ermon\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/CVPR.2018.00630\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"259dcd1afe22e569132ccc41697ac368504c4dd1\",\"title\":\"End-to-End Learning of Motion Representation for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/259dcd1afe22e569132ccc41697ac368504c4dd1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"96668091\",\"name\":\"Tan Yu\"},{\"authorId\":\"49201849\",\"name\":\"Z. Ren\"},{\"authorId\":\"66508219\",\"name\":\"Y. Li\"},{\"authorId\":\"104219153\",\"name\":\"Enxu Yan\"},{\"authorId\":\"145857596\",\"name\":\"N. Xu\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/ICCV.2019.00562\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c\",\"title\":\"Temporal Structure Mining for Weakly Supervised Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f780a8fe6eb184e34c03823fa1b2bcd4b5b4fb7c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.11875\",\"authors\":[{\"authorId\":\"52121635\",\"name\":\"Nathan Inkawhich\"},{\"authorId\":\"52117082\",\"name\":\"Matthew Inkawhich\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"},{\"authorId\":\"47892815\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"title\":\"Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2894025\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"title\":\"Spatiotemporal Relation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9e1dbea5bb15fa88af384ec1baf4a20cffb6e6a8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1909.10695\",\"authors\":[{\"authorId\":\"51310352\",\"name\":\"Philipp V. Rouast\"},{\"authorId\":\"24235135\",\"name\":\"M. Adam\"}],\"doi\":\"10.1109/JBHI.2019.2942845\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"61b86a3b0c3dd290d2a6a67a335e4473ff69f92b\",\"title\":\"Learning Deep Representations for Video-Based Intake Gesture Detection\",\"url\":\"https://www.semanticscholar.org/paper/61b86a3b0c3dd290d2a6a67a335e4473ff69f92b\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"Minlong Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"title\":\"Action analysis and control strategy for rat robot automatic navigation\",\"url\":\"https://www.semanticscholar.org/paper/972b1d8842df8ad06c50a33782af1cfdc9ffd411\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.06165\",\"authors\":[{\"authorId\":\"1379957693\",\"name\":\"Sean Segal\"},{\"authorId\":\"2219575\",\"name\":\"E. Kee\"},{\"authorId\":\"49756115\",\"name\":\"W. Luo\"},{\"authorId\":\"152948272\",\"name\":\"A. Sadat\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"781da932cceb0e69e5471e018c41fb95224e2e4c\",\"title\":\"Universal Embeddings for Spatio-Temporal Tagging of Self-Driving Logs\",\"url\":\"https://www.semanticscholar.org/paper/781da932cceb0e69e5471e018c41fb95224e2e4c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1804.06604\",\"authors\":[{\"authorId\":\"2567354\",\"name\":\"Ana Garcia del Molino\"},{\"authorId\":\"3037160\",\"name\":\"Michael Gygli\"}],\"doi\":\"10.1145/3240508.3240599\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"916218b7fd637d75f644c5ef5f7590c05fabca75\",\"title\":\"PHD-GIFs: Personalized Highlight Detection for Automatic GIF Creation\",\"url\":\"https://www.semanticscholar.org/paper/916218b7fd637d75f644c5ef5f7590c05fabca75\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39829924\",\"name\":\"Ishan Nigam\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00049\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1bb65ce8144fb6684e593a145ec60a268481a795\",\"title\":\"Towards Latent Attribute Discovery From Triplet Similarities\",\"url\":\"https://www.semanticscholar.org/paper/1bb65ce8144fb6684e593a145ec60a268481a795\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46572037\",\"name\":\"A. George\"},{\"authorId\":\"1978827882\",\"name\":\"Dighanchal Banerjee\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"37840630\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"145323795\",\"name\":\"P. Balamurali\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206681\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8fcc63268caa9b8415517102e81fe1b2ae19aae7\",\"title\":\"A Reservoir-based Convolutional Spiking Neural Network for Gesture Recognition from DVS Input\",\"url\":\"https://www.semanticscholar.org/paper/8fcc63268caa9b8415517102e81fe1b2ae19aae7\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120425481\",\"name\":\"Sohee Park\"},{\"authorId\":\"2417743\",\"name\":\"Arani Bhattacharya\"},{\"authorId\":\"152747658\",\"name\":\"Z. Yang\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"1691843\",\"name\":\"Samir R Das\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"}],\"doi\":\"10.23919/IFIPNetworking.2019.8816847\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc8905e22cf4c869c780e51976704bfb6545fd6b\",\"title\":\"Advancing User Quality of Experience in 360-degree Video Streaming\",\"url\":\"https://www.semanticscholar.org/paper/dc8905e22cf4c869c780e51976704bfb6545fd6b\",\"venue\":\"2019 IFIP Networking Conference (IFIP Networking)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"144315735\",\"name\":\"Fan Zhou\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/CAHPC.2018.8645861\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac517a5c713824cad0c02789015d96c71ffc10c9\",\"title\":\"Accelerating Deep Neural Network Training for Action Recognition on a Cluster of GPUs\",\"url\":\"https://www.semanticscholar.org/paper/ac517a5c713824cad0c02789015d96c71ffc10c9\",\"venue\":\"2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CRV.2019.00032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"title\":\"Two-Stream Action Recognition in Ice Hockey using Player Pose Sequences and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/6e31adfe278a8a3da1d2f42ab2fbdb65ed0099eb\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":\"1907.01131\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"47781274\",\"name\":\"Z. Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"title\":\"Learnable Gated Temporal Shift Module for Free-form Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/fe59654dd44dfe5f216587ccbc089c5a0ec1461a\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1810.11735\",\"authors\":[{\"authorId\":\"32251567\",\"name\":\"Shikib Mehri\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a82034bd78ee09117baa35ab23b9d600a7509167\",\"title\":\"Middle-Out Decoding\",\"url\":\"https://www.semanticscholar.org/paper/a82034bd78ee09117baa35ab23b9d600a7509167\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134665127\",\"name\":\"Roberto S\\u00e1nchez P\\u00e1manes\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":true,\"paperId\":\"4c03323dc648d7739aa230ea2d65eb02a0558c6a\",\"title\":\"Learning temporal features of facial action units using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/4c03323dc648d7739aa230ea2d65eb02a0558c6a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46331912\",\"name\":\"M. Liu\"},{\"authorId\":\"89507637\",\"name\":\"X. Chen\"},{\"authorId\":\"144781413\",\"name\":\"Y. Zhang\"},{\"authorId\":\"48513361\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dc7de1c65a52db271016313980ae577d19aace24\",\"title\":\"Paying More Attention to Motion: Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/dc7de1c65a52db271016313980ae577d19aace24\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119837541\",\"name\":\"Jian-Ming Wu\"},{\"authorId\":\"143787146\",\"name\":\"B. Yang\"},{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"31229419\",\"name\":\"G. Hattori\"}],\"doi\":\"10.1145/3382507.3417959\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f19417766c97326f54f82450ab04e5d5d0c23281\",\"title\":\"Advanced Multi-Instance Learning Method with Multi-features Engineering and Conservative Optimization for Engagement Intensity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f19417766c97326f54f82450ab04e5d5d0c23281\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"}],\"doi\":\"10.24384/KQTR-E820\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc64caa4143f88ca1f41a91036d897008f956610\",\"title\":\"Spatio-temporal human action detection and instance segmentation in videos\",\"url\":\"https://www.semanticscholar.org/paper/dc64caa4143f88ca1f41a91036d897008f956610\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/978-3-030-49076-8_24\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5c8c96c2395de045227e6c1165bd8f0886b08536\",\"title\":\"What the Appearance Channel from Two-Stream Architectures for Activity Recognition Is Learning?\",\"url\":\"https://www.semanticscholar.org/paper/5c8c96c2395de045227e6c1165bd8f0886b08536\",\"venue\":\"MCPR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1944615571\",\"name\":\"A. Almeida\"},{\"authorId\":\"145334240\",\"name\":\"J. P. D. Villiers\"},{\"authorId\":\"143985011\",\"name\":\"A. Freitas\"},{\"authorId\":\"1944660087\",\"name\":\"M. Velayudan\"}],\"doi\":\"10.23919/FUSION45008.2020.9190331\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b558a0a74a96f0d08c57ea3c78c2e11335c76aa8\",\"title\":\"Visual comparison of statistical feature aggregation methods for video-based similarity applications\",\"url\":\"https://www.semanticscholar.org/paper/b558a0a74a96f0d08c57ea3c78c2e11335c76aa8\",\"venue\":\"2020 IEEE 23rd International Conference on Information Fusion (FUSION)\",\"year\":2020},{\"arxivId\":\"2006.07006\",\"authors\":[{\"authorId\":\"1429148175\",\"name\":\"Pilhyeon Lee\"},{\"authorId\":\"49605749\",\"name\":\"J. Wang\"},{\"authorId\":\"1500380529\",\"name\":\"Y. Lu\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb8bb50e4b84739b9d3477eead0707d8c3a84cd8\",\"title\":\"Background Modeling via Uncertainty Estimation for Weakly-supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/cb8bb50e4b84739b9d3477eead0707d8c3a84cd8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1703732\",\"name\":\"Shengquan Wang\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"},{\"authorId\":\"145309461\",\"name\":\"Min Jiang\"},{\"authorId\":\"1878899344\",\"name\":\"Tianshan Liu\"}],\"doi\":\"10.1016/J.JVCIR.2020.102929\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"title\":\"Multiple depth-levels features fusion enhanced network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4ecb7e69e64c9f1a49cc718175e8af7b797cae9\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"1907.01166\",\"authors\":[{\"authorId\":\"143725625\",\"name\":\"Hung Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.18653/v1/P19-1564\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"title\":\"Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/594ad264d6b92afb9d13cb56ad8ffadba94a9f7a\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1911.06644\",\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"50652944\",\"name\":\"Xiangyu Wei\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"title\":\"You Only Watch Once: A Unified CNN Architecture for Real-Time Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/143059e7d17fd17c961a538ea98fadcf2667d5ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.14260\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"46756438\",\"name\":\"Chen Yu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"title\":\"A Self Validation Network for Object-Level Human Attention Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b41e631c08be054ab19a88e3fb07077e03a6c53e\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1909.11975\",\"authors\":[{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"},{\"authorId\":\"39092098\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2934852\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a4b2207e6de1e759ac7a7f45abe7a0b1d1da4558\",\"title\":\"Learning Energy-based Spatial-Temporal Generative ConvNets for Dynamic Patterns\",\"url\":\"https://www.semanticscholar.org/paper/a4b2207e6de1e759ac7a7f45abe7a0b1d1da4558\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1912.06430\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.00990\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb40df31aa7177c9d009478479db61c39caebd54\",\"title\":\"End-to-End Learning of Visual Representations From Uncurated Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/fb40df31aa7177c9d009478479db61c39caebd54\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"118098028\",\"name\":\"Linchao He\"},{\"authorId\":\"3172494\",\"name\":\"Jiong Mu\"},{\"authorId\":\"151501329\",\"name\":\"Mengting Luo\"},{\"authorId\":\"152999492\",\"name\":\"Yunlu Lu\"},{\"authorId\":\"1500399614\",\"name\":\"Xuefeng Tan\"},{\"authorId\":\"49357069\",\"name\":\"Dejun Zhang\"}],\"doi\":\"10.1007/978-981-15-3250-4_171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd65beb7fe8dd4d1b32f788a2718d71a8a509164\",\"title\":\"Spatio-Temporal Action Localization for Pedestrian Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/dd65beb7fe8dd4d1b32f788a2718d71a8a509164\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390916430\",\"name\":\"Huan Liu\"},{\"authorId\":\"2817677\",\"name\":\"Qinghua Zheng\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"152299623\",\"name\":\"C. Yan\"},{\"authorId\":\"46518251\",\"name\":\"L. Yao\"}],\"doi\":\"10.1016/j.knosys.2020.106432\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6072b5407daf1db4871fa27bdac7f63407019091\",\"title\":\"Memory transformation networks for weakly supervised visual classification\",\"url\":\"https://www.semanticscholar.org/paper/6072b5407daf1db4871fa27bdac7f63407019091\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2007.10040\",\"authors\":[{\"authorId\":\"123661590\",\"name\":\"Louis Mahon\"},{\"authorId\":\"31847520\",\"name\":\"Eleonora Giunchiglia\"},{\"authorId\":\"49730060\",\"name\":\"B. Li\"},{\"authorId\":\"1690572\",\"name\":\"Thomas Lukasiewicz\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4384342c18d3ceec7be3c4a65e938e93e34ce4ef\",\"title\":\"Knowledge Graph Extraction from Videos\",\"url\":\"https://www.semanticscholar.org/paper/4384342c18d3ceec7be3c4a65e938e93e34ce4ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.07882\",\"authors\":[{\"authorId\":\"2198519\",\"name\":\"Zongwei Zhou\"},{\"authorId\":\"1388013239\",\"name\":\"Vatsal Sodha\"},{\"authorId\":\"72238162\",\"name\":\"Jiaxuan Pang\"},{\"authorId\":\"143751204\",\"name\":\"Michael B. Gotway\"},{\"authorId\":\"1485304039\",\"name\":\"Jianming Liang\"}],\"doi\":\"10.1016/j.media.2020.101840\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"837ac3f4a638b1ae9f424e51f0e7bfa8cb05298d\",\"title\":\"Models Genesis\",\"url\":\"https://www.semanticscholar.org/paper/837ac3f4a638b1ae9f424e51f0e7bfa8cb05298d\",\"venue\":\"Medical Image Anal.\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144289594\",\"name\":\"C. Caetano\"},{\"authorId\":\"143793197\",\"name\":\"V. H. Melo\"},{\"authorId\":\"144103389\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"6141311\",\"name\":\"J. A. D. Santos\"},{\"authorId\":\"9385043\",\"name\":\"W. Schwartz\"}],\"doi\":\"10.1016/J.JVCIR.2019.102596\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"title\":\"Magnitude-Orientation Stream network and depth information applied to activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/c3c201c48d14e0e7135d4558590a4ad3f7bc864c\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1903.05359\",\"authors\":[{\"authorId\":\"145883335\",\"name\":\"J. Long\"},{\"authorId\":\"46912588\",\"name\":\"W. Sun\"},{\"authorId\":\"1754077\",\"name\":\"Zhan Yang\"},{\"authorId\":\"78371785\",\"name\":\"Osolo Ian Raymond\"},{\"authorId\":\"49729707\",\"name\":\"B. Li\"}],\"doi\":\"10.3390/info10060203\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6228558a333e6cfeb57c181010bf454459bf4c8\",\"title\":\"Dual Residual Network for Accurate Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6228558a333e6cfeb57c181010bf454459bf4c8\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":\"2011.13273\",\"authors\":[{\"authorId\":\"143626433\",\"name\":\"Tingtian Li\"},{\"authorId\":\"21072153\",\"name\":\"Zixun Sun\"},{\"authorId\":\"1683647\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3394171.3416280\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e6a67a46883eb1e975ad52c30cd20f0668f5593\",\"title\":\"Group-Skeleton-Based Human Action Recognition in Complex Events\",\"url\":\"https://www.semanticscholar.org/paper/8e6a67a46883eb1e975ad52c30cd20f0668f5593\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2010.11594\",\"authors\":[{\"authorId\":\"3191371\",\"name\":\"Yuanhao Zhai\"},{\"authorId\":\"153755094\",\"name\":\"L. Wang\"},{\"authorId\":\"2914452\",\"name\":\"W. Tang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1007/978-3-030-58539-6_3\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"title\":\"Two-Stream Consensus Network for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/b41ec90b8e8972e6d09ae129ce4e004e37ad4015\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.13042\",\"authors\":[{\"authorId\":\"31463937\",\"name\":\"Haodong Duan\"},{\"authorId\":\"152621421\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"49663328\",\"name\":\"Wentao Liu\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58555-6_40\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"title\":\"Omni-sourced Webly-supervised Learning for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d6f7e18d551743889cd87dc3e0b4a75b8791ea95\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.06845\",\"authors\":[{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2815926\",\"name\":\"Shengxin Zha\"},{\"authorId\":\"38896301\",\"name\":\"G. Kundu\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.1007/978-3-030-58548-8_25\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"84d710727a9a5775ab4691a969f52bc3062325e2\",\"title\":\"SF-Net: Single-Frame Supervision for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/84d710727a9a5775ab4691a969f52bc3062325e2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.10575\",\"authors\":[{\"authorId\":\"3349165\",\"name\":\"Pallabi Ghosh\"},{\"authorId\":\"153462555\",\"name\":\"Yi Yao\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"}],\"doi\":\"10.1109/WACV45572.2020.9093361\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3efc52b9a5190f7f24febb01a969bfdeb804e5fe\",\"title\":\"Stacked Spatio-Temporal Graph Convolutional Networks for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/3efc52b9a5190f7f24febb01a969bfdeb804e5fe\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2002.03266\",\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":\"10.1109/WACV45572.2020.9093283\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360\\u00b0 Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e8dd68dbcbb20b56e87214c681539dd2b39de7a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f26706daac5f920925871c1554da4db6f72702c6\",\"title\":\"Flickering Adversarial Attacks against Video Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/f26706daac5f920925871c1554da4db6f72702c6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.10066\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"title\":\"A Better Baseline for AVA\",\"url\":\"https://www.semanticscholar.org/paper/6fb3940ddd658e549a111870f10ca77ba3c4cf37\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.08496\",\"authors\":[{\"authorId\":\"35199438\",\"name\":\"Joshua Gleason\"},{\"authorId\":\"48467498\",\"name\":\"Rajeev Ranjan\"},{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"145668757\",\"name\":\"Carlos Castillo\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1109/WACV.2019.00021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"title\":\"A Proposal-Based Solution to Spatio-Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/1a2e40b8ef509ed099bb7e77862ed5ddca52c3a2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"2010.14742\",\"authors\":[{\"authorId\":\"51115810\",\"name\":\"Hochul Hwang\"},{\"authorId\":\"1831882\",\"name\":\"C. Jang\"},{\"authorId\":\"51311609\",\"name\":\"Geonwoo Park\"},{\"authorId\":\"1679356768\",\"name\":\"Junghyun Cho\"},{\"authorId\":\"49596689\",\"name\":\"Ig-Jae Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"title\":\"ElderSim: A Synthetic Data Generation Platform for Human Action Recognition in Eldercare Applications\",\"url\":\"https://www.semanticscholar.org/paper/06e3b496911e8f13e4fb54b61a636465d9cf1c99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657264680\",\"name\":\"Cece Jin\"},{\"authorId\":\"1500522440\",\"name\":\"T. Zhang\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"46439321\",\"name\":\"Ge Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053319\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"title\":\"Regression Before Classification for Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/eda43d4c38d7af6cf1dac123fcdd8b8a411e0e1a\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7496553\",\"name\":\"Dongli Wang\"},{\"authorId\":\"1724199\",\"name\":\"Jun Yang\"},{\"authorId\":\"46433441\",\"name\":\"Y. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a04144818f52def61cef3856cde3dd81b6dbaf8\",\"title\":\"Human action recognition based on multi-mode spatial-temporal feature fusion\",\"url\":\"https://www.semanticscholar.org/paper/7a04144818f52def61cef3856cde3dd81b6dbaf8\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":\"1908.08997\",\"authors\":[{\"authorId\":\"145801577\",\"name\":\"T. Hartley\"},{\"authorId\":\"47703950\",\"name\":\"K. Sidorov\"},{\"authorId\":\"97959395\",\"name\":\"C. Willis\"},{\"authorId\":\"144353457\",\"name\":\"A. D. Marshall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e1919f55a56d02cdffb69d9da6d7919bb359bd6\",\"title\":\"Gradient Weighted Superpixels for Interpretability in CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3e1919f55a56d02cdffb69d9da6d7919bb359bd6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"88728572\",\"name\":\"Yalong Jia\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00103\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"title\":\"Channel-wise Temporal Attention Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"62f1b47d94350ac17ec16e8569dcf6d9cf1ffcda\",\"title\":\"Activity Detection with Latent Sub-event Hierarchy Learning\",\"url\":\"https://www.semanticscholar.org/paper/62f1b47d94350ac17ec16e8569dcf6d9cf1ffcda\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49741227\",\"name\":\"Haifeng Sang\"},{\"authorId\":\"152254334\",\"name\":\"Z. Zhao\"},{\"authorId\":\"3030181\",\"name\":\"Dakuo He\"}],\"doi\":\"10.1109/ACCESS.2019.2936628\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"title\":\"Two-Level Attention Model Based Video Action Recognition Network\",\"url\":\"https://www.semanticscholar.org/paper/267dce4f4c6102e24eeac34d4315de7e7d25b538\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"1576511129\",\"name\":\"Zhong Cao\"},{\"authorId\":\"2782958\",\"name\":\"Weishen Pan\"},{\"authorId\":\"14966740\",\"name\":\"Changshui Zhang\"},{\"authorId\":\"1724003\",\"name\":\"J. Wang\"}],\"doi\":\"10.1109/TMM.2019.2960700\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd47c05f454a3c3980a6c623201db45acb08a70c\",\"title\":\"Deep Gesture Video Generation With Learning on Regions of Interest\",\"url\":\"https://www.semanticscholar.org/paper/dd47c05f454a3c3980a6c623201db45acb08a70c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7286873\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"36906906\",\"name\":\"Yi Wu\"},{\"authorId\":\"1750931828\",\"name\":\"Ke Cheng\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"},{\"authorId\":\"1694235\",\"name\":\"Hanqing Lu\"}],\"doi\":\"10.1016/j.patcog.2020.107416\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec7cbc6ef1599bff31816c003d18821fcf6d1bde\",\"title\":\"Gesture recognition based on deep deformable 3D convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7cbc6ef1599bff31816c003d18821fcf6d1bde\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1904.02909\",\"authors\":[{\"authorId\":\"9757384\",\"name\":\"Woon-Sung Park\"},{\"authorId\":\"144366095\",\"name\":\"M. Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b87df69011057c700f581798e8c13667f5205b8e\",\"title\":\"Deep Predictive Video Compression with Bi-directional Prediction\",\"url\":\"https://www.semanticscholar.org/paper/b87df69011057c700f581798e8c13667f5205b8e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"11859d37c85c7bb07f7496a62530340e1fdf7887\",\"title\":\"AHA-3D: A Labelled Dataset for Senior Fitness Exercise Recognition and Segmentation from 3D Skeletal Data\",\"url\":\"https://www.semanticscholar.org/paper/11859d37c85c7bb07f7496a62530340e1fdf7887\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1908.04353\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"},{\"authorId\":null,\"name\":\"HaiBo Chen\"}],\"doi\":\"10.1007/978-3-030-41299-9_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2099f70cabf2a8efaa3c84ee4d3c59bcc7d1518f\",\"title\":\"Action Recognition in Untrimmed Videos with Composite Self-Attention Two-Stream Framework\",\"url\":\"https://www.semanticscholar.org/paper/2099f70cabf2a8efaa3c84ee4d3c59bcc7d1518f\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"41076692\",\"name\":\"King Abdullah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0a1eaf6c39b147b0c25af180c75de60728bd5b05\",\"title\":\"Surfing Start : Unknown End : Unknown ! Input : Temporal Action Localization with Weak Supervision ! Background ! Pseudo Ground Truth ! !\",\"url\":\"https://www.semanticscholar.org/paper/0a1eaf6c39b147b0c25af180c75de60728bd5b05\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.08703\",\"authors\":[{\"authorId\":\"2398479\",\"name\":\"D. Mandal\"},{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"102609418\",\"name\":\"Saikumar Dwivedi\"},{\"authorId\":\"144147487\",\"name\":\"V. Gupta\"},{\"authorId\":\"7483338\",\"name\":\"Shuaib Ahmed\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2019.01022\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"510b6717750d711f590e4df0e9a9c82ff332ff46\",\"title\":\"Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/510b6717750d711f590e4df0e9a9c82ff332ff46\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50699209\",\"name\":\"B. Yang\"},{\"authorId\":\"145313443\",\"name\":\"P. Zhou\"}],\"doi\":\"10.1117/12.2540276\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7bcea6e7382735bcac5c5675412003c75550ffac\",\"title\":\"Mixed 3D-(2+1)D convolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7bcea6e7382735bcac5c5675412003c75550ffac\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1926536\",\"name\":\"Chengcheng Wei\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/BigMM.2019.00027\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be5b602bfbc6488f8ef633db1292f70138b5751b\",\"title\":\"Deep Grammatical Multi-classifier for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be5b602bfbc6488f8ef633db1292f70138b5751b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36751124\",\"name\":\"Amit Nagpal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d5668835305efae2697844a053a3451e25f2b8e9\",\"title\":\"Fine grained action recognition in sports videos\",\"url\":\"https://www.semanticscholar.org/paper/d5668835305efae2697844a053a3451e25f2b8e9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"134883142\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2018.2887408\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification With Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"46365817\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":\"10.1007/978-3-030-37734-2_68\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"22da750028ee1a5b6df4ce8ec1fa8e8d1de2160a\",\"title\":\"VIREO @ Video Browser Showdown 2020\",\"url\":\"https://www.semanticscholar.org/paper/22da750028ee1a5b6df4ce8ec1fa8e8d1de2160a\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":\"1908.08990\",\"authors\":[{\"authorId\":\"1720818\",\"name\":\"Sebastian Agethen\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/TMM.2019.2932564\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1f4e2bdd9bf848e967b4e68203a914475d306a58\",\"title\":\"Deep Multi-Kernel Convolutional LSTM Networks and an Attention-Based Mechanism for Videos\",\"url\":\"https://www.semanticscholar.org/paper/1f4e2bdd9bf848e967b4e68203a914475d306a58\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151472652\",\"name\":\"Yuqi Huo\"},{\"authorId\":\"101246507\",\"name\":\"Xiaoli Xu\"},{\"authorId\":\"46215480\",\"name\":\"Yao Lu\"},{\"authorId\":\"2520427\",\"name\":\"Yulei Niu\"},{\"authorId\":\"48876151\",\"name\":\"Mingyu Ding\"},{\"authorId\":\"1776220\",\"name\":\"Zhiwu Lu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"153693432\",\"name\":\"Jirong Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"title\":\"Lightweight Action Recognition in Compressed Videos\",\"url\":\"https://www.semanticscholar.org/paper/89fafbe91b31d43dc3314ffabffa79a5f5ad746f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"145880167\",\"name\":\"B. Huet\"},{\"authorId\":\"152650698\",\"name\":\"Chong-Wah Ngo\"}],\"doi\":\"10.1109/ICCVW.2019.00233\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc505fdd23c8771182a601f01df9b1a64bf9ba34\",\"title\":\"Fusion of Multimodal Embeddings for Ad-Hoc Video Search\",\"url\":\"https://www.semanticscholar.org/paper/cc505fdd23c8771182a601f01df9b1a64bf9ba34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.1007/978-981-15-4584-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b89036fc9082a9b1871d04a679d68b284069fdb8\",\"title\":\"The Development of Deep Learning Technologies: Research on the Development of Electronic Information Engineering Technology in China\",\"url\":\"https://www.semanticscholar.org/paper/b89036fc9082a9b1871d04a679d68b284069fdb8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1807.08069\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"207a1766a942be3f22534980f47916f6dc683095\",\"title\":\"S3D: Single Shot multi-Span Detector via Fully 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/207a1766a942be3f22534980f47916f6dc683095\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1806.06793\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICPR.2018.8545324\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a377f2c99218e0eb624ba65d6711c640b1697b92\",\"title\":\"Deep Spatiotemporal Representation of the Face for Automatic Pain Intensity Estimation\",\"url\":\"https://www.semanticscholar.org/paper/a377f2c99218e0eb624ba65d6711c640b1697b92\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1906.03340\",\"authors\":[{\"authorId\":\"144097992\",\"name\":\"I. Kwak\"},{\"authorId\":\"38998440\",\"name\":\"David A. Kriegman\"},{\"authorId\":\"2424812\",\"name\":\"K. Branson\"}],\"doi\":\"10.1109/WACV45572.2020.9093405\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66d7fe24f86504517a5a33679043379066676921\",\"title\":\"Detecting the Starting Frame of Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/66d7fe24f86504517a5a33679043379066676921\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2019.00807\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"title\":\"MARS: Motion-Augmented RGB Stream for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152153140\",\"name\":\"Xiuping Bao\"},{\"authorId\":\"49706674\",\"name\":\"J. Yuan\"},{\"authorId\":null,\"name\":\"Bei Chen\"}],\"doi\":\"10.1109/ICTAI.2019.00089\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60de1895702532f93b93b616d7a47096dfd1dc6c\",\"title\":\"ECPNet: An Efficient Attention-Based Convolution Network with Pseudo-3D Block for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60de1895702532f93b93b616d7a47096dfd1dc6c\",\"venue\":\"2019 IEEE 31st International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/WACV45572.2020.9093575\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8cdc241f90d578a1dd79db11081f291211986ac9\",\"title\":\"Looking deeper into Time for Activities of Daily Living Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8cdc241f90d578a1dd79db11081f291211986ac9\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1808.00141\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1007/978-3-030-11015-4_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"title\":\"Action Anticipation By Predicting Future Dynamic Images\",\"url\":\"https://www.semanticscholar.org/paper/5731c4c48aecf2fb15a96a3578016437a4d44cfd\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2006.15731\",\"authors\":[{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"33615817\",\"name\":\"M. Hebert\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"99b33c3b1a38aa4c2569abb98ca21759951849d5\",\"title\":\"Unsupervised Learning of Video Representations via Dense Trajectory Clustering\",\"url\":\"https://www.semanticscholar.org/paper/99b33c3b1a38aa4c2569abb98ca21759951849d5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.12424\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"152464732\",\"name\":\"Qi Dai\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1688516\",\"name\":\"Jingdong Wang\"}],\"doi\":\"10.1109/CVPR42600.2020.00109\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"title\":\"Weakly-Supervised Action Localization by Generative Attention Modeling\",\"url\":\"https://www.semanticscholar.org/paper/3e9901bccd0b210daff1fbeff758cea3cc0ec7f9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.09963\",\"authors\":[{\"authorId\":\"1429148175\",\"name\":\"Pilhyeon Lee\"},{\"authorId\":\"2847986\",\"name\":\"Youngjung Uh\"},{\"authorId\":\"1703310\",\"name\":\"Hyeran Byun\"}],\"doi\":\"10.1609/AAAI.V34I07.6793\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89d28af38b1993d2cb3ab04d2c5e9aeaaf383286\",\"title\":\"Background Suppression Network for Weakly-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/89d28af38b1993d2cb3ab04d2c5e9aeaaf383286\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145691225\",\"name\":\"Santiago Castro\"},{\"authorId\":\"144886349\",\"name\":\"Mahmoud Azab\"},{\"authorId\":\"143935879\",\"name\":\"Jonathan C. Stroud\"},{\"authorId\":\"1724416445\",\"name\":\"Cristina Noujaim\"},{\"authorId\":\"30646659\",\"name\":\"R. Wang\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"title\":\"LifeQA: A Real-life Dataset for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/4621240ed38a7b42ad4fc77aa24d111c5d947934\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3005372\",\"name\":\"Abdourrahmane M. Atto\"},{\"authorId\":\"144373800\",\"name\":\"A. Benoit\"},{\"authorId\":\"47858467\",\"name\":\"P. Lambert\"}],\"doi\":\"10.1016/j.patcog.2020.107353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d767c20bd91fc785b170e271a15508f56ee92fc4\",\"title\":\"Timed-image based deep learning for action recognition in video sequences\",\"url\":\"https://www.semanticscholar.org/paper/d767c20bd91fc785b170e271a15508f56ee92fc4\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1905.12462\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"title\":\"Hierarchical Feature Aggregation Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/adec3b5b4ebccbdacdcd0c805f7c73501852b3cd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119718662\",\"name\":\"Qian Zhang\"},{\"authorId\":\"10841021\",\"name\":\"Yeqi Liu\"},{\"authorId\":\"51436039\",\"name\":\"Chuanyang Gong\"},{\"authorId\":\"2667559\",\"name\":\"Y. Chen\"},{\"authorId\":\"46493350\",\"name\":\"HuiHui Yu\"}],\"doi\":\"10.3390/s20051520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac0d024d53c1e6252229217c79fcd3b1f5d91caf\",\"title\":\"Applications of Deep Learning for Dense Scenes Analysis in Agriculture: A Review\",\"url\":\"https://www.semanticscholar.org/paper/ac0d024d53c1e6252229217c79fcd3b1f5d91caf\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2009.08427\",\"authors\":[{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"343f14319d5e34c37eeb86dea88fa82f56715679\",\"title\":\"Dynamic Regions Graph Neural Networks for Spatio-Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/343f14319d5e34c37eeb86dea88fa82f56715679\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.05438\",\"authors\":[{\"authorId\":\"1846789641\",\"name\":\"Maxat Alibayev\"},{\"authorId\":\"7818698\",\"name\":\"D. Paulius\"},{\"authorId\":\"143971676\",\"name\":\"Y. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"title\":\"Developing Motion Code Embedding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/48fb5a24f32dd72b6f94c4cb079345ea5aeee9b7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26339425\",\"name\":\"Valentin Vielzeuf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0501b8a99270a20c7536ed2f6df6569413810f6d\",\"title\":\"Apprentissage neuronal profond pour l'analyse de contenus multimodaux et temporels. (Deep learning for multimodal and temporal contents analysis)\",\"url\":\"https://www.semanticscholar.org/paper/0501b8a99270a20c7536ed2f6df6569413810f6d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145476300\",\"name\":\"P. Zhdanov\"},{\"authorId\":\"143636123\",\"name\":\"A. Khan\"},{\"authorId\":\"2525887\",\"name\":\"A. R. Rivera\"},{\"authorId\":\"1803086\",\"name\":\"A. Khattak\"}],\"doi\":\"10.1109/IJCNN.2018.8489663\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c54fe61181045865d6834e2fe4376aeea1f9884\",\"title\":\"Improving Human Action Recognition through Hierarchical Neural Network Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/4c54fe61181045865d6834e2fe4376aeea1f9884\",\"venue\":\"2018 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2018},{\"arxivId\":\"1807.10982\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1781242\",\"name\":\"Abhinav Shrivastava\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-01252-6_20\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"title\":\"Actor-Centric Relation Network\",\"url\":\"https://www.semanticscholar.org/paper/6b325af08a63bc8f94c39ae1c12509dce23d755c\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/CVPR42600.2020.01271\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"f6caf91f731fab861ef420f680cf691f12f70134\",\"title\":\"What Makes Training Multi-Modal Classification Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/f6caf91f731fab861ef420f680cf691f12f70134\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1902.06162\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/tpami.2020.2992393\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"title\":\"Self-supervised Visual Feature Learning with Deep Neural Networks: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/4c94ee7df6bc2bfcac76703be4f059a79010f7e5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":null,\"name\":\"Juncheng Li\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/s13735-018-00166-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6305115f393d96df92f9044b8951969e28aa7114\",\"title\":\"Joint embeddings with multimodal cues for video-text retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6305115f393d96df92f9044b8951969e28aa7114\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145905489\",\"name\":\"Y. Huang\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"},{\"authorId\":\"35392319\",\"name\":\"Shao-Heng Tai\"}],\"doi\":\"10.1007/978-3-030-11012-3_33\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8639c08322b30a456662e439b5bb7edd2e2551e6\",\"title\":\"Human Action Recognition Based on Temporal Pose CNN and Multi-dimensional Fusion\",\"url\":\"https://www.semanticscholar.org/paper/8639c08322b30a456662e439b5bb7edd2e2551e6\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1807.09380\",\"authors\":[{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"title\":\"Contrastive Video Representation Learning via Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/2db569d7e7e230ebcbef90ad6bdf9f6ed034c00c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2001.05488\",\"authors\":[{\"authorId\":\"13700560\",\"name\":\"J. J. Sun\"},{\"authorId\":\"50021909\",\"name\":\"T. Liu\"},{\"authorId\":\"49531494\",\"name\":\"Alan S. Cowen\"},{\"authorId\":\"3302320\",\"name\":\"Florian Schroff\"},{\"authorId\":\"2595180\",\"name\":\"H. Adam\"},{\"authorId\":\"2775959\",\"name\":\"Gautam Prasad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b343bd8c8a30e724020bfe753391a10ba5d6100e\",\"title\":\"EEV Dataset: Predicting Expressions Evoked by Diverse Videos\",\"url\":\"https://www.semanticscholar.org/paper/b343bd8c8a30e724020bfe753391a10ba5d6100e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88738343\",\"name\":\"E. Porter\"},{\"authorId\":\"144473481\",\"name\":\"P. Fuentes\"},{\"authorId\":\"8863848\",\"name\":\"Z. Siddiqui\"},{\"authorId\":\"47022428\",\"name\":\"Andrew B Thompson\"},{\"authorId\":\"1845196\",\"name\":\"R. Levitin\"},{\"authorId\":\"38600238\",\"name\":\"D. Solis\"},{\"authorId\":\"83627267\",\"name\":\"N. Myziuk\"},{\"authorId\":\"145884627\",\"name\":\"T. Guerrero\"}],\"doi\":\"10.1002/mp.14098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7081ac2d4a8cc51ff3e836a7cdc63d2148301796\",\"title\":\"Hippocampus Segmentation on non-Contrast CT using Deep Learning.\",\"url\":\"https://www.semanticscholar.org/paper/7081ac2d4a8cc51ff3e836a7cdc63d2148301796\",\"venue\":\"Medical physics\",\"year\":2020},{\"arxivId\":\"2012.07508\",\"authors\":[{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"153211990\",\"name\":\"Di Hu\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b20ccb5e53bcc5e76d05d173149d3926bec952fd\",\"title\":\"Temporal Relational Modeling with Self-Supervision for Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b20ccb5e53bcc5e76d05d173149d3926bec952fd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.09289\",\"authors\":[{\"authorId\":\"1491321681\",\"name\":\"Alptekin Orbay\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3bb8bfe4591346e839cc671d09ddb110bed48bff\",\"title\":\"Master Thesis: Neural Sign Language Translation by Learning Tokenization\",\"url\":\"https://www.semanticscholar.org/paper/3bb8bfe4591346e839cc671d09ddb110bed48bff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10299\",\"authors\":[{\"authorId\":\"35663637\",\"name\":\"R. Sanford\"},{\"authorId\":\"38111179\",\"name\":\"Siavash Gorji\"},{\"authorId\":\"2429097\",\"name\":\"Luiz G. Hafemann\"},{\"authorId\":\"2116752\",\"name\":\"B. Pourbabaee\"},{\"authorId\":\"145556010\",\"name\":\"M. Javan\"}],\"doi\":\"10.1109/CVPRW50498.2020.00457\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9a8f1403dab1116dd841e42fc09212201512d177\",\"title\":\"Group Activity Detection from Trajectory and Video Data in Soccer\",\"url\":\"https://www.semanticscholar.org/paper/9a8f1403dab1116dd841e42fc09212201512d177\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3275727\",\"name\":\"Linxi (Jim) Fan\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"96374437\",\"name\":\"Guanzhi Wang\"},{\"authorId\":\"2013547017\",\"name\":\"Ryan Cao\"},{\"authorId\":\"2117748\",\"name\":\"Yuke Zhu\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-030-58529-7_30\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"title\":\"RubiksNet: Learnable 3D-Shift for Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ab0c5006bb157b801ec592951a1da2c8af9d158\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"}],\"doi\":\"10.1145/3394171.3413654\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87fc465274a3ee292606e81ae1b9e232c0ff0c39\",\"title\":\"Recognizing Camera Wearer from Hand Gestures in Egocentric Videos: https://egocentricbiometric.github.io/\",\"url\":\"https://www.semanticscholar.org/paper/87fc465274a3ee292606e81ae1b9e232c0ff0c39\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2001.03463\",\"authors\":[{\"authorId\":\"5546708\",\"name\":\"Ronak Gupta\"},{\"authorId\":\"72177702\",\"name\":\"Prashant Anand\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"},{\"authorId\":\"46900434\",\"name\":\"S. Singh\"}],\"doi\":\"10.1007/978-981-15-8697-2_40\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3b54f1d1fd2331a05445d0ba1584900dc9674a53\",\"title\":\"Compressive sensing based privacy for fall detection\",\"url\":\"https://www.semanticscholar.org/paper/3b54f1d1fd2331a05445d0ba1584900dc9674a53\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1908.07625\",\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1109/ICCV.2019.00558\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"title\":\"Action Recognition With Spatial-Temporal Discriminative Filter Banks\",\"url\":\"https://www.semanticscholar.org/paper/d5a8fbb37f564b397071e016fb39e4c6a612cc83\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.04316\",\"authors\":[{\"authorId\":\"34656387\",\"name\":\"Matteo Tomei\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"2175529\",\"name\":\"Simone Calderara\"},{\"authorId\":\"102613292\",\"name\":\"Simone Bronzin\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"title\":\"STAGE: Spatio-Temporal Attention on Graph Entities for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ad16dbe1a5c3b192de961a1f1c3fedeba8bf2783\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.11524\",\"authors\":[{\"authorId\":\"46398922\",\"name\":\"Y. Liu\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"48380246\",\"name\":\"Yifeng Zhang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1109/CVPR.2019.00372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"title\":\"Multi-Granularity Generator for Temporal Action Proposal\",\"url\":\"https://www.semanticscholar.org/paper/990fb8c10628754e69fa8d0003d1fc0ed3e2027c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.07385\",\"authors\":[{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"121983272\",\"name\":\"Benjam\\u00edn B\\u00e9jar Haro\"},{\"authorId\":\"144187890\",\"name\":\"R. Vidal\"}],\"doi\":\"10.1007/978-3-030-58526-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74351e588889c4c018f627c6547033b857a7ad38\",\"title\":\"Representation Learning on Visual-Symbolic Graphs for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/74351e588889c4c018f627c6547033b857a7ad38\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038499155\",\"name\":\"Yuhao Zhang\"},{\"authorId\":\"144184407\",\"name\":\"Jun Liao\"},{\"authorId\":\"52201470\",\"name\":\"Mengyuan Ran\"},{\"authorId\":\"50080172\",\"name\":\"X. Li\"},{\"authorId\":\"118188869\",\"name\":\"S. Wang\"},{\"authorId\":\"120095706\",\"name\":\"Li Liu\"}],\"doi\":\"10.1109/SMC42975.2020.9283407\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e188653c8638298f83cbadf4c92ac4d439407640\",\"title\":\"ST-Xception: A Depthwise Separable Convolution Network for Military Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e188653c8638298f83cbadf4c92ac4d439407640\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"1712.00097\",\"authors\":[{\"authorId\":\"3112334\",\"name\":\"Behrooz Mahasseni\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"title\":\"Budget-Aware Activity Detection with A Recurrent Policy Network\",\"url\":\"https://www.semanticscholar.org/paper/11769e150d4473d6983f4f6abb0ec7aa58d555ea\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39103529\",\"name\":\"Talmo D. Pereira\"},{\"authorId\":\"46805706\",\"name\":\"Joshua W Shaevitz\"},{\"authorId\":\"145776127\",\"name\":\"M. Murthy\"}],\"doi\":\"10.1038/s41593-020-00734-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f70264e49ffee8779d6cc87e7aec542d1452afc3\",\"title\":\"Quantifying behavior to understand the brain.\",\"url\":\"https://www.semanticscholar.org/paper/f70264e49ffee8779d6cc87e7aec542d1452afc3\",\"venue\":\"Nature neuroscience\",\"year\":2020},{\"arxivId\":\"2007.10984\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-58621-8_44\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43971a0a2593f660427e016032b983b52f8dd8eb\",\"title\":\"Foley Music: Learning to Generate Music from Videos\",\"url\":\"https://www.semanticscholar.org/paper/43971a0a2593f660427e016032b983b52f8dd8eb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.02488\",\"authors\":[{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"144722114\",\"name\":\"Thalaiyasingam Ajanthan\"},{\"authorId\":\"143729959\",\"name\":\"Vibhav Vineet\"},{\"authorId\":\"49827339\",\"name\":\"R. Hartley\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9a22019d96696965c6d572ff0ad95541c173bd8\",\"title\":\"RANP: Resource Aware Neuron Pruning at Initialization for 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/b9a22019d96696965c6d572ff0ad95541c173bd8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.02406\",\"authors\":[{\"authorId\":\"28064618\",\"name\":\"Xinli Yu\"},{\"authorId\":\"40031204\",\"name\":\"M. Malmir\"},{\"authorId\":\"6312396\",\"name\":\"C. He\"},{\"authorId\":\"100576986\",\"name\":\"Yue Liu\"},{\"authorId\":\"144667222\",\"name\":\"Rex Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b827558cb940ca4ca49c31575cb053da1c4dd9ff\",\"title\":\"Video Moment Retrieval via Natural Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/b827558cb940ca4ca49c31575cb053da1c4dd9ff\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03056\",\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"49796048\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1007/978-3-030-58545-7_5\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"title\":\"VPN: Learning Video-Pose Embedding for Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/de51038f9f9e94fa9fdb54c5c3e911f918e87ba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.12530\",\"authors\":[{\"authorId\":\"1832165240\",\"name\":\"Nikolas Adaloglou\"},{\"authorId\":\"1832364767\",\"name\":\"Theocharis Chatzis\"},{\"authorId\":\"1720774729\",\"name\":\"Ilias Papastratis\"},{\"authorId\":\"51919460\",\"name\":\"Andreas Stergioulas\"},{\"authorId\":\"33961149\",\"name\":\"G. Papadopoulos\"},{\"authorId\":\"1832359458\",\"name\":\"Vassia Zacharopoulou\"},{\"authorId\":\"2619600\",\"name\":\"George J. Xydopoulos\"},{\"authorId\":\"1832338213\",\"name\":\"Klimnis Atzakas\"},{\"authorId\":\"72239752\",\"name\":\"D. Papazachariou\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"29e207f184213e521839f4686d6fc282fea97ef1\",\"title\":\"A Comprehensive Study on Sign Language Recognition Methods\",\"url\":\"https://www.semanticscholar.org/paper/29e207f184213e521839f4686d6fc282fea97ef1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03848\",\"authors\":[{\"authorId\":\"1947101\",\"name\":\"Shijie Geng\"},{\"authorId\":\"144740494\",\"name\":\"Peng Gao\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"9332945\",\"name\":\"Jonathan Le Roux\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03598364626c419d3a2578b5c22403f0dd246e99\",\"title\":\"Spatio-Temporal Scene Graphs for Video Dialog\",\"url\":\"https://www.semanticscholar.org/paper/03598364626c419d3a2578b5c22403f0dd246e99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00074\",\"authors\":[{\"authorId\":\"3270239\",\"name\":\"L. Shi\"},{\"authorId\":\"145882781\",\"name\":\"D. Rajan\"},{\"authorId\":\"27401739\",\"name\":\"S. Abedin\"},{\"authorId\":\"134495047\",\"name\":\"Manikanta Srikar Yellapragada\"},{\"authorId\":\"1740300\",\"name\":\"D. Beymer\"},{\"authorId\":\"2774941\",\"name\":\"E. Dehghan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93f797781222d4367ecc6ebc47f121a1056683a8\",\"title\":\"Automatic Diagnosis of Pulmonary Embolism Using an Attention-guided Framework: A Large-scale Study\",\"url\":\"https://www.semanticscholar.org/paper/93f797781222d4367ecc6ebc47f121a1056683a8\",\"venue\":\"MIDL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1980683\",\"name\":\"S. Aeron\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f0adb0c5bae70e19c84a14de05726d774cf5e1c3\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal TransportSupplementary Material\",\"url\":\"https://www.semanticscholar.org/paper/f0adb0c5bae70e19c84a14de05726d774cf5e1c3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.05993\",\"authors\":[{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"50604196\",\"name\":\"M. Jones\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":\"10.1109/tpami.2020.3040591\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02d0ef096d3b39bb83a344393522360aaf69d694\",\"title\":\"A Survey of Single-Scene Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/02d0ef096d3b39bb83a344393522360aaf69d694\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1906.11415\",\"authors\":[{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"3451430\",\"name\":\"Zhangjie Cao\"},{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ede7829b3f057a874c513919d19307e2b60ead23\",\"title\":\"Few-Shot Video Classification via Temporal Alignment\",\"url\":\"https://www.semanticscholar.org/paper/ede7829b3f057a874c513919d19307e2b60ead23\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2002.05520\",\"authors\":[{\"authorId\":\"49060072\",\"name\":\"Mu Yuan\"},{\"authorId\":\"1491105524\",\"name\":\"Lan Zhang\"},{\"authorId\":\"50080038\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"151491226\",\"name\":\"Hui Xiong\"}],\"doi\":\"10.1109/ICDE48307.2020.00188\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66dd4f71dcf3b7d2b45d453105cb7e4987a0d139\",\"title\":\"Comprehensive and Efficient Data Labeling via Adaptive Model Scheduling\",\"url\":\"https://www.semanticscholar.org/paper/66dd4f71dcf3b7d2b45d453105cb7e4987a0d139\",\"venue\":\"2020 IEEE 36th International Conference on Data Engineering (ICDE)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70249755\",\"name\":\"Zachary Wharton\"},{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"2004428132\",\"name\":\"Nikolaos Bessis\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1b3e3b52ac85512fb87be2df7ad4f0e67c99a8b1\",\"title\":\"Coarse Temporal Attention Network (CTA-Net) for Driver\\u2019s Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3e3b52ac85512fb87be2df7ad4f0e67c99a8b1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":null,\"name\":\"Gedas Bertasius\"},{\"authorId\":null,\"name\":\"Tae-Hyun Oh\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"86a9e09459c5a4e436706d0b89f951d780e80a71\",\"title\":\"Supervoxel Attention Graphs for Long-Range Video Modeling\",\"url\":\"https://www.semanticscholar.org/paper/86a9e09459c5a4e436706d0b89f951d780e80a71\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"1751242\",\"name\":\"Yusuke Sugano\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/cvpr42600.2020.01404\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2aeb56eee55d26fa845c7872b996c3d92bc45abd\",\"title\":\"Improving Action Segmentation via Graph-Based Temporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/2aeb56eee55d26fa845c7872b996c3d92bc45abd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00459\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6f7886ee688d86a575203c1b308199a8fe6c1f5b\",\"title\":\"Activity-aware Attributes for Zero-Shot Driver Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6f7886ee688d86a575203c1b308199a8fe6c1f5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1810.11731\",\"authors\":[{\"authorId\":\"1412518183\",\"name\":\"Marian K. Y. Boktor\"},{\"authorId\":\"1410429737\",\"name\":\"A. Al-Kabbany\"},{\"authorId\":\"46318863\",\"name\":\"Radwa Khalil\"},{\"authorId\":\"1398644693\",\"name\":\"S. El-Khamy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6044b30751c19b3231782fb0475c9ca438940690\",\"title\":\"Real-time Action Recognition with Dissimilarity-based Training of Specialized Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/6044b30751c19b3231782fb0475c9ca438940690\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.11465\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"1761350\",\"name\":\"M. Mansour\"}],\"doi\":\"10.1109/ICIP.2019.8803051\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e017494522a1609516f755f3023e7a48b18a95e\",\"title\":\"Loss Switching Fusion with Similarity Search for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/3e017494522a1609516f755f3023e7a48b18a95e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34608005\",\"name\":\"L. Chen\"},{\"authorId\":\"144207288\",\"name\":\"R. Liu\"},{\"authorId\":\"153450634\",\"name\":\"Dongsheng Zhou\"},{\"authorId\":\"50031413\",\"name\":\"X. Yang\"},{\"authorId\":\"47835286\",\"name\":\"Qing-fang Zhang\"}],\"doi\":\"10.1186/s42492-020-00045-x\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"115880905156feef7d751840b7f59c72987b17a8\",\"title\":\"Fused behavior recognition model based on attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/115880905156feef7d751840b7f59c72987b17a8\",\"venue\":\"Vis. Comput. Ind. Biomed. Art\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1145/3303083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91aa0eb38446643cd622b060a76043b0ca2d7991\",\"title\":\"Rich Visual and Language Representation with Complementary Semantics for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/91aa0eb38446643cd622b060a76043b0ca2d7991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2224475\",\"name\":\"Huogen Wang\"},{\"authorId\":\"9459349\",\"name\":\"Zhanjie Song\"},{\"authorId\":\"15585183\",\"name\":\"W. Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"}],\"doi\":\"10.3390/s20113305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b84d02d6f74a53d1196478689797eef63c306b3\",\"title\":\"A Hybrid Network for Large-Scale Action Recognition from RGB and Depth Modalities\",\"url\":\"https://www.semanticscholar.org/paper/3b84d02d6f74a53d1196478689797eef63c306b3\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2008.05977\",\"authors\":[{\"authorId\":\"1876283791\",\"name\":\"Ling-An Zeng\"},{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"40538505\",\"name\":\"Q. Yu\"},{\"authorId\":\"1491635278\",\"name\":\"Wei Zeng\"},{\"authorId\":null,\"name\":\"Yao-Wei Wang\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1145/1122445.1122456\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ff255c162a2e91bcc871bb9285bdf07d9385ece8\",\"title\":\"Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/ff255c162a2e91bcc871bb9285bdf07d9385ece8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.10663\",\"authors\":[{\"authorId\":\"2598007\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"12358136\",\"name\":\"Fan Lyu\"},{\"authorId\":\"1409949029\",\"name\":\"W. Feng\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/ICME46284.2020.9102717\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d706c38381ec095c8e456b0b0387ae212e0581be\",\"title\":\"Modeling Cross-View Interaction Consistency for Paired Egocentric Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d706c38381ec095c8e456b0b0387ae212e0581be\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390477390\",\"name\":\"Zhenhao Sun\"},{\"authorId\":\"15592126\",\"name\":\"Xiaodong Wang\"},{\"authorId\":\"30024940\",\"name\":\"Qiudan Zhang\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1109/ACCESS.2019.2946479\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"title\":\"Real-Time Video Saliency Prediction Via 3D Residual Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3e896d6e00cd47f8ec07cf4a641d48f032895058\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144118590\",\"name\":\"Kangmin Bae\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1f69376de7aa59dc7a5050c9d9a5254ea26ca6e\",\"title\":\"Anti-Litter Surveillance based on Person Understanding via Multi-Task Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1f69376de7aa59dc7a5050c9d9a5254ea26ca6e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1804.04326\",\"authors\":[{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"2996464\",\"name\":\"Jiaqing Lin\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"title\":\"STAIR Actions: A Video Dataset of Everyday Home Actions\",\"url\":\"https://www.semanticscholar.org/paper/d3f5a1848b0028d8ab51d0b0673732cad2e3c8c9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2647061\",\"name\":\"Zijun Wei\"},{\"authorId\":\"49292395\",\"name\":\"B. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"41193203\",\"name\":\"R. Mech\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"}],\"doi\":\"10.1109/TPAMI.2019.2940225\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"810bfc2786292757185ed53b29e98c56ee1c95d5\",\"title\":\"Sequence-to-Segments Networks for Detecting Segments in Videos.\",\"url\":\"https://www.semanticscholar.org/paper/810bfc2786292757185ed53b29e98c56ee1c95d5\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"50135244\",\"name\":\"Wenjia Li\"},{\"authorId\":\"143677598\",\"name\":\"R. Tao\"}],\"doi\":\"10.1109/LSP.2019.2940111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab9b40a95e4b2328cb681de4413ba918a978ecff\",\"title\":\"Multi-Branch Spatial-Temporal Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab9b40a95e4b2328cb681de4413ba918a978ecff\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47438668\",\"name\":\"M. Borg\"},{\"authorId\":\"9332379\",\"name\":\"K. P. Camilleri\"}],\"doi\":\"10.1109/ICASSP.2019.8683257\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1fdec39d5a8d207db36a181dbe7312713d1a08e4\",\"title\":\"Sign Language Detection \\u201cin the Wild\\u201d with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1fdec39d5a8d207db36a181dbe7312713d1a08e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1811.07157\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"title\":\"Recurrence to the Rescue: Towards Causal Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/247ee3e4519381a84fdfe655223c270c4ef1ad75\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.10364\",\"authors\":[{\"authorId\":\"67344892\",\"name\":\"Federico Landi\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"533aa3d1d990b0916294143d448f895116d825bc\",\"title\":\"Anomaly Locality in Video Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/533aa3d1d990b0916294143d448f895116d825bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"46696307\",\"name\":\"H. Kim\"},{\"authorId\":\"151487048\",\"name\":\"Daekwan Ko\"},{\"authorId\":\"51492435\",\"name\":\"Soo-Chul Lim\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":\"10.1109/RITAPP.2019.8932854\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0263b72d3cea4281a1bf010c041b9a0f4b888bc1\",\"title\":\"Which LSTM Type is Better for Interaction Force Estimation?\",\"url\":\"https://www.semanticscholar.org/paper/0263b72d3cea4281a1bf010c041b9a0f4b888bc1\",\"venue\":\"2019 7th International Conference on Robot Intelligence Technology and Applications (RiTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471304742\",\"name\":\"Manh-Hung Lu\"},{\"authorId\":\"40429856\",\"name\":\"Thi-Oanh Nguyen\"}],\"doi\":\"10.1145/3368926.3369726\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2965fc1c8f97339cac4a5869b2a5ee56dbd27d6\",\"title\":\"Spatio-temporal Multi-level Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2965fc1c8f97339cac4a5869b2a5ee56dbd27d6\",\"venue\":\"SoICT 2019\",\"year\":2019},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.10695\",\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f771b7514664d2b5e4f7dc12400897db95b0e136\",\"title\":\"Multimodal Transformer with Pointer Network for the DSTC8 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/f771b7514664d2b5e4f7dc12400897db95b0e136\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47412818\",\"name\":\"Guangming Zhu\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"},{\"authorId\":\"152538521\",\"name\":\"L. Yang\"},{\"authorId\":\"46665820\",\"name\":\"Lin Mei\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"}],\"doi\":\"10.1109/TNNLS.2019.2919764\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d066facb6624dd54c877068d8727ae536f37d0d4\",\"title\":\"Redundancy and Attention in Convolutional LSTM for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d066facb6624dd54c877068d8727ae536f37d0d4\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1629172313\",\"name\":\"Liqing Wan\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"},{\"authorId\":\"2042151\",\"name\":\"Shunli Zhang\"},{\"authorId\":\"34985619\",\"name\":\"Xiaoping Che\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00168\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"title\":\"A Fast Action Recognition Method with Cascaded Networks\",\"url\":\"https://www.semanticscholar.org/paper/bad812d6500b3e3269880ebf81be9f8f6cbc5c09\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"}],\"doi\":\"10.26153/TSW/5847\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"title\":\"Learning to compose photos and videos from passive cameras\",\"url\":\"https://www.semanticscholar.org/paper/4b64bcb39e979cf6eaeb7739af468b0a08e6250d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"145919634\",\"name\":\"X. Wen\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"153626293\",\"name\":\"Dong Liu\"},{\"authorId\":\"46772808\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3343031.3350891\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"title\":\"Cross-Fiber Spatial-Temporal Co-enhanced Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b725e11efdc4b4bd367e555dd2a70530b9002c68\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.06423\",\"authors\":[{\"authorId\":\"153494805\",\"name\":\"Valter Lu\\u00eds Estevam Junior\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"50534501\",\"name\":\"D. Menotti\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e93e88c1b38e9d4733f3b5d692b354035fe57fdf\",\"title\":\"Zero-Shot Action Recognition in Videos: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/e93e88c1b38e9d4733f3b5d692b354035fe57fdf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2028218872\",\"name\":\"Kara Marie Schatz\"},{\"authorId\":\"1607110764\",\"name\":\"Erik Quintanilla\"},{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":\"10.1007/978-3-030-58583-9_25\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"64eba0de822754df1bc1303f96163265dea9ac4f\",\"title\":\"A Recurrent Transformer Network for Novel View Action Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/64eba0de822754df1bc1303f96163265dea9ac4f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1810.11579\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"65737740\",\"name\":\"J. Li\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5\",\"title\":\"A2-Nets: Double Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7339c1deeb617c894cc08c92ed8c2d4ab14b4b5\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"145940718\",\"name\":\"Yang Zhao\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1016/j.neucom.2018.06.071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"title\":\"Action recognition using spatial-optical data organization and sequential learning framework\",\"url\":\"https://www.semanticscholar.org/paper/f3123b1d2dde97b12fdf3a2bf21fb7e190842721\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"2012.10071\",\"authors\":[{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"9445458\",\"name\":\"Zhan Tong\"},{\"authorId\":\"1511715446\",\"name\":\"Bin Ji\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"839a009d4d530483cb9b365012ffc7d76cd88b85\",\"title\":\"TDN: Temporal Difference Networks for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/839a009d4d530483cb9b365012ffc7d76cd88b85\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40506942\",\"name\":\"Woobin Im\"},{\"authorId\":\"143617697\",\"name\":\"Tae-Kyun Kim\"},{\"authorId\":\"49460338\",\"name\":\"S. Yoon\"}],\"doi\":\"10.1007/978-3-030-58586-0_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60c45ceea3ad5373fcb2801cfc846985e3ed38d3\",\"title\":\"Unsupervised Learning of Optical Flow with Deep Feature Similarity\",\"url\":\"https://www.semanticscholar.org/paper/60c45ceea3ad5373fcb2801cfc846985e3ed38d3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1712.09184\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPR.2018.00044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"title\":\"Detect-and-Track: Efficient Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.04035\",\"authors\":[{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"40550616\",\"name\":\"D. Casas\"},{\"authorId\":\"2895238\",\"name\":\"Yotam Doron\"},{\"authorId\":\"51042571\",\"name\":\"Albin Cassirer\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"title\":\"Transformation-based Adversarial Video Prediction on Large-Scale Data\",\"url\":\"https://www.semanticscholar.org/paper/e93e16a1a9f060841956ae2eca735f5cce457c8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.02190\",\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1109/TPAMI.2020.2992889\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"title\":\"Rolling-Unrolling LSTMs for Action Anticipation from First-Person Video\",\"url\":\"https://www.semanticscholar.org/paper/07cf6c4c1714a0cd88e5c1566aac9df40e111db7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145424954\",\"name\":\"L. Feng\"},{\"authorId\":\"2019709202\",\"name\":\"Qing Yuan\"},{\"authorId\":\"47908890\",\"name\":\"Y. Liu\"},{\"authorId\":\"1500555736\",\"name\":\"Qianxin Huang\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"},{\"authorId\":\"1527101232\",\"name\":\"Yingping Li\"}],\"doi\":\"10.1007/978-3-030-63823-8_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"567b50b98c55e0b4dea2e257e25971368eefa507\",\"title\":\"A Discriminative STGCN for Skeleton Oriented Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/567b50b98c55e0b4dea2e257e25971368eefa507\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1904.05979\",\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/ICCV.2019.00182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c880de441a41c351955ad0bf8f712eeee500ac67\",\"title\":\"The Sound of Motions\",\"url\":\"https://www.semanticscholar.org/paper/c880de441a41c351955ad0bf8f712eeee500ac67\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mohammad Elham Walizad\"},{\"authorId\":null,\"name\":\"Mehreen Hurroo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ecc9d2073755a1364433d83df2a4007e42b16e1\",\"title\":\"Sign Language Recognition System using Convolutional Neural Network and Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/5ecc9d2073755a1364433d83df2a4007e42b16e1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.06882\",\"authors\":[{\"authorId\":\"5954374\",\"name\":\"S. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"2800227\",\"name\":\"Jongyoul Park\"},{\"authorId\":\"46174575\",\"name\":\"J. Choi\"}],\"doi\":\"10.1109/WACV.2019.00014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0426e75aca4177af6396561cfaf945fb22194ef2\",\"title\":\"Skeleton-Based Action Recognition of People Handling Objects\",\"url\":\"https://www.semanticscholar.org/paper/0426e75aca4177af6396561cfaf945fb22194ef2\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1912.06992\",\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/cvpr42600.2020.01025\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"title\":\"Action Genome: Actions As Compositions of Spatio-Temporal Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/d1242ba8fdb994b82a0575dc92f30f7b26a75707\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"82957042\",\"name\":\"K. Abe\"},{\"authorId\":\"40984574\",\"name\":\"Chikara Nakamura\"},{\"authorId\":\"3177909\",\"name\":\"Yosuke Otsubo\"},{\"authorId\":\"31432119\",\"name\":\"T. Koike\"},{\"authorId\":\"6611386\",\"name\":\"N. Yokoya\"}],\"doi\":\"10.1145/3347318.3355521\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74f4225b1303d4c491f76556787a5250d9ed2710\",\"title\":\"Spectator Excitement Detection in Small-scale Sports Events\",\"url\":\"https://www.semanticscholar.org/paper/74f4225b1303d4c491f76556787a5250d9ed2710\",\"venue\":\"MMSports '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403026588\",\"name\":\"Pau Climent-P\\u00e9rez\"},{\"authorId\":\"1699905\",\"name\":\"S. Spinsante\"},{\"authorId\":\"2338883\",\"name\":\"A. Mihailidis\"},{\"authorId\":\"1404190954\",\"name\":\"Francisco Fl\\u00f3rez-Revuelta\"}],\"doi\":\"10.1016/J.ESWA.2019.112847\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"title\":\"A review on video-based active and assisted living technologies for automated lifelogging\",\"url\":\"https://www.semanticscholar.org/paper/516b9b041471a878fcf6baff4b53e3bab8124a8c\",\"venue\":\"Expert Syst. Appl.\",\"year\":2020},{\"arxivId\":\"1904.11492\",\"authors\":[{\"authorId\":\"1696087\",\"name\":\"Yue Cao\"},{\"authorId\":\"7169566\",\"name\":\"J. Xu\"},{\"authorId\":\"145676588\",\"name\":\"Stephen Lin\"},{\"authorId\":\"2480483\",\"name\":\"Fangyun Wei\"},{\"authorId\":\"1805197\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ICCVW.2019.00246\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66143960c0325c70329a3869cc8052f0416b87aa\",\"title\":\"GCNet: Non-Local Networks Meet Squeeze-Excitation Networks and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/66143960c0325c70329a3869cc8052f0416b87aa\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1810.01455\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2019.01018\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"title\":\"Representation Flow for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46365948\",\"name\":\"J. Wu\"},{\"authorId\":\"145951569\",\"name\":\"Wu Luo\"},{\"authorId\":\"120639867\",\"name\":\"Weiwei Liu\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054282\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f20c25ef69171a64549b5aa9b0dc62e98878ff0\",\"title\":\"Global and Local Discriminative Patches Exploiting for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2f20c25ef69171a64549b5aa9b0dc62e98878ff0\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1904.12993\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"title\":\"A Study on Action Detection in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/55f70b16f087ec9b11168c67f3f3ff4e61baa0e5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145977513\",\"name\":\"J. P. Howard\"},{\"authorId\":\"6426766\",\"name\":\"J. Tan\"},{\"authorId\":\"1398240397\",\"name\":\"Matthew J Shun-Shin\"},{\"authorId\":\"1492187763\",\"name\":\"Dina Mahdi\"},{\"authorId\":\"3537255\",\"name\":\"Alexandra N. Nowbar\"},{\"authorId\":\"8806860\",\"name\":\"A. Arnold\"},{\"authorId\":\"1380362507\",\"name\":\"Y. Ahmad\"},{\"authorId\":\"144062805\",\"name\":\"P. McCartney\"},{\"authorId\":\"2070333\",\"name\":\"M. Zolgharni\"},{\"authorId\":\"48615354\",\"name\":\"Nick W F Linton\"},{\"authorId\":\"1944624\",\"name\":\"N. Sutaria\"},{\"authorId\":\"2577168\",\"name\":\"B. Rana\"},{\"authorId\":\"3050053\",\"name\":\"J. Mayet\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"48633106\",\"name\":\"G. Cole\"},{\"authorId\":\"73404927\",\"name\":\"D. Francis\"}],\"doi\":\"10.21037/jmai.2019.10.03\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"82b36e6baa75c700224eb39e9ac838d9adc5d27f\",\"title\":\"Improving ultrasound video classification: an evaluation of novel deep learning methods in echocardiography.\",\"url\":\"https://www.semanticscholar.org/paper/82b36e6baa75c700224eb39e9ac838d9adc5d27f\",\"venue\":\"Journal of medical artificial intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":\"10.1007/978-3-030-42128-1_8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"title\":\"Unsupervised Learning Towards the Future\",\"url\":\"https://www.semanticscholar.org/paper/1431aa3159e932c96265c73f9bf8fbc2fa321926\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145795309\",\"name\":\"K. Shi\"},{\"authorId\":\"145472490\",\"name\":\"Weiqiang Wang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICME.2018.8486530\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"182b627d73de02764498c500aa7fb56cbeb1a424\",\"title\":\"Entity Competition Network for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/182b627d73de02764498c500aa7fb56cbeb1a424\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144486077\",\"name\":\"Xiaoming Peng\"},{\"authorId\":\"51301456\",\"name\":\"A. Bouzerdoum\"}],\"doi\":\"10.1109/DICTA47822.2019.8946036\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fdd19b69b2ddbb770259d8da0223d4edb262f0fe\",\"title\":\"Part-Based Feature Aggregation Method for Dynamic Scene Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fdd19b69b2ddbb770259d8da0223d4edb262f0fe\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"1805.06875\",\"authors\":[{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2018.00771\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80184c6a88fc97a09393b7336bc2ddb12e9b1030\",\"title\":\"NeuralNetwork-Viterbi: A Framework for Weakly Supervised Video Learning\",\"url\":\"https://www.semanticscholar.org/paper/80184c6a88fc97a09393b7336bc2ddb12e9b1030\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9455273\",\"name\":\"Tjeng Wawan Cenggoro\"},{\"authorId\":\"18149042\",\"name\":\"F. Tanzil\"},{\"authorId\":\"30500965\",\"name\":\"Ayu Hidayah Aslamiah\"},{\"authorId\":\"32793694\",\"name\":\"E. K. Karuppiah\"},{\"authorId\":\"2948465\",\"name\":\"Bens Pardamean\"}],\"doi\":\"10.1088/1755-1315/195/1/012063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dfbae80d5206e975baf276101e31d4188e516e77\",\"title\":\"Crowdsourcing annotation system of object counting dataset for deep learning algorithm\",\"url\":\"https://www.semanticscholar.org/paper/dfbae80d5206e975baf276101e31d4188e516e77\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2008.11887\",\"authors\":[{\"authorId\":\"34148354\",\"name\":\"M. Zaheer\"},{\"authorId\":\"38243491\",\"name\":\"A. Mahmood\"},{\"authorId\":\"152557420\",\"name\":\"H. Shin\"},{\"authorId\":\"3193599\",\"name\":\"Seungik Lee\"}],\"doi\":\"10.1109/LSP.2020.3025688\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bdc82fbdbc060ba28930a62aaf174ac14ea71ff\",\"title\":\"A Self-Reasoning Framework for Anomaly Detection Using Video-Level Labels\",\"url\":\"https://www.semanticscholar.org/paper/2bdc82fbdbc060ba28930a62aaf174ac14ea71ff\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12068550\",\"name\":\"Sarah Ibrahimi\"},{\"authorId\":\"116881008\",\"name\":\"Shuo Chen\"},{\"authorId\":\"2854930\",\"name\":\"Devanshu Arya\"},{\"authorId\":\"133572799\",\"name\":\"Arthur C\\u00e2mara\"},{\"authorId\":\"3086701\",\"name\":\"Yunlu Chen\"},{\"authorId\":\"1380203372\",\"name\":\"Tanja Crijns\"},{\"authorId\":\"1388240535\",\"name\":\"Maurits van der Goes\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"},{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"1714964\",\"name\":\"Daan Odijk\"},{\"authorId\":\"143998473\",\"name\":\"William E. Thong\"},{\"authorId\":\"4712803\",\"name\":\"Jiaojiao Zhao\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"}],\"doi\":\"10.1145/3343031.3350597\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"998acc77d5be4325f875b9089f19a61039386c5f\",\"title\":\"Interactive Exploration of Journalistic Video Footage through Multimodal Semantic Matching\",\"url\":\"https://www.semanticscholar.org/paper/998acc77d5be4325f875b9089f19a61039386c5f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410755536\",\"name\":\"David Ivorra-Piqueres\"},{\"authorId\":\"1410269918\",\"name\":\"John Alejandro Castro-Vargas\"},{\"authorId\":\"1410236705\",\"name\":\"P. Martinez-Gonzalez\"}],\"doi\":\"10.4018/IJCVIP.2019040102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2736ba902aaaf02cddcbb95db7117358786227c6\",\"title\":\"Accelerating Deep Action Recognition Networks for Real-Time Applications\",\"url\":\"https://www.semanticscholar.org/paper/2736ba902aaaf02cddcbb95db7117358786227c6\",\"venue\":\"Int. J. Comput. Vis. Image Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413858223\",\"name\":\"M. Al-habib\"},{\"authorId\":\"2258587\",\"name\":\"D. Huang\"},{\"authorId\":\"1411261544\",\"name\":\"Majjed Al-Qatf\"},{\"authorId\":\"1388813797\",\"name\":\"Kamal Al-Sabahi\"}],\"doi\":\"10.1145/3316615.3316722\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aef7731abe7a17f05bbfa1a3185e98c0aee8490d\",\"title\":\"Cooperative Hierarchical Framework for Group Activity Recognition: From Group Detection to Multi-activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aef7731abe7a17f05bbfa1a3185e98c0aee8490d\",\"venue\":\"ICSCA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":null,\"name\":\"Chen Zhao\"},{\"authorId\":\"4042496\",\"name\":\"M. Ramazanova\"},{\"authorId\":\"144723836\",\"name\":\"D. Rojas\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"41076692\",\"name\":\"King Abdullah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d8c7303d3961bef10584df2839290686e63e05d\",\"title\":\"Improve Baseline for Temporal Action Detection: HACS Challenge 2020 Solution of IVUL-KAUST team\",\"url\":\"https://www.semanticscholar.org/paper/0d8c7303d3961bef10584df2839290686e63e05d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2802283\",\"name\":\"H. Liu\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"},{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"2705961\",\"name\":\"R. Ding\"}],\"doi\":\"10.1109/ICIP40778.2020.9190958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"title\":\"Grouped Temporal Enhancement Module for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/93011a4d810eacfc4ff3202d3c38e78706ff3341\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2006.07896\",\"authors\":[{\"authorId\":\"40607664\",\"name\":\"Yuqing Song\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c9c256c33ed4db6b83321c516025b1feb62ddfb\",\"title\":\"Team RUC_AIM3 Technical Report at Activitynet 2020 Task 2: Exploring Sequential Events Detection for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9c256c33ed4db6b83321c516025b1feb62ddfb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"2262209\",\"name\":\"S. Woo\"},{\"authorId\":\"1576788264\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":\"10.1109/TPAMI.2019.2958083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"title\":\"Recurrent Temporal Aggregation Framework for Deep Video Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/ab6d2e28f51012b1968b8b460624178d1cf47a5f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30770253\",\"name\":\"S. Zebhi\"},{\"authorId\":\"3087845\",\"name\":\"S. Almodarresi\"},{\"authorId\":\"1728849\",\"name\":\"V. Abootalebi\"}],\"doi\":\"10.1109/ICEE50131.2020.9261038\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"850b908ac1def4d68f87aaf35bee1e28b25e2ed9\",\"title\":\"Action Recognition in Videos Using Global Descriptors and Pre-trained Deep Learning Architecture\",\"url\":\"https://www.semanticscholar.org/paper/850b908ac1def4d68f87aaf35bee1e28b25e2ed9\",\"venue\":\"2020 28th Iranian Conference on Electrical Engineering (ICEE)\",\"year\":2020},{\"arxivId\":\"2006.11557\",\"authors\":[{\"authorId\":\"145872624\",\"name\":\"Yao Rong\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1884159\",\"name\":\"Enkelejda Kasneci\"}],\"doi\":\"10.1109/ITSC45102.2020.9294181\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"318c74a024b39897b927e462a0ff15c8d2f97415\",\"title\":\"Driver Intention Anticipation Based on In-Cabin and Driving Scene Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/318c74a024b39897b927e462a0ff15c8d2f97415\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144350339\",\"name\":\"Chirag I. Patel\"},{\"authorId\":\"2042647646\",\"name\":\"Dileep Labana\"},{\"authorId\":\"47706103\",\"name\":\"S. Pandya\"},{\"authorId\":\"3438822\",\"name\":\"Kirit Modi\"},{\"authorId\":\"3424424\",\"name\":\"H. Ghayvat\"},{\"authorId\":\"1622021877\",\"name\":\"Muhammad Awais\"}],\"doi\":\"10.3390/s20247299\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"title\":\"Histogram of Oriented Gradient-Based Fusion of Features for Human Action Recognition in Action Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/3fa0ad0a0e3779516e5a9cb74fc40b872448b232\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38796462\",\"name\":\"Imen Jegham\"},{\"authorId\":\"1741571899\",\"name\":\"Anouar Khalifa\"},{\"authorId\":\"2880991\",\"name\":\"Ihsen Alouani\"},{\"authorId\":\"1707715\",\"name\":\"M. Mahjoub\"}],\"doi\":\"10.1109/JSEN.2020.3019258\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9a0b15d54ac277321736886312ddbc4607be032\",\"title\":\"Soft Spatial Attention-Based Multimodal Driver Action Recognition Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/d9a0b15d54ac277321736886312ddbc4607be032\",\"venue\":\"IEEE Sensors Journal\",\"year\":2021},{\"arxivId\":\"2008.09037\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"2331418\",\"name\":\"S. Samsi\"},{\"authorId\":\"3302251\",\"name\":\"W. Arcand\"},{\"authorId\":\"2159806\",\"name\":\"David Bestor\"},{\"authorId\":\"34001612\",\"name\":\"Bill Bergeron\"},{\"authorId\":\"2098646\",\"name\":\"C. Byun\"},{\"authorId\":\"1850501832\",\"name\":\"Micheal Houle\"},{\"authorId\":\"145238688\",\"name\":\"M. Hubbell\"},{\"authorId\":\"145319478\",\"name\":\"Michael J. Jones\"},{\"authorId\":\"3257323\",\"name\":\"J. Kepner\"},{\"authorId\":\"1983355\",\"name\":\"A. Kirby\"},{\"authorId\":\"1684116\",\"name\":\"P. Michaleas\"},{\"authorId\":\"3385550\",\"name\":\"Lauren Milechin\"},{\"authorId\":\"143913450\",\"name\":\"J. Mullen\"},{\"authorId\":\"2417672\",\"name\":\"A. Prout\"},{\"authorId\":\"144557576\",\"name\":\"A. Rosa\"},{\"authorId\":\"2097629\",\"name\":\"Albert Reuther\"},{\"authorId\":\"145378881\",\"name\":\"C. Yee\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":\"10.1109/HPEC43674.2020.9286249\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"title\":\"Accuracy and Performance Comparison of Video Action Recognition Approaches\",\"url\":\"https://www.semanticscholar.org/paper/b3aef63e62e673e852048a24bea1040d3f8b23c1\",\"venue\":\"2020 IEEE High Performance Extreme Computing Conference (HPEC)\",\"year\":2020},{\"arxivId\":\"2011.13399\",\"authors\":[{\"authorId\":\"151136071\",\"name\":\"Mattia Segu\"},{\"authorId\":\"1781788981\",\"name\":\"Federico Pirovano\"},{\"authorId\":\"2029237675\",\"name\":\"Gianmario Fumagalli\"},{\"authorId\":\"1557389943\",\"name\":\"Amedeo Fabris\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"title\":\"Depth-Aware Action Recognition: Pose-Motion Encoding through Temporal Heatmaps\",\"url\":\"https://www.semanticscholar.org/paper/ff46dc2fe07d291e4a829b49b450df29f788efc2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06705\",\"authors\":[{\"authorId\":\"152387853\",\"name\":\"P. Henderson\"},{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"551e78ba5365dbd3a3639990dfc4ea31bbe60c62\",\"title\":\"Unsupervised object-centric video generation and decomposition in 3D\",\"url\":\"https://www.semanticscholar.org/paper/551e78ba5365dbd3a3639990dfc4ea31bbe60c62\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1908.09995\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2020.2985219\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"title\":\"Temporal Reasoning Graph for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1910.11515\",\"authors\":[{\"authorId\":\"35649732\",\"name\":\"Xuesong Niu\"},{\"authorId\":\"144481158\",\"name\":\"S. Shan\"},{\"authorId\":\"1405915001\",\"name\":\"Hu Han\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1109/TIP.2019.2947204\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ce235f0235d00a9c9d9c29dbcef8aeb63f9ec50\",\"title\":\"RhythmNet: End-to-End Heart Rate Estimation From Face via Spatial-Temporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/6ce235f0235d00a9c9d9c29dbcef8aeb63f9ec50\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2004.04981\",\"authors\":[{\"authorId\":\"1491233177\",\"name\":\"Yizhou Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"2820418\",\"name\":\"Chong Luo\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/cvpr42600.2020.00985\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"title\":\"Spatiotemporal Fusion in 3D CNNs: A Probabilistic View\",\"url\":\"https://www.semanticscholar.org/paper/e7ca185e3a4515471c2b9a411da9f264d55ea563\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3923889\",\"name\":\"J. J. V. van Assen\"},{\"authorId\":\"49813322\",\"name\":\"S. Nishida\"},{\"authorId\":\"2436224\",\"name\":\"R. Fleming\"}],\"doi\":\"10.1371/journal.pcbi.1008018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de32c428a44aa2bc99de0421b113a20282549bc0\",\"title\":\"Visual perception of liquids: Insights from deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/de32c428a44aa2bc99de0421b113a20282549bc0\",\"venue\":\"PLoS computational biology\",\"year\":2020},{\"arxivId\":\"1910.11006\",\"authors\":[{\"authorId\":\"2981509\",\"name\":\"Dongxu Li\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"144349266\",\"name\":\"X. Yu\"},{\"authorId\":\"40124570\",\"name\":\"Hongdong Li\"}],\"doi\":\"10.1109/WACV45572.2020.9093512\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2dda8d1d7400d49e5ad54bc9abfca96170245763\",\"title\":\"Word-level Deep Sign Language Recognition from Video: A New Large-scale Dataset and Methods Comparison\",\"url\":\"https://www.semanticscholar.org/paper/2dda8d1d7400d49e5ad54bc9abfca96170245763\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2512283\",\"name\":\"Shahin Amiriparian\"},{\"authorId\":\"1409869991\",\"name\":\"Maximilian Schmitt\"},{\"authorId\":\"31696419\",\"name\":\"Sandra Ottl\"},{\"authorId\":\"31766982\",\"name\":\"Maurice Gerczuk\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"}],\"doi\":\"10.1007/978-3-030-42750-4_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35d0766ea4d9760ef9ce900d4f7db5905171658e\",\"title\":\"Deep Unsupervised Representation Learning for Audio-Based Medical Applications\",\"url\":\"https://www.semanticscholar.org/paper/35d0766ea4d9760ef9ce900d4f7db5905171658e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICPR.2018.8546325\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d45f7abeca184533ee0f0670c4946bcd34edda81\",\"title\":\"Towards Good Practice for Action Recognition with Spatiotemporal 3D Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/d45f7abeca184533ee0f0670c4946bcd34edda81\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145341912\",\"name\":\"Kai Zhao\"},{\"authorId\":\"1934935684\",\"name\":\"Kejun Zhang\"},{\"authorId\":\"97520673\",\"name\":\"Y. Zhai\"},{\"authorId\":\"1934259534\",\"name\":\"D. Wang\"},{\"authorId\":\"2594917\",\"name\":\"Jianbo Su\"}],\"doi\":\"10.23919/CCC50068.2020.9188508\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04c557242b3c21aa38143495a1ee072feb935127\",\"title\":\"Real-Time Sign Language Recognition Based on Video Stream\",\"url\":\"https://www.semanticscholar.org/paper/04c557242b3c21aa38143495a1ee072feb935127\",\"venue\":\"2020 39th Chinese Control Conference (CCC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993592720\",\"name\":\"Zhaobo Qi\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"145422145\",\"name\":\"Chi Su\"},{\"authorId\":\"153142919\",\"name\":\"Li Su\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3413954\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"title\":\"Towards More Explainability: Concept Knowledge Mining Network for Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1d71c6ecb0d7ca618665e6402e84c2f5d39b761f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145470590\",\"name\":\"W. Lin\"},{\"authorId\":\"1517108051\",\"name\":\"Jie Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d0a1bdf67767b420fccb1d1847bfa6b65d11f5d\",\"title\":\"Beyond 2D: Fusion of Monocular 3D Pose, Motion and Appearance for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8d0a1bdf67767b420fccb1d1847bfa6b65d11f5d\",\"venue\":\"2019 22th International Conference on Information Fusion (FUSION)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70026472\",\"name\":\"T. Yu\"},{\"authorId\":\"6470580\",\"name\":\"Y. Yang\"},{\"authorId\":\"47002715\",\"name\":\"Y. Li\"},{\"authorId\":\"49794949\",\"name\":\"Xiaodong Chen\"},{\"authorId\":\"1893044063\",\"name\":\"Mingming Sun\"},{\"authorId\":\"144785135\",\"name\":\"P. Li\"}],\"doi\":\"10.1145/3394486.3403297\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a1d603b0860ca5a27a2813be1e0a0d1277fa44a\",\"title\":\"Combo-Attention Network for Baidu Video Advertising\",\"url\":\"https://www.semanticscholar.org/paper/8a1d603b0860ca5a27a2813be1e0a0d1277fa44a\",\"venue\":\"KDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"3432527\",\"name\":\"Jiepeng Cen\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"}],\"doi\":\"10.1109/ICPR.2018.8545720\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"title\":\"Temporal Inception Architecture for Action Recognition with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e39db6a72f533b5adb2ecd9feaadbbab8204e024\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d572e5851306d7d420a619469c8f449943f5880\",\"title\":\"Modeling Long-Term Interactions to Enhance Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d572e5851306d7d420a619469c8f449943f5880\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"107698641\",\"name\":\"Abdullah M. Algamdi\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"8025372\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/ICIP40778.2020.9190864\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3e33bb6fabf41bbb1de0a80f406aed64c8781b27\",\"title\":\"Dronecaps: Recognition Of Human Actions In Drone Videos Using Capsule Networks With Binary Volume Comparisons\",\"url\":\"https://www.semanticscholar.org/paper/3e33bb6fabf41bbb1de0a80f406aed64c8781b27\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"LU Hao\"},{\"authorId\":null,\"name\":\"Hu HAN\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1c1f3594f4bf4b4879ba24f3337f27c5e20f744\",\"title\":\"NAS-HR: search of neural architecture for heart-rate estimation from face videos\",\"url\":\"https://www.semanticscholar.org/paper/d1c1f3594f4bf4b4879ba24f3337f27c5e20f744\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.11206\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"8786274\",\"name\":\"Boyuan Chen\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":\"10.1109/cvpr42600.2020.00100\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"title\":\"Oops! Predicting Unintentional Action in Video\",\"url\":\"https://www.semanticscholar.org/paper/2324d55ec54b9a12c4ac5353c51bcfa8440f7b6a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92709220\",\"name\":\"Yao-Sen Chen\"},{\"authorId\":\"1455126232\",\"name\":\"Bing Guo\"},{\"authorId\":\"143736944\",\"name\":\"Yan Shen\"},{\"authorId\":\"115438571\",\"name\":\"W. Wang\"},{\"authorId\":\"1836290988\",\"name\":\"Xinhua Suo\"},{\"authorId\":\"1409738616\",\"name\":\"Zhang Zhen\"}],\"doi\":\"10.1007/s11760-020-01758-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"title\":\"Using efficient group pseudo-3D network to learn spatio-temporal features\",\"url\":\"https://www.semanticscholar.org/paper/0e47005fae57dfc1e4e3f3abcbd61a8d2cc9aead\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.09890\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8e6fd410f1d327580f704de83f5c8e073a711c93\",\"title\":\"Supervision Levels Scale (SLS)\",\"url\":\"https://www.semanticscholar.org/paper/8e6fd410f1d327580f704de83f5c8e073a711c93\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10321\",\"authors\":[{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"2391885\",\"name\":\"Sifei Liu\"},{\"authorId\":\"3232265\",\"name\":\"Deqing Sun\"},{\"authorId\":\"152296574\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"title\":\"Hierarchical Contrastive Motion Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1cedd24562c1e95415b246a1a0e9912d8de6f0f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08236\",\"authors\":[{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"46266065\",\"name\":\"Y. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fb932412e570f507f783e2ef633ea64677bd268e\",\"title\":\"Point-Level Temporal Action Localization: Bridging Fully-supervised Proposals to Weakly-supervised Losses\",\"url\":\"https://www.semanticscholar.org/paper/fb932412e570f507f783e2ef633ea64677bd268e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2021517807\",\"name\":\"Sagar R. Tharali\"},{\"authorId\":\"2021543895\",\"name\":\"Gaurav S. Wakchaure\"},{\"authorId\":\"2021549832\",\"name\":\"Durvesh S. Shirsat\"},{\"authorId\":\"9451996\",\"name\":\"Navin G. Singhaniya\"}],\"doi\":\"10.1051/itmconf/20203203014\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f5b9fdc68854cdf2203516be2a44463b61934c2\",\"title\":\"Violence Detection using Embedded GPU\",\"url\":\"https://www.semanticscholar.org/paper/9f5b9fdc68854cdf2203516be2a44463b61934c2\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"46354059\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"7650248\",\"name\":\"C. Yin\"}],\"doi\":\"10.1016/j.cviu.2019.102821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fedf56f95e5e80464254573ce2d9648606899ccb\",\"title\":\"Residual attention unit for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fedf56f95e5e80464254573ce2d9648606899ccb\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1912.07249\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"title\":\"Mimetics: Towards Understanding Human Actions Out of Context\",\"url\":\"https://www.semanticscholar.org/paper/8dce5b1cc382f4a341f7ea43c6329c9e8acd202d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.09568\",\"authors\":[{\"authorId\":\"38173241\",\"name\":\"Yu Luo\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"2164408\",\"name\":\"R. Adams\"},{\"authorId\":\"46275685\",\"name\":\"J. Li\"},{\"authorId\":\"46298867\",\"name\":\"M. Newman\"},{\"authorId\":\"1699550\",\"name\":\"J. Z. Wang\"}],\"doi\":\"10.1007/s11263-019-01215-y\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"61482c061e0d12d94c8d66a259bd2cac76d65d49\",\"title\":\"ARBEE: Towards Automated Recognition of Bodily Expression of Emotion in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/61482c061e0d12d94c8d66a259bd2cac76d65d49\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1904.09288\",\"authors\":[{\"authorId\":\"3042242\",\"name\":\"X. Yang\"},{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"145879186\",\"name\":\"L. Davis\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1109/CVPR.2019.00035\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"title\":\"STEP: Spatio-Temporal Progressive Learning for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c2cc82c2948c0513628a61d4ff829110750fdf9a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2008.06997\",\"authors\":[{\"authorId\":\"24038404\",\"name\":\"Hanqing Chao\"},{\"authorId\":\"3449207\",\"name\":\"Hongming Shan\"},{\"authorId\":\"1491221186\",\"name\":\"Fatemeh Homayounieh\"},{\"authorId\":\"1730999120\",\"name\":\"Ramandeep Singh\"},{\"authorId\":\"79727242\",\"name\":\"Ruhani Doda Khera\"},{\"authorId\":\"14111482\",\"name\":\"Hengtao Guo\"},{\"authorId\":\"10314894\",\"name\":\"Timothy A Su\"},{\"authorId\":\"1850522016\",\"name\":\"Ge Wang\"},{\"authorId\":\"1764113\",\"name\":\"M. Kalra\"},{\"authorId\":\"144855557\",\"name\":\"Pingkun Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"59949218fd00eb7b05c1aceaed6407cc28586590\",\"title\":\"Deep Learning Predicts Cardiovascular Disease Risks from Lung Cancer Screening Low Dose Computed Tomography\",\"url\":\"https://www.semanticscholar.org/paper/59949218fd00eb7b05c1aceaed6407cc28586590\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.13362\",\"authors\":[{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"2267140\",\"name\":\"Jorge A. Balazs\"},{\"authorId\":\"49384810\",\"name\":\"S. Gould\"},{\"authorId\":\"49484314\",\"name\":\"Y. Matsuo\"}],\"doi\":\"10.18653/v1/2020.challengehml-1.2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1b020611eb4534be4d336dfec1dcda77dbfafa1\",\"title\":\"A Multi-modal Approach to Fine-grained Opinion Mining on Video Reviews\",\"url\":\"https://www.semanticscholar.org/paper/e1b020611eb4534be4d336dfec1dcda77dbfafa1\",\"venue\":\"CHALLENGEHML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"17425422\",\"name\":\"D. Riquelme\"},{\"authorId\":\"2629166\",\"name\":\"M. Akhloufi\"}],\"doi\":\"10.3390/ai1010003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeed12420fb2b79e6d610c8fd99fc67f3a7def44\",\"title\":\"Deep Learning for Lung Cancer Nodules Detection and Classification in CT Scans\",\"url\":\"https://www.semanticscholar.org/paper/aeed12420fb2b79e6d610c8fd99fc67f3a7def44\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.03460\",\"authors\":[{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"48030192\",\"name\":\"Xudong Lin\"},{\"authorId\":\"70351911\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1109/CVPR.2019.00136\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"title\":\"DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1910.02027\",\"authors\":[{\"authorId\":\"49170402\",\"name\":\"Yunji Kim\"},{\"authorId\":\"7532506\",\"name\":\"Seonghyeon Nam\"},{\"authorId\":\"4078629\",\"name\":\"I. Cho\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"882fc8a75baf03a01dd18385f50728bada85ed6a\",\"title\":\"Unsupervised Keypoint Learning for Guiding Class-Conditional Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/882fc8a75baf03a01dd18385f50728bada85ed6a\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151478835\",\"name\":\"Chen Xiao-kai\"},{\"authorId\":\"151485756\",\"name\":\"Gao Ke\"},{\"authorId\":\"145515934\",\"name\":\"C. Juan\"}],\"doi\":\"10.1109/ICME.2019.00169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9fb80b6dc6b636478915382f8de2fb43ee5900d\",\"title\":\"Predictability Analyzing: Deep Reinforcement Learning for Early Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c9fb80b6dc6b636478915382f8de2fb43ee5900d\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"34490455\",\"name\":\"Elad Levi\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"153585940\",\"name\":\"Hang Gao\"},{\"authorId\":\"2041489\",\"name\":\"E. Brosh\"},{\"authorId\":\"17279245\",\"name\":\"X. Wang\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCVW.2019.00288\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3be602c7c3812397a29c64e544981a362de80f27\",\"title\":\"Spatio-Temporal Action Graph Networks\",\"url\":\"https://www.semanticscholar.org/paper/3be602c7c3812397a29c64e544981a362de80f27\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1811.09795\",\"authors\":[{\"authorId\":\"24028009\",\"name\":\"Dahun Kim\"},{\"authorId\":\"3160154\",\"name\":\"Donghyeon Cho\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1609/aaai.v33i01.33018545\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b3dbd24407f6e58f6b7bc461fd21782062f0f361\",\"title\":\"Self-Supervised Video Representation Learning with Space-Time Cubic Puzzles\",\"url\":\"https://www.semanticscholar.org/paper/b3dbd24407f6e58f6b7bc461fd21782062f0f361\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1805.06374\",\"authors\":[{\"authorId\":\"8133623\",\"name\":\"Wanjia Liu\"},{\"authorId\":\"31385532\",\"name\":\"Huaijin Chen\"},{\"authorId\":\"46186660\",\"name\":\"R. Goel\"},{\"authorId\":\"35633657\",\"name\":\"Yuzhong Huang\"},{\"authorId\":\"145280967\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"46463998\",\"name\":\"Ankit B. Patel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0c37f07710184597befaa7e6cf2f0893ff440e9\",\"title\":\"Fast Retinomorphic Event Stream for Video Recognition and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/a0c37f07710184597befaa7e6cf2f0893ff440e9\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"98024338\",\"name\":\"M. Souza\"},{\"authorId\":\"46602675\",\"name\":\"A. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"144042009\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1109/ICMLA.2019.00290\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f35057fb1c653c10fd2256f7df454991698971\",\"title\":\"Learnable Visual Rhythms Based on the Stacking of Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/45f35057fb1c653c10fd2256f7df454991698971\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46595245\",\"name\":\"Wenhui Xiao\"},{\"authorId\":\"1643688444\",\"name\":\"Huiguo He\"},{\"authorId\":\"152988058\",\"name\":\"Tingting Wang\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"}],\"doi\":\"10.1109/TMM.2020.2978664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ac6d07997ba14a8bfcfa6989b621c1bfbd2c2ff\",\"title\":\"The Interpretable Fast Multi-Scale Deep Decoder for the Standard HEVC Bitstreams\",\"url\":\"https://www.semanticscholar.org/paper/8ac6d07997ba14a8bfcfa6989b621c1bfbd2c2ff\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2011.01414\",\"authors\":[{\"authorId\":\"144622638\",\"name\":\"L. Sun\"},{\"authorId\":\"3162562\",\"name\":\"Haoqi Zhang\"},{\"authorId\":\"1734973476\",\"name\":\"Songyang Zhang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fba9581f1a4bbeeefc6ebf846af5263ffa56d789\",\"title\":\"Content-based Analysis of the Cultural Differences between TikTok and Douyin\",\"url\":\"https://www.semanticscholar.org/paper/fba9581f1a4bbeeefc6ebf846af5263ffa56d789\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.04146\",\"authors\":[{\"authorId\":\"46399672\",\"name\":\"Yiheng Liu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"1916469\",\"name\":\"M. Xi\"},{\"authorId\":\"1865995287\",\"name\":\"Sanjing Shen\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3394171.3413984\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f261b047f4b5d182af129a12935a512c0a65385\",\"title\":\"Vision Meets Wireless Positioning: Effective Person Re-identification with Recurrent Context Propagation\",\"url\":\"https://www.semanticscholar.org/paper/7f261b047f4b5d182af129a12935a512c0a65385\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423699581\",\"name\":\"A. F. D. Marsiano\"},{\"authorId\":\"9149246\",\"name\":\"I. Soesanti\"},{\"authorId\":\"2969172\",\"name\":\"Igi Ardiyanto\"}],\"doi\":\"10.1109/ICAICTA.2019.8904395\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"title\":\"Deep learning-based Anomaly Detection on Surveillance Videos: Recent Advances\",\"url\":\"https://www.semanticscholar.org/paper/8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766333\",\"name\":\"D. Wei\"},{\"authorId\":\"35198686\",\"name\":\"Joseph J. Lim\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1109/CVPR.2018.00840\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9baf01eb53abda6a169110477f2c7a3492559368\",\"title\":\"Learning and Using the Arrow of Time\",\"url\":\"https://www.semanticscholar.org/paper/9baf01eb53abda6a169110477f2c7a3492559368\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.05049\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"48310008\",\"name\":\"B. Xu\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":\"10.1109/ICCV.2019.00353\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d9eb72ea89bb7bf5720a7b2c2f3f77c26fc67a6\",\"title\":\"Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks With Octave Convolution\",\"url\":\"https://www.semanticscholar.org/paper/0d9eb72ea89bb7bf5720a7b2c2f3f77c26fc67a6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34394988\",\"name\":\"A. Javer\"},{\"authorId\":\"50713410\",\"name\":\"Andr\\u00e9 E. X. Brown\"},{\"authorId\":\"2010660\",\"name\":\"I. Kokkinos\"},{\"authorId\":\"1695351\",\"name\":\"J. Rittscher\"}],\"doi\":\"10.1007/978-3-030-11024-6_35\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0dd7914be9f35631737a900af7928ba2f34bc41d\",\"title\":\"Identification of C. elegans Strains Using a Fully Convolutional Neural Network on Behavioural Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/0dd7914be9f35631737a900af7928ba2f34bc41d\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1811.08815\",\"authors\":[{\"authorId\":\"2798372\",\"name\":\"Khoi-Nguyen C. Mac\"},{\"authorId\":\"5113463\",\"name\":\"D. Joshi\"},{\"authorId\":\"28919105\",\"name\":\"Raymond A. Yeh\"},{\"authorId\":\"46590281\",\"name\":\"Jinjun Xiong\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1834451\",\"name\":\"M. Do\"}],\"doi\":\"10.1109/ICCV.2019.00638\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"title\":\"Learning Motion in Feature Space: Locally-Consistent Deformable Convolution Networks for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ead2714c83cffe52335ed9bfa95025005c8ffcca\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145036494\",\"name\":\"Alexandre Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"Asim Smailagic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4477b9696f39ebecc4af72c45ab1eb7f88fe49c9\",\"title\":\"AHA-3 D : A Labelled Dataset for Senior Fitness Exercise Recognition and Segmentation from 3 D Skeletal Data\",\"url\":\"https://www.semanticscholar.org/paper/4477b9696f39ebecc4af72c45ab1eb7f88fe49c9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48456191\",\"name\":\"Hirokatsu Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICRA.2019.8793709\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d9ee0ef81eb1f5fa3c9dfebdec16933618d1f80e\",\"title\":\"Unsupervised Out-of-context Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d9ee0ef81eb1f5fa3c9dfebdec16933618d1f80e\",\"venue\":\"2019 International Conference on Robotics and Automation (ICRA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8703832cf993aa86b6c6eb48c1d7f76cbacfcb7a\",\"title\":\"Team Efficient Multi-Moments in Time Challenge 2019 Technical Report\",\"url\":\"https://www.semanticscholar.org/paper/8703832cf993aa86b6c6eb48c1d7f76cbacfcb7a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152538515\",\"name\":\"Le Yang\"},{\"authorId\":\"35981826\",\"name\":\"Itir Onal Ertugrul\"},{\"authorId\":\"1737918\",\"name\":\"J. Cohn\"},{\"authorId\":\"1785007\",\"name\":\"Z. Hammal\"},{\"authorId\":\"48219791\",\"name\":\"Dongmei Jiang\"},{\"authorId\":\"48077408\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1109/ACII.2019.8925514\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5a33540963538cfede57d00f2c49236e57d63b7\",\"title\":\"FACS3D-Net: 3D Convolution based Spatiotemporal Representation for Action Unit Detection\",\"url\":\"https://www.semanticscholar.org/paper/f5a33540963538cfede57d00f2c49236e57d63b7\",\"venue\":\"2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"David A. Ross\"},{\"authorId\":\"145820819\",\"name\":\"Jun Deng\"},{\"authorId\":\"1694199\",\"name\":\"Rahul Sukthankar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"RoI Pooling DNN Classifier Person Bike Background 2 D Feature Map Input ImageMulti-scale Anchor Boxes Region Proposal Network Region Proposals 2 D ConvNet c DNN Classifier Dunk Background SoI Pooling\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39069000\",\"name\":\"Elaina Chai\"},{\"authorId\":\"1698147\",\"name\":\"Boris Murmann\"},{\"authorId\":\"49678996\",\"name\":\"Akiko Yamazaki\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a740423a22e2d9b65c7a194e9c633477502a3a0\",\"title\":\"Edge Computing for Smart Buildings\",\"url\":\"https://www.semanticscholar.org/paper/7a740423a22e2d9b65c7a194e9c633477502a3a0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48599063\",\"name\":\"Ziqi Yang\"},{\"authorId\":\"46810102\",\"name\":\"X. Gong\"},{\"authorId\":\"46791330\",\"name\":\"Ying Guo\"},{\"authorId\":\"49663403\",\"name\":\"Wenbin Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2990683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"title\":\"A Temporal Sequence Dual-Branch Network for Classifying Hybrid Ultrasound Data of Breast Cancer\",\"url\":\"https://www.semanticscholar.org/paper/52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720774729\",\"name\":\"Ilias Papastratis\"},{\"authorId\":\"2296506\",\"name\":\"K. Dimitropoulos\"},{\"authorId\":\"144762638\",\"name\":\"D. Konstantinidis\"},{\"authorId\":\"1747572\",\"name\":\"P. Daras\"}],\"doi\":\"10.1109/ACCESS.2020.2993650\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61ed12ecd9e2c92b539f0576eddb05bd91401a8c\",\"title\":\"Continuous Sign Language Recognition Through Cross-Modal Alignment of Video and Text Embeddings in a Joint-Latent Space\",\"url\":\"https://www.semanticscholar.org/paper/61ed12ecd9e2c92b539f0576eddb05bd91401a8c\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2009.14661\",\"authors\":[{\"authorId\":\"1500399016\",\"name\":\"Tong Yu\"},{\"authorId\":\"2655297\",\"name\":\"Nicolas Padoy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"title\":\"Encode the Unseen: Predictive Video Hashing for Scalable Mid-Stream Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/2c386b73f74c2e7f91217bb65504d8725e17b81e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.09691\",\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00461\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"10cf610ca725cdf459f6a4fa68999066b586b93a\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10cf610ca725cdf459f6a4fa68999066b586b93a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8962288\",\"name\":\"Zichen zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"title\":\"Attention Before and After Feature Extraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/498a1e7c6de343dac40f374c4e812e64c6c7826f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40370451\",\"name\":\"H. Kim\"},{\"authorId\":\"10263579\",\"name\":\"Seokmok Park\"},{\"authorId\":\"1820264163\",\"name\":\"Hyeokjin Park\"},{\"authorId\":\"9238090\",\"name\":\"J. Paik\"}],\"doi\":\"10.3390/s20143894\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d76a567188604c227000de1d8e44fe64a176c654\",\"title\":\"Enhanced Action Recognition Using Multiple Stream Deep Learning with Optical Flow and Weighted Sum\",\"url\":\"https://www.semanticscholar.org/paper/d76a567188604c227000de1d8e44fe64a176c654\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ca2c5474491f0a7117e7ca05fc2bdf49deff4b68\",\"title\":\"Symbiotic Attention: UTS-Baidu Submission to the EPIC-Kitchens 2020 Action Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/ca2c5474491f0a7117e7ca05fc2bdf49deff4b68\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TIP.2019.2922108\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff4f13d4973cfe74f8ac7ef8384548c22284011e\",\"title\":\"Breaking Winner-Takes-All: Iterative-Winners-Out Networks for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/ff4f13d4973cfe74f8ac7ef8384548c22284011e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1909.11786\",\"authors\":[{\"authorId\":\"48172949\",\"name\":\"N. Ahuja\"},{\"authorId\":\"3269525\",\"name\":\"I. Ndiour\"},{\"authorId\":\"1388721949\",\"name\":\"Trushant Kalyanpur\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c948ab13b9ecfa35374913710f849e806297e18\",\"title\":\"Probabilistic Modeling of Deep Features for Out-of-Distribution and Adversarial Detection\",\"url\":\"https://www.semanticscholar.org/paper/2c948ab13b9ecfa35374913710f849e806297e18\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.05743\",\"authors\":[{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"title\":\"Contrastive Bidirectional Transformer for Temporal Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/f259bc7ef31c4ec7dd041c94bfd6b2f93b99b47c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551536\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"title\":\"Enhanced Action Recognition With Visual Attribute-Augmented 3D Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/48994f8671d2a3bdff929eefd6086cb8f2f2c4d0\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48016309\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":\"10.1109/ICCV.2019.00404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"title\":\"Asymmetric Cross-Guided Attention Network for Actor and Action Video Segmentation From Natural Language Query\",\"url\":\"https://www.semanticscholar.org/paper/05fc2ab1eb39f8f4d0f30dda1a2838c8125bff1b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1907.09382\",\"authors\":[{\"authorId\":\"145254119\",\"name\":\"Huseyin Coskun\"},{\"authorId\":\"48151137\",\"name\":\"Z. Zia\"},{\"authorId\":\"39307390\",\"name\":\"Bugra Tekin\"},{\"authorId\":\"2988774\",\"name\":\"Federica Bogo\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"},{\"authorId\":\"1733393\",\"name\":\"H. Sawhney\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"18cb8c24fae3186487b14fdb28b1b2617057198f\",\"title\":\"Domain-Specific Priors and Meta Learning for Low-shot First-Person Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18cb8c24fae3186487b14fdb28b1b2617057198f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.11454\",\"authors\":[{\"authorId\":\"40917135\",\"name\":\"Isabel Funke\"},{\"authorId\":\"2462340\",\"name\":\"S. Bodenstedt\"},{\"authorId\":\"116869232\",\"name\":\"F. Oehme\"},{\"authorId\":\"150996210\",\"name\":\"F. Bechtolsheim\"},{\"authorId\":\"143997715\",\"name\":\"J. Weitz\"},{\"authorId\":\"47515221\",\"name\":\"S. Speidel\"}],\"doi\":\"10.1007/978-3-030-32254-0_52\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4b7fe991a163b6fa3b0e09452466e1434633ed97\",\"title\":\"Using 3D Convolutional Neural Networks to Learn Spatiotemporal Features for Automatic Surgical Gesture Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/4b7fe991a163b6fa3b0e09452466e1434633ed97\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089882\",\"name\":\"Haiyang Jiang\"},{\"authorId\":\"7303419\",\"name\":\"Yaozong Pan\"},{\"authorId\":\"101594813\",\"name\":\"J. Zhang\"},{\"authorId\":\"145664195\",\"name\":\"H. Yang\"}],\"doi\":\"10.3390/SYM11060761\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"title\":\"Battlefield Target Aggregation Behavior Recognition Model Based on Multi-Scale Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/66a8b5f9d2578fc2b533bf93d1e4df14cd993643\",\"venue\":\"Symmetry\",\"year\":2019},{\"arxivId\":\"2007.00843\",\"authors\":[{\"authorId\":\"47061966\",\"name\":\"M. Potter\"},{\"authorId\":\"1785364061\",\"name\":\"Henry Gridley\"},{\"authorId\":\"1785339126\",\"name\":\"Noah Lichtenstein\"},{\"authorId\":\"47128606\",\"name\":\"Kevin Hines\"},{\"authorId\":\"50004462\",\"name\":\"John Nguyen\"},{\"authorId\":\"151494580\",\"name\":\"Jacob Walsh\"}],\"doi\":\"10.1109/MLSP49062.2020.9231894\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"216e819a500c2d5ba2dfc993ddf4c161d72d34bb\",\"title\":\"Low-Light Environment Neural Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/216e819a500c2d5ba2dfc993ddf4c161d72d34bb\",\"venue\":\"2020 IEEE 30th International Workshop on Machine Learning for Signal Processing (MLSP)\",\"year\":2020},{\"arxivId\":\"1905.00742\",\"authors\":[{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"8297919\",\"name\":\"E. V. Dam\"},{\"authorId\":\"144882446\",\"name\":\"L. Noldus\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe9083f8d8a4d3c0a00b2c1caf3bf8a14d5c332e\",\"title\":\"Egocentric Hand Track and Object-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe9083f8d8a4d3c0a00b2c1caf3bf8a14d5c332e\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144839067\",\"name\":\"Amir Mazaheri\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"title\":\"Video Content Understanding Using Text\",\"url\":\"https://www.semanticscholar.org/paper/fa2030f41aa0b54965420eb7836c7c32a91b087b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121569773\",\"name\":\"Yuqian Fu\"},{\"authorId\":\"48586318\",\"name\":\"Chengrong Wang\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":null,\"name\":\"Yu-Xiong Wang\"},{\"authorId\":\"151495118\",\"name\":\"Cong Bai\"},{\"authorId\":\"48002027\",\"name\":\"X. Xue\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d54af916d7b813e798fa27327bfb0a909d816fd7\",\"title\":\"Embodied One-Shot Video Recognition: Learning from Actions of a Virtual Embodied Agent\",\"url\":\"https://www.semanticscholar.org/paper/d54af916d7b813e798fa27327bfb0a909d816fd7\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1705.02953\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"134339866\",\"name\":\"L. V. Van Gool\"}],\"doi\":\"10.1109/TPAMI.2018.2868668\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"title\":\"Temporal Segment Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/37c970a2f27810987e2b47dd5b8e0cc9bb976a38\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":\"1811.12814\",\"authors\":[{\"authorId\":\"1713312\",\"name\":\"Y. Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"3305169\",\"name\":\"Zhicheng Yan\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"}],\"doi\":\"10.1109/CVPR.2019.00052\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6\",\"title\":\"Graph-Based Global Reasoning Networks\",\"url\":\"https://www.semanticscholar.org/paper/1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.00227\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1872964\",\"name\":\"Ali K. Thabet\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"34a07e2867c0be481a3fdd9ea43b608c3dc62a5b\",\"title\":\"RefineLoc: Iterative Refinement for Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/34a07e2867c0be481a3fdd9ea43b608c3dc62a5b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1902.10416\",\"authors\":[{\"authorId\":\"37502184\",\"name\":\"P. Stock\"},{\"authorId\":\"143853801\",\"name\":\"B. Graham\"},{\"authorId\":\"1731535\",\"name\":\"R. Gribonval\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dd29bd8bd4197a97d28614f3c13b18fc6c9e2b5\",\"title\":\"Equi-normalization of Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8dd29bd8bd4197a97d28614f3c13b18fc6c9e2b5\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1807.04409\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"143972875\",\"name\":\"Alan Sullivan\"}],\"doi\":\"10.1109/WACV.2019.00196\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cfe4f0ff9886092f1aa3dbfc32156c622140bde\",\"title\":\"Sem-GAN: Semantically-Consistent Image-to-Image Translation\",\"url\":\"https://www.semanticscholar.org/paper/8cfe4f0ff9886092f1aa3dbfc32156c622140bde\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1910.10056\",\"authors\":[{\"authorId\":\"1750502\",\"name\":\"X. Huang\"},{\"authorId\":\"2846597\",\"name\":\"Hossein Mousavi\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"}],\"doi\":\"10.1109/ICIP40778.2020.9190781\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"title\":\"Predictive Coding Networks Meet Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfe3428bc32b957a6ae799e79d31fab88d3ee9f5\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1910.02793\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"Eric Hofesmann\"},{\"authorId\":\"46184233\",\"name\":\"N. Louis\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"title\":\"ViP: Video Platform for PyTorch\",\"url\":\"https://www.semanticscholar.org/paper/4dfaa337fb4cc3d7f755c258f192edc774f601fc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.04140\",\"authors\":[{\"authorId\":\"1381281389\",\"name\":\"Prashant Pandey\"},{\"authorId\":\"1411010600\",\"name\":\"P. PrathoshA.\"},{\"authorId\":\"49085157\",\"name\":\"Manu Kohli\"},{\"authorId\":\"49017407\",\"name\":\"J. Pritchard\"}],\"doi\":\"10.1609/aaai.v34i01.5383\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfefcb0901b173f0da0d4db3948d749ab9734198\",\"title\":\"Guided weak supervision for action recognition with scarce data to assess skills of children with autism\",\"url\":\"https://www.semanticscholar.org/paper/bfefcb0901b173f0da0d4db3948d749ab9734198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113932966\",\"name\":\"J. C. Morales\"},{\"authorId\":\"1417279721\",\"name\":\"Francisco Carrillo-Perez\"},{\"authorId\":\"1679886560\",\"name\":\"Daniel Castillo-Secilla\"},{\"authorId\":\"143648106\",\"name\":\"I. Rojas\"},{\"authorId\":\"1699431\",\"name\":\"L. Herrera\"}],\"doi\":\"10.1007/978-3-030-45385-5_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3034ab1eb738859a474acd96679d0d9e9f6867e3\",\"title\":\"Enhancing Breast Cancer Classification via Information and Multi-model Integration\",\"url\":\"https://www.semanticscholar.org/paper/3034ab1eb738859a474acd96679d0d9e9f6867e3\",\"venue\":\"IWBBIO\",\"year\":2020},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.12506\",\"authors\":[{\"authorId\":\"32234354\",\"name\":\"Yingda Xia\"},{\"authorId\":\"41028084\",\"name\":\"Fengze Liu\"},{\"authorId\":\"144041880\",\"name\":\"D. Yang\"},{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"2342535\",\"name\":\"Lequan Yu\"},{\"authorId\":\"1834450\",\"name\":\"Zhuotun Zhu\"},{\"authorId\":\"3262394\",\"name\":\"Daguang Xu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"144531567\",\"name\":\"H. Roth\"}],\"doi\":\"10.1109/WACV45572.2020.9093608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7000a609c9aa59c1fd893cdfa6f51cd9cd22354\",\"title\":\"3D Semi-Supervised Learning with Uncertainty-Aware Multi-View Co-Training\",\"url\":\"https://www.semanticscholar.org/paper/d7000a609c9aa59c1fd893cdfa6f51cd9cd22354\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1811.02759\",\"authors\":[{\"authorId\":\"29976076\",\"name\":\"Yuenan Hou\"},{\"authorId\":\"80398011\",\"name\":\"Z. Ma\"},{\"authorId\":\"1680344\",\"name\":\"C. Liu\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1609/aaai.v33i01.33018433\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48f2ae39f46e8dfce15688d598836eb670419205\",\"title\":\"Learning to Steer by Mimicking Features from Heterogeneous Auxiliary Networks\",\"url\":\"https://www.semanticscholar.org/paper/48f2ae39f46e8dfce15688d598836eb670419205\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2006.06668\",\"authors\":[{\"authorId\":\"38279784\",\"name\":\"Minghao Yin\"},{\"authorId\":\"32532300\",\"name\":\"Zhuliang Yao\"},{\"authorId\":null,\"name\":\"Yue Cao\"},{\"authorId\":\"1723549\",\"name\":\"X. Li\"},{\"authorId\":\"1852415\",\"name\":\"Zheng Zhang\"},{\"authorId\":\"48639986\",\"name\":\"Stephen Lin\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-58555-6_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93586a3caf5c3428045399abbc5e1b096b59d623\",\"title\":\"Disentangled Non-Local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/93586a3caf5c3428045399abbc5e1b096b59d623\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1711.09125\",\"authors\":[{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"48625175\",\"name\":\"W. Li\"},{\"authorId\":\"145344553\",\"name\":\"W. Li\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/CVPR.2018.00155\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6b534d8838f92461a478a3e737b73e08db94748\",\"title\":\"Appearance-and-Relation Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/e6b534d8838f92461a478a3e737b73e08db94748\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2006.13256\",\"authors\":[{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"},{\"authorId\":\"28798386\",\"name\":\"H. Doughty\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"153155867\",\"name\":\"Jian Ma\"},{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145032628\",\"name\":\"Michael Wray\"}],\"doi\":\"10.5523/bris.2g1n6qdydwa9u22shpxqzp0t8m\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"title\":\"Rescaling Egocentric Vision\",\"url\":\"https://www.semanticscholar.org/paper/6c1a80daadab9c3bc3fdf183c669070ba7a3fd37\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.08589\",\"authors\":[{\"authorId\":\"152569373\",\"name\":\"D. Freedman\"},{\"authorId\":\"8347541\",\"name\":\"Y. Blau\"},{\"authorId\":\"2365417\",\"name\":\"L. Katzir\"},{\"authorId\":\"2680310\",\"name\":\"Amit Aides\"},{\"authorId\":\"1782918\",\"name\":\"I. Shimshoni\"},{\"authorId\":\"1490644434\",\"name\":\"Danny Veikherman\"},{\"authorId\":\"81842808\",\"name\":\"Tomer Golany\"},{\"authorId\":\"152894252\",\"name\":\"A. Gordon\"},{\"authorId\":\"102388768\",\"name\":\"G. Corrado\"},{\"authorId\":\"1745572\",\"name\":\"Y. Matias\"},{\"authorId\":\"1747801\",\"name\":\"E. Rivlin\"}],\"doi\":\"10.1109/TMI.2020.2994221\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae78c2662d34592b712f970eff229b999c59da55\",\"title\":\"Detecting Deficient Coverage in Colonoscopies\",\"url\":\"https://www.semanticscholar.org/paper/ae78c2662d34592b712f970eff229b999c59da55\",\"venue\":\"IEEE Transactions on Medical Imaging\",\"year\":2020},{\"arxivId\":\"2004.07485\",\"authors\":[{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"13812767\",\"name\":\"Xinzhi Mu\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1007/978-3-030-58555-6_5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e820578147cac31a6748c3f6ef2eeaccac066b41\",\"title\":\"Asynchronous Interaction Aggregation for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/e820578147cac31a6748c3f6ef2eeaccac066b41\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.13886\",\"authors\":[{\"authorId\":\"51128743\",\"name\":\"Srikanth Malla\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"},{\"authorId\":\"37435569\",\"name\":\"Chiho Choi\"}],\"doi\":\"10.1109/cvpr42600.2020.01120\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"title\":\"TITAN: Future Forecast Using Action Priors\",\"url\":\"https://www.semanticscholar.org/paper/55303cc7773e5e0528b1dc579bcc348c0fc38569\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.09199\",\"authors\":[{\"authorId\":\"41020711\",\"name\":\"Andrew Rouditchenko\"},{\"authorId\":\"1394839535\",\"name\":\"Angie Boggust\"},{\"authorId\":\"30507748\",\"name\":\"David Harwath\"},{\"authorId\":\"47669634\",\"name\":\"Dhiraj Joshi\"},{\"authorId\":\"70913918\",\"name\":\"S. Thomas\"},{\"authorId\":\"3104038\",\"name\":\"Kartik Audhkhasi\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"144707379\",\"name\":\"Brian Kingsbury\"},{\"authorId\":\"1774515\",\"name\":\"M. Picheny\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"title\":\"AVLnet: Learning Audio-Visual Language Representations from Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/1141ac4a1443ae7b44266a84a7f042f38759ac47\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.01449\",\"authors\":[{\"authorId\":\"35157022\",\"name\":\"Maheen Rashid\"},{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"}],\"doi\":\"10.1109/WACV45572.2020.9093404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"412efd7ffb214d66b2a4e26ff1bbc805e0196b52\",\"title\":\"Action Graphs: Weakly-supervised Action Localization with Graph Convolution Networks\",\"url\":\"https://www.semanticscholar.org/paper/412efd7ffb214d66b2a4e26ff1bbc805e0196b52\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1912.05656\",\"authors\":[{\"authorId\":\"51131930\",\"name\":\"Muhammed Kocabas\"},{\"authorId\":\"51174183\",\"name\":\"Nikos Athanasiou\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1109/CVPR42600.2020.00530\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fe6ef6b4d2795f78e765956d7a6e2ef356c6e04\",\"title\":\"VIBE: Video Inference for Human Body Pose and Shape Estimation\",\"url\":\"https://www.semanticscholar.org/paper/6fe6ef6b4d2795f78e765956d7a6e2ef356c6e04\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49046603\",\"name\":\"C. Liu\"},{\"authorId\":\"2887672\",\"name\":\"A. Shmilovici\"},{\"authorId\":\"3045152\",\"name\":\"Mark Last\"}],\"doi\":\"10.1371/journal.pone.0228579\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab4c7c12dd96b2e746666c6bdd9a59fdbd3c4f2f\",\"title\":\"Towards story-based classification of movie scenes\",\"url\":\"https://www.semanticscholar.org/paper/ab4c7c12dd96b2e746666c6bdd9a59fdbd3c4f2f\",\"venue\":\"PloS one\",\"year\":2020},{\"arxivId\":\"2010.04368\",\"authors\":[{\"authorId\":\"1836642462\",\"name\":\"Sadegh Aliakbarian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"257bcffeb41bf699840d2ccd392ac6aecc551931\",\"title\":\"Deep Sequence Learning for Video Anticipation: From Discrete and Deterministic to Continuous and Stochastic\",\"url\":\"https://www.semanticscholar.org/paper/257bcffeb41bf699840d2ccd392ac6aecc551931\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08716\",\"authors\":[{\"authorId\":\"152666334\",\"name\":\"Sudipta Paul\"},{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"title\":\"Text-based Localization of Moments in a Video Corpus\",\"url\":\"https://www.semanticscholar.org/paper/2efdeaa68e94eeef2831536cdd53f3e3868bbdca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.04685\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054200\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"title\":\"Learning Spatio-Temporal Representations With Temporal Squeeze Pooling\",\"url\":\"https://www.semanticscholar.org/paper/ca2b6df138b34d6d3eeb25e65307ba9b6201816f\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144785131\",\"name\":\"Ping Li\"},{\"authorId\":\"1749395\",\"name\":\"Xianghua Xu\"}],\"doi\":\"10.1109/ACCESS.2020.3003939\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f99d0990c255c635f731cefa434912b09598e8cd\",\"title\":\"Recurrent Compressed Convolutional Networks for Short Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/f99d0990c255c635f731cefa434912b09598e8cd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3056962\",\"name\":\"Shujon Naha\"},{\"authorId\":null,\"name\":\"Alimoor Reza\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80338d1010c36fcbe87c3ce2323b350139521523\",\"title\":\"Localizing Novel Attended Objects in Egocentric Views\",\"url\":\"https://www.semanticscholar.org/paper/80338d1010c36fcbe87c3ce2323b350139521523\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7967365\",\"name\":\"Sijia Tian\"}],\"doi\":\"10.14288/1.0375801\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74e620b52f0bb8d9d39871cbb05cc065c58184f4\",\"title\":\"Group event recognition in ice hockey\",\"url\":\"https://www.semanticscholar.org/paper/74e620b52f0bb8d9d39871cbb05cc065c58184f4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2062432\",\"name\":\"Soheil Kolouri\"},{\"authorId\":\"3268923\",\"name\":\"Nicholas Ketz\"},{\"authorId\":\"26565367\",\"name\":\"Xinyun Zou\"},{\"authorId\":\"1753673\",\"name\":\"J. Krichmar\"},{\"authorId\":\"2888448\",\"name\":\"Praveen K. Pilly\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd45befff6852def1ba78ef0d2cd18f5e0f62f68\",\"title\":\"Attention-Based Selective Plasticity\",\"url\":\"https://www.semanticscholar.org/paper/fd45befff6852def1ba78ef0d2cd18f5e0f62f68\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"1713084\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"145708707\",\"name\":\"P. Wei\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/tpami.2020.2976971\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaccf98302c256f49c7691dd906716ff50e3a44b\",\"title\":\"A Generalized Earley Parser for Human Activity Parsing and Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/aaccf98302c256f49c7691dd906716ff50e3a44b\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1807.06980\",\"authors\":[{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33240704f9efc39f75b4229983c2e10a56ca609f\",\"title\":\"Video Time: Properties, Encoders and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/33240704f9efc39f75b4229983c2e10a56ca609f\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1903.00304\",\"authors\":[{\"authorId\":\"145949475\",\"name\":\"B. Hu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"144530541\",\"name\":\"T. Cham\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f982a23ba54201fa650e2d943fe14b271d353ada\",\"title\":\"Progress Regression RNN for Online Spatial-Temporal Action Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/f982a23ba54201fa650e2d943fe14b271d353ada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.02851\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39fc7acf294739c27078c337706376a1c03dfa06\",\"title\":\"Recognizing American Sign Language Manual Signs from RGB-D Videos\",\"url\":\"https://www.semanticscholar.org/paper/39fc7acf294739c27078c337706376a1c03dfa06\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144036213\",\"name\":\"Thomas Langlois\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"07f5a895aacabd9bd918360012c1a671079d334e\",\"title\":\"MuVi Score Dataset : Modeling Human Music-Video Pairing Preferences\",\"url\":\"https://www.semanticscholar.org/paper/07f5a895aacabd9bd918360012c1a671079d334e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"title\":\"Self-supervised Spatiotemporal Feature Learning by Video Geometric Transformations\",\"url\":\"https://www.semanticscholar.org/paper/3eb9f4ca21bd104b1d9963a5a74e0ad48a1a1bdf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"title\":\"Video representation learning with deep neural networks\",\"url\":\"https://www.semanticscholar.org/paper/04a82bb033a713ae88f2e3e2306822272c30ddd9\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Alexandr Lenk\"},{\"authorId\":null,\"name\":\"Matias Cersosimo\"},{\"authorId\":null,\"name\":\"Negin Raoof\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1e0678bc378d505b4b6f04ad1f9b0c6cd7738ea\",\"title\":\"A Novel Approach for Predicting and Understanding Road Danger in the Developing World: Deep Video-Classification of Roads in Nairobi, Kenya\",\"url\":\"https://www.semanticscholar.org/paper/c1e0678bc378d505b4b6f04ad1f9b0c6cd7738ea\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1779835\",\"name\":\"Soon Ki Jung\"},{\"authorId\":\"145337089\",\"name\":\"Simone D. J. Barbosa\"},{\"authorId\":\"40913232\",\"name\":\"Phoebe Beverly Chen\"},{\"authorId\":\"1381434830\",\"name\":\"Alfredo Cuzzocrea\"},{\"authorId\":\"46993406\",\"name\":\"Xiaoyong Du\"},{\"authorId\":\"144408238\",\"name\":\"Orhun Kara\"},{\"authorId\":\"152244126\",\"name\":\"Ting Liu\"},{\"authorId\":\"1731022\",\"name\":\"Krishna M. Sivalingam\"},{\"authorId\":\"145514738\",\"name\":\"Dominik Slezak\"},{\"authorId\":\"1704749\",\"name\":\"Takashi Washio\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"145078769\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"1690892\",\"name\":\"Raquel Oliveira Prates\"},{\"authorId\":\"1744332\",\"name\":\"Wataru Ohyama\"}],\"doi\":\"10.1007/978-981-15-4818-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee18580b267693d8cf906d191f07d171248a588e\",\"title\":\"Frontiers of Computer Vision: 26th International Workshop, IW-FCV 2020, Ibusuki, Kagoshima, Japan, February 20\\u201322, 2020, Revised Selected Papers\",\"url\":\"https://www.semanticscholar.org/paper/ee18580b267693d8cf906d191f07d171248a588e\",\"venue\":\"IW-FCV\",\"year\":2020},{\"arxivId\":\"1805.02877\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49897466\",\"name\":\"Xiaotian Zhu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f511a6a2b38a26f077a5aec4baf5dffc981d881\",\"title\":\"Low-Latency Human Action Recognition with Weighted Multi-Region Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/7f511a6a2b38a26f077a5aec4baf5dffc981d881\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1807.11122\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"51150048\",\"name\":\"Kyle Buettner\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"title\":\"Story Understanding in Video Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/c72e6992f44ce75a40f44be4365dc4f264735cfb\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"1905.07385\",\"authors\":[{\"authorId\":\"145702263\",\"name\":\"E. Mavroudi\"},{\"authorId\":\"121983272\",\"name\":\"Benjam\\u00edn B\\u00e9jar Haro\"},{\"authorId\":\"144187890\",\"name\":\"R. Vidal\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e0d172287b7d16f9e6c6994d12f7dc574896cc1b\",\"title\":\"Neural Message Passing on Hybrid Spatio-Temporal Visual and Symbolic Graphs for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e0d172287b7d16f9e6c6994d12f7dc574896cc1b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122346674\",\"name\":\"V. Radu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fc2b7a911be9d5531de31fefa20b4d8a6bfc00d6\",\"title\":\"Vision 2 Sensor : Knowledge Transfer Across Sensing Modalities for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fc2b7a911be9d5531de31fefa20b4d8a6bfc00d6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48274587\",\"name\":\"B. Su\"},{\"authorId\":\"1736695\",\"name\":\"Y. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2919303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"69946fbd310a60e3fe938654e8571a92ef4ffa67\",\"title\":\"Learning Low-Dimensional Temporal Representations with Latent Alignments\",\"url\":\"https://www.semanticscholar.org/paper/69946fbd310a60e3fe938654e8571a92ef4ffa67\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1904.05582\",\"authors\":[{\"authorId\":\"50986865\",\"name\":\"A. Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"title\":\"Recurrent Space-time Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/56d7309ae0fccc0de5b09c3d426e09287498e4c3\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1642114345\",\"name\":\"Shuto Horie\"},{\"authorId\":\"1641197698\",\"name\":\"Yuji Sato\"},{\"authorId\":\"1642344262\",\"name\":\"Junko Furuyama\"},{\"authorId\":\"2257910\",\"name\":\"M. Tanabiki\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.1109/SITIS.2019.00078\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19802c95918472d5d7422f585f6fc2b4104ad782\",\"title\":\"Shot Detection in Racket Sport Video at the Frame Level Using A Recurrent Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/19802c95918472d5d7422f585f6fc2b4104ad782\",\"venue\":\"2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"145512909\",\"name\":\"G. Rigoll\"}],\"doi\":\"10.1109/IPAS.2018.8708895\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"title\":\"Analysis on Temporal Dimension of Inputs for 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a8d9b1780989dcac2c6027ab155dbe8939bda56c\",\"venue\":\"2018 IEEE International Conference on Image Processing, Applications and Systems (IPAS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143829432\",\"name\":\"Ngoc Nguyen\"},{\"authorId\":\"2289674\",\"name\":\"Mera Kartika Delimayanti\"},{\"authorId\":\"34805720\",\"name\":\"Bedy Purnama\"},{\"authorId\":\"89895131\",\"name\":\"Kunti Robiatul Mahmudah\"},{\"authorId\":\"2242591\",\"name\":\"M. Kubo\"},{\"authorId\":\"47753514\",\"name\":\"M. Kakikawa\"},{\"authorId\":\"143663888\",\"name\":\"Y. Yamada\"},{\"authorId\":\"1767800\",\"name\":\"K. Satou\"}],\"doi\":\"10.5220/0007567602700275\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc240c52b8f2b53750c1dfb69b0c6cd287ae5ce9\",\"title\":\"Applying Deep Learning Models to Action Recognition of Swimming Mice with the Scarcity of Training Data\",\"url\":\"https://www.semanticscholar.org/paper/cc240c52b8f2b53750c1dfb69b0c6cd287ae5ce9\",\"venue\":\"BIOINFORMATICS\",\"year\":2019},{\"arxivId\":\"1801.01415\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2018.00818\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93a7b595757f0e37e59a7b24c6d08508c4177405\",\"title\":\"What have We Learned from Deep Representations for Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/93a7b595757f0e37e59a7b24c6d08508c4177405\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"2542995\",\"name\":\"T. Kim\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"144878724\",\"name\":\"J. Bai\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5bb19502f8ae80d9db9e748dcb004bbeb318a17\",\"title\":\"Zero-shot Recognition of Complex Action Sequences\",\"url\":\"https://www.semanticscholar.org/paper/d5bb19502f8ae80d9db9e748dcb004bbeb318a17\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.05534\",\"authors\":[{\"authorId\":\"150140884\",\"name\":\"Jin-Woo Choi\"},{\"authorId\":\"49281242\",\"name\":\"C. Gao\"},{\"authorId\":\"79959317\",\"name\":\"Joseph C.E. Messou\"},{\"authorId\":\"3068086\",\"name\":\"Jia-Bin Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"title\":\"Why Can't I Dance in the Mall? Learning to Mitigate Scene Bias in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/439fd498e7b682dea5aa7e910267c10bf2ccb722\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1456168805\",\"name\":\"A. Roy\"},{\"authorId\":\"145848796\",\"name\":\"Deepak Mishra\"}],\"doi\":\"10.1109/TENCON.2019.8929519\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"af9659b69f81f2d63a27df1ab60ac58d3fe6295c\",\"title\":\"ECNN: Activity Recognition Using Ensembled Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/af9659b69f81f2d63a27df1ab60ac58d3fe6295c\",\"venue\":\"TENCON 2019 - 2019 IEEE Region 10 Conference (TENCON)\",\"year\":2019},{\"arxivId\":\"1912.03716\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"93640403\",\"name\":\"Xingqiang Du\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"46583978\",\"name\":\"J. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2df80c3db4550da81854e05a24e658bacec564a2\",\"title\":\"Adversarial Pyramid Network for Video Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/2df80c3db4550da81854e05a24e658bacec564a2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2003.13743\",\"authors\":[{\"authorId\":\"1600339521\",\"name\":\"Manchen Wang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"}],\"doi\":\"10.1109/CVPR42600.2020.01110\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"52a667e5fffa3430b0785d04414fc470e39dd093\",\"title\":\"Combining Detection and Tracking for Human Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/52a667e5fffa3430b0785d04414fc470e39dd093\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47845267\",\"name\":\"Da Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":null,\"name\":\"Yuan-Fang Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00394\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"daf161f0f763bf19246ad51338764c9f732d11f0\",\"title\":\"METAL: Minimum Effort Temporal Activity Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/daf161f0f763bf19246ad51338764c9f732d11f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47570825\",\"name\":\"M. Nekoui\"},{\"authorId\":\"1856258586\",\"name\":\"Fidel Omar Tito Cruz\"},{\"authorId\":\"145193182\",\"name\":\"L. Cheng\"}],\"doi\":\"10.1109/CVPRW50498.2020.00458\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4579f8b20d9f6f419766f6a886f36bef58c8e6d1\",\"title\":\"FALCONS: FAst Learner-grader for CONtorted poses in Sports\",\"url\":\"https://www.semanticscholar.org/paper/4579f8b20d9f6f419766f6a886f36bef58c8e6d1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1911.04127\",\"authors\":[{\"authorId\":\"51266875\",\"name\":\"Chuming Lin\"},{\"authorId\":\"50683988\",\"name\":\"J. Li\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":\"20595955\",\"name\":\"Zhipeng Cui\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1609/AAAI.V34I07.6815\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e2534a3c894c93053341d514967c45c78657969c\",\"title\":\"Fast Learning of Temporal Action Proposal via Dense Boundary Generator\",\"url\":\"https://www.semanticscholar.org/paper/e2534a3c894c93053341d514967c45c78657969c\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292395\",\"name\":\"B. Wang\"},{\"authorId\":\"37012552\",\"name\":\"L. Huang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":\"10.1109/CVPR42600.2020.00116\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f7d8d5c55581563723a98f6090fd122fb376de81\",\"title\":\"Active Vision for Early Recognition of Human Actions\",\"url\":\"https://www.semanticscholar.org/paper/f7d8d5c55581563723a98f6090fd122fb376de81\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1902160423\",\"name\":\"Alison Reboud\"},{\"authorId\":\"1902021703\",\"name\":\"Ismail Harrando\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"1684267\",\"name\":\"Rapha\\u00ebl Troncy\"},{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab0d7b171424ded00acba294e2f349f627c94107\",\"title\":\"Combining Textual and Visual Modeling for Predicting Media Memorability\",\"url\":\"https://www.semanticscholar.org/paper/ab0d7b171424ded00acba294e2f349f627c94107\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":\"2007.07626\",\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"3307580\",\"name\":\"Xudong Jiang\"},{\"authorId\":\"48837492\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1007/978-3-030-58571-6_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"title\":\"Temporal Distinct Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cfb71e0cce6487b6a1cf2dd0cd3755d1d78e908e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49952482\",\"name\":\"Jibin Gao\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"7588999\",\"name\":\"J. Pan\"},{\"authorId\":\"2971945\",\"name\":\"Chengying Gao\"},{\"authorId\":null,\"name\":\"Yaowei Wang\"},{\"authorId\":\"8434337\",\"name\":\"W. Zeng\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1007/978-3-030-58577-8_14\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"20e6a5d5295740952356a1fb2ae33c5550141219\",\"title\":\"An Asymmetric Modeling for Action Assessment\",\"url\":\"https://www.semanticscholar.org/paper/20e6a5d5295740952356a1fb2ae33c5550141219\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.13979\",\"authors\":[{\"authorId\":\"48317098\",\"name\":\"Bruce X. B. Yu\"},{\"authorId\":\"49422024\",\"name\":\"Y. Liu\"},{\"authorId\":\"145003402\",\"name\":\"K. C. Chan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"title\":\"Skeleton Focused Human Activity Recognition in RGB Video\",\"url\":\"https://www.semanticscholar.org/paper/ed79396ea31f71fbbe8a4802ef271def4ab28977\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10518\",\"authors\":[{\"authorId\":\"20624177\",\"name\":\"F. Ziaeetabar\"},{\"authorId\":\"47312115\",\"name\":\"J. Pomp\"},{\"authorId\":\"48979419\",\"name\":\"Stefan Pfeiffer\"},{\"authorId\":\"1403123630\",\"name\":\"N. El-Sourani\"},{\"authorId\":\"66967341\",\"name\":\"Ricarda I. Schubotz\"},{\"authorId\":\"1953638\",\"name\":\"M. Tamosiunaite\"},{\"authorId\":\"1714016\",\"name\":\"F. W\\u00f6rg\\u00f6tter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"599568fcf46761703a1479f6ea9e4065cd71e992\",\"title\":\"Human and Machine Action Prediction Independent of Object Information\",\"url\":\"https://www.semanticscholar.org/paper/599568fcf46761703a1479f6ea9e4065cd71e992\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1909.06957\",\"authors\":[{\"authorId\":\"103750709\",\"name\":\"Ha Thi Phuong Thao\"},{\"authorId\":\"3320845\",\"name\":\"Dorien Herremans\"},{\"authorId\":\"144596911\",\"name\":\"Gemma Roig\"}],\"doi\":\"10.1109/ICCVW.2019.00201\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4f66cb50fcd15221f4d1d3c61cda8c35a75e578a\",\"title\":\"Multimodal Deep Models for Predicting Affective Responses Evoked by Movies\",\"url\":\"https://www.semanticscholar.org/paper/4f66cb50fcd15221f4d1d3c61cda8c35a75e578a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92533069\",\"name\":\"L. Chi\"},{\"authorId\":\"2704823\",\"name\":\"Ze-Huan Yuan\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.01182\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"title\":\"Non-Local Neural Networks With Grouped Bilinear Attentional Transforms\",\"url\":\"https://www.semanticscholar.org/paper/6dcb726b4e1afa5fa6f8684081f19508e61b45c0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.01808\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2954103\",\"name\":\"B. E. Bejnordi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"title\":\"TimeGate: Conditional Gating of Segments in Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.00232\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"150937390\",\"name\":\"Barry A. McNamara\"},{\"authorId\":\"118728832\",\"name\":\"A. Lascelles\"},{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"da0822f776025dd73698adf6ed29ac63302d1a32\",\"title\":\"Multi-Moments in Time: Learning and Interpreting Models for Multi-Action Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/da0822f776025dd73698adf6ed29ac63302d1a32\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.00437\",\"authors\":[{\"authorId\":\"37299201\",\"name\":\"Rodney LaLonde\"},{\"authorId\":\"120420670\",\"name\":\"Irene Tanner\"},{\"authorId\":\"3419231\",\"name\":\"K. Nikiforaki\"},{\"authorId\":\"2178280\",\"name\":\"G. Papadakis\"},{\"authorId\":\"49201384\",\"name\":\"P. Kandel\"},{\"authorId\":\"34458717\",\"name\":\"Candice W. Bolan\"},{\"authorId\":\"1991161\",\"name\":\"M. Wallace\"},{\"authorId\":\"1717161\",\"name\":\"U. Bagci\"}],\"doi\":\"10.1007/978-3-030-32254-0_12\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ee3f243bdaca717d2c228566bb6a698d116f085e\",\"title\":\"INN: Inflated Neural Networks for IPMN Diagnosis\",\"url\":\"https://www.semanticscholar.org/paper/ee3f243bdaca717d2c228566bb6a698d116f085e\",\"venue\":\"MICCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51105591\",\"name\":\"D. Avola\"},{\"authorId\":\"77259716\",\"name\":\"M. Cascio\"},{\"authorId\":\"1729018\",\"name\":\"L. Cinque\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"35404907\",\"name\":\"Cristiano Massaroni\"},{\"authorId\":\"51307157\",\"name\":\"E. Rodol\\u00e0\"}],\"doi\":\"10.1109/TMM.2019.2960588\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e06db13b5d5bbffd2184a3540ed4aa6035ab315\",\"title\":\"2-D Skeleton-Based Action Recognition via Two-Branch Stacked LSTM-RNNs\",\"url\":\"https://www.semanticscholar.org/paper/2e06db13b5d5bbffd2184a3540ed4aa6035ab315\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2008.13254\",\"authors\":[{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"4127040\",\"name\":\"Chi-Tung Cheng\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"79610728\",\"name\":\"Chien-Hung Liao\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2964822\",\"name\":\"Adam P. Harrison\"}],\"doi\":\"10.1007/978-3-030-59719-1_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c73020d052837a897639066be0eee420bb11253\",\"title\":\"Deep Volumetric Universal Lesion Detection using Light-Weight Pseudo 3D Convolution and Surface Point Regression\",\"url\":\"https://www.semanticscholar.org/paper/8c73020d052837a897639066be0eee420bb11253\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"37184350\",\"name\":\"J. Xu\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"},{\"authorId\":\"50763020\",\"name\":\"Jingwen Chen\"},{\"authorId\":\"41079034\",\"name\":\"Hong-Yang Chao\"},{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1394465427\",\"name\":\"Qiuyu Cai\"}],\"doi\":\"10.1145/3394171.3416290\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"93aed487e9b9f51bf05803ef69c92599001358ac\",\"title\":\"XlanV Model with Adaptively Multi-Modality Feature Fusing for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93aed487e9b9f51bf05803ef69c92599001358ac\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993663564\",\"name\":\"Mingyao Hong\"},{\"authorId\":\"46439250\",\"name\":\"Guorong Li\"},{\"authorId\":\"3175853\",\"name\":\"Xinfeng Zhang\"},{\"authorId\":\"153159021\",\"name\":\"Qingming Huang\"}],\"doi\":\"10.1145/3394171.3413517\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2009d525afc02cdc60270669ec760d222ef5bd32\",\"title\":\"Generalized Zero-Shot Video Classification via Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/2009d525afc02cdc60270669ec760d222ef5bd32\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39893135\",\"name\":\"M. Yu\"},{\"authorId\":\"1712773\",\"name\":\"Weizhe Zhang\"},{\"authorId\":\"48411615\",\"name\":\"Qingxiang Zeng\"},{\"authorId\":\"47074418\",\"name\":\"C. Wang\"},{\"authorId\":\"38158055\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/ICAIIC.2019.8669069\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"title\":\"Human-Object Contour for Action Recognition with Attentional Multi-modal Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/ad0dba3713a1210f0b89c66c25e93b22e5e04d9e\",\"venue\":\"2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"21265854\",\"name\":\"N. Chesneau\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"title\":\"Learning to Recognize Actions with Weak Supervision. (Reconnaissance d'actions de mani\\u00e8re faiblement supervis\\u00e9e)\",\"url\":\"https://www.semanticscholar.org/paper/d9de669c07c6a8563a135e5c26b6f6432b354a27\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.12372\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"title\":\"Play Fair: Frame Attributions in Video Models\",\"url\":\"https://www.semanticscholar.org/paper/f6378d6130b82f083882db4c0bf2065b6a3e59b8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1911.03030\",\"authors\":[{\"authorId\":\"1794679\",\"name\":\"C. Guo\"},{\"authorId\":\"69486855\",\"name\":\"T. Goldstein\"},{\"authorId\":\"144479015\",\"name\":\"Awni Hannun\"},{\"authorId\":\"35341401\",\"name\":\"Laurens van der Maaten\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b160e3fd3e7828279a08e5c34cd79cd2c27ef70a\",\"title\":\"Certified Data Removal from Machine Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/b160e3fd3e7828279a08e5c34cd79cd2c27ef70a\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2006.05091\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f252cf230c32847099908e4eda9a37c3086fcb8a\",\"title\":\"PNL: Efficient Long-Range Dependencies Extraction with Pyramid Non-Local Module for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f252cf230c32847099908e4eda9a37c3086fcb8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15287636\",\"name\":\"K. Sun\"},{\"authorId\":\"50703807\",\"name\":\"L. Li\"},{\"authorId\":\"12791664\",\"name\":\"Lianqiang Li\"},{\"authorId\":\"51511262\",\"name\":\"Ningyu He\"},{\"authorId\":\"50820964\",\"name\":\"Jie Zhu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054641\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df8b5676d62e0114ae2a804894c33b8e3d8ab3bf\",\"title\":\"Spatial Attentional Bilinear 3D Convolutional Network for Video-Based Autism Spectrum Disorder Detection\",\"url\":\"https://www.semanticscholar.org/paper/df8b5676d62e0114ae2a804894c33b8e3d8ab3bf\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10839487\",\"name\":\"Chunbo Song\"},{\"authorId\":\"46887763\",\"name\":\"C. Rasmussen\"}],\"doi\":\"10.1007/978-3-030-33720-9_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ce9c9eb94b7308728bca5ee6af45dbd7d6f22fb4\",\"title\":\"Multi-camera Temporal Grouping for Play/Break Event Detection in Soccer Games\",\"url\":\"https://www.semanticscholar.org/paper/ce9c9eb94b7308728bca5ee6af45dbd7d6f22fb4\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1906.03683\",\"authors\":[{\"authorId\":\"144015229\",\"name\":\"Kuan-Hui Lee\"},{\"authorId\":\"1914418\",\"name\":\"Takaaki Tagawa\"},{\"authorId\":\"147128583\",\"name\":\"Jia-En M. Pan\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2674833\",\"name\":\"B. Douillard\"}],\"doi\":\"10.1109/IVS.2019.8814278\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c7437cce0417848d1492f980daa8742e71131cdf\",\"title\":\"An Attention-based Recurrent Convolutional Network for Vehicle Taillight Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c7437cce0417848d1492f980daa8742e71131cdf\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3314448\",\"name\":\"Isma Hadji\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-01264-9_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6b8ae4262a589f4d6bfaf91d0458e593a7a6fb1\",\"title\":\"A New Large Scale Dynamic Texture Dataset with Application to ConvNet Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d6b8ae4262a589f4d6bfaf91d0458e593a7a6fb1\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2012.02383\",\"authors\":[{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"2502329\",\"name\":\"Dakai Jin\"},{\"authorId\":\"143655284\",\"name\":\"S. Miao\"},{\"authorId\":\"2964822\",\"name\":\"Adam P. Harrison\"},{\"authorId\":\"145889317\",\"name\":\"Dazhou Guo\"},{\"authorId\":\"3152399\",\"name\":\"Y. Tang\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"46280021\",\"name\":\"Jingjing Lu\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93523a4fffb689cf068a0cfce8f31539baf1d408\",\"title\":\"Self-supervised Learning of Pixel-wise Anatomical Embeddings in Radiological Images\",\"url\":\"https://www.semanticscholar.org/paper/93523a4fffb689cf068a0cfce8f31539baf1d408\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.08421\",\"authors\":[{\"authorId\":\"39599498\",\"name\":\"C. Gu\"},{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2997956\",\"name\":\"C. Pantofaru\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"1758054\",\"name\":\"Y. Li\"},{\"authorId\":\"2262946\",\"name\":\"S. Ricco\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2018.00633\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"title\":\"AVA: A Video Dataset of Spatio-Temporally Localized Atomic Visual Actions\",\"url\":\"https://www.semanticscholar.org/paper/54c7c3909c7e1e827befdbe8d2595a3b196ba1b8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/WACV45572.2020.9093612\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"title\":\"Learning Multimodal Representations for Unseen Activities\",\"url\":\"https://www.semanticscholar.org/paper/dbbcf8af70db7533f76e8e55f108fcc6af6e0c0e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2003.09392\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":null,\"name\":\"Jie Zhou\"}],\"doi\":\"10.1109/TPAMI.2020.2980824\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"title\":\"Comprehensive Instructional Video Analysis: The COIN Dataset and Performance Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/c974b4547ce5df86f07c428abb6206ad5e52fc0d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"2006.03876\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e30fd64c9659c8cc6b28d37d19395752aae89130\",\"title\":\"ARID: A New Dataset for Recognizing Action in the Dark\",\"url\":\"https://www.semanticscholar.org/paper/e30fd64c9659c8cc6b28d37d19395752aae89130\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50415746\",\"name\":\"Shruti Vyas\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/978-3-030-58583-9_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"title\":\"Multi-view Action Recognition Using Cross-View Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/85f4601fb7cc495f33c80750f30b0e44c7ab6a91\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.11394\",\"authors\":[{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"36352940\",\"name\":\"P. Jin\"},{\"authorId\":\"40049070\",\"name\":\"X. Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a820785df28ee9693001aa5701bba3828229ef0\",\"title\":\"ERA: A Dataset and Deep Learning Benchmark for Event Recognition in Aerial Videos\",\"url\":\"https://www.semanticscholar.org/paper/4a820785df28ee9693001aa5701bba3828229ef0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422195\",\"name\":\"S. Chaudhary\"},{\"authorId\":\"1827383\",\"name\":\"S. Murala\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66cdde8d08733b4d9840089f8af07f042749675f\",\"title\":\"Deep network for human action recognition using Weber motion\",\"url\":\"https://www.semanticscholar.org/paper/66cdde8d08733b4d9840089f8af07f042749675f\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1901.02551\",\"authors\":[{\"authorId\":\"2206630\",\"name\":\"A. Yu\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2019.00080\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab823cbcc22216161f16f63264ee127bcb5a12f7\",\"title\":\"Thinking Outside the Pool: Active Training Image Creation for Relative Attributes\",\"url\":\"https://www.semanticscholar.org/paper/ab823cbcc22216161f16f63264ee127bcb5a12f7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.04868\",\"authors\":[{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"97f1676e20d232d106d71b6007e4b4284a22699d\",\"title\":\"Back to the Future: Knowledge Distillation for Human Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/97f1676e20d232d106d71b6007e4b4284a22699d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.04312\",\"authors\":[{\"authorId\":\"7480219\",\"name\":\"Boyi Li\"},{\"authorId\":\"24277779\",\"name\":\"Felix Wu\"},{\"authorId\":\"7446832\",\"name\":\"Kilian Q. Weinberger\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8d36b4b1a1c0f538b9d4f79671ecfc8a196c5bb0\",\"title\":\"Positional Normalization\",\"url\":\"https://www.semanticscholar.org/paper/8d36b4b1a1c0f538b9d4f79671ecfc8a196c5bb0\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1612.03052\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"119675494\",\"name\":\"Jonghyun Choi\"},{\"authorId\":\"144660077\",\"name\":\"Jan Neumann\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00179\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"title\":\"ActionFlowNet: Learning Motion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6db73f10084ce6a4186363ea9d7475a9a658a11\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"2007.09470\",\"authors\":[{\"authorId\":\"1399646334\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1007/978-3-030-58598-3_13\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"314f0cdcca7cdab68c92821c149786a876c116bb\",\"title\":\"Social Adaptive Module for Weakly-supervised Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/314f0cdcca7cdab68c92821c149786a876c116bb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.11261\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"title\":\"Hierarchically Decoupled Spatial-Temporal Contrast for Self-supervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/93d198d99ef16868d381bc63e9e6f8c6ef3f7a07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.14371\",\"authors\":[{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"145131935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"209b706757048dd8606185bb2ca27c31ff991dd3\",\"title\":\"Tensor Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/209b706757048dd8606185bb2ca27c31ff991dd3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1830456822\",\"name\":\"R. Lang\"},{\"authorId\":\"89662118\",\"name\":\"Xiaosu Zhu\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3397271.3401122\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7066512f40da8bdf61a8165dd08177932b9605be\",\"title\":\"3D Self-Attention for Unsupervised Video Quantization\",\"url\":\"https://www.semanticscholar.org/paper/7066512f40da8bdf61a8165dd08177932b9605be\",\"venue\":\"SIGIR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"7284555\",\"name\":\"A. Jain\"},{\"authorId\":\"52585867\",\"name\":\"Sanskar Agrawal\"},{\"authorId\":\"144240261\",\"name\":\"P. Mitra\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":\"10.1109/CVPR42600.2020.01371\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"55c86c15dd41cbb23f657de01a8a867ce1b7383b\",\"title\":\"Prior Guided GAN Based Semantic Inpainting\",\"url\":\"https://www.semanticscholar.org/paper/55c86c15dd41cbb23f657de01a8a867ce1b7383b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.10903\",\"authors\":[{\"authorId\":\"2862582\",\"name\":\"Peratham Wiriyathammabhum\"}],\"doi\":\"10.1007/978-3-030-63820-7_63\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"09da26797d509cc5e193512589e205c088f4b1f4\",\"title\":\"SpotFast Networks with Memory Augmented Lateral Transformers for Lipreading\",\"url\":\"https://www.semanticscholar.org/paper/09da26797d509cc5e193512589e205c088f4b1f4\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":true,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09662\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TIP.2020.3005508\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c075cfd9a4b300a3386eb0bcba2f940e72e84977\",\"title\":\"Biased Mixtures of Experts: Enabling Computer Vision Inference Under Data Transfer Limitations\",\"url\":\"https://www.semanticscholar.org/paper/c075cfd9a4b300a3386eb0bcba2f940e72e84977\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.02072\",\"authors\":[{\"authorId\":\"2287437\",\"name\":\"Pranay Gupta\"},{\"authorId\":\"1796274241\",\"name\":\"Anirudh Thatipelli\"},{\"authorId\":\"2418644\",\"name\":\"A. Aggarwal\"},{\"authorId\":\"30504851\",\"name\":\"S. Maheshwari\"},{\"authorId\":\"30768978\",\"name\":\"Neel Trivedi\"},{\"authorId\":\"144447729\",\"name\":\"S. Das\"},{\"authorId\":\"1730952\",\"name\":\"Ravi Kiran Sarvadevabhatla\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5cc7e2c98c5e04d265e5d1adcdc1814b159cc0e4\",\"title\":\"Quo Vadis, Skeleton Action Recognition ?\",\"url\":\"https://www.semanticscholar.org/paper/5cc7e2c98c5e04d265e5d1adcdc1814b159cc0e4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2223645\",\"name\":\"K. Bozek\"},{\"authorId\":\"31549285\",\"name\":\"Laetitia Hebert\"},{\"authorId\":\"1603891782\",\"name\":\"Yoann Portugal\"},{\"authorId\":\"3096034\",\"name\":\"G. Stephens\"}],\"doi\":\"10.1101/2020.03.26.007302\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"92eae33048f33f539b9703d7989cb5d679dd0014\",\"title\":\"Markerless tracking of an entire insect colony\",\"url\":\"https://www.semanticscholar.org/paper/92eae33048f33f539b9703d7989cb5d679dd0014\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.07758\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1109/CVPRW50498.2020.00487\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"23e36087637e9d74815eba07990c38c02fecc966\",\"title\":\"Multi-modal Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/23e36087637e9d74815eba07990c38c02fecc966\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390729139\",\"name\":\"Yuxuan Zhao\"},{\"authorId\":\"1712515\",\"name\":\"K. Man\"},{\"authorId\":\"33830793\",\"name\":\"J. Smith\"},{\"authorId\":\"38672851\",\"name\":\"Kamran Siddique\"},{\"authorId\":\"143638589\",\"name\":\"S. Guan\"}],\"doi\":\"10.1186/s13640-020-00501-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"847aa95e2072b6c654a8b4ccb03dc76ebc0c2f96\",\"title\":\"Improved two-stream model for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/847aa95e2072b6c654a8b4ccb03dc76ebc0c2f96\",\"venue\":\"EURASIP J. Image Video Process.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2006.10734\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"47029037\",\"name\":\"L. Gustafson\"},{\"authorId\":\"37292073\",\"name\":\"A. Adcock\"},{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7aeecf9e5553336e6e49c22efc426f55e2070171\",\"title\":\"Forward Prediction for Physical Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7aeecf9e5553336e6e49c22efc426f55e2070171\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1878475584\",\"name\":\"Xin Gao\"},{\"authorId\":\"1878338267\",\"name\":\"Xusheng Liu\"},{\"authorId\":\"1879512992\",\"name\":\"Taotao Yang\"},{\"authorId\":\"34604525\",\"name\":\"G. Deng\"},{\"authorId\":\"1878360893\",\"name\":\"Hao Peng\"},{\"authorId\":\"1877628045\",\"name\":\"Qiaosong Zhang\"},{\"authorId\":\"97584815\",\"name\":\"H. Li\"},{\"authorId\":\"1879297772\",\"name\":\"Junhui Liu\"}],\"doi\":\"10.1109/ICMEW46912.2020.9106051\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"title\":\"Automatic Key Moment Extraction and Highlights Generation Based on Comprehensive Soccer Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/31e55bc719db796d8022b2c9b1e9285812fb0da8\",\"venue\":\"2020 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2020},{\"arxivId\":\"2006.09116\",\"authors\":[{\"authorId\":\"30733670\",\"name\":\"S. Chen\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"1967781\",\"name\":\"Ziyi Lin\"},{\"authorId\":\"1388486428\",\"name\":\"Jing Shao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb8eca609bdd9dc37968a48b5e74ba30d0ecff12\",\"title\":\"1st place solution for AVA-Kinetics Crossover in AcitivityNet Challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/eb8eca609bdd9dc37968a48b5e74ba30d0ecff12\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10141\",\"authors\":[{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"1645272447\",\"name\":\"Mor Shpigel\"},{\"authorId\":\"1408268488\",\"name\":\"Ophir Azulai\"},{\"authorId\":\"46189009\",\"name\":\"U. Barzelay\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8b7637b757133c1aa88403754bdc42e25ad3ab31\",\"title\":\"TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b7637b757133c1aa88403754bdc42e25ad3ab31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"40832988\",\"name\":\"Y. H. Kim\"},{\"authorId\":\"32850725\",\"name\":\"Kyungmin Kim\"},{\"authorId\":\"1754380\",\"name\":\"S. Kim\"}],\"doi\":\"10.1007/978-3-030-01267-0_25\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041115cb5509466f7449451709387268a008aba2\",\"title\":\"Teaching Machines to Understand Baseball Games: Large-Scale Baseball Video Database for Multiple Video Understanding Tasks\",\"url\":\"https://www.semanticscholar.org/paper/041115cb5509466f7449451709387268a008aba2\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yong Wang\"},{\"authorId\":\"49185049\",\"name\":\"Shasha Wang\"},{\"authorId\":\"5510802\",\"name\":\"M. Zhou\"},{\"authorId\":\"143616264\",\"name\":\"Wei Nie\"},{\"authorId\":\"48520847\",\"name\":\"Xiaolong Yang\"},{\"authorId\":\"9435771\",\"name\":\"Zeng-shan Tian\"}],\"doi\":\"10.1109/GCWkshps45667.2019.9024691\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e38580a5b410cfc5b8367aeb3c9166919fe7f85d\",\"title\":\"Two-Stream Time Sequential Network Based Hand Gesture Recognition Method Using Radar Sensor\",\"url\":\"https://www.semanticscholar.org/paper/e38580a5b410cfc5b8367aeb3c9166919fe7f85d\",\"venue\":\"2019 IEEE Globecom Workshops (GC Wkshps)\",\"year\":2019},{\"arxivId\":\"1904.13080\",\"authors\":[{\"authorId\":\"145377162\",\"name\":\"Y. Yuan\"},{\"authorId\":\"49370704\",\"name\":\"Dong Wang\"},{\"authorId\":\"39669401\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33019167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e3fc2a67967b1355609094175f19b2412dd4851d\",\"title\":\"Memory-Augmented Temporal Dynamic Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e3fc2a67967b1355609094175f19b2412dd4851d\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2011.09540\",\"authors\":[{\"authorId\":\"150300448\",\"name\":\"Shylendra Kumar\"},{\"authorId\":\"145542943\",\"name\":\"A S M Iftekhar\"},{\"authorId\":\"49944379\",\"name\":\"M. G\\u00f6bel\"},{\"authorId\":\"150317829\",\"name\":\"Tom Bullock\"},{\"authorId\":\"5933443\",\"name\":\"Mary Maclean\"},{\"authorId\":\"46906757\",\"name\":\"M. B. Miller\"},{\"authorId\":\"2008152232\",\"name\":\"Tyler Santander\"},{\"authorId\":\"145080695\",\"name\":\"B. Giesbrecht\"},{\"authorId\":\"3047772\",\"name\":\"Scott T. Grafton\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"dd17e830f7a32da97956967ba2272e2a9828a328\",\"title\":\"StressNet: Detecting Stress in Thermal Videos\",\"url\":\"https://www.semanticscholar.org/paper/dd17e830f7a32da97956967ba2272e2a9828a328\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"48641524\",\"name\":\"Sainan Liu\"},{\"authorId\":\"2010983\",\"name\":\"Zeyu Chen\"},{\"authorId\":\"47744833\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/CVPR.2018.00484\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"36777066966899fb48c1850d5776af97f1c81942\",\"title\":\"Attentional ShapeContextNet for Point Cloud Recognition\",\"url\":\"https://www.semanticscholar.org/paper/36777066966899fb48c1850d5776af97f1c81942\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2003.12060\",\"authors\":[{\"authorId\":\"145117688\",\"name\":\"Bin Liu\"},{\"authorId\":\"153842980\",\"name\":\"Y. Cao\"},{\"authorId\":\"51091819\",\"name\":\"Yutong Lin\"},{\"authorId\":\"144836952\",\"name\":\"Q. Li\"},{\"authorId\":null,\"name\":\"Zheng Zhang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"100541102\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-58548-8_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2ad5f836e1d9876fa3fc53cb2c0a704b45988f0f\",\"title\":\"Negative Margin Matters: Understanding Margin in Few-shot Classification\",\"url\":\"https://www.semanticscholar.org/paper/2ad5f836e1d9876fa3fc53cb2c0a704b45988f0f\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.06961\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"title\":\"Tiny Video Networks\",\"url\":\"https://www.semanticscholar.org/paper/7f330ebc8bce345825e3860988aaeb0a7e34ace9\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.10700\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"13167100\",\"name\":\"Zhiyong Cheng\"},{\"authorId\":\"144585402\",\"name\":\"Peng Zhang\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1145/3343031.3351040\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"title\":\"Explainable Video Action Reasoning via Prior Knowledge and State Transitions\",\"url\":\"https://www.semanticscholar.org/paper/7dc27232b593549fca0d1e146b6ace4ef46e183d\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1902.10024\",\"authors\":[{\"authorId\":\"143884578\",\"name\":\"W. McNally\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"},{\"authorId\":\"144304939\",\"name\":\"J. McPhee\"}],\"doi\":\"10.1109/CRV.2019.00015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bf3e15a9392621c45da6141a78a60d341ab2e506\",\"title\":\"STAR-Net: Action Recognition using Spatio-Temporal Activation Reprojection\",\"url\":\"https://www.semanticscholar.org/paper/bf3e15a9392621c45da6141a78a60d341ab2e506\",\"venue\":\"2019 16th Conference on Computer and Robot Vision (CRV)\",\"year\":2019},{\"arxivId\":\"1911.00212\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.18653/v1/D19-1207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55f546209c01530a7717d4170aa24947c6b92775\",\"title\":\"Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/55f546209c01530a7717d4170aa24947c6b92775\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2001.03024\",\"authors\":[{\"authorId\":\"94106850\",\"name\":\"L. Jiang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"15882215\",\"name\":\"R. Li\"},{\"authorId\":\"144461220\",\"name\":\"Chen Qian\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1109/cvpr42600.2020.00296\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"75d6df636f55583cab76c58738a7766d0a025900\",\"title\":\"DeeperForensics-1.0: A Large-Scale Dataset for Real-World Face Forgery Detection\",\"url\":\"https://www.semanticscholar.org/paper/75d6df636f55583cab76c58738a7766d0a025900\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.10751\",\"authors\":[{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"46950892\",\"name\":\"Zhao-yang Lu\"},{\"authorId\":\"46276828\",\"name\":\"J. Li\"},{\"authorId\":\"144954285\",\"name\":\"T. Yang\"},{\"authorId\":\"144299910\",\"name\":\"C. Yao\"}],\"doi\":\"10.1109/TIP.2019.2957930\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"title\":\"Deep Image-to-Video Adaptation and Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cfd5817802102b0326243c95ebfe1c8e14427cd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2610029\",\"name\":\"H. Wu\"},{\"authorId\":\"1409918228\",\"name\":\"Xin Ma\"},{\"authorId\":\"9348561\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/TMM.2019.2953814\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9433095a4a5339815bc0fc000971797e99babdda\",\"title\":\"Convolutional Networks With Channel and STIPs Attention Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9433095a4a5339815bc0fc000971797e99babdda\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2003.05837\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a700417579a1fbde76baba60595bc00c909606c\",\"title\":\"Top-1 Solution of Multi-Moments in Time Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/5a700417579a1fbde76baba60595bc00c909606c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.08510\",\"authors\":[{\"authorId\":\"144234446\",\"name\":\"Bo He\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b77967866434f46c41f25baf7149d9b027b600b3\",\"title\":\"GTA: Global Temporal Attention for Video Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b77967866434f46c41f25baf7149d9b027b600b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1907.13280\",\"authors\":[{\"authorId\":\"2531558\",\"name\":\"G. Chao\"},{\"authorId\":\"2188497\",\"name\":\"Abhinav Rastogi\"},{\"authorId\":\"3014143\",\"name\":\"Semih Yavuz\"},{\"authorId\":\"152325757\",\"name\":\"D. Hakkani-T\\u00fcr\"},{\"authorId\":\"47740493\",\"name\":\"Jindong Chen\"},{\"authorId\":\"5347612\",\"name\":\"I. Lane\"}],\"doi\":\"10.18653/v1/W19-5926\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"title\":\"Learning Question-Guided Video Representation for Multi-Turn Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb5af7b7d5ebf9e8ff4164233a73b8fe4fe737a3\",\"venue\":\"ViGIL@NeurIPS\",\"year\":2019},{\"arxivId\":\"1909.03580\",\"authors\":[{\"authorId\":\"66438699\",\"name\":\"Yucai Bai\"},{\"authorId\":\"153740190\",\"name\":\"Giang Dai\"},{\"authorId\":null,\"name\":\"Long Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"title\":\"Extreme Low Resolution Activity Recognition with Spatial-Temporal Attention Transfer\",\"url\":\"https://www.semanticscholar.org/paper/1132b5161dc26ccefeb7187a35251df9f7d0ba3f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94567368\",\"name\":\"C. Sun\"},{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144816684\",\"name\":\"K. Murphy\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"title\":\"Learning Video Representations using Contrastive Bidirectional Transformer\",\"url\":\"https://www.semanticscholar.org/paper/025a0dc4a2a98742f1b410b6318a46de2c854b22\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1903.08225\",\"authors\":[{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2019.00365\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3605e41ce77dfd259eaebed906804bb60f634f75\",\"title\":\"Cross-Task Weakly Supervised Learning From Instructional Videos\",\"url\":\"https://www.semanticscholar.org/paper/3605e41ce77dfd259eaebed906804bb60f634f75\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1901.02598\",\"authors\":[{\"authorId\":\"4251916\",\"name\":\"C. Chang\"},{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"3285568\",\"name\":\"Yanan Sui\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2019.00366\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00ccecc56ed83945fafb8e2dc48ffc1609618040\",\"title\":\"D3TW: Discriminative Differentiable Dynamic Time Warping for Weakly Supervised Action Alignment and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00ccecc56ed83945fafb8e2dc48ffc1609618040\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.03349\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/cvpr42600.2020.00043\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45a924794b2c6501b671cf4249c6ac4fa1671597\",\"title\":\"Video Modeling With Correlation Networks\",\"url\":\"https://www.semanticscholar.org/paper/45a924794b2c6501b671cf4249c6ac4fa1671597\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1712.01938\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPR.2018.00556\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"title\":\"Learning Latent Super-Events to Detect Multiple Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/1c4d2759eb491073d2c26c3193fd62cd9cabd091\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1901.00484\",\"authors\":[{\"authorId\":\"29132542\",\"name\":\"Meera Hahn\"},{\"authorId\":\"49915485\",\"name\":\"Andrew Silva\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"title\":\"Action2Vec: A Crossmodal Embedding Approach to Action Learning\",\"url\":\"https://www.semanticscholar.org/paper/797243368d6ccde3b70bab9e1265f4e1d4e1cc43\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1804.03641\",\"authors\":[{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":\"10.1007/978-3-030-01231-1_39\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"title\":\"Audio-Visual Scene Analysis with Self-Supervised Multisensory Features\",\"url\":\"https://www.semanticscholar.org/paper/171f8f1090ef0533ff470ed5a4d31ecfefcc74be\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.08496\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1007/978-3-030-01246-5_49\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"title\":\"Temporal Relational Reasoning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/8ad12d3ee186403b856639b58d7797aa4b89a6c7\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1708.09268\",\"authors\":[{\"authorId\":\"144603946\",\"name\":\"A. Tran\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"}],\"doi\":\"10.1109/ICCVW.2017.368\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cdbfc8786f9ef0c1331f180398857347d29f901b\",\"title\":\"Two-Stream Flow-Guided Convolutional Attention Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cdbfc8786f9ef0c1331f180398857347d29f901b\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1708.06834\",\"authors\":[{\"authorId\":\"144444663\",\"name\":\"Victor Campos\"},{\"authorId\":\"2447185\",\"name\":\"B. Jou\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"144345280\",\"name\":\"J. Torres\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae8d5be3caea59a21221f02ef04d49a86cb80191\",\"title\":\"Skip RNN: Learning to Skip State Updates in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/ae8d5be3caea59a21221f02ef04d49a86cb80191\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3007561\",\"name\":\"Yinghui Kong\"},{\"authorId\":\"47681511\",\"name\":\"L. Li\"},{\"authorId\":\"46459368\",\"name\":\"Ke Zhang\"},{\"authorId\":\"143710669\",\"name\":\"Qiang Ni\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1117/1.JEI.28.4.043032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cefcbafc3484c05a0d1d48fe7588f7af3ae8c37\",\"title\":\"Attention module-based spatial\\u2013temporal graph convolutional networks for skeleton-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/7cefcbafc3484c05a0d1d48fe7588f7af3ae8c37\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47508738\",\"name\":\"Shuangshuang Guo\"},{\"authorId\":\"2343895\",\"name\":\"Laiyun Qing\"},{\"authorId\":\"47430935\",\"name\":\"Jun Miao\"},{\"authorId\":\"7667827\",\"name\":\"L. Duan\"}],\"doi\":\"10.1007/s11042-019-7675-4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b04b5503532a69428841548e32c1847f4cd24021\",\"title\":\"Action prediction via deep residual feature learning and weighted loss\",\"url\":\"https://www.semanticscholar.org/paper/b04b5503532a69428841548e32c1847f4cd24021\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2002.03312\",\"authors\":[{\"authorId\":\"27700913\",\"name\":\"Shenlan Liu\"},{\"authorId\":\"117565367\",\"name\":\"Xiang Liu\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"48521932\",\"name\":\"L. Feng\"},{\"authorId\":null,\"name\":\"Lianyu Hu\"},{\"authorId\":\"143949784\",\"name\":\"Dong Jiang\"},{\"authorId\":\"49425435\",\"name\":\"Aibin Zhang\"},{\"authorId\":\"40457423\",\"name\":\"Y. Liu\"},{\"authorId\":\"1397156292\",\"name\":\"Hong Qiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d23441be3a8fc73413afc6d2c67db66b3686b0e3\",\"title\":\"FSD-10: A Dataset for Competitive Sports Content Analysis\",\"url\":\"https://www.semanticscholar.org/paper/d23441be3a8fc73413afc6d2c67db66b3686b0e3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2961531\",\"name\":\"M. Hosseini\"},{\"authorId\":\"145226394\",\"name\":\"F. Ghaderi\"}],\"doi\":\"10.5829/ije.2020.33.05b.29\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"title\":\"A Hybrid Deep Learning Architecture Using 3D CNNs and GRUs for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.06131\",\"authors\":[{\"authorId\":\"30184984\",\"name\":\"Randy Tan\"},{\"authorId\":\"1471390437\",\"name\":\"Naimul Khan\"},{\"authorId\":\"49210768\",\"name\":\"Ling Guan\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207559\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16615aa54126fc12ffd1cbfd79d78a821c398b6b\",\"title\":\"Locality Guided Neural Networks for Explainable Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/16615aa54126fc12ffd1cbfd79d78a821c398b6b\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"}],\"doi\":\"10.1007/978-3-030-58577-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"title\":\"Computer Vision \\u2013 ECCV 2020: 16th European Conference, Glasgow, UK, August 23\\u201328, 2020, Proceedings, Part XXX\",\"url\":\"https://www.semanticscholar.org/paper/08a578d7f7f3d0edf46470e33f92e2335d19b70b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123331898\",\"name\":\"Y. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"title\":\"Refinement of Boundary Regression Using Uncertainty in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6e60bc1a90aa660320476bd422239cfaa1d9ee5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/ICCV.2019.00092\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c17f395738bc3494974283ba9460c516a948f7ef\",\"title\":\"Toyota Smarthome: Real-World Activities of Daily Living\",\"url\":\"https://www.semanticscholar.org/paper/c17f395738bc3494974283ba9460c516a948f7ef\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"73365425\",\"name\":\"Y. Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCV.2019.00015\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3b76da17a060f1edb80b26f489f4b6256d785c57\",\"title\":\"Hierarchical Self-Attention Network for Action Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3b76da17a060f1edb80b26f489f4b6256d785c57\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"1742452\",\"name\":\"S. Battiato\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":\"10.1007/978-3-030-11021-5_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"title\":\"Leveraging Uncertainty to Rethink Loss Functions and Evaluation Measures for Egocentric Action Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/9d09701ea8c5809086fca2919400ff7f5b80ae30\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuai Wang\"},{\"authorId\":\"47824843\",\"name\":\"W. Wang\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"17b8ee04fb61ba55d5bfc0b06cf54548034fef18\",\"title\":\"RUC at MediaEval 2018: Visual and Textual Features Exploration for Predicting Media Memorability\",\"url\":\"https://www.semanticscholar.org/paper/17b8ee04fb61ba55d5bfc0b06cf54548034fef18\",\"venue\":\"MediaEval\",\"year\":2018},{\"arxivId\":\"1812.00087\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/CVPR.2019.00134\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"613f59279586bd53aed57bc133246a4eb3c38977\",\"title\":\"MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment\",\"url\":\"https://www.semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.08178\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"48696416\",\"name\":\"Y. Cao\"},{\"authorId\":\"1761508\",\"name\":\"B. Liu\"}],\"doi\":\"10.1109/ICIP.2019.8803564\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"title\":\"Multi-Stream Single Shot Spatial-Temporal Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/f0ba9505b5f625fae2a0b50c89224744f5b11207\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152674907\",\"name\":\"Lili Meng\"},{\"authorId\":\"47705564\",\"name\":\"B. Zhao\"},{\"authorId\":\"144757437\",\"name\":\"B. Chang\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"115284322\",\"name\":\"W. Sun\"},{\"authorId\":\"1402348340\",\"name\":\"Frederich Tung\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/ICCVW.2019.00189\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"title\":\"Interpretable Spatio-Temporal Attention for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2672d3b50dbf4a0e81f506a8d1d6bbb361149c2b\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1910.11105\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"145128144\",\"name\":\"Lior Wolf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f3b1e7592d91717a3cf0e9c42bd27c22ca5d3aab\",\"title\":\"Adaptive and Iteratively Improving Recurrent Lateral Connections\",\"url\":\"https://www.semanticscholar.org/paper/f3b1e7592d91717a3cf0e9c42bd27c22ca5d3aab\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49290494\",\"name\":\"Zhijie Lin\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1742291\",\"name\":\"Zixing Zhang\"},{\"authorId\":\"48805561\",\"name\":\"Zijian Zhang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2020.2965987\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"title\":\"Moment Retrieval via Cross-Modal Interaction Networks With Query Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/5a68ef4d0c1a814dd0920f6824aaad8e15339f66\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.10837\",\"authors\":[{\"authorId\":\"2447769\",\"name\":\"Chunfei Ma\"},{\"authorId\":\"32407457\",\"name\":\"Joonhyang Choi\"},{\"authorId\":\"150936578\",\"name\":\"Byeongwon Lee\"},{\"authorId\":\"3246975\",\"name\":\"Seungji Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"title\":\"Submission to ActivityNet Challenge 2019: Task B Spatio-temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a3cb1fff165f191cf2a7d3be2b9efb7cb26e3ea8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.03857\",\"authors\":[{\"authorId\":null,\"name\":\"Yufei Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"Lorenzo Torresani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"425c33485b32301df75d16cb9cd224763782da8c\",\"title\":\"UniDual: A Unified Model for Image and Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/425c33485b32301df75d16cb9cd224763782da8c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.02189\",\"authors\":[{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682466\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d63dc4f0eb83ceea8c2bfcd71300b7c12eff13a1\",\"title\":\"BLP - Boundary Likelihood Pinpointing Networks for Accurate Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d63dc4f0eb83ceea8c2bfcd71300b7c12eff13a1\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2010.07524\",\"authors\":[{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"616e4fa9ac89ef99f073aabfcdb4cc05e4407520\",\"title\":\"Unsupervised Video Anomaly Detection via Flow-based Generative Modeling on Appearance and Motion Latent Features\",\"url\":\"https://www.semanticscholar.org/paper/616e4fa9ac89ef99f073aabfcdb4cc05e4407520\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1912.04462\",\"authors\":[{\"authorId\":\"3264239\",\"name\":\"Shi-Yuan Huang\"},{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"35862299\",\"name\":\"S. Karaman\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"title\":\"Flow-Distilled IP Two-Stream Networks for Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c801bcaa007c6bf6ce4027bdb45f88f7a861db3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"144411970\",\"name\":\"J. Qin\"},{\"authorId\":\"34798935\",\"name\":\"Xiantong Zhen\"},{\"authorId\":\"144942207\",\"name\":\"Di Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3394171.3416269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27df4822497b090811c3576f17245feaee40d2ff\",\"title\":\"Few-Shot Ensemble Learning for Video Classification with SlowFast Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/27df4822497b090811c3576f17245feaee40d2ff\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"114498698\",\"name\":\"Ankush Manocha\"},{\"authorId\":\"50631862\",\"name\":\"R. Singh\"}],\"doi\":\"10.1007/s11042-019-7700-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad6493b57050955d9686b3c1fc84a19195852f8c\",\"title\":\"Computer vision based working environment monitoring to analyze Generalized Anxiety Disorder (GAD)\",\"url\":\"https://www.semanticscholar.org/paper/ad6493b57050955d9686b3c1fc84a19195852f8c\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1911.09243\",\"authors\":[{\"authorId\":null,\"name\":\"Ya Wang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145724892\",\"name\":\"Fu Li\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"1685259\",\"name\":\"Jinwen Ma\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/AAAI.V34I07.6909\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8cc97fff3292f13cfc73721dc4ae26d8f970692f\",\"title\":\"Multi-Label Classification with Label Graph Superimposing\",\"url\":\"https://www.semanticscholar.org/paper/8cc97fff3292f13cfc73721dc4ae26d8f970692f\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3076130\",\"name\":\"Keyang Cheng\"},{\"authorId\":\"1453694581\",\"name\":\"Lubamba Kasangu Eric\"},{\"authorId\":\"49503455\",\"name\":\"Rabia Tahir\"},{\"authorId\":\"47605260\",\"name\":\"M. Li\"}],\"doi\":\"10.1007/978-3-030-32456-8_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e4f8bccea93b03ceb7fbe38080a826a8f87a6dc8\",\"title\":\"Capsule Recurrent Neural Network with Weight Update Using Dynamic Routing by Agreement: A Unified Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e4f8bccea93b03ceb7fbe38080a826a8f87a6dc8\",\"venue\":\"ICNC-FSKD\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.5220/0008345900110013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68e12c2f62a1d7a177172148711e0f83ae48d918\",\"title\":\"A Fine-grained Perspective onto Object Interactions from First-person Views\",\"url\":\"https://www.semanticscholar.org/paper/68e12c2f62a1d7a177172148711e0f83ae48d918\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1904.09140\",\"authors\":[{\"authorId\":\"2505740\",\"name\":\"Dennis Ludl\"},{\"authorId\":\"7932331\",\"name\":\"T. Gulde\"},{\"authorId\":\"8045043\",\"name\":\"C. Curio\"}],\"doi\":\"10.1109/ITSC.2019.8917128\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"title\":\"Simple yet efficient real-time pose-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f889fe0875881b3cfa7a424eaf99f7dfd02738ce\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66425285\",\"name\":\"Akash Panchal\"},{\"authorId\":\"48756948\",\"name\":\"H. Trivedi\"},{\"authorId\":\"101106680\",\"name\":\"M. Rajput\"},{\"authorId\":\"144027193\",\"name\":\"D. Trivedi\"}],\"doi\":\"10.1007/978-981-15-3369-3_65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3eb1ee19f1312c0a7e4cf8459ff260039968342\",\"title\":\"Activity Recognition Using Temporal Features and Deep Bottleneck 3D-ResNeXt\",\"url\":\"https://www.semanticscholar.org/paper/a3eb1ee19f1312c0a7e4cf8459ff260039968342\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.07203\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"40052301\",\"name\":\"F. Petroni\"},{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"title\":\"Video Understanding as Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/a2bf96de7889360dce11b9fc80f578a56e63dcfc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1752781688\",\"name\":\"Siyuan Yang\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"50345079\",\"name\":\"Shijian Lu\"},{\"authorId\":\"9412318\",\"name\":\"M. Er\"},{\"authorId\":\"1711097\",\"name\":\"A. Kot\"}],\"doi\":\"10.1007/978-3-030-58580-8_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dcafbfa5030fe96fb7e39764d72742ccb58dc6a2\",\"title\":\"Collaborative Learning of Gesture Recognition and 3D Hand Pose Estimation with Multi-order Feature Analysis\",\"url\":\"https://www.semanticscholar.org/paper/dcafbfa5030fe96fb7e39764d72742ccb58dc6a2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.14285\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"1762890\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"},{\"authorId\":\"144387904\",\"name\":\"S. Chakraborty\"},{\"authorId\":\"1804334\",\"name\":\"Prudhvi Gurram\"},{\"authorId\":\"151479420\",\"name\":\"Richard Tomsett\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab170d55c661bf7cf5868ca82b67a3d6fed758d2\",\"title\":\"Explaining Motion Relevance for Activity Recognition in Video Deep Learning Models\",\"url\":\"https://www.semanticscholar.org/paper/ab170d55c661bf7cf5868ca82b67a3d6fed758d2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.08732\",\"authors\":[{\"authorId\":\"50811450\",\"name\":\"Kranti K. Parida\"},{\"authorId\":\"31352334\",\"name\":\"Neeraj Matiyali\"},{\"authorId\":\"1720741\",\"name\":\"T. Guha\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV45572.2020.9093438\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a243ee80146ca37fc296bc67043ea2a67222de68\",\"title\":\"Coordinated Joint Multimodal Embeddings for Generalized Audio-Visual Zero-shot Classification and Retrieval of Videos\",\"url\":\"https://www.semanticscholar.org/paper/a243ee80146ca37fc296bc67043ea2a67222de68\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2001.08740\",\"authors\":[{\"authorId\":\"2299381\",\"name\":\"Fanyi Xiao\"},{\"authorId\":\"144756076\",\"name\":\"Y. Lee\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"153652147\",\"name\":\"J. Malik\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80685dc522d30b18f3feb97d6c977f71fa746325\",\"title\":\"Audiovisual SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80685dc522d30b18f3feb97d6c977f71fa746325\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1772198\",\"name\":\"X. Wu\"},{\"authorId\":\"3307319\",\"name\":\"Qing-Ge Ji\"}],\"doi\":\"10.1145/3426826.3426836\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"title\":\"Split and Attentive-Aggregated Learnable Shift Module for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64469e496132f3e25cdc5bfcfb3b7069c5e15ac4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.07519\",\"authors\":[{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"title\":\"Higher-order Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41ab8c0c47dd8fce41dbe904ab78ed1a7320dfd6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49898078\",\"name\":\"Xierong Zhu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.24963/ijcai.2020/105\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"title\":\"Multi-Scale Spatial-Temporal Integration Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4fb429109591a5d20136fe884b5fd7c7584a62c\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"2012.10671\",\"authors\":[{\"authorId\":\"152957752\",\"name\":\"Shreyank N Gowda\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"title\":\"SMART Frame Selection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c062be0a5ba96b5d0cd606d2eeacd768845a116\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13726\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00017\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"title\":\"Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":\"2012.00514\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"39523424\",\"name\":\"Tiffany Yau\"},{\"authorId\":\"145367501\",\"name\":\"M. Rohani\"},{\"authorId\":\"151488623\",\"name\":\"J. Luo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fe1fa0cf2a49a4a40be3e99f55170306314029f\",\"title\":\"Multi-Modal Hybrid Architecture for Pedestrian Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/2fe1fa0cf2a49a4a40be3e99f55170306314029f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.08434\",\"authors\":[{\"authorId\":\"3471257\",\"name\":\"Xinqian Gu\"},{\"authorId\":\"120076009\",\"name\":\"H. Chang\"},{\"authorId\":\"1798982\",\"name\":\"Bingpeng Ma\"},{\"authorId\":\"1490939067\",\"name\":\"Hongkai Zhang\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-58536-5_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"468c12b1ff6a5c4f2630cdbaca214e6df0c935cc\",\"title\":\"Appearance-Preserving 3D Convolution for Video-based Person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/468c12b1ff6a5c4f2630cdbaca214e6df0c935cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2009.02568\",\"authors\":[{\"authorId\":\"117232498\",\"name\":\"Anelise Newman\"},{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"24026083\",\"name\":\"Vincent Casser\"},{\"authorId\":\"123872529\",\"name\":\"Allen Lee\"},{\"authorId\":\"47276980\",\"name\":\"Barry\"},{\"authorId\":\"46498555\",\"name\":\"Mcnamara\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1007/978-3-030-58517-4_14\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"203bfa5e488a9c3100e3d9b9af5ea34537068612\",\"title\":\"Multimodal Memorability: Modeling Effects of Semantics and Decay on Video Memorability\",\"url\":\"https://www.semanticscholar.org/paper/203bfa5e488a9c3100e3d9b9af5ea34537068612\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.06232\",\"authors\":[{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"1782475\",\"name\":\"G. Swirszcz\"},{\"authorId\":\"153062108\",\"name\":\"J. Carreira\"},{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"}],\"doi\":\"10.1109/cvpr42600.2020.01185\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"title\":\"Sideways: Depth-Parallel Training of Video Models\",\"url\":\"https://www.semanticscholar.org/paper/21f96afef802b3e00edd9bb8c4b71fc3f0cc43df\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.08271\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d87489d2facf197caafd24d0796523d55d47fb62\",\"title\":\"A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer\",\"url\":\"https://www.semanticscholar.org/paper/d87489d2facf197caafd24d0796523d55d47fb62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.05078\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"1471708751\",\"name\":\"M. Malinowski\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01086\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"title\":\"Visual Grounding in Video for Unsupervised Word Translation\",\"url\":\"https://www.semanticscholar.org/paper/a1f1d17a350d30d55de52b15c9fe7fea4ba6ff13\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.1007/978-3-030-24289-3_26\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a2c302047b5c0b66e0be4594200006d93c30c565\",\"title\":\"Human Action Recognition Using Convolutional Neural Networks with Symmetric Time Extension of Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a2c302047b5c0b66e0be4594200006d93c30c565\",\"venue\":\"ICCSA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685776\",\"name\":\"Y. Li\"},{\"authorId\":\"1695600\",\"name\":\"X. Chai\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-20876-9_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a34f44e3890e8fa1dbf9456375ed5c32afb76e0\",\"title\":\"ScoringNet: Learning Key Fragment for Action Quality Assessment with Ranking Loss in Skilled Sports\",\"url\":\"https://www.semanticscholar.org/paper/2a34f44e3890e8fa1dbf9456375ed5c32afb76e0\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6321439\",\"name\":\"J. Korndorffer\"},{\"authorId\":\"6328870\",\"name\":\"M. Hawn\"},{\"authorId\":\"2591561\",\"name\":\"D. Spain\"},{\"authorId\":\"7647336\",\"name\":\"Lisa M Knowlton\"},{\"authorId\":\"50389795\",\"name\":\"D. E. Azagury\"},{\"authorId\":\"31833906\",\"name\":\"Aussama K Nassar\"},{\"authorId\":\"31776090\",\"name\":\"J. Lau\"},{\"authorId\":\"3794129\",\"name\":\"Katherine D. Arnow\"},{\"authorId\":\"3994955\",\"name\":\"A. Trickey\"},{\"authorId\":\"2575546\",\"name\":\"C. Pugh\"}],\"doi\":\"10.1097/SLA.0000000000004207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fc0b98ceb7a1d3bc57f6c34f46bf96d8cae2af5\",\"title\":\"Situating Artificial Intelligence in Surgery\",\"url\":\"https://www.semanticscholar.org/paper/2fc0b98ceb7a1d3bc57f6c34f46bf96d8cae2af5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1811.09128\",\"authors\":[{\"authorId\":\"3194878\",\"name\":\"Chaoyun Zhang\"},{\"authorId\":\"1704992\",\"name\":\"R. Li\"},{\"authorId\":\"40348926\",\"name\":\"W. Kim\"},{\"authorId\":\"1705580\",\"name\":\"D. Yoon\"},{\"authorId\":\"144555592\",\"name\":\"Paul Patras\"}],\"doi\":\"10.1109/ACCESS.2020.3032344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01a572a8d3994458b30fd3a4a42cd4b6881240e4\",\"title\":\"Driver Behavior Recognition via Interwoven Deep Convolutional Neural Nets With Multi-Stream Inputs\",\"url\":\"https://www.semanticscholar.org/paper/01a572a8d3994458b30fd3a4a42cd4b6881240e4\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1391970001\",\"name\":\"Tim Pollert\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"143985656\",\"name\":\"Manuel Martin\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/CVPRW.2019.00029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"942942c74fb0230207ef1640144e885e5cfe76d3\",\"title\":\"Analysis of Deep Fusion Strategies for Multi-Modal Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/942942c74fb0230207ef1640144e885e5cfe76d3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1711.07971\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/CVPR.2018.00813\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8899094797e82c5c185a0893896320ef77f60e64\",\"title\":\"Non-local Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8899094797e82c5c185a0893896320ef77f60e64\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.07563\",\"authors\":[{\"authorId\":\"74480447\",\"name\":\"Manjot Bilkhu\"},{\"authorId\":\"87779441\",\"name\":\"H. Ayyubi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d29074a0e2dee3d394b51669a9ec5297c008e469\",\"title\":\"Human Activity Recognition for Edge Devices\",\"url\":\"https://www.semanticscholar.org/paper/d29074a0e2dee3d394b51669a9ec5297c008e469\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1388870641\",\"name\":\"Patrick Gebert\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/IVS.2019.8814249\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d4901f667458a3a2144fe42e965ed43b7dbe995a\",\"title\":\"End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d4901f667458a3a2144fe42e965ed43b7dbe995a\",\"venue\":\"2019 IEEE Intelligent Vehicles Symposium (IV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"49897466\",\"name\":\"Xiaotian Zhu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICMEW.2018.8551526\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35cbb64d46dfa3e74aea367a173dcb94cb6125c4\",\"title\":\"Weighted Multi-Region Convolutional Neural Network for Action Recognition With Low-Latency Online Prediction\",\"url\":\"https://www.semanticscholar.org/paper/35cbb64d46dfa3e74aea367a173dcb94cb6125c4\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"1911.09989\",\"authors\":[{\"authorId\":\"1429191721\",\"name\":\"Menatallh Hammad\"},{\"authorId\":\"1429191719\",\"name\":\"May Hammad\"},{\"authorId\":\"31358369\",\"name\":\"M. ElShenawy\"}],\"doi\":\"10.1007/978-3-030-59830-3_21\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86ac173f03a5dbfb1d64a84759aa920ed6c1aec1\",\"title\":\"Characterizing the impact of using features extracted from pre-trained models on the quality of video captioning sequence-to-sequence models\",\"url\":\"https://www.semanticscholar.org/paper/86ac173f03a5dbfb1d64a84759aa920ed6c1aec1\",\"venue\":\"ICPRAI\",\"year\":2020},{\"arxivId\":\"1908.05786\",\"authors\":[{\"authorId\":\"41018180\",\"name\":\"Kyle Min\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":\"10.1109/ICCV.2019.00248\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"title\":\"TASED-Net: Temporally-Aggregating Spatial Encoder-Decoder Network for Video Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/5b93aaf71e4c18d304ab9b3e77598cb0423d0952\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"73441024\",\"name\":\"Q. Wang\"},{\"authorId\":\"47319805\",\"name\":\"S. Li\"},{\"authorId\":\"143767587\",\"name\":\"X. Niu\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1007/978-3-030-00767-6_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb4d7a18909979d93ed26f7d33b98adb7cf1bfc5\",\"title\":\"Frame Segmentation Networks for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/eb4d7a18909979d93ed26f7d33b98adb7cf1bfc5\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2008.03014\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"145026397\",\"name\":\"Ashis G. Banerjee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab70651a16a217e2d4d7d33d3a20a42762768ae7\",\"title\":\"A Multi-Task Learning Approach for Human Action Detection and Ergonomics Risk Assessment\",\"url\":\"https://www.semanticscholar.org/paper/ab70651a16a217e2d4d7d33d3a20a42762768ae7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6624871\",\"name\":\"Dmytro Tkachenko\"}],\"doi\":\"10.29007/WJ5T\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e7f320bb31be1f41d7d33d2eccdd4a96a526ca8\",\"title\":\"Human Action Recognition Using Fusion of Modern Deep Convolutional and Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8e7f320bb31be1f41d7d33d2eccdd4a96a526ca8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8092281\",\"name\":\"Hai-Hong Phan\"},{\"authorId\":\"9923528\",\"name\":\"Chi Trung Ha\"},{\"authorId\":\"47523551\",\"name\":\"T. T. Nguy\\u1ec5n\"}],\"doi\":\"10.1109/MAPR49794.2020.9237772\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"title\":\"Improving the efficiency of human action recognition using deep compression\",\"url\":\"https://www.semanticscholar.org/paper/14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"venue\":\"2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097122\",\"name\":\"Y. Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"9359893\",\"name\":\"Shengrong Gong\"}],\"doi\":\"10.1145/3378026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e075864cdf19117f6b5f78db877347e2bca4f\",\"title\":\"Spatio-temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/083e075864cdf19117f6b5f78db877347e2bca4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1853983930\",\"name\":\"Aparna Kanakatte\"},{\"authorId\":\"34041171\",\"name\":\"Akshaya Ramaswamy\"},{\"authorId\":\"49294154\",\"name\":\"J. Gubbi\"},{\"authorId\":\"38033709\",\"name\":\"A. Ghose\"},{\"authorId\":\"1854047279\",\"name\":\"Balamuralidhar Purushothaman\"}],\"doi\":\"10.1109/EMBC44109.2020.9176676\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3678ba1865ebd7a6f123712f12b7f2d26b8ce89\",\"title\":\"Surgical tool segmentation and localization using spatio-temporal deep network\",\"url\":\"https://www.semanticscholar.org/paper/c3678ba1865ebd7a6f123712f12b7f2d26b8ce89\",\"venue\":\"2020 42nd Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\",\"year\":2020},{\"arxivId\":\"2004.06971\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e389ac072b25305c8f17af292ede43115479077a\",\"title\":\"ActionSpotter: Deep Reinforcement Learning Framework for Temporal Action Spotting in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e389ac072b25305c8f17af292ede43115479077a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33685943\",\"name\":\"Mayoore S. Jaiswal\"},{\"authorId\":\"144222336\",\"name\":\"H. P. Hofstee\"},{\"authorId\":\"15110752\",\"name\":\"V. Chen\"},{\"authorId\":\"21080039\",\"name\":\"Suvadip Paul\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"153035546\",\"name\":\"F. Liu\"},{\"authorId\":\"2055404\",\"name\":\"A. Jagannathan\"},{\"authorId\":\"32272278\",\"name\":\"A. Gattiker\"},{\"authorId\":\"152565412\",\"name\":\"Inseok Hwang\"},{\"authorId\":\"48052648\",\"name\":\"J. Lee\"},{\"authorId\":\"11398739\",\"name\":\"M. Tong\"},{\"authorId\":\"1382198044\",\"name\":\"Sahil Dureja\"},{\"authorId\":\"4353428\",\"name\":\"Soham Shah\"}],\"doi\":\"10.1109/ICCVW.2019.00188\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8873d1369590249113e1f0491ce49d1502395b9c\",\"title\":\"Video-Text Compliance: Activity Verification Based on Natural Language Instructions\",\"url\":\"https://www.semanticscholar.org/paper/8873d1369590249113e1f0491ce49d1502395b9c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51244018\",\"name\":\"Mihai Gabriel Constantin\"},{\"authorId\":\"47695213\",\"name\":\"Chen Kang\"},{\"authorId\":\"96211746\",\"name\":\"G. Dinu\"},{\"authorId\":\"50987240\",\"name\":\"Fr\\u00e9d\\u00e9ric Dufaux\"},{\"authorId\":\"1680080\",\"name\":\"Giuseppe Valenzise\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e9a81ccdb95872d15d7ab38a6c738355aa96cdd1\",\"title\":\"Using Aesthetics and Action Recognition-Based Networks for the Prediction of Media Memorability\",\"url\":\"https://www.semanticscholar.org/paper/e9a81ccdb95872d15d7ab38a6c738355aa96cdd1\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":\"2008.12085\",\"authors\":[{\"authorId\":\"2088061\",\"name\":\"Juan Diego Ortega\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"1910490649\",\"name\":\"Paola Canas\"},{\"authorId\":\"3319539\",\"name\":\"Min-An Chao\"},{\"authorId\":\"71814613\",\"name\":\"A. Unnervik\"},{\"authorId\":\"144931363\",\"name\":\"M. Nieto\"},{\"authorId\":\"2353401\",\"name\":\"O. Otaegui\"},{\"authorId\":\"144180623\",\"name\":\"L. Salgado\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"89764b01e004ad39256e0351fef9acea3eecf747\",\"title\":\"DMD: A Large-Scale Multi-Modal Driver Monitoring Dataset for Attention and Alertness Analysis\",\"url\":\"https://www.semanticscholar.org/paper/89764b01e004ad39256e0351fef9acea3eecf747\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.02182\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"40521893\",\"name\":\"Abir Das\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/TPAMI.2019.2921539\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95138f276b34cc84695b64ee5fc00c1e27091497\",\"title\":\"Two-Stream Region Convolutional 3D Network for Temporal Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/95138f276b34cc84695b64ee5fc00c1e27091497\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51033208\",\"name\":\"B. Liu\"},{\"authorId\":\"3451334\",\"name\":\"Michelle Guo\"},{\"authorId\":\"34613203\",\"name\":\"Edward Chou\"},{\"authorId\":\"24126456\",\"name\":\"Rishab Mehra\"},{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"3225040\",\"name\":\"N. L. Downing\"},{\"authorId\":\"13454501\",\"name\":\"Francesca Salipur\"},{\"authorId\":\"50165568\",\"name\":\"Jeffrey Jopling\"},{\"authorId\":\"35678076\",\"name\":\"Brian Campbell\"},{\"authorId\":\"6535683\",\"name\":\"K. Deru\"},{\"authorId\":\"2066361\",\"name\":\"W. Beninati\"},{\"authorId\":\"46802048\",\"name\":\"A. Milstein\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0ffc8feb93f0c3240bcdf155e665009276f75d6\",\"title\":\"D Point Cloud-Based Visual Prediction of ICU Mobility Care Activities 3 D Point Cloud-Based Visual Prediction of ICU Mobility Care Activities\",\"url\":\"https://www.semanticscholar.org/paper/a0ffc8feb93f0c3240bcdf155e665009276f75d6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.11009\",\"authors\":[{\"authorId\":\"47424372\",\"name\":\"Yu Xiong\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"10357054\",\"name\":\"L. Guo\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2019.00469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87699cff38982712ddb0b2349313077779a5d0ff\",\"title\":\"A Graph-Based Framework to Bridge Movies and Synopses\",\"url\":\"https://www.semanticscholar.org/paper/87699cff38982712ddb0b2349313077779a5d0ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.11102\",\"authors\":[{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1923156\",\"name\":\"Peng Yao\"},{\"authorId\":\"1749850\",\"name\":\"Jing Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shichen Lu\"},{\"authorId\":\"2125223\",\"name\":\"Zheng Gen Yu\"},{\"authorId\":\"46641690\",\"name\":\"Wei Liu\"},{\"authorId\":\"46386029\",\"name\":\"Hanqing Lu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"title\":\"Multi-View Features and Hybrid Reward Strategies for Vatex Video Captioning Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/1ae6fc431791e0daa8bfb3b195acdba4535cf07c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"837e732e09bcb47d31dc9ef4293b97a05b07bedd\",\"title\":\"Multimodal Deep Neural Networks for Pose Estimation and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/837e732e09bcb47d31dc9ef4293b97a05b07bedd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1807.10706\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01219-9_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1786d26835e0add50c013ef5089afc5ff5796e1e\",\"title\":\"Diagnosing Error in Temporal Action Detectors\",\"url\":\"https://www.semanticscholar.org/paper/1786d26835e0add50c013ef5089afc5ff5796e1e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"100856944\",\"name\":\"Muhammad Zeeshan Khan\"},{\"authorId\":\"46714878\",\"name\":\"Muhammad Khairul Ali Hassan\"},{\"authorId\":\"32824146\",\"name\":\"Ammarah Farooq\"},{\"authorId\":\"113607553\",\"name\":\"Muhammad Usman Ghanni Khan\"}],\"doi\":\"10.1109/ICAEM.2018.8536277\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6aa9f29b43e76049c3b302e373ebd010c4187df5\",\"title\":\"Deep CNN Based Data-Driven Recognition of Cricket Batting Shots\",\"url\":\"https://www.semanticscholar.org/paper/6aa9f29b43e76049c3b302e373ebd010c4187df5\",\"venue\":\"2018 International Conference on Applied and Engineering Mathematics (ICAEM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10029285\",\"name\":\"Nieves Crasto\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"47e1b171fab52368f14f41955cdc7ca7775ded58\",\"title\":\"RGB TVL 1 Flow RGB + TVL 1 FlowMARS MARS + RGB MERS MERS + RGB Accuracy vs Time on MiniKinetics\",\"url\":\"https://www.semanticscholar.org/paper/47e1b171fab52368f14f41955cdc7ca7775ded58\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47781687\",\"name\":\"Z. Liu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1007/s11063-018-09972-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"33c615be88df63dfd0e8f1b770066f062ee8d157\",\"title\":\"Spatiotemporal Fusion Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33c615be88df63dfd0e8f1b770066f062ee8d157\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24638beb5e24c2df424dab16cd715ebce1dda9ab\",\"title\":\"Discriminative Subspace Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24638beb5e24c2df424dab16cd715ebce1dda9ab\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1906.06521\",\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfdd73269882b6d512786f64118a305aea18e43b\",\"title\":\"Delving into 3D Action Anticipation from Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/bfdd73269882b6d512786f64118a305aea18e43b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.03863\",\"authors\":[{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1756112\",\"name\":\"Viorica Patraucean\"},{\"authorId\":\"1807336\",\"name\":\"L. Mazar\\u00e9\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"2217144\",\"name\":\"Simon Osindero\"}],\"doi\":\"10.1007/978-3-030-01225-0_40\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3254692e2794ef8c8f96374aadb27c3f3926492e\",\"title\":\"Massively Parallel Video Networks\",\"url\":\"https://www.semanticscholar.org/paper/3254692e2794ef8c8f96374aadb27c3f3926492e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"1390793590\",\"name\":\"Peike Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"9929684\",\"name\":\"Xuanyi Dong\"},{\"authorId\":\"1732242\",\"name\":\"Y. Liu\"},{\"authorId\":\"79327094\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ceb2523aad0510881cada1b9476840b24a564fcf\",\"title\":\"Activities in Extended Video\",\"url\":\"https://www.semanticscholar.org/paper/ceb2523aad0510881cada1b9476840b24a564fcf\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":\"2004.01278\",\"authors\":[{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"3098817\",\"name\":\"Antoine Toisoul\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"title\":\"Knowing What, Where and When to Look: Efficient Video Action Modeling with Attention\",\"url\":\"https://www.semanticscholar.org/paper/8fcc3c2e525307f7a694979500dcca09d0f3a830\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10774\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"1648707714\",\"name\":\"Qazi Ammar Arshad\"},{\"authorId\":\"144212662\",\"name\":\"Chen Chen\"}],\"doi\":\"10.1007/978-3-030-03243-2_846-1\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"54e3ff4cad99d691ecb613b384d311cd411569b9\",\"title\":\"Action recognition in real-world videos\",\"url\":\"https://www.semanticscholar.org/paper/54e3ff4cad99d691ecb613b384d311cd411569b9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.01764\",\"authors\":[{\"authorId\":\"1829964\",\"name\":\"Rares Ambrus\"},{\"authorId\":\"9370721\",\"name\":\"V. Guizilini\"},{\"authorId\":\"47786973\",\"name\":\"J. Li\"},{\"authorId\":\"1769274\",\"name\":\"S. Pillai\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8057875a74d959e769d037764f2da81c060b25a1\",\"title\":\"Two Stream Networks for Self-Supervised Ego-Motion Estimation\",\"url\":\"https://www.semanticscholar.org/paper/8057875a74d959e769d037764f2da81c060b25a1\",\"venue\":\"CoRL\",\"year\":2019},{\"arxivId\":\"2007.12898\",\"authors\":[{\"authorId\":\"88013848\",\"name\":\"D. Korat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3bc8e66102fefd8c6c6f6e577fa668a35dab9117\",\"title\":\"3D Neural Network for Lung Cancer Risk Prediction on CT Volumes\",\"url\":\"https://www.semanticscholar.org/paper/3bc8e66102fefd8c6c6f6e577fa668a35dab9117\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978827882\",\"name\":\"Dighanchal Banerjee\"},{\"authorId\":\"2528842\",\"name\":\"Smriti Rani\"},{\"authorId\":\"46572037\",\"name\":\"A. George\"},{\"authorId\":\"1477950964\",\"name\":\"Arijit Chowdhury\"},{\"authorId\":\"151478793\",\"name\":\"S. Dey\"},{\"authorId\":\"37840630\",\"name\":\"A. Mukherjee\"},{\"authorId\":\"145622300\",\"name\":\"T. Chakravarty\"},{\"authorId\":\"47178669\",\"name\":\"A. Pal\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206853\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ae872ebb4427e1d97672631f0caadc8799387faa\",\"title\":\"Application of Spiking Neural Networks for Action Recognition from Radar Data\",\"url\":\"https://www.semanticscholar.org/paper/ae872ebb4427e1d97672631f0caadc8799387faa\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1516175879\",\"name\":\"Amin Ullah\"},{\"authorId\":\"147236005\",\"name\":\"Khan Muhammad\"},{\"authorId\":\"1978767682\",\"name\":\"Killichbek Haydarov\"},{\"authorId\":\"29438845\",\"name\":\"I. Haq\"},{\"authorId\":\"39468622\",\"name\":\"Miyoung Lee\"},{\"authorId\":\"1777998\",\"name\":\"S. Baik\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207595\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6684ccafd3efae18df2ae9269d0c333bffc1eaf\",\"title\":\"One-Shot Learning for Surveillance Anomaly Recognition using Siamese 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/e6684ccafd3efae18df2ae9269d0c333bffc1eaf\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"2002.09423\",\"authors\":[{\"authorId\":\"31915818\",\"name\":\"D. Torpey\"},{\"authorId\":\"48627696\",\"name\":\"T. \\u00c7elik\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e7f485a76d95127158683b7bbe386df98394f42\",\"title\":\"Human Action Recognition using Local Two-Stream Convolution Neural Network Features and Support Vector Machines\",\"url\":\"https://www.semanticscholar.org/paper/5e7f485a76d95127158683b7bbe386df98394f42\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.07485\",\"authors\":[{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1109/CVPR.2018.00624\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1e55e9c647832c969e449da28a391205a9704c60\",\"title\":\"Actor and Action Video Segmentation from a Sentence\",\"url\":\"https://www.semanticscholar.org/paper/1e55e9c647832c969e449da28a391205a9704c60\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2005.00253\",\"authors\":[{\"authorId\":\"19263938\",\"name\":\"Elahe Vahdani\"},{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"145587605\",\"name\":\"Y. Tian\"},{\"authorId\":\"1747703\",\"name\":\"Matt Huenerfauth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"206beeef56a1cb5409d5b5a4395255ffe9c38bbe\",\"title\":\"Recognizing American Sign Language Nonmanual Signal Grammar Errors in Continuous Videos\",\"url\":\"https://www.semanticscholar.org/paper/206beeef56a1cb5409d5b5a4395255ffe9c38bbe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"},{\"authorId\":\"51066371\",\"name\":\"Yuli Chen\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"47767769\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"},{\"authorId\":\"144401327\",\"name\":\"Jing Deng\"}],\"doi\":\"10.1007/s11042-020-09137-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"title\":\"XwiseNet: action recognition with Xwise separable convolutions\",\"url\":\"https://www.semanticscholar.org/paper/08a34d85465a3ee611d8bc48ae3083f578f6833d\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2004.04968\",\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1628244042\",\"name\":\"Tenga Wakamiya\"},{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"title\":\"Would Mega-scale Datasets Further Enhance Spatiotemporal 3D CNNs?\",\"url\":\"https://www.semanticscholar.org/paper/4b1ca549b3378ff8ae52db1528f9f7402544cfd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143954557\",\"name\":\"J. Jones\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"2803071\",\"name\":\"S. Khudanpur\"}],\"doi\":\"10.1109/WACV.2019.00051\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ecf6fc2c42d83ca7fe18fdb6dd8c9b8770f9baca\",\"title\":\"Toward Computer Vision Systems That Understand Real-World Assembly Processes\",\"url\":\"https://www.semanticscholar.org/paper/ecf6fc2c42d83ca7fe18fdb6dd8c9b8770f9baca\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702644\",\"name\":\"H. Zhang\"},{\"authorId\":\"1888678\",\"name\":\"Miao Xin\"},{\"authorId\":\"49185004\",\"name\":\"Shuhang Wang\"},{\"authorId\":\"46285365\",\"name\":\"Yifan Yang\"},{\"authorId\":\"36794849\",\"name\":\"L. Zhang\"},{\"authorId\":\"2512046\",\"name\":\"Helong Wang\"}],\"doi\":\"10.1007/s00138-018-0956-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"title\":\"End-to-end temporal attention extraction and human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e8a150b743d487e9dbf6e023b0928f03b2c39aef\",\"venue\":\"Machine Vision and Applications\",\"year\":2018},{\"arxivId\":\"2010.00263\",\"authors\":[{\"authorId\":\"37923017\",\"name\":\"Miriam Bellver\"},{\"authorId\":\"38478804\",\"name\":\"C. Ventura\"},{\"authorId\":\"2490430\",\"name\":\"Carina Silberer\"},{\"authorId\":\"40954941\",\"name\":\"Ioannis Kazakos\"},{\"authorId\":\"144345280\",\"name\":\"J. Torres\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"574cfdc454a6b44026fcbc5539127ca507ca3045\",\"title\":\"RefVOS: A Closer Look at Referring Expressions for Video Object Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/574cfdc454a6b44026fcbc5539127ca507ca3045\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.14303\",\"authors\":[{\"authorId\":\"48009996\",\"name\":\"Yitian Yuan\"},{\"authorId\":\"152309770\",\"name\":\"Lin Ma\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"145583985\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1109/tpami.2020.3038993\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"613634071acd170fe5c20600f8d49662a8c3b23f\",\"title\":\"Semantic Conditioned Dynamic Modulation for Temporal Sentence Grounding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/613634071acd170fe5c20600f8d49662a8c3b23f\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.10759\",\"authors\":[{\"authorId\":\"2028192777\",\"name\":\"Faizaan Sakib\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f200eb3aae73c4626fd239fe15ab1fe5a1e957c3\",\"title\":\"Visual Recognition of Great Ape Behaviours in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/f200eb3aae73c4626fd239fe15ab1fe5a1e957c3\",\"venue\":\"ICPR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"}],\"doi\":\"10.1007/978-981-15-1816-4_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c426717bed63d0afdfb16dd98c8cba915f52853\",\"title\":\"Action Recognition in Videos Using Multi-stream Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0c426717bed63d0afdfb16dd98c8cba915f52853\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04538\",\"authors\":[{\"authorId\":\"115023832\",\"name\":\"Zhi-Kai Chen\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2852872\",\"name\":\"S. Pang\"},{\"authorId\":\"51004368\",\"name\":\"Y. He\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b9f01b9054517581a675fb919850ad558d4640d7\",\"title\":\"Appending Adversarial Frames for Universal Video Attack\",\"url\":\"https://www.semanticscholar.org/paper/b9f01b9054517581a675fb919850ad558d4640d7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.10027\",\"authors\":[{\"authorId\":\"3195774\",\"name\":\"Waqas Sultani\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a9a80cbddaa54002fce1345523960a0f02550e86\",\"title\":\"Human Action Recognition in Drone Videos using a Few Aerial Training Examples\",\"url\":\"https://www.semanticscholar.org/paper/a9a80cbddaa54002fce1345523960a0f02550e86\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.05085\",\"authors\":[{\"authorId\":\"40192003\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1145/3240508.3240534\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"title\":\"Temporal Sequence Distillation: Towards Few-Frame Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2012.08508\",\"authors\":[{\"authorId\":\"1399191196\",\"name\":\"David Ding\"},{\"authorId\":\"145783676\",\"name\":\"Felix Hill\"},{\"authorId\":\"35030998\",\"name\":\"A. Santoro\"},{\"authorId\":\"46378362\",\"name\":\"M. Botvinick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02791e807dc9a91f854a1f3d5f6005122a546109\",\"title\":\"Object-based attention for spatio-temporal reasoning: Outperforming neuro-symbolic models with flexible distributed architectures\",\"url\":\"https://www.semanticscholar.org/paper/02791e807dc9a91f854a1f3d5f6005122a546109\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1811.08362\",\"authors\":[{\"authorId\":\"91060830\",\"name\":\"Zhiyu Yao\"},{\"authorId\":null,\"name\":\"Yunbo Wang\"},{\"authorId\":\"35776445\",\"name\":\"Mingsheng Long\"},{\"authorId\":\"1519286448\",\"name\":\"J. Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"153552276\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/ICME46284.2020.9102724\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"title\":\"Multi-Task Learning of Generalizable Representations for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/371ab565b512a5ef9133831c8b7b04fb5b1905c4\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"1811.07503\",\"authors\":[{\"authorId\":\"143749869\",\"name\":\"Y. Pan\"},{\"authorId\":\"1703302\",\"name\":\"J. Xu\"},{\"authorId\":\"50468674\",\"name\":\"M. Wang\"},{\"authorId\":\"7173620\",\"name\":\"Jinmian Ye\"},{\"authorId\":\"39586294\",\"name\":\"Fei Wang\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"},{\"authorId\":\"1683510\",\"name\":\"Zenglin Xu\"}],\"doi\":\"10.1609/aaai.v33i01.33014683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"title\":\"Compressing Recurrent Neural Networks with Tensor Ring for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/23b7d6a9fce5732ca5c5e11a3f42e17860ef05ad\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1804.07667\",\"authors\":[{\"authorId\":\"2820136\",\"name\":\"Yu-Wei Chao\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"2535887\",\"name\":\"Bryan Seybold\"},{\"authorId\":\"144711958\",\"name\":\"D. Ross\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"}],\"doi\":\"10.1109/CVPR.2018.00124\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e85c01ff4979357b428538c9f224fa4259541c1a\",\"title\":\"Rethinking the Faster R-CNN Architecture for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e85c01ff4979357b428538c9f224fa4259541c1a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1109/CVPR.2018.00772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3586c182a3450f6eea4d64d69217383bae77e6c1\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/3586c182a3450f6eea4d64d69217383bae77e6c1\",\"venue\":\"CVPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120425481\",\"name\":\"Sohee Park\"},{\"authorId\":\"120736326\",\"name\":\"A. Bhattacharya\"},{\"authorId\":\"48598731\",\"name\":\"Zhibo Yang\"},{\"authorId\":\"48374961\",\"name\":\"Mallesham Dasari\"},{\"authorId\":\"1691843\",\"name\":\"Samir R Das\"},{\"authorId\":\"1686020\",\"name\":\"D. Samaras\"}],\"doi\":\"10.23919/IFIPNetworking46909.2019.8999460\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea47c6281000429bb43bc50e9585cb8ec185a1eb\",\"title\":\"Advancing user quality of experience in 360-degree video streaming\",\"url\":\"https://www.semanticscholar.org/paper/ea47c6281000429bb43bc50e9585cb8ec185a1eb\",\"venue\":\"2019 IFIP Networking Conference (IFIP Networking)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2186316\",\"name\":\"H. Chen\"},{\"authorId\":\"3102340\",\"name\":\"Mingcong Song\"},{\"authorId\":\"9693830\",\"name\":\"J. Zhao\"},{\"authorId\":\"145279386\",\"name\":\"Yuting Dai\"},{\"authorId\":null,\"name\":\"Tao Li\"}],\"doi\":\"10.1145/3307650.3322260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0ad728e01d83ff880bd63735a0fc2156e908fd53\",\"title\":\"3D-based Video Recognition Acceleration by Leveraging Temporal Locality\",\"url\":\"https://www.semanticscholar.org/paper/0ad728e01d83ff880bd63735a0fc2156e908fd53\",\"venue\":\"2019 ACM/IEEE 46th Annual International Symposium on Computer Architecture (ISCA)\",\"year\":2019},{\"arxivId\":\"1804.03247\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2018.00226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7404a8d77ba515633b61c68164210d3422d0aaf0\",\"title\":\"Fine-Grained Activity Recognition in Baseball Videos\",\"url\":\"https://www.semanticscholar.org/paper/7404a8d77ba515633b61c68164210d3422d0aaf0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":\"2008.09180\",\"authors\":[{\"authorId\":\"1924976\",\"name\":\"Jerry Liu\"},{\"authorId\":\"1892247\",\"name\":\"Shenlong Wang\"},{\"authorId\":\"2650832\",\"name\":\"W. Ma\"},{\"authorId\":\"144826412\",\"name\":\"Meet Shah\"},{\"authorId\":\"1471616367\",\"name\":\"Rui Hu\"},{\"authorId\":\"1877133981\",\"name\":\"Pranaab Dhawan\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"}],\"doi\":\"10.1007/978-3-030-58520-4_27\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c45c364c170970584442d87512b1702b5750aeda\",\"title\":\"Conditional Entropy Coding for Efficient Video Compression\",\"url\":\"https://www.semanticscholar.org/paper/c45c364c170970584442d87512b1702b5750aeda\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.00317\",\"authors\":[{\"authorId\":\"3445691\",\"name\":\"Youngwan Lee\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"35323281\",\"name\":\"Kimin Yun\"},{\"authorId\":\"3035146\",\"name\":\"Jinyoung Moon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"title\":\"Diverse Temporal Aggregation and Depthwise Spatiotemporal Factorization for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/87b2f4542659801ab5b4baddbd88b2a7d1296726\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2978134\",\"name\":\"Y. Su\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"},{\"authorId\":\"48566545\",\"name\":\"J. Zhu\"},{\"authorId\":\"8277017\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-58548-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"60498bfca85f39068f34d222484dc77b23f62035\",\"title\":\"Human Interaction Learning on 3D Skeleton Point Clouds for Video Violence Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60498bfca85f39068f34d222484dc77b23f62035\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.00649\",\"authors\":[{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1755381c55d8e52e3a72b3f065a5380874597af1\",\"title\":\"Group Ensemble: Learning an Ensemble of ConvNets in a single ConvNet\",\"url\":\"https://www.semanticscholar.org/paper/1755381c55d8e52e3a72b3f065a5380874597af1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10937\",\"authors\":[{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145984817\",\"name\":\"Yu Xiong\"},{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58548-8_41\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"0732df185bdfcb9c908ec30bb441252593f58875\",\"title\":\"MovieNet: A Holistic Dataset for Movie Understanding\",\"url\":\"https://www.semanticscholar.org/paper/0732df185bdfcb9c908ec30bb441252593f58875\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.06045\",\"authors\":[{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"1947383\",\"name\":\"Ashish Tawari\"},{\"authorId\":\"1841835\",\"name\":\"Sujitha Martin\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICRA40945.2020.9197104\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"title\":\"Interaction Graphs for Object Importance Estimation in On-road Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb51e17fc3e88c759ea3d41c9099e22ae7397e85\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":\"2007.02632\",\"authors\":[{\"authorId\":\"52025559\",\"name\":\"Mahsa Ehsanpour\"},{\"authorId\":\"3447236\",\"name\":\"A. Abedin\"},{\"authorId\":\"19170799\",\"name\":\"F. Saleh\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1007/978-3-030-58545-7_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81287e31f3e659aaedb5dce0646ba2b86377b282\",\"title\":\"Joint Learning of Social Groups, Individuals Action and Sub-group Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/81287e31f3e659aaedb5dce0646ba2b86377b282\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.06499\",\"authors\":[{\"authorId\":\"46798949\",\"name\":\"H. Shao\"},{\"authorId\":\"152230789\",\"name\":\"Shengju Qian\"},{\"authorId\":\"119924269\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1609/AAAI.V34I07.6872\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a573c125e85d1230626c8f3cf6193354f753958d\",\"title\":\"Temporal Interlacing Network\",\"url\":\"https://www.semanticscholar.org/paper/a573c125e85d1230626c8f3cf6193354f753958d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"144805693\",\"name\":\"C. Kuo\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"103483753\",\"name\":\"Yu-Hung Liu\"},{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"1491078400\",\"name\":\"Zijun Li\"},{\"authorId\":\"121418048\",\"name\":\"J. Shen\"},{\"authorId\":\"1743408\",\"name\":\"L. Fu\"}],\"doi\":\"10.1109/IROS40897.2019.8968533\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f98c4ae113621fdddaf5321b6f2f22310698f994\",\"title\":\"ResFlow: Multi-tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/f98c4ae113621fdddaf5321b6f2f22310698f994\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"64ab7408ea3e78b7319ff062a5c9df0faf741d0d\",\"title\":\"CSCI 699 ML4Know: Midterm Report\",\"url\":\"https://www.semanticscholar.org/paper/64ab7408ea3e78b7319ff062a5c9df0faf741d0d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730228\",\"name\":\"M. Liu\"},{\"authorId\":\"47781541\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1145/3347450.3357654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d062058cdef85163512c3984f0f1ba78f625582e\",\"title\":\"Deep Reinforcement Learning Visual-Text Attention for Multimodal Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d062058cdef85163512c3984f0f1ba78f625582e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.01091\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"47268124\",\"name\":\"T. Li\"},{\"authorId\":\"144484147\",\"name\":\"Rongyao Fang\"},{\"authorId\":\"10755270\",\"name\":\"R. Hristov\"},{\"authorId\":\"46499812\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1109/cvpr42600.2020.01071\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fdde6fa669761e385dafe48942495336f352fab\",\"title\":\"Learning Longterm Representations for Person Re-Identification Using Radio Signals\",\"url\":\"https://www.semanticscholar.org/paper/7fdde6fa669761e385dafe48942495336f352fab\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.03030\",\"authors\":[{\"authorId\":\"50623801\",\"name\":\"Shihao Zhao\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"145014256\",\"name\":\"Xiang Zheng\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"40663515\",\"name\":\"J. Chen\"},{\"authorId\":\"152163873\",\"name\":\"Yugang Jiang\"}],\"doi\":\"10.1109/cvpr42600.2020.01445\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"803f9bf6ab893073c514492a220747aa3d5fbf64\",\"title\":\"Clean-Label Backdoor Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/803f9bf6ab893073c514492a220747aa3d5fbf64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.00375\",\"authors\":[{\"authorId\":\"49970148\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"40560502\",\"name\":\"W. Wang\"},{\"authorId\":\"46947534\",\"name\":\"Z. Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dbcafe488f5b8153d4e43cae3577a590bd62840\",\"title\":\"A Comprehensive Study on Visual Explanations for Spatio-temporal Networks\",\"url\":\"https://www.semanticscholar.org/paper/1dbcafe488f5b8153d4e43cae3577a590bd62840\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2359832\",\"name\":\"Hongya Wang\"},{\"authorId\":\"1398305251\",\"name\":\"C. Dartigues-Pallez\"},{\"authorId\":\"70023327\",\"name\":\"M. Riveill\"}],\"doi\":\"10.1007/978-3-030-59413-8_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"986712869037687f9f1eb3ce3e1932c3606d5d5d\",\"title\":\"Supervised Learning for Human Action Recognition from Multiple Kinects\",\"url\":\"https://www.semanticscholar.org/paper/986712869037687f9f1eb3ce3e1932c3606d5d5d\",\"venue\":\"DASFAA\",\"year\":2020},{\"arxivId\":\"2007.10963\",\"authors\":[{\"authorId\":\"12771034\",\"name\":\"Jinxiu Liang\"},{\"authorId\":\"48093314\",\"name\":\"Jing-Wen Wang\"},{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"143874667\",\"name\":\"Tianyi Chen\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"29116642\",\"name\":\"H. Ling\"},{\"authorId\":\"121983569\",\"name\":\"Yanchen Xu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a01938c37317e5a93eab8300fe77f93b9809c8ae\",\"title\":\"Recurrent Exposure Generation for Low-Light Face Detection\",\"url\":\"https://www.semanticscholar.org/paper/a01938c37317e5a93eab8300fe77f93b9809c8ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050421\",\"name\":\"J. Zhang\"},{\"authorId\":\"145314992\",\"name\":\"Z. Wei\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"143813538\",\"name\":\"L. Liu\"},{\"authorId\":\"152506137\",\"name\":\"F. Zhu\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.1145/3343031.3350897\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e2593a896d82b60adf0a982afef27756dcddc6ed\",\"title\":\"Generative Reconstructive Hashing for Incomplete Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e2593a896d82b60adf0a982afef27756dcddc6ed\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"2007.09033\",\"authors\":[{\"authorId\":\"16323128\",\"name\":\"Guoxi Huang\"},{\"authorId\":\"1707271\",\"name\":\"Adrian G. Bors\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"215182fe19015d315cae9cd2c39e3a576b7193bf\",\"title\":\"Region-based Non-local Operation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/215182fe19015d315cae9cd2c39e3a576b7193bf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"}],\"doi\":\"10.1007/978-3-030-12177-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d7f93e107e81125397652c5d2ae4535c5344612\",\"title\":\"Three-Stream Convolution Networks After Background Subtraction for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0d7f93e107e81125397652c5d2ae4535c5344612\",\"venue\":\"FFER/DLPR@ICPR\",\"year\":2018},{\"arxivId\":\"1909.08171\",\"authors\":[{\"authorId\":\"144957857\",\"name\":\"H. Nishimura\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"84caa8a506e47b322cf9dc116806b06bca0c0981\",\"title\":\"Multiple Human Tracking using Multi-Cues including Primitive Action Features\",\"url\":\"https://www.semanticscholar.org/paper/84caa8a506e47b322cf9dc116806b06bca0c0981\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1802.09232\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"}],\"doi\":\"10.1109/CVPR.2018.00539\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d4f5c848b41160ac665d1991529a67a3208061e\",\"title\":\"2D/3D Pose Estimation and Action Recognition Using Multitask Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/3d4f5c848b41160ac665d1991529a67a3208061e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6486893\",\"name\":\"Chao Pu\"},{\"authorId\":null,\"name\":\"Hikvision\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"88997434c3dcfe1b9355edae84c78429e423600c\",\"title\":\"Spatiotemporal Feature Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/88997434c3dcfe1b9355edae84c78429e423600c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2142272\",\"name\":\"Jong Moo Lee\"},{\"authorId\":\"2059257\",\"name\":\"E. Park\"},{\"authorId\":\"3392973\",\"name\":\"Tae-Du Jung\"}],\"doi\":\"10.3390/s19183873\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"03d3bb3b703df3d7a05422c35daeaa4bb76aac0c\",\"title\":\"Automatic Detection of the Pharyngeal Phase in Raw Videos for the Videofluoroscopic Swallowing Study Using Efficient Data Collection and 3D Convolutional Networks \\u2020\",\"url\":\"https://www.semanticscholar.org/paper/03d3bb3b703df3d7a05422c35daeaa4bb76aac0c\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41022447\",\"name\":\"Okan K\\u00f6p\\u00fckl\\u00fc\"},{\"authorId\":\"1862703\",\"name\":\"N. Kose\"},{\"authorId\":\"66999822\",\"name\":\"Ahmet Gunduz\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"title\":\"Resource Efficient 3 D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d712fdf54d2d4c56afdc89e779208113b6edeafb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145580092\",\"name\":\"Pierre-Etienne Martin\"},{\"authorId\":\"1381345946\",\"name\":\"J. Benois-Pineau\"},{\"authorId\":\"1766371\",\"name\":\"Renaud P\\u00e9teri\"},{\"authorId\":\"48278763\",\"name\":\"J. Morlier\"}],\"doi\":\"10.1109/CBMI.2018.8516488\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e387b29ba253ddfe402509b2608d3f964721a8a\",\"title\":\"Sport Action Recognition with Siamese Spatio-Temporal CNNs: Application to Table Tennis\",\"url\":\"https://www.semanticscholar.org/paper/5e387b29ba253ddfe402509b2608d3f964721a8a\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"144530691\",\"name\":\"Lili Wan\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1145/3343031.3351073\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"13bf8def0af5ce1883d3d046b4c48ee6153d6241\",\"title\":\"Prediction-CGAN: Human Action Prediction with Conditional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/13bf8def0af5ce1883d3d046b4c48ee6153d6241\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"32281398\",\"name\":\"V. Q. Tran\"},{\"authorId\":\"1698158\",\"name\":\"Minh Hoai Nguyen\"}],\"doi\":\"10.1109/FG.2018.00076\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2bb36c875754a2a8919f2f9b00a336c00006e453\",\"title\":\"Eigen-Evolution Dense Trajectory Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/2bb36c875754a2a8919f2f9b00a336c00006e453\",\"venue\":\"2018 13th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2018)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1996209\",\"name\":\"Davide Modolo\"},{\"authorId\":null,\"name\":\"Yuanjun Xiong\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"title\":\"Dribbling Basketball Shooting Basketball Dribbling Basketball Shooting Basketball Baking Cookies Peeling Potatos Baking Cookies Peeling Potatos Smoking Eating BurgerSmoking Eating\",\"url\":\"https://www.semanticscholar.org/paper/d9266a16e9213b7406968578b5f7a8dde2c15f43\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48805860\",\"name\":\"Zhimeng Zhang\"},{\"authorId\":\"145453305\",\"name\":\"Xin Ma\"},{\"authorId\":\"145401371\",\"name\":\"R. Song\"},{\"authorId\":\"2924438\",\"name\":\"Xuewen Rong\"},{\"authorId\":\"32004054\",\"name\":\"X. Tian\"},{\"authorId\":\"49209779\",\"name\":\"G. Tian\"},{\"authorId\":\"29275442\",\"name\":\"Yibin Li\"}],\"doi\":\"10.1109/CAC.2017.8243438\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"title\":\"Deep learning based human action recognition: A survey\",\"url\":\"https://www.semanticscholar.org/paper/2063222c5ce0dd233fa3056ddc245fca26bd5cf2\",\"venue\":\"2017 Chinese Automation Congress (CAC)\",\"year\":2017},{\"arxivId\":\"1906.05910\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f9a9965c013be1269c05a96857c78ad8c87ee517\",\"title\":\"Hallucinating Bag-of-Words and Fisher Vector IDT terms for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9a9965c013be1269c05a96857c78ad8c87ee517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00052\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"title\":\"Improving a 3-D Convolutional Neural Network Model Reinvented from VGG16 with Batch Normalization\",\"url\":\"https://www.semanticscholar.org/paper/50c0cc993c7f2179d36d6868c0f01871ed855bfc\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2357503\",\"name\":\"Ya-Chun Li\"},{\"authorId\":\"97596774\",\"name\":\"Y. Liu\"},{\"authorId\":\"48935472\",\"name\":\"Chi Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"title\":\"What Elements are Essential to Recognize Human Actions?\",\"url\":\"https://www.semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"152193942\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"8547960\",\"name\":\"Lijun Yu\"},{\"authorId\":\"72399893\",\"name\":\"Yijun Qian\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"1970583\",\"name\":\"Liangke Gui\"},{\"authorId\":\"32058482\",\"name\":\"Jing Wen\"},{\"authorId\":\"144675264\",\"name\":\"Peng Chen\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1109/WACVW50321.2020.9096929\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"703015f87eb089a70e882af715a81fd100114bbd\",\"title\":\"Argus: Efficient Activity Detection System for Extended Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/703015f87eb089a70e882af715a81fd100114bbd\",\"venue\":\"2020 IEEE Winter Applications of Computer Vision Workshops (WACVW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145042308\",\"name\":\"U. Iqbal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ea3421243d8edb4fbe8b4962c1566d8b9ce42e1\",\"title\":\"Articulated Human Pose Estimation in Unconstrained Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/6ea3421243d8edb4fbe8b4962c1566d8b9ce42e1\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.06583\",\"authors\":[{\"authorId\":\"46522476\",\"name\":\"Xiaoli Liu\"},{\"authorId\":\"72002635\",\"name\":\"Jianqin Yin\"},{\"authorId\":\"48210845\",\"name\":\"Jinghao Liu\"},{\"authorId\":\"93349641\",\"name\":\"P. Ding\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"2641547\",\"name\":\"H. Liu\"}],\"doi\":\"10.1109/tcsvt.2020.3021409\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fef6913fe0ed6a5a25162b3502c381adfae56b3c\",\"title\":\"TrajectoryNet: a new spatio-temporal feature learning network for human motion prediction.\",\"url\":\"https://www.semanticscholar.org/paper/fef6913fe0ed6a5a25162b3502c381adfae56b3c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1718226\",\"name\":\"C. Li\"},{\"authorId\":\"3128157\",\"name\":\"Ruofeng Tong\"},{\"authorId\":\"50627816\",\"name\":\"Min Tang\"}],\"doi\":\"10.1007/S13369-018-3189-Z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f0b7c8345d065f7326f3835fe022e43d020ce050\",\"title\":\"Modelling Human Body Pose for Action Recognition Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f0b7c8345d065f7326f3835fe022e43d020ce050\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117257245\",\"name\":\"Negar Moslemi\"},{\"authorId\":\"2854562\",\"name\":\"R. Azmi\"},{\"authorId\":\"2522837\",\"name\":\"M. Soryani\"}],\"doi\":\"10.1109/PRIA.2019.8786012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ed0a147c4ef174e4243deff70bf43781a3519fa\",\"title\":\"Driver Distraction Recognition using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/9ed0a147c4ef174e4243deff70bf43781a3519fa\",\"venue\":\"2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA)\",\"year\":2019},{\"arxivId\":\"1912.01180\",\"authors\":[{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"12732902\",\"name\":\"Xinyue Wei\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"9381483\",\"name\":\"Zihao Xiao\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"title\":\"RSA: Randomized Simulation as Augmentation for Robust Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3260a2fb397b9a04d96546f0823ce7b84ba8e3d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.06149\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/tmm.2020.3025665\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"title\":\"Universal-to-Specific Framework for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1fc76cc67ad82df1f7695b4d9e0b7536a70732\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27213742\",\"name\":\"W. Zhao\"},{\"authorId\":\"152905258\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"51350339\",\"name\":\"Yingli Sun\"},{\"authorId\":\"50991066\",\"name\":\"Cheng Li\"},{\"authorId\":\"7970336\",\"name\":\"Wei-lan Wu\"},{\"authorId\":\"103154524\",\"name\":\"L. Jin\"},{\"authorId\":\"1390867136\",\"name\":\"Zhiming Yang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"50735393\",\"name\":\"P. Gao\"},{\"authorId\":\"48319637\",\"name\":\"P. Wang\"},{\"authorId\":\"40284404\",\"name\":\"Yanqing Hua\"},{\"authorId\":\"50651607\",\"name\":\"Maoxing Li\"}],\"doi\":\"10.1158/0008-5472.CAN-18-0696\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3dae87cbcd7475b0775287c4c3223e4d6089a13f\",\"title\":\"3D Deep Learning from CT Scans Predicts Tumor Invasiveness of Subcentimeter Pulmonary Adenocarcinomas.\",\"url\":\"https://www.semanticscholar.org/paper/3dae87cbcd7475b0775287c4c3223e4d6089a13f\",\"venue\":\"Cancer research\",\"year\":2018},{\"arxivId\":\"2006.04489\",\"authors\":[{\"authorId\":\"1650071598\",\"name\":\"Ahmed Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"title\":\"Action Recognition with Deep Multiple Aggregation Networks\",\"url\":\"https://www.semanticscholar.org/paper/fe7915ca11fda06d678933e2f51ad26e4ce2c661\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00163\",\"authors\":[{\"authorId\":\"1603002784\",\"name\":\"Zhekun Luo\"},{\"authorId\":\"3493957\",\"name\":\"Devin Guillory\"},{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"4505317\",\"name\":\"W. Ke\"},{\"authorId\":\"1510781142\",\"name\":\"Fang Wan\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"}],\"doi\":\"10.1007/978-3-030-58526-6_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a84514fc6b08b93e51432d0539cae4ab7692cc56\",\"title\":\"Weakly-Supervised Action Localization with Expectation-Maximization Multi-Instance Learning\",\"url\":\"https://www.semanticscholar.org/paper/a84514fc6b08b93e51432d0539cae4ab7692cc56\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.06540\",\"authors\":[{\"authorId\":\"34831857\",\"name\":\"Jasper S. Wijnands\"},{\"authorId\":\"145040690\",\"name\":\"J. Thompson\"},{\"authorId\":\"52351371\",\"name\":\"Kerry A. Nice\"},{\"authorId\":\"75058211\",\"name\":\"G. Aschwanden\"},{\"authorId\":\"144795096\",\"name\":\"M. Stevenson\"}],\"doi\":\"10.1007/s00521-019-04506-0\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"82a9a9fde3c2c7acb2980506c15d323b338ad85b\",\"title\":\"Real-time monitoring of driver drowsiness on mobile platforms using 3D neural networks\",\"url\":\"https://www.semanticscholar.org/paper/82a9a9fde3c2c7acb2980506c15d323b338ad85b\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151492109\",\"name\":\"Wensong Chan\"},{\"authorId\":\"71506962\",\"name\":\"Zhiqiang Tian\"},{\"authorId\":\"51381728\",\"name\":\"S. Liu\"},{\"authorId\":\"145160620\",\"name\":\"J. Ren\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"}],\"doi\":\"10.1007/978-3-030-27535-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"title\":\"Select and Focus: Action Recognition with Spatial-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"47818608\",\"name\":\"Leilei Chen\"},{\"authorId\":\"152745066\",\"name\":\"Can-jin Wang\"},{\"authorId\":null,\"name\":\"Chen Wang\"},{\"authorId\":\"1732904\",\"name\":\"Haijing Liu\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d9448f6fa289b86b1c448882907332a0ce49376\",\"title\":\"Comprehensive Soccer Video Understanding: Towards Human-comparable Video Understanding System in Constrained Environment\",\"url\":\"https://www.semanticscholar.org/paper/0d9448f6fa289b86b1c448882907332a0ce49376\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50762746\",\"name\":\"Jun Chen\"},{\"authorId\":\"13849852\",\"name\":\"Yuan-ping Xu\"},{\"authorId\":\"9372837\",\"name\":\"Chao-long Zhang\"},{\"authorId\":\"50070258\",\"name\":\"Zhijie Xu\"},{\"authorId\":\"89978385\",\"name\":\"Xiangxiang Meng\"},{\"authorId\":\"97773646\",\"name\":\"J. Wang\"}],\"doi\":\"10.23919/IConAC.2019.8894962\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"841ae506fbd745273cd3498c923088a5736f42d1\",\"title\":\"An Improved Two-stream 3D Convolutional Neural Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/841ae506fbd745273cd3498c923088a5736f42d1\",\"venue\":\"2019 25th International Conference on Automation and Computing (ICAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49443983\",\"name\":\"Wei Yuan\"},{\"authorId\":\"7550863\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47027584\",\"name\":\"Xiaojun Hu\"},{\"authorId\":\"145126238\",\"name\":\"M. Song\"}],\"doi\":\"10.1007/978-3-030-29513-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"020e4ec36d0dc80dc94c5eb57dea430fa1f78a24\",\"title\":\"Automatic Curation System Using Multimodal Analysis Approach (MAA)\",\"url\":\"https://www.semanticscholar.org/paper/020e4ec36d0dc80dc94c5eb57dea430fa1f78a24\",\"venue\":\"IntelliSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91433101\",\"name\":\"Diego Ardila\"},{\"authorId\":\"48057821\",\"name\":\"A. Kiraly\"},{\"authorId\":\"31001026\",\"name\":\"S. Bharadwaj\"},{\"authorId\":\"49026696\",\"name\":\"B. Choi\"},{\"authorId\":\"40056219\",\"name\":\"J. Reicher\"},{\"authorId\":\"145942443\",\"name\":\"Lily Peng\"},{\"authorId\":\"145448045\",\"name\":\"Daniel Tse\"},{\"authorId\":\"144500251\",\"name\":\"M. Etemadi\"},{\"authorId\":\"35067802\",\"name\":\"W. Ye\"},{\"authorId\":\"34662997\",\"name\":\"Greg Corrado\"},{\"authorId\":\"2079002\",\"name\":\"D. Naidich\"},{\"authorId\":\"2894170\",\"name\":\"S. Shetty\"}],\"doi\":\"10.1038/s41591-019-0447-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"45aa47293d70bbed4d93725ed9858bf6dfcd81a1\",\"title\":\"End-to-end lung cancer screening with three-dimensional deep learning on low-dose chest computed tomography\",\"url\":\"https://www.semanticscholar.org/paper/45aa47293d70bbed4d93725ed9858bf6dfcd81a1\",\"venue\":\"Nature Medicine\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1720818\",\"name\":\"Sebastian Agethen\"},{\"authorId\":\"3245101\",\"name\":\"Hu-Cheng Lee\"},{\"authorId\":\"1716836\",\"name\":\"W. Hsu\"}],\"doi\":\"10.1109/CVPRW.2019.00357\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"73a006022a64a7de18cd99ba7c7cb570e0566e38\",\"title\":\"Anticipation of Human Actions With Pose-Based Fine-Grained Representations\",\"url\":\"https://www.semanticscholar.org/paper/73a006022a64a7de18cd99ba7c7cb570e0566e38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"2006.00212\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"152949394\",\"name\":\"J. Tang\"},{\"authorId\":\"50753313\",\"name\":\"Minghui Yu\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1038/s42256-020-0168-3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"title\":\"Complex sequential understanding through the awareness of spatial and temporal concepts\",\"url\":\"https://www.semanticscholar.org/paper/86cc65a2b78f5ad9205faf0dba26b5f04d11126c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"1780642035\",\"name\":\"Mohammad Zaki Zadeh\"},{\"authorId\":\"47589531\",\"name\":\"A. Jaiswal\"},{\"authorId\":\"2000284842\",\"name\":\"Alexis Lueckenhoff\"},{\"authorId\":\"1603672934\",\"name\":\"Maria Kyrarini\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.1145/3382507.3418829\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a0bd941b60fc653b7e05a79cae49af5477347444\",\"title\":\"A Multi-modal System to Assess Cognition in Children from their Physical Movements\",\"url\":\"https://www.semanticscholar.org/paper/a0bd941b60fc653b7e05a79cae49af5477347444\",\"venue\":\"ICMI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145829609\",\"name\":\"Hung T. Le\"},{\"authorId\":\"36187119\",\"name\":\"Doyen Sahoo\"},{\"authorId\":\"2185019\",\"name\":\"Nancy F. Chen\"},{\"authorId\":\"1741126\",\"name\":\"S. Hoi\"}],\"doi\":\"10.1016/j.csl.2020.101095\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"661f04ecc734ced906e16980a6143c814ce085ed\",\"title\":\"Hierarchical multimodal attention for end-to-end audio-visual scene-aware dialogue response generation\",\"url\":\"https://www.semanticscholar.org/paper/661f04ecc734ced906e16980a6143c814ce085ed\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000186088\",\"name\":\"Jie Shao\"},{\"authorId\":\"1991059454\",\"name\":\"Kai Hu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":\"48002027\",\"name\":\"X. Xue\"},{\"authorId\":\"1681921\",\"name\":\"B. Raj\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a9bf293a794642b17f117f80d0183faadcccd28\",\"title\":\"Is normalization indispensable for training deep neural network?\",\"url\":\"https://www.semanticscholar.org/paper/1a9bf293a794642b17f117f80d0183faadcccd28\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2010.10839\",\"authors\":[{\"authorId\":\"7878341\",\"name\":\"Wubo Li\"},{\"authorId\":\"46197764\",\"name\":\"D. Jiang\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"1898780\",\"name\":\"Xiangang Li\"}],\"doi\":\"10.21437/interspeech.2020-2359\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"title\":\"TMT: A Transformer-based Modal Translator for Improving Multimodal Sequence Representations in Audio Visual Scene-aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/f5bb5c693a69cc10bc9d4dcc48eb96bae3d0600a\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":\"1904.03249\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"40897068\",\"name\":\"Xin Chen\"},{\"authorId\":\"23614019\",\"name\":\"Y. Zhang\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"76db87564c7e6a6f417fca41b9f659a879de5027\",\"title\":\"Attention Distillation for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/76db87564c7e6a6f417fca41b9f659a879de5027\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51487791\",\"name\":\"L. C. Valeriano\"},{\"authorId\":\"1705089\",\"name\":\"P. Napoletano\"},{\"authorId\":\"143940718\",\"name\":\"R. Schettini\"}],\"doi\":\"10.1109/ICCE-Berlin.2018.8576183\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"566d09c45ff60abe62e4e3dcac13f0f6747688e5\",\"title\":\"Recognition of driver distractions using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/566d09c45ff60abe62e4e3dcac13f0f6747688e5\",\"venue\":\"2018 IEEE 8th International Conference on Consumer Electronics - Berlin (ICCE-Berlin)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52580548\",\"name\":\"M. Young\"},{\"authorId\":\"153761408\",\"name\":\"Hyung-il Kim\"},{\"authorId\":\"83168173\",\"name\":\"Park Jongyoul\"}],\"doi\":\"10.22648/ETRI.2020.J.350303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31c47ff65e56035aa523f48ece1b462df1ed0c7f\",\"title\":\"Trends in Temporal Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/31c47ff65e56035aa523f48ece1b462df1ed0c7f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46433230\",\"name\":\"Y. Zhou\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"46275945\",\"name\":\"Jingyu Li\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1725421\",\"name\":\"Shi Qiu\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"}],\"doi\":\"10.1145/3134263.3134265\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"title\":\"Video Classification via Relational Feature Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":\"1808.00928\",\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"32245472\",\"name\":\"Corey Lynch\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"}],\"doi\":\"10.1109/IROS.2018.8593951\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"93adca9ce6f4a0fab9ea027c90b4df828cfa10d7\",\"title\":\"Learning Actionable Representations from Visual Observations\",\"url\":\"https://www.semanticscholar.org/paper/93adca9ce6f4a0fab9ea027c90b4df828cfa10d7\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":\"1712.04851\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"1808244\",\"name\":\"J. Huang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"},{\"authorId\":\"1702318\",\"name\":\"Kevin Murphy\"}],\"doi\":\"10.1007/978-3-030-01267-0_19\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"815aa52cfc02961d82415f080384594639a21984\",\"title\":\"Rethinking Spatiotemporal Feature Learning: Speed-Accuracy Trade-offs in Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/815aa52cfc02961d82415f080384594639a21984\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842115\",\"name\":\"M. Liu\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"47002162\",\"name\":\"Y. Li\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"title\":\"Forecasting Human Object Interaction: Joint Prediction of Motor Attention and Egocentric Activity\",\"url\":\"https://www.semanticscholar.org/paper/c94aa2bff74824bb8c3adbd5c697d890d0e73620\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83167758\",\"name\":\"Jie Zheng\"},{\"authorId\":\"11733729\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1109/CISP-BMEI48845.2019.8965930\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2b0f6b8c475d1765629ec7d03ae479c6036ee90a\",\"title\":\"Non-Local Spatiaotemporal Two-Stream Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b0f6b8c475d1765629ec7d03ae479c6036ee90a\",\"venue\":\"2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47120363\",\"name\":\"X. Wang\"},{\"authorId\":\"3316344\",\"name\":\"Junsan Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"144019071\",\"name\":\"Philip S. Yu\"},{\"authorId\":\"47055140\",\"name\":\"J. Zhu\"},{\"authorId\":\"46382188\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3357384.3357935\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"title\":\"Video-level Multi-model Fusion for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51e4e7b322c53dac73048fa5bd5dd1c5145b2d82\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1911.08511\",\"authors\":[{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"3207112\",\"name\":\"A. Reiter\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"title\":\"Action Recognition Using Volumetric Motion Representations\",\"url\":\"https://www.semanticscholar.org/paper/b5a3276c943aea32d6331c317649e5d1dc1faf91\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71712589\",\"name\":\"L. Courtney\"},{\"authorId\":\"40568918\",\"name\":\"R. Sreenivas\"}],\"doi\":\"10.1007/978-3-030-41299-9_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7db0bb6ed3630373be94e678dbc397d619473e90\",\"title\":\"Using Deep Convolutional LSTM Networks for Learning Spatiotemporal Features\",\"url\":\"https://www.semanticscholar.org/paper/7db0bb6ed3630373be94e678dbc397d619473e90\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":\"1805.08162\",\"authors\":[{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d9a576f03fc5f6cabbd6291fb65db0ee0a607103\",\"title\":\"VideoCapsuleNet: A Simplified Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/d9a576f03fc5f6cabbd6291fb65db0ee0a607103\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87874401\",\"name\":\"Cai Qiang\"},{\"authorId\":\"1409990256\",\"name\":\"Jin Yan\"},{\"authorId\":\"144766132\",\"name\":\"Haisheng Li\"},{\"authorId\":\"2003541846\",\"name\":\"Deng Yibiao\"}],\"doi\":\"10.1007/978-981-15-8450-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94c5d2d26bde4c314b7a51e42495192c5affb651\",\"title\":\"Human Action Recognition Method Based on Video-Level Features and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/94c5d2d26bde4c314b7a51e42495192c5affb651\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"46737456\",\"name\":\"Pu Zhao\"},{\"authorId\":\"32661932\",\"name\":\"M. Gungor\"},{\"authorId\":\"69467609\",\"name\":\"M. Pedram\"},{\"authorId\":\"1710866\",\"name\":\"M. Leeser\"},{\"authorId\":\"145282404\",\"name\":\"X. Lin\"}],\"doi\":\"10.1109/DAC18072.2020.9218571\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8fc582afcb3b81b724ea2af73175ae3c594cef0c\",\"title\":\"3D CNN Acceleration on FPGA using Hardware-Aware Pruning\",\"url\":\"https://www.semanticscholar.org/paper/8fc582afcb3b81b724ea2af73175ae3c594cef0c\",\"venue\":\"2020 57th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144290805\",\"name\":\"L. Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"144228565\",\"name\":\"Jian Cheng\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00810\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"68a024d7b70ef3989a6751678f635cbe754440fc\",\"title\":\"Skeleton-Based Action Recognition With Directed Graph Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/68a024d7b70ef3989a6751678f635cbe754440fc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2259852\",\"name\":\"Jianing Li\"},{\"authorId\":\"46583677\",\"name\":\"J. Wang\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"101001846\",\"name\":\"Wen Gao\"},{\"authorId\":\"1776581\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1109/ICCV.2019.00406\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Global-Local Temporal Representations for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81188084\",\"name\":\"Saima Nazir\"},{\"authorId\":\"50059673\",\"name\":\"Yu Qian\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"},{\"authorId\":\"145643264\",\"name\":\"E. Izquierdo\"},{\"authorId\":\"30902466\",\"name\":\"Eduard Vazquez\"}],\"doi\":\"10.5220/0007371104200426\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"title\":\"Human Action Recognition using Multi-Kernel Learning for Temporal Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/f7984cc627276d934e8f9ff43ff95ffa3614016c\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576087725\",\"name\":\"Reed Chen\"},{\"authorId\":\"1579340152\",\"name\":\"Dylan Siegler\"},{\"authorId\":\"1581868817\",\"name\":\"Michael FaskoJr.\"},{\"authorId\":\"2409366\",\"name\":\"Shunkun Yang\"},{\"authorId\":\"9160831\",\"name\":\"X. Luo\"},{\"authorId\":\"144101028\",\"name\":\"W. Zhao\"}],\"doi\":\"10.1007/978-981-15-1925-3_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6170da5f075911d23b86a5a1239e4b10e18fbf4e\",\"title\":\"Baseball Pitch Type Recognition Based on Broadcast Videos\",\"url\":\"https://www.semanticscholar.org/paper/6170da5f075911d23b86a5a1239e4b10e18fbf4e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491438016\",\"name\":\"Yuanye Fang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"}],\"doi\":\"10.1007/978-3-030-39431-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"title\":\"Action Recognition in Videos with Temporal Segments Fusions\",\"url\":\"https://www.semanticscholar.org/paper/d662fa47ebfc8b800d9bbadbe581325cf27a6764\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":\"1909.12929\",\"authors\":[{\"authorId\":\"46868059\",\"name\":\"Yumeng Zhang\"},{\"authorId\":\"1380048842\",\"name\":\"Gaoguo Jia\"},{\"authorId\":\"69856210\",\"name\":\"Li Chen\"},{\"authorId\":\"48985485\",\"name\":\"Mingrui Zhang\"},{\"authorId\":\"102662387\",\"name\":\"J. Yong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3010141db561594cad7325554fbc6d41f88c8eba\",\"title\":\"Self-Paced Video Data Augmentation with Dynamic Images Generated by Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/3010141db561594cad7325554fbc6d41f88c8eba\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47842072\",\"name\":\"M. Liu\"},{\"authorId\":\"1774797\",\"name\":\"Fanyang Meng\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"2525392\",\"name\":\"S. Wu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018762\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32c216b09b1208585a70cff674460735bd9939fe\",\"title\":\"Joint Dynamic Pose Image and Space Time Reversal for Human Action Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/32c216b09b1208585a70cff674460735bd9939fe\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1812.03982\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"2681569\",\"name\":\"Haoqi Fan\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1109/ICCV.2019.00630\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"title\":\"SlowFast Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b47b9c3c35b2b2a78bff7822605b3040f87d699\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2029336786\",\"name\":\"Junmin Ke\"},{\"authorId\":\"2029316704\",\"name\":\"Shengting Guo\"}],\"doi\":\"10.1109/CISP-BMEI51763.2020.9263674\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"987cb6c0330b3ef431716212c2b31de10481f21d\",\"title\":\"A Simple Multi-Frame Fusion Baseline For Long-Term Multi-Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/987cb6c0330b3ef431716212c2b31de10481f21d\",\"venue\":\"2020 13th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52454948\",\"name\":\"A. Verma\"},{\"authorId\":\"2903495\",\"name\":\"T. Meenpal\"},{\"authorId\":\"2456349\",\"name\":\"Bibhudendra Acharya\"}],\"doi\":\"10.1111/coin.12419\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"title\":\"Multiperson interaction recognition in images: A body keypoint based feature image analysis\",\"url\":\"https://www.semanticscholar.org/paper/3fa95ecd010ac58a0149c08c90965d78fca8d3b6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.05667\",\"authors\":[{\"authorId\":\"151473559\",\"name\":\"Liam Hiley\"},{\"authorId\":\"144978811\",\"name\":\"A. Preece\"},{\"authorId\":\"2256975\",\"name\":\"Y. Hicks\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"title\":\"Explainable Deep Learning for Video Recognition Tasks: A Framework & Recommendations\",\"url\":\"https://www.semanticscholar.org/paper/c138499d43e3e2d4e2cf9e498d984fe2632d7d03\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8967435\",\"name\":\"Yosuke Oyama\"},{\"authorId\":\"3264280\",\"name\":\"N. Maruyama\"},{\"authorId\":\"2134146\",\"name\":\"Nikoli Dryden\"},{\"authorId\":\"152260750\",\"name\":\"Erin McCarthy\"},{\"authorId\":\"74627487\",\"name\":\"P. Harrington\"},{\"authorId\":\"102237835\",\"name\":\"J. Balewski\"},{\"authorId\":\"49317791\",\"name\":\"Satoshi Matsuoka\"},{\"authorId\":\"145484336\",\"name\":\"P. Nugent\"},{\"authorId\":\"32977294\",\"name\":\"B. V. Essen\"}],\"doi\":\"10.1109/tpds.2020.3047974\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e8ec5d6a279ab53708d396a8853cb87b5013cacb\",\"title\":\"The Case for Strong Scaling in Deep Learning: Training Large 3D CNNs with Hybrid Parallelism\",\"url\":\"https://www.semanticscholar.org/paper/e8ec5d6a279ab53708d396a8853cb87b5013cacb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ITSC45102.2020.9294731\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"afe640b4cfcbaf0885147eafd7d92887096e0e99\",\"title\":\"CNN-based Driver Activity Understanding: Shedding Light on Deep Spatiotemporal Representations\",\"url\":\"https://www.semanticscholar.org/paper/afe640b4cfcbaf0885147eafd7d92887096e0e99\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"2008.11378\",\"authors\":[{\"authorId\":\"153420733\",\"name\":\"Haozhi Cao\"},{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"title\":\"Effective Action Recognition with Embedded Key Point Shifts\",\"url\":\"https://www.semanticscholar.org/paper/c16a94fe31835a67a8cf5e2d4d1076e0037844a9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.10985\",\"authors\":[{\"authorId\":\"1817030\",\"name\":\"Saining Xie\"},{\"authorId\":\"3016273\",\"name\":\"Jiatao Gu\"},{\"authorId\":\"35578711\",\"name\":\"Demi Guo\"},{\"authorId\":\"1898455\",\"name\":\"Charles R. Qi\"},{\"authorId\":\"1744254\",\"name\":\"L. Guibas\"},{\"authorId\":\"2528439\",\"name\":\"O. Litany\"}],\"doi\":\"10.1007/978-3-030-58580-8_34\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"491188ac198663094537cb4c38ac1c8808ef7440\",\"title\":\"PointContrast: Unsupervised Pre-training for 3D Point Cloud Understanding\",\"url\":\"https://www.semanticscholar.org/paper/491188ac198663094537cb4c38ac1c8808ef7440\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2005.00375\",\"authors\":[{\"authorId\":\"152985547\",\"name\":\"Z. Li\"},{\"authorId\":\"40560502\",\"name\":\"W. Wang\"},{\"authorId\":\"121544228\",\"name\":\"Z. Li\"},{\"authorId\":\"48355651\",\"name\":\"Yifei Huang\"},{\"authorId\":\"2003804019\",\"name\":\"Yoichi Sato\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b9338b7de4b849cb094aa4cbd5b85f9935a4ae00\",\"title\":\"Towards Visually Explaining Video Understanding Networks with Perturbation\",\"url\":\"https://www.semanticscholar.org/paper/b9338b7de4b849cb094aa4cbd5b85f9935a4ae00\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423743315\",\"name\":\"Theodoros Georgiou\"},{\"authorId\":\"3546791\",\"name\":\"Y. Liu\"},{\"authorId\":\"47482437\",\"name\":\"W. Chen\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1007/s13735-019-00183-w\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"title\":\"A survey of traditional and deep learning-based feature descriptors for high dimensional data in computer vision\",\"url\":\"https://www.semanticscholar.org/paper/763495e4ce53c989bf7c2910ae8cb51e4469e195\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.12886\",\"authors\":[{\"authorId\":\"1965933798\",\"name\":\"Alban Main De Boissiere\"},{\"authorId\":\"2479033\",\"name\":\"Rita Noumeir\"}],\"doi\":\"10.1109/ACCESS.2020.3023599\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"title\":\"Infrared and 3D Skeleton Feature Fusion for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f67eca7b8511a3253d58fd12b0768c9caa12610d\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49299019\",\"name\":\"Junnan Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d281b07ee152f6c1312297b71791d358f4dc88cb\",\"title\":\"Weakly-Supervised Multi-Person Action Recognition in 360$^{\\\\circ}$ Videos\",\"url\":\"https://www.semanticscholar.org/paper/d281b07ee152f6c1312297b71791d358f4dc88cb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.05654\",\"authors\":[{\"authorId\":\"39714216\",\"name\":\"F. Ragusa\"},{\"authorId\":\"1792681\",\"name\":\"Antonino Furnari\"},{\"authorId\":\"2444519\",\"name\":\"S. Livatino\"},{\"authorId\":\"1729739\",\"name\":\"G. Farinella\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a58a0732664b97b471b795df5812f98f24840490\",\"title\":\"The MECCANO Dataset: Understanding Human-Object Interactions from Egocentric Videos in an Industrial-like Domain\",\"url\":\"https://www.semanticscholar.org/paper/a58a0732664b97b471b795df5812f98f24840490\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1905.05143\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"title\":\"VideoGraph: Recognizing Minutes-Long Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83172278\",\"name\":\"Y. Li\"},{\"authorId\":\"49901469\",\"name\":\"G. Chen\"},{\"authorId\":\"66678312\",\"name\":\"Xiangqian Cheng\"},{\"authorId\":\"48240541\",\"name\":\"C. Chen\"},{\"authorId\":\"2303180\",\"name\":\"S. Xu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"51470719\",\"name\":\"Xuanlu Xiang\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"144443297\",\"name\":\"Z. Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"09ff6f4ef34c1519dcdf9b8c0fd3b77e19c2426a\",\"title\":\"BUPT-MCPRL at TRECVID 2019: ActEV and INS\",\"url\":\"https://www.semanticscholar.org/paper/09ff6f4ef34c1519dcdf9b8c0fd3b77e19c2426a\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1559793886\",\"name\":\"W. Yu\"},{\"authorId\":\"2505474\",\"name\":\"Y. Lu\"},{\"authorId\":\"1693900\",\"name\":\"S. Easterbrook\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43fae6940c4ef3f47d80b0749c3447012254a615\",\"title\":\"Efficient and Information-Preserving Future Frame Prediction and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/43fae6940c4ef3f47d80b0749c3447012254a615\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410772490\",\"name\":\"R. Ogata\"},{\"authorId\":\"1398077025\",\"name\":\"Edgar Simo-Serra\"},{\"authorId\":\"150298109\",\"name\":\"Satoshi Iizuka\"},{\"authorId\":\"66193516\",\"name\":\"H. Ishikawa\"}],\"doi\":\"10.1109/CVPRW.2019.00309\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de7cbc5737177ff89913a916e9bd6417836f520e\",\"title\":\"Temporal Distance Matrices for Squat Classification\",\"url\":\"https://www.semanticscholar.org/paper/de7cbc5737177ff89913a916e9bd6417836f520e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"Srijan Das\"},{\"authorId\":\"52622630\",\"name\":\"Kaustubh Sakhalkar\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"144103389\",\"name\":\"Fran\\u00e7ois Br\\u00e9mond\"}],\"doi\":\"10.1145/3293353.3293376\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"631a704edb53b0a4b852421891172ff785879727\",\"title\":\"Spatio-Temporal Grids for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/631a704edb53b0a4b852421891172ff785879727\",\"venue\":\"ICVGIP\",\"year\":2018},{\"arxivId\":\"1810.03964\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"},{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"}],\"doi\":\"10.1109/ICIP.2018.8451666\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"3450230\",\"name\":\"Yiliang Shi\"},{\"authorId\":\"48144872\",\"name\":\"E. Wu\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc8a78b43b5e14643dbf8991b585314cdee6a341\",\"title\":\"What\\u2019s Missing From Self-Supervised Representation Learning?\",\"url\":\"https://www.semanticscholar.org/paper/cc8a78b43b5e14643dbf8991b585314cdee6a341\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.07520\",\"authors\":[{\"authorId\":\"1750375688\",\"name\":\"Zhiwu Qing\"},{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"1749375503\",\"name\":\"Yongpeng Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e6ee2de875529f7af5419b66266c4664cffdd84\",\"title\":\"Temporal Fusion Network for Temporal Action Localization: Submission to ActivityNet Challenge 2020 (Task E)\",\"url\":\"https://www.semanticscholar.org/paper/7e6ee2de875529f7af5419b66266c4664cffdd84\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66039652\",\"name\":\"Abel D\\u00edaz Berenguer\"},{\"authorId\":\"30988779\",\"name\":\"Meshia C\\u00e9dric Oveneke\"},{\"authorId\":\"153055277\",\"name\":\"Habib-Ur-Rehman Khalid\"},{\"authorId\":\"1402930818\",\"name\":\"Mitchel Alioscha-P\\u00e9rez\"},{\"authorId\":\"66423728\",\"name\":\"A. Bourdoux\"},{\"authorId\":\"48077408\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1109/ACCESS.2019.2942305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bc9f2f4c34ccacd90248aedf10899c8c4e1596f\",\"title\":\"GestureVLAD: Combining Unsupervised Features Representation and Spatio-Temporal Aggregation for Doppler-Radar Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bc9f2f4c34ccacd90248aedf10899c8c4e1596f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"145529194\",\"name\":\"M. Martinez\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1007/978-3-030-11018-5_8\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1c127e27ec746afbeede792f63316663fb96bf95\",\"title\":\"Towards a Fair Evaluation of Zero-Shot Action Recognition Using External Data\",\"url\":\"https://www.semanticscholar.org/paper/1c127e27ec746afbeede792f63316663fb96bf95\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10025937\",\"name\":\"Z. Xu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"46868155\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICMEW.2018.8551529\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"title\":\"S2L: Single-Streamline For Complex Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"1711.09577\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/CVPR.2018.00685\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"title\":\"Can Spatiotemporal 3D CNNs Retrace the History of 2D CNNs and ImageNet?\",\"url\":\"https://www.semanticscholar.org/paper/d716435f0cb0cac56237f74b1ced940aabce6a2b\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1903.06528\",\"authors\":[{\"authorId\":\"143884578\",\"name\":\"W. McNally\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"88186692\",\"name\":\"T. Pinto\"},{\"authorId\":\"87975332\",\"name\":\"Chris Dulhanty\"},{\"authorId\":\"144304939\",\"name\":\"J. McPhee\"},{\"authorId\":\"144821966\",\"name\":\"A. Wong\"}],\"doi\":\"10.1109/CVPRW.2019.00311\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a5a79b85162e296113067995e3ba9ad850ccf280\",\"title\":\"GolfDB: A Video Database for Golf Swing Sequencing\",\"url\":\"https://www.semanticscholar.org/paper/a5a79b85162e296113067995e3ba9ad850ccf280\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"27ff341652fff45d545f68c6e00b0b07627dccc1\",\"title\":\"Training Kinetics in 15 Minutes: Large-scale Distributed Training on Videos\",\"url\":\"https://www.semanticscholar.org/paper/27ff341652fff45d545f68c6e00b0b07627dccc1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31092565\",\"name\":\"Talha Ali Khan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9df23768db7b6f68adb4441a3d50070649cc6a03\",\"title\":\"Masters Thesis: Multi-frame deep learning models for action detection in surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/9df23768db7b6f68adb4441a3d50070649cc6a03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1905.10608\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":\"10.1109/ICIP.2019.8803745\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c7bba13bc221b9490df561f6c152253024b35f93\",\"title\":\"Exploring Feature Representation and Training Strategies in Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/c7bba13bc221b9490df561f6c152253024b35f93\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1908.02486\",\"authors\":[{\"authorId\":\"51128181\",\"name\":\"Boyuan Jiang\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717890\",\"name\":\"W. Wu\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"}],\"doi\":\"10.1109/ICCV.2019.00209\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"title\":\"STM: SpatioTemporal and Motion Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b812b20192ffac37b03bde0261934a2a8c7fdf47\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79755154\",\"name\":\"Hongje Seong\"},{\"authorId\":\"2246939\",\"name\":\"Junhyuk Hyun\"},{\"authorId\":\"70400973\",\"name\":\"Euntai Kim\"}],\"doi\":\"10.1109/ICCVW.2019.00194\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"title\":\"Video Multitask Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"}],\"doi\":\"10.7916/D8-SRKZ-T696\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"title\":\"Deep Learning for Action Understanding in Video\",\"url\":\"https://www.semanticscholar.org/paper/3ea5b4e02a448174cbc6872eaec27695b04e9b87\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1485630780\",\"name\":\"Yanbin Hao\"},{\"authorId\":\"145063759\",\"name\":\"Hao Zhang\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"48874063\",\"name\":\"Q. Liu\"},{\"authorId\":\"144635784\",\"name\":\"X. Hu\"}],\"doi\":\"10.1145/3394171.3413595\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"title\":\"Compact Bilinear Augmented Query Structured Attention for Sport Highlights Classification\",\"url\":\"https://www.semanticscholar.org/paper/1e29826ff34cc39f04d23784ad8ec6649717e1ce\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144393682\",\"name\":\"Q. Ye\"},{\"authorId\":\"1654173355\",\"name\":\"Haoxin Zhong\"},{\"authorId\":\"143640699\",\"name\":\"C. Qu\"},{\"authorId\":\"46866955\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.3390/s20082346\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5ab81b36f88067720fc6309b6123983839672bf\",\"title\":\"Human Interaction Recognition Based on Whole-Individual Detection\",\"url\":\"https://www.semanticscholar.org/paper/b5ab81b36f88067720fc6309b6123983839672bf\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2004.01283\",\"authors\":[{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"49107065\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d97d2fe18aa00be936fa8492a0c394f3b6791ed4\",\"title\":\"BosphorusSign22k Sign Language Recognition Dataset\",\"url\":\"https://www.semanticscholar.org/paper/d97d2fe18aa00be936fa8492a0c394f3b6791ed4\",\"venue\":\"LREC 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014665420\",\"name\":\"Robert E. Tyrrell\"},{\"authorId\":\"153696623\",\"name\":\"Matthew S. Holden\"}],\"doi\":\"10.1080/21681163.2020.1835549\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd4a051057c23ca450408a78db78ab6b0274f416\",\"title\":\"Ultrasound video analysis for skill level assessment in FAST ultrasound\",\"url\":\"https://www.semanticscholar.org/paper/bd4a051057c23ca450408a78db78ab6b0274f416\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.06971\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1694235\",\"name\":\"Hanqing Lu\"}],\"doi\":\"10.1109/TIP.2020.3028207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5376cbbf263fb6433da15a81948c9d4060677a59\",\"title\":\"Skeleton-Based Action Recognition With Multi-Stream Adaptive Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5376cbbf263fb6433da15a81948c9d4060677a59\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.05687\",\"authors\":[{\"authorId\":\"119997084\",\"name\":\"Xuhua Huang\"},{\"authorId\":\"1690418794\",\"name\":\"Jiarui Xu\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"},{\"authorId\":\"2088295\",\"name\":\"C. Tang\"}],\"doi\":\"10.1109/cvpr42600.2020.00890\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6404aaba4d243b519b7c65a4e52cb9ffb886f042\",\"title\":\"Fast Video Object Segmentation With Temporal Aggregation Network and Dynamic Template Matching\",\"url\":\"https://www.semanticscholar.org/paper/6404aaba4d243b519b7c65a4e52cb9ffb886f042\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121339452\",\"name\":\"Y. Tian\"},{\"authorId\":\"1810382\",\"name\":\"Zhaohui Che\"},{\"authorId\":\"116279011\",\"name\":\"Wenbo Bao\"},{\"authorId\":\"1509899757\",\"name\":\"Guangtao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1007/978-3-030-58568-6_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27568c821ab008facaa57dc4f99217a294e196c4\",\"title\":\"Self-supervised Motion Representation via Scattering Local Motion Cues\",\"url\":\"https://www.semanticscholar.org/paper/27568c821ab008facaa57dc4f99217a294e196c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.09228\",\"authors\":[{\"authorId\":\"84102771\",\"name\":\"L. Dai\"},{\"authorId\":\"46522414\",\"name\":\"Xiaohong Liu\"},{\"authorId\":\"3428585\",\"name\":\"Chengqi Li\"},{\"authorId\":null,\"name\":\"Jun Chen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c24e0f42c1fb9d46f5381342139236647745c943\",\"title\":\"AWNet: Attentive Wavelet Network for Image ISP\",\"url\":\"https://www.semanticscholar.org/paper/c24e0f42c1fb9d46f5381342139236647745c943\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04608\",\"authors\":[{\"authorId\":\"1527103472\",\"name\":\"Yixuan Li\"},{\"authorId\":\"50218816\",\"name\":\"Zixu Wang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"39914710\",\"name\":\"Gangshan Wu\"}],\"doi\":\"10.1007/978-3-030-58517-4_5\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e6e3034cd8855616533d091dc1d70e969c20a42b\",\"title\":\"Actions as Moving Points\",\"url\":\"https://www.semanticscholar.org/paper/e6e3034cd8855616533d091dc1d70e969c20a42b\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.06640\",\"authors\":[{\"authorId\":\"52023459\",\"name\":\"Steven Schwarcz\"},{\"authorId\":\"104382958\",\"name\":\"P. Xu\"},{\"authorId\":\"1401079497\",\"name\":\"David B. D'Ambrosio\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"2574014\",\"name\":\"H. Phan\"},{\"authorId\":\"3111912\",\"name\":\"Navdeep Jaitly\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"title\":\"SPIN: A High Speed, High Resolution Vision Dataset for Tracking and Action Recognition in Ping Pong\",\"url\":\"https://www.semanticscholar.org/paper/6e7a36fb58596cefc089de92696fc6f5cfc7259c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49836180\",\"name\":\"Zhimin Bai\"},{\"authorId\":\"2849542\",\"name\":\"H. Yan\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"}],\"doi\":\"10.1007/978-3-030-31654-9_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e3baf29a555ca959f51b848fb21ee224835db9b\",\"title\":\"High-Order Graph Convolutional Network for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5e3baf29a555ca959f51b848fb21ee224835db9b\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1912.04070\",\"authors\":[{\"authorId\":\"82657029\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"title\":\"Synthetic Humans for Action Recognition from Unseen Viewpoints\",\"url\":\"https://www.semanticscholar.org/paper/d9cd1ffcd91ef7e51b7a6bb4e65a3fada4e11244\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2536658\",\"name\":\"Mahesh Subedar\"},{\"authorId\":\"13026224\",\"name\":\"Ranganath Krishnan\"},{\"authorId\":\"1405331439\",\"name\":\"P. Lopez-Meyer\"},{\"authorId\":\"1798616\",\"name\":\"O. Tickoo\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/ICCV.2019.00640\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8eca936f462712f3d67ebe564292857144f704f1\",\"title\":\"Uncertainty-Aware Audiovisual Activity Recognition Using Deep Bayesian Variational Inference\",\"url\":\"https://www.semanticscholar.org/paper/8eca936f462712f3d67ebe564292857144f704f1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31993415\",\"name\":\"A. Clark\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"83769658\",\"name\":\"K. Simonyan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"12c37cb419121cdb43f2c6620303932f43e2e1b7\",\"title\":\"Adversarial Video Generation on Complex Datasets\",\"url\":\"https://www.semanticscholar.org/paper/12c37cb419121cdb43f2c6620303932f43e2e1b7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1902.05488\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"48946791\",\"name\":\"Xiaolong Shen\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"47319805\",\"name\":\"S. Li\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1016/J.JVCIR.2019.02.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4a47d580e8a3129fdf070f99d5030056058f52b\",\"title\":\"Exploring Frame Segmentation Networks for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/c4a47d580e8a3129fdf070f99d5030056058f52b\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":\"1905.11799\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"26485115\",\"name\":\"Lianqiang Zhou\"}],\"doi\":\"10.24963/ijcai.2019/130\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"37252f8cd1324a972131fc6a92f778835ba2fac3\",\"title\":\"Hallucinating Optical Flow Features for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/37252f8cd1324a972131fc6a92f778835ba2fac3\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1807.05073\",\"authors\":[{\"authorId\":\"71425456\",\"name\":\"Xingyu Liao\"},{\"authorId\":\"144486617\",\"name\":\"Lingxiao He\"},{\"authorId\":\"2016529\",\"name\":\"Zhouwang Yang\"}],\"doi\":\"10.1007/978-3-030-20876-9_39\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bff271886a64964a0a3f4ccdb6e0abb85abfbea0\",\"title\":\"Video-based Person Re-identification via 3D Convolutional Networks and Non-local Attention\",\"url\":\"https://www.semanticscholar.org/paper/bff271886a64964a0a3f4ccdb6e0abb85abfbea0\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1809.03316\",\"authors\":[{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"1793739\",\"name\":\"David J. Fleet\"}],\"doi\":\"10.1007/978-3-030-11018-5_53\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de94c7faeb3e4baf24bde841ff1bf3af6f38a81a\",\"title\":\"Hierarchical Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/de94c7faeb3e4baf24bde841ff1bf3af6f38a81a\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1802.06822\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":\"144983134\",\"name\":\"J. Chan\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"145730148\",\"name\":\"Hassan Mansour\"},{\"authorId\":\"1690385\",\"name\":\"A. Vetro\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01219-9_33\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"title\":\"Online Detection of Action Start in Untrimmed, Streaming Videos\",\"url\":\"https://www.semanticscholar.org/paper/b8b4a0bdfb561edaaed971f6e416c641b295376d\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390770350\",\"name\":\"Liyuan Wang\"},{\"authorId\":\"47539278\",\"name\":\"J. Zhang\"},{\"authorId\":\"48957872\",\"name\":\"Meng Wang\"},{\"authorId\":\"1902835560\",\"name\":\"Jimiao Tian\"},{\"authorId\":\"145210913\",\"name\":\"L. Zhuo\"}],\"doi\":\"10.1016/J.PATREC.2020.09.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c764b579b6c751de978a1da2ff5a9f87c38e4f75\",\"title\":\"Multilevel fusion of multimodal deep features for porn streamer recognition in live video\",\"url\":\"https://www.semanticscholar.org/paper/c764b579b6c751de978a1da2ff5a9f87c38e4f75\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":\"1801.10304\",\"authors\":[{\"authorId\":\"21518096\",\"name\":\"Zhengyuan Yang\"},{\"authorId\":\"3092578\",\"name\":\"Y. Li\"},{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICPR.2018.8546012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"title\":\"Action Recognition with Visual Attention on Skeleton Images\",\"url\":\"https://www.semanticscholar.org/paper/e9ef13f6e59361d67f4b4fe7132cb7b3ce1bb6d0\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9411658\",\"name\":\"Jiangtao Kong\"},{\"authorId\":\"104301768\",\"name\":\"R. Xu\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"79228663\",\"name\":\"K. Li\"},{\"authorId\":\"108575462\",\"name\":\"W. Ma\"}],\"doi\":\"10.1109/ICIP.2019.8803586\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6e891a6638043735f4d78561f433084be46845f1\",\"title\":\"Spatial Temporal Attentional Glimpse for Human Activity Classification in Video\",\"url\":\"https://www.semanticscholar.org/paper/6e891a6638043735f4d78561f433084be46845f1\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"95906612\",\"name\":\"D. Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"30477181\",\"name\":\"Yie-Tarng Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1109/ICCVW.2019.00125\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a160c956afc22ad837e61f865eb80169bd12259\",\"title\":\"Extreme Low Resolution Action Recognition with Spatial-Temporal Multi-Head Self-Attention and Knowledge Distillation\",\"url\":\"https://www.semanticscholar.org/paper/2a160c956afc22ad837e61f865eb80169bd12259\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2004.03044\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"47120072\",\"name\":\"Xizi Wang\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"41066643\",\"name\":\"Zelin Pu\"},{\"authorId\":\"153499091\",\"name\":\"E. Atkins\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a8be994e7069236d94e30c4c7b481988effc106\",\"title\":\"When, Where, and What? A New Dataset for Anomaly Detection in Driving Videos\",\"url\":\"https://www.semanticscholar.org/paper/9a8be994e7069236d94e30c4c7b481988effc106\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1007/978-3-030-04167-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caae04e73d362180f9586fabb224244200add105\",\"title\":\"Multi-stream with Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/caae04e73d362180f9586fabb224244200add105\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1657366361\",\"name\":\"Hanzao Chen\"},{\"authorId\":\"2667341\",\"name\":\"Xiaofen Xing\"},{\"authorId\":\"9303726\",\"name\":\"Xiangmin Xu\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054757\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b3e313a139b0f2f9ae09d4137485e8f277732aa\",\"title\":\"Learning Spatio-Temporal Convolutional Network for Real-Time Object Tracking\",\"url\":\"https://www.semanticscholar.org/paper/6b3e313a139b0f2f9ae09d4137485e8f277732aa\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"34561667\",\"name\":\"Michal Koperski\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":\"10.1109/AVSS.2018.8639122\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0793b85c46c29387a1cc3ef801dcbc4782126e3\",\"title\":\"Deep-Temporal LSTM for Daily Living Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e0793b85c46c29387a1cc3ef801dcbc4782126e3\",\"venue\":\"2018 15th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2018},{\"arxivId\":\"1907.12919\",\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"152477216\",\"name\":\"P. Abreu\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"102c5f96b879de46921cfc1f589dbc364310cf54\",\"title\":\"Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/102c5f96b879de46921cfc1f589dbc364310cf54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.03152\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"50463545\",\"name\":\"Yang Guan\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"49576139\",\"name\":\"Longfei Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f0320cd101ed6426a4330ecb395015c266e976c\",\"title\":\"CTM: Collaborative Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9f0320cd101ed6426a4330ecb395015c266e976c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102769741\",\"name\":\"Jung-In. Park\"},{\"authorId\":\"49685029\",\"name\":\"J. Lee\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"2099537\",\"name\":\"Seungryong Kim\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICIP.2019.8803589\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6633bf2049917272ba7f60087d3b0a1e89e21e3\",\"title\":\"Graph Regularization Network with Semantic Affinity for Weakly-Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a6633bf2049917272ba7f60087d3b0a1e89e21e3\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"48093650\",\"name\":\"Chunhui Liu\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"9956463\",\"name\":\"Yueyu Hu\"}],\"doi\":\"10.1145/3365212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"76f6ca119c719cd9f9362a160fb15af2b895095f\",\"title\":\"A Benchmark Dataset and Comparison Study for Multi-modal Human Action Analytics\",\"url\":\"https://www.semanticscholar.org/paper/76f6ca119c719cd9f9362a160fb15af2b895095f\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":\"1903.06855\",\"authors\":[{\"authorId\":\"88115299\",\"name\":\"Ali Oguz Uzman\"},{\"authorId\":\"49273321\",\"name\":\"J. Horn\"},{\"authorId\":\"1699019\",\"name\":\"Sven Behnke\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b04731f6fea28694bcead177f70ad9c0a06beaca\",\"title\":\"Learning super-resolution 3D segmentation of plant root MRI images from few examples\",\"url\":\"https://www.semanticscholar.org/paper/b04731f6fea28694bcead177f70ad9c0a06beaca\",\"venue\":\"ESANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2302223\",\"name\":\"Manolis Vasileiadis\"},{\"authorId\":\"4408876\",\"name\":\"C. Bouganis\"},{\"authorId\":\"15784009\",\"name\":\"G. Stavropoulos\"},{\"authorId\":\"143636644\",\"name\":\"D. Tzovaras\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"24db2c29d4a1b2b4130ff2123816873ed6b90a4e\",\"title\":\"Optimising 3D-CNN Design towards Human Pose Estimation on Low Power Devices\",\"url\":\"https://www.semanticscholar.org/paper/24db2c29d4a1b2b4130ff2123816873ed6b90a4e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1812.04172\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46865129\",\"name\":\"J. Shi\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e412efc9baecddac274639c0a5140aa28446792c\",\"title\":\"Learning Discriminative Motion Features Through Detection\",\"url\":\"https://www.semanticscholar.org/paper/e412efc9baecddac274639c0a5140aa28446792c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8277405\",\"name\":\"Brian Dolhansky\"},{\"authorId\":\"1749686057\",\"name\":\"Joanna Bitton\"},{\"authorId\":\"1417654107\",\"name\":\"Ben Pflaum\"},{\"authorId\":\"119590112\",\"name\":\"Jikuo Lu\"},{\"authorId\":\"1410913697\",\"name\":\"Russ Howes\"},{\"authorId\":\"51202149\",\"name\":\"Menglin Wang\"},{\"authorId\":\"1399086207\",\"name\":\"C. Canton-Ferrer\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1af36c1a0fafa4aed6ad7937a32b962982e2654b\",\"title\":\"The DeepFake Detection Challenge Dataset\",\"url\":\"https://www.semanticscholar.org/paper/1af36c1a0fafa4aed6ad7937a32b962982e2654b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.08897\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"48386951\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"49051904\",\"name\":\"P. Yao\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/cvpr42600.2020.01034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"833560cd68a3e3d1be1bc650756dd6c679798551\",\"title\":\"Normalized and Geometry-Aware Self-Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/833560cd68a3e3d1be1bc650756dd6c679798551\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.09743\",\"authors\":[{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90027124137516217a53d167d0b668de0f0e561d\",\"title\":\"On Evaluating Weakly Supervised Action Segmentation Methods\",\"url\":\"https://www.semanticscholar.org/paper/90027124137516217a53d167d0b668de0f0e561d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.05227\",\"authors\":[{\"authorId\":\"2008155399\",\"name\":\"Th'eo Ayral\"},{\"authorId\":\"3048367\",\"name\":\"M. Pedersoli\"},{\"authorId\":\"3477862\",\"name\":\"S. Bacon\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9080a9f5464b37572202e4a4061997428993fe50\",\"title\":\"Temporal Stochastic Softmax for 3D CNNs: An Application in Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9080a9f5464b37572202e4a4061997428993fe50\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3446334\",\"name\":\"Hehe Fan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"title\":\"From Video Classification to Video Prediction: Deep Learning Approaches to Video Modelling\",\"url\":\"https://www.semanticscholar.org/paper/bea684bb4f9b96c09169ef1a45fc3f4ebf24369c\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26986716\",\"name\":\"Clemens Pohlt\"},{\"authorId\":\"2016549\",\"name\":\"T. Schlegl\"},{\"authorId\":\"1724954\",\"name\":\"S. Wachsmuth\"}],\"doi\":\"10.1109/SMC.2019.8913873\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eb4ee1232012908a0b40fa927be4bbcb0e646edf\",\"title\":\"Human Work Activity Recognition for Working Cells in Industrial Production Contexts\",\"url\":\"https://www.semanticscholar.org/paper/eb4ee1232012908a0b40fa927be4bbcb0e646edf\",\"venue\":\"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8702449\",\"name\":\"Wanneng Wang\"},{\"authorId\":\"47009814\",\"name\":\"Yanan Ma\"},{\"authorId\":\"144947764\",\"name\":\"Ke Gao\"},{\"authorId\":\"152813130\",\"name\":\"J. Cao\"}],\"doi\":\"10.1145/3343031.3350884\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0be689463698d92433b4fd343379a32e763c9f2c\",\"title\":\"Cost-free Transfer Learning Mechanism: Deep Digging Relationships of Action Categories\",\"url\":\"https://www.semanticscholar.org/paper/0be689463698d92433b4fd343379a32e763c9f2c\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920920163\",\"name\":\"Haofei Wang\"},{\"authorId\":\"49298973\",\"name\":\"Junfeng Li\"}],\"doi\":\"10.1109/ACCESS.2020.3017076\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"title\":\"Human Action Recognition Algorithm Based on Multi-Feature Map Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1803.08094\",\"authors\":[{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"40893359\",\"name\":\"Byungsu Min\"},{\"authorId\":\"40893002\",\"name\":\"Nadha Gafoor\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"7f52b5bbc2678d3bebef7e00e281d5ccdbac9f4b\",\"title\":\"T-RECS: Training for Rate-Invariant Embeddings by Controlling Speed for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f52b5bbc2678d3bebef7e00e281d5ccdbac9f4b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2012.05698\",\"authors\":[{\"authorId\":\"1399491371\",\"name\":\"Agelos Kratimenos\"},{\"authorId\":\"2829330\",\"name\":\"Georgios Pavlakos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0a710020fc416b9fdb4217b2fc9a5142bb51e161\",\"title\":\"Independent Sign Language Recognition with 3D Body, Hands, and Face Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/0a710020fc416b9fdb4217b2fc9a5142bb51e161\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.01874\",\"authors\":[{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/TIP.2020.3007841\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"title\":\"Mutual Context Network for Jointly Estimating Egocentric Gaze and Action\",\"url\":\"https://www.semanticscholar.org/paper/78d95b989b807f28ef624318e3cb583ca1d73a3e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1804.09627\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"47465174\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"}],\"doi\":\"10.1145/3265987.3265995\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"title\":\"Actor and Observer: Joint Modeling of First and Third-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/e5bce81f9f0a4b962ae39205be9985bc5128fce9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2011.09192\",\"authors\":[{\"authorId\":\"103368444\",\"name\":\"K. Tuyls\"},{\"authorId\":\"2008186335\",\"name\":\"Shayegan Omidshafiei\"},{\"authorId\":\"2008186474\",\"name\":\"Paul Muller\"},{\"authorId\":\"47197505\",\"name\":\"Zhe Wang\"},{\"authorId\":\"2007915382\",\"name\":\"Jerome Connor\"},{\"authorId\":\"2008182142\",\"name\":\"Daniel Hennes\"},{\"authorId\":\"145253240\",\"name\":\"I. Graham\"},{\"authorId\":\"52462738\",\"name\":\"W. Spearman\"},{\"authorId\":\"2026325301\",\"name\":\"Tim Waskett\"},{\"authorId\":\"2026283770\",\"name\":\"Dafydd Steele\"},{\"authorId\":\"152831141\",\"name\":\"Pauline Luc\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"51980959\",\"name\":\"Alexandre Galashov\"},{\"authorId\":\"2005813\",\"name\":\"G. Thornton\"},{\"authorId\":\"47431108\",\"name\":\"R. Elie\"},{\"authorId\":\"2905900\",\"name\":\"P. Sprechmann\"},{\"authorId\":\"50713166\",\"name\":\"P. Moreno\"},{\"authorId\":\"3421987\",\"name\":\"Kris Cao\"},{\"authorId\":\"3468254\",\"name\":\"Marta Garnelo\"},{\"authorId\":\"9076891\",\"name\":\"P. Dutta\"},{\"authorId\":\"1806291\",\"name\":\"Michal Valko\"},{\"authorId\":\"1599360864\",\"name\":\"Nicolas Heess\"},{\"authorId\":\"1392692054\",\"name\":\"Alex Bridgland\"},{\"authorId\":\"3422031\",\"name\":\"Julien P\\u00e9rolat\"},{\"authorId\":\"1419267454\",\"name\":\"Bart De Vylder\"},{\"authorId\":\"49961426\",\"name\":\"A. Eslami\"},{\"authorId\":\"144845452\",\"name\":\"M. Rowland\"},{\"authorId\":\"2689633\",\"name\":\"Andrew Jaegle\"},{\"authorId\":\"49274028\",\"name\":\"R. Munos\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"2026327929\",\"name\":\"Razia Ahamed\"},{\"authorId\":\"1404756328\",\"name\":\"Simon Bouton\"},{\"authorId\":\"2026355587\",\"name\":\"Nathalie Beauguerlange\"},{\"authorId\":\"2026325402\",\"name\":\"Jackson Broshear\"},{\"authorId\":\"1686971\",\"name\":\"T. Graepel\"},{\"authorId\":\"1838779\",\"name\":\"D. Hassabis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66240545b56959cec31b4187d93e71884365d1f7\",\"title\":\"Game Plan: What AI can do for Football, and What Football can do for AI\",\"url\":\"https://www.semanticscholar.org/paper/66240545b56959cec31b4187d93e71884365d1f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.09930\",\"authors\":[{\"authorId\":\"7654960\",\"name\":\"Joanna Materzynska\"},{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"46796686\",\"name\":\"Roei Herzig\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"39635018\",\"name\":\"Xiaolong Wang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/cvpr42600.2020.00113\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"af06120e7883ff969746ab473bfe09e642a90fc3\",\"title\":\"Something-Else: Compositional Action Recognition With Spatial-Temporal Interaction Networks\",\"url\":\"https://www.semanticscholar.org/paper/af06120e7883ff969746ab473bfe09e642a90fc3\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.07064\",\"authors\":[{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":\"10.1109/cvpr42600.2020.01428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"title\":\"On Translation Invariance in CNNs: Convolutional Layers can Exploit Absolute Spatial Location\",\"url\":\"https://www.semanticscholar.org/paper/e00b35920a38cfc3fc58c72d70f5518b0a397a8d\",\"venue\":\"CVPR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5106839\",\"name\":\"Evelien H. S. Schut\"},{\"authorId\":\"40106013\",\"name\":\"A. Alonso\"},{\"authorId\":\"1391614617\",\"name\":\"Steven Smits\"},{\"authorId\":\"4735342\",\"name\":\"L. Genzel\"}],\"doi\":\"10.1016/j.nlm.2020.107265\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"03915db7c9cf1db1fb5f169b4d0ba5c21abd9ac4\",\"title\":\"The Object Space Task reveals increased expression of cumulative memory in a mouse model of Kleefstra syndrome\",\"url\":\"https://www.semanticscholar.org/paper/03915db7c9cf1db1fb5f169b4d0ba5c21abd9ac4\",\"venue\":\"Neurobiology of Learning and Memory\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"title\":\"Feature-Supervised Action Modality Transfer\",\"url\":\"https://www.semanticscholar.org/paper/b7f3c20652907d4aae0c773f265d5cb833d5d767\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Valeo. ai\"},{\"authorId\":null,\"name\":\"Valeo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9c8707ffb59b37029942baf4606b415b462de8eb\",\"title\":\"Driving Behavior Explanation with Multi-level Fusion\",\"url\":\"https://www.semanticscholar.org/paper/9c8707ffb59b37029942baf4606b415b462de8eb\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2002.05123\",\"authors\":[{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ef4549c94e1ee3e2a132c63bde4c2de51396febc\",\"title\":\"Over-the-Air Adversarial Flickering Attacks against Video Recognition Networks.\",\"url\":\"https://www.semanticscholar.org/paper/ef4549c94e1ee3e2a132c63bde4c2de51396febc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.08247\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.patrec.2020.11.012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c9ee02e3394adde596c35d1966566b2d971f426\",\"title\":\"Learn to cycle: Time-consistent feature discovery for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9c9ee02e3394adde596c35d1966566b2d971f426\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.10049\",\"authors\":[{\"authorId\":\"47787021\",\"name\":\"J. Li\"},{\"authorId\":\"47179758\",\"name\":\"Shiliang Zhang\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TIP.2020.2972108\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"title\":\"Multi-Scale Temporal Cues Learning for Video Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/a4ae54757da23ad0551308e5a5a314bc5a9515ff\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738590176\",\"name\":\"Alfarabi Imashev\"},{\"authorId\":\"134440762\",\"name\":\"Medet Mukushev\"},{\"authorId\":\"1556952980\",\"name\":\"V. Kimmelman\"},{\"authorId\":\"1913584\",\"name\":\"Anara Sandygulova\"}],\"doi\":\"10.18653/v1/2020.conll-1.51\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a7d07bb7d86ed0fd4825ea97ad18f7ba3bc7a60\",\"title\":\"A Dataset for Linguistic Understanding, Visual Evaluation, and Recognition of Sign Languages: The K-RSL\",\"url\":\"https://www.semanticscholar.org/paper/9a7d07bb7d86ed0fd4825ea97ad18f7ba3bc7a60\",\"venue\":\"CoNLL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51050729\",\"name\":\"Hongtao Yang\"},{\"authorId\":\"33913193\",\"name\":\"Xuming He\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"}],\"doi\":\"10.1109/CVPR.2018.00157\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"title\":\"One-Shot Action Localization by Learning Sequence Matching Network\",\"url\":\"https://www.semanticscholar.org/paper/bf69a9a967fcefaf66f4ca216de4d9afc68a496a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2011.00362\",\"authors\":[{\"authorId\":\"47589719\",\"name\":\"Ashish Jaiswal\"},{\"authorId\":\"33166796\",\"name\":\"A. R. Babu\"},{\"authorId\":\"1780642035\",\"name\":\"Mohammad Zaki Zadeh\"},{\"authorId\":\"153789025\",\"name\":\"D. Banerjee\"},{\"authorId\":\"1728274\",\"name\":\"F. Makedon\"}],\"doi\":\"10.3390/technologies9010002\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02f3c052a9cf675a6f033eac56c9dacb0a10ea28\",\"title\":\"A Survey on Contrastive Self-supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/02f3c052a9cf675a6f033eac56c9dacb0a10ea28\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07367\",\"authors\":[{\"authorId\":\"47319611\",\"name\":\"S. Li\"},{\"authorId\":\"9098920\",\"name\":\"Jinhui Yi\"},{\"authorId\":\"41022481\",\"name\":\"Yazan Abu Farha\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78be22768737a1bb97d7b1d0e1c479f50d429e58\",\"title\":\"Pose Refinement Graph Convolutional Network for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/78be22768737a1bb97d7b1d0e1c479f50d429e58\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.05264\",\"authors\":[{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"1400188907\",\"name\":\"Hezhen Hu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1145/3394171.3413931\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce50fa888551b640fe3dddc57289c27f325c029b\",\"title\":\"Boosting Continuous Sign Language Recognition via Cross Modality Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/ce50fa888551b640fe3dddc57289c27f325c029b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2007.15781\",\"authors\":[{\"authorId\":\"26663607\",\"name\":\"Baoxiong Jia\"},{\"authorId\":\"49069534\",\"name\":\"Yixin Chen\"},{\"authorId\":\"51442394\",\"name\":\"Siyuan Huang\"},{\"authorId\":\"2672448\",\"name\":\"Yixin Zhu\"},{\"authorId\":\"12554898\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1007/978-3-030-58574-7_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"title\":\"LEMMA: A Multi-view Dataset for Learning Multi-agent Multi-task Activities\",\"url\":\"https://www.semanticscholar.org/paper/cd6b1063f234836a1dcdc7f8a39c10c4d8fdbbbe\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.07306\",\"authors\":[{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c26974821644f8ae9ab2619c2b2725136214330d\",\"title\":\"COBE: Contextualized Object Embeddings from Narrated Instructional Video\",\"url\":\"https://www.semanticscholar.org/paper/c26974821644f8ae9ab2619c2b2725136214330d\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2003.02501\",\"authors\":[{\"authorId\":\"39832600\",\"name\":\"E. Chong\"},{\"authorId\":null,\"name\":\"Yongxin Wang\"},{\"authorId\":\"31601235\",\"name\":\"Nataniel Ruiz\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/cvpr42600.2020.00544\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95bdf80c6d53003374694eea9707a1d20ac93195\",\"title\":\"Detecting Attended Visual Targets in Video\",\"url\":\"https://www.semanticscholar.org/paper/95bdf80c6d53003374694eea9707a1d20ac93195\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1804.01824\",\"authors\":[{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2019.102886\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a427fc1fde8206136075785eda3d757278adfb44\",\"title\":\"Guess Where? Actor-Supervision for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a427fc1fde8206136075785eda3d757278adfb44\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":\"2003.10469\",\"authors\":[{\"authorId\":\"1587627172\",\"name\":\"Aviv Shamsian\"},{\"authorId\":\"1587754052\",\"name\":\"Ofri Kleinfeld\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":\"10.1007/978-3-030-58517-4_3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5b51d362a824851b4997903003746173fe41d348\",\"title\":\"Learning Object Permanence from Video\",\"url\":\"https://www.semanticscholar.org/paper/5b51d362a824851b4997903003746173fe41d348\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.10639\",\"authors\":[{\"authorId\":\"151352107\",\"name\":\"Valentin Gabeur\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-58548-8_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6871f6c5437a747fae75a19962f418d234ce2dc1\",\"title\":\"Multi-modal Transformer for Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/6871f6c5437a747fae75a19962f418d234ce2dc1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"115113072\",\"name\":\"S. Kondratiuk\"},{\"authorId\":\"9368047\",\"name\":\"I. Krak\"},{\"authorId\":\"1933321065\",\"name\":\"Anatolii Kylias\"},{\"authorId\":\"81418873\",\"name\":\"V. Kasianiuk\"}],\"doi\":\"10.1007/978-3-030-54215-3_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ded59719c96e05ffe1d39bb73d0ff73de74bb8fd\",\"title\":\"Fingerspelling Alphabet Recognition Using CNNs with 3D Convolutions for Cross Platform Applications\",\"url\":\"https://www.semanticscholar.org/paper/ded59719c96e05ffe1d39bb73d0ff73de74bb8fd\",\"venue\":\"ISDMCI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153490631\",\"name\":\"Y. Chang\"},{\"authorId\":\"100842298\",\"name\":\"C. S. Chan\"},{\"authorId\":\"1711669\",\"name\":\"Paolo Remagnino\"}],\"doi\":\"10.1007/s00521-020-04982-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a7a88c44f85f9ed9ac27de55d1838ba3ce4d05a2\",\"title\":\"Action recognition on continuous video\",\"url\":\"https://www.semanticscholar.org/paper/a7a88c44f85f9ed9ac27de55d1838ba3ce4d05a2\",\"venue\":\"Neural Computing and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1396300636\",\"name\":\"Avital Meshi\"},{\"authorId\":\"34963191\",\"name\":\"Angus G. Forbes\"}],\"doi\":\"10.1162/leon_a_01924\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc90334ac52834e223ed6e47a15adb0bb27ae51c\",\"title\":\"Stepping Inside the Classification Cube: An Intimate Interaction with an AI System\",\"url\":\"https://www.semanticscholar.org/paper/fc90334ac52834e223ed6e47a15adb0bb27ae51c\",\"venue\":\"Leonardo\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1857417\",\"name\":\"Kittipat Apicharttrisorn\"},{\"authorId\":\"23148437\",\"name\":\"Xukan Ran\"},{\"authorId\":\"1391202254\",\"name\":\"Jiasi Chen\"},{\"authorId\":\"145895343\",\"name\":\"S. V. Krishnamurthy\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3356250.3360044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bd7c11d713fc8e97c486f67641bc604c4c34d3aa\",\"title\":\"Frugal following: power thrifty object detection and tracking for mobile augmented reality\",\"url\":\"https://www.semanticscholar.org/paper/bd7c11d713fc8e97c486f67641bc604c4c34d3aa\",\"venue\":\"SenSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98365612\",\"name\":\"Wei Wu\"},{\"authorId\":\"119883591\",\"name\":\"J. Yu\"}],\"doi\":\"10.1109/CISP-BMEI48845.2019.8965888\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45386412354d3a26f37cdee84a72816439c4bef1\",\"title\":\"Large-Scale Image Action Recognition Depends on Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/45386412354d3a26f37cdee84a72816439c4bef1\",\"venue\":\"2019 12th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145008428\",\"name\":\"Anh H. Nguyen\"},{\"authorId\":\"145847451\",\"name\":\"Huyen T. T. Tran\"},{\"authorId\":\"2217440\",\"name\":\"Duc V. Nguyen\"},{\"authorId\":\"145511287\",\"name\":\"T. Thang\"}],\"doi\":\"10.1109/icce-asia46551.2019.8942197\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e08c7666f2aca01bd8f8c29ea2593ab1ca4e0475\",\"title\":\"Impacts of Artefacts and Adversarial Attacks in Deep Learning based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e08c7666f2aca01bd8f8c29ea2593ab1ca4e0475\",\"venue\":\"2019 IEEE International Conference on Consumer Electronics - Asia (ICCE-Asia)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00183\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"title\":\"Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/718418a88461c44a77bc4c0a1bdc9f3e6434fbab\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1908.08216\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2951229\",\"name\":\"Hisham Cholakkal\"},{\"authorId\":\"152256401\",\"name\":\"Fahad Khan\"},{\"authorId\":\"144951205\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1109/ICCV.2019.00877\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4a762c74d6c1f66b1d7a6a439f35c5c30e37c53f\",\"title\":\"3C-Net: Category Count and Center Loss for Weakly-Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4a762c74d6c1f66b1d7a6a439f35c5c30e37c53f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"1907582\",\"name\":\"T. Zhang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3240508.3240566\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"title\":\"Watch, Think and Attend: End-to-End Video Classification via Dynamic Knowledge Evolution Modeling\",\"url\":\"https://www.semanticscholar.org/paper/eb904609f211216a98bdab0a6d12c2f82ef89b0f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"2011.07735\",\"authors\":[{\"authorId\":\"40016108\",\"name\":\"Aman Chadha\"},{\"authorId\":\"2025073690\",\"name\":\"Gurneet Arora\"},{\"authorId\":\"2025065763\",\"name\":\"Navpreet Kaloty\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"title\":\"iPerceive: Applying Common-Sense Reasoning to Multi-Modal Dense Video Captioning and Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bcffc406b4cc5b179ed973cd7f974c656e129c4f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02426\",\"authors\":[{\"authorId\":\"1879292723\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"2029317446\",\"name\":\"Ting Yu\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e84c8a5b818d6c121083550bae9bda257a4df60f\",\"title\":\"Spatial-Temporal Alignment Network for Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/e84c8a5b818d6c121083550bae9bda257a4df60f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05515\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0e599d703e358d6e554da859cff116553053d0fa\",\"title\":\"AViD Dataset: Anonymized Videos from Diverse Countries\",\"url\":\"https://www.semanticscholar.org/paper/0e599d703e358d6e554da859cff116553053d0fa\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134880523\",\"name\":\"Xinyu Li\"},{\"authorId\":\"49140658\",\"name\":\"M. Li\"},{\"authorId\":\"48607861\",\"name\":\"Y. Wu\"},{\"authorId\":\"12183490\",\"name\":\"X. Zhou\"},{\"authorId\":\"50673731\",\"name\":\"F. Hao\"},{\"authorId\":\"2031457741\",\"name\":\"Xueyu Liu\"}],\"doi\":\"10.1145/3433996.3434485\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"100d15c7b2e15d04ea95b99ed68f6712532260a5\",\"title\":\"An accurate classification method based on multi-focus videos and deep learning for urinary red blood cell\",\"url\":\"https://www.semanticscholar.org/paper/100d15c7b2e15d04ea95b99ed68f6712532260a5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.02755\",\"authors\":[{\"authorId\":\"3288111\",\"name\":\"S. Ghosh\"},{\"authorId\":\"50714560\",\"name\":\"A. Agarwal\"},{\"authorId\":\"27456119\",\"name\":\"Zarana Parekh\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.18653/v1/N19-1198\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"title\":\"ExCL: Extractive Clip Localization Using Natural Language Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ddf69a6ef015a1b0668ca48a486c4cc7e22a7d9c\",\"venue\":\"NAACL-HLT\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145270607\",\"name\":\"M. Brown\"},{\"authorId\":\"3055953\",\"name\":\"Keith Fieldhouse\"},{\"authorId\":\"2754027\",\"name\":\"E. Swears\"},{\"authorId\":\"3356764\",\"name\":\"Paul Tunison\"},{\"authorId\":\"80916270\",\"name\":\"Adam Romlein\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":\"10.1109/WACV.2019.00207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b58b4db7ee349b963cebe272b92c5d5eb3b1770a\",\"title\":\"Multi-Modal Detection Fusion on a Mobile UGV for Wide-Area, Long-Range Surveillance\",\"url\":\"https://www.semanticscholar.org/paper/b58b4db7ee349b963cebe272b92c5d5eb3b1770a\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1901.09107\",\"authors\":[{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"50317425\",\"name\":\"Abhishek Das\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"153149395\",\"name\":\"P. Anderson\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"}],\"doi\":\"10.1109/CVPR.2019.00774\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"044c56af7005c2013ce24c7199af716319378d7f\",\"title\":\"Audio Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.05067\",\"authors\":[{\"authorId\":\"47999368\",\"name\":\"Yi-Ting Yeh\"},{\"authorId\":\"145514809\",\"name\":\"Tzu-Chuan Lin\"},{\"authorId\":\"152498628\",\"name\":\"Hsiao-Hua Cheng\"},{\"authorId\":\"152141374\",\"name\":\"Yu-Hsuan Deng\"},{\"authorId\":\"27629426\",\"name\":\"Shang-Yu Su\"},{\"authorId\":\"1725643\",\"name\":\"Yun-Nung (Vivian) Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2539fad727e1def50b87fc88d3a499b4fe1f393\",\"title\":\"Reactive Multi-Stage Feature Fusion for Multimodal Dialogue Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f2539fad727e1def50b87fc88d3a499b4fe1f393\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.14982\",\"authors\":[{\"authorId\":\"1478813684\",\"name\":\"Rui Dai\"},{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"18139992\",\"name\":\"Saurav Sharma\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a99a0f24b71f8048f4d30a4ca27dafca3fa7ac24\",\"title\":\"Toyota Smarthome Untrimmed: Real-World Untrimmed Videos for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/a99a0f24b71f8048f4d30a4ca27dafca3fa7ac24\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093549\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"29995014\",\"name\":\"Shiren Li\"},{\"authorId\":\"30646831\",\"name\":\"Zhi-kui Duan\"},{\"authorId\":\"48803999\",\"name\":\"Z. Yuan\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053794\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a021daf17351415827420456377f77f6a146fd56\",\"title\":\"Rethinking Temporal-Related Sample for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a021daf17351415827420456377f77f6a146fd56\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1801.09184\",\"authors\":[{\"authorId\":\"2860057\",\"name\":\"Yancheng Bai\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"601d81b164afceecf6f155d60bfb400510a5be4e\",\"title\":\"Contextual Multi-Scale Region Convolutional 3D Network for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/601d81b164afceecf6f155d60bfb400510a5be4e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30779333\",\"name\":\"Seunghan Yang\"},{\"authorId\":\"3432445\",\"name\":\"Seungjun Jung\"},{\"authorId\":\"72584079\",\"name\":\"Heekwang Kang\"},{\"authorId\":\"70493359\",\"name\":\"Changick Kim\"}],\"doi\":\"10.1007/978-3-030-37731-1_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b88cf48060647841c8e316e885ea069f285bebb6\",\"title\":\"The Korean Sign Language Dataset for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b88cf48060647841c8e316e885ea069f285bebb6\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398447065\",\"name\":\"Sadjad Asghari-Esfeden\"},{\"authorId\":\"1687866\",\"name\":\"M. Sznaier\"},{\"authorId\":\"143867334\",\"name\":\"O. Camps\"}],\"doi\":\"10.1109/WACV45572.2020.9093500\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51bcb7de98bedf65215910fcfd08555d5eed682a\",\"title\":\"Dynamic Motion Representation for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51bcb7de98bedf65215910fcfd08555d5eed682a\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004346846\",\"name\":\"Jialin Gao\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145987553\",\"name\":\"F. Li\"},{\"authorId\":\"3223020\",\"name\":\"Xin Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b0b58740e78ca06cc8c2963720e1657d012d9922\",\"title\":\"Multi-modal fusion network based on relation-aware pyramid network for temporal action localization\",\"url\":\"https://www.semanticscholar.org/paper/b0b58740e78ca06cc8c2963720e1657d012d9922\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.07175\",\"authors\":[{\"authorId\":\"3151024\",\"name\":\"Lang Su\"},{\"authorId\":\"2037365541\",\"name\":\"Chuqing Hu\"},{\"authorId\":\"46439101\",\"name\":\"G. Li\"},{\"authorId\":\"1491099112\",\"name\":\"Dongpu Cao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da72f519272681d685b5fb07e8d2e42b447e680b\",\"title\":\"MSAF: Multimodal Split Attention Fusion\",\"url\":\"https://www.semanticscholar.org/paper/da72f519272681d685b5fb07e8d2e42b447e680b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.10428\",\"authors\":[{\"authorId\":\"1400188907\",\"name\":\"Hezhen Hu\"},{\"authorId\":\"51476742\",\"name\":\"Wengang Zhou\"},{\"authorId\":\"2653622\",\"name\":\"Junfu Pu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"title\":\"Global-local Enhancement Network for NMFs-aware Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc338010de2bfba5dcf52d61bbb0ea3fe5495cea\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2217653\",\"name\":\"Y. Quan\"},{\"authorId\":\"47557959\",\"name\":\"Y. Chen\"},{\"authorId\":\"47462870\",\"name\":\"Ruotao Xu\"},{\"authorId\":\"153172100\",\"name\":\"Hui Ji\"}],\"doi\":\"10.1016/J.CVIU.2019.102794\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"title\":\"Attention with structure regularization for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0d17b7b11994bb3c85e44a3ae1c7ca7eeaeaafc\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1911.12509\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"40382978\",\"name\":\"Yifan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"title\":\"Action Recognition via Pose-Based Graph Convolutional Networks with Intermediate Dense Supervision\",\"url\":\"https://www.semanticscholar.org/paper/9471c5ea8fbd4bcdc780962770d062d1eaa5ce4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93385858\",\"name\":\"Z. Han\"},{\"authorId\":\"9260001\",\"name\":\"Yaling Liang\"},{\"authorId\":\"115023860\",\"name\":\"Zengqun Chen\"},{\"authorId\":\"6364267\",\"name\":\"Zhiheng Zhou\"}],\"doi\":\"10.3233/jifs-192067\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1eb45acc4f27fc47ed13249273cf5cb86476b154\",\"title\":\"A two-stream network with joint spatial-temporal distance for video-based person re-identification\",\"url\":\"https://www.semanticscholar.org/paper/1eb45acc4f27fc47ed13249273cf5cb86476b154\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4909159\",\"name\":\"J. Wu\"},{\"authorId\":\"50251654\",\"name\":\"Zhiguang Zhou\"},{\"authorId\":null,\"name\":\"Yanan Wang\"},{\"authorId\":\"31964291\",\"name\":\"Yi Li\"},{\"authorId\":\"122135877\",\"name\":\"X. Xu\"},{\"authorId\":\"1683889\",\"name\":\"Yusuke Uchida\"}],\"doi\":\"10.1145/3340555.3355717\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4f5d8b51f81c7d590b91e89241d1dfdbf901d069\",\"title\":\"Multi-feature and Multi-instance Learning with Anti-overfitting Strategy for Engagement Intensity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/4f5d8b51f81c7d590b91e89241d1dfdbf901d069\",\"venue\":\"ICMI\",\"year\":2019},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390412671\",\"name\":\"Yanbo Fan\"},{\"authorId\":\"46223195\",\"name\":\"Shuchen Weng\"},{\"authorId\":\"49889486\",\"name\":\"Y. Zhang\"},{\"authorId\":\"35580784\",\"name\":\"Boxin Shi\"},{\"authorId\":\"80266964\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2968054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"title\":\"Context-Aware Cross-Attention for Skeleton-Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/72b92168ce61d3d13f37c2f910dd3829bc1a2668\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1903.06070\",\"authors\":[{\"authorId\":\"2062432\",\"name\":\"Soheil Kolouri\"},{\"authorId\":\"3268923\",\"name\":\"Nicholas Ketz\"},{\"authorId\":\"26565367\",\"name\":\"Xinyun Zou\"},{\"authorId\":\"1753673\",\"name\":\"J. Krichmar\"},{\"authorId\":\"2888448\",\"name\":\"Praveen K. Pilly\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"84b1069da7581761e11ad2c1a2678eb41d53b5e6\",\"title\":\"Attention-Based Structural-Plasticity\",\"url\":\"https://www.semanticscholar.org/paper/84b1069da7581761e11ad2c1a2678eb41d53b5e6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1910.06699\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"3407519\",\"name\":\"Y. Cabon\"},{\"authorId\":\"26734366\",\"name\":\"N. Murray\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/s11263-019-01222-z\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"title\":\"Generating Human Action Videos by Coupling 3D Game Engines and Probabilistic Graphical Models\",\"url\":\"https://www.semanticscholar.org/paper/099bdf9cf1c59c7f5ed201759157fb505f51a762\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1811.09974\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"50023941\",\"name\":\"Y. Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1609/aaai.v33i01.33018674\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6ae72dc774f62b190036fb094be4558d827e53d2\",\"title\":\"Temporal Bilinear Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ae72dc774f62b190036fb094be4558d827e53d2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2011.07460\",\"authors\":[{\"authorId\":\"2024250141\",\"name\":\"Jacob Ouyang\"},{\"authorId\":\"1382495709\",\"name\":\"I. Galatzer-Levy\"},{\"authorId\":\"1734850560\",\"name\":\"V. Koesmahargyo\"},{\"authorId\":\"48571183\",\"name\":\"Liyong Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c76cf2400649cd540ce2b117aebc6002b177c267\",\"title\":\"Direct Classification of Emotional Intensity\",\"url\":\"https://www.semanticscholar.org/paper/c76cf2400649cd540ce2b117aebc6002b177c267\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50152643\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1109/ICASSP.2019.8682261\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e133e8cf792334969365ff7746ebed7b98fce702\",\"title\":\"Boundary Information Matters More: Accurate Temporal Action Detection with Temporal Boundary Network\",\"url\":\"https://www.semanticscholar.org/paper/e133e8cf792334969365ff7746ebed7b98fce702\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2012.03439\",\"authors\":[{\"authorId\":\"9726614\",\"name\":\"Haokui Zhang\"},{\"authorId\":\"31669239\",\"name\":\"Y. Li\"},{\"authorId\":\"5541349\",\"name\":\"Y. Jiang\"},{\"authorId\":\"40486942\",\"name\":\"P. Wang\"},{\"authorId\":\"46417172\",\"name\":\"Q. Shen\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.1109/TGRS.2019.2902568\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c2416c4b8e46ef14e17b3293ba98ac8a9a9294e\",\"title\":\"Hyperspectral Classification Based on Lightweight 3-D-CNN With Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/4c2416c4b8e46ef14e17b3293ba98ac8a9a9294e\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2019},{\"arxivId\":\"2011.00427\",\"authors\":[{\"authorId\":\"2874605\",\"name\":\"X. Liu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6d96b6405c1636bb7080ee809c8ec7fa1ada98f\",\"title\":\"Efficient Pipelines for Vision-Based Context Sensing\",\"url\":\"https://www.semanticscholar.org/paper/d6d96b6405c1636bb7080ee809c8ec7fa1ada98f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31445589\",\"name\":\"C. Lee\"},{\"authorId\":\"3097674\",\"name\":\"Hyo-Rim Choi\"},{\"authorId\":\"1452338168\",\"name\":\"S. Muralidharan\"},{\"authorId\":\"97578500\",\"name\":\"Heedong Ko\"},{\"authorId\":\"1452344757\",\"name\":\"Byounghyun Yoo\"},{\"authorId\":\"144766284\",\"name\":\"G. Kim\"}],\"doi\":\"10.1109/MFI49285.2020.9235269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cc72f9bc222c6cea118863ce7ac60edf93b47c4b\",\"title\":\"Machine Assisted Video Tagging of Elderly Activities in K-Log Centre\",\"url\":\"https://www.semanticscholar.org/paper/cc72f9bc222c6cea118863ce7ac60edf93b47c4b\",\"venue\":\"2020 IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI)\",\"year\":2020},{\"arxivId\":\"2005.06803\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"title\":\"TAM: Temporal Adaptive Module for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3ac6ad718bbdeda6b5b00b61983f8b520d8a6bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06288\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"98256637\",\"name\":\"Zhou Yang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"},{\"authorId\":\"46946060\",\"name\":\"M. Jian\"},{\"authorId\":\"49217626\",\"name\":\"Boxuan Zhao\"},{\"authorId\":\"3063894\",\"name\":\"Junchi Yan\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1016/j.neucom.2020.07.003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50efde486726ae435c28211b6cd123c6b61e3a99\",\"title\":\"Fusing Motion Patterns and Key Visual Information for Semantic Event Recognition in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/50efde486726ae435c28211b6cd123c6b61e3a99\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24702080\",\"name\":\"S. Tong\"},{\"authorId\":\"7727059\",\"name\":\"Yuzhuo Fu\"},{\"authorId\":\"9543601\",\"name\":\"Xinwei Yue\"},{\"authorId\":\"144125487\",\"name\":\"Hefei Ling\"}],\"doi\":\"10.1109/ACCESS.2018.2874073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3fbeda9cbce94bbc0d85494935ed27c49e8a0a6\",\"title\":\"Multi-View Gait Recognition Based on a Spatial-Temporal Deep Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c3fbeda9cbce94bbc0d85494935ed27c49e8a0a6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"1740721\",\"name\":\"F. Metze\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b02dba59a087f16d8286aec5e6481d5952a37df5\",\"title\":\"CMU Sinbad\\u2019s Submission for the DSTC7 AVSD Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b02dba59a087f16d8286aec5e6481d5952a37df5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ad2e71a521179599d133f07287a9a36d4019254\",\"title\":\"Learning De-biased Representations with Biased Representations\\u2013 Appendix \\u2013\",\"url\":\"https://www.semanticscholar.org/paper/7ad2e71a521179599d133f07287a9a36d4019254\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145491338\",\"name\":\"S. Palacio\"},{\"authorId\":\"1824088\",\"name\":\"V. Campos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ffd9e745e58f9dc876af7f68e9ef5b9d56d6461\",\"title\":\"VIDEO UNDERSTANDING THROUGH THE DISENTANGLEMENT OF APPEARANCE AND MOTION\",\"url\":\"https://www.semanticscholar.org/paper/7ffd9e745e58f9dc876af7f68e9ef5b9d56d6461\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1007/978-3-030-01219-9_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bec3c3e6bb9c738dad942f00fc69848018c3b1cc\",\"title\":\"Part-Activated Deep Reinforcement Learning for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/bec3c3e6bb9c738dad942f00fc69848018c3b1cc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"144106940\",\"name\":\"A. Soto\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1007/978-3-030-01225-0_43\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"62c1a6558a2a0d5fd6df4c0fec99dd9027d1c448\",\"title\":\"End-to-End Joint Semantic Segmentation of Actors and Actions in Video\",\"url\":\"https://www.semanticscholar.org/paper/62c1a6558a2a0d5fd6df4c0fec99dd9027d1c448\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01240-3_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78c4086c392d03e206d2a25be55768cd58ce3462\",\"title\":\"Action Search: Spotting Actions in Videos and Its Application to Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/78c4086c392d03e206d2a25be55768cd58ce3462\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1907.04632\",\"authors\":[{\"authorId\":\"145439284\",\"name\":\"Wei Peng\"},{\"authorId\":\"46761465\",\"name\":\"Xiaopeng Hong\"},{\"authorId\":\"1757287\",\"name\":\"G. Zhao\"}],\"doi\":\"10.1109/ICIP.2019.8802919\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"title\":\"Video Action Recognition Via Neural Architecture Searching\",\"url\":\"https://www.semanticscholar.org/paper/eabb3eff8811d4aadcdb7c285505295f39ac1613\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50986865\",\"name\":\"Andrei Liviu Nicolicioiu\"},{\"authorId\":\"51011850\",\"name\":\"Iulia Duta\"},{\"authorId\":\"1749627\",\"name\":\"Marius Leordeanu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"69309c61e336a32df3569248765e06abd2f35077\",\"title\":\"Recurrent Space-time Graphs for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/69309c61e336a32df3569248765e06abd2f35077\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46401013\",\"name\":\"Jian-wen Jiang\"},{\"authorId\":\"153843000\",\"name\":\"Y. Cao\"},{\"authorId\":\"80834369\",\"name\":\"L. Song\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"51487081\",\"name\":\"Yunkai Li\"},{\"authorId\":\"70397730\",\"name\":\"Ziyao Xu\"},{\"authorId\":\"47506758\",\"name\":\"Q. Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"145844907\",\"name\":\"Gang Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4f968688dcdd8980399265de1996a00a62034913\",\"title\":\"Human Centric Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/4f968688dcdd8980399265de1996a00a62034913\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1812.02817\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"2252963\",\"name\":\"Xinyu Li\"},{\"authorId\":\"3302978\",\"name\":\"Kaixiang Huang\"},{\"authorId\":\"7707929\",\"name\":\"Yehan Wang\"},{\"authorId\":\"51231992\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"144555425\",\"name\":\"Ivan Marsic\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"556ca2389246b0a848b578dc824b930e1337a4bc\",\"title\":\"Tri-axial Self-Attention for Concurrent Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/556ca2389246b0a848b578dc824b930e1337a4bc\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.11387\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"40058797\",\"name\":\"Xiaodong Yang\"},{\"authorId\":\"1800425\",\"name\":\"Jingen Liu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"title\":\"Self-Supervised Spatiotemporal Feature Learning via Video Rotation Prediction.\",\"url\":\"https://www.semanticscholar.org/paper/f7fa3b8ed5f3f75ace4fe8447ccd9abfbb19e621\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1908.10899\",\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"145607579\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"title\":\"Out the Window: A Crowd-Sourced Dataset for Activity Classification in Surveillance Video\",\"url\":\"https://www.semanticscholar.org/paper/8eae86794cb94adfc3022a6929d58c961ad73c1c\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405073588\",\"name\":\"Itsaso Rodr\\u00edguez-Moreno\"},{\"authorId\":\"1401677216\",\"name\":\"J. M. Mart\\u00ednez-Otzeta\"},{\"authorId\":\"144286136\",\"name\":\"B. Sierra\"},{\"authorId\":\"24857630\",\"name\":\"I. Rodriguez\"},{\"authorId\":\"95170363\",\"name\":\"E. Jauregi\"}],\"doi\":\"10.3390/s19143160\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"title\":\"Video Activity Recognition: State-of-the-Art\",\"url\":\"https://www.semanticscholar.org/paper/44f1ae791e8e858a9c7060e42d5db76b170b51e0\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":\"2001.07501\",\"authors\":[{\"authorId\":\"2719454\",\"name\":\"W. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b06383710f5dff3028db31d1497914d65888194\",\"title\":\"A Comprehensive Study on Temporal Modeling for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/6b06383710f5dff3028db31d1497914d65888194\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.12392\",\"authors\":[{\"authorId\":\"1958036\",\"name\":\"Gongbo Liang\"},{\"authorId\":\"48631827\",\"name\":\"Xiaoqin Wang\"},{\"authorId\":\"46867976\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1491631303\",\"name\":\"Xin Xing\"},{\"authorId\":\"1491643960\",\"name\":\"Hunter Blanton\"},{\"authorId\":\"1491644479\",\"name\":\"Tawfiq Salem\"},{\"authorId\":\"47259377\",\"name\":\"Nathan B. Jacobs\"}],\"doi\":\"10.1109/BIBM47256.2019.8983048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7d0e1914fb9df12cf42d1f8621d0de024276b735\",\"title\":\"Joint 2D-3D Breast Cancer Classification\",\"url\":\"https://www.semanticscholar.org/paper/7d0e1914fb9df12cf42d1f8621d0de024276b735\",\"venue\":\"2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145770427\",\"name\":\"Lin Ding\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"25141665\",\"name\":\"Hongfei Fan\"},{\"authorId\":\"1485105756\",\"name\":\"Changhuai Chen\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TIP.2020.2965306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"398b5f6b317dd6ecdd81cbd9723030db2a5bed0e\",\"title\":\"Joint Coding of Local and Global Deep Features in Videos for Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/398b5f6b317dd6ecdd81cbd9723030db2a5bed0e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1907.04433\",\"authors\":[{\"authorId\":\"46724450\",\"name\":\"Jian Guo\"},{\"authorId\":\"144466851\",\"name\":\"He He\"},{\"authorId\":\"145633170\",\"name\":\"Tong He\"},{\"authorId\":\"8789103\",\"name\":\"Leonard Lausen\"},{\"authorId\":null,\"name\":\"Mu Li\"},{\"authorId\":\"49955730\",\"name\":\"Haibin Lin\"},{\"authorId\":\"3008587\",\"name\":\"Xingjian Shi\"},{\"authorId\":\"48585703\",\"name\":\"C. Wang\"},{\"authorId\":\"2369548\",\"name\":\"Junyuan Xie\"},{\"authorId\":\"40881843\",\"name\":\"Sheng Zha\"},{\"authorId\":\"2085709\",\"name\":\"A. Zhang\"},{\"authorId\":\"39819831\",\"name\":\"H. Zhang\"},{\"authorId\":\"145430305\",\"name\":\"Zhi Zhang\"},{\"authorId\":\"48806269\",\"name\":\"Zhongyue Zhang\"},{\"authorId\":\"144147900\",\"name\":\"Shuai Zheng\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"56c5cd638111ce5bf720d70dfe034c5f7d2f868e\",\"title\":\"GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/56c5cd638111ce5bf720d70dfe034c5f7d2f868e\",\"venue\":\"J. Mach. Learn. Res.\",\"year\":2020},{\"arxivId\":\"2003.01888\",\"authors\":[{\"authorId\":\"1966561\",\"name\":\"S. Ghorbani\"},{\"authorId\":\"1519541371\",\"name\":\"Kimia Mahdaviani\"},{\"authorId\":\"40481439\",\"name\":\"A. Thaler\"},{\"authorId\":\"36121677\",\"name\":\"Konrad P. K\\u00f6rding\"},{\"authorId\":\"32104861\",\"name\":\"D. J. Cook\"},{\"authorId\":\"2015591\",\"name\":\"G. Blohm\"},{\"authorId\":\"2932365\",\"name\":\"N. Troje\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"title\":\"MoVi: A Large Multipurpose Motion and Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/bb1bedb1c11ce6b45b854db303ebf7fe320e856a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.11008\",\"authors\":[{\"authorId\":\"1902524\",\"name\":\"Guilhem Ch\\u00e9ron\"},{\"authorId\":\"145319877\",\"name\":\"Anton Osokin\"},{\"authorId\":\"143991676\",\"name\":\"Ivan Laptev\"},{\"authorId\":\"2462253\",\"name\":\"Cordelia Schmid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"title\":\"Modeling Spatio-Temporal Human Track Structure for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/14fee990a372bcc4cb6dc024ab7fc4ecf09dba2b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40354734\",\"name\":\"Haoze Wu\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"}],\"doi\":\"10.24963/ijcai.2019/136\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"title\":\"Mutually Reinforced Spatio-Temporal Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/21526c9cb9ba45e4748fb9a967f51c9bd9c0bf16\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":\"1812.10071\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"Kui Jia\"},{\"authorId\":\"48234805\",\"name\":\"Yuejia Shen\"},{\"authorId\":\"1702137\",\"name\":\"Silvio Savarese\"},{\"authorId\":\"1739816\",\"name\":\"Dit-Yan Yeung\"},{\"authorId\":\"2131088\",\"name\":\"Bertram Emil Shi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"073fabecf18f1421321f1961872b9842d913e4ee\",\"title\":\"Coupled Recurrent Network (CRN)\",\"url\":\"https://www.semanticscholar.org/paper/073fabecf18f1421321f1961872b9842d913e4ee\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.07052\",\"authors\":[{\"authorId\":\"31415725\",\"name\":\"Chen-Lin Zhang\"},{\"authorId\":\"49543907\",\"name\":\"Xin-Xin Liu\"},{\"authorId\":\"49388002\",\"name\":\"Jianxin Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"title\":\"Towards Real-Time Action Recognition on Mobile Devices Using Deep Models\",\"url\":\"https://www.semanticscholar.org/paper/ed2fd4d36340c61e4af9ff6fbf33c336c45458f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"title\":\"Two-Stream Oriented Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390937493\",\"name\":\"Alaaeldin Ali\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"title\":\"Spatiotemporal Representation Learning For Human Action Recognition And Localization\",\"url\":\"https://www.semanticscholar.org/paper/54bede87f33f39d0242e3e9fed20e662563b0ebb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.03259\",\"authors\":[{\"authorId\":\"144861502\",\"name\":\"Lei Shi\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74f78f64e5d72f18a1679a5c7bc4269e237e53f7\",\"title\":\"SC4D: A Sparse 4D Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74f78f64e5d72f18a1679a5c7bc4269e237e53f7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"1491414917\",\"name\":\"Xin Yan\"},{\"authorId\":\"4004957\",\"name\":\"W. Cheng\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3366710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"title\":\"Multichannel Attention Refinement for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/26997b5e761bfa0f98331e297b6e9518fef3ece1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1410131672\",\"name\":\"Yang Mi\"},{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"48459086\",\"name\":\"Zhongguo Li\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1109/TIP.2020.2989864\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"title\":\"Dual-Branch Network With a Subtle Motion Detector for Microaction Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/e099ed2b5389322c71cf693c59decbf08bb4c2d6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2006.07609\",\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1380212680\",\"name\":\"A. K. Qin\"},{\"authorId\":\"46276184\",\"name\":\"Jinyang Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ddc5b5371bc1bc1ab283818034f3dcb3756cff69\",\"title\":\"DTG-Net: Differentiated Teachers Guided Self-Supervised Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ddc5b5371bc1bc1ab283818034f3dcb3756cff69\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.10547\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2019.01067\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ce079b5a18054eb9434bf7032bcdffb599fd4f6e\",\"title\":\"Video Relationship Reasoning Using Gated Spatio-Temporal Energy Graph\",\"url\":\"https://www.semanticscholar.org/paper/ce079b5a18054eb9434bf7032bcdffb599fd4f6e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.11954\",\"authors\":[{\"authorId\":\"2117357\",\"name\":\"Chengxu Zhuang\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"40657572\",\"name\":\"D. Yamins\"}],\"doi\":\"10.1109/CVPR42600.2020.00958\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"02cd7e1a888fedd25337a4598f332c5203091e71\",\"title\":\"Unsupervised Learning From Video With Deep Neural Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/02cd7e1a888fedd25337a4598f332c5203091e71\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46930271\",\"name\":\"Junyu Gao\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/TMM.2020.2969787\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9548b20d7347ae098e03a73eef98f42d0db3775b\",\"title\":\"CI-GNN: Building a Category-Instance Graph for Zero-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/9548b20d7347ae098e03a73eef98f42d0db3775b\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"R. O. Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"E. Morales\"},{\"authorId\":\"144763689\",\"name\":\"L. Sucar\"}],\"doi\":\"10.1007/s10044-020-00924-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2b3d22fad864939a5e630fda197e8584fef793e0\",\"title\":\"Second-order motion descriptors for efficient action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b3d22fad864939a5e630fda197e8584fef793e0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.02577\",\"authors\":[{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"6643700\",\"name\":\"Youjing Zheng\"},{\"authorId\":\"2964822\",\"name\":\"Adam P. Harrison\"},{\"authorId\":\"2502329\",\"name\":\"Dakai Jin\"},{\"authorId\":\"3152399\",\"name\":\"Y. Tang\"},{\"authorId\":\"144679623\",\"name\":\"Yuxing Tang\"},{\"authorId\":\"50055456\",\"name\":\"Lingyun Huang\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"}],\"doi\":\"10.1109/TMI.2020.3047598\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"658f21d4ee0380db978d787ae1e7e36270f02768\",\"title\":\"Learning from Multiple Datasets with Heterogeneous and Partial Labels for Universal Lesion Detection in CT\",\"url\":\"https://www.semanticscholar.org/paper/658f21d4ee0380db978d787ae1e7e36270f02768\",\"venue\":\"IEEE transactions on medical imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2244863\",\"name\":\"X. Zhang\"},{\"authorId\":\"1715708\",\"name\":\"Yaping Huang\"},{\"authorId\":\"2035596033\",\"name\":\"Yang Mi\"},{\"authorId\":\"80996783\",\"name\":\"Yanting Pei\"},{\"authorId\":\"2196589\",\"name\":\"Qi Zou\"},{\"authorId\":\"40696794\",\"name\":\"Song Wang\"}],\"doi\":\"10.1007/s10489-020-01905-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"title\":\"Video sketch: A middle-level representation for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ffd6d8c2f114895c3506b8326a0fdb6b8728e901\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.11783\",\"authors\":[{\"authorId\":\"3307885\",\"name\":\"Taesup Kim\"},{\"authorId\":\"87586093\",\"name\":\"S. Kim\"},{\"authorId\":\"1865800402\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fab4598dc40ee5840196dd2c85e62f1238f11a48\",\"title\":\"Visual Concept Reasoning Networks\",\"url\":\"https://www.semanticscholar.org/paper/fab4598dc40ee5840196dd2c85e62f1238f11a48\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09791\",\"authors\":[{\"authorId\":\"46979645\",\"name\":\"J. Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1007/978-3-030-58589-1_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"title\":\"Identity-Aware Multi-Sentence Video Description\",\"url\":\"https://www.semanticscholar.org/paper/21a1b6f4f56c1fb6d844c5a1d971c59ab9cf81f7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2003.13141\",\"authors\":[{\"authorId\":\"46669153\",\"name\":\"J. Chen\"},{\"authorId\":\"48458657\",\"name\":\"Zhiheng Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00992\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5bc2905c4436f3d0c64f9efd075a27bb065539a4\",\"title\":\"Learning a Weakly-Supervised Video Actor-Action Segmentation Model With a Wise Selection\",\"url\":\"https://www.semanticscholar.org/paper/5bc2905c4436f3d0c64f9efd075a27bb065539a4\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.01455\",\"authors\":[{\"authorId\":\"27629992\",\"name\":\"B. Brattoli\"},{\"authorId\":\"40580686\",\"name\":\"Joe Tighe\"},{\"authorId\":\"2096007\",\"name\":\"Fedor Zhdanov\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"3180200\",\"name\":\"Krzysztof Chalupka\"}],\"doi\":\"10.1109/CVPR42600.2020.00467\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"title\":\"Rethinking Zero-Shot Video Classification: End-to-End Training for Realistic Applications\",\"url\":\"https://www.semanticscholar.org/paper/c58c4c6ce9ae60dce8b2f6a02c06d086d7c2e545\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2008.11516\",\"authors\":[{\"authorId\":\"46196169\",\"name\":\"S. Mahadevan\"},{\"authorId\":\"3488419\",\"name\":\"Ali Athar\"},{\"authorId\":\"3331304\",\"name\":\"Aljosa Osep\"},{\"authorId\":\"1908537619\",\"name\":\"Sebastian Hennen\"},{\"authorId\":\"1388407684\",\"name\":\"L. Leal-Taix\\u00e9\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc79bd6fb5e674199dfa52a61c819735aed568c5\",\"title\":\"Making a Case for 3D Convolutions for Object Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/bc79bd6fb5e674199dfa52a61c819735aed568c5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152142657\",\"name\":\"Y. Tian\"},{\"authorId\":\"1825799769\",\"name\":\"Guangzhao Zhai\"},{\"authorId\":\"97709070\",\"name\":\"Z. Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"5768e26731fb55edced4193596f6a470d0029ce6\",\"title\":\"Video-ception Network: Towards Multi-Scale Efficient Asymmetric Spatial-Temporal Interactions\",\"url\":\"https://www.semanticscholar.org/paper/5768e26731fb55edced4193596f6a470d0029ce6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.03186\",\"authors\":[{\"authorId\":\"7885575\",\"name\":\"E. Amrani\"},{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"},{\"authorId\":\"144858358\",\"name\":\"Alex Bronstein\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"title\":\"Noise Estimation Using Density Estimation for Self-Supervised Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/777873ef6d23c2cdd7dfd6c4834eb56769a25bb1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1874862797\",\"name\":\"Boge Wen\"},{\"authorId\":\"122665402\",\"name\":\"Siyuan Chen\"},{\"authorId\":\"3090858\",\"name\":\"Chenhui Shao\"}],\"doi\":\"10.1016/j.compind.2020.103255\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"title\":\"Temporal action proposal for online driver action monitoring using Dilated Convolutional Temporal Prediction Network\",\"url\":\"https://www.semanticscholar.org/paper/adf8ed4ba1c5bfb47364607b58cb186f09431257\",\"venue\":\"Comput. Ind.\",\"year\":2020},{\"arxivId\":\"1908.03180\",\"authors\":[{\"authorId\":\"1399431057\",\"name\":\"Paola Cascante-Bonilla\"},{\"authorId\":\"1416539256\",\"name\":\"Kalpathy Sitaraman\"},{\"authorId\":\"31143971\",\"name\":\"Mengjia Luo\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"title\":\"Moviescope: Large-scale Analysis of Movies using Multiple Modalities\",\"url\":\"https://www.semanticscholar.org/paper/e8dc97a4d489bab50abdef6f8c616694f9c68d9f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"},{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"51519347\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"}],\"doi\":\"10.1109/ICMLA.2018.00077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a294e26e92187a447a74bafc2d6123847c4acd7b\",\"title\":\"Multi-stream Convolutional Neural Networks for Action Recognition in Video Sequences Based on Adaptive Visual Rhythms\",\"url\":\"https://www.semanticscholar.org/paper/a294e26e92187a447a74bafc2d6123847c4acd7b\",\"venue\":\"2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49989940\",\"name\":\"A. Jamal\"},{\"authorId\":\"145460361\",\"name\":\"Vinay P. Namboodiri\"},{\"authorId\":\"2064509\",\"name\":\"Dipti Deodhare\"},{\"authorId\":\"145952735\",\"name\":\"K. Venkatesh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ecc793f0b4f8b7a41ed25f7f3bb34d157329cf1\",\"title\":\"Deep Domain Adaptation in Action Space\",\"url\":\"https://www.semanticscholar.org/paper/3ecc793f0b4f8b7a41ed25f7f3bb34d157329cf1\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2002.07358\",\"authors\":[{\"authorId\":\"2283619\",\"name\":\"Peisen Zhao\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2899544\",\"name\":\"C. Ju\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"title\":\"Constraining Temporal Relationship for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/a5021e7621b1aa90642208d65ea5c20ad83bbcba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"33532407\",\"name\":\"S. Cha\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"},{\"authorId\":\"40656963\",\"name\":\"Soonmin Bae\"},{\"authorId\":\"1769295\",\"name\":\"Junmo Kim\"}],\"doi\":\"10.1109/cvpr42600.2020.01212\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"96c0ba91d650c571d20961f1fae0560f8962afa5\",\"title\":\"Regularization on Spatio-Temporally Smoothed Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96c0ba91d650c571d20961f1fae0560f8962afa5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1596808016\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/tpami.2020.3015894\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7401d3895e1cb78c34fa25db12409fdff56b1661\",\"title\":\"Symbiotic Attention for Egocentric Action Recognition with Object-centric Alignment.\",\"url\":\"https://www.semanticscholar.org/paper/7401d3895e1cb78c34fa25db12409fdff56b1661\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143985656\",\"name\":\"Manuel Martin\"},{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"67310661\",\"name\":\"Monica Haurilet\"},{\"authorId\":\"37255582\",\"name\":\"M. Horne\"},{\"authorId\":\"1845905584\",\"name\":\"Simon Rei\\u00df\"},{\"authorId\":\"145265390\",\"name\":\"M. Voit\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00289\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5f6dd9cdbf3419c6bd2ad670f0ff2a3419e384d6\",\"title\":\"Drive&Act: A Multi-Modal Dataset for Fine-Grained Driver Behavior Recognition in Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/5f6dd9cdbf3419c6bd2ad670f0ff2a3419e384d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46461170\",\"name\":\"Yan Yang\"},{\"authorId\":\"27423107\",\"name\":\"Shanzhen Lan\"},{\"authorId\":\"50201744\",\"name\":\"Shengjun Zhang\"},{\"authorId\":\"9963055\",\"name\":\"Qi Bu\"},{\"authorId\":\"47558252\",\"name\":\"Y. Chen\"}],\"doi\":\"10.1109/ICCST50977.2020.00068\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3fab8bb744aa2e1d0c0507ef1449395e3b43d73b\",\"title\":\"Precise Temporal Action Detection for Fine-grained Actions\",\"url\":\"https://www.semanticscholar.org/paper/3fab8bb744aa2e1d0c0507ef1449395e3b43d73b\",\"venue\":\"2020 International Conference on Culture-oriented Science & Technology (ICCST)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188471\",\"name\":\"J. Kim\"},{\"authorId\":\"1706549\",\"name\":\"C. Won\"}],\"doi\":\"10.1109/ACCESS.2020.2983427\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"title\":\"Action Recognition in Videos Using Pre-Trained 2D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/d091af317fa1e58c6e8222d0048fd5de8cfa3065\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26400211\",\"name\":\"Shruti Palaskar\"},{\"authorId\":\"40489004\",\"name\":\"R. Sanabria\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"}],\"doi\":\"10.1016/j.csl.2020.101093\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"title\":\"Transfer learning for multimodal dialog\",\"url\":\"https://www.semanticscholar.org/paper/9094fc5d46fe4b81c9b5157b5768ed8e0c955d0d\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":\"2011.02265\",\"authors\":[{\"authorId\":\"90724813\",\"name\":\"Y. Cheng\"},{\"authorId\":\"3566342\",\"name\":\"Yuchao Yang\"},{\"authorId\":\"50688512\",\"name\":\"Haibao Chen\"},{\"authorId\":\"1873081\",\"name\":\"N. Wong\"},{\"authorId\":\"37629830\",\"name\":\"H. Yu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"085e32367a143a829fd6c6adc8e28a552afcc191\",\"title\":\"S3-Net: A Fast and Lightweight Video Scene Understanding Network by Single-shot Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/085e32367a143a829fd6c6adc8e28a552afcc191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93250272\",\"name\":\"C. Cheng\"},{\"authorId\":\"47474586\",\"name\":\"Pin Lv\"},{\"authorId\":\"144985898\",\"name\":\"B. Su\"}],\"doi\":\"10.1109/ICIP.2018.8451625\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8de174e1e050e0037d1d51fa35d43b2bfcd7dc2e\",\"title\":\"Spatiotemporal Pyramid Pooling in 3D Convolutional Neural Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8de174e1e050e0037d1d51fa35d43b2bfcd7dc2e\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2045915\",\"name\":\"Michalis Vrigkas\"},{\"authorId\":\"40867966\",\"name\":\"Ermioni Mastora\"},{\"authorId\":\"1727495\",\"name\":\"Christophoros Nikou\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1007/978-3-030-03801-4_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5054a8082a0adea6008b16bdc1489b99f1853275\",\"title\":\"Robust Incremental Hidden Conditional Random Fields for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5054a8082a0adea6008b16bdc1489b99f1853275\",\"venue\":\"ISVC\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404304087\",\"name\":\"Salah Al-Obaidi\"},{\"authorId\":\"2034275779\",\"name\":\"Hiba Al-Khafaji\"},{\"authorId\":\"74338570\",\"name\":\"Charith Abhayaratne\"}],\"doi\":\"10.1109/ACCESS.2020.3039740\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"title\":\"Modeling Temporal Visual Salience for Human Action Recognition Enabled Visual Anonymity Preservation\",\"url\":\"https://www.semanticscholar.org/paper/9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121067506\",\"name\":\"Karina Mariela Figueroa Mora\"},{\"authorId\":\"47506907\",\"name\":\"J. Mar\\u00edn\"},{\"authorId\":\"143669366\",\"name\":\"J. Cerd\\u00e1\"},{\"authorId\":\"1398026763\",\"name\":\"J. A. Carrasco-Ochoa\"},{\"authorId\":\"1404558266\",\"name\":\"J. F. Mart\\u00ednez-Trinidad\"},{\"authorId\":\"1400326434\",\"name\":\"J. A. Olvera-L\\u00f3pez\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"},{\"authorId\":\"1752005681\",\"name\":\"Karina Mariela Figueroa\"}],\"doi\":\"10.1007/978-3-030-49076-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b38358f5be96b465fa18a8eee4b671532f9eeea4\",\"title\":\"Pattern Recognition: 12th Mexican Conference, MCPR 2020, Morelia, Mexico, June 24\\u201327, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/b38358f5be96b465fa18a8eee4b671532f9eeea4\",\"venue\":\"MCPR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27280d900be88e6b613bc1da4be386bb8b2b1490\",\"title\":\"UvA-DARE ( Digital Academic Repository ) Actor and Action Video Segmentation From a\",\"url\":\"https://www.semanticscholar.org/paper/27280d900be88e6b613bc1da4be386bb8b2b1490\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"2007.05840\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1980683\",\"name\":\"S. Aeron\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4a2ef52618bc02c12e9edf59088d9fafee829185\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/4a2ef52618bc02c12e9edf59088d9fafee829185\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7877122\",\"name\":\"Youngjae Yu\"},{\"authorId\":\"2175130\",\"name\":\"Jongseok Kim\"},{\"authorId\":\"66663648\",\"name\":\"Heeseung Yun\"},{\"authorId\":\"2004821977\",\"name\":\"Jiwan Chung\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1007/978-3-030-58558-7_32\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3afcf32596398c04bd734ee6469506522e224e52\",\"title\":\"Character Grounding and Re-identification in Story of Videos and Text Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/3afcf32596398c04bd734ee6469506522e224e52\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1908.11240\",\"authors\":[{\"authorId\":\"2595119\",\"name\":\"X. Yang\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":\"10.1109/ICCVW.2019.00034\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6974b7fa30fa5d616e9941904806bdd0a68a9c27\",\"title\":\"Great Ape Detection in Challenging Jungle Camera Trap Footage via Attention-Based Spatial and Temporal Feature Blending\",\"url\":\"https://www.semanticscholar.org/paper/6974b7fa30fa5d616e9941904806bdd0a68a9c27\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52224898\",\"name\":\"Patrick Weyers\"},{\"authorId\":\"1778586\",\"name\":\"David Schiebener\"},{\"authorId\":\"31335306\",\"name\":\"A. Kummert\"}],\"doi\":\"10.1109/ITSC.2019.8917139\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aabe0e2ee00a25754f1549eeea0cfc2e2339f8a4\",\"title\":\"Action and Object Interaction Recognition for Driver Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/aabe0e2ee00a25754f1549eeea0cfc2e2339f8a4\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651582\",\"name\":\"C. Li\"},{\"authorId\":\"2891860\",\"name\":\"Yue Ming\"},{\"authorId\":\"1916963\",\"name\":\"Y. Shen\"},{\"authorId\":\"89080361\",\"name\":\"Hui Yu\"}],\"doi\":\"10.1109/ICMEW.2019.00034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"title\":\"Deep Key Clips-Video Feature Fusion Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c96638d66c1d3423aea1c2f21436e22bc8cd3d7f\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134668928\",\"name\":\"Raimon H. R. Pruim\"},{\"authorId\":\"133678273\",\"name\":\"Annegreet van Opbroek\"},{\"authorId\":\"3138549\",\"name\":\"M. Kruithof\"},{\"authorId\":\"134632765\",\"name\":\"R. D. den Hollander\"},{\"authorId\":\"145445122\",\"name\":\"J. Baan\"},{\"authorId\":\"134767384\",\"name\":\"Sebastiaan P. van den Broek\"},{\"authorId\":\"134536174\",\"name\":\"Nanda van der Stap\"},{\"authorId\":\"144229488\",\"name\":\"J. Dijk\"}],\"doi\":\"10.1117/12.2532323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e093abab071b058d6822afde819709a8677bcb9f\",\"title\":\"Spatiotemporal detection of maritime targets using neural networks\",\"url\":\"https://www.semanticscholar.org/paper/e093abab071b058d6822afde819709a8677bcb9f\",\"venue\":\"Security + Defence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1733113\",\"name\":\"T. Kanade\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"title\":\"Cooperative Learning of Audio and Video Models from Self-Supervised Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/8dac02f61e12560607f857cee3c1d5abaf40ecd0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.07482\",\"authors\":[{\"authorId\":\"10791325\",\"name\":\"Ozan Caglayan\"},{\"authorId\":\"151480727\",\"name\":\"Zixiu Wu\"},{\"authorId\":\"144695472\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"37f371fe04f3dc38df7f27f43277ba15d3637890\",\"title\":\"Imperial College London Submission to VATEX Video Captioning Task\",\"url\":\"https://www.semanticscholar.org/paper/37f371fe04f3dc38df7f27f43277ba15d3637890\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145131937\",\"name\":\"L. Wang\"},{\"authorId\":\"143709258\",\"name\":\"Yangyang Xu\"},{\"authorId\":\"144703461\",\"name\":\"J. Cheng\"},{\"authorId\":\"39827902\",\"name\":\"H. Xia\"},{\"authorId\":\"1890165\",\"name\":\"J. Yin\"},{\"authorId\":\"26883623\",\"name\":\"Jiaji Wu\"}],\"doi\":\"10.1109/ACCESS.2018.2817253\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"263ed62f94ea615c747c00ebbb4008385285b33b\",\"title\":\"Human Action Recognition by Learning Spatio-Temporal Features With Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/263ed62f94ea615c747c00ebbb4008385285b33b\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2010.15464\",\"authors\":[{\"authorId\":\"1720851638\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"title\":\"Self-Supervised Video Representation Using Pretext-Contrastive Learning\",\"url\":\"https://www.semanticscholar.org/paper/5ada370b12a174a45b27c2e40d01cd47155bb9d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50322696\",\"name\":\"Haoliang Tan\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8715474732e8d024078d482b8d0f7cae88a31bcc\",\"title\":\"Object Affordances Graph Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8715474732e8d024078d482b8d0f7cae88a31bcc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1911.08206\",\"authors\":[{\"authorId\":\"1382652819\",\"name\":\"Barak Battash\"},{\"authorId\":\"1420126809\",\"name\":\"Haim Barad\"},{\"authorId\":\"39278465\",\"name\":\"Hanlin Tang\"},{\"authorId\":\"3243137\",\"name\":\"Amit Bleiweiss\"}],\"doi\":\"10.1109/CVPRW50498.2020.00350\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"da2934c24a9de690ff399736711b754cc10ae1ec\",\"title\":\"Mimic The Raw Domain: Accelerating Action Recognition in the Compressed Domain\",\"url\":\"https://www.semanticscholar.org/paper/da2934c24a9de690ff399736711b754cc10ae1ec\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2007.02036\",\"authors\":[{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"103278467\",\"name\":\"Minuk Ma\"},{\"authorId\":\"48920375\",\"name\":\"T. Pham\"},{\"authorId\":\"97531942\",\"name\":\"Kyungsu Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/cvpr42600.2020.01012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"title\":\"Modality Shifting Attention Network for Multi-Modal Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/7fa5fdaacc87165a0281babd96949e8ec74d3a41\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2691929\",\"name\":\"Anoop Cherian\"},{\"authorId\":\"1980683\",\"name\":\"Shuchin Aeron\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"b8c001c449cec20221ba3daa76536a124cddc0e5\",\"title\":\"Representation Learning via Adversarially-Contrastive Optimal Transport /Author=Cherian, Anoop; Aeron, Shuchin /CreationDate=July 3, 2020 /Subject=Artificial Intelligence, Computer Vision, Machine Learning\",\"url\":\"https://www.semanticscholar.org/paper/b8c001c449cec20221ba3daa76536a124cddc0e5\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3378742\",\"name\":\"Zelun Luo\"},{\"authorId\":\"39978626\",\"name\":\"Lu Jiang\"},{\"authorId\":\"7164257\",\"name\":\"Jun-Ting Hsieh\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b1682da96af72ce0ddaa9384ce294611807a8b3\",\"title\":\"Graph Distillation for Action Detection with Privileged Information\",\"url\":\"https://www.semanticscholar.org/paper/4b1682da96af72ce0ddaa9384ce294611807a8b3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"506ea19145838a035e7dba535519fb40a3a0018c\",\"title\":\"Learning Shared Multimodal Embeddings with Unpaired Data\",\"url\":\"https://www.semanticscholar.org/paper/506ea19145838a035e7dba535519fb40a3a0018c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1803.08834\",\"authors\":[{\"authorId\":\"3314448\",\"name\":\"Isma Hadji\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"title\":\"What Do We Understand About Convolutional Networks?\",\"url\":\"https://www.semanticscholar.org/paper/5d78fcc8ea2771c8408cf6f66f31f3090b6b5637\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1910.09920\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85accdf27ef03155d41f9740fed6044afb5dd5f6\",\"title\":\"Weakly-Supervised Completion Moment Detection using Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/85accdf27ef03155d41f9740fed6044afb5dd5f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35838466\",\"name\":\"Dimitri Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0beb9e1a6ff844b929e4fdecf9e01d1ef1bb9a81\",\"title\":\"Meringue Pour egg Add sugar Whisk mixture ... Making Pancakes Pour mixture Making Lemonade Pour\",\"url\":\"https://www.semanticscholar.org/paper/0beb9e1a6ff844b929e4fdecf9e01d1ef1bb9a81\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51023221\",\"name\":\"Daochang Liu\"},{\"authorId\":\"145427096\",\"name\":\"T. Jiang\"},{\"authorId\":\"26960212\",\"name\":\"Yizhou Wang\"}],\"doi\":\"10.1109/CVPR.2019.00139\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e1976a516fda5e0e164c5ae7d7ad89dd09387116\",\"title\":\"Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/e1976a516fda5e0e164c5ae7d7ad89dd09387116\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"1889486\",\"name\":\"Yaser Souri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICIP.2019.8803650\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b28c19bc1dd8d6db7fa65c1aa5aa6714463c0e5\",\"title\":\"Hierarchical Graph-Rnns for Action Detection of Multiple Activities\",\"url\":\"https://www.semanticscholar.org/paper/0b28c19bc1dd8d6db7fa65c1aa5aa6714463c0e5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1904.07911\",\"authors\":[{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2019.00980\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e91dca6e99f2d392953524986f2125be2008d9fc\",\"title\":\"REPAIR: Removing Representation Bias by Dataset Resampling\",\"url\":\"https://www.semanticscholar.org/paper/e91dca6e99f2d392953524986f2125be2008d9fc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.00440\",\"authors\":[{\"authorId\":\"47604355\",\"name\":\"G. Brazil\"},{\"authorId\":\"48032852\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00740\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c90d413c1b7b95c1926569eeab016b31b7a90350\",\"title\":\"Pedestrian Detection With Autoregressive Network Phases\",\"url\":\"https://www.semanticscholar.org/paper/c90d413c1b7b95c1926569eeab016b31b7a90350\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"38014112\",\"name\":\"A. Kumar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c229249b2d8c5d2cbf5fb463aa193a0a458cbe48\",\"title\":\"Query by Video: Cross-modal Music Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/c229249b2d8c5d2cbf5fb463aa193a0a458cbe48\",\"venue\":\"ISMIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1566489065\",\"name\":\"Yukun Huang\"},{\"authorId\":\"2425471\",\"name\":\"Yongcai Guo\"},{\"authorId\":\"153686290\",\"name\":\"C. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.2978223\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"title\":\"Efficient Parallel Inflated 3D Convolution Architecture for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd59c68dc58e350b51288d2b6ee6d5ea52ad9f84\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1453599537\",\"name\":\"Syed Abdussami\"},{\"authorId\":\"2590710\",\"name\":\"S. Nagendraprasad\"},{\"authorId\":\"1453596812\",\"name\":\"K. Shivarajakumara\"},{\"authorId\":\"4127641\",\"name\":\"S. Singh\"},{\"authorId\":\"73755136\",\"name\":\"A. Thyagarajamurthy\"}],\"doi\":\"10.5120/ijca2019919605\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f45bb42007c6c5f849af477a86e172a845708b2\",\"title\":\"A Review on Action Recognition and Action Prediction of Human(s) using Deep Learning Approaches\",\"url\":\"https://www.semanticscholar.org/paper/8f45bb42007c6c5f849af477a86e172a845708b2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000153057\",\"name\":\"Zhikang Qiu\"},{\"authorId\":null,\"name\":\"Xu Zhao\"},{\"authorId\":\"49941675\",\"name\":\"Zhilan Hu\"}],\"doi\":\"10.1109/ICIP40778.2020.9190997\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"title\":\"Efficient Temporal-Spatial Feature Grouping For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/593fa71e5cad2afcc4b105c45d5ee4eae101bf54\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"2009.13087\",\"authors\":[{\"authorId\":\"3173493\",\"name\":\"Y. Li\"},{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"title\":\"PERF-Net: Pose Empowered RGB-Flow Net\",\"url\":\"https://www.semanticscholar.org/paper/c8bf6f41d6df5c6cdc6249aecfa1aab027f0c8e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.06308\",\"authors\":[{\"authorId\":\"47824876\",\"name\":\"W. Wang\"},{\"authorId\":\"2088511\",\"name\":\"Zeyuan Wang\"},{\"authorId\":\"48380350\",\"name\":\"Yinghui Zhang\"},{\"authorId\":\"145741492\",\"name\":\"Bo Sun\"},{\"authorId\":\"49477460\",\"name\":\"K. Xia\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3eb859e105c240de52a1803441360457988fe33\",\"title\":\"Learning Order Parameters from Videos of Dynamical Phases for Skyrmions with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b3eb859e105c240de52a1803441360457988fe33\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.00392\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.01065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"title\":\"Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/0b78e14dfc2050878e8c817e4782c0c81ee7f5dd\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.13870\",\"authors\":[{\"authorId\":\"2050979\",\"name\":\"Zhichao Lu\"},{\"authorId\":\"40303375\",\"name\":\"V. Rathod\"},{\"authorId\":\"69423660\",\"name\":\"Ronny Votel\"},{\"authorId\":\"4240351\",\"name\":\"Jonathan Huang\"}],\"doi\":\"10.1109/cvpr42600.2020.01468\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7b7742b617320c9abf077f853de971259ae0182\",\"title\":\"RetinaTrack: Online Single Stage Joint Detection and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/d7b7742b617320c9abf077f853de971259ae0182\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.05261\",\"authors\":[{\"authorId\":\"1420042733\",\"name\":\"Sanjay Haresh\"},{\"authorId\":\"152663515\",\"name\":\"S. Kumar\"},{\"authorId\":\"143663576\",\"name\":\"M. Zia\"},{\"authorId\":\"3090093\",\"name\":\"Quoc-Huy Tran\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"619ffa719626ca929827101ef514bcb836f806d7\",\"title\":\"Towards Anomaly Detection in Dashcam Videos\",\"url\":\"https://www.semanticscholar.org/paper/619ffa719626ca929827101ef514bcb836f806d7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2830865\",\"name\":\"Burcu A. Urgen\"},{\"authorId\":\"39173237\",\"name\":\"S. Pehlivan\"},{\"authorId\":\"2277803\",\"name\":\"A. Saygin\"}],\"doi\":\"10.1016/j.neuropsychologia.2019.02.006\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a0f614f406840e798f893907c24f80ff88bd9a9e\",\"title\":\"Distinct representations in occipito-temporal, parietal, and premotor cortex during action perception revealed by fMRI and computational modeling\",\"url\":\"https://www.semanticscholar.org/paper/a0f614f406840e798f893907c24f80ff88bd9a9e\",\"venue\":\"Neuropsychologia\",\"year\":2019},{\"arxivId\":\"1812.01923\",\"authors\":[{\"authorId\":\"49890236\",\"name\":\"Y. Zhang\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1007/978-3-030-11024-6_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba577c7cd74b6999dadc3c9b2e7863628cf72426\",\"title\":\"An Empirical Study towards Understanding How Deep Convolutional Nets Recognize Falls\",\"url\":\"https://www.semanticscholar.org/paper/ba577c7cd74b6999dadc3c9b2e7863628cf72426\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123183952\",\"name\":\"Bennet Breier\"},{\"authorId\":\"1950866\",\"name\":\"A. Onken\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"1a6bc111cf6bf30d37a9610427f2a0a98fcf8492\",\"title\":\"SWIM BOUT CLASSIFICATION\",\"url\":\"https://www.semanticscholar.org/paper/1a6bc111cf6bf30d37a9610427f2a0a98fcf8492\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81781019\",\"name\":\"Minho Shim\"},{\"authorId\":\"28033903\",\"name\":\"Hsuan-I Ho\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"},{\"authorId\":\"1405197098\",\"name\":\"Dongyoon Wee\"}],\"doi\":\"10.1007/978-3-030-58568-6_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9f8c337087bfb7498ec3d6990b9df44ce7ff876d\",\"title\":\"READ: Reciprocal Attention Discriminator for Image-to-Video Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/9f8c337087bfb7498ec3d6990b9df44ce7ff876d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.08670\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"2966051\",\"name\":\"Amirreza Shaban\"},{\"authorId\":\"67294118\",\"name\":\"Michael L. Iuzzolino\"},{\"authorId\":\"145733034\",\"name\":\"K. Koishida\"}],\"doi\":\"10.1109/cvpr42600.2020.01330\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eb8304061be88b2452872e12a53b23bc9f6b4925\",\"title\":\"MMTM: Multimodal Transfer Module for CNN Fusion\",\"url\":\"https://www.semanticscholar.org/paper/eb8304061be88b2452872e12a53b23bc9f6b4925\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5546708\",\"name\":\"Ronak Gupta\"},{\"authorId\":\"72177702\",\"name\":\"Prashant Anand\"},{\"authorId\":\"5911068\",\"name\":\"V. Kaushik\"},{\"authorId\":\"144725842\",\"name\":\"S. Chaudhury\"},{\"authorId\":\"143632379\",\"name\":\"Brejesh Lall\"}],\"doi\":\"10.1007/978-3-030-34869-4_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"082855f9000482c9571cda2aadaad05306caaf00\",\"title\":\"Data Driven Sensing for Action Recognition Using Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/082855f9000482c9571cda2aadaad05306caaf00\",\"venue\":\"PReMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144957857\",\"name\":\"H. Nishimura\"},{\"authorId\":\"2764854\",\"name\":\"K. Tasaka\"},{\"authorId\":\"1770200\",\"name\":\"Y. Kawanishi\"},{\"authorId\":\"82910116\",\"name\":\"H. Murase\"}],\"doi\":\"10.3169/mta.8.269\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a1ba4af7caa08a2dd5a69dd99499d544dd2178d\",\"title\":\"[Paper] Multiple Human Tracking with Alternately Updating Trajectories and Multi-Frame Action Features\",\"url\":\"https://www.semanticscholar.org/paper/3a1ba4af7caa08a2dd5a69dd99499d544dd2178d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.02401\",\"authors\":[{\"authorId\":\"8080821\",\"name\":\"Megha Nawhal\"},{\"authorId\":\"1936990\",\"name\":\"Mengyao Zhai\"},{\"authorId\":\"20812150\",\"name\":\"Andreas M. Lehrmann\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1007/978-3-030-58610-2_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"title\":\"Generating Videos of Zero-Shot Compositions of Actions and Objects\",\"url\":\"https://www.semanticscholar.org/paper/4ebb4985c6da258fe47a63d1f9dc1ae491e6db62\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.09676\",\"authors\":[{\"authorId\":\"50465425\",\"name\":\"P. Sharma\"},{\"authorId\":\"38236002\",\"name\":\"Deepak Pathak\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbd93f7a687cdece41b2d92399525f03cc00cede\",\"title\":\"Third-Person Visual Imitation Learning via Decoupled Hierarchical Controller\",\"url\":\"https://www.semanticscholar.org/paper/bbd93f7a687cdece41b2d92399525f03cc00cede\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1902.00505\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1609/AAAI.V34I07.6861\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5e5b4aa57f9cd48438eac3407a49232fb1e52d89\",\"title\":\"Differentiable Grammars for Videos\",\"url\":\"https://www.semanticscholar.org/paper/5e5b4aa57f9cd48438eac3407a49232fb1e52d89\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1907.10292\",\"authors\":[{\"authorId\":\"39032755\",\"name\":\"Yunus Can Bilge\"},{\"authorId\":\"1398643531\",\"name\":\"N. Ikizler-Cinbis\"},{\"authorId\":\"1939006\",\"name\":\"Ramazan Gokberk Cinbis\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"04323b8f60e261af54aec4b5cd345cbdd475267d\",\"title\":\"Zero-Shot Sign Language Recognition: Can Textual Data Uncover Sign Languages?\",\"url\":\"https://www.semanticscholar.org/paper/04323b8f60e261af54aec4b5cd345cbdd475267d\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1906.04236\",\"authors\":[{\"authorId\":\"41079205\",\"name\":\"Oana Ignat\"},{\"authorId\":\"8003011\",\"name\":\"Laura Burdick\"},{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"145557251\",\"name\":\"R. Mihalcea\"}],\"doi\":\"10.18653/v1/P19-1643\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0fe96f493334987589f8ccd55f2d1209df258449\",\"title\":\"Identifying Visible Actions in Lifestyle Vlogs\",\"url\":\"https://www.semanticscholar.org/paper/0fe96f493334987589f8ccd55f2d1209df258449\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1807.02929\",\"authors\":[{\"authorId\":\"28891563\",\"name\":\"Jia-Xing Zhong\"},{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"33559754\",\"name\":\"Weijie Kong\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"},{\"authorId\":\"47949235\",\"name\":\"G. Li\"}],\"doi\":\"10.1145/3240508.3240511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"title\":\"Step-by-step Erasion, One-by-one Collection: A Weakly Supervised Temporal Action Detector\",\"url\":\"https://www.semanticscholar.org/paper/d66b80614f873bab0adbb7b1902fcff39fe63fdd\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"13741850\",\"name\":\"Yijing Lv\"},{\"authorId\":\"39458374\",\"name\":\"H. Zheng\"},{\"authorId\":null,\"name\":\"Wei Zhang\"}],\"doi\":\"10.1007/978-3-030-03335-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"title\":\"Multi-level Three-Stream Convolutional Networks for Video-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b33742f8b5852c8d89bb9a0236bb88412c8a807f\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005271\",\"name\":\"Z. Li\"},{\"authorId\":\"1390685056\",\"name\":\"Yue Wu\"},{\"authorId\":\"1404588675\",\"name\":\"W. Abd-Almageed\"},{\"authorId\":\"145603129\",\"name\":\"P. Natarajan\"}],\"doi\":\"10.1007/978-3-030-20873-8_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4cb5780b87c44bde549420a93b2ae990d0d423b9\",\"title\":\"Weighted Feature Pooling Network in Template-Based Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cb5780b87c44bde549420a93b2ae990d0d423b9\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1804.06248\",\"authors\":[{\"authorId\":\"48169955\",\"name\":\"L. Wang\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"2858139\",\"name\":\"L. Yang\"},{\"authorId\":\"47827548\",\"name\":\"Y. Zhao\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"1803714\",\"name\":\"D. Meng\"}],\"doi\":\"10.1007/978-3-030-01231-1_24\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f1afe81db19cc4a60d597f5480c9d8e9346f21e\",\"title\":\"PM-GANs: Discriminative Representation Learning for Action Recognition Using Partial-modalities\",\"url\":\"https://www.semanticscholar.org/paper/8f1afe81db19cc4a60d597f5480c9d8e9346f21e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1395615456\",\"name\":\"Elena Nicora\"},{\"authorId\":\"2442124\",\"name\":\"Gaurvi Goyal\"},{\"authorId\":\"2600472\",\"name\":\"Nicoletta Noceti\"},{\"authorId\":\"2511943\",\"name\":\"A. Vignolo\"},{\"authorId\":\"1961676436\",\"name\":\"Alessandra Sciutti\"},{\"authorId\":\"1712692\",\"name\":\"F. Odone\"}],\"doi\":\"10.1038/s41597-020-00776-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"title\":\"The MoCA dataset, kinematic and multi-view visual streams of fine-grained cooking actions\",\"url\":\"https://www.semanticscholar.org/paper/bb9f7b110e4b8e9ab4c9ceb8967f505d80837cca\",\"venue\":\"Scientific data\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1663616783\",\"name\":\"Diego R. B. da Silva\"},{\"authorId\":\"70515398\",\"name\":\"T. M. U. Ara\\u00fajo\"},{\"authorId\":\"3266833\",\"name\":\"Thais G. do Rego\"},{\"authorId\":\"152374714\",\"name\":\"M. A. C. B. Lima\"}],\"doi\":\"10.1145/3428658.3430980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01b128e15226aa3407ee256dcb0c817b0e94482d\",\"title\":\"A Two-Stream Model Based on 3D Convolutional Neural Networks for the Recognition of Brazilian Sign Language in the Health Context\",\"url\":\"https://www.semanticscholar.org/paper/01b128e15226aa3407ee256dcb0c817b0e94482d\",\"venue\":\"WebMedia\",\"year\":2020},{\"arxivId\":\"2011.10190\",\"authors\":[{\"authorId\":\"102811267\",\"name\":\"Reza Ghoddoosian\"},{\"authorId\":\"34282786\",\"name\":\"Saif Sayed\"},{\"authorId\":\"1720747\",\"name\":\"V. Athitsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041f428cf81939985843402b72521289ea48b2e6\",\"title\":\"Action Duration Prediction for Segment-Level Alignment of Weakly-Labeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/041f428cf81939985843402b72521289ea48b2e6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47077615\",\"name\":\"J. Munro\"},{\"authorId\":\"1677780022\",\"name\":\"Dima Damen\"}],\"doi\":\"10.1109/cvpr42600.2020.00020\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"646a256e30cd244b668660c32b529ff31a874a78\",\"title\":\"Multi-Modal Domain Adaptation for Fine-Grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/646a256e30cd244b668660c32b529ff31a874a78\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042569583\",\"name\":\"Kensho Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"2042706087\",\"name\":\"Masaki Inaba\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"2042698122\",\"name\":\"Ryusuke Hotta\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ITSC45102.2020.9294443\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"title\":\"Predicting Vehicles Appearing from Blind Spots Based on Pedestrian Behaviors\",\"url\":\"https://www.semanticscholar.org/paper/2744f2138795d0a2da3aa9b8b413fbfdb7b82bcb\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47883221\",\"name\":\"Jingwei Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"}],\"doi\":\"10.1007/s11263-020-01389-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6e81249d8f00e54a627785a47e62c694cce119e3\",\"title\":\"Progressive Multi-granularity Analysis for Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/6e81249d8f00e54a627785a47e62c694cce119e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.06107\",\"authors\":[{\"authorId\":\"46448559\",\"name\":\"Xiaoman Zhang\"},{\"authorId\":\"49890039\",\"name\":\"Y. Zhang\"},{\"authorId\":\"49469756\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Yanfeng Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ba173ef79de6174493543559e606d8a855ac5bd\",\"title\":\"Universal Model for 3D Medical Image Analysis\",\"url\":\"https://www.semanticscholar.org/paper/5ba173ef79de6174493543559e606d8a855ac5bd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"153747406\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"48934241\",\"name\":\"Qianqian Li\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"49721778\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1145/3394171.3413646\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"title\":\"Multi-Group Multi-Attention: Towards Discriminative Spatiotemporal Representation\",\"url\":\"https://www.semanticscholar.org/paper/c0d5f622f775d02e90b715b80485dbcab250e7bd\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2003.00197\",\"authors\":[{\"authorId\":\"29724362\",\"name\":\"Longlong Jing\"},{\"authorId\":\"1807477\",\"name\":\"T. Parag\"},{\"authorId\":\"152247556\",\"name\":\"Zhe Wu\"},{\"authorId\":\"8193125\",\"name\":\"Y. Tian\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"title\":\"VideoSSL: Semi-Supervised Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/637b413488ef5b72a3f04089ea3e3c635caab9ee\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.01646\",\"authors\":[{\"authorId\":\"2628886\",\"name\":\"Tao Zhuo\"},{\"authorId\":\"1491424051\",\"name\":\"Mohan Kankanhalli\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ea6919c7e1633693b9ee4a53ca79db8b3d990e6\",\"title\":\"Solving Raven's Progressive Matrices with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/3ea6919c7e1633693b9ee4a53ca79db8b3d990e6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144930542\",\"name\":\"D. Gil\"},{\"authorId\":\"145931119\",\"name\":\"W. Green\"}],\"doi\":\"10.1109/ISSCC19947.2020.9062918\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee5690a3c5a0b76a92c55e2f87e1f3ecf7a15dd2\",\"title\":\"1.4 The Future of Computing: Bits + Neurons + Qubits\",\"url\":\"https://www.semanticscholar.org/paper/ee5690a3c5a0b76a92c55e2f87e1f3ecf7a15dd2\",\"venue\":\"2020 IEEE International Solid- State Circuits Conference - (ISSCC)\",\"year\":2020},{\"arxivId\":\"2007.10558\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"40580714\",\"name\":\"Dingzeyu Li\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-58580-8_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3867340091c920dc5f8ba462197fa5bc924a98c4\",\"title\":\"Unified Multisensory Perception: Weakly-Supervised Audio-Visual Video Parsing\",\"url\":\"https://www.semanticscholar.org/paper/3867340091c920dc5f8ba462197fa5bc924a98c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31586818\",\"name\":\"H. G. Chen\"},{\"authorId\":\"8133623\",\"name\":\"Wanjia Liu\"},{\"authorId\":\"46186660\",\"name\":\"R. Goel\"},{\"authorId\":\"2492444\",\"name\":\"Rhonald C. Lua\"},{\"authorId\":\"47732006\",\"name\":\"S. Mittal\"},{\"authorId\":\"35633657\",\"name\":\"Yuzhong Huang\"},{\"authorId\":\"145280967\",\"name\":\"A. Veeraraghavan\"},{\"authorId\":\"46463998\",\"name\":\"Ankit B. Patel\"}],\"doi\":\"10.1109/TCI.2019.2948755\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7377982e58702e0f44beff2c00ab2d32825cf557\",\"title\":\"Fast Retinomorphic Event-Driven Representations for Video Gameplay and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7377982e58702e0f44beff2c00ab2d32825cf557\",\"venue\":\"IEEE Transactions on Computational Imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19120180\",\"name\":\"L. Song\"},{\"authorId\":\"1810660380\",\"name\":\"X. Guo\"},{\"authorId\":\"1965900016\",\"name\":\"Yiqi Fan\"}],\"doi\":\"10.1109/ICCSE49874.2020.9201857\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7469bdeb3ecabc3eead628789467173b86b6970\",\"title\":\"Action Recognition in Video Using Human Keypoint Detection\",\"url\":\"https://www.semanticscholar.org/paper/b7469bdeb3ecabc3eead628789467173b86b6970\",\"venue\":\"2020 15th International Conference on Computer Science & Education (ICCSE)\",\"year\":2020},{\"arxivId\":\"2004.05054\",\"authors\":[{\"authorId\":\"51000619\",\"name\":\"Evgeny Izutov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"title\":\"ASL Recognition with Metric-Learning based Lightweight Network\",\"url\":\"https://www.semanticscholar.org/paper/f4436c77e4232d36d95f95989d2e5ae2fa0b0514\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92422787\",\"name\":\"X. Wang\"},{\"authorId\":\"145175070\",\"name\":\"C. Qi\"}],\"doi\":\"10.1007/s11042-019-08535-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0359bf810974ff6bbd61f543f6c33aa1dad25603\",\"title\":\"Detecting action-relevant regions for action recognition using a three-stage saliency detection technique\",\"url\":\"https://www.semanticscholar.org/paper/0359bf810974ff6bbd61f543f6c33aa1dad25603\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"2008.04888\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/978-3-030-58536-5_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"49dcefd14e92f3ffd5871abf78ee8ca5067fbb49\",\"title\":\"Adversarial Generative Grammars for Human Activity Prediction\",\"url\":\"https://www.semanticscholar.org/paper/49dcefd14e92f3ffd5871abf78ee8ca5067fbb49\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.02172\",\"authors\":[{\"authorId\":\"51224607\",\"name\":\"Yi-Chieh Liu\"},{\"authorId\":\"15809720\",\"name\":\"Yung-An Hsieh\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"46962482\",\"name\":\"C. H. Yang\"},{\"authorId\":\"1687483\",\"name\":\"J. Tegn\\u00e9r\"},{\"authorId\":\"49291215\",\"name\":\"Y. Tsai\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053783\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7151072c07431b5e65aed6bd86e6894e43b1c7be\",\"title\":\"Interpretable Self-Attention Temporal Reasoning for Driving Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/7151072c07431b5e65aed6bd86e6894e43b1c7be\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1810.12819\",\"authors\":[{\"authorId\":\"33390229\",\"name\":\"Alina Roitberg\"},{\"authorId\":\"1390024605\",\"name\":\"Ziad Al-Halah\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"563143c5f4fed0184c1f3e661917da94cfed1d46\",\"title\":\"Informed Democracy: Voting-based Novelty Detection for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/563143c5f4fed0184c1f3e661917da94cfed1d46\",\"venue\":\"BMVC\",\"year\":2018},{\"arxivId\":\"2004.14487\",\"authors\":[{\"authorId\":\"94314731\",\"name\":\"Matthew Purri\"},{\"authorId\":\"1710772\",\"name\":\"K. Dana\"}],\"doi\":\"10.1007/978-3-030-58583-9_1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"title\":\"Teaching Cameras to Feel: Estimating Tactile Physical Properties of Surfaces From Images\",\"url\":\"https://www.semanticscholar.org/paper/dd5f4a7a3f619cb64428dc1a8a128019c8d4f512\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144622635\",\"name\":\"L. Sun\"},{\"authorId\":\"49069099\",\"name\":\"Yanjun Chen\"},{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"1490938774\",\"name\":\"Haiyan Wu\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"}],\"doi\":\"10.1109/ICIP40778.2020.9191072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1311a646fb9a7928f37dddf8df1b15a05d7ff646\",\"title\":\"Discriminative Clip Mining for Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/1311a646fb9a7928f37dddf8df1b15a05d7ff646\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2034347747\",\"name\":\"Chang Liu\"},{\"authorId\":\"153690115\",\"name\":\"Yulin Yang\"},{\"authorId\":\"2034348002\",\"name\":\"Xingyan Liu\"},{\"authorId\":\"51310276\",\"name\":\"Linpu Fang\"},{\"authorId\":\"40497356\",\"name\":\"Wenxiong Kang\"}],\"doi\":\"10.1109/TIFS.2020.3036218\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4a93f6df11436e0f5df09d79c814930430104b75\",\"title\":\"Dynamic-Hand-Gesture Authentication Dataset and Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/4a93f6df11436e0f5df09d79c814930430104b75\",\"venue\":\"IEEE Transactions on Information Forensics and Security\",\"year\":2021},{\"arxivId\":\"2006.13017\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":\"10.1109/ICIP40778.2020.9191133\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"title\":\"Motion Representation Using Residual Frames with 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/3cfee833437b81b89bb272dd4f5a501b61f2c0d1\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":\"1905.12681\",\"authors\":[{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":null,\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"4b434904230cd2c09f349cc69b72baa670b5d815\",\"title\":\"What Makes Training Multi-Modal Networks Hard?\",\"url\":\"https://www.semanticscholar.org/paper/4b434904230cd2c09f349cc69b72baa670b5d815\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.05640\",\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2884918\",\"name\":\"M. Sabokrou\"},{\"authorId\":\"144979251\",\"name\":\"A. Hadid\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"title\":\"AVD: Adversarial Video Distillation\",\"url\":\"https://www.semanticscholar.org/paper/1bd2c92ff77126f7352b32d3b00f998f15bfdf07\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1403064499\",\"name\":\"M. Skublewska-Paszkowska\"},{\"authorId\":\"66534160\",\"name\":\"P. Powroznik\"},{\"authorId\":\"14708514\",\"name\":\"E. Lukasik\"}],\"doi\":\"10.3390/s20216094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7559a950c354f764992cc858b63bf4d446ab50b5\",\"title\":\"Learning Three Dimensional Tennis Shots Using Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/7559a950c354f764992cc858b63bf4d446ab50b5\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"2008.08332\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"46961961\",\"name\":\"Cong Yang\"}],\"doi\":\"10.1007/978-3-030-58517-4_30\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"title\":\"CFAD: Coarse-to-Fine Action Detector for Spatiotemporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f5140c7251be78ff4fec48efea3b1c6ba581fba9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2010.09709\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88f440120730e21b07bbd188b2a04787a3208861\",\"title\":\"Self-supervised Co-training for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/88f440120730e21b07bbd188b2a04787a3208861\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2008.13759\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"title\":\"Online Spatiotemporal Action Detection and Prediction via Causal Representations\",\"url\":\"https://www.semanticscholar.org/paper/67968b5b59b08ea1dd8a1266b422ee38e3ca8ad5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1720856277\",\"name\":\"Junting Pan\"},{\"authorId\":\"48605271\",\"name\":\"J. Guo\"},{\"authorId\":\"144478191\",\"name\":\"J. Shao\"},{\"authorId\":\"1717179\",\"name\":\"Chen Change Loy\"}],\"doi\":\"10.1007/s11263-020-01334-x\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"991649f2903d05a27243a7d26016c4df735a6fbb\",\"title\":\"High-Quality Video Generation from Static Structural Annotations\",\"url\":\"https://www.semanticscholar.org/paper/991649f2903d05a27243a7d26016c4df735a6fbb\",\"venue\":\"International Journal of Computer Vision\",\"year\":2020},{\"arxivId\":\"2008.09646\",\"authors\":[{\"authorId\":\"1581479411\",\"name\":\"Abhinav Sagar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b367a582b8921997bbbea433bf99c4671568b44c\",\"title\":\"HRVGAN: High Resolution Video Generation using Spatio-Temporal GAN\",\"url\":\"https://www.semanticscholar.org/paper/b367a582b8921997bbbea433bf99c4671568b44c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.09835\",\"authors\":[{\"authorId\":\"48643324\",\"name\":\"Wei Niu\"},{\"authorId\":\"8712588\",\"name\":\"Mengshu Sun\"},{\"authorId\":\"48459506\",\"name\":\"Z. Li\"},{\"authorId\":\"84681008\",\"name\":\"J. Chen\"},{\"authorId\":\"1823636176\",\"name\":\"Jiexiong Guan\"},{\"authorId\":\"47435542\",\"name\":\"Xipeng Shen\"},{\"authorId\":null,\"name\":\"Yanzhi Wang\"},{\"authorId\":\"1662772707\",\"name\":\"Xue Lin\"},{\"authorId\":\"153108488\",\"name\":\"Bin Ren\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2f44d0cd05ccc1db98af5fabf96e0f4ebd86d9c\",\"title\":\"Achieving Real-Time Execution of 3D Convolutional Neural Networks on Mobile Devices\",\"url\":\"https://www.semanticscholar.org/paper/b2f44d0cd05ccc1db98af5fabf96e0f4ebd86d9c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.15657\",\"authors\":[{\"authorId\":\"32486555\",\"name\":\"D. Epstein\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0\",\"title\":\"Video Representations of Goals Emerge from Watching Failure\",\"url\":\"https://www.semanticscholar.org/paper/9a6dd28c5449ddcad7b079c0dca6ea6a518c3eb0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2227667\",\"name\":\"Naifan Zhuang\"},{\"authorId\":\"49502400\",\"name\":\"G. Qi\"},{\"authorId\":\"29765068\",\"name\":\"T. Kieu\"},{\"authorId\":\"1730455\",\"name\":\"K. Hua\"}],\"doi\":\"10.1145/3337928\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"43e5251d30ae8090511d26df83be26ba90d03092\",\"title\":\"Rethinking the Combined and Individual Orders of Derivative of States for Differential Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43e5251d30ae8090511d26df83be26ba90d03092\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2678268\",\"name\":\"P. Wu\"},{\"authorId\":null,\"name\":\"Jing Liu\"},{\"authorId\":\"49141009\",\"name\":\"M. Li\"},{\"authorId\":\"5264927\",\"name\":\"Yujia Sun\"},{\"authorId\":\"1382210269\",\"name\":\"Fang Shen\"}],\"doi\":\"10.1016/j.patcog.2020.107515\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"999e740a50f0bbfe4e1e4e52e29fd83a30aa9156\",\"title\":\"Fast sparse coding networks for anomaly detection in videos\",\"url\":\"https://www.semanticscholar.org/paper/999e740a50f0bbfe4e1e4e52e29fd83a30aa9156\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1812.03544\",\"authors\":[{\"authorId\":\"49890205\",\"name\":\"Yubo Zhang\"},{\"authorId\":\"2931554\",\"name\":\"P. Tokmakov\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPR.2019.01021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0181eb5f6f94df18586fea79d6ad37e583ff6f0c\",\"title\":\"A Structured Model for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/0181eb5f6f94df18586fea79d6ad37e583ff6f0c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1908.01449\",\"authors\":[{\"authorId\":\"2177037\",\"name\":\"Andrew Kae\"},{\"authorId\":\"2317183\",\"name\":\"Yale Song\"}],\"doi\":\"10.1109/WACV45572.2020.9093645\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e776cc129ed89303af6f2075ccfcea596243ff5d\",\"title\":\"Image to Video Domain Adaptation Using Web Supervision\",\"url\":\"https://www.semanticscholar.org/paper/e776cc129ed89303af6f2075ccfcea596243ff5d\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1811.09961\",\"authors\":[{\"authorId\":\"144865353\",\"name\":\"B. Pang\"},{\"authorId\":\"15376265\",\"name\":\"Kaiwen Zha\"},{\"authorId\":\"3166067\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"145716219\",\"name\":\"C. Shi\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":\"10.1109/CVPR.2019.00051\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"title\":\"Deep RNN Framework for Visual Sequential Applications\",\"url\":\"https://www.semanticscholar.org/paper/5cd3a3c746c0fdb26630c3ed483294e2daeffa38\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145057310\",\"name\":\"A. Ho\"}],\"doi\":\"10.1186/s12877-020-01764-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe0b3685af4badc1f866091e5a1a146c6e37252c\",\"title\":\"Are we ready for artificial intelligence health monitoring in elder care?\",\"url\":\"https://www.semanticscholar.org/paper/fe0b3685af4badc1f866091e5a1a146c6e37252c\",\"venue\":\"BMC Geriatrics\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1804.04810\",\"authors\":[{\"authorId\":\"143758901\",\"name\":\"Jungbeom Lee\"},{\"authorId\":\"2808551\",\"name\":\"Jangho Lee\"},{\"authorId\":\"47090426\",\"name\":\"Sungmin Lee\"},{\"authorId\":\"2999019\",\"name\":\"S. Yoon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3497be24bcecb698a700b02c12e23b305ea0c24c\",\"title\":\"MSnet: Mutual Suppression Network for Disentangled Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/3497be24bcecb698a700b02c12e23b305ea0c24c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30679763\",\"name\":\"Xuezhe Li\"},{\"authorId\":\"153109159\",\"name\":\"L. Wen\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"},{\"authorId\":\"2020817\",\"name\":\"Ming Zeng\"}],\"doi\":\"10.1109/ICAICA50127.2020.9182498\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b679ccceefd9605661115e6e2391ad3c9076168\",\"title\":\"Spatio-temporal Collaborative Convolution for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5b679ccceefd9605661115e6e2391ad3c9076168\",\"venue\":\"2020 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)\",\"year\":2020},{\"arxivId\":\"1708.07632\",\"authors\":[{\"authorId\":\"2199251\",\"name\":\"K. Hara\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"}],\"doi\":\"10.1109/ICCVW.2017.373\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"title\":\"Learning Spatio-Temporal Features with 3D Residual Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/07c83f544d0604e6bab5d741b0bf9a3621d133da\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18071979\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2588acc7a730d864f84d4e1a050070ff873b03d5\",\"title\":\"Action Recognition by an Attention-Aware Temporal Weighted Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/2588acc7a730d864f84d4e1a050070ff873b03d5\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"2008.00744\",\"authors\":[{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"1614038854\",\"name\":\"Yang Liu\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"47107270\",\"name\":\"E. Coto\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"151352107\",\"name\":\"Valentin Gabeur\"},{\"authorId\":\"1612977414\",\"name\":\"Chen Sun\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"50976845\",\"name\":\"Yida Zhao\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"87652983\",\"name\":\"H. Liu\"},{\"authorId\":\"1808091339\",\"name\":\"Chen Wang\"},{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145912650\",\"name\":\"X. Hao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2921b34b99c6150a7625acdbdd99504c2789f7a2\",\"title\":\"The End-of-End-to-End: A Video Understanding Pentathlon Challenge (2020)\",\"url\":\"https://www.semanticscholar.org/paper/2921b34b99c6150a7625acdbdd99504c2789f7a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.10211\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3727443e7c0bb819846a1f98e6efd772d34824c9\",\"title\":\"Motion-Aware Feature for Improved Video Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/3727443e7c0bb819846a1f98e6efd772d34824c9\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143868463\",\"name\":\"Hao Zhou\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICME.2019.00223\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f4a391a41b386612a86f6296a7a86b0e71f1381e\",\"title\":\"Dynamic Pseudo Label Decoding for Continuous Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4a391a41b386612a86f6296a7a86b0e71f1381e\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"2004.01225\",\"authors\":[{\"authorId\":\"1944885\",\"name\":\"A. Kindiroglu\"},{\"authorId\":\"32852728\",\"name\":\"Ogulcan \\u00d6zdemir\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":\"10.1109/ICCVW.2019.00164\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"title\":\"Temporal Accumulative Features for Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13fbc66718d1a4b1c05e0aad78da9642cb61925e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1910.09165\",\"authors\":[{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"3235234\",\"name\":\"Mengyuan Yan\"},{\"authorId\":\"1775407\",\"name\":\"Jeannette Bohg\"}],\"doi\":\"10.1109/ICCV.2019.00934\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b653666bfda393adbc765fc5cac8a3a6b0cdf54\",\"title\":\"MeteorNet: Deep Learning on Dynamic 3D Point Cloud Sequences\",\"url\":\"https://www.semanticscholar.org/paper/1b653666bfda393adbc765fc5cac8a3a6b0cdf54\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39974958\",\"name\":\"T. Yu\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"49610443\",\"name\":\"Cheng Da\"},{\"authorId\":\"1909131\",\"name\":\"Huxiang Gu\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2907060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"title\":\"Weakly Semantic Guided Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/53dc8bbc0ccf39b916e0833edeef63fa09eea43c\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73441526\",\"name\":\"R. Tan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"2856622\",\"name\":\"Bryan A. Plummer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"title\":\"wMAN: Weakly-supervised Moment Alignment Network for Text-based Video Segment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/23fb5231bb8629bec8b7bfc15cccefca2cbd1754\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49751801\",\"name\":\"C. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"488370572904a8fd97f5bc68fbdf0b3b3984cc76\",\"title\":\"Alibaba-Venus at ActivityNet Challenge 2018-Task C Trimmed Event Recognition ( Moments in Time )\",\"url\":\"https://www.semanticscholar.org/paper/488370572904a8fd97f5bc68fbdf0b3b3984cc76\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32346302\",\"name\":\"F. Wang\"},{\"authorId\":\"1423415979\",\"name\":\"Guorui Wang\"},{\"authorId\":\"100975725\",\"name\":\"Yunwen Huang\"},{\"authorId\":\"49276987\",\"name\":\"Hao Chu\"}],\"doi\":\"10.1109/ACCESS.2019.2953113\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65d934938c27585e144660ae7c293d297dddf64b\",\"title\":\"SAST: Learning Semantic Action-Aware Spatial-Temporal Features for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65d934938c27585e144660ae7c293d297dddf64b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1904.04689\",\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.01015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"title\":\"Action Recognition From Single Timestamp Supervision in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/c7ee1000ff197985553c9fb8d9cdc838d2858cff\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.07712\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-11015-4_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ffcf3435b1e7a984836bac25800481fb5140d97\",\"title\":\"Predicting Action Tubes\",\"url\":\"https://www.semanticscholar.org/paper/7ffcf3435b1e7a984836bac25800481fb5140d97\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144460714\",\"name\":\"Yuan Liu\"},{\"authorId\":\"49712840\",\"name\":\"Xiang-dong You\"}],\"doi\":\"10.1109/ICICSP48821.2019.8958568\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0cf7feac9b536941b9014d2bb54217cd9a9e77a\",\"title\":\"Specific Action Recognition Method based on Unbalanced Dataset\",\"url\":\"https://www.semanticscholar.org/paper/f0cf7feac9b536941b9014d2bb54217cd9a9e77a\",\"venue\":\"2019 IEEE 2nd International Conference on Information Communication and Signal Processing (ICICSP)\",\"year\":2019},{\"arxivId\":\"2003.00389\",\"authors\":[{\"authorId\":\"32879676\",\"name\":\"Jiezhang Cao\"},{\"authorId\":\"90891818\",\"name\":\"Langyuan Mo\"},{\"authorId\":\"150270181\",\"name\":\"Qing Du\"},{\"authorId\":\"143670622\",\"name\":\"Yong Guo\"},{\"authorId\":\"144259957\",\"name\":\"P. Zhao\"},{\"authorId\":\"50882910\",\"name\":\"Junzhou Huang\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3cec7f2172d4e09db5a62e8a4f83c4f32a3e32e9\",\"title\":\"Joint Wasserstein Distribution Matching\",\"url\":\"https://www.semanticscholar.org/paper/3cec7f2172d4e09db5a62e8a4f83c4f32a3e32e9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51136895\",\"name\":\"Jose Rodrigo Sanchez Vicarte\"},{\"authorId\":\"49283812\",\"name\":\"Benjamin Schreiber\"},{\"authorId\":\"153098244\",\"name\":\"Riccardo Paccagnella\"},{\"authorId\":\"2012099\",\"name\":\"Christopher W. Fletcher\"}],\"doi\":\"10.1145/3373376.3378462\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cee94afe3ebb3a03059611d384722e9c3c714ad7\",\"title\":\"Game of Threads: Enabling Asynchronous Poisoning Attacks\",\"url\":\"https://www.semanticscholar.org/paper/cee94afe3ebb3a03059611d384722e9c3c714ad7\",\"venue\":\"ASPLOS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1685776\",\"name\":\"Y. Li\"},{\"authorId\":\"1695600\",\"name\":\"X. Chai\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1007/978-3-030-00767-6_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f2eb32ef5538ae65e0fbe905ba6cfe7387b6eb3f\",\"title\":\"End-To-End Learning for Action Quality Assessment\",\"url\":\"https://www.semanticscholar.org/paper/f2eb32ef5538ae65e0fbe905ba6cfe7387b6eb3f\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2009.11232\",\"authors\":[{\"authorId\":\"1432778730\",\"name\":\"Binjie Zhang\"},{\"authorId\":\"1940342\",\"name\":\"Y. Li\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"},{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"2091174\",\"name\":\"Pin Jiang\"},{\"authorId\":\"1387190008\",\"name\":\"Ying Shan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1e645df446ccdc985b85864ac0b91b053090c14d\",\"title\":\"A Simple Yet Effective Method for Video Temporal Grounding with Cross-Modality Attention\",\"url\":\"https://www.semanticscholar.org/paper/1e645df446ccdc985b85864ac0b91b053090c14d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03996\",\"authors\":[{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"1382648588\",\"name\":\"Wei Peng\"},{\"authorId\":\"66966514\",\"name\":\"Yoon Lee\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6c9d32b48ad0c668e496b7c04c6f49dd87d5c5f5\",\"title\":\"2nd Place Scheme on Action Recognition Track of ECCV 2020 VIPriors Challenges: An Efficient Optical Flow Stream Guided Framework\",\"url\":\"https://www.semanticscholar.org/paper/6c9d32b48ad0c668e496b7c04c6f49dd87d5c5f5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1807.08333\",\"authors\":[{\"authorId\":\"2195345\",\"name\":\"Zheng Shou\"},{\"authorId\":null,\"name\":\"Hang Gao\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"1789840\",\"name\":\"K. Miyazawa\"},{\"authorId\":\"9546964\",\"name\":\"S. Chang\"}],\"doi\":\"10.1007/978-3-030-01270-0_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca\",\"title\":\"AutoLoc: Weakly-Supervised Temporal Action Localization in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/523909d26ea94eaa0dd0285ba6ea0cd00a0aa7ca\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7607636\",\"name\":\"Y. Yang\"},{\"authorId\":\"51499895\",\"name\":\"Zhe Yuan\"},{\"authorId\":\"1739150831\",\"name\":\"Fang Su\"},{\"authorId\":\"1859341456\",\"name\":\"Fanyang Cheng\"},{\"authorId\":\"47292352\",\"name\":\"Z. Yuan\"},{\"authorId\":\"49424303\",\"name\":\"Huazhong Yang\"},{\"authorId\":\"7895895\",\"name\":\"Yongpan Liu\"}],\"doi\":\"10.1145/3370748.3407002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e35724afbb4fcfe5d40f73e495604f8d7afa338f\",\"title\":\"Multi-channel precision-sparsity-adapted inter-frame differential data codec for video neural network processor\",\"url\":\"https://www.semanticscholar.org/paper/e35724afbb4fcfe5d40f73e495604f8d7afa338f\",\"venue\":\"ISLPED\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2577842\",\"name\":\"R. An\"},{\"authorId\":\"145183674\",\"name\":\"Z. Miao\"},{\"authorId\":\"50444385\",\"name\":\"Q. Li\"},{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49347106\",\"name\":\"Q. Zhang\"}],\"doi\":\"10.1117/1.JEI.28.2.023007\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea9d0ab37fd0ab42ede12271a6eb1ff2eb55aab1\",\"title\":\"Spatiotemporal visual-semantic embedding network for zero-shot action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea9d0ab37fd0ab42ede12271a6eb1ff2eb55aab1\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":\"1910.00932\",\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840270\",\"name\":\"S. Han\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9739f39feacca0550eff8ac42a92445efdce31c8\",\"title\":\"Training Kinetics in 15 Minutes: Large-scale Distributed Training on Videos\",\"url\":\"https://www.semanticscholar.org/paper/9739f39feacca0550eff8ac42a92445efdce31c8\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2519063\",\"name\":\"Zhengyang Shen\"},{\"authorId\":\"49451441\",\"name\":\"F. Wang\"},{\"authorId\":\"145618715\",\"name\":\"J. Dai\"}],\"doi\":\"10.1109/ACCESS.2020.2967627\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4f574dbac4d1f33412e003bc4659561713566dc9\",\"title\":\"Weakly Supervised Temporal Action Localization by Multi-Stage Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/4f574dbac4d1f33412e003bc4659561713566dc9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48354916\",\"name\":\"Ze Chen\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3297097.3297107\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f9fff8a34942053fd93760c8c84a40849b9db734\",\"title\":\"Recurrent Spatiotemporal Feature Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f9fff8a34942053fd93760c8c84a40849b9db734\",\"venue\":\"ICRAI 2018\",\"year\":2018},{\"arxivId\":\"1910.13888\",\"authors\":[{\"authorId\":\"3040310\",\"name\":\"Y. Jiang\"},{\"authorId\":\"1389284356\",\"name\":\"Kaixu Cui\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"48258796\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCVW.2019.00195\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"title\":\"Comprehensive Video Understanding: Video Summarization with Content-Based Video Recommender Design\",\"url\":\"https://www.semanticscholar.org/paper/126d93fb45ee6e4d9af314981e8430aa5b2f24c1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47096736\",\"name\":\"Y. Wu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1007/s11263-019-01198-w\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d08b35243edc5be07387a9ed218070b31e502901\",\"title\":\"Group Normalization\",\"url\":\"https://www.semanticscholar.org/paper/d08b35243edc5be07387a9ed218070b31e502901\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2012.05689\",\"authors\":[{\"authorId\":\"1845885740\",\"name\":\"Rui Yan\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f40225f23d46fd15d35b1529427f2f6055c737d4\",\"title\":\"Interactive Fusion of Multi-level Features for Compositional Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f40225f23d46fd15d35b1529427f2f6055c737d4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2007.09933\",\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"16142867\",\"name\":\"Manjin Kim\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1007/978-3-030-58517-4_21\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5be8a78db1631159500e7cee249729820e355b2\",\"title\":\"MotionSqueeze: Neural Motion Feature Learning for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b5be8a78db1631159500e7cee249729820e355b2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1910.06271\",\"authors\":[{\"authorId\":\"50992950\",\"name\":\"Karim Armanious\"},{\"authorId\":\"30001943\",\"name\":\"Sherif Abdulatif\"},{\"authorId\":\"1379794654\",\"name\":\"Anish Rao Bhaktharaguttu\"},{\"authorId\":\"3245968\",\"name\":\"Thomas K\\u00fcstner\"},{\"authorId\":\"12268601\",\"name\":\"T. Hepp\"},{\"authorId\":\"3403367\",\"name\":\"S. Gatidis\"},{\"authorId\":\"1390708649\",\"name\":\"Bin Yang\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287398\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b586e0e3c64a93e02cf9f37989b740a9390478c\",\"title\":\"Organ-Based Chronological Age Estimation Based on 3D MRI Scans\",\"url\":\"https://www.semanticscholar.org/paper/0b586e0e3c64a93e02cf9f37989b740a9390478c\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":\"1910.06271\",\"authors\":[{\"authorId\":\"50992950\",\"name\":\"Karim Armanious\"},{\"authorId\":\"30001943\",\"name\":\"Sherif Abdulatif\"},{\"authorId\":\"1379794654\",\"name\":\"Anish Rao Bhaktharaguttu\"},{\"authorId\":\"3245968\",\"name\":\"Thomas K\\u00fcstner\"},{\"authorId\":\"12268601\",\"name\":\"T. Hepp\"},{\"authorId\":\"3403367\",\"name\":\"S. Gatidis\"},{\"authorId\":\"90869173\",\"name\":\"B. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba8dca1f01eb1f6827950184e4d5289c6b71d799\",\"title\":\"Organ-based Age Estimation based on 3D MRI Scans\",\"url\":\"https://www.semanticscholar.org/paper/ba8dca1f01eb1f6827950184e4d5289c6b71d799\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117454237\",\"name\":\"Zirui Qiu\"},{\"authorId\":\"144359415\",\"name\":\"J. Sun\"},{\"authorId\":\"51163848\",\"name\":\"Mingyue Guo\"},{\"authorId\":\"21836351\",\"name\":\"Mantao Wang\"},{\"authorId\":\"46334637\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-0121-0_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71e47cea739e472da47756040e78fdae8bd21752\",\"title\":\"Survey on Deep Learning for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/71e47cea739e472da47756040e78fdae8bd21752\",\"venue\":\"ICPCSEE\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77537913\",\"name\":\"J. Lee\"}],\"doi\":\"10.1007/s11042-019-08011-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2623c1b4aee3f043da30d05f3e2c0f62fca5d5e\",\"title\":\"Deep multimodal embedding for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/c2623c1b4aee3f043da30d05f3e2c0f62fca5d5e\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1806.08409\",\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"2809915\",\"name\":\"H. AlAmri\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"51002409\",\"name\":\"Vincent Cartillier\"},{\"authorId\":\"143826364\",\"name\":\"Raphael Gontijo Lopes\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"21472040\",\"name\":\"Irfan Essa\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICASSP.2019.8682583\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"title\":\"End-to-end Audio Visual Scene-aware Dialog Using Multimodal Attention-based Video Features\",\"url\":\"https://www.semanticscholar.org/paper/85c22ce1a62973a4b64bbcde26748893d61d01e4\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1420048927\",\"name\":\"Molefe Vicky Mleya\"},{\"authorId\":\"48625207\",\"name\":\"W. Li\"},{\"authorId\":\"2607232\",\"name\":\"Jiayu Liang\"},{\"authorId\":\"3386073\",\"name\":\"Kunliang Liu\"},{\"authorId\":\"1414723015\",\"name\":\"Yunkuan Sun\"},{\"authorId\":\"151470674\",\"name\":\"Guanghao Jin\"},{\"authorId\":\"46584793\",\"name\":\"J. Wang\"}],\"doi\":\"10.1007/978-3-030-35231-8_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"84fecb0af9b7c29afb78512648751018f0029cb7\",\"title\":\"Online Aggregated-Event Representation for Multiple Event Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/84fecb0af9b7c29afb78512648751018f0029cb7\",\"venue\":\"ADMA\",\"year\":2019},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1612.00738\",\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"}],\"doi\":\"10.1109/TPAMI.2017.2769085\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2fe8c43aa9427582906c684afadebbc6a86fa036\",\"title\":\"Action Recognition with Dynamic Image Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe8c43aa9427582906c684afadebbc6a86fa036\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"2011.13202\",\"authors\":[{\"authorId\":\"2029244883\",\"name\":\"Soroosh Poorgholi\"},{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"title\":\"t-EVA: Time-Efficient t-SNE Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.00451\",\"authors\":[{\"authorId\":\"153276988\",\"name\":\"Antoine Yang\"},{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"title\":\"Just Ask: Learning to Answer Questions from Millions of Narrated Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1b6ff0df21818ac8c4f61d86141da48188f36b3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11893\",\"authors\":[{\"authorId\":\"1596823732\",\"name\":\"Baifeng Shi\"},{\"authorId\":\"2000157278\",\"name\":\"Qi Dai\"},{\"authorId\":\"50196944\",\"name\":\"Judy Hoffman\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"80126506f744e1efd827e69951bdb6e558eb77a7\",\"title\":\"Temporal Action Detection with Multi-level Supervision\",\"url\":\"https://www.semanticscholar.org/paper/80126506f744e1efd827e69951bdb6e558eb77a7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.09725\",\"authors\":[{\"authorId\":\"82677028\",\"name\":\"Coen de Vente\"},{\"authorId\":\"1844322460\",\"name\":\"Luuk H Boulogne\"},{\"authorId\":\"1955423208\",\"name\":\"Kiran Vaidhya Venkadesh\"},{\"authorId\":\"1568863061\",\"name\":\"Cheryl Sital\"},{\"authorId\":\"2913408\",\"name\":\"Nikolas Lessmann\"},{\"authorId\":\"2895994\",\"name\":\"C. Jacobs\"},{\"authorId\":\"2107706\",\"name\":\"C. I. S\\u00e1nchez\"},{\"authorId\":\"8038506\",\"name\":\"B. Ginneken\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"441d6e8ba2cc2314d7d44425a158c25e27f9cb96\",\"title\":\"Improving Automated COVID-19 Grading with Convolutional Neural Networks in Computed Tomography Scans: An Ablation Study\",\"url\":\"https://www.semanticscholar.org/paper/441d6e8ba2cc2314d7d44425a158c25e27f9cb96\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.06843\",\"authors\":[{\"authorId\":\"1416650467\",\"name\":\"Vida Adeli\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"1387977754\",\"name\":\"Hamid Rezatofighi\"}],\"doi\":\"10.1109/lra.2020.3010742\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39716ff3e1d5a464f42c6b55366fcc8ddb712f7b\",\"title\":\"Socially and Contextually Aware Human Motion and Pose Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/39716ff3e1d5a464f42c6b55366fcc8ddb712f7b\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"2008.07728\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":null,\"name\":\"Tao Zhao\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c065821de73b6bb87a2a2376134ac9c28008486\",\"title\":\"Equivalent Classification Mapping for Weakly Supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/1c065821de73b6bb87a2a2376134ac9c28008486\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.07833\",\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"2702234\",\"name\":\"A. Gupta\"},{\"authorId\":\"2358803\",\"name\":\"F. Khan\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"}],\"doi\":\"10.1007/978-3-030-58542-6_29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9e98cbe813ead99c5f4f57be4ff6949fb51442a\",\"title\":\"Latent Embedding Feedback and Discriminative Features for Zero-Shot Classification\",\"url\":\"https://www.semanticscholar.org/paper/d9e98cbe813ead99c5f4f57be4ff6949fb51442a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.04325\",\"authors\":[{\"authorId\":\"1904028\",\"name\":\"Oren Haik\"},{\"authorId\":\"151162020\",\"name\":\"Oded Perry\"},{\"authorId\":\"28108620\",\"name\":\"Eli Chen\"},{\"authorId\":\"69926165\",\"name\":\"P. Klammer\"}],\"doi\":\"10.1109/WACV45572.2020.9093396\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f66e7483f41f579c8867edfb8f5b3df7ea5649c3\",\"title\":\"A Novel Inspection System For Variable Data Printing Using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/f66e7483f41f579c8867edfb8f5b3df7ea5649c3\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2008.02129\",\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"46396519\",\"name\":\"Yiqi Lin\"},{\"authorId\":\"38624848\",\"name\":\"A. J. Ma\"},{\"authorId\":\"1768574\",\"name\":\"P. Yuen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"title\":\"Self-supervised Temporal Discriminative Learning for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a4bf06da8592a52d5bc7a52c5fa8d0dca45b9bce\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2808158\",\"name\":\"Necati Cihan Camg\\u00f6z\"},{\"authorId\":\"2417546\",\"name\":\"S. Hadfield\"},{\"authorId\":\"145398628\",\"name\":\"R. Bowden\"}],\"doi\":\"10.1109/ICCVW.2017.364\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"908667ca31085ff89a56f00f30aa3c6592a223e7\",\"title\":\"Particle Filter Based Probabilistic Forced Alignment for Continuous Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/908667ca31085ff89a56f00f30aa3c6592a223e7\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1910.06693\",\"authors\":[{\"authorId\":\"1901010\",\"name\":\"A. Cartas\"},{\"authorId\":\"145114663\",\"name\":\"J. Luque\"},{\"authorId\":\"143601910\",\"name\":\"P. Radeva\"},{\"authorId\":\"1380262503\",\"name\":\"C. Segura\"},{\"authorId\":\"2837527\",\"name\":\"Mariella Dimiccoli\"}],\"doi\":\"10.1109/ICCVW.2019.00548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d1cf1ce95af190223519c1c9705251c15557afe4\",\"title\":\"Seeing and Hearing Egocentric Actions: How Much Can We Learn?\",\"url\":\"https://www.semanticscholar.org/paper/d1cf1ce95af190223519c1c9705251c15557afe4\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51046192\",\"name\":\"Yixiong Zou\"},{\"authorId\":\"38179026\",\"name\":\"Y. Shi\"},{\"authorId\":\"5765799\",\"name\":\"Yaowei Wang\"},{\"authorId\":\"143672707\",\"name\":\"Y. Shu\"},{\"authorId\":\"3330973\",\"name\":\"Qingsheng Yuan\"},{\"authorId\":\"40161651\",\"name\":\"Yonghong Tian\"}],\"doi\":\"10.1109/ICME.2018.8486447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d530c341b3eda84c0b0a2c3149232daf16056f4\",\"title\":\"Hierarchical Temporal Memory Enhanced One-Shot Distance Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d530c341b3eda84c0b0a2c3149232daf16056f4\",\"venue\":\"2018 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2018},{\"arxivId\":\"1908.03448\",\"authors\":[{\"authorId\":\"33556804\",\"name\":\"Jialin Gao\"},{\"authorId\":\"3568337\",\"name\":\"Zhixiang Shi\"},{\"authorId\":\"1492113737\",\"name\":\"Jiani Li\"},{\"authorId\":\"46499930\",\"name\":\"Yufeng Yuan\"},{\"authorId\":\"5183779\",\"name\":\"Jiwei Li\"},{\"authorId\":\"116176284\",\"name\":\"Xi Zhou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b2a6d158acdd05516fa43acf354dcd18918a251\",\"title\":\"Relation-Aware Pyramid Network (RapNet) for temporal action proposal\",\"url\":\"https://www.semanticscholar.org/paper/8b2a6d158acdd05516fa43acf354dcd18918a251\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.05006\",\"authors\":[{\"authorId\":\"150065958\",\"name\":\"Chiwan Song\"},{\"authorId\":\"40506942\",\"name\":\"Woobin Im\"},{\"authorId\":\"144182454\",\"name\":\"Sung-eui Yoon\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"title\":\"Two-stream Spatiotemporal Feature for Video QA Task\",\"url\":\"https://www.semanticscholar.org/paper/b48cf57d41e81f201a756c6b280fa2ebfe52f9d3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"97474510\",\"name\":\"L. Xu\"},{\"authorId\":\"153940079\",\"name\":\"Guan Huang\"}],\"doi\":\"10.1109/LSP.2019.2942739\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"title\":\"Action Machine: Toward Person-Centric Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d45d6e1625af82c656ee9cc6d98fd7f58c923636\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":\"1903.04480\",\"authors\":[{\"authorId\":\"7588865\",\"name\":\"Junting Pan\"},{\"authorId\":null,\"name\":\"Chengyu Wang\"},{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00385\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f66d531439f5847afa7b31f49db87a44b788690\",\"title\":\"Video Generation From Single Semantic Label Map\",\"url\":\"https://www.semanticscholar.org/paper/2f66d531439f5847afa7b31f49db87a44b788690\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145338246\",\"name\":\"F. Yang\"},{\"authorId\":\"1783949\",\"name\":\"Sakriani Sakti\"},{\"authorId\":\"1390531397\",\"name\":\"Wu Yang\"},{\"authorId\":\"1755144\",\"name\":\"Satoshi\"},{\"authorId\":\"122237784\",\"name\":\"Nakamura\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"45f19db1beacdf5753544603e80dfb3ebc7a4a9e\",\"title\":\"Detection Tracking Action Recognition Generate Patches Downscale Multi-label Actions Ultra-high-resolution Aerial Image 2160 x 3840 Patches 608 x 608 Cropping\",\"url\":\"https://www.semanticscholar.org/paper/45f19db1beacdf5753544603e80dfb3ebc7a4a9e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"Rui Hou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/b4f422ef7f1297860bb4f011fbe30e01b233951c\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1007/978-3-030-01252-6_13\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"9258ae3ad05e77555d3459dfbcfa9c70440c5f88\",\"title\":\"What Do I Annotate Next? An Empirical Study of Active Learning for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/9258ae3ad05e77555d3459dfbcfa9c70440c5f88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.02860\",\"authors\":[{\"authorId\":\"49417387\",\"name\":\"Y. Wang\"},{\"authorId\":\"38272296\",\"name\":\"W. Zhou\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f414a4f51748d548c2e72971f1e428ebb34754bd\",\"title\":\"Visual Attribute-augmented Three-dimensional Convolutional Neural Network for Enhanced Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f414a4f51748d548c2e72971f1e428ebb34754bd\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f23b737af93469efc4b7438377a3cec2e9c8febb\",\"title\":\"Ju l 2 01 8 Learning Discriminative Video Representations Using Adversarial Perturbations\",\"url\":\"https://www.semanticscholar.org/paper/f23b737af93469efc4b7438377a3cec2e9c8febb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"101980376\",\"name\":\"F. Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b7214890681dda4ff5e86fa44c900287f3788eb\",\"title\":\"Supplementary Material: Recurrent Convolutions for Causal 3D CNNs\",\"url\":\"https://www.semanticscholar.org/paper/8b7214890681dda4ff5e86fa44c900287f3788eb\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144118668\",\"name\":\"En Yu\"},{\"authorId\":\"3446043\",\"name\":\"Wenhe Liu\"},{\"authorId\":\"3374337\",\"name\":\"Guoliang Kang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"51299154\",\"name\":\"Jiande Sun\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a610209df26b3a090e587e70f09792410fb0b26f\",\"title\":\"Inf@TRECVID 2019: Instance Search Task\",\"url\":\"https://www.semanticscholar.org/paper/a610209df26b3a090e587e70f09792410fb0b26f\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153185012\",\"name\":\"G. Li\"},{\"authorId\":\"1500519009\",\"name\":\"Ziwei Wang\"},{\"authorId\":null,\"name\":\"Yi Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5ff92cb44f42fdd3537cb6e6a226465d8e9df9e\",\"title\":\"UTS_CETC_D2DCRC Submission at the TRECVID 2018 Video to Text Description Task\",\"url\":\"https://www.semanticscholar.org/paper/c5ff92cb44f42fdd3537cb6e6a226465d8e9df9e\",\"venue\":\"TRECVID\",\"year\":2018},{\"arxivId\":\"2004.01494\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"title\":\"Two-Stream AMTnet for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/b6186cb2b81c4d39f7ba1b5ec649a3171b0caefd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144821367\",\"name\":\"Tian Jin\"},{\"authorId\":\"152237365\",\"name\":\"Zhihao He\"},{\"authorId\":\"152449715\",\"name\":\"Amlan Basu\"},{\"authorId\":\"1684980\",\"name\":\"J. Soraghan\"},{\"authorId\":\"27469280\",\"name\":\"G. Di Caterina\"},{\"authorId\":\"69329588\",\"name\":\"L. Petropoulakis\"}],\"doi\":\"10.1109/ICCAR.2019.8813408\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0c245c67fcf0e472bb2eb1fe6fa9821c0c4bd2f0\",\"title\":\"Dense Convolutional Networks for Efficient Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/0c245c67fcf0e472bb2eb1fe6fa9821c0c4bd2f0\",\"venue\":\"2019 5th International Conference on Control, Automation and Robotics (ICCAR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145905953\",\"name\":\"X. Xue\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b3fd234bd072706af99100edba037b13d5a0069\",\"title\":\"High Order Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5b3fd234bd072706af99100edba037b13d5a0069\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2092543\",\"name\":\"Gediminas Bertasius\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"title\":\"Embodied Visual Perception Models For Human Behavior Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5dee122d4a5e8726ba280dd3c9a804b1e69e7406\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153772546\",\"name\":\"K. Ning\"},{\"authorId\":\"3041937\",\"name\":\"Lingxi Xie\"},{\"authorId\":\"1521935491\",\"name\":\"Fei Wu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.24963/ijcai.2020/132\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d358f8939992a8c2c649338810aa5e66ed665568\",\"title\":\"Polar Relative Positional Encoding for Video-Language Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/d358f8939992a8c2c649338810aa5e66ed665568\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2444704\",\"name\":\"Xindi Shang\"},{\"authorId\":\"79723716\",\"name\":\"D. Di\"},{\"authorId\":\"66358686\",\"name\":\"J. Xiao\"},{\"authorId\":\"144149886\",\"name\":\"Yu Cao\"},{\"authorId\":\"2028727\",\"name\":\"X. Yang\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3323873.3325056\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0388f5373a2f17a3c456346a52427c887667ea\",\"title\":\"Annotating Objects and Relations in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/fa0388f5373a2f17a3c456346a52427c887667ea\",\"venue\":\"ICMR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153344447\",\"name\":\"Bruce McIntosh\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":\"10.1109/cvpr42600.2020.00996\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b990461318a506822182a689b0e13d5e9465f0dc\",\"title\":\"Visual-Textual Capsule Routing for Text-Based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b990461318a506822182a689b0e13d5e9465f0dc\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2001.06769\",\"authors\":[{\"authorId\":\"151080964\",\"name\":\"Kaiyu Shan\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"},{\"authorId\":\"5744018\",\"name\":\"Z. Wang\"},{\"authorId\":\"47715977\",\"name\":\"Ting-Ting Liang\"},{\"authorId\":null,\"name\":\"Zhi Tang\"},{\"authorId\":\"50581109\",\"name\":\"Y. Chen\"},{\"authorId\":\"1920864\",\"name\":\"Yangyan Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"title\":\"MixTConv: Mixed Temporal Convolutional Kernels for Efficient Action Recogntion\",\"url\":\"https://www.semanticscholar.org/paper/0c09d3844807f4cbed18f5ff5d5df34a89365d07\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3235708\",\"name\":\"Guoqiang Gong\"},{\"authorId\":\"93768847\",\"name\":\"Xinghan Wang\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/cvpr42600.2020.00984\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"title\":\"Learning Temporal Co-Attention Models for Unsupervised Video Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/d2301072587dadf9e18552f35abfc26dac3f4b8e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1659078191\",\"name\":\"X. Nguyena\"},{\"authorId\":\"1659078265\",\"name\":\"Yongjian HUb\"},{\"authorId\":\"1659077518\",\"name\":\"Khan Gohar Hayatc\"},{\"authorId\":\"1659070836\",\"name\":\"Van Thinh Led\"},{\"authorId\":\"1659072037\",\"name\":\"Tu D. Truonge\"}],\"doi\":\"10.28933/AJCSA-2019-09-0905\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec1511a643dc763d43c7fda91b40f72c65f33574\",\"title\":\"Detecting Video Inter-Frame Forgeries Based on Convolutional Neural Network Models\",\"url\":\"https://www.semanticscholar.org/paper/ec1511a643dc763d43c7fda91b40f72c65f33574\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143727953\",\"name\":\"A. Wu\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1007/s11263-019-01238-5\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"879a6970d46e6a22f45875f404e067148dcd326c\",\"title\":\"Model-Based Robot Imitation with Future Image Similarity\",\"url\":\"https://www.semanticscholar.org/paper/879a6970d46e6a22f45875f404e067148dcd326c\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2010.08164\",\"authors\":[{\"authorId\":\"47287725\",\"name\":\"Anshul B. Shah\"},{\"authorId\":\"2850880\",\"name\":\"Shlok Kumar Mishra\"},{\"authorId\":\"2068427\",\"name\":\"Ankan Bansal\"},{\"authorId\":\"1391201966\",\"name\":\"Jun-Cheng Chen\"},{\"authorId\":\"69416958\",\"name\":\"Ramalingam Chellappa\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"title\":\"Pose And Joint-Aware Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5ac51a6eb28656c670c36a6460be0e458b2e562f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.11844\",\"authors\":[{\"authorId\":\"24060014\",\"name\":\"Ipek Ganiyusufoglu\"},{\"authorId\":\"72187685\",\"name\":\"L. M. Ngo\"},{\"authorId\":\"1557601824\",\"name\":\"N. Savov\"},{\"authorId\":\"1968574\",\"name\":\"Sezer Karaoglu\"},{\"authorId\":\"1620219267\",\"name\":\"Theo Gevers\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c6b9e7f0d35690a30a41b090ddba33fd5fe4b8c6\",\"title\":\"Spatio-temporal Features for Generalized Detection of Deepfake Videos\",\"url\":\"https://www.semanticscholar.org/paper/c6b9e7f0d35690a30a41b090ddba33fd5fe4b8c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.10864\",\"authors\":[{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"34450903\",\"name\":\"J. Carreira\"},{\"authorId\":\"51210148\",\"name\":\"Eric Noland\"},{\"authorId\":\"152202493\",\"name\":\"Ellen Clancy\"},{\"authorId\":\"5157210\",\"name\":\"A. Wu\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb034caef3720744402363162e8f9b8758f0b82c\",\"title\":\"A Short Note on the Kinetics-700-2020 Human Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/fb034caef3720744402363162e8f9b8758f0b82c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2300332\",\"name\":\"R. Pourreza\"},{\"authorId\":\"90191889\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"3000952\",\"name\":\"A. Habibian\"}],\"doi\":\"10.1109/ICCVW.2019.00129\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"607b8b660c4a60cca358ab7583a3ee24d76c27b2\",\"title\":\"Recognizing Compressed Videos: Challenges and Promises\",\"url\":\"https://www.semanticscholar.org/paper/607b8b660c4a60cca358ab7583a3ee24d76c27b2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2004.13217\",\"authors\":[{\"authorId\":\"34871664\",\"name\":\"R. Cruz\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145185576\",\"name\":\"Dylan Campbell\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPRW50498.2020.00192\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"537b0899452b3ed09a2945cdd5f3d42383611fac\",\"title\":\"Inferring Temporal Compositions of Actions Using Probabilistic Automata\",\"url\":\"https://www.semanticscholar.org/paper/537b0899452b3ed09a2945cdd5f3d42383611fac\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2006.15983\",\"authors\":[{\"authorId\":\"46933964\",\"name\":\"Gabrielle Ras\"},{\"authorId\":\"2396027\",\"name\":\"L. Ambrogioni\"},{\"authorId\":\"69426785\",\"name\":\"Pim Haselager\"},{\"authorId\":\"143799386\",\"name\":\"M. V. Gerven\"},{\"authorId\":\"8470000\",\"name\":\"Umut Gucclu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6a670bb5caa48964329e482414939c43f3dd6e83\",\"title\":\"Explainable 3D Convolutional Neural Networks by Learning Temporal Transformations\",\"url\":\"https://www.semanticscholar.org/paper/6a670bb5caa48964329e482414939c43f3dd6e83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1809.01844\",\"authors\":[{\"authorId\":\"47786844\",\"name\":\"J. Li\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"589bdd7f68dea73564329589344c102b585ef15a\",\"title\":\"Unsupervised Learning of View-invariant Action Representations\",\"url\":\"https://www.semanticscholar.org/paper/589bdd7f68dea73564329589344c102b585ef15a\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1803.11064\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"3072326\",\"name\":\"S. Sra\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"143750009\",\"name\":\"R. Hartley\"}],\"doi\":\"10.1109/CVPR.2018.00234\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"13d93feb5431eda200ac482b5230f51667c0146a\",\"title\":\"Non-linear Temporal Subspace Representations for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13d93feb5431eda200ac482b5230f51667c0146a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.14582\",\"authors\":[{\"authorId\":\"50079897\",\"name\":\"X. Li\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":\"1491073267\",\"name\":\"Zhipeng Zhou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/cvpr42600.2020.00117\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"title\":\"SmallBigNet: Integrating Core and Contextual Views for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/da9b802ea051ffb7ef2de0d8d1003944a60bf44c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2010.15675\",\"authors\":[{\"authorId\":\"1379934616\",\"name\":\"R. GnanaPraveen\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"},{\"authorId\":\"2180710\",\"name\":\"Patrick Cardinal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d0feb3f5d92a38f33a0190e0641efcedd497ec66\",\"title\":\"Deep DA for Ordinal Regression of Pain Intensity Estimation Using Weakly-Labeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/d0feb3f5d92a38f33a0190e0641efcedd497ec66\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.13158\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/cvpr42600.2020.00987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d57d0c8071378c26967fa428bf339193713b91a5\",\"title\":\"Learning Interactions and Relationships Between Movie Characters\",\"url\":\"https://www.semanticscholar.org/paper/d57d0c8071378c26967fa428bf339193713b91a5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"144067957\",\"name\":\"K. Mao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"title\":\"Semantic-filtered Soft-Split-Aware video captioning with audio-augmented feature\",\"url\":\"https://www.semanticscholar.org/paper/fd9a6ff5f908a6e8e785eb0a1432a5c9da2c2192\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122346674\",\"name\":\"V. Radu\"},{\"authorId\":\"151496716\",\"name\":\"Maximilian Henne\"}],\"doi\":\"10.1145/3351242\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcdebbe036f673b9da283af89d68d048b3540132\",\"title\":\"Vision2Sensor: Knowledge Transfer Across Sensing Modalities for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dcdebbe036f673b9da283af89d68d048b3540132\",\"venue\":\"Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.\",\"year\":2019},{\"arxivId\":\"1909.13474\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICMLA.2019.00036\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"title\":\"Spatio-Temporal FAST 3D Convolutions for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":\"10.1109/ICASSP.2019.8683035\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"52373cd152e2afdc7e8c75025b2c9a02509bb2c1\",\"title\":\"Deep Temporal Pyramid Design for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/52373cd152e2afdc7e8c75025b2c9a02509bb2c1\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1810.00207\",\"authors\":[{\"authorId\":\"7868449\",\"name\":\"Yongyi Tang\"},{\"authorId\":\"46447561\",\"name\":\"X. Zhang\"},{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-11018-5_20\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"title\":\"Non-local NetVLAD Encoding for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/507f398b79e94a1ebde61c0a854c3954e7bb3d33\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108646857\",\"name\":\"Dan Liu\"},{\"authorId\":\"152994876\",\"name\":\"Yunfeng Ji\"},{\"authorId\":\"144560368\",\"name\":\"M. Ye\"},{\"authorId\":\"46636010\",\"name\":\"Y. Gan\"},{\"authorId\":\"1739414\",\"name\":\"Jianwei Zhang\"}],\"doi\":\"10.1109/ACCESS.2020.2983355\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"title\":\"An Improved Attention-Based Spatiotemporal-Stream Model for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b89aed9287493cc57eb0dcd58eccec4ec0c981b6\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1911.08548\",\"authors\":[{\"authorId\":\"47792983\",\"name\":\"J. Ma\"},{\"authorId\":\"46227885\",\"name\":\"Satya Krishna Gorti\"},{\"authorId\":\"1765951\",\"name\":\"Maksims Volkovs\"},{\"authorId\":\"93169948\",\"name\":\"Ilya Stanevich\"},{\"authorId\":\"46546800\",\"name\":\"Guangwei Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8283f38f9e027a38c454957297d4a685b453575\",\"title\":\"Cross-Class Relevance Learning for Temporal Concept Localization\",\"url\":\"https://www.semanticscholar.org/paper/d8283f38f9e027a38c454957297d4a685b453575\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"51458977\",\"name\":\"J. Xu\"},{\"authorId\":\"1429834069\",\"name\":\"Canqian Yang\"},{\"authorId\":\"7314697\",\"name\":\"Guozheng Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1881b72a1d5abc9d016e88203e8bb04b831a4586\",\"title\":\"Reinventing 2D Convolutions for 3D Medical Images\",\"url\":\"https://www.semanticscholar.org/paper/1881b72a1d5abc9d016e88203e8bb04b831a4586\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.09542\",\"authors\":[{\"authorId\":\"2035597\",\"name\":\"N. Yudistira\"},{\"authorId\":\"145263742\",\"name\":\"M. S. Kavitha\"},{\"authorId\":\"152802242\",\"name\":\"T. Kurita\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"title\":\"Weakly-Supervised Action Localization and Action Recognition using Global-Local Attention of 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/64eda1c73af5f24c43e60727fd3aa1e198f27ff7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.07355\",\"authors\":[{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"title\":\"TinyVIRAT: Low-resolution Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f00fcda3127dc697fd2aa30569eafa5e1b0c2f8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1557269924\",\"name\":\"Tao Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1016/j.patcog.2020.107477\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"156fae773062f7ef0d4e9c4bb141cfae46e8ba85\",\"title\":\"Play and rewind: Context-aware video temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/156fae773062f7ef0d4e9c4bb141cfae46e8ba85\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2005.03684\",\"authors\":[{\"authorId\":\"153825694\",\"name\":\"D. Fried\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"1685771\",\"name\":\"P. Blunsom\"},{\"authorId\":\"1745899\",\"name\":\"Chris Dyer\"},{\"authorId\":\"152361825\",\"name\":\"S. Clark\"},{\"authorId\":\"3208081\",\"name\":\"A. Nematzadeh\"}],\"doi\":\"10.18653/v1/2020.acl-main.231\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23edba4188492f39a7aefebbd7267a6a8d9ddb74\",\"title\":\"Learning to Segment Actions from Observation and Narration\",\"url\":\"https://www.semanticscholar.org/paper/23edba4188492f39a7aefebbd7267a6a8d9ddb74\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2010.09211\",\"authors\":[{\"authorId\":\"40930518\",\"name\":\"Nakul Agarwal\"},{\"authorId\":\"73365400\",\"name\":\"Y. Chen\"},{\"authorId\":\"1387979739\",\"name\":\"Behzad Dariush\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"017484d832e0b217897adc889f9becbf1f8f3bcb\",\"title\":\"Unsupervised Domain Adaptation for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/017484d832e0b217897adc889f9becbf1f8f3bcb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01432\",\"authors\":[{\"authorId\":\"13657788\",\"name\":\"Y. Bai\"},{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"8230405\",\"name\":\"Y. Tong\"},{\"authorId\":\"46285717\",\"name\":\"Y. Yang\"},{\"authorId\":\"150270503\",\"name\":\"Qiyue Liu\"},{\"authorId\":\"48211752\",\"name\":\"Jun-Hui Liu\"}],\"doi\":\"10.1007/978-3-030-58604-1_8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab87795177c3d53913cc91771162420ef75671e3\",\"title\":\"Boundary Content Graph Neural Network for Temporal Action Proposal Generation\",\"url\":\"https://www.semanticscholar.org/paper/ab87795177c3d53913cc91771162420ef75671e3\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"2000194881\",\"name\":\"R. Zhang\"},{\"authorId\":\"47530538\",\"name\":\"G. Han\"},{\"authorId\":\"144202010\",\"name\":\"Ning Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1016/J.SYSARC.2020.101882\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ecda34f73c1512466b6441022f127be279a2288\",\"title\":\"Video action recognition with visual privacy protection based on compressed sensing\",\"url\":\"https://www.semanticscholar.org/paper/5ecda34f73c1512466b6441022f127be279a2288\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.09215\",\"authors\":[{\"authorId\":\"50218817\",\"name\":\"Zhengwei Wang\"},{\"authorId\":\"1486411393\",\"name\":\"Qi She\"},{\"authorId\":\"25054465\",\"name\":\"Tejo Chalasani\"},{\"authorId\":\"118065745\",\"name\":\"A. Smolic\"}],\"doi\":\"10.1109/CVPRW50498.2020.00123\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"title\":\"CatNet: Class Incremental 3D ConvNets for Lifelong Egocentric Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/190999dcc6895c0218961a11ae3ef4d5d03ae5f0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9127897\",\"name\":\"A. Sasithradevi\"},{\"authorId\":\"2010132\",\"name\":\"S. Roomi\"}],\"doi\":\"10.1016/j.patcog.2019.107099\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96e1bde6095d0db64ff46c689fda3d27ce0c02c8\",\"title\":\"Video classification and retrieval through spatio-temporal Radon features\",\"url\":\"https://www.semanticscholar.org/paper/96e1bde6095d0db64ff46c689fda3d27ce0c02c8\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":\"1811.02765\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33018965\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"title\":\"Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1904.02811\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"}],\"doi\":\"10.1109/ICCV.2019.00565\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f4852f5385d60e8870e30db5c65392d120e58574\",\"title\":\"Video Classification With Channel-Separated Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/f4852f5385d60e8870e30db5c65392d120e58574\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70147929\",\"name\":\"H. Yang\"},{\"authorId\":\"18997752\",\"name\":\"Jun Zhang\"},{\"authorId\":\"2721485\",\"name\":\"Shuohao Li\"},{\"authorId\":\"3249639\",\"name\":\"Tingjin Luo\"}],\"doi\":\"10.3233/JIFS-18209\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"title\":\"Bi-direction hierarchical LSTM with spatial-temporal attention for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c6d8c084b395804b68ffbec2724a91b1cf8e269b\",\"venue\":\"J. Intell. Fuzzy Syst.\",\"year\":2019},{\"arxivId\":\"1812.01053\",\"authors\":[{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"47285696\",\"name\":\"Oscar Koller\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"title\":\"MS-ASL: A Large-Scale Data Set and Benchmark for Understanding American Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/310a8e2c9f2650fa2e44fdf0d82d11c0cb3e387e\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144692146\",\"name\":\"Ming Tong\"},{\"authorId\":\"27746265\",\"name\":\"Mengao Zhao\"},{\"authorId\":\"5442167\",\"name\":\"Yiran Chen\"},{\"authorId\":\"49527719\",\"name\":\"Houyi Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"title\":\"D3-LND: A two-stream framework with discriminant deep descriptor, linear CMDT and nonlinear KCMDT descriptors for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d98642db8d4fc5330190c7832b86e8bbf85b46ca\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1802.07898\",\"authors\":[{\"authorId\":\"9943923\",\"name\":\"Fabien Baradel\"},{\"authorId\":\"144899680\",\"name\":\"C. Wolf\"},{\"authorId\":\"1723242\",\"name\":\"J. Mille\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"}],\"doi\":\"10.1109/CVPR.2018.00056\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab45ab887b7c1379bba4179579568296448d16d6\",\"title\":\"Glimpse Clouds: Human Activity Recognition from Unstructured Feature Points\",\"url\":\"https://www.semanticscholar.org/paper/ab45ab887b7c1379bba4179579568296448d16d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35041003\",\"name\":\"Lichao Mou\"},{\"authorId\":\"51151222\",\"name\":\"Yuansheng Hua\"},{\"authorId\":\"2038525606\",\"name\":\"Pu Jin\"},{\"authorId\":\"46875441\",\"name\":\"X. X. Zhu\"}],\"doi\":\"10.1109/MGRS.2020.3005751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6770c2a1d5777c1bf4c266485deb3440d8f32c2\",\"title\":\"ERA: A Data Set and Deep Learning Benchmark for Event Recognition in Aerial Videos [Software and Data Sets]\",\"url\":\"https://www.semanticscholar.org/paper/f6770c2a1d5777c1bf4c266485deb3440d8f32c2\",\"venue\":\"IEEE Geoscience and Remote Sensing Magazine\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2007311898\",\"name\":\"Yangyang Qiao\"},{\"authorId\":\"2007310586\",\"name\":\"Whenhua Cui\"},{\"authorId\":\"1838022\",\"name\":\"Tianwei Shi\"}],\"doi\":\"10.1109/ACCESS.2020.3032533\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2a19004227240cd365422eaa00b589469897a3d7\",\"title\":\"LaM-2SRN: A Method Which Can Enhance Local Features and Detect Moving Objects for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2a19004227240cd365422eaa00b589469897a3d7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88762202\",\"name\":\"J. Li\"},{\"authorId\":\"1888867\",\"name\":\"X. Jiang\"},{\"authorId\":\"3307728\",\"name\":\"T. Sun\"},{\"authorId\":\"2876147\",\"name\":\"K. Xu\"}],\"doi\":\"10.1109/AVSS.2019.8909883\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8a029b5380133aa2aee82064182683e5db81eeeb\",\"title\":\"Efficient Violence Detection Using 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8a029b5380133aa2aee82064182683e5db81eeeb\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"2086066\",\"name\":\"B. Huet\"}],\"doi\":\"10.1145/3347449.3357484\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"989730c00381805543baa470a2d6490cc5354a13\",\"title\":\"L-STAP: Learned Spatio-Temporal Adaptive Pooling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/989730c00381805543baa470a2d6490cc5354a13\",\"venue\":\"AI4TV@MM\",\"year\":2019},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.04950\",\"authors\":[{\"authorId\":\"34246012\",\"name\":\"Ryan Szeto\"},{\"authorId\":\"1382637019\",\"name\":\"Mostafa El-Khamy\"},{\"authorId\":\"35462690\",\"name\":\"Jungwon Lee\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0d52448d649ce5d35189abdeecdc62db647b4246\",\"title\":\"HyperCon: Image-To-Video Model Transfer for Video-To-Video Translation Tasks\",\"url\":\"https://www.semanticscholar.org/paper/0d52448d649ce5d35189abdeecdc62db647b4246\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.12743\",\"authors\":[{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"66370228\",\"name\":\"J. Yoo\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"15460136\",\"name\":\"Jianqiu Zheng\"}],\"doi\":\"10.1109/ICCV.2019.00642\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89917e19175eb4f3bca02e0bace8f99d6910b054\",\"title\":\"Temporal Attentive Alignment for Large-Scale Video Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/89917e19175eb4f3bca02e0bace8f99d6910b054\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3705643\",\"name\":\"H. Wang\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"1410309633\",\"name\":\"Fan Ma\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6895\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"491bfcc0dbcca04b4983d2716e9125b76a45ede2\",\"title\":\"Context Modulated Dynamic Networks for Actor and Action Video Segmentation with Language Queries\",\"url\":\"https://www.semanticscholar.org/paper/491bfcc0dbcca04b4983d2716e9125b76a45ede2\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519286161\",\"name\":\"Junjie Wang\"},{\"authorId\":\"51311907\",\"name\":\"Xueyan Wen\"}],\"doi\":\"10.1088/1742-6596/1651/1/012193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"title\":\"A Spatio-Temporal Attention Convolution Block for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/61a78b9873ca5a0ce47eea5f4c1115dce7658d1e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.10869\",\"authors\":[{\"authorId\":\"1405226912\",\"name\":\"D. Fern\\u00e1ndez-Llorca\"},{\"authorId\":\"24057066\",\"name\":\"Mahdi Biparva\"},{\"authorId\":\"1905637731\",\"name\":\"Rub'en Izquierdo-Gonzalo\"},{\"authorId\":\"1727853\",\"name\":\"John K. Tsotsos\"}],\"doi\":\"10.1109/ITSC45102.2020.9294326\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"184ac4dcd301ff465a2af83da7680f276647f2f1\",\"title\":\"Two-Stream Networks for Lane-Change Prediction of Surrounding Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/184ac4dcd301ff465a2af83da7680f276647f2f1\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"2012.00781\",\"authors\":[{\"authorId\":\"2030527072\",\"name\":\"Anirudh Tunga\"},{\"authorId\":\"71070791\",\"name\":\"Sai Vidyaranya Nuthalapati\"},{\"authorId\":\"1768610\",\"name\":\"J. Wachs\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e0d7289231dc4b1cd822186690b426810da620b\",\"title\":\"Pose-based Sign Language Recognition using GCN and BERT\",\"url\":\"https://www.semanticscholar.org/paper/2e0d7289231dc4b1cd822186690b426810da620b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3379055\",\"name\":\"M. Hossain\"},{\"authorId\":\"8112875\",\"name\":\"K. Cannons\"},{\"authorId\":\"40284986\",\"name\":\"D. Jang\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"},{\"authorId\":\"47047818\",\"name\":\"Zhan Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"64c37e58d706ce429e379ed05097762ed737a87a\",\"title\":\"Video-Based Crowd Counting Using a Multi-Scale Optical Flow Pyramid Network\",\"url\":\"https://www.semanticscholar.org/paper/64c37e58d706ce429e379ed05097762ed737a87a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.11760\",\"authors\":[{\"authorId\":\"24040986\",\"name\":\"Gabriel Huang\"},{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"2062703\",\"name\":\"Z. Zhu\"},{\"authorId\":\"66193113\",\"name\":\"C. Rivera\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bacd2f2a70d756f108ad889b6bcddc79cc1ce51\",\"title\":\"Multimodal Pretraining for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2bacd2f2a70d756f108ad889b6bcddc79cc1ce51\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.04515\",\"authors\":[{\"authorId\":\"3234247\",\"name\":\"Senthil Purushwalkam\"},{\"authorId\":\"1391076188\",\"name\":\"Tian Ye\"},{\"authorId\":\"47924870\",\"name\":\"Saurabh Gupta\"},{\"authorId\":null,\"name\":\"Abhinav Gupta\"}],\"doi\":\"10.1007/978-3-030-58574-7_16\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e3a6c70799ee375e4b6035f59236677439c41a5\",\"title\":\"Aligning Videos in Space and Time\",\"url\":\"https://www.semanticscholar.org/paper/9e3a6c70799ee375e4b6035f59236677439c41a5\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"},{\"authorId\":\"46522622\",\"name\":\"X. Liu\"},{\"authorId\":\"143983679\",\"name\":\"Gao Huang\"},{\"authorId\":\"1397156292\",\"name\":\"Hong Qiao\"},{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"143949784\",\"name\":\"Dong Jiang\"},{\"authorId\":\"49425435\",\"name\":\"Aibin Zhang\"},{\"authorId\":\"40959393\",\"name\":\"Yang Liu\"},{\"authorId\":\"145168166\",\"name\":\"G. Guo\"}],\"doi\":\"10.1016/j.neucom.2020.06.108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0862ba6326c0667fe909828a5af05a2c809f4b7b\",\"title\":\"FSD-10: A fine-grained classification dataset for figure skating\",\"url\":\"https://www.semanticscholar.org/paper/0862ba6326c0667fe909828a5af05a2c809f4b7b\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2001.05661\",\"authors\":[{\"authorId\":\"143657833\",\"name\":\"Li Tao\"},{\"authorId\":\"1524733293\",\"name\":\"Xueting Wang\"},{\"authorId\":\"145572095\",\"name\":\"T. Yamasaki\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"18726788e8a74aed4420745fc420dddd3950e1c6\",\"title\":\"Rethinking Motion Representation: Residual Frames with 3D ConvNets for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/18726788e8a74aed4420745fc420dddd3950e1c6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03800\",\"authors\":[{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":\"1486442460\",\"name\":\"Tianjian Meng\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"},{\"authorId\":\"3154495\",\"name\":\"H. Wang\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"1387716705\",\"name\":\"Yin Cui\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"title\":\"Spatiotemporal Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/1f3a9a431dc5bf813455ac89df5c0a4e747bc553\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.13594\",\"authors\":[{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"152567560\",\"name\":\"D. Ross\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/cvpr42600.2020.01033\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"title\":\"Speech2Action: Cross-Modal Supervision for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee3ba7ebf3a0116d17857c53fe10d98ae3a586d9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2006.14613\",\"authors\":[{\"authorId\":\"14258597\",\"name\":\"A. Jabri\"},{\"authorId\":\"144956994\",\"name\":\"Andrew Owens\"},{\"authorId\":\"1763086\",\"name\":\"Alexei A. Efros\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c78b00f2abbf7523a860e717f767b0bb8f860143\",\"title\":\"Space-Time Correspondence as a Contrastive Random Walk\",\"url\":\"https://www.semanticscholar.org/paper/c78b00f2abbf7523a860e717f767b0bb8f860143\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47513708\",\"name\":\"Junjie Huang\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"143986385\",\"name\":\"G. Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1aa7bbb799f0317874caa90ba78b3018f1d98f2\",\"title\":\"How to Train Your Robust Human Pose Estimator: Pay Attention to the Constraint Cue\",\"url\":\"https://www.semanticscholar.org/paper/e1aa7bbb799f0317874caa90ba78b3018f1d98f2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02406\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"46656552\",\"name\":\"Mohammad Asif Khan\"},{\"authorId\":\"2785141\",\"name\":\"H. Farazi\"},{\"authorId\":\"1699019\",\"name\":\"Sven Behnke\"}],\"doi\":\"10.1007/978-3-030-35699-6_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"546a9dc73e7f2991a1172ed422cc24d835313f62\",\"title\":\"Utilizing Temporal Information in Deep Convolutional Network for Efficient Soccer Ball Detection and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/546a9dc73e7f2991a1172ed422cc24d835313f62\",\"venue\":\"RoboCup\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83145882\",\"name\":\"J. You\"},{\"authorId\":\"144388019\",\"name\":\"P. Shi\"},{\"authorId\":\"29348697\",\"name\":\"Xiaojie Bao\"}],\"doi\":\"10.1109/ITOEC.2018.8740606\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7f41e30a97b7ea505de56630755fde312d3752c5\",\"title\":\"Multi-stream I3D Network for Fine-grained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f41e30a97b7ea505de56630755fde312d3752c5\",\"venue\":\"2018 IEEE 4th Information Technology and Mechatronics Engineering Conference (ITOEC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390925314\",\"name\":\"Yue Yao\"},{\"authorId\":\"49981081\",\"name\":\"T. Wang\"},{\"authorId\":\"150121597\",\"name\":\"Heming Du\"},{\"authorId\":\"144436089\",\"name\":\"L. Zheng\"},{\"authorId\":\"27011207\",\"name\":\"T. Gedeon\"}],\"doi\":\"10.1145/3340555.3356101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2fb5712d639658310c28785f74e6f7f8cf65630\",\"title\":\"Spotting Visual Keywords from Temporal Sliding Windows\",\"url\":\"https://www.semanticscholar.org/paper/d2fb5712d639658310c28785f74e6f7f8cf65630\",\"venue\":\"ICMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1476813805\",\"name\":\"M. Al-Naser\"},{\"authorId\":\"1836124\",\"name\":\"T. Niikura\"},{\"authorId\":\"144723875\",\"name\":\"S. Ahmed\"},{\"authorId\":\"1743276\",\"name\":\"H. Ohashi\"},{\"authorId\":\"35920106\",\"name\":\"T. Sato\"},{\"authorId\":\"1690288\",\"name\":\"M. Okada\"},{\"authorId\":\"153823664\",\"name\":\"K. Nakamura\"},{\"authorId\":\"153402269\",\"name\":\"Andreas Dengel\"}],\"doi\":\"10.1007/978-3-030-39098-3_15\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1fd5ec17c5c984425555c2758f1b5156359c44e5\",\"title\":\"Quantifying Quality of Actions Using Wearable Sensor\",\"url\":\"https://www.semanticscholar.org/paper/1fd5ec17c5c984425555c2758f1b5156359c44e5\",\"venue\":\"AALTD@PKDD/ECML\",\"year\":2019},{\"arxivId\":\"1904.04817\",\"authors\":[{\"authorId\":\"71712589\",\"name\":\"L. Courtney\"},{\"authorId\":\"40568918\",\"name\":\"R. Sreenivas\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3034c12a9c5b27592a123216a0cfd79f955b0a0f\",\"title\":\"Learning from Videos with Deep Convolutional LSTM Networks\",\"url\":\"https://www.semanticscholar.org/paper/3034c12a9c5b27592a123216a0cfd79f955b0a0f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1692966\",\"name\":\"J. Choi\"},{\"authorId\":\"104810482\",\"name\":\"M. Larson\"},{\"authorId\":\"1452353442\",\"name\":\"Gerald Friedland\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"}],\"doi\":\"10.1109/BigMM.2019.00-48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7759d2df9310c44d2cb4da133b7035b9e83f33b0\",\"title\":\"From Intra-Modal to Inter-Modal Space: Multi-task Learning of Shared Representations for Cross-Modal Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/7759d2df9310c44d2cb4da133b7035b9e83f33b0\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":\"2011.07949\",\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"145592817\",\"name\":\"D. Huang\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"46550737\",\"name\":\"Xiang Long\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2336388131b3cb41eb44e927aeac10a1dabbedad\",\"title\":\"RSPNet: Relative Speed Perception for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/2336388131b3cb41eb44e927aeac10a1dabbedad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.06601\",\"authors\":[{\"authorId\":\"2195314\",\"name\":\"T. Wang\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"},{\"authorId\":\"2436356\",\"name\":\"Jun-Yan Zhu\"},{\"authorId\":\"47062069\",\"name\":\"Guilin Liu\"},{\"authorId\":\"29955511\",\"name\":\"A. Tao\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"},{\"authorId\":\"2301680\",\"name\":\"Bryan Catanzaro\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"title\":\"Video-to-Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/c5b55f410365bb889c25a9f0354f2b86ec61c4f0\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1811.10762\",\"authors\":[{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"2642913\",\"name\":\"A. Hoogs\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8d82091b1e817be4497fbe11c01ad473d99894c6\",\"title\":\"A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Video Forgery\",\"url\":\"https://www.semanticscholar.org/paper/8d82091b1e817be4497fbe11c01ad473d99894c6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1906.01012\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"3434584\",\"name\":\"Ahsan Iqbal\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"title\":\"Mining YouTube - A dataset for learning fine-grained action concepts from webly supervised video data\",\"url\":\"https://www.semanticscholar.org/paper/b0e31596fe23b8b6c99c1e51fd3d08dcd856d5ac\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1904.08916\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/CVPRW.2019.00298\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"077346a4336f2c1d8cb1f5edb42c6d4bcbedb850\",\"title\":\"Early Detection of Injuries in MLB Pitchers from Video\",\"url\":\"https://www.semanticscholar.org/paper/077346a4336f2c1d8cb1f5edb42c6d4bcbedb850\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9335567\",\"name\":\"A. Elaoud\"},{\"authorId\":\"1747242\",\"name\":\"W. Barhoumi\"},{\"authorId\":\"2641251\",\"name\":\"H. Drira\"},{\"authorId\":\"1684187\",\"name\":\"E. Zagrouba\"}],\"doi\":\"10.1007/978-3-030-41590-7_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1302b862cf6244ab3b8f0e92bd578525d398b625\",\"title\":\"Modeling Trajectories for 3D Motion Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1302b862cf6244ab3b8f0e92bd578525d398b625\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"2011.06958\",\"authors\":[{\"authorId\":\"1632971845\",\"name\":\"Guillaume Vaudaux-Ruth\"},{\"authorId\":\"1403862742\",\"name\":\"Adrien Chan-Hon-Tong\"},{\"authorId\":\"1787641\",\"name\":\"C. Achard\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4545cdb909f2be23ce6542defef6091912729648\",\"title\":\"SALAD: Self-Assessment Learning for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/4545cdb909f2be23ce6542defef6091912729648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123756463\",\"name\":\"Bibrat Ranjan Pradhan\"},{\"authorId\":\"121456805\",\"name\":\"Yeshwanth Bethi\"},{\"authorId\":\"119885109\",\"name\":\"Sathyaprakash Narayanan\"},{\"authorId\":\"37287044\",\"name\":\"A. Chakraborty\"},{\"authorId\":\"1807880\",\"name\":\"C. Thakur\"}],\"doi\":\"10.1109/ISCAS.2019.8702581\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b214d16c338dde0b626a34aa9509c248ba2efbdc\",\"title\":\"N-HAR: A Neuromorphic Event-Based Human Activity Recognition System using Memory Surfaces\",\"url\":\"https://www.semanticscholar.org/paper/b214d16c338dde0b626a34aa9509c248ba2efbdc\",\"venue\":\"2019 IEEE International Symposium on Circuits and Systems (ISCAS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491240780\",\"name\":\"Z. Shi\"},{\"authorId\":\"144962375\",\"name\":\"Cheng Guan\"},{\"authorId\":\"1491233401\",\"name\":\"Liangjie Cao\"},{\"authorId\":\"1632356255\",\"name\":\"Qianqian Li\"},{\"authorId\":\"1993660232\",\"name\":\"Ju Liang\"},{\"authorId\":\"29344734\",\"name\":\"Zhaorui Gu\"},{\"authorId\":\"2336297\",\"name\":\"Haiyong Zheng\"},{\"authorId\":\"1470709309\",\"name\":\"Bing Zheng\"}],\"doi\":\"10.1007/978-3-030-58539-6_23\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"title\":\"CoTeRe-Net: Discovering Collaborative Ternary Relations in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c826e169f505f6fda0872d0a3e1e156e15b5111e\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2001.01083\",\"authors\":[{\"authorId\":\"51991145\",\"name\":\"Naina Dhingra\"},{\"authorId\":\"143717147\",\"name\":\"A. Kunz\"}],\"doi\":\"10.1109/3DV.2019.00061\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"title\":\"Res3ATN - Deep 3D Residual Attention Network for Hand Gesture Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b5e3962f8771a86ea89692fb2a6ddd69b17425b7\",\"venue\":\"2019 International Conference on 3D Vision (3DV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"30477181\",\"name\":\"Yie-Tarng Chen\"},{\"authorId\":\"122315920\",\"name\":\"Wen-Hsien Fang\"}],\"doi\":\"10.1007/978-3-030-58452-8_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"33f62e6f851da560037f1ed008d2eb51bb80f062\",\"title\":\"Empowering Relational Network by Self-attention Augmented Conditional Random Fields for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/33f62e6f851da560037f1ed008d2eb51bb80f062\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1481012996\",\"name\":\"Evin Pinar \\u00d6rnek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63998c9ef7bffaf4a92619af32eeac95320d0b1e\",\"title\":\"Zero-Shot Activity Recognition with Videos\",\"url\":\"https://www.semanticscholar.org/paper/63998c9ef7bffaf4a92619af32eeac95320d0b1e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2720733\",\"name\":\"Wangli Hao\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"04d27bbbc875bd8fe52521112841d47b21950e7c\",\"title\":\"Spatiotemporal distilled dense-connectivity network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/04d27bbbc875bd8fe52521112841d47b21950e7c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICASSP.2019.8683606\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"750c885ee644cb19d89f52ab31639f56254273a2\",\"title\":\"Neuromorphic Vision Sensing for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/750c885ee644cb19d89f52ab31639f56254273a2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"2007.09049\",\"authors\":[{\"authorId\":\"1810689822\",\"name\":\"Ganchao Tan\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"152808542\",\"name\":\"Meng Wang\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"}],\"doi\":\"10.24963/ijcai.2020/104\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a7e8aeca681e6409aa73ab0f70ff9e6fb891d071\",\"title\":\"Learning to Discretely Compose Reasoning Module Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7e8aeca681e6409aa73ab0f70ff9e6fb891d071\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116998585\",\"name\":\"Petr Byvshev\"},{\"authorId\":\"40892875\",\"name\":\"Pascal Mettes\"},{\"authorId\":\"144755236\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1145/3372278.3390675\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3b7340a8490b8de31bb4106b37e957f3db476bef\",\"title\":\"Heterogeneous Non-Local Fusion for Multimodal Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3b7340a8490b8de31bb4106b37e957f3db476bef\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145309464\",\"name\":\"Min Jiang\"},{\"authorId\":\"51010977\",\"name\":\"N. Pan\"},{\"authorId\":\"1644912978\",\"name\":\"Jun Kong\"}],\"doi\":\"10.1016/j.jvcir.2020.102846\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"title\":\"Spatial-temporal saliency action mask attention network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/1378199d4242d3d8699bf79d13cfcbbdefea9120\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2020},{\"arxivId\":\"2009.14639\",\"authors\":[{\"authorId\":\"1976000468\",\"name\":\"Okan Kopuklu\"},{\"authorId\":\"114991183\",\"name\":\"Stefan Hormann\"},{\"authorId\":\"32240536\",\"name\":\"Fabian Herzog\"},{\"authorId\":\"2277308\",\"name\":\"Hakan Cevikalp\"},{\"authorId\":\"46343645\",\"name\":\"G. Rigoll\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"title\":\"Dissected 3D CNNs: Temporal Skip Connections for Efficient Online Video Processing\",\"url\":\"https://www.semanticscholar.org/paper/d197d0ab852c20122ffb1833fb29199ca77ce9bb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11365\",\"authors\":[{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145879750\",\"name\":\"Manisha Verma\"},{\"authorId\":\"1789677\",\"name\":\"Yuta Nakashima\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4914a205aa1ddeaae3c86a449c69703c89484f54\",\"title\":\"Depthwise Spatio-Temporal STFT Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4914a205aa1ddeaae3c86a449c69703c89484f54\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41c21f12f6896c458004f26b1fd704f4058aaac1\",\"title\":\"CV-C3D: Action Recognition on Compressed Videos with Convolutional 3D Networks\",\"url\":\"https://www.semanticscholar.org/paper/41c21f12f6896c458004f26b1fd704f4058aaac1\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"71caf2f74e94cbb1c7fb3250e083a4d6924fb30e\",\"title\":\"PicSOM and EURECOM Experiments in TRECVID 2019 Pre-workshop draft \\u2013 Revision : 0 . 9\",\"url\":\"https://www.semanticscholar.org/paper/71caf2f74e94cbb1c7fb3250e083a4d6924fb30e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.14266\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/cvpr42600.2020.00058\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"title\":\"SCT: Set Constrained Temporal Transformer for Set Supervised Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/e1e3a36644d71bf1e8a09ad943c7a1bbb65ae73e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c97774191be232678a45d343a25fcc0c96c065e7\",\"title\":\"Co-Training of Audio and Video Representations from Self-Supervised Temporal Synchronization\",\"url\":\"https://www.semanticscholar.org/paper/c97774191be232678a45d343a25fcc0c96c065e7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144130711\",\"name\":\"C. Lin\"},{\"authorId\":\"2003807524\",\"name\":\"Mengxiang Lin\"},{\"authorId\":\"2003808280\",\"name\":\"Suhui Yang\"}],\"doi\":\"10.1109/ACCESS.2020.3032430\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"25db1ba302821f83040021e164e34d323354b154\",\"title\":\"SOPNet Method for the Fine-Grained Measurement and Prediction of Precipitation Intensity Using Outdoor Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/25db1ba302821f83040021e164e34d323354b154\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3294647\",\"name\":\"H. Chen\"},{\"authorId\":\"2069934\",\"name\":\"Shyi-Chyi Cheng\"},{\"authorId\":\"40513660\",\"name\":\"Chin-Chun Chang\"}],\"doi\":\"10.1117/12.2566273\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9dd860562a0ac6538358699ba63e0945bdd1d85e\",\"title\":\"Semantic scene modeling for aquaculture management using an autonomous drone\",\"url\":\"https://www.semanticscholar.org/paper/9dd860562a0ac6538358699ba63e0945bdd1d85e\",\"venue\":\"Other Conferences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47557746\",\"name\":\"Y. Chen\"},{\"authorId\":\"2175693\",\"name\":\"He-Fei Ling\"},{\"authorId\":\"1722881\",\"name\":\"Jiazhong Chen\"},{\"authorId\":\"152318075\",\"name\":\"Lei Wu\"},{\"authorId\":\"1753219181\",\"name\":\"Yuxuan Shi\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207404\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e2807495123a402bee172b9697f3a98a2351d134\",\"title\":\"Lightweight Action Recognition with Sequence-Specific Global Context\",\"url\":\"https://www.semanticscholar.org/paper/e2807495123a402bee172b9697f3a98a2351d134\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98787367\",\"name\":\"Xianhe Wen\"},{\"authorId\":\"1705783\",\"name\":\"H. Chen\"},{\"authorId\":\"145867478\",\"name\":\"Qi Hong\"}],\"doi\":\"10.1109/CYBER46603.2019.9066597\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d7c504ee2331149e773f1afd322680fb94a40df\",\"title\":\"Human Assembly Task Recognition in Human-Robot Collaboration based on 3D CNN\",\"url\":\"https://www.semanticscholar.org/paper/1d7c504ee2331149e773f1afd322680fb94a40df\",\"venue\":\"2019 IEEE 9th Annual International Conference on CYBER Technology in Automation, Control, and Intelligent Systems (CYBER)\",\"year\":2019},{\"arxivId\":\"2004.00779\",\"authors\":[{\"authorId\":\"83500873\",\"name\":\"Myungsub Choi\"},{\"authorId\":\"9535762\",\"name\":\"Janghoon Choi\"},{\"authorId\":\"148009160\",\"name\":\"Sungyong Baik\"},{\"authorId\":\"40592441\",\"name\":\"T. Kim\"},{\"authorId\":\"2135837\",\"name\":\"Kyoung Mu Lee\"}],\"doi\":\"10.1109/cvpr42600.2020.00946\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"title\":\"Scene-Adaptive Video Frame Interpolation via Meta-Learning\",\"url\":\"https://www.semanticscholar.org/paper/45e87cea5afe99417ec48bd67555ce8a6213e8f8\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72557716\",\"name\":\"Song Liu\"},{\"authorId\":\"1709381241\",\"name\":\"Qiaolin He\"},{\"authorId\":\"48708884\",\"name\":\"Z. Wang\"},{\"authorId\":\"153005923\",\"name\":\"Y. Pu\"},{\"authorId\":\"4763857\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICCCBDA49378.2020.9095594\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"title\":\"Irregular Action Recognition in Court with 3D Residual Network\",\"url\":\"https://www.semanticscholar.org/paper/2f1cb50a5ff56f95e43b1fcc3dffe1907e0523d5\",\"venue\":\"2020 IEEE 5th International Conference on Cloud Computing and Big Data Analytics (ICCCBDA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47876379\",\"name\":\"J. Wu\"},{\"authorId\":\"1846644339\",\"name\":\"Yingying Li\"},{\"authorId\":\"47528427\",\"name\":\"W. Zhang\"},{\"authorId\":\"145831603\",\"name\":\"Yi Wu\"},{\"authorId\":\"145681035\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2316745\",\"name\":\"H. Zhang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"},{\"authorId\":\"32914175\",\"name\":\"Errui Ding\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"}],\"doi\":\"10.1145/3394171.3416279\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ae5893a65394d45498aa4c0eeca587bbe772201\",\"title\":\"Modularized Framework with Category-Sensitive Abnormal Filter for City Anomaly Detection\",\"url\":\"https://www.semanticscholar.org/paper/7ae5893a65394d45498aa4c0eeca587bbe772201\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.08452\",\"authors\":[{\"authorId\":\"50841913\",\"name\":\"Asif Shahriyar Sushmit\"},{\"authorId\":\"10458138\",\"name\":\"P. Ghosh\"},{\"authorId\":\"1885311407\",\"name\":\"Md.Abrar Istiak\"},{\"authorId\":\"1742267771\",\"name\":\"Nayeeb Rashid\"},{\"authorId\":\"1742267920\",\"name\":\"Ahsan Habib Akash\"},{\"authorId\":\"144782474\",\"name\":\"T. Hasan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"title\":\"SegCodeNet: Color-Coded Segmentation Masks for Activity Detection from Wearable Cameras\",\"url\":\"https://www.semanticscholar.org/paper/d4953e2a564f68bc7eccd8d1af12da3c2c5bbf7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144578530\",\"name\":\"Vishal Anand\"},{\"authorId\":\"1993691002\",\"name\":\"Raksha Ramesh\"},{\"authorId\":\"1993659768\",\"name\":\"Ziyin Wang\"},{\"authorId\":\"1993645840\",\"name\":\"Yijing Feng\"},{\"authorId\":\"1993660453\",\"name\":\"Jiana Feng\"},{\"authorId\":\"1993695696\",\"name\":\"Wenfeng Lyu\"},{\"authorId\":\"1993695801\",\"name\":\"Tianle Zhu\"},{\"authorId\":\"1993660605\",\"name\":\"Serena Yuan\"},{\"authorId\":\"153903099\",\"name\":\"Ching-Yung Lin\"}],\"doi\":\"10.1145/3394171.3416305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"95327ce60abc25ea530a31d29a09a4be62d0e16f\",\"title\":\"Story Semantic Relationships from Multimodal Cognitions\",\"url\":\"https://www.semanticscholar.org/paper/95327ce60abc25ea530a31d29a09a4be62d0e16f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ACCESS.2020.3025931\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"title\":\"Multi-Label Multi-Class Action Recognition With Deep Spatio-Temporal Layers Based on Temporal Gaussian Mixtures\",\"url\":\"https://www.semanticscholar.org/paper/0ef9affa9c633e1c2713cef266f246c4a0a23821\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2003.02692\",\"authors\":[{\"authorId\":\"12888106\",\"name\":\"H. Cho\"},{\"authorId\":\"40152520\",\"name\":\"Tae-Hoon Kim\"},{\"authorId\":\"145917158\",\"name\":\"H. J. Chang\"},{\"authorId\":\"34600044\",\"name\":\"Wonjun Hwang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90e185b5011a11fba9dea8db9136e4048b3728ec\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning Using Variable Playback Speed Prediction\",\"url\":\"https://www.semanticscholar.org/paper/90e185b5011a11fba9dea8db9136e4048b3728ec\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.09422\",\"authors\":[{\"authorId\":\"50065546\",\"name\":\"W. Price\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00173\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"title\":\"Retro-Actions: Learning 'Close' by Time-Reversing 'Open' Videos\",\"url\":\"https://www.semanticscholar.org/paper/3c0cf56b33fdca7529ec5bc308060e307c9ae1bc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727828\",\"name\":\"Yongyang Xu\"},{\"authorId\":\"30411581\",\"name\":\"Y. Feng\"},{\"authorId\":\"145980916\",\"name\":\"Zhong Xie\"},{\"authorId\":\"1491410471\",\"name\":\"Mingyu Xie\"},{\"authorId\":\"102577932\",\"name\":\"W. Luo\"}],\"doi\":\"10.1109/ACCESS.2020.3022407\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"title\":\"Action Recognition Using High Temporal Resolution 3D Neural Network Based on Dilated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/b21c6a492e8330111ad19d9a708fb25a0c8eca7f\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.02442\",\"authors\":[{\"authorId\":\"115044425\",\"name\":\"Sho Maeoki\"},{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/CVPRW50498.2020.00484\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"title\":\"Interactive Video Retrieval with Dialog\",\"url\":\"https://www.semanticscholar.org/paper/1cb7549a77b7040b7e2ea63ce79065ab2064df59\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1904.04189\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/CVPR.2019.01234\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c4d6220fafa3b4b302edd28c5229041b80727e1\",\"title\":\"Unsupervised Learning of Action Classes With Continuous Temporal Embedding\",\"url\":\"https://www.semanticscholar.org/paper/5c4d6220fafa3b4b302edd28c5229041b80727e1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.08634\",\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/CVPR.2019.00804\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1aea7d20edfd40b0907249270a80842382d93964\",\"title\":\"DDLSTM: Dual-Domain LSTM for Cross-Dataset Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1aea7d20edfd40b0907249270a80842382d93964\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1804.06919\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"40943290\",\"name\":\"Nayan Singhal\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1007/978-3-030-01237-3_26\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"title\":\"Video Compression through Image Interpolation\",\"url\":\"https://www.semanticscholar.org/paper/e2ab15c1f84a5a5080e06129daf7b22c8990411f\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79891656\",\"name\":\"Kaibo Yao\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"}],\"doi\":\"10.1109/ACCESS.2018.2871733\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ed51ceb0a5a54932c1ef70c6193e6b2ff9f3360\",\"title\":\"A Cuboid Bi-Level Log Operator for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/9ed51ceb0a5a54932c1ef70c6193e6b2ff9f3360\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3420479\",\"name\":\"D. Moltisanti\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"title\":\"y 1 ? ? ? ? ? open jar scoop sugar ? ? ? ? ? ? ?\",\"url\":\"https://www.semanticscholar.org/paper/e1363237a3ddc9a1c9ab9180f09c5bb58df62887\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"145443186\",\"name\":\"T. Hori\"},{\"authorId\":\"1816785\",\"name\":\"G. Wichern\"},{\"authorId\":null,\"name\":\"Jue Wang\"},{\"authorId\":\"1747615\",\"name\":\"Teng-Yok Lee\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e561b60c6aea937f9d98ee336dde01abd1ff651\",\"title\":\"Multimodal Attention for Fusion of Audio and Spatiotemporal Features for Video Description\",\"url\":\"https://www.semanticscholar.org/paper/8e561b60c6aea937f9d98ee336dde01abd1ff651\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"656c001e91378f460c898a85b5019e367992b030\",\"title\":\"Trajectory Convolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/656c001e91378f460c898a85b5019e367992b030\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740612\",\"name\":\"C. Wu\"},{\"authorId\":\"50171534\",\"name\":\"Xiaojun Wu\"},{\"authorId\":\"47091894\",\"name\":\"J. Kittler\"}],\"doi\":\"10.1109/ICCVW.2019.00216\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"title\":\"Spatial Residual Layer and Dense Connection Block Enhanced Spatial Temporal Graph Convolutional Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d0678d9b06fa66786cc6213254820184d8ebfd2a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355010\",\"name\":\"Greg Casta\\u00f1\\u00f3n\"},{\"authorId\":\"2962929\",\"name\":\"Nathan Shnidman\"},{\"authorId\":\"50780334\",\"name\":\"Tim Anderson\"},{\"authorId\":\"152187759\",\"name\":\"Jeffrey Byrne\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"title\":\"Dataset Paper Videos Hours Classes Description Charades Hollywood in Homes : Crowdsourcing Data Collection for Activity Understanding 9848\",\"url\":\"https://www.semanticscholar.org/paper/aeea6a28ff7290e9e7d9188df569ad75e79788bc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2003.08042\",\"authors\":[{\"authorId\":\"66562585\",\"name\":\"Xu Li\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1568961008\",\"name\":\"Fengzong Lian\"},{\"authorId\":\"2705857\",\"name\":\"Zhanhui Kang\"},{\"authorId\":\"71563118\",\"name\":\"Jinjun Wang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"786a010cb738fe28bb44fcff790966a380c9da56\",\"title\":\"STH: Spatio-Temporal Hybrid Convolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/786a010cb738fe28bb44fcff790966a380c9da56\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1639344722\",\"name\":\"Junqing Miao\"},{\"authorId\":\"1791880\",\"name\":\"Hailun Xia\"},{\"authorId\":\"7801828\",\"name\":\"Zhimin Zeng\"}],\"doi\":\"10.1109/ICCC47050.2019.9064443\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3c6f5ee9b64bf6bd7557193665bc38b3e9a0ac1f\",\"title\":\"Exploiting Pose Mask Features For Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3c6f5ee9b64bf6bd7557193665bc38b3e9a0ac1f\",\"venue\":\"2019 IEEE 5th International Conference on Computer and Communications (ICCC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40647545\",\"name\":\"A. Saveliev\"},{\"authorId\":\"1654173982\",\"name\":\"Mikhail Uzdiaev\"},{\"authorId\":\"1654160653\",\"name\":\"Malov Dmitrii\"}],\"doi\":\"10.1109/DeSE.2019.00165\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"51c790640bb74eeb0af7187ec93e3af80905a53d\",\"title\":\"Aggressive Action Recognition Using 3D CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/51c790640bb74eeb0af7187ec93e3af80905a53d\",\"venue\":\"2019 12th International Conference on Developments in eSystems Engineering (DeSE)\",\"year\":2019},{\"arxivId\":\"1803.07179\",\"authors\":[{\"authorId\":\"14800230\",\"name\":\"J. Zang\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dd613000f7b2b6161548b1c1044ab46c7327a901\",\"title\":\"Attention-based Temporal Weighted Convolutional Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dd613000f7b2b6161548b1c1044ab46c7327a901\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"2007.09903\",\"authors\":[{\"authorId\":\"151257945\",\"name\":\"Xiangyang Mou\"},{\"authorId\":\"1824292863\",\"name\":\"Brandyn Sigouin\"},{\"authorId\":\"1824242400\",\"name\":\"Ian Steenstra\"},{\"authorId\":\"1563539653\",\"name\":\"Hui Su\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cb2782f61c964e9b207f34c5dd1cb367b0fc561\",\"title\":\"Multimodal Dialogue State Tracking By QA Approach with Data Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/8cb2782f61c964e9b207f34c5dd1cb367b0fc561\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.03597\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"46398631\",\"name\":\"Yunhui Liu\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/CVPR.2019.00413\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e\",\"title\":\"Self-Supervised Spatio-Temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics\",\"url\":\"https://www.semanticscholar.org/paper/eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"48624462\",\"name\":\"W. Li\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"}],\"doi\":\"10.1109/TMM.2018.2839534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"602412f61e8902052e6489e84a6f24ccc7407814\",\"title\":\"Fully Convolutional Network for Multiscale Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/602412f61e8902052e6489e84a6f24ccc7407814\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143829432\",\"name\":\"Ngoc Nguyen\"},{\"authorId\":\"89558801\",\"name\":\"Dau Phan\"},{\"authorId\":\"70045535\",\"name\":\"F. R. Lumbanraja\"},{\"authorId\":\"145020752\",\"name\":\"M. Faisal\"},{\"authorId\":\"72808308\",\"name\":\"B. Abapihi\"},{\"authorId\":\"34805720\",\"name\":\"Bedy Purnama\"},{\"authorId\":\"2289674\",\"name\":\"Mera Kartika Delimayanti\"},{\"authorId\":\"89895131\",\"name\":\"Kunti Robiatul Mahmudah\"},{\"authorId\":\"2242591\",\"name\":\"M. Kubo\"},{\"authorId\":\"1767800\",\"name\":\"K. Satou\"}],\"doi\":\"10.4236/JBISE.2019.122012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"482feebc7f9f7234abe889a2d2a25118df296413\",\"title\":\"Applying Deep Learning Models to Mouse Behavior Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482feebc7f9f7234abe889a2d2a25118df296413\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.06260\",\"authors\":[{\"authorId\":\"145112187\",\"name\":\"Cristian Rodriguez-Opazo\"},{\"authorId\":\"1389646918\",\"name\":\"Edison Marrese-Taylor\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"title\":\"DORi: Discovering Object Relationship for Moment Localization of a Natural-Language Query in Video\",\"url\":\"https://www.semanticscholar.org/paper/a7177ae93ed91f3bf34875205396ec97f0873bb7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993662230\",\"name\":\"Advaith Sridhar\"},{\"authorId\":\"1993699262\",\"name\":\"Rohith Gandhi Ganesan\"},{\"authorId\":\"38724234\",\"name\":\"Pratyush Kumar\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":\"10.1145/3394171.3413528\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd9642b9a64553e36184565f1d21a2fa43b41362\",\"title\":\"INCLUDE: A Large Scale Dataset for Indian Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd9642b9a64553e36184565f1d21a2fa43b41362\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1805.07550\",\"authors\":[{\"authorId\":\"3162023\",\"name\":\"Xiaokai Chen\"},{\"authorId\":\"144947766\",\"name\":\"Ke Gao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6dee5bb3ff1b44f160259fa57815fa980b05659\",\"title\":\"DenseImage Network: Video Spatial-Temporal Evolution Encoding and Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a6dee5bb3ff1b44f160259fa57815fa980b05659\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2010.08946\",\"authors\":[{\"authorId\":\"1572302655\",\"name\":\"S. Innocenti\"},{\"authorId\":\"41172759\",\"name\":\"Federico Becattini\"},{\"authorId\":\"2619131\",\"name\":\"F. Pernici\"},{\"authorId\":\"8196487\",\"name\":\"A. D. Bimbo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bdf618e4d75d565ca9305a6ad31b4f6318d30402\",\"title\":\"Temporal Binary Representation for Event-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bdf618e4d75d565ca9305a6ad31b4f6318d30402\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07787\",\"authors\":[{\"authorId\":\"81226618\",\"name\":\"Jinmiao Cai\"},{\"authorId\":\"2855391\",\"name\":\"N. Jiang\"},{\"authorId\":\"50016941\",\"name\":\"Xiao-Guang Han\"},{\"authorId\":\"49104090\",\"name\":\"Kui Jia\"},{\"authorId\":\"1715148\",\"name\":\"Jiangbo Lu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c2664de9388332008077c54278c4f59025dc0bab\",\"title\":\"JOLO-GCN: Mining Joint-Centered Light-Weight Information for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c2664de9388332008077c54278c4f59025dc0bab\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2010.07217\",\"authors\":[{\"authorId\":\"2595119\",\"name\":\"X. Yang\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"1717278\",\"name\":\"T. Burghardt\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"af44b51ac01b2599961107a7a76a5892601c5f7c\",\"title\":\"Back to the Future: Cycle Encoding Prediction for Self-supervised Contrastive Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/af44b51ac01b2599961107a7a76a5892601c5f7c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.05577\",\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":\"10.1007/978-3-030-58523-5_41\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"119b1526842c105ef9a5b187c13045eb580220e7\",\"title\":\"Context-Gated Convolution\",\"url\":\"https://www.semanticscholar.org/paper/119b1526842c105ef9a5b187c13045eb580220e7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e626c57c874d30965b08bfaa0d559d6fc35610d1\",\"title\":\"M-PACT: Michigan Platform for Activity Classification in Tensorflow\",\"url\":\"https://www.semanticscholar.org/paper/e626c57c874d30965b08bfaa0d559d6fc35610d1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3321511\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51738887bb680cc01bdd40fed98442c1b0b226cb\",\"title\":\"Moving Foreground-Aware Visual Attention and Key Volume Mining for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/51738887bb680cc01bdd40fed98442c1b0b226cb\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47818720\",\"name\":\"L. Chen\"},{\"authorId\":\"2450987\",\"name\":\"Z. Song\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1016/j.patcog.2018.08.016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c6f39799392aaacf2fb342518d420e30e24785\",\"title\":\"Learning principal orientations and residual descriptor for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2c6f39799392aaacf2fb342518d420e30e24785\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1806.07110\",\"authors\":[{\"authorId\":\"10364164\",\"name\":\"Nerea Centeno Garc\\u00eda\"},{\"authorId\":\"2322579\",\"name\":\"Pietro Morerio\"},{\"authorId\":\"1727204\",\"name\":\"Vittorio Murino\"}],\"doi\":\"10.1007/978-3-030-01237-3_7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4f472fb027775554187fa3688a95aff9c3c5d977\",\"title\":\"Modality Distillation with Multiple Stream Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4f472fb027775554187fa3688a95aff9c3c5d977\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"},{\"authorId\":\"152150149\",\"name\":\"Lin Feng\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"}],\"doi\":\"10.1145/3422844.3423052\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"title\":\"HFNet: A Novel Model for Human Focused Sports Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/661a89fbbe1fadc94c145af3a6a1ddb79c7d99a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1845611487\",\"name\":\"L. Chen\"},{\"authorId\":null,\"name\":\"Liu Rui\"},{\"authorId\":null,\"name\":\"Zhou Dongsheng\"},{\"authorId\":null,\"name\":\"Xin Yang\"},{\"authorId\":null,\"name\":\"Qiang Zhang\"},{\"authorId\":null,\"name\":\"Wei Xiaopeng\"}],\"doi\":\"10.1007/978-3-030-63426-1_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"title\":\"ESENet: A Human Behavior Recognition Model Based on Extended Squeeze-and-Excitation Network\",\"url\":\"https://www.semanticscholar.org/paper/62295aaed70cb1e3a40b732e7c92748258cb4ec0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.09955\",\"authors\":[{\"authorId\":\"46659935\",\"name\":\"Lei Wang\"},{\"authorId\":\"144199437\",\"name\":\"D. Huynh\"},{\"authorId\":\"2155775\",\"name\":\"Piotr Koniusz\"}],\"doi\":\"10.1109/TIP.2019.2925285\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"title\":\"A Comparative Review of Recent Kinect-Based Action Recognition Algorithms\",\"url\":\"https://www.semanticscholar.org/paper/ae825c501b0b0d512c5db820ad55f64e307a09d2\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1904.08505\",\"authors\":[{\"authorId\":\"65914312\",\"name\":\"Clebeson Canuto dos Santos\"},{\"authorId\":\"143622442\",\"name\":\"J. A. Samatelo\"},{\"authorId\":\"21859276\",\"name\":\"Raquel Frizera Vassallo\"}],\"doi\":\"10.1016/j.neucom.2020.03.038\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d0b763e684aa26436efb8da8dad15d4fd555866e\",\"title\":\"Dynamic Gesture Recognition by Using CNNs and Star RGB: a Temporal Information Condensation\",\"url\":\"https://www.semanticscholar.org/paper/d0b763e684aa26436efb8da8dad15d4fd555866e\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"47652825\",\"name\":\"Ming Zong\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"1962363403\",\"name\":\"Ruili Wang\"},{\"authorId\":\"150356113\",\"name\":\"Zhe Chen\"},{\"authorId\":\"2018580\",\"name\":\"M. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"1725522\",\"name\":\"X. Wang\"},{\"authorId\":\"144783648\",\"name\":\"J. Potgieter\"}],\"doi\":\"10.1007/s00521-020-05313-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"title\":\"Multi-cue based 3D residual network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/721fe37281bf9ea474a0c4f1441f02a7d6e4e4ed\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2009.10765\",\"authors\":[{\"authorId\":\"50992950\",\"name\":\"Karim Armanious\"},{\"authorId\":\"30001943\",\"name\":\"Sherif Abdulatif\"},{\"authorId\":\"48321809\",\"name\":\"Wenbin Shi\"},{\"authorId\":\"35618416\",\"name\":\"Shashank Salian\"},{\"authorId\":\"3245968\",\"name\":\"Thomas K\\u00fcstner\"},{\"authorId\":\"69863469\",\"name\":\"D. Weiskopf\"},{\"authorId\":\"12268601\",\"name\":\"T. Hepp\"},{\"authorId\":\"3403367\",\"name\":\"S. Gatidis\"},{\"authorId\":\"1390708649\",\"name\":\"Bin Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebc7de90c2035abaea164ce93431d58b53a42a03\",\"title\":\"Age-Net: An MRI-Based Iterative Framework for Biological Age Estimation\",\"url\":\"https://www.semanticscholar.org/paper/ebc7de90c2035abaea164ce93431d58b53a42a03\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01065\",\"authors\":[{\"authorId\":\"22237490\",\"name\":\"Tengda Han\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-030-58580-8_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"202c79bbb45ab6524141feacc81caacc4ba00401\",\"title\":\"Memory-augmented Dense Predictive Coding for Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/202c79bbb45ab6524141feacc81caacc4ba00401\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2012.06134\",\"authors\":[{\"authorId\":\"49576412\",\"name\":\"L. Yang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"3246404\",\"name\":\"P. Ren\"},{\"authorId\":\"14104497\",\"name\":\"Siwei Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"title\":\"Intrinsic Temporal Regularization for High-resolution Human Video Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/38efe9308a95b354007cf2e7194c3b029e3eec5a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50542782\",\"name\":\"Chunhua Deng\"},{\"authorId\":\"2041273109\",\"name\":\"Xiaoge Kang\"},{\"authorId\":\"34611435\",\"name\":\"Ziqi Zhu\"},{\"authorId\":\"1820915\",\"name\":\"S. Wu\"}],\"doi\":\"10.1109/ACCESS.2020.3043412\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"31d3b4c798f0513e59bf25d560bb8bdedf5ca210\",\"title\":\"Behavior Recognition Based on Category Subspace in Crowded Videos\",\"url\":\"https://www.semanticscholar.org/paper/31d3b4c798f0513e59bf25d560bb8bdedf5ca210\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"2041335607\",\"name\":\"Jinyang Li\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"2041264362\",\"name\":\"Alex K. Qin\"}],\"doi\":\"10.1109/ACCESS.2020.3043386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"title\":\"Temporal Memory Network Towards Real-Time Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/16df18da2ab27ef1affeefe62ab842ce0f9d8520\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.05168\",\"authors\":[{\"authorId\":\"13136900\",\"name\":\"J. Yang\"},{\"authorId\":\"1999236\",\"name\":\"H. Chang\"},{\"authorId\":\"51151436\",\"name\":\"Seungeui Lee\"},{\"authorId\":\"71494716\",\"name\":\"Nojun Kwak\"}],\"doi\":\"10.1007/978-3-030-58610-2_8\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"6521a48553dbef8d6c9caef0584c70da0127488d\",\"title\":\"SeqHAND: RGB-Sequence-Based 3D Hand Pose and Shape Estimation\",\"url\":\"https://www.semanticscholar.org/paper/6521a48553dbef8d6c9caef0584c70da0127488d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.09833\",\"authors\":[{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"1823519002\",\"name\":\"Xuanteng Huang\"},{\"authorId\":\"50135134\",\"name\":\"Weihong Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1007/978-3-030-58601-0_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4079558004efd97ddb20ea160909f7fa97d689c2\",\"title\":\"MINI-Net: Multiple Instance Ranking Network for Video Highlight Detection\",\"url\":\"https://www.semanticscholar.org/paper/4079558004efd97ddb20ea160909f7fa97d689c2\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"87971957\",\"name\":\"I. Harsono\"},{\"authorId\":\"9269126\",\"name\":\"S. Liawatimena\"},{\"authorId\":\"9455273\",\"name\":\"Tjeng Wawan Cenggoro\"}],\"doi\":\"10.1016/j.jksuci.2020.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d336a86b821854a30a281762863408ab65dc10e3\",\"title\":\"Lung nodule detection and classification from Thorax CT-scan using RetinaNet with transfer learning\",\"url\":\"https://www.semanticscholar.org/paper/d336a86b821854a30a281762863408ab65dc10e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2003.03007\",\"authors\":[{\"authorId\":\"144041880\",\"name\":\"D. Yang\"},{\"authorId\":\"1406016848\",\"name\":\"M. M. Li\"},{\"authorId\":\"144552626\",\"name\":\"H. Fu\"},{\"authorId\":\"2599803\",\"name\":\"Jicong Fan\"},{\"authorId\":\"39109691\",\"name\":\"H. Leung\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d7c9961a6b3f95a57f2325a94ffc3912548b01e5\",\"title\":\"Centrality Graph Convolutional Networks for Skeleton-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d7c9961a6b3f95a57f2325a94ffc3912548b01e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.00451\",\"authors\":[{\"authorId\":\"1573843594\",\"name\":\"Daniel Cores\"},{\"authorId\":\"1725529\",\"name\":\"V. Brea\"},{\"authorId\":\"1734140\",\"name\":\"M. Mucientes\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"title\":\"Spatio-temporal Tubelet Feature Aggregation and Object Linking in Videos\",\"url\":\"https://www.semanticscholar.org/paper/eb0b0056ccecb9b484acd9eaac55f68bf9559174\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19188615\",\"name\":\"Ricardo Manh\\u00e3es Savii\"},{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"574aba95ba9718ab86a9c05f3728f50d1ce6ec41\",\"title\":\"GIBIS at MediaEval 2018: Predicting Media Memorability Task\",\"url\":\"https://www.semanticscholar.org/paper/574aba95ba9718ab86a9c05f3728f50d1ce6ec41\",\"venue\":\"MediaEval\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72434202\",\"name\":\"Zixian Cai\"},{\"authorId\":\"143685465\",\"name\":\"S. Gould\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71b9c46f223dc0d48113f6da1415dc35b2f73eab\",\"title\":\"Activity Recognition in Videos with Segmented Streams\",\"url\":\"https://www.semanticscholar.org/paper/71b9c46f223dc0d48113f6da1415dc35b2f73eab\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2009.05244\",\"authors\":[{\"authorId\":\"80977068\",\"name\":\"Shao-Yuan Lo\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4aca8d9185be9c52157400f887987872eddd1ba\",\"title\":\"Defending Against Multiple and Unforeseen Adversarial Videos\",\"url\":\"https://www.semanticscholar.org/paper/b4aca8d9185be9c52157400f887987872eddd1ba\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2475959\",\"name\":\"Y. Shi\"},{\"authorId\":\"143802908\",\"name\":\"H. Suk\"},{\"authorId\":\"47842255\",\"name\":\"Mingxia Liu\"}],\"doi\":\"10.1007/978-3-030-00919-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93ae71aa6b1736b2b777c3566b6144196c7ccadd\",\"title\":\"Machine Learning in Medical Imaging: 9th International Workshop, MLMI 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/93ae71aa6b1736b2b777c3566b6144196c7ccadd\",\"venue\":\"MLMI@MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48071615\",\"name\":\"Huda Alamri\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"title\":\"Audio Visual Scene-aware dialog (AVSD) Track for Natural Language Generation in DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/aa6c59f0cab5f8dcc899a356d364ce51626536a8\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"2003.14065\",\"authors\":[{\"authorId\":\"153216912\",\"name\":\"Dong Li\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1145/3343031.3350978\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"title\":\"Long Short-Term Relation Networks for Video Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/8370ba2cd080bbc82925106b9fa6c914928cb90b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1907.05023\",\"authors\":[{\"authorId\":\"3381691\",\"name\":\"Yante Li\"},{\"authorId\":\"46423139\",\"name\":\"Xiaohua Huang\"},{\"authorId\":\"1757287\",\"name\":\"Guoying Zhao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2dba6123c278ab7be92cc21cd18b74bb9db97eb3\",\"title\":\"Micro-expression Action Unit Detection withSpatio-temporal Adaptive Pooling\",\"url\":\"https://www.semanticscholar.org/paper/2dba6123c278ab7be92cc21cd18b74bb9db97eb3\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.12522\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-030-20893-6_34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"283181a2173b485726664edc6fe73f0465387629\",\"title\":\"Random Temporal Skipping for Multirate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/283181a2173b485726664edc6fe73f0465387629\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50089367\",\"name\":\"P. Abreu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d5809d13e9de52ff113575533a029297f737468\",\"title\":\"Augmentation of Two-stream CNN architectures with context and attention for action detection and recognition\",\"url\":\"https://www.semanticscholar.org/paper/6d5809d13e9de52ff113575533a029297f737468\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"94870020\",\"name\":\"K. Zhang\"},{\"authorId\":\"46598954\",\"name\":\"Dan Li\"},{\"authorId\":\"1500543635\",\"name\":\"Jiayun Huang\"},{\"authorId\":\"97042247\",\"name\":\"Y. Chen\"}],\"doi\":\"10.3390/s20041085\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6f5d8763486faa3fc343ea7b73f205593869ebd5\",\"title\":\"Automated Video Behavior Recognition of Pigs Using Two-Stream Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/6f5d8763486faa3fc343ea7b73f205593869ebd5\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2871170\",\"name\":\"Huifen Xia\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/ACCESS.2020.2986861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"title\":\"A Survey on Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/6a73ed2d412f2f1a57e400c6f1722f69cf9fcd13\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2874605\",\"name\":\"X. Liu\"},{\"authorId\":\"49934897\",\"name\":\"P. Ghosh\"},{\"authorId\":\"32859304\",\"name\":\"Oytun Ulutan\"},{\"authorId\":\"50591689\",\"name\":\"B. S. Manjunath\"},{\"authorId\":\"38101039\",\"name\":\"K. Chan\"},{\"authorId\":\"1747970\",\"name\":\"R. Govindan\"}],\"doi\":\"10.1145/3356250.3360041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a457b703d51d7d6fffe1ce24bf8405d24ad23b0\",\"title\":\"Caesar: cross-camera complex activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/4a457b703d51d7d6fffe1ce24bf8405d24ad23b0\",\"venue\":\"SenSys\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1802.02091\",\"authors\":[{\"authorId\":\"2845745\",\"name\":\"Sovan Biswas\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/WACV.2018.00180\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8663b8d0d8cdbbbb3e9a5b7e46bc33b3eac96a7\",\"title\":\"Structural Recurrent Neural Network (SRNN) for Group Activity Analysis\",\"url\":\"https://www.semanticscholar.org/paper/c8663b8d0d8cdbbbb3e9a5b7e46bc33b3eac96a7\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1812.01461\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00256\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8dae3a013d83a99e407313be2c9b7c3529cd2440\",\"title\":\"The Visual Centrifuge: Model-Free Layered Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/8dae3a013d83a99e407313be2c9b7c3529cd2440\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145967420\",\"name\":\"Liang Zhang\"},{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"46665820\",\"name\":\"Lin Mei\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5a3e761d0f2c2aeac7804d7ff87887711988e30\",\"title\":\"Attention in Convolutional LSTM for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b5a3e761d0f2c2aeac7804d7ff87887711988e30\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"24289349\",\"name\":\"Didik Purwanto\"},{\"authorId\":\"150282005\",\"name\":\"Rizard Renanda Adhi Pramono\"},{\"authorId\":\"49069045\",\"name\":\"Y. Chen\"},{\"authorId\":\"9319953\",\"name\":\"W. Fang\"}],\"doi\":\"10.1109/LSP.2019.2923918\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"title\":\"Three-Stream Network With Bidirectional Self-Attention for Action Recognition in Extreme Low Resolution Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d5ef23c727f979867ca1791d3ea7106a76f7066\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":\"1908.07519\",\"authors\":[{\"authorId\":\"9261974\",\"name\":\"Wenjin Tao\"},{\"authorId\":\"144081378\",\"name\":\"M. Leu\"},{\"authorId\":\"2466689\",\"name\":\"Z. Yin\"}],\"doi\":\"10.1016/j.engappai.2020.103868\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17e343adfd2d2e4b1385f71d8c463a3357ad49e1\",\"title\":\"Multi-Modal Recognition of Worker Activity for Human-Centered Intelligent Manufacturing\",\"url\":\"https://www.semanticscholar.org/paper/17e343adfd2d2e4b1385f71d8c463a3357ad49e1\",\"venue\":\"Eng. Appl. Artif. Intell.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2018.00176\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6c1227659878e867a01888eef472dd96b679adb6\",\"title\":\"Temporal Difference Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6c1227659878e867a01888eef472dd96b679adb6\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71013766\",\"name\":\"Mathilde Brousmiche\"},{\"authorId\":\"47322308\",\"name\":\"S. Dupont\"},{\"authorId\":\"1993689197\",\"name\":\"Jean Rout\"}],\"doi\":\"10.1145/3422852.3423486\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"204190d66b85145bacc42001b760ff91b84d5443\",\"title\":\"Intra and Inter-modality Interactions for Audio-visual Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/204190d66b85145bacc42001b760ff91b84d5443\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.00618\",\"authors\":[{\"authorId\":\"145545664\",\"name\":\"Y. Yao\"},{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"145489010\",\"name\":\"Yuchen Wang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"},{\"authorId\":\"144729148\",\"name\":\"E. Atkins\"}],\"doi\":\"10.1109/IROS40897.2019.8967556\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7787488d4b1c0487b4393f44bc3d0148e15cf0c5\",\"title\":\"Unsupervised Traffic Accident Detection in First-Person Videos\",\"url\":\"https://www.semanticscholar.org/paper/7787488d4b1c0487b4393f44bc3d0148e15cf0c5\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"2007.14682\",\"authors\":[{\"authorId\":\"1840585237\",\"name\":\"Philipp Rimle\"},{\"authorId\":\"12984122\",\"name\":\"Pelin Dogan\"},{\"authorId\":\"143720818\",\"name\":\"M. Gro\\u00df\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8cf7fdf3f9595f7841ea2e128f569e23f99468f\",\"title\":\"Enriching Video Captions With Contextual Text\",\"url\":\"https://www.semanticscholar.org/paper/f8cf7fdf3f9595f7841ea2e128f569e23f99468f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1876283791\",\"name\":\"Ling-An Zeng\"},{\"authorId\":\"94281814\",\"name\":\"Fa-Ting Hong\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"50543849\",\"name\":\"Q. Yu\"},{\"authorId\":\"8434337\",\"name\":\"W. Zeng\"},{\"authorId\":null,\"name\":\"Yao-Wei Wang\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1145/3394171.3413560\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"971eab82480e3f3b75c2446561aab820b0dee300\",\"title\":\"Hybrid Dynamic-static Context-aware Attention Network for Action Assessment in Long Videos\",\"url\":\"https://www.semanticscholar.org/paper/971eab82480e3f3b75c2446561aab820b0dee300\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2487235\",\"name\":\"Wen-Chia Tsai\"},{\"authorId\":\"153819312\",\"name\":\"Kuan-Chou. Chen\"},{\"authorId\":\"1878732094\",\"name\":\"Jhih-Sheng Lai\"},{\"authorId\":\"36027402\",\"name\":\"Jiun-In Guo\"}],\"doi\":\"10.1109/MWSCAS48704.2020.9184578\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"97fb6c6d29246ceb5a70138ff1847f9cdeea1305\",\"title\":\"Front Moving Object Behavior Prediction System Exploiting Deep Learning Technology for ADAS Applications\",\"url\":\"https://www.semanticscholar.org/paper/97fb6c6d29246ceb5a70138ff1847f9cdeea1305\",\"venue\":\"2020 IEEE 63rd International Midwest Symposium on Circuits and Systems (MWSCAS)\",\"year\":2020},{\"arxivId\":\"2010.07160\",\"authors\":[{\"authorId\":\"66186379\",\"name\":\"Xiangwei Shi\"},{\"authorId\":\"9262977\",\"name\":\"Yunqiang Li\"},{\"authorId\":\"46521850\",\"name\":\"X. Liu\"},{\"authorId\":\"21225169\",\"name\":\"J. V. Gemert\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"841498f527948f94354cae94f25f8ae8df066b83\",\"title\":\"WeightAlign: Normalizing Activations by Weight Alignment\",\"url\":\"https://www.semanticscholar.org/paper/841498f527948f94354cae94f25f8ae8df066b83\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03028\",\"authors\":[{\"authorId\":\"8301799\",\"name\":\"Lingyu Zhu\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"title\":\"Visually Guided Sound Source Separation using Cascaded Opponent Filter Network\",\"url\":\"https://www.semanticscholar.org/paper/4024fb95ebf35d0edd25123b604d26e832b61a6b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/s11263-019-01225-w\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"43cbabdac51091773d1b003d76adaf8426d17b24\",\"title\":\"Deep Insights into Convolutional Networks for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/43cbabdac51091773d1b003d76adaf8426d17b24\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50231158\",\"name\":\"Eirini Mathe\"},{\"authorId\":\"104402185\",\"name\":\"A. Tranou\"},{\"authorId\":\"144116678\",\"name\":\"E. Spyrou\"},{\"authorId\":\"2397702\",\"name\":\"S. Perantonis\"}],\"doi\":\"10.1145/3389189.3397652\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5a4ca0d3faefffcd0d752f8fcc7577d10627e959\",\"title\":\"Human action recognition with deep learning techniques\",\"url\":\"https://www.semanticscholar.org/paper/5a4ca0d3faefffcd0d752f8fcc7577d10627e959\",\"venue\":\"PETRA\",\"year\":2020},{\"arxivId\":\"2006.11808\",\"authors\":[{\"authorId\":\"143630472\",\"name\":\"Minseok Seo\"},{\"authorId\":\"120704782\",\"name\":\"Jae-Min Lee\"},{\"authorId\":\"72297759\",\"name\":\"Jongchan Park\"},{\"authorId\":\"2854596\",\"name\":\"Dong-Geol Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6749b9ce96ff36892871c1a60f1f04af7845b2e\",\"title\":\"Sequential Feature Filtering Classifier\",\"url\":\"https://www.semanticscholar.org/paper/f6749b9ce96ff36892871c1a60f1f04af7845b2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.03732\",\"authors\":[{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"1396536560\",\"name\":\"Ran Xu\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5ae911d5c92fdaece8171f5db8b08e083b7b8f29\",\"title\":\"WOAD: Weakly Supervised Online Action Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/5ae911d5c92fdaece8171f5db8b08e083b7b8f29\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.06228\",\"authors\":[{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"},{\"authorId\":\"152247501\",\"name\":\"Zhirong Wu\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.317\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"59c3a05eac92285aece62bb90d289f8904f11683\",\"title\":\"Temporal Action Detection with Structured Segment Networks\",\"url\":\"https://www.semanticscholar.org/paper/59c3a05eac92285aece62bb90d289f8904f11683\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2006.03201\",\"authors\":[{\"authorId\":\"51230038\",\"name\":\"Eadom Dessalene\"},{\"authorId\":\"2739186\",\"name\":\"Michael Maynord\"},{\"authorId\":\"39685196\",\"name\":\"Chinmaya Devaraj\"},{\"authorId\":\"1759899\",\"name\":\"C. Ferm\\u00fcller\"},{\"authorId\":\"1697493\",\"name\":\"Y. Aloimonos\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"50f9b0fb3448435f569e702aacc02bac4298d314\",\"title\":\"Egocentric Object Manipulation Graphs\",\"url\":\"https://www.semanticscholar.org/paper/50f9b0fb3448435f569e702aacc02bac4298d314\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.07248\",\"authors\":[{\"authorId\":\"1560385163\",\"name\":\"Bo Pang\"},{\"authorId\":\"1527112562\",\"name\":\"Yizhuo Li\"},{\"authorId\":\"49299169\",\"name\":\"J. Li\"},{\"authorId\":\"1807805250\",\"name\":\"Muchen Li\"},{\"authorId\":\"50732737\",\"name\":\"Hanwen Cao\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"965571810fcb79fdaaed7329ff57b3720508a241\",\"title\":\"TDAF: Top-Down Attention Framework for Vision Tasks\",\"url\":\"https://www.semanticscholar.org/paper/965571810fcb79fdaaed7329ff57b3720508a241\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.06977\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"1998948807\",\"name\":\"F. Li\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"12081764\",\"name\":\"E. Ding\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"title\":\"MVFNet: Multi-View Fusion Network for Efficient Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a6e71b58ea6668dd3872e0c9e6cdd258b4582e2a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"},{\"authorId\":\"144934143\",\"name\":\"Dongdong Zhang\"}],\"doi\":\"10.1145/3371425.3371491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4273282e911323957c9b885231658ca592612bee\",\"title\":\"Cross-enhancement transform two-stream 3D ConvNets for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/4273282e911323957c9b885231658ca592612bee\",\"venue\":\"AIIPCC '19\",\"year\":2019},{\"arxivId\":\"1903.02874\",\"authors\":[{\"authorId\":\"35299091\",\"name\":\"Yansong Tang\"},{\"authorId\":\"50792340\",\"name\":\"Dajun Ding\"},{\"authorId\":\"39358728\",\"name\":\"Yongming Rao\"},{\"authorId\":\"145473095\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2118333\",\"name\":\"Danyang Zhang\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"1697700\",\"name\":\"Jiwen Lu\"},{\"authorId\":\"49640256\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/CVPR.2019.00130\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"title\":\"COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e27e78c33288728f66f7dab2fe2696ddbc5c1026\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1907.10473\",\"authors\":[{\"authorId\":\"47571885\",\"name\":\"Ping Luo\"},{\"authorId\":\"2247393\",\"name\":\"Ruimao Zhang\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"2201921\",\"name\":\"Z. Peng\"},{\"authorId\":\"5096712\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/TPAMI.2019.2932062\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2e2534eb1f1af5c043a009391f0ef955aeed2044\",\"title\":\"Switchable Normalization for Learning-to-Normalize Deep Representation\",\"url\":\"https://www.semanticscholar.org/paper/2e2534eb1f1af5c043a009391f0ef955aeed2044\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40162786\",\"name\":\"T. Uemori\"},{\"authorId\":\"145233017\",\"name\":\"A. Ito\"},{\"authorId\":\"2586236\",\"name\":\"Yusuke Moriuchi\"},{\"authorId\":\"34587120\",\"name\":\"Alexander Gatto\"},{\"authorId\":\"35027833\",\"name\":\"J. Murayama\"}],\"doi\":\"10.1109/CVPR.2019.01263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b82d07aa04d883efca35b3c73619d1d0cbd1e738\",\"title\":\"Skin-Based Identification From Multispectral Image Data Using CNNs\",\"url\":\"https://www.semanticscholar.org/paper/b82d07aa04d883efca35b3c73619d1d0cbd1e738\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.10418\",\"authors\":[{\"authorId\":\"49616225\",\"name\":\"Sujoy Paul\"},{\"authorId\":\"2177805\",\"name\":\"S. Roy\"},{\"authorId\":\"1404727582\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1007/978-3-030-01225-0_35\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"title\":\"W-TALC: Weakly-supervised Temporal Activity Localization and Classification\",\"url\":\"https://www.semanticscholar.org/paper/b2ed766ca48d42ac57e16f30ca039fc8aa960189\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1915596\",\"name\":\"Hossein Malekmohamadi\"},{\"authorId\":\"123162731\",\"name\":\"Nontawat Pattanajak\"},{\"authorId\":\"5810483\",\"name\":\"R. Bom\"}],\"doi\":\"10.1007/978-3-030-25590-9_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"title\":\"Human Activity Identification in Smart Daily Environments\",\"url\":\"https://www.semanticscholar.org/paper/0b159a20134dc7325316ee5d39fdbe5d8af8bcc0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49264448\",\"name\":\"Jiang He\"},{\"authorId\":\"48481808\",\"name\":\"Y. Song\"},{\"authorId\":\"28911396\",\"name\":\"H. Jiang\"}],\"doi\":\"10.1007/978-3-030-41404-7_63\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c2c88ee0091e12d2f2a068de19a0a86c83702be0\",\"title\":\"Bi-direction Feature Pyramid Temporal Action Detection Network\",\"url\":\"https://www.semanticscholar.org/paper/c2c88ee0091e12d2f2a068de19a0a86c83702be0\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1579340152\",\"name\":\"Dylan Siegler\"},{\"authorId\":\"1576087725\",\"name\":\"Reed Chen\"},{\"authorId\":\"1579213855\",\"name\":\"Michael Fasko\"},{\"authorId\":\"2409366\",\"name\":\"Shunkun Yang\"},{\"authorId\":\"9160831\",\"name\":\"X. Luo\"},{\"authorId\":\"144101028\",\"name\":\"W. Zhao\"}],\"doi\":\"10.1007/978-981-15-1925-3_25\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de2bde4449c6e0c4687bedc3d2d383e9157a7d2a\",\"title\":\"Semi-automated Development of a Dataset for Baseball Pitch Type Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de2bde4449c6e0c4687bedc3d2d383e9157a7d2a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1902.01078\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICIP.2019.8803153\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7a307c21fdd9a3edff092fe0485399714e53fd7a\",\"title\":\"Saliency Tubes: Visual Explanations for Spatio-Temporal Convolutions\",\"url\":\"https://www.semanticscholar.org/paper/7a307c21fdd9a3edff092fe0485399714e53fd7a\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"1911.09449\",\"authors\":[{\"authorId\":\"108526754\",\"name\":\"Linxi Jiang\"},{\"authorId\":\"9576855\",\"name\":\"Xingjun Ma\"},{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"145148600\",\"name\":\"J. Bailey\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1145/3343031.3351088\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6be44364db3a46ab5fcf8172910650b210cc5c39\",\"title\":\"Black-box Adversarial Attacks on Video Recognition Models\",\"url\":\"https://www.semanticscholar.org/paper/6be44364db3a46ab5fcf8172910650b210cc5c39\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1904.10247\",\"authors\":[{\"authorId\":\"48133807\",\"name\":\"Y. Chang\"},{\"authorId\":\"143822897\",\"name\":\"Zhe Yu Liu\"},{\"authorId\":\"3403825\",\"name\":\"Kuan-Ying Lee\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1109/ICCV.2019.00916\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"title\":\"Free-Form Video Inpainting With 3D Gated Convolution and Temporal PatchGAN\",\"url\":\"https://www.semanticscholar.org/paper/e8705ab4b9626c1ab6442483731fe0371f2234b6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1801.03986\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"37649055\",\"name\":\"J. Paden\"},{\"authorId\":\"145943292\",\"name\":\"G. Fox\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/WACV.2018.00144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"35a24f9f2e01edfba8c2e0dad8dc7d53a4def861\",\"title\":\"Multi-task Spatiotemporal Neural Networks for Structured Surface Reconstruction\",\"url\":\"https://www.semanticscholar.org/paper/35a24f9f2e01edfba8c2e0dad8dc7d53a4def861\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3138328\",\"name\":\"M. A. Maraci\"},{\"authorId\":\"10096695\",\"name\":\"Weidi Xie\"},{\"authorId\":\"144870105\",\"name\":\"J. Noble\"}],\"doi\":\"10.1007/978-3-030-00919-9_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bdc5970c857aba68c097fbe104a93562d676c44\",\"title\":\"Can Dilated Convolutions Capture Ultrasound Video Dynamics?\",\"url\":\"https://www.semanticscholar.org/paper/2bdc5970c857aba68c097fbe104a93562d676c44\",\"venue\":\"MLMI@MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068891\",\"name\":\"Alexander Mathis\"},{\"authorId\":\"41020817\",\"name\":\"Pranav Mamidanna\"},{\"authorId\":\"50283382\",\"name\":\"Kevin M. Cury\"},{\"authorId\":\"39107109\",\"name\":\"Taiga Abe\"},{\"authorId\":\"144440610\",\"name\":\"V. Murthy\"},{\"authorId\":\"4058359\",\"name\":\"M. Mathis\"},{\"authorId\":\"1731199\",\"name\":\"M. Bethge\"}],\"doi\":\"10.1038/s41593-018-0209-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a2d9d04a8d309aa4ce35b45fa3a326215cb12f\",\"title\":\"DeepLabCut: markerless pose estimation of user-defined body parts with deep learning\",\"url\":\"https://www.semanticscholar.org/paper/93a2d9d04a8d309aa4ce35b45fa3a326215cb12f\",\"venue\":\"Nature Neuroscience\",\"year\":2018},{\"arxivId\":\"2012.04872\",\"authors\":[{\"authorId\":\"3457945\",\"name\":\"Jinzheng Cai\"},{\"authorId\":\"1694049581\",\"name\":\"Youbao Tang\"},{\"authorId\":\"1671290360\",\"name\":\"Ke Yan\"},{\"authorId\":\"2964822\",\"name\":\"Adam P. Harrison\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"2710670\",\"name\":\"G. Lin\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27660c8e9627b204dc2ebc9a9431555cfafa8dcc\",\"title\":\"Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging Studies\",\"url\":\"https://www.semanticscholar.org/paper/27660c8e9627b204dc2ebc9a9431555cfafa8dcc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"2028829514\",\"name\":\"Leming Guo\"},{\"authorId\":\"15880069\",\"name\":\"W. Guan\"},{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"1744930\",\"name\":\"T. Ren\"},{\"authorId\":\"1788427\",\"name\":\"Shengyong Chen\"}],\"doi\":\"10.1109/TIP.2020.3038372\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6648479157216bee1f31ef9718fcb64eeafa6843\",\"title\":\"A Pairwise Attentive Adversarial Spatiotemporal Network for Cross-Domain Few-Shot Action Recognition-R2\",\"url\":\"https://www.semanticscholar.org/paper/6648479157216bee1f31ef9718fcb64eeafa6843\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035518509\",\"name\":\"Yitong Yu\"},{\"authorId\":\"2023161740\",\"name\":\"Ziyu Lu\"},{\"authorId\":\"93648280\",\"name\":\"Y. Li\"},{\"authorId\":\"48929321\",\"name\":\"De-Long Liu\"}],\"doi\":\"10.1007/s11042-020-10125-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7bfa32ed921f1a2b09d671dab70db2f3dfa19960\",\"title\":\"ASTS: attention based spatio-temporal sequential framework for movie trailer genre classification\",\"url\":\"https://www.semanticscholar.org/paper/7bfa32ed921f1a2b09d671dab70db2f3dfa19960\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"2012.10283\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"title\":\"Temporal Bilinear Encoding Network of Audio-Visual Features at Low Sampling Rates\",\"url\":\"https://www.semanticscholar.org/paper/eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":\"2007.01065\",\"authors\":[{\"authorId\":\"1729393497\",\"name\":\"Ziyang Song\"},{\"authorId\":\"1508368547\",\"name\":\"Z. Yin\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"},{\"authorId\":\"144535741\",\"name\":\"C. Zhang\"},{\"authorId\":\"34739761\",\"name\":\"W. Chi\"},{\"authorId\":\"3338873\",\"name\":\"Yonggen Ling\"},{\"authorId\":\"13936152\",\"name\":\"Shenghao Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef66cdc03eefd0b9f11b021da8bb20164b79a21b\",\"title\":\"Attention-Oriented Action Recognition for Real-Time Human-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/ef66cdc03eefd0b9f11b021da8bb20164b79a21b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.10229\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"title\":\"Intra- and Inter-Action Understanding via Temporal Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/c09af0b1bdbd5d532b0d5d2ba2a2a12b29ba4f19\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6798639\",\"name\":\"Jinyang Guo\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"1510477221\",\"name\":\"Dong Xu\"}],\"doi\":\"10.1109/cvpr42600.2020.00158\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ffbcd6379e865f150d2f1d2c7074d5d1e482e547\",\"title\":\"Multi-Dimensional Pruning: A Unified Framework for Model Compression\",\"url\":\"https://www.semanticscholar.org/paper/ffbcd6379e865f150d2f1d2c7074d5d1e482e547\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014277\",\"name\":\"G. Zhu\"},{\"authorId\":\"145144215\",\"name\":\"L. Zhang\"},{\"authorId\":\"12166382\",\"name\":\"Peiyi Shen\"},{\"authorId\":\"40403682\",\"name\":\"J. Song\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/TMM.2018.2869278\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"f7029cf09ef4a8fb6b53123314e540113fc8ab6a\",\"title\":\"Continuous Gesture Segmentation and Recognition Using 3DCNN and Convolutional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/f7029cf09ef4a8fb6b53123314e540113fc8ab6a\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49372683\",\"name\":\"Niamul Quader\"},{\"authorId\":\"150152476\",\"name\":\"Juwei Lu\"},{\"authorId\":\"144287598\",\"name\":\"Peng Dai\"},{\"authorId\":\"122009001\",\"name\":\"Wei Li\"}],\"doi\":\"10.1007/978-3-030-58577-8_3\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"080039e68707b483e5c3c27f38660acc1e51ddde\",\"title\":\"Towards Efficient Coarse-to-Fine Networks for Action and Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/080039e68707b483e5c3c27f38660acc1e51ddde\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.07460\",\"authors\":[{\"authorId\":\"47103450\",\"name\":\"Yunlu Xu\"},{\"authorId\":\"1737602\",\"name\":\"C. Zhang\"},{\"authorId\":\"2398015\",\"name\":\"Zhanzhan Cheng\"},{\"authorId\":\"39380386\",\"name\":\"Jianwen Xie\"},{\"authorId\":\"143767386\",\"name\":\"Yi Niu\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1609/aaai.v33i01.33019070\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3934262388cddf2fa6a8af32fbca7e8533ef62df\",\"title\":\"Segregated Temporal Assembly Recurrent Networks for Weakly Supervised Multiple Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/3934262388cddf2fa6a8af32fbca7e8533ef62df\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1909.07945\",\"authors\":[{\"authorId\":\"30625178\",\"name\":\"S. K. Dwivedi\"},{\"authorId\":\"49368129\",\"name\":\"V. Gupta\"},{\"authorId\":\"108057223\",\"name\":\"Rudrajit Mitra\"},{\"authorId\":\"83703493\",\"name\":\"S. Ahmed\"},{\"authorId\":\"36399635\",\"name\":\"Arjun Jain\"}],\"doi\":\"10.1109/ICCVW.2019.00166\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"130373cc752e2c51a6cf14c6d1b2e5f7d9006987\",\"title\":\"ProtoGAN: Towards Few Shot Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/130373cc752e2c51a6cf14c6d1b2e5f7d9006987\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7588999\",\"name\":\"J. Pan\"},{\"authorId\":\"49952482\",\"name\":\"Jibin Gao\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.1109/ICCV.2019.00643\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c21e45a6f5cd075cfa5f7c0e8eca011b9bc59a4f\",\"title\":\"Action Assessment by Joint Relation Graphs\",\"url\":\"https://www.semanticscholar.org/paper/c21e45a6f5cd075cfa5f7c0e8eca011b9bc59a4f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35838466\",\"name\":\"D. Zhukov\"},{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1007/978-3-030-58526-6_28\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"title\":\"Learning Actionness via Long-Range Temporal Order Verification\",\"url\":\"https://www.semanticscholar.org/paper/1bcb053622ef73ccebbfce3d7a8663b15e0c33a8\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1912.03442\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/WACV45572.2020.9093368\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"afafc4077d9ead2260c6ab12293ada21ee889747\",\"title\":\"Spatio-Temporal Pyramid Graph Convolutions for Human Action Recognition and Postural Assessment\",\"url\":\"https://www.semanticscholar.org/paper/afafc4077d9ead2260c6ab12293ada21ee889747\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49037379\",\"name\":\"K. Tang\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"144061928\",\"name\":\"L. Zhu\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"}],\"doi\":\"10.1109/BigData.2018.8621906\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"803d495d63e21972e3820ed200b501e8f3350ee8\",\"title\":\"AutoHighlight : Automatic Highlights Detection and Segmentation in Soccer Matches\",\"url\":\"https://www.semanticscholar.org/paper/803d495d63e21972e3820ed200b501e8f3350ee8\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490236\",\"name\":\"N. Sarhan\"},{\"authorId\":\"1800953\",\"name\":\"S. Frintrop\"}],\"doi\":\"10.1109/ICIP40778.2020.9191289\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f6acfe4b84b0b2234f6c315a2aba25b8624d4727\",\"title\":\"Transfer Learning For Videos: From Action Recognition To Sign Language Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f6acfe4b84b0b2234f6c315a2aba25b8624d4727\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"title\":\"Image-set, Temporal and Spatiotemporal Representations of Videos for Recognizing, Localizing and Quantifying Actions\",\"url\":\"https://www.semanticscholar.org/paper/c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5998740\",\"name\":\"T. Wang\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47896919\",\"name\":\"Hongqiang Lv\"},{\"authorId\":\"1680217\",\"name\":\"Jing Teng\"},{\"authorId\":\"2103629\",\"name\":\"H. Snoussi\"},{\"authorId\":\"152412578\",\"name\":\"Fei Tao\"}],\"doi\":\"10.1109/TII.2020.2997032\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c33b896f43e41d3cf04fc8ad53f88de985666107\",\"title\":\"Online Detection of Action Start via Soft Computing for Smart City\",\"url\":\"https://www.semanticscholar.org/paper/c33b896f43e41d3cf04fc8ad53f88de985666107\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2021},{\"arxivId\":\"2004.11475\",\"authors\":[{\"authorId\":\"9247631\",\"name\":\"M. N. Rizve\"},{\"authorId\":\"2935412\",\"name\":\"U. Demir\"},{\"authorId\":\"82021814\",\"name\":\"Praveen Tirupattur\"},{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"7839191\",\"name\":\"K. Duarte\"},{\"authorId\":\"27058669\",\"name\":\"I. Dave\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"title\":\"Gabriella: An Online System for Real-Time Activity Detection in Untrimmed Security Videos\",\"url\":\"https://www.semanticscholar.org/paper/beb5336d3babd2307887fd7ac7db5d946160f8a1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2001513508\",\"name\":\"Takashi Hosono\"},{\"authorId\":\"97711590\",\"name\":\"Kiyohito Sawada\"},{\"authorId\":\"2000311125\",\"name\":\"Yongqing Sun\"},{\"authorId\":\"40048288\",\"name\":\"K. Hayase\"},{\"authorId\":\"145475360\",\"name\":\"J. Shimamura\"}],\"doi\":\"10.1109/ICIP40778.2020.9190884\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a9218999067514016dee35fecdbd9dc588462ea9\",\"title\":\"Activity Normalization for Activity Detection in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/a9218999067514016dee35fecdbd9dc588462ea9\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47058862\",\"name\":\"L. Zhang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"40588062\",\"name\":\"Jun Liu\"},{\"authorId\":\"3326677\",\"name\":\"Minnan Luo\"},{\"authorId\":\"153580417\",\"name\":\"M. Prakash\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"}],\"doi\":\"10.1016/j.patcog.2020.107348\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"title\":\"Few-shot activity recognition with cross-modal memory network\",\"url\":\"https://www.semanticscholar.org/paper/c164a4da7e69353bc76ed15a08247165c2a6ebf1\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"2007.15244\",\"authors\":[{\"authorId\":\"1841089935\",\"name\":\"Mahdi Davoodikakhki\"},{\"authorId\":\"153505292\",\"name\":\"KangKang Yin\"}],\"doi\":\"10.1007/978-3-030-64556-4_23\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0359520036f33beea638b979d515c170420ac37b\",\"title\":\"Hierarchical Action Classification with Network Pruning\",\"url\":\"https://www.semanticscholar.org/paper/0359520036f33beea638b979d515c170420ac37b\",\"venue\":\"ISVC\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2027021219\",\"name\":\"Peter CK Law\"},{\"authorId\":\"2028220555\",\"name\":\"Wang Yip Lau\"},{\"authorId\":\"32535886\",\"name\":\"Lawrence C. K. Poon\"},{\"authorId\":\"2027023309\",\"name\":\"Andy WC Chung\"},{\"authorId\":\"2027006578\",\"name\":\"Ken WM Lai\"}],\"doi\":\"10.1109/IECON43393.2020.9255402\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ecc564f2a8e1c78cee60ca16b5c6f80347b5a902\",\"title\":\"Smart Prison - Video Analysis for Human Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ecc564f2a8e1c78cee60ca16b5c6f80347b5a902\",\"venue\":\"IECON 2020 The 46th Annual Conference of the IEEE Industrial Electronics Society\",\"year\":2020},{\"arxivId\":\"2010.08055\",\"authors\":[{\"authorId\":\"27478395\",\"name\":\"K. Bhandari\"},{\"authorId\":\"1998945138\",\"name\":\"Mario A. DeLaGarza\"},{\"authorId\":\"153364719\",\"name\":\"Ziliang Zong\"},{\"authorId\":\"3422205\",\"name\":\"Hugo Latapie\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1109/ICIP40778.2020.9191256\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"title\":\"Egok360: A 360 Egocentric Kinetic Human Activity Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/b30ef8520715d7e5584fbe3bd0f4d0351859154a\",\"venue\":\"2020 IEEE International Conference on Image Processing (ICIP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122150713\",\"name\":\"Shuichi Urabe\"},{\"authorId\":\"2256574\",\"name\":\"K. Inoue\"},{\"authorId\":\"2593208\",\"name\":\"M. Yoshioka\"}],\"doi\":\"10.1145/3230519.3230584\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"title\":\"Cooking activities recognition in egocentric videos using combining 2DCNN and 3DCNN\",\"url\":\"https://www.semanticscholar.org/paper/43eda7a5b5c3ba144dcfb92303442f3100cb05dc\",\"venue\":\"CEA@IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30770253\",\"name\":\"S. Zebhi\"},{\"authorId\":\"2936962\",\"name\":\"S. M. T. Almodarresi\"},{\"authorId\":\"1728849\",\"name\":\"V. Abootalebi\"}],\"doi\":\"10.1117/1.JEI.29.5.053011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52d5e9066cd49383a46b045959ddc680c67e6424\",\"title\":\"Video classification by fusing two-stream image template classification and pretrained network\",\"url\":\"https://www.semanticscholar.org/paper/52d5e9066cd49383a46b045959ddc680c67e6424\",\"venue\":\"J. Electronic Imaging\",\"year\":2020},{\"arxivId\":\"1905.04753\",\"authors\":[{\"authorId\":\"3439037\",\"name\":\"Mengtian Li\"},{\"authorId\":\"8020964\",\"name\":\"Ersin Yumer\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6885dc17f1607f1947721ef4c430f1eda22f1228\",\"title\":\"Budgeted Training: Rethinking Deep Neural Network Training Under Resource Constraints\",\"url\":\"https://www.semanticscholar.org/paper/6885dc17f1607f1947721ef4c430f1eda22f1228\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1905.00745\",\"authors\":[{\"authorId\":\"2013521\",\"name\":\"A. Mazari\"},{\"authorId\":\"1692389\",\"name\":\"H. Sahbi\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"79795951498660c539ff440d2ddcb32f3132b97e\",\"title\":\"Human Action Recognition with Deep Temporal Pyramids\",\"url\":\"https://www.semanticscholar.org/paper/79795951498660c539ff440d2ddcb32f3132b97e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.03457\",\"authors\":[{\"authorId\":\"2151587\",\"name\":\"Sangdoo Yun\"},{\"authorId\":\"2390510\",\"name\":\"Seong Joon Oh\"},{\"authorId\":\"3086596\",\"name\":\"Byeongho Heo\"},{\"authorId\":\"2086576\",\"name\":\"Dongyoon Han\"},{\"authorId\":\"52289773\",\"name\":\"Jinhyung Kim\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"title\":\"VideoMix: Rethinking Data Augmentation for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/0f6830373b3a2758baf5efa50f4ca9ac17b1a377\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.01954\",\"authors\":[{\"authorId\":\"20772402\",\"name\":\"B. Gatto\"},{\"authorId\":\"2657966\",\"name\":\"E. M. D. Santos\"},{\"authorId\":\"1808179\",\"name\":\"Alessandro Lameiras Koerich\"},{\"authorId\":\"1770128\",\"name\":\"K. Fukui\"},{\"authorId\":\"144996736\",\"name\":\"Waldir S. S. Junior\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc8395a520a79ffe636dd3fb2d03889529baa211\",\"title\":\"Tensor Analysis with n-Mode Generalized Difference Subspace\",\"url\":\"https://www.semanticscholar.org/paper/bc8395a520a79ffe636dd3fb2d03889529baa211\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.08173\",\"authors\":[{\"authorId\":\"145799444\",\"name\":\"R Gnana Praveen\"},{\"authorId\":\"52194462\",\"name\":\"\\u00c9ric Granger\"},{\"authorId\":\"2180710\",\"name\":\"Patrick Cardinal\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"6b0638dedd5a15856ce0c85e834464a76f026405\",\"title\":\"Deep Weakly-Supervised Domain Adaptation for Pain Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0638dedd5a15856ce0c85e834464a76f026405\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1803.06316\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"title\":\"Temporal Gaussian Mixture Layer for Videos\",\"url\":\"https://www.semanticscholar.org/paper/43b66008ab33dcc4456e157e757cc4f0570f77fb\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"2012.14259\",\"authors\":[{\"authorId\":\"3413560\",\"name\":\"C. Palmero\"},{\"authorId\":\"38081877\",\"name\":\"J. Selva\"},{\"authorId\":\"14556193\",\"name\":\"Sorina Smeureanu\"},{\"authorId\":\"39140182\",\"name\":\"J. J. Junior\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"2042751973\",\"name\":\"Alexa Mosegu'i\"},{\"authorId\":\"2437263\",\"name\":\"Z. Zhang\"},{\"authorId\":\"145182692\",\"name\":\"D. Gallardo\"},{\"authorId\":\"6282552\",\"name\":\"G. Guilera\"},{\"authorId\":\"116209576\",\"name\":\"D. Leiva\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"55afa75a545cf4949372b264c558c7555551a504\",\"title\":\"Context-Aware Personality Inference in Dyadic Scenarios: Introducing the UDIVA Dataset\",\"url\":\"https://www.semanticscholar.org/paper/55afa75a545cf4949372b264c558c7555551a504\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05861\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58520-4_30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78ad3beec8cc6c331dfe491291c213214e798f45\",\"title\":\"Self-supervised Video Representation Learning by Pace Prediction\",\"url\":\"https://www.semanticscholar.org/paper/78ad3beec8cc6c331dfe491291c213214e798f45\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202626\",\"name\":\"Shibo Zhang\"},{\"authorId\":\"2959332\",\"name\":\"Nabil Alshurafa\"}],\"doi\":\"10.1145/3410530.3414329\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b6f3a2c99e797e21f4ad301f8c1150d5f554d1b1\",\"title\":\"Deep generative cross-modal on-body accelerometer data synthesis from videos\",\"url\":\"https://www.semanticscholar.org/paper/b6f3a2c99e797e21f4ad301f8c1150d5f554d1b1\",\"venue\":\"UbiComp/ISWC Adjunct\",\"year\":2020},{\"arxivId\":\"2011.12986\",\"authors\":[{\"authorId\":\"3581705\",\"name\":\"K. Renz\"},{\"authorId\":\"1881393\",\"name\":\"N. Stache\"},{\"authorId\":\"7641268\",\"name\":\"Samuel Albanie\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7dbd6b630d37384c90b05ac3e05c2eeb88537fdd\",\"title\":\"Sign language segmentation with temporal convolutional networks\",\"url\":\"https://www.semanticscholar.org/paper/7dbd6b630d37384c90b05ac3e05c2eeb88537fdd\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.09837\",\"authors\":[{\"authorId\":\"46554630\",\"name\":\"L. Yang\"},{\"authorId\":\"2484788\",\"name\":\"Houwen Peng\"},{\"authorId\":\"39901030\",\"name\":\"Dingwen Zhang\"},{\"authorId\":\"3247966\",\"name\":\"J. Fu\"},{\"authorId\":\"122200133\",\"name\":\"J. Han\"}],\"doi\":\"10.1109/TIP.2020.3016486\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"086057656b94de8bfd0d50ebe935e3d433f593d3\",\"title\":\"Revisiting Anchor Mechanisms for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/086057656b94de8bfd0d50ebe935e3d433f593d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2008.09104\",\"authors\":[{\"authorId\":\"145668226\",\"name\":\"S. Zhou\"},{\"authorId\":\"1704223075\",\"name\":\"Hayit Greenspan\"},{\"authorId\":\"1740714\",\"name\":\"C. Davatzikos\"},{\"authorId\":\"153093430\",\"name\":\"J. S. Duncan\"},{\"authorId\":\"8038506\",\"name\":\"B. Ginneken\"},{\"authorId\":\"1705442\",\"name\":\"A. Madabhushi\"},{\"authorId\":\"144664548\",\"name\":\"J. Prince\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4c4a61edf42ed162651135dbf07e24b695ec2aa\",\"title\":\"A review of deep learning in medical imaging: Image traits, technology trends, case studies with progress highlights, and future promises\",\"url\":\"https://www.semanticscholar.org/paper/c4c4a61edf42ed162651135dbf07e24b695ec2aa\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.07139\",\"authors\":[{\"authorId\":\"145505727\",\"name\":\"Junjie Huang\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"2000447246\",\"name\":\"Guan Huang\"},{\"authorId\":\"40359161\",\"name\":\"Dalong Du\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4760aa7baecaa4842ace30a701cefaffbb5df40\",\"title\":\"AID: Pushing the Performance Boundary of Human Pose Estimation with Information Dropping Augmentation\",\"url\":\"https://www.semanticscholar.org/paper/b4760aa7baecaa4842ace30a701cefaffbb5df40\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48882412\",\"name\":\"Tasweer Ahmad\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"153285152\",\"name\":\"J. Feng\"},{\"authorId\":\"153073573\",\"name\":\"Guozhi Tang\"}],\"doi\":\"10.1109/ACCESS.2019.2937344\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d3fd39dad90b6326b87f0bed5074b4885a013033\",\"title\":\"Human Action Recognition in Unconstrained Trimmed Videos Using Residual Attention Network and Joints Path Signature\",\"url\":\"https://www.semanticscholar.org/paper/d3fd39dad90b6326b87f0bed5074b4885a013033\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"2011.02674\",\"authors\":[{\"authorId\":\"145153296\",\"name\":\"Hao Zhu\"},{\"authorId\":\"50876245\",\"name\":\"Chaoyou Fu\"},{\"authorId\":\"123182910\",\"name\":\"Qianyi Wu\"},{\"authorId\":\"3096434\",\"name\":\"W. Wu\"},{\"authorId\":\"7350503\",\"name\":\"Chen Qian\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"98d639e548b4a981ac6c8a58fd045f6f502fce38\",\"title\":\"AOT: Appearance Optimal Transport Based Identity Swapping for Forgery Detection\",\"url\":\"https://www.semanticscholar.org/paper/98d639e548b4a981ac6c8a58fd045f6f502fce38\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2011.10927\",\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"title\":\"We don't Need Thousand Proposals$\\\\colon$ Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d61f90fe39caa04f3540e0496aa8eef9bf0b7221\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144180678\",\"name\":\"M. Lu\"},{\"authorId\":\"3190022\",\"name\":\"Danping Liao\"},{\"authorId\":\"1689656\",\"name\":\"Z. Li\"}],\"doi\":\"10.1109/ICCVW.2019.00543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"title\":\"Learning Spatiotemporal Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/64fd0514ea322ffd5c80ab8eafc3fec16479ca21\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1804.05879\",\"authors\":[{\"authorId\":\"24337238\",\"name\":\"E. Hofesmann\"},{\"authorId\":\"144487556\",\"name\":\"Madan Ravi Ganesh\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"548f656802735674c269da389afe662d73af661a\",\"title\":\"M-PACT: An Open Source Platform for Repeatable Activity Classification Research\",\"url\":\"https://www.semanticscholar.org/paper/548f656802735674c269da389afe662d73af661a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29779792\",\"name\":\"Kailun Zhong\"},{\"authorId\":\"31964291\",\"name\":\"Yi Li\"},{\"authorId\":\"144567629\",\"name\":\"L. Fang\"},{\"authorId\":\"145842268\",\"name\":\"P. Chen\"}],\"doi\":\"10.1007/978-3-030-31456-9_20\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0dadd8e0d9bd106009d801a2fc96310943a38b6a\",\"title\":\"Cross-Dimension Transfer Learning for Video-Based Facial Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0dadd8e0d9bd106009d801a2fc96310943a38b6a\",\"venue\":\"CCBR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443786569\",\"name\":\"Pablo Rodrigo Gantier Cadena\"},{\"authorId\":\"2909406\",\"name\":\"Ming Yang\"},{\"authorId\":\"22187872\",\"name\":\"Yeqiang Qian\"},{\"authorId\":\"47073793\",\"name\":\"Chunxiang Wang\"}],\"doi\":\"10.1109/ITSC.2019.8917118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2fe7ff2390df0f72c64a05181c38cde9a6b29870\",\"title\":\"Pedestrian Graph: Pedestrian Crossing Prediction Based on 2D Pose Estimation and Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/2fe7ff2390df0f72c64a05181c38cde9a6b29870\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":\"1908.05674\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":\"10.1007/978-981-15-3651-9_2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f99d62a02d91de622dbf5208ef859938980c16d6\",\"title\":\"Bypass Enhancement RGB Stream Model for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/f99d62a02d91de622dbf5208ef859938980c16d6\",\"venue\":\"ACPR Workshops\",\"year\":2019},{\"arxivId\":\"1911.10477\",\"authors\":[{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"97620448\",\"name\":\"Xiaoyang. Huang\"},{\"authorId\":\"2007540200\",\"name\":\"Yi He\"},{\"authorId\":\"51458977\",\"name\":\"J. Xu\"},{\"authorId\":\"1429834069\",\"name\":\"Canqian Yang\"},{\"authorId\":\"7314697\",\"name\":\"Guozheng Xu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7384a5a54c6bc376e4bde319e5a3fe3e935407b2\",\"title\":\"Reinventing 2D Convolutions for 3D Images\",\"url\":\"https://www.semanticscholar.org/paper/7384a5a54c6bc376e4bde319e5a3fe3e935407b2\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2004.06502\",\"authors\":[{\"authorId\":\"120448717\",\"name\":\"Kangning Liu\"},{\"authorId\":\"2476317\",\"name\":\"Shuhang Gu\"},{\"authorId\":\"145848547\",\"name\":\"A. Romero\"},{\"authorId\":\"1732855\",\"name\":\"R. Timofte\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6f5f9706d0a29fc0c6f6c4a1f343542920cdfe1\",\"title\":\"Unsupervised Multimodal Video-to-Video Translation via Self-Supervised Learning\",\"url\":\"https://www.semanticscholar.org/paper/d6f5f9706d0a29fc0c6f6c4a1f343542920cdfe1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144309298\",\"name\":\"D. Tian\"},{\"authorId\":\"72244754\",\"name\":\"Zhe-ming Lu\"},{\"authorId\":\"46772062\",\"name\":\"X. Chen\"},{\"authorId\":\"1409695238\",\"name\":\"Longhua Ma\"}],\"doi\":\"10.1007/s11042-020-08611-4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e599982e5a1b6780420f3d646f49c86396c9b83b\",\"title\":\"An attentional spatial temporal graph convolutional network with co-occurrence feature learning for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/e599982e5a1b6780420f3d646f49c86396c9b83b\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2007.12034\",\"authors\":[{\"authorId\":\"1809218238\",\"name\":\"Xiaofang Wang\"},{\"authorId\":\"3182065\",\"name\":\"Xuehan Xiong\"},{\"authorId\":\"7679232\",\"name\":\"M. Neumann\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"},{\"authorId\":\"145221796\",\"name\":\"W. Hua\"}],\"doi\":\"10.1007/978-3-030-58598-3_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"title\":\"AttentionNAS: Spatiotemporal Attention Cell Search for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/858a9f482e2dc1cebf7a116a740ddd0cf1f13506\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1811.01549\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"31442858\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018401\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"title\":\"StNet: Local and Global Spatial-Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73416563\",\"name\":\"Guoliang Pang\"},{\"authorId\":\"50141950\",\"name\":\"Xionghui Wang\"},{\"authorId\":\"8520539\",\"name\":\"Jianfang Hu\"},{\"authorId\":\"47539770\",\"name\":\"Q. Zhang\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"}],\"doi\":\"10.24963/ijcai.2019/126\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e6a5cbcd6788a75586807e6c14a164ffca9907f\",\"title\":\"DBDNet: Learning Bi-directional Dynamics for Early Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1e6a5cbcd6788a75586807e6c14a164ffca9907f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1803.08494\",\"authors\":[{\"authorId\":\"98264506\",\"name\":\"Yuxin Wu\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"}],\"doi\":\"10.1007/978-3-030-01261-8_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f7919a5677290ab2eca4fa8056bdbbf7c0b11d6\",\"title\":\"Group Normalization\",\"url\":\"https://www.semanticscholar.org/paper/9f7919a5677290ab2eca4fa8056bdbbf7c0b11d6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2012.03298\",\"authors\":[{\"authorId\":\"26902477\",\"name\":\"Amir Rasouli\"},{\"authorId\":\"145367501\",\"name\":\"M. Rohani\"},{\"authorId\":\"151488623\",\"name\":\"J. Luo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"77c74e8ddb4939badc822fe49fde17fd96e3e8f9\",\"title\":\"Pedestrian Behavior Prediction via Multitask Learning and Categorical Interaction Modeling\",\"url\":\"https://www.semanticscholar.org/paper/77c74e8ddb4939badc822fe49fde17fd96e3e8f9\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbc143a6926733a72226e2a4a4f382beb7b36691\",\"title\":\"Supplementary for Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph 1 . Towards Leveraging Language Priors\",\"url\":\"https://www.semanticscholar.org/paper/cbc143a6926733a72226e2a4a4f382beb7b36691\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"153317948\",\"name\":\"Shaobo Lin\"},{\"authorId\":\"150048347\",\"name\":\"B. Wang\"},{\"authorId\":\"47058944\",\"name\":\"L. Zhang\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d607aeef85b2fc0b66d7b58da442bd4b4551ded\",\"title\":\"Alibaba-AIC : Submission to Multi-Moments in Time Challenge 2019 \\u2217\",\"url\":\"https://www.semanticscholar.org/paper/4d607aeef85b2fc0b66d7b58da442bd4b4551ded\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2229862\",\"name\":\"Baohan Xu\"},{\"authorId\":\"151500898\",\"name\":\"Yingbin Zheng\"},{\"authorId\":\"151486061\",\"name\":\"H. Ye\"},{\"authorId\":\"4343057\",\"name\":\"Caili Wu\"},{\"authorId\":\"1390778760\",\"name\":\"Heng Wang\"},{\"authorId\":\"35682933\",\"name\":\"Gufei Sun\"}],\"doi\":\"10.1109/ICME.2019.00077\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"afa66992797efc8b742cd5f8d6313f20de46f559\",\"title\":\"Video Emotion Recognition with Concept Selection\",\"url\":\"https://www.semanticscholar.org/paper/afa66992797efc8b742cd5f8d6313f20de46f559\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"91999133\",\"name\":\"Ji-Hwan Kim\"},{\"authorId\":\"3247148\",\"name\":\"Jae-Pil Heo\"}],\"doi\":\"10.1109/ACCESS.2019.2946898\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f1db07ce91065594751cd51d31f086bc02d42968\",\"title\":\"Learning Coarse and Fine Features for Precise Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/f1db07ce91065594751cd51d31f086bc02d42968\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1904.05876\",\"authors\":[{\"authorId\":\"38211837\",\"name\":\"Idan Schwartz\"},{\"authorId\":\"2068227\",\"name\":\"Alexander G. Schwing\"},{\"authorId\":\"1918412\",\"name\":\"T. Hazan\"}],\"doi\":\"10.1109/CVPR.2019.01283\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"cf072e469d82e71f0515f32b686fb084f4f31714\",\"title\":\"A Simple Baseline for Audio-Visual Scene-Aware Dialog\",\"url\":\"https://www.semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28108620\",\"name\":\"Eli Chen\"},{\"authorId\":\"1904028\",\"name\":\"Oren Haik\"},{\"authorId\":\"1779830\",\"name\":\"Yitzhak Yitzhaky\"}],\"doi\":\"10.1117/12.2534670\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"934265518e2f3a15698132a997b8266e1f7f1f84\",\"title\":\"Action localization and classification in long-distance surveillance\",\"url\":\"https://www.semanticscholar.org/paper/934265518e2f3a15698132a997b8266e1f7f1f84\",\"venue\":\"Security + Defence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2017.161\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"title\":\"Recurrent Assistance: Cross-Dataset Training of LSTMs on Kitchen Tasks\",\"url\":\"https://www.semanticscholar.org/paper/28a7f604b98938d97f15a9a2d16c5ea177d46447\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"75069299\",\"name\":\"Carlos Roig\"},{\"authorId\":\"52085393\",\"name\":\"Manuel Sarmiento\"},{\"authorId\":\"2023762\",\"name\":\"David Varas\"},{\"authorId\":\"8136555\",\"name\":\"Issey Masuda\"},{\"authorId\":\"35528008\",\"name\":\"Juan Carlos Riveiro\"},{\"authorId\":\"2429242\",\"name\":\"Elisenda Bou\"}],\"doi\":\"10.1109/ICCVW.2019.00465\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cab16e6bd58719849380bdceb12c868b8e75e58c\",\"title\":\"Multi-Modal Pyramid Feature Combination for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cab16e6bd58719849380bdceb12c868b8e75e58c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"be35517555e01428ed04577f4e7e566041706aa9\",\"title\":\"Object-centric Attention for Egocentric Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be35517555e01428ed04577f4e7e566041706aa9\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2004.07967\",\"authors\":[{\"authorId\":\"144810262\",\"name\":\"H. M. Nguyen\"},{\"authorId\":\"3388392\",\"name\":\"T. Miyazaki\"},{\"authorId\":\"2137463\",\"name\":\"Y. Sugaya\"},{\"authorId\":\"1740235\",\"name\":\"S. Omachi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"title\":\"Multiple Visual-Semantic Embedding for Video Retrieval from Query Sentence\",\"url\":\"https://www.semanticscholar.org/paper/20b15ddf9efe511961321355bcb4a62c3a29a9ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32723478\",\"name\":\"Reinier Oves Garc\\u00eda\"},{\"authorId\":\"34970419\",\"name\":\"Eduardo F. Morales\"},{\"authorId\":\"144763689\",\"name\":\"Luis Enrique Sucar\"}],\"doi\":\"10.1007/978-3-030-33904-3_69\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3497d8a0438bd69e857690ed1d60ce32ce8546f8\",\"title\":\"A Novel Scheme for Training Two-Stream CNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3497d8a0438bd69e857690ed1d60ce32ce8546f8\",\"venue\":\"CIARP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83172278\",\"name\":\"Y. Li\"},{\"authorId\":\"2303180\",\"name\":\"S. Xu\"},{\"authorId\":\"66678312\",\"name\":\"Xiangqian Cheng\"},{\"authorId\":\"1471662289\",\"name\":\"L. Zhou\"},{\"authorId\":\"49339105\",\"name\":\"Yanyun Zhao\"},{\"authorId\":\"153023158\",\"name\":\"Z. Zhao\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"48430112\",\"name\":\"BoJin Zhuang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de47d9734fcb028339e95d5052281050ff237351\",\"title\":\"An Effective Detection Framework for Activities in Surveillance Videos\",\"url\":\"https://www.semanticscholar.org/paper/de47d9734fcb028339e95d5052281050ff237351\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47719677\",\"name\":\"Xiaolei Qin\"},{\"authorId\":\"31248326\",\"name\":\"Y. Ge\"},{\"authorId\":\"145429878\",\"name\":\"Hui Yu\"},{\"authorId\":\"47591280\",\"name\":\"Feiyu Chen\"},{\"authorId\":\"144485153\",\"name\":\"D. Yang\"}],\"doi\":\"10.1109/LSP.2020.3018914\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc27658c8db517561c77de3a8cd2cdee08a547bf\",\"title\":\"Spatial Enhancement and Temporal Constraint for Weakly Supervised Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/dc27658c8db517561c77de3a8cd2cdee08a547bf\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2020},{\"arxivId\":\"2007.08180\",\"authors\":[{\"authorId\":\"1665217447\",\"name\":\"Zhipeng Luo\"},{\"authorId\":\"48207720\",\"name\":\"Dawei Xu\"},{\"authorId\":\"47294156\",\"name\":\"ZhiGuang Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"420bed1645128b2132acda3c235b657cc2c90fd7\",\"title\":\"Challenge report: VIPriors Action Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/420bed1645128b2132acda3c235b657cc2c90fd7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03263\",\"authors\":[{\"authorId\":\"93242167\",\"name\":\"Lei Shi\"},{\"authorId\":\"48380079\",\"name\":\"Yi-Fan Zhang\"},{\"authorId\":\"48265260\",\"name\":\"Jian Cheng\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df131f9d1fa5570192a5a3c040fe42ebe4bdfe5f\",\"title\":\"Decoupled Spatial-Temporal Attention Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df131f9d1fa5570192a5a3c040fe42ebe4bdfe5f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"49483094\",\"name\":\"Yan Yan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"62e42d5655b7553d8940ca2fd9b9b9a72e3bb51f\",\"title\":\"Supplementary Material Searching for Actions on the Hyperbole\",\"url\":\"https://www.semanticscholar.org/paper/62e42d5655b7553d8940ca2fd9b9b9a72e3bb51f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153008120\",\"name\":\"Zineng Xu\"},{\"authorId\":\"1798046\",\"name\":\"Ver\\u00f3nica Vilaplana\"},{\"authorId\":\"2585946\",\"name\":\"J. R. Morros\"}],\"doi\":\"10.1109/CBMI.2018.8516450\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"084a5a1699ab799517baa316bc4c8d0754b145a9\",\"title\":\"Action Tube Extraction Based 3D-CNN for RGB-D Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/084a5a1699ab799517baa316bc4c8d0754b145a9\",\"venue\":\"2018 International Conference on Content-Based Multimedia Indexing (CBMI)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144462304\",\"name\":\"George Bebis\"},{\"authorId\":\"67054063\",\"name\":\"Richard Boyle\"},{\"authorId\":\"144946888\",\"name\":\"B. Parvin\"},{\"authorId\":\"1766575\",\"name\":\"Darko Koracin\"},{\"authorId\":\"1811543\",\"name\":\"Daniela Ushizima\"},{\"authorId\":\"144360273\",\"name\":\"Sek Chai\"},{\"authorId\":\"35315389\",\"name\":\"Shinjiro Sueda\"},{\"authorId\":\"145122731\",\"name\":\"Xin Lin\"},{\"authorId\":\"48272564\",\"name\":\"Ai-dong Lu\"},{\"authorId\":\"143725529\",\"name\":\"Daniel Thalmann\"},{\"authorId\":\"40505818\",\"name\":\"Chaoli Wang\"},{\"authorId\":\"49080140\",\"name\":\"Panpan Xu\"}],\"doi\":\"10.1007/978-3-030-33720-9\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b38d49795eb7b421123381b92509527b48941143\",\"title\":\"Advances in Visual Computing: 14th International Symposium on Visual Computing, ISVC 2019, Lake Tahoe, NV, USA, October 7\\u20139, 2019, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/b38d49795eb7b421123381b92509527b48941143\",\"venue\":\"ISVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sigurthor Bjorgvinsson\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"caefc47fa525a407944ac5c84bd5cbbbc74af74b\",\"title\":\"In Search of a Generic Deepfake Detector\",\"url\":\"https://www.semanticscholar.org/paper/caefc47fa525a407944ac5c84bd5cbbbc74af74b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2004.03548\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"46865320\",\"name\":\"Jianping Shi\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/cvpr42600.2020.00067\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"title\":\"Temporal Pyramid Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10db26c80238d70ca51d8a5293d893b6f1dedc8b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1903.04176\",\"authors\":[{\"authorId\":\"71590901\",\"name\":\"P. Schlosser\"},{\"authorId\":\"31556032\",\"name\":\"D. M\\u00fcnch\"},{\"authorId\":\"2431669\",\"name\":\"M. Arens\"}],\"doi\":\"10.1109/CVPRW.2019.00300\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48dc1bdbac70bd1abe89a284f4f10807f63dd884\",\"title\":\"Investigation on Combining 3D Convolution of Image Data and Optical Flow to Generate Temporal Action Proposals\",\"url\":\"https://www.semanticscholar.org/paper/48dc1bdbac70bd1abe89a284f4f10807f63dd884\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50633239\",\"name\":\"I. Abramovich\"},{\"authorId\":\"1411460100\",\"name\":\"Tomer Ben-Yehuda\"},{\"authorId\":\"2221482\",\"name\":\"Rami Cohen\"}],\"doi\":\"10.1109/ICSEE.2018.8646076\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0bb2de5b9bd7b350cba97adea5826226329ab5a\",\"title\":\"Low-Complexity Video Classification using Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b0bb2de5b9bd7b350cba97adea5826226329ab5a\",\"venue\":\"2018 IEEE International Conference on the Science of Electrical Engineering in Israel (ICSEE)\",\"year\":2018},{\"arxivId\":\"2002.09424\",\"authors\":[{\"authorId\":\"1500721503\",\"name\":\"Ziyad Jappie\"},{\"authorId\":\"31915818\",\"name\":\"D. Torpey\"},{\"authorId\":\"48627696\",\"name\":\"T. \\u00c7elik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f9486264ebd4f609453f96a9df97588027f1dfb\",\"title\":\"SummaryNet: A Multi-Stage Deep Learning Model for Automatic Video Summarisation\",\"url\":\"https://www.semanticscholar.org/paper/1f9486264ebd4f609453f96a9df97588027f1dfb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.11888\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"1796254\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.24963/ijcai.2020/88\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"884be34dd5d2ea78940da96d2813be7768933857\",\"title\":\"SBAT: Video Captioning with Sparse Boundary-Aware Transformer\",\"url\":\"https://www.semanticscholar.org/paper/884be34dd5d2ea78940da96d2813be7768933857\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738652956\",\"name\":\"Jui-Yuan Su\"},{\"authorId\":\"1738709726\",\"name\":\"Pei-Hua Zhang\"},{\"authorId\":\"1739037594\",\"name\":\"Sin-Yi Cai\"},{\"authorId\":\"2069934\",\"name\":\"Shyi-Chyi Cheng\"},{\"authorId\":\"40513660\",\"name\":\"Chin-Chun Chang\"}],\"doi\":\"10.1117/12.2566902\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"a733b3ae5111358b9a7c6088419503d9fdf89bb5\",\"title\":\"Visual analysis of fish feeding intensity for smart feeding in aquaculture using deep learning\",\"url\":\"https://www.semanticscholar.org/paper/a733b3ae5111358b9a7c6088419503d9fdf89bb5\",\"venue\":\"Other Conferences\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103750709\",\"name\":\"Ha Thi Phuong Thao\"}],\"doi\":\"10.1145/3394171.3416517\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d15391bc414a0646a2e95de60fa4813eb663427c\",\"title\":\"Deep Neural Networks for Predicting Affective Responses from Movies\",\"url\":\"https://www.semanticscholar.org/paper/d15391bc414a0646a2e95de60fa4813eb663427c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81324021\",\"name\":\"F. Castro\"},{\"authorId\":\"1643043427\",\"name\":\"P. Costa\"},{\"authorId\":\"145249846\",\"name\":\"Filipe Marques\"},{\"authorId\":\"1711214067\",\"name\":\"M. Parente\"}],\"doi\":\"10.1109/ICIST49303.2020.9202063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80d6740d037111473faab2930904a129159b8c36\",\"title\":\"Hierarchical Multitask Learning for Improved Underwater Recognition on Imbalanced Tasks\",\"url\":\"https://www.semanticscholar.org/paper/80d6740d037111473faab2930904a129159b8c36\",\"venue\":\"2020 10th International Conference on Information Science and Technology (ICIST)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445905\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"47957191\",\"name\":\"Xiao-yun Zhang\"},{\"authorId\":\"1490938774\",\"name\":\"Haiyan Wu\"}],\"doi\":\"10.1109/VCIP47243.2019.8965768\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5acec6921c4015a3fb252bc18645b33d416b8784\",\"title\":\"Improving Action Recognition with the Graph-Neural-Network-based Interaction Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/5acec6921c4015a3fb252bc18645b33d416b8784\",\"venue\":\"2019 IEEE Visual Communications and Image Processing (VCIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2812440\",\"name\":\"S. Zhong\"},{\"authorId\":\"46366007\",\"name\":\"Jiaxin Wu\"},{\"authorId\":\"145054089\",\"name\":\"J. Jiang\"}],\"doi\":\"10.1016/j.neucom.2018.12.040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0adddb83eb89da8ecd14a296fa016773dc774646\",\"title\":\"Video summarization via spatio-temporal deep architecture\",\"url\":\"https://www.semanticscholar.org/paper/0adddb83eb89da8ecd14a296fa016773dc774646\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"2007.11154\",\"authors\":[{\"authorId\":\"1825768521\",\"name\":\"Kamalesh Palanisamy\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dfa8b5cfd28a8b461c1a1e1bb13e3c6e28a24a28\",\"title\":\"Rethinking CNN Models for Audio Classification\",\"url\":\"https://www.semanticscholar.org/paper/dfa8b5cfd28a8b461c1a1e1bb13e3c6e28a24a28\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.07471\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"}],\"doi\":\"10.1609/AAAI.V34I07.6983\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65e170ba65e94ea7310367fc5540fbb9629010b5\",\"title\":\"Knowledge Integration Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/65e170ba65e94ea7310367fc5540fbb9629010b5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.03497\",\"authors\":[{\"authorId\":\"6917558\",\"name\":\"Daniel Deniz\"},{\"authorId\":\"144484799\",\"name\":\"F. Barranco\"},{\"authorId\":\"103939214\",\"name\":\"J. Isern\"},{\"authorId\":\"32132184\",\"name\":\"E. Ros\"}],\"doi\":\"10.1109/ETFA46521.2020.9211910\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"92594b024a19bc5cb3e38984c864e1653179db8f\",\"title\":\"Reconfigurable Cyber-Physical System for Lifestyle Video-Monitoring via Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/92594b024a19bc5cb3e38984c864e1653179db8f\",\"venue\":\"2020 25th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)\",\"year\":2020},{\"arxivId\":\"2009.06902\",\"authors\":[{\"authorId\":\"13099867\",\"name\":\"Haisheng Su\"},{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"1605763279\",\"name\":\"Dongliang Wang\"},{\"authorId\":\"35893447\",\"name\":\"W. Gan\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"47446949\",\"name\":\"M. Wang\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"145858545\",\"name\":\"Y. Qiao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"title\":\"Collaborative Distillation in the Parameter and Spectrum Domains for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/882a973e02bfe9717f4ad70fe9fb327a515b16ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.05789\",\"authors\":[{\"authorId\":\"1443743722\",\"name\":\"Ying Cheng\"},{\"authorId\":\"29068663\",\"name\":\"Ruize Wang\"},{\"authorId\":\"48699340\",\"name\":\"Zhihao Pan\"},{\"authorId\":\"51304315\",\"name\":\"Rui Feng\"},{\"authorId\":\"3067458\",\"name\":\"Yuejie Zhang\"}],\"doi\":\"10.1145/3394171.3413869\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"title\":\"Look, Listen, and Attend: Co-Attention Network for Self-Supervised Audio-Visual Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/17b28643a5aaed62fbccd98781d4ebc0f0477afa\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2004341822\",\"name\":\"Noorhan K. Fawzy\"},{\"authorId\":\"37370786\",\"name\":\"M. Marey\"},{\"authorId\":\"143987203\",\"name\":\"Mostafa Aref\"}],\"doi\":\"10.1007/978-3-030-58669-0_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18bacea52db19f69bc4933c6ad82eb5d22da281b\",\"title\":\"Video Captioning Using Attention Based Visual Fusion with Bi-temporal Context and Bi-modal Semantic Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/18bacea52db19f69bc4933c6ad82eb5d22da281b\",\"venue\":\"AISI\",\"year\":2020},{\"arxivId\":\"2008.05721\",\"authors\":[{\"authorId\":\"48271129\",\"name\":\"T. Kim\"},{\"authorId\":\"98080420\",\"name\":\"H. Lee\"},{\"authorId\":\"1387831061\",\"name\":\"MyeongAh Cho\"},{\"authorId\":\"48411936\",\"name\":\"H. Lee\"},{\"authorId\":\"80069330\",\"name\":\"Dong Heon Cho\"},{\"authorId\":\"39847092\",\"name\":\"Sangyoun Lee\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"24b300420bd814e48b59a3419a22d706da6c4191\",\"title\":\"Learning Temporally Invariant and Localizable Features via Data Augmentation for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/24b300420bd814e48b59a3419a22d706da6c4191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.00832\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"50031872\",\"name\":\"Yunsheng Ma\"},{\"authorId\":\"37989322\",\"name\":\"Y. Gu\"},{\"authorId\":\"1755872\",\"name\":\"Jufeng Yang\"},{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50591162\",\"name\":\"P. Xu\"},{\"authorId\":\"151185822\",\"name\":\"Runbo Hu\"},{\"authorId\":\"144626314\",\"name\":\"Hua Chai\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1609/AAAI.V34I01.5364\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"title\":\"An End-to-End Visual-Audio Attention Network for Emotion Recognition in User-Generated Videos\",\"url\":\"https://www.semanticscholar.org/paper/9e0a7eac69abb2d375392f38b63bef238cf9f333\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2012.07123\",\"authors\":[{\"authorId\":\"47553511\",\"name\":\"Emanuela Haller\"},{\"authorId\":\"31609940\",\"name\":\"Adina Madgda Florea\"},{\"authorId\":\"1749627\",\"name\":\"M. Leordeanu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"436e1d15c415e621b8ae68712b7cc0203a3f4554\",\"title\":\"Iterative Knowledge Exchange Between Deep Learning and Space-Time Spectral Clustering for Unsupervised Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/436e1d15c415e621b8ae68712b7cc0203a3f4554\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.09791\",\"authors\":[{\"authorId\":\"3152399\",\"name\":\"Y. Tang\"},{\"authorId\":\"144679623\",\"name\":\"Yuxing Tang\"},{\"authorId\":\"144079770\",\"name\":\"Yingying Zhu\"},{\"authorId\":\"1779360407\",\"name\":\"Jing Xiao\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-59719-1_50\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8343628b050f379c32efe511bba3bb92fc38deff\",\"title\":\"E2Net: An Edge Enhanced Network for Accurate Liver and Tumor Segmentation on CT Scans\",\"url\":\"https://www.semanticscholar.org/paper/8343628b050f379c32efe511bba3bb92fc38deff\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406678671\",\"name\":\"\\u00d8yvind Meinich-Bache\"},{\"authorId\":\"1557403564\",\"name\":\"Simon Lennart Austnes\"},{\"authorId\":\"2691592\",\"name\":\"K. Engan\"},{\"authorId\":\"1704325\",\"name\":\"Ivar Austvoll\"},{\"authorId\":\"8985915\",\"name\":\"T. Eftest\\u00f8l\"},{\"authorId\":\"2665808\",\"name\":\"H. Myklebust\"},{\"authorId\":\"16935010\",\"name\":\"S. Kusulla\"},{\"authorId\":\"143762843\",\"name\":\"H. Kidanto\"},{\"authorId\":\"40423610\",\"name\":\"H. Ersdal\"}],\"doi\":\"10.1109/JBHI.2020.2978252\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"936f4a0a53ca9b08cc0380da8ef806f957d17d12\",\"title\":\"Activity Recognition From Newborn Resuscitation Videos\",\"url\":\"https://www.semanticscholar.org/paper/936f4a0a53ca9b08cc0380da8ef806f957d17d12\",\"venue\":\"IEEE Journal of Biomedical and Health Informatics\",\"year\":2020},{\"arxivId\":\"2007.05835\",\"authors\":[{\"authorId\":\"3250505\",\"name\":\"Avisek Lahiri\"},{\"authorId\":\"26883188\",\"name\":\"Sourav Bairagya\"},{\"authorId\":\"77697247\",\"name\":\"Sutanu Bera\"},{\"authorId\":\"51445278\",\"name\":\"Siddhant Haldar\"},{\"authorId\":\"1758797\",\"name\":\"P. Biswas\"}],\"doi\":\"10.1109/TCSVT.2020.3007723\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"895fd2de6aa1dbd146e351a850c6a032e339c1ad\",\"title\":\"Lightweight Modules for Efficient Deep Learning based Image Restoration\",\"url\":\"https://www.semanticscholar.org/paper/895fd2de6aa1dbd146e351a850c6a032e339c1ad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10033841\",\"name\":\"Xinzhe Zhou\"},{\"authorId\":\"145353089\",\"name\":\"Y. Mu\"}],\"doi\":\"10.1145/3372278.3390687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"title\":\"Google Helps YouTube: Learning Few-Shot Video Classification from Historic Tasks and Cross-Domain Sample Transfer\",\"url\":\"https://www.semanticscholar.org/paper/fe1b4f10431881512b6dc4c4ece9545732db6f83\",\"venue\":\"ICMR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2913408\",\"name\":\"Nikolas Lessmann\"},{\"authorId\":\"144085811\",\"name\":\"C. S\\u00e1nchez\"},{\"authorId\":\"2048003\",\"name\":\"L. Beenen\"},{\"authorId\":\"1844322460\",\"name\":\"Luuk H Boulogne\"},{\"authorId\":\"39428940\",\"name\":\"M. Brink\"},{\"authorId\":\"102402948\",\"name\":\"E. Calli\"},{\"authorId\":\"50088608\",\"name\":\"J. Charbonnier\"},{\"authorId\":\"14884796\",\"name\":\"Ton Dofferhoff\"},{\"authorId\":\"134876175\",\"name\":\"Wouter van Everdingen\"},{\"authorId\":\"16752360\",\"name\":\"P. Gerke\"},{\"authorId\":\"34326547\",\"name\":\"B. Geurts\"},{\"authorId\":\"145984096\",\"name\":\"H. Gietema\"},{\"authorId\":\"1844316831\",\"name\":\"Miriam Groeneveld\"},{\"authorId\":\"1844316825\",\"name\":\"Louis van Harten\"},{\"authorId\":\"1844316863\",\"name\":\"N. Hendrix\"},{\"authorId\":\"1844322840\",\"name\":\"Ward Hendrix\"},{\"authorId\":\"34754023\",\"name\":\"H. Huisman\"},{\"authorId\":\"3165444\",\"name\":\"I. I\\u0161gum\"},{\"authorId\":\"2895994\",\"name\":\"C. Jacobs\"},{\"authorId\":\"1844330879\",\"name\":\"Ruben Kluge\"},{\"authorId\":\"1844338537\",\"name\":\"Michel Kok\"},{\"authorId\":\"1490804284\",\"name\":\"Jasenko Krdzalic\"},{\"authorId\":\"1844330854\",\"name\":\"Bianca Lassen-Schmidt\"},{\"authorId\":\"1844316866\",\"name\":\"Kicky van Leeuwen\"},{\"authorId\":\"4960344\",\"name\":\"J. Meakin\"},{\"authorId\":\"1844322837\",\"name\":\"Mike Overkamp\"},{\"authorId\":\"13845583\",\"name\":\"T. van Rees Vellinga\"},{\"authorId\":\"1737654\",\"name\":\"E. V. van Rikxoort\"},{\"authorId\":\"1844323314\",\"name\":\"Riccardo Samperna\"},{\"authorId\":\"1389949132\",\"name\":\"C. Schaefer-Prokop\"},{\"authorId\":\"3504603\",\"name\":\"S. Schalekamp\"},{\"authorId\":\"152867460\",\"name\":\"E. Scholten\"},{\"authorId\":\"1568863061\",\"name\":\"Cheryl Sital\"},{\"authorId\":\"4235127\",\"name\":\"L. St\\u00f6ger\"},{\"authorId\":\"32649341\",\"name\":\"Jonas Teuwen\"},{\"authorId\":\"1844317054\",\"name\":\"Kiran Vaidhya Venkadesh\"},{\"authorId\":\"1693414462\",\"name\":\"Coen de Vente\"},{\"authorId\":\"32356091\",\"name\":\"M. Vermaat\"},{\"authorId\":\"1844279266\",\"name\":\"Weiyi Xie\"},{\"authorId\":\"1844316837\",\"name\":\"Bram de Wilde\"},{\"authorId\":\"113208834\",\"name\":\"M. Prokop\"},{\"authorId\":\"123637526\",\"name\":\"B. van Ginneken\"}],\"doi\":\"10.1148/radiol.2020202439\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4330ce9c73af04a35d1a7dd366df8434c98e30ed\",\"title\":\"Automated Assessment of CO-RADS and Chest CT Severity Scores in Patients with Suspected COVID-19 Using Artificial Intelligence\",\"url\":\"https://www.semanticscholar.org/paper/4330ce9c73af04a35d1a7dd366df8434c98e30ed\",\"venue\":\"Radiology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145424954\",\"name\":\"L. Feng\"},{\"authorId\":\"23743970\",\"name\":\"Zhenning Lu\"},{\"authorId\":\"8602618\",\"name\":\"Shenglan Liu\"},{\"authorId\":\"143949784\",\"name\":\"Dong Jiang\"},{\"authorId\":\"40959393\",\"name\":\"Yang Liu\"},{\"authorId\":\"1994488088\",\"name\":\"Lianyu Hu\"}],\"doi\":\"10.1007/978-3-030-63823-8_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9144975fe61347ebe874025a56dff54883f1aa82\",\"title\":\"Skeleton-Based Action Recognition with Dense Spatial Temporal Graph Network\",\"url\":\"https://www.semanticscholar.org/paper/9144975fe61347ebe874025a56dff54883f1aa82\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2621181\",\"name\":\"Haoye Dong\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"50457502\",\"name\":\"Xiaohui Shen\"},{\"authorId\":\"152365288\",\"name\":\"B. Wu\"},{\"authorId\":\"8567485\",\"name\":\"Bing-cheng Chen\"},{\"authorId\":\"144926874\",\"name\":\"J. Yin\"}],\"doi\":\"10.1109/ICCV.2019.00125\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"69a1e9a45eff33105a5f236e36876c917b278a0e\",\"title\":\"FW-GAN: Flow-Navigated Warping GAN for Video Virtual Try-On\",\"url\":\"https://www.semanticscholar.org/paper/69a1e9a45eff33105a5f236e36876c917b278a0e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.11285\",\"authors\":[{\"authorId\":\"1821514\",\"name\":\"Xu-Dong Lin\"},{\"authorId\":\"73423138\",\"name\":\"Zheng Shou\"},{\"authorId\":\"72197815\",\"name\":\"Shih-Fu Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f395d2bb7cb41a7aff934cbecc9f567a27a070\",\"title\":\"Towards Train-Test Consistency for Semi-supervised Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/45f395d2bb7cb41a7aff934cbecc9f567a27a070\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.09778\",\"authors\":[{\"authorId\":\"1715317\",\"name\":\"Hye-jin Shim\"},{\"authorId\":\"3403702\",\"name\":\"Hee-Soo Heo\"},{\"authorId\":\"31930118\",\"name\":\"Jee-weon Jung\"},{\"authorId\":\"150129390\",\"name\":\"Ha-Jin Yu\"}],\"doi\":\"10.21437/interspeech.2020-1345\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d01cf8d6e08d31e2959148eb5e6947a356f1076c\",\"title\":\"Self-supervised pre-training with acoustic configurations for replay spoofing detection\",\"url\":\"https://www.semanticscholar.org/paper/d01cf8d6e08d31e2959148eb5e6947a356f1076c\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"46659696\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ICCV.2019.00400\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"title\":\"Weakly Supervised Temporal Action Localization Through Contrast Based Evaluation Networks\",\"url\":\"https://www.semanticscholar.org/paper/87ecaaf627d441e5f42465a237a3e3a2c10da5d1\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.02707\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94bbc4ea271c918705876b60d98d227a0ab55a43\",\"title\":\"Video Action Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143672737\",\"name\":\"A. Mu\\u00f1oz\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"49965376\",\"name\":\"Max Argus\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"title\":\"Multi-Variate Temporal GAN for Large Scale Video Generation\",\"url\":\"https://www.semanticscholar.org/paper/1233d892716e3c8efab5a72bef14c8a4bdf668d4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1905.07853\",\"authors\":[{\"authorId\":\"31162518\",\"name\":\"Xingyu Liu\"},{\"authorId\":\"1926578\",\"name\":\"Joon-Young Lee\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"}],\"doi\":\"10.1109/CVPR.2019.00440\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66c21a179824037becb94105cafea75c746ad89a\",\"title\":\"Learning Video Representations From Correspondence Proposals\",\"url\":\"https://www.semanticscholar.org/paper/66c21a179824037becb94105cafea75c746ad89a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1808.02536\",\"authors\":[{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"}],\"doi\":\"10.1007/978-3-030-20870-7_44\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"929c8a73fceb88148847c6abca98a4d413d15415\",\"title\":\"Dynamic Temporal Pyramid Network: A Closer Look at Multi-Scale Modeling for Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/929c8a73fceb88148847c6abca98a4d413d15415\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2012.09890\",\"authors\":[{\"authorId\":\"50997909\",\"name\":\"Amirhossein Dadashzadeh\"},{\"authorId\":\"2271983\",\"name\":\"A. Whone\"},{\"authorId\":\"2836006\",\"name\":\"M. Rolinski\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad0f49996ccd867a19e2a4964746bf5b981db3b9\",\"title\":\"Exploring Motion Boundaries in an End-to-End Network for Vision-based Parkinson's Severity Assessment\",\"url\":\"https://www.semanticscholar.org/paper/ad0f49996ccd867a19e2a4964746bf5b981db3b9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31101125\",\"name\":\"K. Papadimitriou\"},{\"authorId\":\"1423737852\",\"name\":\"Gerasimos Potamianos\"}],\"doi\":\"10.23919/Eusipco47968.2020.9287365\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ec050e66591109e2ba948642a0cad57c37a121c2\",\"title\":\"A Fully Convolutional Sequence Learning Approach for Cued Speech Recognition from Videos\",\"url\":\"https://www.semanticscholar.org/paper/ec050e66591109e2ba948642a0cad57c37a121c2\",\"venue\":\"2020 28th European Signal Processing Conference (EUSIPCO)\",\"year\":2021},{\"arxivId\":\"1811.08883\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"}],\"doi\":\"10.1109/ICCV.2019.00502\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4152d2c8585f7e3f85d3b3d84036171de104cbd7\",\"title\":\"Rethinking ImageNet Pre-Training\",\"url\":\"https://www.semanticscholar.org/paper/4152d2c8585f7e3f85d3b3d84036171de104cbd7\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.10966\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"47268124\",\"name\":\"T. Li\"},{\"authorId\":\"46499812\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1007/978-3-030-58536-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"title\":\"In-Home Daily-Life Captioning Using Radio Signals\",\"url\":\"https://www.semanticscholar.org/paper/fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.07712\",\"authors\":[{\"authorId\":\"153596089\",\"name\":\"P. Zhang\"},{\"authorId\":\"32138597\",\"name\":\"W. Calderon\"},{\"authorId\":\"2206741\",\"name\":\"B. Lee\"},{\"authorId\":\"1879839\",\"name\":\"A. Tessier\"},{\"authorId\":\"1387446753\",\"name\":\"Jacky Bibliowicz\"},{\"authorId\":\"93410866\",\"name\":\"L. Calin\"},{\"authorId\":\"65756158\",\"name\":\"M. Lee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"029409bcd00b3649b74a5a4cd3078517cedbdbaf\",\"title\":\"Contact Area Detector using Cross View Projection Consistency for COVID-19 Projects\",\"url\":\"https://www.semanticscholar.org/paper/029409bcd00b3649b74a5a4cd3078517cedbdbaf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.07637\",\"authors\":[{\"authorId\":\"49724493\",\"name\":\"H. Zhang\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-58565-5_15\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"180d7e45e5fc84138039f738830950dd9b7d0e06\",\"title\":\"Motion-Excited Sampler: Video Adversarial Attack with Sparked Prior\",\"url\":\"https://www.semanticscholar.org/paper/180d7e45e5fc84138039f738830950dd9b7d0e06\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97514733\",\"name\":\"Jin-woo Choi\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"},{\"authorId\":\"1491032137\",\"name\":\"M. Chandraker\"},{\"authorId\":\"50535349\",\"name\":\"J. Huang\"}],\"doi\":\"10.1109/WACV45572.2020.9093511\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6f73e8d3b567b763898342567c332ff821b5f60e\",\"title\":\"Unsupervised and Semi-Supervised Domain Adaptation for Action Recognition from Drones\",\"url\":\"https://www.semanticscholar.org/paper/6f73e8d3b567b763898342567c332ff821b5f60e\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"2006.15489\",\"authors\":[{\"authorId\":\"49984891\",\"name\":\"Ceyuan Yang\"},{\"authorId\":\"121983635\",\"name\":\"Yinghao Xu\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3cb65b26e407e7464223e9568010965fe73ae61f\",\"title\":\"Video Representation Learning with Visual Tempo Consistency\",\"url\":\"https://www.semanticscholar.org/paper/3cb65b26e407e7464223e9568010965fe73ae61f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.06409\",\"authors\":[{\"authorId\":\"1909776\",\"name\":\"Anthony Hu\"},{\"authorId\":\"30467209\",\"name\":\"Fergal Cotter\"},{\"authorId\":\"145536619\",\"name\":\"N. Mohan\"},{\"authorId\":\"31618584\",\"name\":\"C. Gurau\"},{\"authorId\":\"47645184\",\"name\":\"Alex Kendall\"}],\"doi\":\"10.1007/978-3-030-58517-4_45\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a79685e5b72e31405ded418abe8af86166313aa0\",\"title\":\"Probabilistic Future Prediction for Video Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/a79685e5b72e31405ded418abe8af86166313aa0\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1801.03150\",\"authors\":[{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"3298267\",\"name\":\"Sarah Adel Bargal\"},{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"12082007\",\"name\":\"Tom Yan\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"49860655\",\"name\":\"L. Brown\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1109/TPAMI.2019.2901464\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07174c2f209f15cacf9ad3422b48652df286be69\",\"title\":\"Moments in Time Dataset: One Million Videos for Event Understanding\",\"url\":\"https://www.semanticscholar.org/paper/07174c2f209f15cacf9ad3422b48652df286be69\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1912.08077\",\"authors\":[{\"authorId\":\"26988468\",\"name\":\"Diogo C. Luvizon\"},{\"authorId\":\"2397984\",\"name\":\"H. Tabia\"},{\"authorId\":\"145897899\",\"name\":\"D. Picard\"}],\"doi\":\"10.1109/TPAMI.2020.2976014\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"145e426e378b29ea5cf62f5300f337561b3c2784\",\"title\":\"Multi-task Deep Learning for Real-Time 3D Human Pose Estimation and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/145e426e378b29ea5cf62f5300f337561b3c2784\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423738380\",\"name\":\"Zakia Yahya\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"}],\"doi\":\"10.1109/HONET.2019.8908040\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"title\":\"Classification and Temporal Localization of Robbery Events in CCTV Videos through Multi-Stream Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/e188d4e4fa6985a65cfb6e2ca981e4ca3469acad\",\"venue\":\"2019 IEEE 16th International Conference on Smart Cities: Improving Quality of Life Using ICT & IoT and AI (HONET-ICT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"14547418\",\"name\":\"Shengwei Zhou\"},{\"authorId\":\"153555891\",\"name\":\"L. Bai\"},{\"authorId\":\"1500530481\",\"name\":\"Haoran Wang\"},{\"authorId\":\"123580511\",\"name\":\"Zhi-Hong Deng\"},{\"authorId\":\"121330693\",\"name\":\"X. Zhu\"},{\"authorId\":\"143724074\",\"name\":\"C. Gong\"}],\"doi\":\"10.12783/dtcse/cisnrc2019/33302\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"title\":\"A Spatial-temporal Attention Module for 3D Convolution Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f1b8e2c68d93617489b838c223d402fa4f425f8e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2236614\",\"name\":\"W. Liu\"},{\"authorId\":\"145142026\",\"name\":\"Q. Fu\"},{\"authorId\":\"121713026\",\"name\":\"Y. Lu\"},{\"authorId\":\"9253805\",\"name\":\"Jin-yu Sun\"},{\"authorId\":\"144193588\",\"name\":\"Shi-wei Ma\"}],\"doi\":\"10.1117/12.2542195\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"69d3ed6066b177a96a0ef268ae807cde8edaa3b3\",\"title\":\"Video action recognition based on improved 3D convolutional network and sparse representation classification\",\"url\":\"https://www.semanticscholar.org/paper/69d3ed6066b177a96a0ef268ae807cde8edaa3b3\",\"venue\":\"Other Conferences\",\"year\":2019},{\"arxivId\":\"1910.01370\",\"authors\":[{\"authorId\":\"46185180\",\"name\":\"A. Masullo\"},{\"authorId\":\"47158825\",\"name\":\"Tilo Burghardt\"},{\"authorId\":\"2682004\",\"name\":\"T. Perrett\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.1007/978-3-030-27272-2_15\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"95d231ce7283958a96d62fef2598d9a44fb388a9\",\"title\":\"Sit-to-Stand Analysis in the Wild Using Silhouettes for Longitudinal Health Monitoring\",\"url\":\"https://www.semanticscholar.org/paper/95d231ce7283958a96d62fef2598d9a44fb388a9\",\"venue\":\"ICIAR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3281413\",\"name\":\"Diangang Li\"},{\"authorId\":\"49722335\",\"name\":\"Jianquan Liu\"},{\"authorId\":\"1382175791\",\"name\":\"Shoji Nishimura\"},{\"authorId\":\"1993699405\",\"name\":\"Yuka Hayashi\"},{\"authorId\":\"144042991\",\"name\":\"Jun Suzuki\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"}],\"doi\":\"10.1145/3394171.3413801\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2587144054982adc9b4c5adef760f45bf3be0a26\",\"title\":\"Multi-Person Action Recognition in Microwave Sensors\",\"url\":\"https://www.semanticscholar.org/paper/2587144054982adc9b4c5adef760f45bf3be0a26\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9455273\",\"name\":\"Tjeng Wawan Cenggoro\"}],\"doi\":\"10.1109/ICoDSA50139.2020.9212994\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"67bfa1c0e2cfc0dd5a7e7f78cf55c5d4836d3cf0\",\"title\":\"Incorporating the Knowledge Distillation to Improve the EfficientNet Transfer Learning Capability\",\"url\":\"https://www.semanticscholar.org/paper/67bfa1c0e2cfc0dd5a7e7f78cf55c5d4836d3cf0\",\"venue\":\"2020 International Conference on Data Science and Its Applications (ICoDSA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121209369\",\"name\":\"J. Cai\"},{\"authorId\":\"50779096\",\"name\":\"J. Hu\"}],\"doi\":\"10.1007/s00371-019-01733-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"324054c22c974b24bff452cd0144df07665fa00e\",\"title\":\"3D RANs: 3D Residual Attention Networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/324054c22c974b24bff452cd0144df07665fa00e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"2002.09461\",\"authors\":[{\"authorId\":\"1405834398\",\"name\":\"Peng Xu\"},{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"},{\"authorId\":\"79456794\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"145886114\",\"name\":\"Jun Guo\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":\"10.1109/tcsvt.2020.3014491\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b5c8c79a9a943ababce9bd6892da97d297d0b3e1\",\"title\":\"Fine-Grained Instance-Level Sketch-Based Video Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b5c8c79a9a943ababce9bd6892da97d297d0b3e1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47733442\",\"name\":\"Niluthpol Chowdhury Mithun\"},{\"authorId\":\"3428237\",\"name\":\"Juncheng Billy Li\"},{\"authorId\":\"2048745\",\"name\":\"F. Metze\"},{\"authorId\":\"2968713\",\"name\":\"A. Roy-Chowdhury\"}],\"doi\":\"10.1145/3206025.3206064\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dbca9da6a72ba3739813288b677888a6cf76272\",\"title\":\"Learning Joint Embedding with Multimodal Cues for Cross-Modal Video-Text Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/9dbca9da6a72ba3739813288b677888a6cf76272\",\"venue\":\"ICMR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"152245395\",\"name\":\"Zexin Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2933303\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"title\":\"Refined Spatial Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49913895\",\"name\":\"Romain Belmonte\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"title\":\"Facial Landmark Detection with Local and Global Motion Modeling. (D\\u00e9tection des points caract\\u00e9ristiques du visage par mod\\u00e9lisation des mouvements locaux et globaux)\",\"url\":\"https://www.semanticscholar.org/paper/6b7fefd13817bb4b5f028b5f98d69a573d308435\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05410\",\"authors\":[{\"authorId\":\"2295608\",\"name\":\"Y. Wang\"},{\"authorId\":\"143889270\",\"name\":\"V. Tran\"},{\"authorId\":\"3313330\",\"name\":\"Gedas Bertasius\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2356016\",\"name\":\"Minh Hoai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fdff096ae7f7f72a435481e27623ad1a6276900b\",\"title\":\"Attentive Action and Context Factorization\",\"url\":\"https://www.semanticscholar.org/paper/fdff096ae7f7f72a435481e27623ad1a6276900b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2004.11623\",\"authors\":[{\"authorId\":\"10792639\",\"name\":\"Maarten Vandersteegen\"},{\"authorId\":\"1656709277\",\"name\":\"Wouter Reusen\"},{\"authorId\":\"2321568\",\"name\":\"Kristof Van Beeck\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1109/CVPRW50498.2020.00057\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"db922731bf1469a525f72bbc71eb229a853b0c93\",\"title\":\"Low-latency hand gesture recognition with a low resolution thermal imager\",\"url\":\"https://www.semanticscholar.org/paper/db922731bf1469a525f72bbc71eb229a853b0c93\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2008.13426\",\"authors\":[{\"authorId\":\"46584859\",\"name\":\"Jiangliu Wang\"},{\"authorId\":\"2840852\",\"name\":\"Jianbo Jiao\"},{\"authorId\":\"2780029\",\"name\":\"Linchao Bao\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1654091065\",\"name\":\"Wei Liu\"},{\"authorId\":\"47908910\",\"name\":\"Y. Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"b38e482488359da26a25ed9ef5341cd38a2b6562\",\"title\":\"Self-supervised Video Representation Learning by Uncovering Spatio-temporal Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b38e482488359da26a25ed9ef5341cd38a2b6562\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"38df033adc8b89ad02a638db823be439260113bd\",\"title\":\"Tiny Video Networks: Architecture Search for Efficient Video Models\",\"url\":\"https://www.semanticscholar.org/paper/38df033adc8b89ad02a638db823be439260113bd\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150358371\",\"name\":\"Zhiyong Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4ef4417e61687aee0196573d0c29422bc9ac225f\",\"title\":\"DeepFuse: HKU\\u2019s Multimodal Machine Translation System for VMT\\u201920\",\"url\":\"https://www.semanticscholar.org/paper/4ef4417e61687aee0196573d0c29422bc9ac225f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.10000\",\"authors\":[{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"46721825\",\"name\":\"U. Iqbal\"},{\"authorId\":\"34761498\",\"name\":\"A. Milan\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"2299109\",\"name\":\"L. Pishchulin\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/CVPR.2018.00542\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"09b2e7af73689dbdba1547e19111a6ee06767906\",\"title\":\"PoseTrack: A Benchmark for Human Pose Estimation and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/09b2e7af73689dbdba1547e19111a6ee06767906\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"},{\"authorId\":\"113011036\",\"name\":\"Kun-Hsuan Wu\"}],\"doi\":\"10.1109/ICASSP.2019.8682450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"title\":\"Multi-teacher Knowledge Distillation for Compressed Video Action Recognition on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1908.08916\",\"authors\":[{\"authorId\":\"40478348\",\"name\":\"Dong Cao\"},{\"authorId\":\"49287317\",\"name\":\"Lisha Xu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cebe8d2fda288261f4f6206a58d4f52a15f351c6\",\"title\":\"Cross-Enhancement Transform Two-Stream 3D ConvNets for Pedestrian Action Recognition of Autonomous Vehicles\",\"url\":\"https://www.semanticscholar.org/paper/cebe8d2fda288261f4f6206a58d4f52a15f351c6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646959833\",\"name\":\"Yuecong Min\"},{\"authorId\":\"152550038\",\"name\":\"Xiujuan Chai\"},{\"authorId\":\"9055516\",\"name\":\"L. Zhao\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb74477f987459e27bc6b667b4535c378442bd6b\",\"title\":\"FlickerNet: Adaptive 3D Gesture Recognition from Sparse Point Clouds\",\"url\":\"https://www.semanticscholar.org/paper/fb74477f987459e27bc6b667b4535c378442bd6b\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2014145\",\"name\":\"Mohammad Tavakolian\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"46606565\",\"name\":\"A. Hadid\"}],\"doi\":\"10.1109/ICCV.2019.00811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acd1e0773799658a4481693220f38157f204f9bf\",\"title\":\"AWSD: Adaptive Weighted Spatiotemporal Distillation for Video Representation\",\"url\":\"https://www.semanticscholar.org/paper/acd1e0773799658a4481693220f38157f204f9bf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38962424\",\"name\":\"Raghav Goyal\"},{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"40586522\",\"name\":\"Guillaume Berger\"},{\"authorId\":\"3462264\",\"name\":\"Waseem Gharbieh\"},{\"authorId\":\"2443288\",\"name\":\"I. Bax\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b9ac1c21d8dc68643bf214338ff75e554191ccd2\",\"title\":\"Evaluating visual \\\"common sense\\\" using fine-grained classification and captioning tasks\",\"url\":\"https://www.semanticscholar.org/paper/b9ac1c21d8dc68643bf214338ff75e554191ccd2\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1812.06145\",\"authors\":[{\"authorId\":\"3152993\",\"name\":\"Mahdi Abavisani\"},{\"authorId\":\"3227254\",\"name\":\"Hamid Reza Vaezi Joze\"},{\"authorId\":\"1741177\",\"name\":\"V. Patel\"}],\"doi\":\"10.1109/CVPR.2019.00126\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae\",\"title\":\"Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition With Multimodal Training\",\"url\":\"https://www.semanticscholar.org/paper/7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145359181\",\"name\":\"Yang Yi\"},{\"authorId\":\"145688138\",\"name\":\"Feng Ni\"},{\"authorId\":\"15470287\",\"name\":\"Yuexin Ma\"},{\"authorId\":\"22689408\",\"name\":\"Xinge Zhu\"},{\"authorId\":\"35653798\",\"name\":\"Yuankai Qi\"},{\"authorId\":\"51177968\",\"name\":\"Riming Qiu\"},{\"authorId\":\"2946035\",\"name\":\"Shijie Zhao\"},{\"authorId\":\"143806294\",\"name\":\"Feng Li\"},{\"authorId\":null,\"name\":\"Yongtao Wang\"}],\"doi\":\"10.24963/ijcai.2019/141\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"title\":\"High Performance Gesture Recognition via Effective and Efficient Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/40060755a791a85a6b9c61bd0f5d859b3a3417a6\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921425\",\"name\":\"D. Thaker\"},{\"authorId\":\"46800227\",\"name\":\"K. Krishnakumar\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"75768ff4129ca6cd122c5ca729e9cfc66cc798fe\",\"title\":\"k-Shot Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/75768ff4129ca6cd122c5ca729e9cfc66cc798fe\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1910.04641\",\"authors\":[{\"authorId\":\"1387989010\",\"name\":\"Fida Mohammad Thoker\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/ICIP.2019.8802909\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ac32b94a87b145cd82521ddaf5954f261799e28e\",\"title\":\"Cross-Modal Knowledge Distillation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ac32b94a87b145cd82521ddaf5954f261799e28e\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1904.01665\",\"authors\":[{\"authorId\":\"3469030\",\"name\":\"Zhenheng Yang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"144862593\",\"name\":\"R. Nevatia\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"}],\"doi\":\"10.1109/CVPR.2019.00303\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fbd8bd944f883f465679248493bc097a4b7ab4ef\",\"title\":\"Activity Driven Weakly Supervised Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/fbd8bd944f883f465679248493bc097a4b7ab4ef\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"9140376\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"97583844\",\"name\":\"Jian Yu\"},{\"authorId\":\"144116884\",\"name\":\"Qiang Ji\"}],\"doi\":\"10.1109/TIP.2019.2942814\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"title\":\"Deep Reinforcement Learning for Weak Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/47a457d3999a4367a0997075a6a4c2476b4c6cfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9272516\",\"name\":\"Suharjito\"},{\"authorId\":\"66416702\",\"name\":\"Herman Gunawan\"},{\"authorId\":\"66467949\",\"name\":\"Narada Thiracitta\"},{\"authorId\":\"1795227\",\"name\":\"A. Nugroho\"}],\"doi\":\"10.1109/INAPR.2018.8627014\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fe4dbea7d530c21c77137f52fed28c9b0947172b\",\"title\":\"Sign Language Recognition Using Modified Convolutional Neural Network Model\",\"url\":\"https://www.semanticscholar.org/paper/fe4dbea7d530c21c77137f52fed28c9b0947172b\",\"venue\":\"2018 Indonesian Association for Pattern Recognition International Conference (INAPR)\",\"year\":2018},{\"arxivId\":\"1904.07850\",\"authors\":[{\"authorId\":\"3422097\",\"name\":\"Xingyi Zhou\"},{\"authorId\":\"2774612\",\"name\":\"Dequan Wang\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6a2e2fd1b5bb11224daef98b3fb6d029f68a73f2\",\"title\":\"Objects as Points\",\"url\":\"https://www.semanticscholar.org/paper/6a2e2fd1b5bb11224daef98b3fb6d029f68a73f2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31176543\",\"name\":\"Juan Buhagiar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43b4b13f1a928834b4f5eed725305a60d9ba6641\",\"title\":\"Temporal localization of actions in untrimmed videos\",\"url\":\"https://www.semanticscholar.org/paper/43b4b13f1a928834b4f5eed725305a60d9ba6641\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390421338\",\"name\":\"Sheng Yu\"},{\"authorId\":\"1400233791\",\"name\":\"Li Xie\"},{\"authorId\":\"152644954\",\"name\":\"Lin Liu\"},{\"authorId\":\"9340242\",\"name\":\"Daoxun Xia\"}],\"doi\":\"10.1109/ACCESS.2019.2962284\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"title\":\"Learning Long-Term Temporal Features With Deep Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/179a116f3fb59dac65c974f94ad92e21eaf011a1\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3073314\",\"name\":\"Yongqing Sun\"},{\"authorId\":\"93400480\",\"name\":\"X. Chen\"},{\"authorId\":\"1500383826\",\"name\":\"Chaoyu Li\"},{\"authorId\":\"97711590\",\"name\":\"Kiyohito Sawada\"},{\"authorId\":\"1849035\",\"name\":\"T. Hosono\"},{\"authorId\":\"145254056\",\"name\":\"J. Zhu\"},{\"authorId\":\"47415770\",\"name\":\"Chengjuan Xie\"},{\"authorId\":\"145429677\",\"name\":\"Sixiang Huang\"},{\"authorId\":\"100807603\",\"name\":\"Lan Wang\"},{\"authorId\":\"143993120\",\"name\":\"Kai Hu\"},{\"authorId\":\"144179287\",\"name\":\"Qingsong Zhou\"},{\"authorId\":\"145196759\",\"name\":\"Chenqiang Gao\"},{\"authorId\":\"145475359\",\"name\":\"Jun Shimamura\"},{\"authorId\":\"2969978\",\"name\":\"Atsushi Sagata\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b682a9104ade8b143633a475ad8d6a6a50cb88\",\"title\":\"NTT_CQUPT@TRECVID2019 ActEV: Activities in Extended Video\",\"url\":\"https://www.semanticscholar.org/paper/71b682a9104ade8b143633a475ad8d6a6a50cb88\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"title\":\"POLITECNICO DI TORINO Master of Science in Mathematical Engineering Deep Learning Algorithms for Video Classification: Application on Real-Time Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/08d9bea632aa3e32fe6b5436b147edacb69e4660\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1739631130\",\"name\":\"Fanjia Li\"},{\"authorId\":\"2643261\",\"name\":\"A. Zhu\"},{\"authorId\":\"50125448\",\"name\":\"Yonggang Xu\"},{\"authorId\":\"8159002\",\"name\":\"Ran Cui\"},{\"authorId\":\"49195402\",\"name\":\"Gang Hua\"}],\"doi\":\"10.1109/ACCESS.2020.2996779\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2580a93582f9a28bf66982cfa51022089a6e337b\",\"title\":\"Multi-Stream and Enhanced Spatial-Temporal Graph Convolution Network for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2580a93582f9a28bf66982cfa51022089a6e337b\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.07442\",\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"df2f2591054080d069e563cb9ca4e0592bc6df08\",\"title\":\"V4D: 4D Convolutional Neural Networks for Video-level Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/df2f2591054080d069e563cb9ca4e0592bc6df08\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2012.03212\",\"authors\":[{\"authorId\":\"2032227478\",\"name\":\"Lior Gelberg\"},{\"authorId\":\"2963236\",\"name\":\"D. Mendlovic\"},{\"authorId\":\"2283049\",\"name\":\"Dan Raviv\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"77495264f33629a76458e52b7f59ba8e71725244\",\"title\":\"Skeleon-Based Typing Style Learning For Person Identification\",\"url\":\"https://www.semanticscholar.org/paper/77495264f33629a76458e52b7f59ba8e71725244\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83677221\",\"name\":\"L. Shiripova\"},{\"authorId\":\"1827361\",\"name\":\"E. V. Myasnikov\"}],\"doi\":\"10.18287/1613-0073-2019-2391-48-53\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e754c289ce5a057e9e4c40d8d7bd128e5c2ae34e\",\"title\":\"Human action recognition using dimensionality reduction and support vector machine\",\"url\":\"https://www.semanticscholar.org/paper/e754c289ce5a057e9e4c40d8d7bd128e5c2ae34e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1910.12770\",\"authors\":[{\"authorId\":\"1388811741\",\"name\":\"Alaaeldin El-Nouby\"},{\"authorId\":\"2443456\",\"name\":\"Shuangfei Zhai\"},{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"49158771\",\"name\":\"J. Susskind\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ab402a45266620d4c41218242be5d5ddf1f63ca\",\"title\":\"Skip-Clip: Self-Supervised Spatiotemporal Representation Learning by Future Clip Order Ranking\",\"url\":\"https://www.semanticscholar.org/paper/6ab402a45266620d4c41218242be5d5ddf1f63ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"},{\"authorId\":\"1959406969\",\"name\":\"Teppei Suzuki\"},{\"authorId\":\"1484094470\",\"name\":\"Kodai Nakashima\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"}],\"doi\":\"10.1109/ICRA40945.2020.9197399\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7422c29fc16151913940b0dad2eb5baec0e2dfa9\",\"title\":\"Joint Pedestrian Detection and Risk-level Prediction with Motion-Representation-by-Detection\",\"url\":\"https://www.semanticscholar.org/paper/7422c29fc16151913940b0dad2eb5baec0e2dfa9\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1778986\",\"name\":\"Wanru Xu\"},{\"authorId\":\"49402429\",\"name\":\"J. Yu\"},{\"authorId\":\"46533851\",\"name\":\"Zhenjiang Miao\"},{\"authorId\":\"40322073\",\"name\":\"L. Wan\"},{\"authorId\":\"50426357\",\"name\":\"Q. Ji\"}],\"doi\":\"10.1109/TCSVT.2019.2919064\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"10129da014606c70b6fab077319491c772b01c04\",\"title\":\"Spatio-Temporal Deep Q-Networks for Human Activity Localization\",\"url\":\"https://www.semanticscholar.org/paper/10129da014606c70b6fab077319491c772b01c04\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2003.12224\",\"authors\":[{\"authorId\":\"1486397342\",\"name\":\"Zhizheng Zhang\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"143912275\",\"name\":\"Zhibo Chen\"}],\"doi\":\"10.1109/cvpr42600.2020.01042\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c31527844d90c2c877e9816ce86541a9258ae0a\",\"title\":\"Multi-Granularity Reference-Aided Attentive Feature Aggregation for Video-Based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/8c31527844d90c2c877e9816ce86541a9258ae0a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2005.02113\",\"authors\":[{\"authorId\":\"47892681\",\"name\":\"Haoxin Li\"},{\"authorId\":\"3333315\",\"name\":\"W. Zheng\"},{\"authorId\":\"1401057385\",\"name\":\"Yu Tao\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"153224231\",\"name\":\"Jianhuang Lai\"}],\"doi\":\"10.1109/CVPR42600.2020.00060\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"title\":\"Adaptive Interaction Modeling via Graph Operations Search\",\"url\":\"https://www.semanticscholar.org/paper/5c02af517dff2ff0d34dee04535731b7d252bbbb\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121638702\",\"name\":\"Jungin Park\"},{\"authorId\":\"82536700\",\"name\":\"J. Lee\"},{\"authorId\":\"9535835\",\"name\":\"Sangryul Jeon\"},{\"authorId\":\"144442279\",\"name\":\"K. Sohn\"}],\"doi\":\"10.1109/ICCVW.2019.00193\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"title\":\"Video Summarization by Learning Relationships between Action and Scene\",\"url\":\"https://www.semanticscholar.org/paper/62d6e66c6a97540064c3de51b455cdc8fd7f0bdc\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"7992455\",\"name\":\"W. Shim\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1109/ICCVW.2019.00192\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f8de23a4528ae7f569161d295cbda1619d28abca\",\"title\":\"Temporal U-Nets for Video Summarization with Scene and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f8de23a4528ae7f569161d295cbda1619d28abca\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2008.00932\",\"authors\":[{\"authorId\":\"73263377\",\"name\":\"Ozge Mercanoglu Sincan\"},{\"authorId\":\"2987805\",\"name\":\"Hacer Yalim Keles\"}],\"doi\":\"10.1109/ACCESS.2020.3028072\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad74c71ed8eecf4a5e5f2c448f46292980a52227\",\"title\":\"AUTSL: A Large Scale Multi-Modal Turkish Sign Language Dataset and Baseline Methods\",\"url\":\"https://www.semanticscholar.org/paper/ad74c71ed8eecf4a5e5f2c448f46292980a52227\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1806.04391\",\"authors\":[{\"authorId\":\"9642011\",\"name\":\"Xiaoteng Zhang\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"3369242\",\"name\":\"F. Zhang\"},{\"authorId\":\"143993120\",\"name\":\"K. Hu\"},{\"authorId\":\"3100759\",\"name\":\"Yicheng Wang\"},{\"authorId\":\"144061928\",\"name\":\"L. Zhu\"},{\"authorId\":\"48900060\",\"name\":\"Qinzhu He\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"593045f63de1273d116097eeea6fda7aa244e74d\",\"title\":\"Qiniu Submission to ActivityNet Challenge 2018\",\"url\":\"https://www.semanticscholar.org/paper/593045f63de1273d116097eeea6fda7aa244e74d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9369513\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"50876944\",\"name\":\"Ashraf Siddique\"},{\"authorId\":\"101481224\",\"name\":\"Md. Imtiaz Hossain\"},{\"authorId\":\"81133680\",\"name\":\"Md. Sohorab Hossain\"},{\"authorId\":\"1705900\",\"name\":\"E. Huh\"}],\"doi\":\"10.1109/ACCESS.2020.3037529\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"title\":\"Batch Entropy Supervised Convolutional Neural Networks for Feature Extraction and Harmonizing for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2b4d7724aecdd21451648b84bff065132fc6e9d9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2010.05468\",\"authors\":[{\"authorId\":\"2981509\",\"name\":\"Dongxu Li\"},{\"authorId\":\"49770180\",\"name\":\"Chenchen Xu\"},{\"authorId\":\"1490933487\",\"name\":\"Xin Yu\"},{\"authorId\":\"3397429\",\"name\":\"K. Zhang\"},{\"authorId\":\"1402604708\",\"name\":\"Ben Swift\"},{\"authorId\":\"1387047136\",\"name\":\"Hanna Suominen\"},{\"authorId\":\"71200893\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"16091f0821502b70294ef66671183dadd1afcdc0\",\"title\":\"TSPNet: Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation\",\"url\":\"https://www.semanticscholar.org/paper/16091f0821502b70294ef66671183dadd1afcdc0\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2001.05691\",\"authors\":[{\"authorId\":\"122460701\",\"name\":\"Tianhao Li\"},{\"authorId\":\"119770705\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2783c13471060300e62a1eed458d9d2888b5b5be\",\"title\":\"Learning Spatiotemporal Features via Video and Text Pair Discrimination\",\"url\":\"https://www.semanticscholar.org/paper/2783c13471060300e62a1eed458d9d2888b5b5be\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.02306\",\"authors\":[{\"authorId\":\"40917135\",\"name\":\"Isabel Funke\"},{\"authorId\":\"3591119\",\"name\":\"S. T. Mees\"},{\"authorId\":\"143997712\",\"name\":\"J. Weitz\"},{\"authorId\":\"47515221\",\"name\":\"S. Speidel\"}],\"doi\":\"10.1007/s11548-019-01995-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7972d64ceb58cc8ab5a439f52d1d137be640a54b\",\"title\":\"Video-based surgical skill assessment using 3D\\u00a0convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/7972d64ceb58cc8ab5a439f52d1d137be640a54b\",\"venue\":\"International Journal of Computer Assisted Radiology and Surgery\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3136303\",\"name\":\"G. Cong\"},{\"authorId\":\"2972684\",\"name\":\"G. Domeniconi\"},{\"authorId\":\"47377263\",\"name\":\"Joshua Shapiro\"},{\"authorId\":\"34765265\",\"name\":\"C. Yang\"},{\"authorId\":\"144969569\",\"name\":\"B. Chen\"}],\"doi\":\"10.1109/WACV.2019.00013\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"dcdf68e007737ebae40e27239b3340b236337f03\",\"title\":\"Video Action Recognition With an Additional End-to-End Trained Temporal Stream\",\"url\":\"https://www.semanticscholar.org/paper/dcdf68e007737ebae40e27239b3340b236337f03\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":\"1905.00561\",\"authors\":[{\"authorId\":\"2028234\",\"name\":\"Deepti Ghadiyaram\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"11529694\",\"name\":\"Xueting Yan\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":\"10.1109/CVPR.2019.01232\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"title\":\"Large-Scale Weakly-Supervised Pre-Training for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4cbaea4c21e15312ef2aeb9529a39baa48bbb522\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626541\",\"name\":\"Ziming Liu\"},{\"authorId\":\"47296615\",\"name\":\"Guangyu Gao\"},{\"authorId\":\"1380212680\",\"name\":\"A. K. Qin\"},{\"authorId\":\"150325884\",\"name\":\"T. Wu\"},{\"authorId\":\"1390585158\",\"name\":\"Chi Harold Liu\"}],\"doi\":\"10.1145/3343031.3350916\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"554d3d5cdffa7e2aa292504d4d4507af498e30d2\",\"title\":\"Action Recognition with Bootstrapping based Long-range Temporal Context Attention\",\"url\":\"https://www.semanticscholar.org/paper/554d3d5cdffa7e2aa292504d4d4507af498e30d2\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2004.03545\",\"authors\":[{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2342663\",\"name\":\"H. Xu\"},{\"authorId\":\"51026885\",\"name\":\"W. Huang\"},{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/cvpr42600.2020.01030\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"355403d7ce4b625307fd3ebb2beea269ecc15213\",\"title\":\"Dense Regression Network for Video Grounding\",\"url\":\"https://www.semanticscholar.org/paper/355403d7ce4b625307fd3ebb2beea269ecc15213\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.00180\",\"authors\":[{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"2683916\",\"name\":\"Lizhi Yang\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"title\":\"Spatio-Temporal Action Detection with Multi-Object Interaction\",\"url\":\"https://www.semanticscholar.org/paper/fe9d2d14143e13e20cc318d4483a2a750a5ec55b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1903.02155\",\"authors\":[{\"authorId\":\"144770282\",\"name\":\"D. Xie\"},{\"authorId\":\"145102437\",\"name\":\"Cheng Deng\"},{\"authorId\":\"49528465\",\"name\":\"Hao Wang\"},{\"authorId\":\"66140038\",\"name\":\"Chao Li\"},{\"authorId\":\"1701119\",\"name\":\"Dapeng Tao\"}],\"doi\":\"10.1609/AAAI.V33I01.33019030\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"title\":\"Semantic Adversarial Network with Multi-scale Pyramid Attention for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/19458fa0d29181cc3f72f5f1253b64ba0e02e5f3\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"2001.05833\",\"authors\":[{\"authorId\":\"48378653\",\"name\":\"Yongxue Zhang\"},{\"authorId\":\"47074522\",\"name\":\"C. Wang\"},{\"authorId\":\"153697497\",\"name\":\"Y. Zheng\"},{\"authorId\":\"33524946\",\"name\":\"Jieyu Zhao\"},{\"authorId\":\"50023941\",\"name\":\"Y. Li\"},{\"authorId\":\"2391806\",\"name\":\"Xijiong Xie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"17837906e7349d3bdbb17ae2cc24348d10762388\",\"title\":\"Short-Term Temporal Convolutional Networks for Dynamic Hand Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/17837906e7349d3bdbb17ae2cc24348d10762388\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993702018\",\"name\":\"Yashaswi Rauthan\"},{\"authorId\":\"1993550053\",\"name\":\"Vatsala Singh\"},{\"authorId\":\"48352874\",\"name\":\"Rishabh Agrawal\"},{\"authorId\":\"1993696456\",\"name\":\"Satej Kadlay\"},{\"authorId\":\"2072630\",\"name\":\"N. Pedanekar\"},{\"authorId\":\"2973267\",\"name\":\"Shirish S. Karande\"},{\"authorId\":\"1993677784\",\"name\":\"Manasi Malik\"},{\"authorId\":\"1993660153\",\"name\":\"Iaphi Tariang\"}],\"doi\":\"10.1145/3422839.3423065\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbfb6d73de94c09c17ce39fd9bb268728315faf4\",\"title\":\"Avoid Crowding in the Battlefield: Semantic Placement of Social Messages in Entertainment Programs\",\"url\":\"https://www.semanticscholar.org/paper/dbfb6d73de94c09c17ce39fd9bb268728315faf4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.06203\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2019.00022\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"title\":\"TAN: Temporal Aggregation Network for Dense Multi-Label Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"144957598\",\"name\":\"K. Li\"},{\"authorId\":\"47120598\",\"name\":\"X. Wang\"}],\"doi\":\"10.24963/ijcai.2018/112\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ac1c192f920fa501175d1edc187db1d31dc97c03\",\"title\":\"Deeply-Supervised CNN Model for Action Recognition with Trainable Feature Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/ac1c192f920fa501175d1edc187db1d31dc97c03\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1706.06905\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"title\":\"Learnable pooling with Context Gating for video classification\",\"url\":\"https://www.semanticscholar.org/paper/1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"49659001\",\"name\":\"Zheng Zhu\"},{\"authorId\":\"1736595\",\"name\":\"Yiming Hu\"}],\"doi\":\"10.1016/j.neucom.2019.08.043\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30fc6edf2c499025b26dc0e55e95af03c35d34d5\",\"title\":\"Convolutional relation network for skeleton-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/30fc6edf2c499025b26dc0e55e95af03c35d34d5\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50159305\",\"name\":\"T. Kobayashi\"},{\"authorId\":\"10664005\",\"name\":\"Y. Aoki\"},{\"authorId\":\"46384962\",\"name\":\"Shogo Shimizu\"},{\"authorId\":\"101212771\",\"name\":\"Katsuhiro Kusano\"},{\"authorId\":\"1642317805\",\"name\":\"Seiji Okumura\"}],\"doi\":\"10.1109/SITIS.2019.00077\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65d39cc70b06559c70a020b1d62db36566707567\",\"title\":\"Fine-Grained Action Recognition in Assembly Work Scenes by Drawing Attention to the Hands\",\"url\":\"https://www.semanticscholar.org/paper/65d39cc70b06559c70a020b1d62db36566707567\",\"venue\":\"2019 15th International Conference on Signal-Image Technology & Internet-Based Systems (SITIS)\",\"year\":2019},{\"arxivId\":\"1912.09857\",\"authors\":[{\"authorId\":\"123183952\",\"name\":\"Bennet Breier\"},{\"authorId\":\"1950866\",\"name\":\"A. Onken\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ae922b26e35895891c275bb5ed880bb588671b6b\",\"title\":\"Analysis of Video Feature Learning in Two-Stream CNNs on the Example of Zebrafish Swim Bout Classification\",\"url\":\"https://www.semanticscholar.org/paper/ae922b26e35895891c275bb5ed880bb588671b6b\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2006.15560\",\"authors\":[{\"authorId\":\"1391155455\",\"name\":\"Yin-Dong Zheng\"},{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/TIP.2020.3007826\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"3ee328e73acc9be44d874756dab4c13c65a835c0\",\"title\":\"Dynamic Sampling Networks for Efficient Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3ee328e73acc9be44d874756dab4c13c65a835c0\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1902.03604\",\"authors\":[{\"authorId\":\"2767859\",\"name\":\"P. Voigtlaender\"},{\"authorId\":\"144410055\",\"name\":\"M. Krause\"},{\"authorId\":\"3331304\",\"name\":\"Aljosa Osep\"},{\"authorId\":\"31553652\",\"name\":\"Jonathon Luiten\"},{\"authorId\":\"69984537\",\"name\":\"Berin Balachandar Gnana Sekar\"},{\"authorId\":\"47237027\",\"name\":\"Andreas Geiger\"},{\"authorId\":\"1789756\",\"name\":\"B. Leibe\"}],\"doi\":\"10.1109/CVPR.2019.00813\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddb80e2c3e1c2ba012ff33bafaef86f02b7275b0\",\"title\":\"MOTS: Multi-Object Tracking and Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ddb80e2c3e1c2ba012ff33bafaef86f02b7275b0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.07391\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"1759094\",\"name\":\"Mingfei Gao\"},{\"authorId\":\"27018486\",\"name\":\"Y. Chen\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/ICCV.2019.00563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bcaa81e2150dffcb5dc7bc785285444570443b80\",\"title\":\"Temporal Recurrent Networks for Online Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/bcaa81e2150dffcb5dc7bc785285444570443b80\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1811.10636\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"145426908\",\"name\":\"A. Angelova\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/ICCV.2019.00188\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"title\":\"Evolving Space-Time Neural Architectures for Videos\",\"url\":\"https://www.semanticscholar.org/paper/793ba81fa3bc728e9e35e0f82a8c4286d61d3aff\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.03270\",\"authors\":[{\"authorId\":\"1726109879\",\"name\":\"Xiang Wang\"},{\"authorId\":\"40115662\",\"name\":\"Changxin Gao\"},{\"authorId\":\"50202110\",\"name\":\"Shiwei Zhang\"},{\"authorId\":\"1707161\",\"name\":\"N. Sang\"}],\"doi\":\"10.1007/978-3-030-60639-8_4\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"title\":\"Multi-level Temporal Pyramid Network for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/27f888dae7f9d4cb67e79cbebdab238be7186eff\",\"venue\":\"PRCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145380510\",\"name\":\"L. Rossetto\"},{\"authorId\":\"145779317\",\"name\":\"R. Gasser\"},{\"authorId\":\"1693655\",\"name\":\"Jakub Loko\\u010d\"},{\"authorId\":\"35537256\",\"name\":\"W. Bailer\"},{\"authorId\":\"1937120\",\"name\":\"K. Sch\\u00f6ffmann\"},{\"authorId\":\"2251616\",\"name\":\"Bernd M\\u00fcnzer\"},{\"authorId\":\"40037607\",\"name\":\"T. Soucek\"},{\"authorId\":\"32860700\",\"name\":\"P. Nguyen\"},{\"authorId\":\"1982596\",\"name\":\"Paolo Bolettieri\"},{\"authorId\":\"3403185\",\"name\":\"A. Leibetseder\"},{\"authorId\":\"1381295446\",\"name\":\"S. Vrochidis\"}],\"doi\":\"10.1109/TMM.2020.2980944\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67ea56e031a77eed8214bede62c52004e201cb9f\",\"title\":\"Interactive Video Retrieval in the Age of Deep Learning \\u2013 Detailed Evaluation of VBS 2019\",\"url\":\"https://www.semanticscholar.org/paper/67ea56e031a77eed8214bede62c52004e201cb9f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":\"2002.03137\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"47096706\",\"name\":\"Y. Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":\"10.1609/AAAI.V34I07.6907\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4bca2665f80765d25e71796c928dd20963e0b26e\",\"title\":\"Symbiotic Attention with Privileged Information for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bca2665f80765d25e71796c928dd20963e0b26e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.01220\",\"authors\":[{\"authorId\":\"1986291097\",\"name\":\"Giovanni Bellitto\"},{\"authorId\":\"1985894550\",\"name\":\"Federica Proietto Salanitri\"},{\"authorId\":\"1409705906\",\"name\":\"S. Palazzo\"},{\"authorId\":\"50528328\",\"name\":\"F. Rundo\"},{\"authorId\":\"35906202\",\"name\":\"D. Giordano\"},{\"authorId\":\"2441118\",\"name\":\"C. Spampinato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"36081963c58871adc8706e2cfcbf94872a42c5ae\",\"title\":\"Video Saliency Detection with Domain Adaptation using Hierarchical Gradient Reversal Layers\",\"url\":\"https://www.semanticscholar.org/paper/36081963c58871adc8706e2cfcbf94872a42c5ae\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"77281176\",\"name\":\"M. Martin\"},{\"authorId\":\"1430776903\",\"name\":\"Michael Voit\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ITSC45102.2020.9294520\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb71dc1b83e57be1d15e1592ac590f48f0b86403\",\"title\":\"Dynamic Interaction Graphs for Driver Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb71dc1b83e57be1d15e1592ac590f48f0b86403\",\"venue\":\"2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC)\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.12384\",\"authors\":[{\"authorId\":\"9385903\",\"name\":\"S. Zhu\"},{\"authorId\":\"1390892946\",\"name\":\"Taojiannan Yang\"},{\"authorId\":\"1422036273\",\"name\":\"Mat'ias Mendieta\"},{\"authorId\":\"143916976\",\"name\":\"Chen Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ba1dda6494709cac7c48c95c81afff7a087f2031\",\"title\":\"A3D: Adaptive 3D Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ba1dda6494709cac7c48c95c81afff7a087f2031\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.08497\",\"authors\":[{\"authorId\":\"3216509\",\"name\":\"L. Zaadnoordijk\"},{\"authorId\":\"143862012\",\"name\":\"Tarek R. Besold\"},{\"authorId\":\"145234732\",\"name\":\"R. Cusack\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"106c718286812b3cdeb764934ed76b5108d7f7bc\",\"title\":\"The Next Big Thing(s) in Unsupervised Machine Learning: Five Lessons from Infant Learning\",\"url\":\"https://www.semanticscholar.org/paper/106c718286812b3cdeb764934ed76b5108d7f7bc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1643682004\",\"name\":\"He Zhao\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":\"10.1007/978-3-030-58526-6_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bd941a3cb2664715269cbbd30a4df6828799ac01\",\"title\":\"On Diverse Asynchronous Activity Anticipation\",\"url\":\"https://www.semanticscholar.org/paper/bd941a3cb2664715269cbbd30a4df6828799ac01\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.05596\",\"authors\":[{\"authorId\":\"50112310\",\"name\":\"Alex Andonian\"},{\"authorId\":\"1482544048\",\"name\":\"Camilo Fosco\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"123872529\",\"name\":\"Allen Lee\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"1856025\",\"name\":\"Carl Vondrick\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1007/978-3-030-58523-5_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"33c723f096c3fd156e32295325afc2e6081afac4\",\"title\":\"We Have So Much In Common: Modeling Semantic Relational Set Abstractions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/33c723f096c3fd156e32295325afc2e6081afac4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2008.05058\",\"authors\":[{\"authorId\":\"1872001351\",\"name\":\"Borna Bevsi'c\"},{\"authorId\":\"2609831\",\"name\":\"Abhinav Valada\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"45f50ebcaa5a230d5a9611aa6676881a56398ae7\",\"title\":\"Dynamic Object Removal and Spatio-Temporal RGB-D Inpainting via Geometry-Aware Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/45f50ebcaa5a230d5a9611aa6676881a56398ae7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145110338\",\"name\":\"Tao Liang\"},{\"authorId\":\"23110616\",\"name\":\"P. Chen\"},{\"authorId\":\"88011662\",\"name\":\"Guangzhi Zhou\"},{\"authorId\":\"2755326\",\"name\":\"Hongchao Gao\"},{\"authorId\":null,\"name\":\"Jin Liu\"},{\"authorId\":\"5448024\",\"name\":\"Z. Li\"},{\"authorId\":\"151475818\",\"name\":\"Jiao Dai\"}],\"doi\":\"10.1109/ICTAI50040.2020.00108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a13029da465ca41905a5594eb879229a49740d3d\",\"title\":\"SDHF: Spotting DeepFakes with Hierarchical Features\",\"url\":\"https://www.semanticscholar.org/paper/a13029da465ca41905a5594eb879229a49740d3d\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":\"2008.03548\",\"authors\":[{\"authorId\":\"36290866\",\"name\":\"Anyi Rao\"},{\"authorId\":\"1557390077\",\"name\":\"Jiaze Wang\"},{\"authorId\":\"150196512\",\"name\":\"Linning Xu\"},{\"authorId\":\"80180784\",\"name\":\"Xuekun Jiang\"},{\"authorId\":\"39360892\",\"name\":\"Q. Huang\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-58621-8_2\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"title\":\"A Unified Framework for Shot Type Classification Based on Subject Centric Lens\",\"url\":\"https://www.semanticscholar.org/paper/49b2d6f498bde324151cc5d0f8a9bba70540efbd\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.01018\",\"authors\":[{\"authorId\":\"71013766\",\"name\":\"Mathilde Brousmiche\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"},{\"authorId\":\"1640427539\",\"name\":\"Jean Rouat\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d3f5b5b3aaa25a7ea302d8fc6cbae7054315961\",\"title\":\"AVECL-UMONS database for audio-visual event classification and localization\",\"url\":\"https://www.semanticscholar.org/paper/2d3f5b5b3aaa25a7ea302d8fc6cbae7054315961\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.12434\",\"authors\":[{\"authorId\":\"144701907\",\"name\":\"G. Elahi\"},{\"authorId\":\"35964920\",\"name\":\"Yee-Hong Yang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"048de3aa58e86791aa61ae08316e823528ee11f6\",\"title\":\"Online Learnable Keyframe Extraction in Videos and its Application with Semantic Word Vector in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/048de3aa58e86791aa61ae08316e823528ee11f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152393567\",\"name\":\"B. Wan\"},{\"authorId\":\"50313388\",\"name\":\"Y. Fang\"},{\"authorId\":\"144229534\",\"name\":\"Xue Xia\"},{\"authorId\":\"1878859199\",\"name\":\"Jiajie Mei\"}],\"doi\":\"10.1109/icme46284.2020.9102722\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"49133ffa30e0acaf4ea5bd8bbf68c841b02e3f2a\",\"title\":\"Weakly Supervised Video Anomaly Detection via Center-Guided Discriminative Learning\",\"url\":\"https://www.semanticscholar.org/paper/49133ffa30e0acaf4ea5bd8bbf68c841b02e3f2a\",\"venue\":\"2020 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2020},{\"arxivId\":\"2005.04208\",\"authors\":[{\"authorId\":\"153000035\",\"name\":\"M. Bain\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"152853748\",\"name\":\"A. Brown\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"title\":\"Condensed Movies: Story Based Retrieval with Contextual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/239c34ab213229725c6428e63b1315f2e8cdcbc8\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1912.00998\",\"authors\":[{\"authorId\":\"100880679\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"51506875\",\"name\":\"Philipp Krahenbuhl\"}],\"doi\":\"10.1109/cvpr42600.2020.00023\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"title\":\"A Multigrid Method for Efficiently Training Video Models\",\"url\":\"https://www.semanticscholar.org/paper/b8cc28e11900e4d191651ae7234b4dbd129b1007\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2011.10830\",\"authors\":[{\"authorId\":\"97375393\",\"name\":\"Mengmeng Xu\"},{\"authorId\":\"1397974082\",\"name\":\"Juan-Manuel Perez-Rua\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"2171228\",\"name\":\"Xiatian Zhu\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"145406420\",\"name\":\"Tao Xiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"title\":\"Boundary-sensitive Pre-training for Temporal Localization in Videos\",\"url\":\"https://www.semanticscholar.org/paper/cdc28eb98cd4e5fa28811f4ea6dbe7c64d5fcffe\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65995199\",\"name\":\"Wentao Xie\"},{\"authorId\":\"2886054\",\"name\":\"Guanghui Ren\"},{\"authorId\":\"153318526\",\"name\":\"Si Liu\"}],\"doi\":\"10.1145/3394171.3416284\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9851ab41417d1369af230de32265c5637ea5176\",\"title\":\"Video Relation Detection with Trajectory-aware Multi-modal Features\",\"url\":\"https://www.semanticscholar.org/paper/c9851ab41417d1369af230de32265c5637ea5176\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2011.08722\",\"authors\":[{\"authorId\":\"2025654589\",\"name\":\"Videsh Suman\"},{\"authorId\":\"2718563\",\"name\":\"Aniket Bera\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"5bfb1da715b7bd9115f14d033db092da43706e8c\",\"title\":\"RAIST: Learning Risk Aware Traffic Interactions via Spatio-Temporal Graph Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/5bfb1da715b7bd9115f14d033db092da43706e8c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144406781\",\"name\":\"Lijun He\"},{\"authorId\":\"2035803194\",\"name\":\"Shuai Wen\"},{\"authorId\":\"2199437\",\"name\":\"L. Wang\"},{\"authorId\":\"1825677658\",\"name\":\"Fan Li\"}],\"doi\":\"10.1007/s10489-020-01933-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"title\":\"Vehicle theft recognition from surveillance video based on spatiotemporal attention\",\"url\":\"https://www.semanticscholar.org/paper/eb68cda0fdd2e9fec857ff8016b3a74912ceb57e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1910.00714\",\"authors\":[{\"authorId\":\"65914312\",\"name\":\"Clebeson Canuto dos Santos\"},{\"authorId\":\"1746258\",\"name\":\"P. Moreno\"},{\"authorId\":\"143622442\",\"name\":\"J. A. Samatelo\"},{\"authorId\":\"21859276\",\"name\":\"Raquel Frizera Vassallo\"},{\"authorId\":\"1398909021\",\"name\":\"J. Santos-Victor\"}],\"doi\":\"10.1016/j.neucom.2020.07.135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5569fdf87bab94014615a04c1ad16204180e7d1\",\"title\":\"Action Anticipation for Collaborative Environments: The Impact of Contextual Information and Uncertainty-Based Prediction\",\"url\":\"https://www.semanticscholar.org/paper/d5569fdf87bab94014615a04c1ad16204180e7d1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2035849200\",\"name\":\"Jinyue Zhang\"},{\"authorId\":\"2005762495\",\"name\":\"Lijun Zi\"},{\"authorId\":\"50006930\",\"name\":\"Yue-xian Hou\"},{\"authorId\":\"2004643958\",\"name\":\"Mingen Wang\"},{\"authorId\":\"49408815\",\"name\":\"Wenting Jiang\"},{\"authorId\":\"143727769\",\"name\":\"D. Deng\"}],\"doi\":\"10.1155/2020/8812928\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"54f1b547fda12112d33878aa185f0779c37a8456\",\"title\":\"A Deep Learning-Based Approach to Enable Action Recognition for Construction Equipment\",\"url\":\"https://www.semanticscholar.org/paper/54f1b547fda12112d33878aa185f0779c37a8456\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1905.04430\",\"authors\":[{\"authorId\":\"119352476\",\"name\":\"M. M. K. Moghaddam\"},{\"authorId\":\"8088602\",\"name\":\"Ehsan Abbasnejad\"},{\"authorId\":\"31635758\",\"name\":\"Javen Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"title\":\"Follow the Attention: Combining Partial Pose and Object Motion for Fine-Grained Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/c6e889406f3f85dcb33e90eba2a6dfffbb3c51a1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.10698\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/CVPR.2019.01019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed78a2671ef61c031759c01434678c282f23faec\",\"title\":\"LSTA: Long Short-Term Attention for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1904.11953\",\"authors\":[{\"authorId\":\"1682816\",\"name\":\"Fei Wang\"},{\"authorId\":\"8280915\",\"name\":\"Yunpeng Song\"},{\"authorId\":\"27899522\",\"name\":\"J. Zhang\"},{\"authorId\":\"1783892\",\"name\":\"J. Han\"},{\"authorId\":\"145252513\",\"name\":\"Dong Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"61367718a07bafbd696871be25e11815f1dd85c4\",\"title\":\"Temporal Unet: Sample Level Human Action Recognition using WiFi\",\"url\":\"https://www.semanticscholar.org/paper/61367718a07bafbd696871be25e11815f1dd85c4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.12355\",\"authors\":[{\"authorId\":\"2117357\",\"name\":\"Chengxu Zhuang\"},{\"authorId\":\"1920406\",\"name\":\"Alex Lin Zhai\"},{\"authorId\":\"2292273\",\"name\":\"Daniel Yamins\"}],\"doi\":\"10.1109/ICCV.2019.00610\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"982b9c948c7e1f23e14a014002e451f9fd673252\",\"title\":\"Local Aggregation for Unsupervised Learning of Visual Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/982b9c948c7e1f23e14a014002e451f9fd673252\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50980197\",\"name\":\"Yongchen Wang\"},{\"authorId\":\"94751361\",\"name\":\"Y. Wang\"},{\"authorId\":\"46382709\",\"name\":\"H. Li\"},{\"authorId\":\"144724152\",\"name\":\"Cong Shi\"},{\"authorId\":\"40613624\",\"name\":\"Xiaowei Li\"}],\"doi\":\"10.1145/3316781.3317919\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e1b8ff4a2e1a7a9f29ebc07df978c7cf9d75f1ff\",\"title\":\"Systolic Cube: A Spatial 3D CNN Accelerator Architecture for Low Power Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e1b8ff4a2e1a7a9f29ebc07df978c7cf9d75f1ff\",\"venue\":\"2019 56th ACM/IEEE Design Automation Conference (DAC)\",\"year\":2019},{\"arxivId\":\"1906.01843\",\"authors\":[{\"authorId\":\"90070363\",\"name\":\"Amir Ziai\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46d062fe61e9a1bdd328bc600a87353958312c8a\",\"title\":\"Detecting Kissing Scenes in a Database of Hollywood Films\",\"url\":\"https://www.semanticscholar.org/paper/46d062fe61e9a1bdd328bc600a87353958312c8a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143995146\",\"name\":\"Hao Huang\"},{\"authorId\":\"48206987\",\"name\":\"L. Zhou\"},{\"authorId\":\"90638604\",\"name\":\"W. Zhang\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3341898f570384ce310445d6f3f0b6c598831a61\",\"title\":\"Dynamic Graph Modules for Modeling Object-Object Interactions in Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3341898f570384ce310445d6f3f0b6c598831a61\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"107698641\",\"name\":\"Abdullah M. Algamdi\"},{\"authorId\":\"144853917\",\"name\":\"Victor Sanchez\"},{\"authorId\":\"1799504\",\"name\":\"Chang-Tsun Li\"}],\"doi\":\"10.1109/ICASSP.2019.8683720\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4a958eaba99834612735ab45c4b78eca7c317a97\",\"title\":\"Learning Temporal Information from Spatial Information Using CapsNets for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4a958eaba99834612735ab45c4b78eca7c317a97\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216212\",\"name\":\"Vladyslav Sydorov\"},{\"authorId\":\"72492981\",\"name\":\"Alahari Karteek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"32045707a041e18f7afd2b4e7024f9b0dad75890\",\"title\":\"Focused Attention for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/32045707a041e18f7afd2b4e7024f9b0dad75890\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1612.08871\",\"authors\":[{\"authorId\":\"47841989\",\"name\":\"D. Nilsson\"},{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"}],\"doi\":\"10.1109/CVPR.2018.00713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0006a2268d299644e9f1b455601bcbe89ddc2b5\",\"title\":\"Semantic Video Segmentation by Gated Recurrent Flow Propagation\",\"url\":\"https://www.semanticscholar.org/paper/c0006a2268d299644e9f1b455601bcbe89ddc2b5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30770253\",\"name\":\"S. Zebhi\"}],\"doi\":\"10.3906/elk-1910-171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"09ae7cd22ec89129b83f86c9d8d390b23195a2a0\",\"title\":\"Human activity recognition by using MHIs of frame sequences\",\"url\":\"https://www.semanticscholar.org/paper/09ae7cd22ec89129b83f86c9d8d390b23195a2a0\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49597328\",\"name\":\"J. Xia\"},{\"authorId\":\"48624966\",\"name\":\"Wei Li\"},{\"authorId\":\"15316116\",\"name\":\"J. Shao\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"},{\"authorId\":null,\"name\":\"ByteDance AI Lab\"},{\"authorId\":\"46197004\",\"name\":\"S. Tong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec00a57820335f136efe96eada551fddb83cde08\",\"title\":\"Multiple Attempts for AVA-Kinetics challenge 2020\",\"url\":\"https://www.semanticscholar.org/paper/ec00a57820335f136efe96eada551fddb83cde08\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1808.00297\",\"authors\":[{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1007/978-3-030-20876-9_27\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"563fcc87934a4e6c8843c81b58273cb366918bfb\",\"title\":\"TraMNet - Transition Matrix Network for Efficient Action Tube Proposals\",\"url\":\"https://www.semanticscholar.org/paper/563fcc87934a4e6c8843c81b58273cb366918bfb\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23982870\",\"name\":\"Badour Albahar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6ef158d95042f39765df04373c01546524c9ccd\",\"title\":\"Im2Vid: Future Video Prediction for Static Image Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b6ef158d95042f39765df04373c01546524c9ccd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1910.01286\",\"authors\":[{\"authorId\":\"2547290\",\"name\":\"Jingwei Ji\"},{\"authorId\":\"48865984\",\"name\":\"Kaidi Cao\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/ICCV.2019.00717\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39623465df05ddf240bf900fed81fdf9fdad191d\",\"title\":\"Learning Temporal Action Proposals With Fewer Labels\",\"url\":\"https://www.semanticscholar.org/paper/39623465df05ddf240bf900fed81fdf9fdad191d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1905.00546\",\"authors\":[{\"authorId\":\"3059058\",\"name\":\"I. Z. Yalniz\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"115727183\",\"name\":\"K. Chen\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"88ee291cf1f57fd0f4914a80b986a08a90d887f1\",\"title\":\"Billion-scale semi-supervised learning for image classification\",\"url\":\"https://www.semanticscholar.org/paper/88ee291cf1f57fd0f4914a80b986a08a90d887f1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69893872\",\"name\":\"Yuri Yudhaswana Joefrie\"},{\"authorId\":\"96853476\",\"name\":\"Masaki Aono\"}],\"doi\":\"10.1109/ICAICTA.2019.8904245\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"title\":\"Action Recognition by Composite Deep Learning Architecture I3D-DenseLSTM\",\"url\":\"https://www.semanticscholar.org/paper/6ccba260ccaa7fb9a649497e80aefa737756b3b0\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3367041\",\"name\":\"Himanshu Buckchash\"},{\"authorId\":\"1796442\",\"name\":\"B. Raman\"}],\"doi\":\"10.1109/ACCESS.2020.2985318\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a9e20bb1ecf7140dfe826e124f1d1a3282d24f7\",\"title\":\"Variational Conditioning of Deep Recurrent Networks for Modeling Complex Motion Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/0a9e20bb1ecf7140dfe826e124f1d1a3282d24f7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"73580684\",\"name\":\"Sheng Wang\"},{\"authorId\":\"144897103\",\"name\":\"Z. Xu\"},{\"authorId\":\"14417127\",\"name\":\"Chaochao Yan\"},{\"authorId\":\"1768190\",\"name\":\"J. Huang\"}],\"doi\":\"10.1007/978-3-030-20351-1_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02860cb57262bceefde3ba0ba20cfe97a0a5c4c9\",\"title\":\"Graph Convolutional Nets for Tool Presence Detection in Surgical Videos\",\"url\":\"https://www.semanticscholar.org/paper/02860cb57262bceefde3ba0ba20cfe97a0a5c4c9\",\"venue\":\"IPMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409092086\",\"name\":\"J\\u00e9r\\u00f4me Fink\"},{\"authorId\":\"2377431\",\"name\":\"Anthony Cleve\"},{\"authorId\":\"1786603\",\"name\":\"Beno\\u00eet Fr\\u00e9nay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46e549ce004774d2b9f1d0d3eb61f9a85e2c9567\",\"title\":\"Deep Learning Applied to Sign Language\",\"url\":\"https://www.semanticscholar.org/paper/46e549ce004774d2b9f1d0d3eb61f9a85e2c9567\",\"venue\":\"BNAIC/BENELEARN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1007/978-3-030-01234-2_46\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"396520344fb4894849a826b3de56fc86d4d79100\",\"title\":\"Compound Memory Networks for Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/396520344fb4894849a826b3de56fc86d4d79100\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749579\",\"name\":\"R. Hou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"title\":\"An Efficient 3 D CNN for Action / Object Segmentation in Video\",\"url\":\"https://www.semanticscholar.org/paper/8a3e9a317ec14b6673beead812b2134c7b5c623b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1388834506\",\"name\":\"Hao Jiang\"}],\"doi\":\"10.1109/CVPR.2019.01213\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"title\":\"Action4D: Online Action Recognition in the Crowd and Clutter\",\"url\":\"https://www.semanticscholar.org/paper/5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50257322\",\"name\":\"M. Chang\"},{\"authorId\":\"1490669500\",\"name\":\"Jih-Tang Hsieh\"},{\"authorId\":\"97651700\",\"name\":\"C. Fang\"},{\"authorId\":\"144663281\",\"name\":\"Sei-Wang Chen\"}],\"doi\":\"10.1145/3372806.3372815\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4787f180b92c5507992ecf0c3a38e6df2eece1f3\",\"title\":\"A Vision-based Human Action Recognition System for Moving Cameras Through Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/4787f180b92c5507992ecf0c3a38e6df2eece1f3\",\"venue\":\"SPML '19\",\"year\":2019},{\"arxivId\":\"2002.00479\",\"authors\":[{\"authorId\":\"1491321681\",\"name\":\"Alptekin Orbay\"},{\"authorId\":\"1694599\",\"name\":\"L. Akarun\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"00dd6d1faf96e7a952f2ded54ef760c59c3fdbca\",\"title\":\"Neural Sign Language Translation by Learning Tokenization\",\"url\":\"https://www.semanticscholar.org/paper/00dd6d1faf96e7a952f2ded54ef760c59c3fdbca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":null,\"name\":\"Wenhao Yu\"},{\"authorId\":\"144526347\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-019-7404-z\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9804bbb0724c333e9b900d849e492db00b20dbde\",\"title\":\"An attention mechanism based convolutional LSTM network for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/9804bbb0724c333e9b900d849e492db00b20dbde\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1904.00758\",\"authors\":[{\"authorId\":\"144529493\",\"name\":\"Li Ding\"},{\"authorId\":\"40466504\",\"name\":\"Jack Terwilliger\"},{\"authorId\":\"2204677\",\"name\":\"Rini Sherony\"},{\"authorId\":\"144479290\",\"name\":\"B. Reimer\"},{\"authorId\":\"145857744\",\"name\":\"A. Fridman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b0a9b679737fec054439924ecc8883f4d225b517\",\"title\":\"Value of Temporal Dynamics Information in Driving Scene Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/b0a9b679737fec054439924ecc8883f4d225b517\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12808196\",\"name\":\"I. Naeh\"},{\"authorId\":\"1491911042\",\"name\":\"Roi Pony\"},{\"authorId\":\"1712535\",\"name\":\"Shie Mannor\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf1e40e4628b00ffba63190b1866c41f07e755e5\",\"title\":\"Patternless Adversarial Attacks on Video Recognition Networks\",\"url\":\"https://www.semanticscholar.org/paper/cf1e40e4628b00ffba63190b1866c41f07e755e5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.05854\",\"authors\":[{\"authorId\":\"22236100\",\"name\":\"Sasank Chilamkurthy\"},{\"authorId\":\"34917931\",\"name\":\"Rohit Ghosh\"},{\"authorId\":\"35640498\",\"name\":\"Swetha Tanamala\"},{\"authorId\":\"49047272\",\"name\":\"Mustafa Biviji\"},{\"authorId\":\"3907413\",\"name\":\"N. Campeau\"},{\"authorId\":\"12645334\",\"name\":\"V. Venugopal\"},{\"authorId\":\"40900486\",\"name\":\"V. Mahajan\"},{\"authorId\":\"40699900\",\"name\":\"P. Rao\"},{\"authorId\":\"10207677\",\"name\":\"Prashant Warier\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d20414fec0db22fffbb1c3d04a65cc6e608c2ac2\",\"title\":\"Development and Validation of Deep Learning Algorithms for Detection of Critical Findings in Head CT Scans\",\"url\":\"https://www.semanticscholar.org/paper/d20414fec0db22fffbb1c3d04a65cc6e608c2ac2\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1801.03983\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/WACV.2018.00178\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"title\":\"Fully-Coupled Two-Stream Spatiotemporal Networks for Extremely Low Resolution Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19177140\",\"name\":\"S. Das\"},{\"authorId\":\"38905965\",\"name\":\"Arpit Chaudhary\"},{\"authorId\":\"1729410\",\"name\":\"F. Bremond\"},{\"authorId\":\"1686585\",\"name\":\"M. Thonnat\"}],\"doi\":\"10.1109/WACV.2019.00015\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"title\":\"Where to Focus on for Human Action Recognition?\",\"url\":\"https://www.semanticscholar.org/paper/e25f9d3a5b28d8c04a44b8d9fcfcf1d0ac1d08ef\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4965440\",\"name\":\"Peihao Chen\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"34413657\",\"name\":\"G. Shen\"},{\"authorId\":\"51026885\",\"name\":\"W. Huang\"},{\"authorId\":\"147992804\",\"name\":\"Runhao Zeng\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"}],\"doi\":\"10.1109/TMM.2019.2959977\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"320d212dd25dfdec58ac6d9f60198eb893d3744e\",\"title\":\"Relation Attention for Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/320d212dd25dfdec58ac6d9f60198eb893d3744e\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"2008.13196\",\"authors\":[{\"authorId\":null,\"name\":\"Yuxi Li\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145527065\",\"name\":\"Tao Wang\"},{\"authorId\":\"143937986\",\"name\":\"John See\"},{\"authorId\":\"47519958\",\"name\":\"Rui Qian\"},{\"authorId\":null,\"name\":\"Ning Xu\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"1802931\",\"name\":\"Shugong Xu\"}],\"doi\":\"10.1609/AAAI.V34I07.6811\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7b66ea4e404cc119f2f7970486cee19bc300a198\",\"title\":\"Finding Action Tubes with a Sparse-to-Dense Framework\",\"url\":\"https://www.semanticscholar.org/paper/7b66ea4e404cc119f2f7970486cee19bc300a198\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26903445\",\"name\":\"H. Mantec\\u00f3n\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"},{\"authorId\":\"34382594\",\"name\":\"D. Francis\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0af1363c2d03e5d2435d9ba2b05ca5aecd568fd\",\"title\":\"PicSOM and EURECOM Experiments in TRECVID 2019\",\"url\":\"https://www.semanticscholar.org/paper/d0af1363c2d03e5d2435d9ba2b05ca5aecd568fd\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"83200181\",\"name\":\"X. Gu\"},{\"authorId\":\"32797485\",\"name\":\"X. Xue\"},{\"authorId\":\"50981614\",\"name\":\"F. Wang\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053928\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4f856ebdb3ec93583e1ed99c0dff5deb57e9e9d7\",\"title\":\"Fine-Grained Action Recognition on a Novel Basketball Dataset\",\"url\":\"https://www.semanticscholar.org/paper/4f856ebdb3ec93583e1ed99c0dff5deb57e9e9d7\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1912.01326\",\"authors\":[{\"authorId\":\"51006998\",\"name\":\"A. Cioppa\"},{\"authorId\":\"32590713\",\"name\":\"A. Deli\\u00e8ge\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"46541168\",\"name\":\"Marc Van Droogenbroeck\"},{\"authorId\":\"9870507\",\"name\":\"R. Gade\"},{\"authorId\":\"1700569\",\"name\":\"T. Moeslund\"}],\"doi\":\"10.1109/CVPR42600.2020.01314\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"title\":\"A Context-Aware Loss Function for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/d233084a12e59328f00d1e5832a6c0d4403d49ae\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.11851\",\"authors\":[{\"authorId\":\"143707982\",\"name\":\"Lu Wang\"},{\"authorId\":\"2433068\",\"name\":\"Dongxue Liang\"},{\"authorId\":\"2026424\",\"name\":\"X. Yin\"},{\"authorId\":\"145505348\",\"name\":\"Jing Qiu\"},{\"authorId\":\"39632903\",\"name\":\"Z. Yang\"},{\"authorId\":\"46951283\",\"name\":\"J. Xing\"},{\"authorId\":\"65906901\",\"name\":\"Jian-zeng Dong\"},{\"authorId\":\"1903011\",\"name\":\"Zhaoyuan Ma\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"867db00148be8bc966a49a15eeb0621310e9e376\",\"title\":\"Coronary Artery Segmentation in Angiographic Videos Using A 3D-2D CE-Net\",\"url\":\"https://www.semanticscholar.org/paper/867db00148be8bc966a49a15eeb0621310e9e376\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1806.08251\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"title\":\"Unseen Action Recognition with Multimodal Learning\",\"url\":\"https://www.semanticscholar.org/paper/8f27df2d4fb7dd7ed5587640dcbe4dc1eb37acfb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2735585\",\"name\":\"K. Gadzicki\"},{\"authorId\":\"1431726883\",\"name\":\"R. Khamsehashari\"},{\"authorId\":\"1683937\",\"name\":\"C. Zetzsche\"}],\"doi\":\"10.23919/FUSION45008.2020.9190246\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"692ea9770c42bb3b4f9ddb075ce157dd1064e75c\",\"title\":\"Early vs Late Fusion in Multimodal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/692ea9770c42bb3b4f9ddb075ce157dd1064e75c\",\"venue\":\"2020 IEEE 23rd International Conference on Information Fusion (FUSION)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34041171\",\"name\":\"Akshaya Ramaswamy\"},{\"authorId\":\"49294154\",\"name\":\"J. Gubbi\"},{\"authorId\":\"46390096\",\"name\":\"P. Balamuralidhar\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207305\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9429f5afe3edb33c870f9ed2041a0cf3b968bb5d\",\"title\":\"Video object segmentation using spatio-temporal deep network\",\"url\":\"https://www.semanticscholar.org/paper/9429f5afe3edb33c870f9ed2041a0cf3b968bb5d\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":\"1905.03922\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"144416719\",\"name\":\"W. Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00138\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c19659297ac67a29d7524fba60062558f2235f8a\",\"title\":\"Spatio-Temporal Video Re-Localization by Warp LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.00958\",\"authors\":[{\"authorId\":\"1403093510\",\"name\":\"R. Rey-de-Castro\"},{\"authorId\":\"91345327\",\"name\":\"H. Rabitz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6d86a64bb8d7c44f1822fee3b1f90fabeb04926b\",\"title\":\"Targeted Nonlinear Adversarial Perturbations in Images and Videos\",\"url\":\"https://www.semanticscholar.org/paper/6d86a64bb8d7c44f1822fee3b1f90fabeb04926b\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1007/978-3-030-01264-9_39\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"71167cf519940a7373adc221401c396198763ab0\",\"title\":\"Scenes-Objects-Actions: A Multi-task, Multi-label Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71167cf519940a7373adc221401c396198763ab0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2006.11393\",\"authors\":[{\"authorId\":\"49119153\",\"name\":\"Tyler R. Scott\"},{\"authorId\":\"145529241\",\"name\":\"M. Shvartsman\"},{\"authorId\":\"1788247\",\"name\":\"K. Ridgeway\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"13a120e3f091732b24fc86dbe3f855f214398e49\",\"title\":\"Unifying Few- and Zero-Shot Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/13a120e3f091732b24fc86dbe3f855f214398e49\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.06189\",\"authors\":[{\"authorId\":\"1739538\",\"name\":\"L. Wang\"},{\"authorId\":\"21072153\",\"name\":\"Zixun Sun\"},{\"authorId\":\"3315113\",\"name\":\"Wentao Yao\"},{\"authorId\":\"47940636\",\"name\":\"Hui Zhan\"},{\"authorId\":\"3252265\",\"name\":\"Chengwei Zhu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d760fc5d63705bd33d33b759fe727149f8e47e67\",\"title\":\"Unsupervised Multi-stream Highlight detection for the Game \\\"Honor of Kings\\\"\",\"url\":\"https://www.semanticscholar.org/paper/d760fc5d63705bd33d33b759fe727149f8e47e67\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153173254\",\"name\":\"J. Xu\"},{\"authorId\":\"8766232\",\"name\":\"Zhen-Bo Yu\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"47988339\",\"name\":\"Jiancheng Yang\"},{\"authorId\":\"15469693\",\"name\":\"Xiaokang Yang\"},{\"authorId\":\"153645488\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00098\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"76116887e1d2236190084cf4953c4a22eb98f0c9\",\"title\":\"Deep Kinematics Analysis for Monocular 3D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/76116887e1d2236190084cf4953c4a22eb98f0c9\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1908.08191\",\"authors\":[{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1725643\",\"name\":\"Yun-Nung (Vivian) Chen\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"ee1add32f430fb6e9f82958dc431b635174ee9bd\",\"title\":\"Entropy-Enhanced Multimodal Attention Model for Scene-Aware Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/ee1add32f430fb6e9f82958dc431b635174ee9bd\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41125198\",\"name\":\"D. Chittajallu\"},{\"authorId\":\"32865856\",\"name\":\"A. Basharat\"},{\"authorId\":\"3356764\",\"name\":\"Paul Tunison\"},{\"authorId\":\"13060232\",\"name\":\"S. Horvath\"},{\"authorId\":\"32763093\",\"name\":\"K. Wells\"},{\"authorId\":\"2928098\",\"name\":\"Steven G. Leeds\"},{\"authorId\":\"4433600\",\"name\":\"J. Fleshman\"},{\"authorId\":\"144390141\",\"name\":\"G. Sankaranarayanan\"},{\"authorId\":\"1689543\",\"name\":\"A. Enquobahrie\"}],\"doi\":\"10.1117/12.2509985\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c4458740ba5ac7d0a295481bf7c5b768920166b9\",\"title\":\"Content-based retrieval of video segments from minimally invasive surgery videos using deep convolutional video descriptors and iterative query refinement\",\"url\":\"https://www.semanticscholar.org/paper/c4458740ba5ac7d0a295481bf7c5b768920166b9\",\"venue\":\"Medical Imaging\",\"year\":2019},{\"arxivId\":\"1906.02549\",\"authors\":[{\"authorId\":\"26907392\",\"name\":\"Zhenfang Chen\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"145909988\",\"name\":\"Wenhan Luo\"},{\"authorId\":\"1698116\",\"name\":\"K. Wong\"}],\"doi\":\"10.18653/v1/P19-1183\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"title\":\"Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video\",\"url\":\"https://www.semanticscholar.org/paper/7e158a7619c6d0d583a8bbdf00658b7d4bbe0374\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145745355\",\"name\":\"Rui Dai\"},{\"authorId\":\"10392396\",\"name\":\"Luca Minciullo\"},{\"authorId\":\"2645224\",\"name\":\"Lorenzo Garattoni\"},{\"authorId\":\"2647267\",\"name\":\"G. Francesca\"},{\"authorId\":\"69929964\",\"name\":\"F. Br\\u00e9mond\"}],\"doi\":\"10.1109/AVSS.2019.8909841\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd5e49eb51940a5d1555f40486d6b31534c13786\",\"title\":\"Self-Attention Temporal Convolutional Network for Long-Term Daily Living Activity Detection\",\"url\":\"https://www.semanticscholar.org/paper/cd5e49eb51940a5d1555f40486d6b31534c13786\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391032149\",\"name\":\"S. Zheng\"},{\"authorId\":\"1391212613\",\"name\":\"Xiangyu Chen\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3343031.3356080\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23784720dd5eb38df73245188e080a73c743d48b\",\"title\":\"Relation Understanding in Videos\",\"url\":\"https://www.semanticscholar.org/paper/23784720dd5eb38df73245188e080a73c743d48b\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144077750\",\"name\":\"Hang Zhao\"},{\"authorId\":null,\"name\":\"Zhicheng Yan\"},{\"authorId\":null,\"name\":\"Heng Wang\"},{\"authorId\":null,\"name\":\"Lorenzo Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00876\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"title\":\"HACS: Human Action Clips and Segments Dataset for Recognition and Temporal Localization\",\"url\":\"https://www.semanticscholar.org/paper/5aeef2c4f3eb125ec1db9c20392f95e64ef62b41\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.06314\",\"authors\":[{\"authorId\":\"66326227\",\"name\":\"Jia-Ling Lyu\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"12732902\",\"name\":\"Xinyue Wei\"},{\"authorId\":\"145954571\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"}],\"doi\":\"10.1109/cvprw50498.2020.00012\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4933e8cb91e441693085dc18b2dde699f1d88e30\",\"title\":\"Identity Preserve Transform: Understand What Activity Classification Models Have Learnt\",\"url\":\"https://www.semanticscholar.org/paper/4933e8cb91e441693085dc18b2dde699f1d88e30\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2001.08702\",\"authors\":[{\"authorId\":\"145944235\",\"name\":\"B. Mart\\u00ednez\"},{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"2403354\",\"name\":\"S. Petridis\"},{\"authorId\":\"145387779\",\"name\":\"M. Pantic\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053841\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d8da125d2511d037df036c0f0da7c57135e24409\",\"title\":\"Lipreading Using Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d8da125d2511d037df036c0f0da7c57135e24409\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40256896\",\"name\":\"L. Wang\"},{\"authorId\":\"1758267\",\"name\":\"X. Zhao\"},{\"authorId\":\"1701515\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1109/ACCESS.2018.2869751\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7f9b192dad9f85289016c8a089d2a6a65ed1224a\",\"title\":\"Skeleton Feature Fusion Based on Multi-Stream LSTM for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7f9b192dad9f85289016c8a089d2a6a65ed1224a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"2002.02918\",\"authors\":[{\"authorId\":\"47968272\",\"name\":\"Li-Yu Daisy Liu\"},{\"authorId\":\"3143130\",\"name\":\"Dongyang Cai\"},{\"authorId\":\"49723003\",\"name\":\"J. Liu\"},{\"authorId\":\"145534763\",\"name\":\"N. Ding\"},{\"authorId\":\"1491094850\",\"name\":\"Tao Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aff765ae3c6be6c83c731ae1289facaa87dbb6b0\",\"title\":\"iqiyi Submission to ActivityNet Challenge 2019 Kinetics-700 challenge: Hierarchical Group-wise Attention\",\"url\":\"https://www.semanticscholar.org/paper/aff765ae3c6be6c83c731ae1289facaa87dbb6b0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50190972\",\"name\":\"Dan Zeng\"},{\"authorId\":\"1753948451\",\"name\":\"Han Liu\"},{\"authorId\":\"46933412\",\"name\":\"H. Lin\"},{\"authorId\":\"39646508\",\"name\":\"Shiming Ge\"}],\"doi\":\"10.1145/3394171.3413844\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79a511eca03dbfd0b48bd876f6bc99ca1690d1cc\",\"title\":\"Talking Face Generation with Expression-Tailored Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/79a511eca03dbfd0b48bd876f6bc99ca1690d1cc\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"2008.11254\",\"authors\":[{\"authorId\":\"49901923\",\"name\":\"Tingting Xie\"},{\"authorId\":\"1694090\",\"name\":\"Christos Tzelepis\"},{\"authorId\":\"50058816\",\"name\":\"I. Patras\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"title\":\"Temporal Action Localization with Variance-Aware Networks\",\"url\":\"https://www.semanticscholar.org/paper/ec7b5f36e8a129521bf46f958cd366aa50a5a46d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.08055\",\"authors\":[{\"authorId\":\"31352334\",\"name\":\"Neeraj Matiyali\"},{\"authorId\":\"144054466\",\"name\":\"G. Sharma\"}],\"doi\":\"10.1109/WACV45572.2020.9093510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"cd79213a5e10dbd039328232dbb51eb4a80f3b5f\",\"title\":\"Video Person Re-Identification using Learned Clip Similarity Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/cd79213a5e10dbd039328232dbb51eb4a80f3b5f\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406152923\",\"name\":\"Tingting Han\"},{\"authorId\":\"31255274\",\"name\":\"Hongxun Yao\"},{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":null,\"name\":\"Jun Yu\"}],\"doi\":\"10.1016/j.patcog.2020.107267\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93dc1e7e7fbcb3110e19d6a8bca55b11b85a4604\",\"title\":\"TVENet: Temporal variance embedding network for fine-grained action representation\",\"url\":\"https://www.semanticscholar.org/paper/93dc1e7e7fbcb3110e19d6a8bca55b11b85a4604\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1912.04608\",\"authors\":[{\"authorId\":\"1383481973\",\"name\":\"Yan Bin Ng\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"}],\"doi\":\"10.1109/TIP.2020.3021497\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"08bf24e179aff7971ba95aed185c8e13da9f8ce4\",\"title\":\"Forecasting Future Action Sequences With Attention: A New Approach to Weakly Supervised Action Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/08bf24e179aff7971ba95aed185c8e13da9f8ce4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"28969692\",\"name\":\"Junwu Weng\"},{\"authorId\":\"34608228\",\"name\":\"Xu-dong Jiang\"},{\"authorId\":\"3108302\",\"name\":\"Wei-Long Zheng\"},{\"authorId\":\"145078769\",\"name\":\"J. Yuan\"}],\"doi\":\"10.1109/TCSVT.2020.2976789\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"title\":\"Early Action Recognition With Category Exclusion Using Policy-Based Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/07f712eb18f2357e917f63692a8e9ab2ed9d279e\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1908.05717\",\"authors\":[{\"authorId\":\"3000952\",\"name\":\"A. Habibian\"},{\"authorId\":\"1388073495\",\"name\":\"T. V. Rozendaal\"},{\"authorId\":\"1849327\",\"name\":\"J. Tomczak\"},{\"authorId\":\"2056266\",\"name\":\"T. Cohen\"}],\"doi\":\"10.1109/ICCV.2019.00713\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"341bce2c88f26f1d17b59730c5db993f6d19c31f\",\"title\":\"Video Compression With Rate-Distortion Autoencoders\",\"url\":\"https://www.semanticscholar.org/paper/341bce2c88f26f1d17b59730c5db993f6d19c31f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6146190\",\"name\":\"S. Li\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"2256493\",\"name\":\"Xiumin Diao\"}],\"doi\":\"10.1007/S10846-019-01049-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"title\":\"Deep-Learning-Based Human Intention Prediction Using RGB Images and Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/2eafdd1aa5aab7ec1b116e28a7d1ab3c44bb3f37\",\"venue\":\"J. Intell. Robotic Syst.\",\"year\":2020},{\"arxivId\":\"2011.02543\",\"authors\":[{\"authorId\":\"30621486\",\"name\":\"Stepan Alekseevich Komkov\"},{\"authorId\":\"2007675511\",\"name\":\"Maksim Dzabraev\"},{\"authorId\":\"1380315305\",\"name\":\"Aleksandr Petiushko\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"title\":\"Mutual Modality Learning for Video Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/0e0be00a9dac71413ebfca60ea6b40a5d73c5877\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.06172\",\"authors\":[{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"2774166\",\"name\":\"M. Fani\"},{\"authorId\":\"84178850\",\"name\":\"P. Walters\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW50498.2020.00449\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9ac13a6c900bd931e9aed298b9ccb3413b6bcf3a\",\"title\":\"Event detection in coarsely annotated sports videos via parallel multi receptive field 1D convolutions\",\"url\":\"https://www.semanticscholar.org/paper/9ac13a6c900bd931e9aed298b9ccb3413b6bcf3a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1892008902\",\"name\":\"Xiaoyu Zhang\"}],\"doi\":\"10.1145/3404555.3404628\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7fd084823dae54cc32c07361e749b3932919da35\",\"title\":\"Learning Temporal Structure of Videos for Action Recognition Using Pattern Theory\",\"url\":\"https://www.semanticscholar.org/paper/7fd084823dae54cc32c07361e749b3932919da35\",\"venue\":\"ICCAI\",\"year\":2020},{\"arxivId\":\"2008.04999\",\"authors\":[{\"authorId\":\"13930770\",\"name\":\"Faegheh Sardari\"},{\"authorId\":\"2657085\",\"name\":\"A. Paiement\"},{\"authorId\":\"1751117\",\"name\":\"S. Hannuna\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"}],\"doi\":\"10.3390/s20185258\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"title\":\"VI-Net\\u2014View-Invariant Quality of Human Movement Assessment\",\"url\":\"https://www.semanticscholar.org/paper/eddbf3b7783f528a3413dbe96a58da1690d7f156\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39650418\",\"name\":\"S. Chen\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"}],\"doi\":\"10.1007/978-3-030-58565-5_36\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"853069fa3f976fe368858ce4650b6348a17a3764\",\"title\":\"Hierarchical Visual-Textual Graph for Temporal Activity Localization via Language\",\"url\":\"https://www.semanticscholar.org/paper/853069fa3f976fe368858ce4650b6348a17a3764\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1911.09435\",\"authors\":[{\"authorId\":\"46270766\",\"name\":\"Zhaoyang Liu\"},{\"authorId\":\"9393671\",\"name\":\"Donghao Luo\"},{\"authorId\":null,\"name\":\"Yabiao Wang\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"},{\"authorId\":\"144970872\",\"name\":\"Ying Tai\"},{\"authorId\":\"1978245\",\"name\":\"Chengjie Wang\"},{\"authorId\":\"49298244\",\"name\":\"Jilin Li\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":\"144720251\",\"name\":\"Tong Lu\"}],\"doi\":\"10.1609/AAAI.V34I07.6836\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"title\":\"TEINet: Towards an Efficient Architecture for Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa3473f1f5d4f19ec6d561e2700a4d88dad4ccf8\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1910.09616\",\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"},{\"authorId\":\"145087510\",\"name\":\"H. Krim\"}],\"doi\":\"10.1609/aaai.v34i07.6870\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"title\":\"Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering Approach for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2002.12177\",\"authors\":[{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"},{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"}],\"doi\":\"10.1109/cvpr42600.2020.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3cb1b739f32641938485b714a186fb705d0b0215\",\"title\":\"Evolving Losses for Unsupervised Video Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3cb1b739f32641938485b714a186fb705d0b0215\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2009.10434\",\"authors\":[{\"authorId\":\"49687714\",\"name\":\"Haoyu Tang\"},{\"authorId\":\"2237811\",\"name\":\"Jihua Zhu\"},{\"authorId\":\"38813990\",\"name\":\"M. Liu\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"46504200\",\"name\":\"Zhiyong Cheng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"title\":\"Frame-wise Cross-modal Match for Video Moment Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/d1d28e778c391d07a6c3e7a2e96312fdc53c0ae2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.16228\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"39257069\",\"name\":\"A. Recasens\"},{\"authorId\":\"145721402\",\"name\":\"Ros\\u00e1lia G. Schneider\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"16092809\",\"name\":\"Jason Ramapuram\"},{\"authorId\":\"3364908\",\"name\":\"J. Fauw\"},{\"authorId\":\"1466466597\",\"name\":\"Lucas Smaira\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"title\":\"Self-Supervised MultiModal Versatile Networks\",\"url\":\"https://www.semanticscholar.org/paper/4174f03c7d8d9add62ae4ecd0ec90efba680b7ae\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":\"2006.16166\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"1780000543\",\"name\":\"Helene Haugerud\"},{\"authorId\":\"1670961136\",\"name\":\"Daniel Oh\"},{\"authorId\":\"2146343\",\"name\":\"O. Mohareri\"}],\"doi\":\"10.1007/978-3-030-59716-0_37\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"65c3b0ab81cd7294b22df4cb6c30b2b2a792ce23\",\"title\":\"Automatic Operating Room Surgical Activity Recognition for Robot-Assisted Surgery\",\"url\":\"https://www.semanticscholar.org/paper/65c3b0ab81cd7294b22df4cb6c30b2b2a792ce23\",\"venue\":\"MICCAI\",\"year\":2020},{\"arxivId\":\"1912.04363\",\"authors\":[{\"authorId\":\"143714918\",\"name\":\"Pengfei Li\"},{\"authorId\":\"3256056\",\"name\":\"Weichao Qiu\"},{\"authorId\":\"51207689\",\"name\":\"Michael Peven\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ec5d2fcf2b070401f1178326b66ab0f0c0059b1\",\"title\":\"Car Pose in Context: Accurate Pose Estimation with Ground Plane Constraints\",\"url\":\"https://www.semanticscholar.org/paper/3ec5d2fcf2b070401f1178326b66ab0f0c0059b1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1910.11306\",\"authors\":[{\"authorId\":\"2285263\",\"name\":\"Jean-Baptiste Alayrac\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2019.00583\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c4892a8ac3e3e3575b17fff393e57b8fd20a08a8\",\"title\":\"Controllable Attention for Structured Layered Video Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/c4892a8ac3e3e3575b17fff393e57b8fd20a08a8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2003.12798\",\"authors\":[{\"authorId\":\"2156559\",\"name\":\"Qihang Yu\"},{\"authorId\":\"48513320\",\"name\":\"Yingwei Li\"},{\"authorId\":\"10407760\",\"name\":\"Jieru Mei\"},{\"authorId\":\"7743268\",\"name\":\"Yuyin Zhou\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3743c3c7c30d700f37bcd00048af007137517a18\",\"title\":\"CAKES: Channel-wise Automatic KErnel Shrinking for Efficient 3D Network\",\"url\":\"https://www.semanticscholar.org/paper/3743c3c7c30d700f37bcd00048af007137517a18\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.09383\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"48607331\",\"name\":\"Yu Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"title\":\"Baidu-UTS Submission to the EPIC-Kitchens Action Recognition Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3130030\",\"name\":\"M. Farrajota\"},{\"authorId\":\"143955056\",\"name\":\"J. Rodrigues\"},{\"authorId\":\"1394604631\",\"name\":\"J. M. H. du Buf\"}],\"doi\":\"10.1007/s10044-018-0727-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b999364980e4c21d9c22cc5a9f14501432999ca4\",\"title\":\"Human action recognition in videos with articulated pose information by deep networks\",\"url\":\"https://www.semanticscholar.org/paper/b999364980e4c21d9c22cc5a9f14501432999ca4\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2018},{\"arxivId\":\"1903.09102\",\"authors\":[{\"authorId\":\"39576371\",\"name\":\"A. Manglik\"},{\"authorId\":\"7885067\",\"name\":\"Xinshuo Weng\"},{\"authorId\":\"1401940506\",\"name\":\"Eshed Ohn-Bar\"},{\"authorId\":\"1491177496\",\"name\":\"Kris M. Kitanil\"}],\"doi\":\"10.1109/IROS40897.2019.8967730\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"96faca0c3994a110375b78e47568e0fa10d77279\",\"title\":\"Forecasting Time-to-Collision from Monocular Video: Feasibility, Dataset, and Challenges\",\"url\":\"https://www.semanticscholar.org/paper/96faca0c3994a110375b78e47568e0fa10d77279\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"1909.09300\",\"authors\":[{\"authorId\":\"3928052\",\"name\":\"T. Li\"},{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"2931940\",\"name\":\"M. Zhao\"},{\"authorId\":\"51149370\",\"name\":\"Yingcheng Liu\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1109/ICCV.2019.00096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"02ec4b311978f8a16ae4ecd232e2464c08e59d84\",\"title\":\"Making the Invisible Visible: Action Recognition Through Walls and Occlusions\",\"url\":\"https://www.semanticscholar.org/paper/02ec4b311978f8a16ae4ecd232e2464c08e59d84\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2008.09412\",\"authors\":[{\"authorId\":\"8706479\",\"name\":\"Z. Yu\"},{\"authorId\":\"73819368\",\"name\":\"Benjia Zhou\"},{\"authorId\":\"1785406293\",\"name\":\"Jun Wan\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"1471684559\",\"name\":\"Haoyu Chen\"},{\"authorId\":null,\"name\":\"Xin Liu\"},{\"authorId\":\"34679741\",\"name\":\"S. Li\"},{\"authorId\":\"83433495\",\"name\":\"G. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"title\":\"Searching Multi-Rate and Multi-Modal Temporal Enhanced Networks for Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d2fec7fd0d928788491651ef66e795c5d7b73d0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405511901\",\"name\":\"Luis Fernando D'Haro\"},{\"authorId\":\"2237192\",\"name\":\"Koichiro Yoshino\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"},{\"authorId\":\"1725498\",\"name\":\"L. Polymenakos\"},{\"authorId\":\"1727211\",\"name\":\"Jonathan K. Kummerfeld\"},{\"authorId\":\"1947267\",\"name\":\"Michel Galley\"},{\"authorId\":\"71886367\",\"name\":\"Xiang Gao\"}],\"doi\":\"10.1016/j.csl.2020.101068\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2da92688aef91371424f0e3ca5482c9f8dbe67b7\",\"title\":\"Overview of the seventh Dialog System Technology Challenge: DSTC7\",\"url\":\"https://www.semanticscholar.org/paper/2da92688aef91371424f0e3ca5482c9f8dbe67b7\",\"venue\":\"Comput. Speech Lang.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1387878329\",\"name\":\"Oggi Rudovic\"},{\"authorId\":\"2756001\",\"name\":\"H. W. Park\"},{\"authorId\":\"153590291\",\"name\":\"John Busche\"},{\"authorId\":\"145411696\",\"name\":\"B. Schuller\"},{\"authorId\":\"1711777\",\"name\":\"C. Breazeal\"},{\"authorId\":\"1719389\",\"name\":\"Rosalind W. Picard\"}],\"doi\":\"10.1109/CVPRW.2019.00031\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"371d69fc3cebd7c2d4544e706d129a57566d713e\",\"title\":\"Personalized Estimation of Engagement From Videos Using Active Learning With Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/371d69fc3cebd7c2d4544e706d129a57566d713e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2031813950\",\"name\":\"Kent Wu\"},{\"authorId\":\"2031839518\",\"name\":\"Suzy He\"},{\"authorId\":\"3247498\",\"name\":\"G. Fernie\"},{\"authorId\":\"2026720994\",\"name\":\"Atena Roshan Fekr\"}],\"doi\":\"10.3390/s20236883\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d4001fe6d384d2bc8ac1447021d34b07310c27f7\",\"title\":\"Deep Neural Network for Slip Detection on Ice Surface\",\"url\":\"https://www.semanticscholar.org/paper/d4001fe6d384d2bc8ac1447021d34b07310c27f7\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xiaoqiang Li\"},{\"authorId\":null,\"name\":\"Miao Xie\"},{\"authorId\":null,\"name\":\"Yin Zhang\"},{\"authorId\":null,\"name\":\"Jide Li\"}],\"doi\":\"10.1117/1.JEI.29.6.063013\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2ff367b6e92953c0f0e72f5bee2f64f1c1d19f01\",\"title\":\"Multi-scale temporal feature-based dense convolutional network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ff367b6e92953c0f0e72f5bee2f64f1c1d19f01\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8207793\",\"name\":\"James P. Bohnslav\"},{\"authorId\":\"8419711\",\"name\":\"Nivanthika K Wimalasena\"},{\"authorId\":\"1945164690\",\"name\":\"Kelsey J Clausing\"},{\"authorId\":\"1976696822\",\"name\":\"David Yarmolinksy\"},{\"authorId\":\"144998880\",\"name\":\"T. Cruz\"},{\"authorId\":\"71489902\",\"name\":\"Eugenia Chiappe\"},{\"authorId\":\"48926043\",\"name\":\"Lauren L. Orefice\"},{\"authorId\":\"3824034\",\"name\":\"C. Woolf\"},{\"authorId\":\"3966889\",\"name\":\"C. Harvey\"}],\"doi\":\"10.1101/2020.09.24.312504\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ddfc8674186fdf356ccc2bd030e187ba5232682\",\"title\":\"DeepEthogram: a machine learning pipeline for supervised behavior classification from raw pixels\",\"url\":\"https://www.semanticscholar.org/paper/5ddfc8674186fdf356ccc2bd030e187ba5232682\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2038426504\",\"name\":\"Zhouning Du\"},{\"authorId\":\"2873178\",\"name\":\"H. Mukaidani\"},{\"authorId\":\"1381799120\",\"name\":\"Ramasamy Saravanakumar\"}],\"doi\":\"10.1109/SMC42975.2020.9283429\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d00445b8d5b6da620056aed4685bf9b766a9700b\",\"title\":\"Action Recognition Based on Linear Dynamical Systems with Deep Features in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d00445b8d5b6da620056aed4685bf9b766a9700b\",\"venue\":\"2020 IEEE International Conference on Systems, Man, and Cybernetics (SMC)\",\"year\":2020},{\"arxivId\":\"2001.06206\",\"authors\":[{\"authorId\":\"9628638\",\"name\":\"Yun-Wei Chu\"},{\"authorId\":\"152923110\",\"name\":\"Kuan-Yen Lin\"},{\"authorId\":\"23608432\",\"name\":\"Chao-Chun Hsu\"},{\"authorId\":\"1746959\",\"name\":\"Lun-Wei Ku\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e885f1523349be48c884a4663d705487fde05b8a\",\"title\":\"Multi-step Joint-Modality Attention Network for Scene-Aware Dialogue System\",\"url\":\"https://www.semanticscholar.org/paper/e885f1523349be48c884a4663d705487fde05b8a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.12606\",\"authors\":[{\"authorId\":\"22598670\",\"name\":\"Yurui Ren\"},{\"authorId\":\"1410115257\",\"name\":\"Ge Li\"},{\"authorId\":\"51197045\",\"name\":\"S. Liu\"},{\"authorId\":\"50289966\",\"name\":\"Thomas H. Li\"}],\"doi\":\"10.1109/TIP.2020.3018224\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"364193005b7b22c212780528215945af4c0bbda6\",\"title\":\"Deep Spatial Transformation for Pose-Guided Person Image Generation and Animation\",\"url\":\"https://www.semanticscholar.org/paper/364193005b7b22c212780528215945af4c0bbda6\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2007.10703\",\"authors\":[{\"authorId\":\"31638576\",\"name\":\"A. Arnab\"},{\"authorId\":\"1491624845\",\"name\":\"Chen Sun\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"153433844\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-030-58607-2_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d9660f127a880ec9757aedc90509524d744c15a\",\"title\":\"Uncertainty-Aware Weakly Supervised Action Detection from Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/7d9660f127a880ec9757aedc90509524d744c15a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.11040\",\"authors\":[{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"2521776\",\"name\":\"B. Shuai\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"}],\"doi\":\"10.1007/978-3-030-58539-6_17\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"c40990d00633b63caf78082f8570a55e2ec5abbb\",\"title\":\"Directional Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c40990d00633b63caf78082f8570a55e2ec5abbb\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.15796\",\"authors\":[{\"authorId\":\"1470673136\",\"name\":\"Yue Meng\"},{\"authorId\":\"47532522\",\"name\":\"Chung-Ching Lin\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"1706272\",\"name\":\"P. Sattigeri\"},{\"authorId\":\"2428823\",\"name\":\"Leonid Karlinsky\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"}],\"doi\":\"10.1007/978-3-030-58571-6_6\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"title\":\"AR-Net: Adaptive Frame Resolution for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/11bf57d8a652de8e2ea436ff6a2707c95fa5197a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50202365\",\"name\":\"S. Zhang\"},{\"authorId\":\"153098982\",\"name\":\"Sheng Guo\"},{\"authorId\":\"49015548\",\"name\":\"Weilin Huang\"},{\"authorId\":\"1915350\",\"name\":\"M. Scott\"},{\"authorId\":\"29461006\",\"name\":\"L. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"title\":\"V4D: 4D Covolutional Neural Networks for Video-level Representations Learning\",\"url\":\"https://www.semanticscholar.org/paper/60d95b4ed4f6e9ac38441d130d3969597ce4d626\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":\"2003.01920\",\"authors\":[{\"authorId\":\"3367803\",\"name\":\"Jinhyeok Jang\"},{\"authorId\":null,\"name\":\"Dohyung Kim\"},{\"authorId\":\"2944780\",\"name\":\"Cheonshu Park\"},{\"authorId\":\"145416765\",\"name\":\"M. Jang\"},{\"authorId\":\"46663405\",\"name\":\"Jaeyeon Lee\"},{\"authorId\":\"37079663\",\"name\":\"Jae-Hong Kim\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de43519e1838f217f46abefa835dd3dd6ac38ec6\",\"title\":\"ETRI-Activity3D: A Large-Scale RGB-D Dataset for Robots to Recognize Daily Activities of the Elderly\",\"url\":\"https://www.semanticscholar.org/paper/de43519e1838f217f46abefa835dd3dd6ac38ec6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03014\",\"authors\":[{\"authorId\":\"49530215\",\"name\":\"Behnoosh Parsa\"},{\"authorId\":\"145026397\",\"name\":\"Ashis G. Banerjee\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"baf1570958f179908b02b1fa8f596fd8872ced24\",\"title\":\"A Multi-Task Learning Approach for Human Activity Segmentation and Ergonomics Risk Assessment.\",\"url\":\"https://www.semanticscholar.org/paper/baf1570958f179908b02b1fa8f596fd8872ced24\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Sohee Park\"},{\"authorId\":null,\"name\":\"Minh Hoai\"},{\"authorId\":null,\"name\":\"Arani Bhaacharya\"},{\"authorId\":null,\"name\":\"Samir R. Das\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1f8d142467d21028bd420604cd8b9285593f7f6b\",\"title\":\"Adaptive Streaming of 360-Degree Videos with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/1f8d142467d21028bd420604cd8b9285593f7f6b\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1564031469\",\"name\":\"A. J. Rana\"},{\"authorId\":\"2116440\",\"name\":\"Y. Rawat\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f6dd3595637c470f7f008b80a4db131da929e35e\",\"title\":\"We don't Need Thousand Proposals: Single Shot Actor-Action Detection in Videos\",\"url\":\"https://www.semanticscholar.org/paper/f6dd3595637c470f7f008b80a4db131da929e35e\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":206596127,\"doi\":\"10.1109/CVPR.2017.502\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":628,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"references\":[{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2008.4587735\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"560171665e78c9341c0a735be437ee7f99bb2f2c\",\"title\":\"Action recognition by learning mid-level motion features\",\"url\":\"https://www.semanticscholar.org/paper/560171665e78c9341c0a735be437ee7f99bb2f2c\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2093491\",\"name\":\"M. Oquab\"},{\"authorId\":\"119267979\",\"name\":\"L. Bottou\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2014.222\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c08f5fa876181fc040d76c75fe2433eee3c9b001\",\"title\":\"Learning and Transferring Mid-level Image Representations Using Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c08f5fa876181fc040d76c75fe2433eee3c9b001\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Karpathy\"},{\"authorId\":null,\"name\":\"G. Toderici\"},{\"authorId\":null,\"name\":\"S. Shetty\"},{\"authorId\":null,\"name\":\"T. Leung\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and L\",\"url\":\"\",\"venue\":\"Fei-Fei. Large-scale video classification with convolutional neural networks. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 1725\\u20131732\",\"year\":2014},{\"arxivId\":\"1411.6031\",\"authors\":[{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"143751119\",\"name\":\"Jitendra Malik\"}],\"doi\":\"10.1109/CVPR.2015.7298676\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"title\":\"Finding action tubes\",\"url\":\"https://www.semanticscholar.org/paper/295a1c000c5e3fd5959bb250e8376a06efa405b1\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2428034\",\"name\":\"C. Bregler\"}],\"doi\":\"10.1007/978-3-642-15567-3_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4d476b96be73fccc61f2076befbf5a468caa4180\",\"title\":\"Convolutional Learning of Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/4d476b96be73fccc61f2076befbf5a468caa4180\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5886094\",\"name\":\"P. Cochat\"},{\"authorId\":\"13267685\",\"name\":\"L. Vaucoret\"},{\"authorId\":\"31455512\",\"name\":\"J. Sarles\"}],\"doi\":\"10.1016/j.arcped.2012.01.013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10d85561e4aafc516d10064f30dff05b41f70afe\",\"title\":\"[Et al].\",\"url\":\"https://www.semanticscholar.org/paper/10d85561e4aafc516d10064f30dff05b41f70afe\",\"venue\":\"Archives de pediatrie : organe officiel de la Societe francaise de pediatrie\",\"year\":2012},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1705.06950\",\"authors\":[{\"authorId\":\"21028601\",\"name\":\"W. Kay\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"11809518\",\"name\":\"Brian Zhang\"},{\"authorId\":\"38961760\",\"name\":\"Chloe Hillier\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"143740871\",\"name\":\"F. Viola\"},{\"authorId\":\"143897708\",\"name\":\"T. Green\"},{\"authorId\":\"2830305\",\"name\":\"T. Back\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"2573615\",\"name\":\"Mustafa Suleyman\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"title\":\"The Kinetics Human Action Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/86e1bdbfd13b9ed137e4c4b8b459a3980eb257f6\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1743600\",\"name\":\"S. Ji\"},{\"authorId\":\"143836295\",\"name\":\"W. Xu\"},{\"authorId\":\"41216159\",\"name\":\"Ming Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"}],\"doi\":\"10.1109/TPAMI.2012.59\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"title\":\"3D Convolutional Neural Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/80bfcf1be2bf1b95cc6f36d229665cdf22d76190\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"3254319\",\"name\":\"Hongcheng Wang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.5244/C.20.127\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e25d2a9aa691e63657fef30f5850799d757f69e6\",\"title\":\"Unsupervised Learning of Human Action Categories Using Spatial-Temporal Words\",\"url\":\"https://www.semanticscholar.org/paper/e25d2a9aa691e63657fef30f5850799d757f69e6\",\"venue\":\"BMVC\",\"year\":2006},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1603.04467\",\"authors\":[{\"authorId\":\"145832079\",\"name\":\"M. Abadi\"},{\"authorId\":\"145984138\",\"name\":\"A. Agarwal\"},{\"authorId\":\"144758007\",\"name\":\"P. Barham\"},{\"authorId\":\"2445241\",\"name\":\"E. Brevdo\"},{\"authorId\":\"2545358\",\"name\":\"Z. Chen\"},{\"authorId\":\"48738717\",\"name\":\"Craig Citro\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"36347083\",\"name\":\"Andy Davis\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"},{\"authorId\":\"145139947\",\"name\":\"M. Devin\"},{\"authorId\":\"1780892\",\"name\":\"Sanjay Ghemawat\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"3384453\",\"name\":\"A. Harp\"},{\"authorId\":\"145659929\",\"name\":\"Geoffrey Irving\"},{\"authorId\":\"2090818\",\"name\":\"M. Isard\"},{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1944541\",\"name\":\"R. J\\u00f3zefowicz\"},{\"authorId\":\"40527594\",\"name\":\"L. Kaiser\"},{\"authorId\":\"1942300\",\"name\":\"M. Kudlur\"},{\"authorId\":\"3369421\",\"name\":\"Josh Levenberg\"},{\"authorId\":\"143767989\",\"name\":\"Dan Man\\u00e9\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"144375552\",\"name\":\"Sherry Moore\"},{\"authorId\":\"20154699\",\"name\":\"D. Murray\"},{\"authorId\":\"153301219\",\"name\":\"Chris Olah\"},{\"authorId\":\"144927151\",\"name\":\"Mike Schuster\"},{\"authorId\":\"1789737\",\"name\":\"Jonathon Shlens\"},{\"authorId\":\"32163737\",\"name\":\"B. Steiner\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"35210462\",\"name\":\"Kunal Talwar\"},{\"authorId\":\"2080690\",\"name\":\"P. Tucker\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"38062095\",\"name\":\"V. Vasudevan\"},{\"authorId\":\"1765169\",\"name\":\"F. Vi\\u00e9gas\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"47941411\",\"name\":\"Pete Warden\"},{\"authorId\":\"145233583\",\"name\":\"M. Wattenberg\"},{\"authorId\":\"35078078\",\"name\":\"Martin Wicke\"},{\"authorId\":\"47112093\",\"name\":\"Y. Yu\"},{\"authorId\":\"2777763\",\"name\":\"X. Zheng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d\",\"title\":\"TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems\",\"url\":\"https://www.semanticscholar.org/paper/9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1007/978-3-642-35749-7_17\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"07fd302320449434f52fdfcf30feda50c0450909\",\"title\":\"Human Focused Action Localization in Video\",\"url\":\"https://www.semanticscholar.org/paper/07fd302320449434f52fdfcf30feda50c0450909\",\"venue\":\"ECCV Workshops\",\"year\":2010},{\"arxivId\":\"1603.09025\",\"authors\":[{\"authorId\":\"2348758\",\"name\":\"Tim Cooijmans\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"40201308\",\"name\":\"C\\u00e9sar Laurent\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"952454718139dba3aafc6b3b67c4f514ac3964af\",\"title\":\"Recurrent Batch Normalization\",\"url\":\"https://www.semanticscholar.org/paper/952454718139dba3aafc6b3b67c4f514ac3964af\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688328\",\"name\":\"A. Bobick\"},{\"authorId\":\"144429686\",\"name\":\"J. Davis\"}],\"doi\":\"10.1109/34.910878\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"886431a362bfdbcc6dd518f844eb374950b9de86\",\"title\":\"The Recognition of Human Movement Using Temporal Templates\",\"url\":\"https://www.semanticscholar.org/paper/886431a362bfdbcc6dd518f844eb374950b9de86\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2001},{\"arxivId\":\"1506.01497\",\"authors\":[{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"144716314\",\"name\":\"J. Sun\"}],\"doi\":\"10.1109/TPAMI.2016.2577031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"title\":\"Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks\",\"url\":\"https://www.semanticscholar.org/paper/424561d8585ff8ebce7d5d07de8dbf7aae5e7270\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Qiao L. Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Learning spatiotemporal features with 3 d convolutional networks Action recognition with improved trajectories\",\"url\":\"\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/978-3-319-46493-0_45\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"title\":\"Multi-region Two-Stream R-CNN for Action Detection\",\"url\":\"https://www.semanticscholar.org/paper/ddbd24a73ba3d74028596f393bb07a6b87a469c0\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1607.01794\",\"authors\":[{\"authorId\":\"3245057\",\"name\":\"Zhenyang Li\"},{\"authorId\":\"32781361\",\"name\":\"Kirill Gavrilyuk\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1016/j.cviu.2017.10.011\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86031f555c128b82a1ac0db89ff4faeae16a1802\",\"title\":\"VideoLSTM convolves, attends and flows for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/86031f555c128b82a1ac0db89ff4faeae16a1802\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Li\"},{\"authorId\":null,\"name\":\"E. Gavves\"},{\"authorId\":null,\"name\":\"M. Jain\"},{\"authorId\":null,\"name\":\"C. G. Snoek\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"VideoLSTM convolves\",\"url\":\"\",\"venue\":\"attends and flows for action recognition. arXiv preprint arXiv:1607.01794\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1608.01529\",\"authors\":[{\"authorId\":null,\"name\":\"Suman Saha\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"145466505\",\"name\":\"M. Sapienza\"},{\"authorId\":\"143635540\",\"name\":\"P. Torr\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.5244/C.30.58\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"title\":\"Deep Learning for Detecting Multiple Space-Time Action Tubes in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6b0983e11312938381bb9d11ef42612aaf78f5f4\",\"venue\":\"BMVC\",\"year\":2016},{\"arxivId\":\"1311.2524\",\"authors\":[{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"153652146\",\"name\":\"J. Malik\"}],\"doi\":\"10.1109/CVPR.2014.81\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"title\":\"Rich Feature Hierarchies for Accurate Object Detection and Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/2f4df08d9072fc2ac181b7fced6a245315ce05c8\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1503.07274\",\"authors\":[{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc5bdb98ff97581d7c1e5eb2d24d3f10714aa192\",\"title\":\"Initialization Strategies of Spatio-Temporal Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/fc5bdb98ff97581d7c1e5eb2d24d3f10714aa192\",\"venue\":\"ArXiv\",\"year\":2015}],\"title\":\"Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\",\"topics\":[{\"topic\":\"Kinesiology\",\"topicId\":\"113188\",\"url\":\"https://www.semanticscholar.org/topic/113188\"},{\"topic\":\"ImageNet\",\"topicId\":\"256302\",\"url\":\"https://www.semanticscholar.org/topic/256302\"},{\"topic\":\"Status quo bias\",\"topicId\":\"444234\",\"url\":\"https://www.semanticscholar.org/topic/444234\"},{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Seamless3d\",\"topicId\":\"4101624\",\"url\":\"https://www.semanticscholar.org/topic/4101624\"},{\"topic\":\"Action potential\",\"topicId\":\"343\",\"url\":\"https://www.semanticscholar.org/topic/343\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"}],\"url\":\"https://www.semanticscholar.org/paper/b61a3f8b80bbd44f24544dc915f52fd30bbdf485\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"