"{\"abstract\":\"We introduce Spatio-Temporal Vector of Locally Max Pooled Features (ST-VLMPF), a super vector-based encoding method specifically designed for local deep features encoding. The proposed method addresses an important problem of video understanding: how to build a video representation that incorporates the CNN features over the entire video. Feature assignment is carried out at two levels, by using the similarity and spatio-temporal information. For each assignment we build a specific encoding, focused on the nature of deep features, with the goal to capture the highest feature responses from the highest neuron activation of the network. Our ST-VLMPF clearly provides a more reliable video representation than some of the most widely used and powerful encoding approaches (Improved Fisher Vectors and Vector of Locally Aggregated Descriptors), while maintaining a low computational complexity. We conduct experiments on three action recognition datasets: HMDB51, UCF50 and UCF101. Our pipeline obtains state-of-the-art results.\",\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\",\"url\":\"https://www.semanticscholar.org/author/153580352\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\",\"url\":\"https://www.semanticscholar.org/author/1796198\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\",\"url\":\"https://www.semanticscholar.org/author/1712839\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\",\"url\":\"https://www.semanticscholar.org/author/1703601\"}],\"citationVelocity\":16,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"145594181\",\"name\":\"B. Zhu\"}],\"doi\":\"10.1007/978-3-030-03338-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"title\":\"Feature Aggregation Tree: Capture Temporal Motion Information for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46945678\",\"name\":\"T. Singh\"},{\"authorId\":\"47731526\",\"name\":\"D. Vishwakarma\"}],\"doi\":\"10.1007/s10462-018-9651-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9018e160b6e73f6816939a37b3e392033d610f09\",\"title\":\"Video benchmarks of human action datasets: a review\",\"url\":\"https://www.semanticscholar.org/paper/9018e160b6e73f6816939a37b3e392033d610f09\",\"venue\":\"Artificial Intelligence Review\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"title\":\"Efficient and Effective Solutions for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/558fc9a2bce3d3993a9c1f41b6c7f290cefcf92f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI.2019.00012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41c21f12f6896c458004f26b1fd704f4058aaac1\",\"title\":\"CV-C3D: Action Recognition on Compressed Videos with Convolutional 3D Networks\",\"url\":\"https://www.semanticscholar.org/paper/41c21f12f6896c458004f26b1fd704f4058aaac1\",\"venue\":\"2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35654996\",\"name\":\"B. Pan\"},{\"authorId\":\"2282025\",\"name\":\"Jiankai Sun\"},{\"authorId\":\"35992009\",\"name\":\"Wuwei Lin\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/CVPRW.2019.00059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"title\":\"Cross-Stream Selective Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38100171\",\"name\":\"Yoshiki Kohari\"},{\"authorId\":\"1691940\",\"name\":\"Jun Miura\"},{\"authorId\":\"35620770\",\"name\":\"S. Oishi\"}],\"doi\":\"10.1109/IROS.2018.8594427\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74091a749da5c38196bc47cbff33cf9e6ebfb19a\",\"title\":\"Generating Adaptive Attending Behaviors using User State Classification and Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74091a749da5c38196bc47cbff33cf9e6ebfb19a\",\"venue\":\"2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1902.09928\",\"authors\":[{\"authorId\":\"143781496\",\"name\":\"K. Yang\"},{\"authorId\":\"38373258\",\"name\":\"Jingjing Fu\"},{\"authorId\":\"145762398\",\"name\":\"Xun Guo\"},{\"authorId\":\"144574822\",\"name\":\"Y. Lu\"},{\"authorId\":\"50468629\",\"name\":\"Peng Qiao\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"143844357\",\"name\":\"Y. Dou\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31707c9c377cffb1e6e7435c7b35a46d33976562\",\"title\":\"IF-TTN: Information Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/31707c9c377cffb1e6e7435c7b35a46d33976562\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"}],\"doi\":\"10.1109/ICIP.2018.8451226\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"4c6655ab00cf3fbcb412949e85204b608937c881\",\"title\":\"Action Recognition Based on Discriminative Embedding of Actions Using Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6655ab00cf3fbcb412949e85204b608937c881\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1706.04589\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"19320138\",\"name\":\"Ansh Kapil\"},{\"authorId\":\"144387494\",\"name\":\"N. Liu\"},{\"authorId\":\"1795847\",\"name\":\"Lamberto Ballan\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1016/j.cviu.2017.08.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e444db884b5272f3a41e4b68dc0d453d4ec1f4c\",\"title\":\"Learning without Prejudice: Avoiding Bias in Webly-Supervised Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4e444db884b5272f3a41e4b68dc0d453d4ec1f4c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3258842\",\"name\":\"J. Wang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/TMM.2018.2855081\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"title\":\"Multiscale Deep Alternative Neural Network for Large-Scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d3aba33ac0025d067bc3ed80d2d73ee883a1c2b1\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1007/978-3-030-04167-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caae04e73d362180f9586fabb224244200add105\",\"title\":\"Multi-stream with Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/caae04e73d362180f9586fabb224244200add105\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"144805693\",\"name\":\"C. Kuo\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"103483753\",\"name\":\"Yu-Hung Liu\"},{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"1491078400\",\"name\":\"Zijun Li\"},{\"authorId\":\"121418048\",\"name\":\"J. Shen\"},{\"authorId\":\"1743408\",\"name\":\"L. Fu\"}],\"doi\":\"10.1109/IROS40897.2019.8968533\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f98c4ae113621fdddaf5321b6f2f22310698f994\",\"title\":\"ResFlow: Multi-tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/f98c4ae113621fdddaf5321b6f2f22310698f994\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.13726\",\"authors\":[{\"authorId\":\"34539976\",\"name\":\"S. Santos\"},{\"authorId\":\"23962586\",\"name\":\"J. Almeida\"}],\"doi\":\"10.1109/SIBGRAPI51738.2020.00017\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"title\":\"Faster and Accurate Compressed Video Action Recognition Straight from the Frequency Domain\",\"url\":\"https://www.semanticscholar.org/paper/cda76b5d34007c23d67aa2b379ca45bc9c1d8981\",\"venue\":\"2020 33rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3471544\",\"name\":\"Feixiang He\"},{\"authorId\":\"2254178\",\"name\":\"Fayao Liu\"},{\"authorId\":\"145786594\",\"name\":\"Rui Yao\"},{\"authorId\":\"2604251\",\"name\":\"Guosheng Lin\"}],\"doi\":\"10.1016/J.IMAVIS.2018.12.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"17eaac80a260bc5d665e1035d7291293b056d3b6\",\"title\":\"Local fusion networks with chained residual pooling for video action recognition\",\"url\":\"https://www.semanticscholar.org/paper/17eaac80a260bc5d665e1035d7291293b056d3b6\",\"venue\":\"Image Vis. Comput.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/ICIP.2018.8451255\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ad58b92ebc45e71e40ce68d4375441267549b054\",\"title\":\"DA-VLAD: Discriminative Action Vector of Locally Aggregated Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad58b92ebc45e71e40ce68d4375441267549b054\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1669190956\",\"name\":\"Quanling Meng\"},{\"authorId\":\"9517714\",\"name\":\"Heyan Zhu\"},{\"authorId\":\"8660383\",\"name\":\"W. Zhang\"},{\"authorId\":\"37507545\",\"name\":\"Xuefeng Piao\"},{\"authorId\":\"1669161026\",\"name\":\"A. Zhang\"}],\"doi\":\"10.1145/3350840\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a27008678d149d4d286654217a29559c2a55b96\",\"title\":\"Action Recognition Using Form and Motion Modalities\",\"url\":\"https://www.semanticscholar.org/paper/8a27008678d149d4d286654217a29559c2a55b96\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"49722633\",\"name\":\"Jixin Liu\"},{\"authorId\":\"2000194881\",\"name\":\"R. Zhang\"},{\"authorId\":\"47530538\",\"name\":\"G. Han\"},{\"authorId\":\"144202010\",\"name\":\"Ning Sun\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":\"10.1016/J.SYSARC.2020.101882\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ecda34f73c1512466b6441022f127be279a2288\",\"title\":\"Video action recognition with visual privacy protection based on compressed sensing\",\"url\":\"https://www.semanticscholar.org/paper/5ecda34f73c1512466b6441022f127be279a2288\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40760781\",\"name\":\"Zheming Zuo\"},{\"authorId\":\"1706028\",\"name\":\"L. Yang\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"2864709\",\"name\":\"F. Chao\"},{\"authorId\":\"48968697\",\"name\":\"R. Song\"},{\"authorId\":\"31851271\",\"name\":\"YanPeng Qu\"}],\"doi\":\"10.1109/TII.2019.2957268\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b3bbe379ef5f12cab36ba86d93ec40b1fbe133b7\",\"title\":\"Histogram of Fuzzy Local Spatio-Temporal Descriptors for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b3bbe379ef5f12cab36ba86d93ec40b1fbe133b7\",\"venue\":\"IEEE Transactions on Industrial Informatics\",\"year\":2020},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2269558\",\"name\":\"Q. Li\"},{\"authorId\":\"144854843\",\"name\":\"X. Zhao\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"},{\"authorId\":\"2887871\",\"name\":\"K. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2923444\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9ff61d933f95bab4d0390b0372b0e6f1829251c6\",\"title\":\"Recurrent Prediction With Spatio-Temporal Attention for Crowd Attribute Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ff61d933f95bab4d0390b0372b0e6f1829251c6\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825539\",\"name\":\"Wei Wang\"},{\"authorId\":\"152299675\",\"name\":\"Siyuan Hao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"3124720\",\"name\":\"Shengtao Xiao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ACCESS.2019.2936604\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"74195742093c489401ef8dc3d7f8639fd12c20e8\",\"title\":\"Temporal Spiking Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74195742093c489401ef8dc3d7f8639fd12c20e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"2002.08219\",\"authors\":[{\"authorId\":\"1489467112\",\"name\":\"Yeji Kim\"},{\"authorId\":\"122808682\",\"name\":\"Dong-Gyu Lee\"},{\"authorId\":\"50112753\",\"name\":\"Seong-Whan Lee\"}],\"doi\":\"10.1016/j.patcog.2020.107279\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"title\":\"Three-Stream Fusion Network for First-Person Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a8baa039ea325efa0a5de795dc820532eb3f8e77\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150223\",\"name\":\"K. Yang\"},{\"authorId\":\"47196642\",\"name\":\"Z. Wang\"},{\"authorId\":\"7944784\",\"name\":\"H. Dai\"},{\"authorId\":\"15785036\",\"name\":\"Tianlong Shen\"},{\"authorId\":\"48957961\",\"name\":\"P. Qiao\"},{\"authorId\":\"143767586\",\"name\":\"Xin Niu\"},{\"authorId\":\"47911285\",\"name\":\"J. Jiang\"},{\"authorId\":\"144032853\",\"name\":\"Dong-sheng Li\"},{\"authorId\":\"1791001\",\"name\":\"Y. Dou\"}],\"doi\":\"10.1109/ICASSP40776.2020.9053394\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"651bbfced764c3e8039adf8598def1bd1d69506d\",\"title\":\"Attentional Fused Temporal Transformation Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/651bbfced764c3e8039adf8598def1bd1d69506d\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51268431\",\"name\":\"Xinshu Qiao\"},{\"authorId\":\"9764225\",\"name\":\"Chuanwei Zhou\"},{\"authorId\":\"48258938\",\"name\":\"Chunyan Xu\"},{\"authorId\":\"144801562\",\"name\":\"Zhen Cui\"},{\"authorId\":null,\"name\":\"Jian Yang\"}],\"doi\":\"10.1109/ICIP.2018.8451548\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53da7e4e193b334ce3891a55c61593a9fe479e19\",\"title\":\"Action Recognition with Spatial-Temporal Representation Analysis Across Grassmannian Manifold and Euclidean Space\",\"url\":\"https://www.semanticscholar.org/paper/53da7e4e193b334ce3891a55c61593a9fe479e19\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1711.10143\",\"authors\":[{\"authorId\":\"47916686\",\"name\":\"Kenji Matsui\"},{\"authorId\":\"134811419\",\"name\":\"Toru Tamaki\"},{\"authorId\":\"30171131\",\"name\":\"Gwladys Auffret\"},{\"authorId\":\"1688940\",\"name\":\"Bisser Raytchev\"},{\"authorId\":\"1686272\",\"name\":\"Kazufumi Kaneda\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"title\":\"Revisiting hand-crafted feature for action recognition: a set of improved dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/714cd75fe3557b4cbce4b7d5335d06af0fa99689\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738469\",\"name\":\"A. Tapus\"},{\"authorId\":\"32045772\",\"name\":\"A. Bandera\"},{\"authorId\":\"1754151\",\"name\":\"R. Mart\\u00edn\"},{\"authorId\":\"2258049\",\"name\":\"L. Calderita\"}],\"doi\":\"10.1016/j.patrec.2018.03.006\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4248b25edbfcfa3889c55e49d3576bed685168\",\"title\":\"Perceiving the person and their interactions with the others for social robotics - A review\",\"url\":\"https://www.semanticscholar.org/paper/3d4248b25edbfcfa3889c55e49d3576bed685168\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2378843\",\"name\":\"L. Lu\"},{\"authorId\":\"1932096\",\"name\":\"Huijun Di\"},{\"authorId\":\"1803391\",\"name\":\"Y. Lu\"},{\"authorId\":\"47058844\",\"name\":\"Lin Zhang\"},{\"authorId\":\"9437193\",\"name\":\"Shunzhou Wang\"}],\"doi\":\"10.1016/j.neucom.2018.09.060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ccb80471d2bb2236b7f2c37ff9159e9b0d082474\",\"title\":\"A two-level attention-based interaction model for multi-person activity recognition\",\"url\":\"https://www.semanticscholar.org/paper/ccb80471d2bb2236b7f2c37ff9159e9b0d082474\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8492319\",\"name\":\"Z. Wang\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"145951569\",\"name\":\"Wu Luo\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICIP.2018.8451483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dce5aa041b08862f24f4e11301e9466a204d24f4\",\"title\":\"Key Joints Selection and Spatiotemporal Mining for Skeleton-Based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce5aa041b08862f24f4e11301e9466a204d24f4\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"49338773\",\"name\":\"Y. Zhan\"},{\"authorId\":\"27718163\",\"name\":\"Y. Yang\"},{\"authorId\":\"1410252832\",\"name\":\"Xing Xu\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2019.2952088\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"title\":\"A Context Knowledge Map Guided Coarse-to-Fine Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ac2b6006886e6693ce85a5c935abceef90ae3b89\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145141847\",\"name\":\"M. Fan\"},{\"authorId\":\"145264515\",\"name\":\"Qi Han\"},{\"authorId\":\"47956995\",\"name\":\"X. Zhang\"},{\"authorId\":\"47910149\",\"name\":\"Yaling Liu\"},{\"authorId\":\"10993830\",\"name\":\"Huan Chen\"},{\"authorId\":\"48484029\",\"name\":\"Y. Hu\"}],\"doi\":\"10.1109/DDCLS.2018.8515970\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f3b0452e11e44c9adb16e228defc3966e04334e\",\"title\":\"Human Action Recognition Based on Dense Sampling of Motion Boundary and Histogram of Motion Gradient\",\"url\":\"https://www.semanticscholar.org/paper/7f3b0452e11e44c9adb16e228defc3966e04334e\",\"venue\":\"2018 IEEE 7th Data Driven Control and Learning Systems Conference (DDCLS)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"9201993\",\"name\":\"S. A. Velastin\"}],\"doi\":\"10.1016/J.CVIU.2019.04.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3917d925dac0abf6e7b452fa2916c25f9e72fc2c\",\"title\":\"TAB: Temporally aggregated bag-of-discriminant-words for temporal action proposals\",\"url\":\"https://www.semanticscholar.org/paper/3917d925dac0abf6e7b452fa2916c25f9e72fc2c\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144341272\",\"name\":\"Cheng Cheng\"},{\"authorId\":\"2989422\",\"name\":\"Xianzhong Long\"},{\"authorId\":\"121704698\",\"name\":\"Yun Li\"}],\"doi\":\"10.1145/3318299.3318322\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"793d8d2c4442164282572a8e38f72bcbc0ed0a42\",\"title\":\"VLAD Encoding Based on LLC for Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/793d8d2c4442164282572a8e38f72bcbc0ed0a42\",\"venue\":\"ICMLC '19\",\"year\":2019},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145951562\",\"name\":\"W. Luo\"},{\"authorId\":\"50445655\",\"name\":\"C. Zhang\"},{\"authorId\":\"49663261\",\"name\":\"W. Liu\"},{\"authorId\":\"91945776\",\"name\":\"J. Wu\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/BigMM.2019.00-27\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de265804b8a955308f42fee71d01dfe45fe83f3b\",\"title\":\"Improving Action Recognition with Valued Patches Exploiting\",\"url\":\"https://www.semanticscholar.org/paper/de265804b8a955308f42fee71d01dfe45fe83f3b\",\"venue\":\"2019 IEEE Fifth International Conference on Multimedia Big Data (BigMM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1711.07430\",\"authors\":[{\"authorId\":\"8131625\",\"name\":\"W. Lin\"},{\"authorId\":\"145071344\",\"name\":\"Yang Mi\"},{\"authorId\":\"49388002\",\"name\":\"J. Wu\"},{\"authorId\":\"144392311\",\"name\":\"Ke Lu\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"title\":\"Action Recognition with Coarse-to-Fine Deep Feature Integration and Asynchronous Fusion\",\"url\":\"https://www.semanticscholar.org/paper/4f22d424292594c164a5f72846ac2cbfe94cd69f\",\"venue\":\"AAAI\",\"year\":2018}],\"corpusId\":4320549,\"doi\":\"10.1109/CVPR.2017.341\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":5,\"is_open_access\":false,\"is_publisher_licensed\":true,\"paperId\":\"e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144154444\",\"name\":\"Marcus Hutter\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.212\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"641421832f237b280644261a77eca3974ac9c0c1\",\"title\":\"Discriminative Hierarchical Rank Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/641421832f237b280644261a77eca3974ac9c0c1\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10578-9_43\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5716788c78748f2fd77e799bb70f8a2920cc6ec\",\"title\":\"Boosting VLAD with Supervised Dictionary Learning and High-Order Statistics\",\"url\":\"https://www.semanticscholar.org/paper/b5716788c78748f2fd77e799bb70f8a2920cc6ec\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144434220\",\"name\":\"X. Yang\"},{\"authorId\":\"2824500\",\"name\":\"P. Molchanov\"},{\"authorId\":\"1690538\",\"name\":\"J. Kautz\"}],\"doi\":\"10.1145/2964284.2964297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"title\":\"Multilayer and Multimodal Fusion of Deep Neural Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/ed1fe0b01c0e97fa840dc4d9f020e8ce1f7ea3c7\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145096334\",\"name\":\"K. Reddy\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s00138-012-0450-4\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c7eee57d8a8c057ab1f599105d16d0e8489a61e0\",\"title\":\"Recognizing 50 human action categories of web videos\",\"url\":\"https://www.semanticscholar.org/paper/c7eee57d8a8c057ab1f599105d16d0e8489a61e0\",\"venue\":\"Machine Vision and Applications\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1716733\",\"name\":\"P. Bouthemy\"}],\"doi\":\"10.1109/CVPR.2013.330\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"title\":\"Better Exploiting Motion for Better Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9a4bff7e93a2d2d50495d873890cf52f868d3b66\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2155311\",\"name\":\"Eunbyung Park\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"}],\"doi\":\"10.1109/WACV.2016.7477589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"title\":\"Combining multiple sources of knowledge in deep CNNs for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/ec44bf99ba11f3b6d0bb32dd5bc6ac08dd0c63d6\",\"venue\":\"2016 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2016},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1864288\",\"name\":\"I. Everts\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"},{\"authorId\":\"1695527\",\"name\":\"T. Gevers\"}],\"doi\":\"10.1109/TIP.2014.2302677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"624a14e83a4deb9f0667da6754f75f8f7bcda5d8\",\"title\":\"Evaluation of Color Spatio-Temporal Interest Points for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/624a14e83a4deb9f0667da6754f75f8f7bcda5d8\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2014},{\"arxivId\":\"1608.08851\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"title\":\"Efficient Two-Stream Motion and Appearance 3D CNNs for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1604.07669\",\"authors\":[{\"authorId\":\"3047890\",\"name\":\"Bowen Zhang\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"}],\"doi\":\"10.1109/CVPR.2016.297\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"title\":\"Real-Time Action Recognition with Enhanced Motion Vector CNNs\",\"url\":\"https://www.semanticscholar.org/paper/3d4cf68fad61cd7dc9061670ba3864a7fdf87d4c\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799216\",\"name\":\"Jeong-Jik Seo\"},{\"authorId\":\"2645625\",\"name\":\"H. Kim\"},{\"authorId\":\"7627712\",\"name\":\"W. D. Neve\"},{\"authorId\":\"7251290\",\"name\":\"Yong Man Ro\"}],\"doi\":\"10.1016/j.imavis.2016.06.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6c491fb6a57c9a7c2d71522a1a066be2e681c84\",\"title\":\"Effective and efficient human action recognition using dynamic frame skipping and trajectory rejection\",\"url\":\"https://www.semanticscholar.org/paper/e6c491fb6a57c9a7c2d71522a1a066be2e681c84\",\"venue\":\"Image Vis. Comput.\",\"year\":2017},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2003.1238663\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"642e328cae81c5adb30069b680cf60ba6b475153\",\"title\":\"Video Google: a text retrieval approach to object matching in videos\",\"url\":\"https://www.semanticscholar.org/paper/642e328cae81c5adb30069b680cf60ba6b475153\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2827750\",\"name\":\"Berkan Solmaz\"},{\"authorId\":\"2963501\",\"name\":\"S. M. Assari\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1007/s00138-012-0449-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"797f32a0c07c99d2718477c2bdbce71b1ec76e62\",\"title\":\"Classifying web videos using a global video descriptor\",\"url\":\"https://www.semanticscholar.org/paper/797f32a0c07c99d2718477c2bdbce71b1ec76e62\",\"venue\":\"Machine Vision and Applications\",\"year\":2012},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2695601\",\"name\":\"Vadim Kantorov\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/CVPR.2014.332\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"482f7471c708f371cbd7658aa4a48187dc830e17\",\"title\":\"Efficient Feature Extraction, Encoding, and Classification for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/482f7471c708f371cbd7658aa4a48187dc830e17\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"1770571\",\"name\":\"Bertrand Delezoide\"},{\"authorId\":\"1742371\",\"name\":\"F. Pr\\u00eateux\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/ICCV.2013.336\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4aedadc4866271c8a41cfd9158e5a70bf628b94f\",\"title\":\"Space-Time Robust Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4aedadc4866271c8a41cfd9158e5a70bf628b94f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2011.235\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5183230b706b72f6f6c19415c423d93c79ddde53\",\"title\":\"Aggregating Local Image Descriptors into Compact Codes\",\"url\":\"https://www.semanticscholar.org/paper/5183230b706b72f6f6c19415c423d93c79ddde53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1007/s11263-005-1838-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"title\":\"On Space-Time Interest Points\",\"url\":\"https://www.semanticscholar.org/paper/d2fb2fa53021b2776da0fb8b53c54820ed3982cc\",\"venue\":\"International Journal of Computer Vision\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3347447\",\"name\":\"Sanath Narayan\"},{\"authorId\":\"145986798\",\"name\":\"K. Ramakrishnan\"}],\"doi\":\"10.1109/CVPR.2014.337\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fcead8c3b491076165f6c5168eaa147dcc550f2\",\"title\":\"A Cause and Effect Analysis of Motion Trajectories for Modeling Actions\",\"url\":\"https://www.semanticscholar.org/paper/7fcead8c3b491076165f6c5168eaa147dcc550f2\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"134861178\",\"name\":\"Wei Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPRW.2009.5206848\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/d2c733e34d48784a37d717fe43d9e93277a8c53e\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1716310\",\"name\":\"E. Sangineto\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/s13735-014-0069-5\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"aa5e24ac5ea78fb9ee4f39143a5c0b74e9eced98\",\"title\":\"Video classification with Densely extracted HOG/HOF/MBH features: an evaluation of the accuracy/computational efficiency trade-off\",\"url\":\"https://www.semanticscholar.org/paper/aa5e24ac5ea78fb9ee4f39143a5c0b74e9eced98\",\"venue\":\"International Journal of Multimedia Information Retrieval\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"2599281\",\"name\":\"N. Rostamzadeh\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1145/2578726.2578744\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c9f85d1c6d568af3cbfbca7e62321cfcb952248\",\"title\":\"Realtime Video Classification using Dense HOF/HOG\",\"url\":\"https://www.semanticscholar.org/paper/2c9f85d1c6d568af3cbfbca7e62321cfcb952248\",\"venue\":\"ICMR\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1007/s11263-012-0594-8\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"title\":\"Dense Trajectories and Motion Boundary Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bbe0819a47a9f3f11dd34bb3ab44a997ef111088\",\"venue\":\"International Journal of Computer Vision\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39851640\",\"name\":\"X. Zhou\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"},{\"authorId\":\"49104973\",\"name\":\"Tong Zhang\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1007/978-3-642-15555-0_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4e65c9f0a64b6a4333b12e2adc3861ad75aca83b\",\"title\":\"Image Classification Using Super-Vector Coding of Local Image Descriptors\",\"url\":\"https://www.semanticscholar.org/paper/4e65c9f0a64b6a4333b12e2adc3861ad75aca83b\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1411.4006\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298789\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"title\":\"A discriminative CNN video representation for event detection\",\"url\":\"https://www.semanticscholar.org/paper/10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"I.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Laptev . On space - time interest points\",\"url\":\"\",\"venue\":\"IJCV\",\"year\":2011},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"144189388\",\"name\":\"J. Ponce\"}],\"doi\":\"10.1109/CVPR.2006.68\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dbaff29d3898cf60f63f5a34cb9610ebb75220c\",\"title\":\"Beyond Bags of Features: Spatial Pyramid Matching for Recognizing Natural Scene Categories\",\"url\":\"https://www.semanticscholar.org/paper/6dbaff29d3898cf60f63f5a34cb9610ebb75220c\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.228\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08e61adbfa2178e3fa895a7f85a84597c183aede\",\"title\":\"Action and Event Recognition with Fisher Vectors on a Compact Feature Set\",\"url\":\"https://www.semanticscholar.org/paper/08e61adbfa2178e3fa895a7f85a84597c183aede\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145254044\",\"name\":\"Jun Zhu\"},{\"authorId\":\"2450889\",\"name\":\"B. Wang\"},{\"authorId\":\"1795291\",\"name\":\"X. Yang\"},{\"authorId\":\"31064779\",\"name\":\"W. Zhang\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":\"10.1109/ICCV.2013.442\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21e8f3344170a8f133b69308c178518df8a27274\",\"title\":\"Action Recognition with Actons\",\"url\":\"https://www.semanticscholar.org/paper/21e8f3344170a8f133b69308c178518df8a27274\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1823362\",\"name\":\"J. Uijlings\"},{\"authorId\":\"40429857\",\"name\":\"T. Nguyen\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/CBMI.2016.7500260\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1824da04987caa42417cdf5a3008b8006e1610ba\",\"title\":\"Histograms of Motion Gradients for real-time video classification\",\"url\":\"https://www.semanticscholar.org/paper/1824da04987caa42417cdf5a3008b8006e1610ba\",\"venue\":\"2016 14th International Workshop on Content-Based Multimedia Indexing (CBMI)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"40429857\",\"name\":\"T. Nguyen\"},{\"authorId\":\"1712839\",\"name\":\"K. Aizawa\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ICPR.2016.7899964\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1a167e10fe57f6d6eff0bb9e45c94924d9347a3e\",\"title\":\"Boosting VLAD with double assignment using deep features for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/1a167e10fe57f6d6eff0bb9e45c94924d9347a3e\",\"venue\":\"2016 23rd International Conference on Pattern Recognition (ICPR)\",\"year\":2016},{\"arxivId\":\"1504.05524\",\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"3095774\",\"name\":\"Dan Oneata\"},{\"authorId\":\"1721683\",\"name\":\"J. Verbeek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/s11263-015-0846-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"title\":\"A Robust and Efficient Video Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb84bb1f298efe45d4f7571e32083f83ae8e5ba9\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2013.207\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"25d0fa49ca846370ff4796a6ac6688a42cf50f77\",\"title\":\"All About VLAD\",\"url\":\"https://www.semanticscholar.org/paper/25d0fa49ca846370ff4796a6ac6688a42cf50f77\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1759152\",\"name\":\"Ionut Mironica\"},{\"authorId\":\"153580352\",\"name\":\"Ionut Cosmin Duta\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1007/s11042-015-2819-7\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"1b3895364de8a12a43b0a4a258fa755cab17ffb7\",\"title\":\"A modified vector of locally aggregated descriptors approach for fast video classification\",\"url\":\"https://www.semanticscholar.org/paper/1b3895364de8a12a43b0a4a258fa755cab17ffb7\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46968909\",\"name\":\"Ju Sun\"},{\"authorId\":\"47150103\",\"name\":\"Xiao Wu\"},{\"authorId\":\"143653681\",\"name\":\"S. Yan\"},{\"authorId\":\"6835136\",\"name\":\"L. Cheong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"},{\"authorId\":\"1706774\",\"name\":\"J. Li\"}],\"doi\":\"10.1109/CVPR.2009.5206721\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f4ca64c6d45b71dec91d1aa9dde3f13f7f4e6e80\",\"title\":\"Hierarchical spatio-temporal context modeling for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4ca64c6d45b71dec91d1aa9dde3f13f7f4e6e80\",\"venue\":\"CVPR\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1687524\",\"name\":\"A. Vedaldi\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2016.331\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"title\":\"Dynamic Image Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5aae6f1aedb3e78a05bc430a1d8b86cac33c5184\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7dffe7498c67e9451db2d04bb8408f376ae86992\",\"title\":\"LEAR-INRIA submission for the THUMOS workshop\",\"url\":\"https://www.semanticscholar.org/paper/7dffe7498c67e9451db2d04bb8408f376ae86992\",\"venue\":\"\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145327729\",\"name\":\"Feng Shi\"},{\"authorId\":\"1745632\",\"name\":\"E. Petriu\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CVPR.2013.335\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b360fdc731997ad2efe4ab0687057f691f365c62\",\"title\":\"Sampling Strategies for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b360fdc731997ad2efe4ab0687057f691f365c62\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3244141\",\"name\":\"A. Ciptadi\"},{\"authorId\":\"1769348\",\"name\":\"Matthew S. Goodwin\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1007/978-3-319-10605-2_45\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bc0254d2fc53bb81cfb21318fed8b71eb5757785\",\"title\":\"Movement Pattern Histogram for Action Recognition and Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/bc0254d2fc53bb81cfb21318fed8b71eb5757785\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1512.01848\",\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/TPAMI.2016.2558148\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd4defba71c686946351f5e7a090c7aa8136d32f\",\"title\":\"Rank Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4defba71c686946351f5e7a090c7aa8136d32f\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Spatio-Temporal Vector of Locally Max Pooled Features for Action Recognition in Videos\",\"topics\":[{\"topic\":\"Computational complexity theory\",\"topicId\":\"1133\",\"url\":\"https://www.semanticscholar.org/topic/1133\"},{\"topic\":\"Fisher\\u2013Yates shuffle\",\"topicId\":\"600574\",\"url\":\"https://www.semanticscholar.org/topic/600574\"},{\"topic\":\"Neuron\",\"topicId\":\"8353\",\"url\":\"https://www.semanticscholar.org/topic/8353\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"}],\"url\":\"https://www.semanticscholar.org/paper/e3ce4c3e1279e3dc0c14ff3bb2920aced9e62638\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"