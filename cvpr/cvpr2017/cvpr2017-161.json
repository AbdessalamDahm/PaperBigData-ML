"{\"abstract\":\"The CNN-encoding of features from entire videos for the representation of human actions has rarely been addressed. Instead, CNN work has focused on approaches to fuse spatial and temporal networks, but these were typically limited to processing shorter sequences. We present a new video representation, called temporal linear encoding (TLE) and embedded inside of CNNs as a new layer, which captures the appearance and motion throughout entire videos. It encodes this aggregated information into a robust video feature representation, via end-to-end learning. Advantages of TLEs are: (a) they encode the entire video into a compact feature representation, learning the semantics and a discriminative feature space, (b) they are applicable to all kinds of networks like 2D and 3D CNNs for video classification, and (c) they model feature interactions in a more expressive way and without loss of information. We conduct experiments on two challenging human action datasets: HMDB51 and UCF101. The experiments show that TLE outperforms current state-of-the-art methods on both datasets.\",\"arxivId\":\"1611.06678\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\",\"url\":\"https://www.semanticscholar.org/author/3310120\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\",\"url\":\"https://www.semanticscholar.org/author/50633800\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\",\"url\":\"https://www.semanticscholar.org/author/1681236\"}],\"citationVelocity\":45,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"40590308\",\"name\":\"Chen Chen\"},{\"authorId\":\"145798959\",\"name\":\"Zhenhua Zhu\"},{\"authorId\":\"144964918\",\"name\":\"A. Hammad\"}],\"doi\":\"10.1016/j.autcon.2019.103045\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f0ce5f3eefc6b646090897db82e71dcf0a22c9f\",\"title\":\"Automated excavators activity recognition and productivity analysis from construction site surveillance videos\",\"url\":\"https://www.semanticscholar.org/paper/3f0ce5f3eefc6b646090897db82e71dcf0a22c9f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"145082678\",\"name\":\"G. Chen\"}],\"doi\":\"10.1007/978-3-030-05710-7_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"title\":\"Hierarchical Temporal Pooling for Efficient Online Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":\"1807.04445\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-030-01240-3_9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"04791b727d0b0820d110288546fa5d3fb5528a63\",\"title\":\"Adding Attentiveness to the Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/04791b727d0b0820d110288546fa5d3fb5528a63\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1109/ACCESS.2019.2895472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"title\":\"Deep Spatiotemporal Relation Learning With 3D Multi-Level Dense Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/82d4b2272799f0c4acc284bbc6ed3eaeeefdc7c0\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"},{\"authorId\":\"113011036\",\"name\":\"Kun-Hsuan Wu\"}],\"doi\":\"10.1109/ICASSP.2019.8682450\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"title\":\"Multi-teacher Knowledge Distillation for Compressed Video Action Recognition on Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cb847b8ff42194165bd3cc55368e8df15c992f7\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1711.11152\",\"authors\":[{\"authorId\":\"47392986\",\"name\":\"S. Sun\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"84200540\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"title\":\"Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/42517e072406ea6f8d2c579d98ee3f9918a8a1d3\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"1388834506\",\"name\":\"Hao Jiang\"}],\"doi\":\"10.1109/CVPR.2019.01213\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"title\":\"Action4D: Online Action Recognition in the Crowd and Clutter\",\"url\":\"https://www.semanticscholar.org/paper/5b5c59d5ee264227a370ea68929bfcac0209b4e0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49890940\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9276668\",\"name\":\"Kuangrong Hao\"},{\"authorId\":\"2269658\",\"name\":\"Xue-Song Tang\"},{\"authorId\":\"40190124\",\"name\":\"Bing Wei\"},{\"authorId\":\"36416361\",\"name\":\"Lihong Ren\"}],\"doi\":\"10.1109/ICAICA.2019.8873471\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"89041a6a962fd68b23c29bb6e9c1516a82f6e5e3\",\"title\":\"Long-term 3D Convolutional Fusion Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89041a6a962fd68b23c29bb6e9c1516a82f6e5e3\",\"venue\":\"2019 IEEE International Conference on Artificial Intelligence and Computer Applications (ICAICA)\",\"year\":2019},{\"arxivId\":\"2003.11241\",\"authors\":[{\"authorId\":\"49110790\",\"name\":\"Qilong Wang\"},{\"authorId\":\"48571183\",\"name\":\"Liyong Zhang\"},{\"authorId\":\"1387668229\",\"name\":\"Banggu Wu\"},{\"authorId\":\"2404143\",\"name\":\"Dongwei Ren\"},{\"authorId\":\"40426020\",\"name\":\"P. Li\"},{\"authorId\":\"121977442\",\"name\":\"W. Zuo\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1109/cvpr42600.2020.01078\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d06ac6043c76ab20969e110030125bc922535bf\",\"title\":\"What Deep CNNs Benefit From Global Covariance Pooling: An Optimization Perspective\",\"url\":\"https://www.semanticscholar.org/paper/1d06ac6043c76ab20969e110030125bc922535bf\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/ACCESS.2019.2953455\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"title\":\"Spatio-Temporal Representation Matching-Based Open-Set Action Recognition by Joint Learning of Motion and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/345a2fa96bb50c7986cd39875ac9d55b7f2c7769\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"50030836\",\"name\":\"Xudong Yang\"}],\"doi\":\"10.1007/978-3-030-04167-0_23\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"caae04e73d362180f9586fabb224244200add105\",\"title\":\"Multi-stream with Deep Convolutional Neural Networks for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/caae04e73d362180f9586fabb224244200add105\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2345721\",\"name\":\"S. Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1145/3139958.3140055\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"40dd736c803720890d6bfc1e083f6050e35d8f7a\",\"title\":\"Large-Scale Mapping of Human Activity using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/40dd736c803720890d6bfc1e083f6050e35d8f7a\",\"venue\":\"SIGSPATIAL/GIS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2961531\",\"name\":\"M. Hosseini\"},{\"authorId\":\"145226394\",\"name\":\"F. Ghaderi\"}],\"doi\":\"10.5829/ije.2020.33.05b.29\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"title\":\"A Hybrid Deep Learning Architecture Using 3D CNNs and GRUs for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ec274b911cf19d45b7cb2e92bcc7e42bd70a156\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35336338\",\"name\":\"Jae Woong Soh\"},{\"authorId\":\"2370571\",\"name\":\"Jaewoo Park\"},{\"authorId\":\"8797410\",\"name\":\"Y. Kim\"},{\"authorId\":\"2400108\",\"name\":\"Byeongyong Ahn\"},{\"authorId\":\"30649390\",\"name\":\"H. Lee\"},{\"authorId\":\"2884493\",\"name\":\"Young-Su Moon\"},{\"authorId\":\"1707645\",\"name\":\"N. I. Cho\"}],\"doi\":\"10.1109/ACCESS.2018.2876864\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3fd10f68ec61a3723915708f65670f0a32d3066c\",\"title\":\"Reduction of Video Compression Artifacts Based on Deep Temporal Networks\",\"url\":\"https://www.semanticscholar.org/paper/3fd10f68ec61a3723915708f65670f0a32d3066c\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49658876\",\"name\":\"Z. Zhu\"},{\"authorId\":\"153172093\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"73312165\",\"name\":\"Wen-bo Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.12.077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"title\":\"Nonlinear gated channels networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d57ee13b28e6c918ef534e5d88363f5c487513a8\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2751577\",\"name\":\"Chenjie Ge\"},{\"authorId\":\"1761436\",\"name\":\"I. Y. Gu\"},{\"authorId\":\"47440958\",\"name\":\"A. Jakola\"},{\"authorId\":\"35979370\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/ACCESS.2020.2969805\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48caba34d8280f5169b4db674cc331d470c06262\",\"title\":\"Enlarged Training Dataset by Pairwise GANs for Molecular-Based Brain Tumor Classification\",\"url\":\"https://www.semanticscholar.org/paper/48caba34d8280f5169b4db674cc331d470c06262\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145161471\",\"name\":\"Y. Yoon\"},{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"2184044\",\"name\":\"Moongu Jeon\"}],\"doi\":\"10.1109/AVSS.2019.8909868\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60d7c89c12351d5b05f221092ed537d0869228b2\",\"title\":\"Spatio-Temporal Feature Extraction and Distance Metric Learning for Unconstrained Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/60d7c89c12351d5b05f221092ed537d0869228b2\",\"venue\":\"2019 16th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)\",\"year\":2019},{\"arxivId\":\"2004.02205\",\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"e908719ae2a09e3726300df65bcd31dfddea5a86\",\"title\":\"Deep Multimodal Feature Encoding for Video Ordering\",\"url\":\"https://www.semanticscholar.org/paper/e908719ae2a09e3726300df65bcd31dfddea5a86\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40415139\",\"name\":\"Neelay Pandit\"},{\"authorId\":\"40005980\",\"name\":\"S. Abdelhak\"}],\"doi\":\"10.1145/3126686.3126775\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c648da4d3b0fb7f175111ddad58ba912b37d9c6\",\"title\":\"Evolution of Trajectories: A Novel Representation for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c648da4d3b0fb7f175111ddad58ba912b37d9c6\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1906.05571\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"143977389\",\"name\":\"C. Ngo\"},{\"authorId\":\"40434674\",\"name\":\"X. Tian\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01233\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"title\":\"Learning Spatio-Temporal Representation With Local and Global Diffusion\",\"url\":\"https://www.semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145770427\",\"name\":\"Lin Ding\"},{\"authorId\":\"144051792\",\"name\":\"Yonghong Tian\"},{\"authorId\":\"25141665\",\"name\":\"Hongfei Fan\"},{\"authorId\":\"1485105756\",\"name\":\"Changhuai Chen\"},{\"authorId\":\"50592933\",\"name\":\"Tiejun Huang\"}],\"doi\":\"10.1109/TIP.2020.2965306\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"398b5f6b317dd6ecdd81cbd9723030db2a5bed0e\",\"title\":\"Joint Coding of Local and Global Deep Features in Videos for Visual Search\",\"url\":\"https://www.semanticscholar.org/paper/398b5f6b317dd6ecdd81cbd9723030db2a5bed0e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38298733\",\"name\":\"Muhaddisa Barat Ali\"},{\"authorId\":\"1761436\",\"name\":\"I. Y. Gu\"},{\"authorId\":\"82318840\",\"name\":\"M. Berger\"},{\"authorId\":\"6724181\",\"name\":\"J. Pallud\"},{\"authorId\":\"6995924\",\"name\":\"Derek G. Southwell\"},{\"authorId\":\"1686641\",\"name\":\"G. Widhalm\"},{\"authorId\":\"34519106\",\"name\":\"A. Roux\"},{\"authorId\":\"1906065075\",\"name\":\"Tom\\u00e1s Gomez Vecchio\"},{\"authorId\":\"47440958\",\"name\":\"A. Jakola\"}],\"doi\":\"10.3390/brainsci10070463\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c097e8832a988c43d930e65d48875f20965c96f\",\"title\":\"Domain Mapping and Deep Learning from Multiple MRI Clinical Datasets for Prediction of Molecular Subtypes in Low Grade Gliomas\",\"url\":\"https://www.semanticscholar.org/paper/4c097e8832a988c43d930e65d48875f20965c96f\",\"venue\":\"Brain sciences\",\"year\":2020},{\"arxivId\":\"2012.10283\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"title\":\"Temporal Bilinear Encoding Network of Audio-Visual Features at Low Sampling Rates\",\"url\":\"https://www.semanticscholar.org/paper/eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48799346\",\"name\":\"W. Chang\"},{\"authorId\":\"2395047\",\"name\":\"C. Ye\"},{\"authorId\":\"1725354018\",\"name\":\"Hui Zhou\"}],\"doi\":\"10.1007/978-3-030-50347-5_18\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"title\":\"Two-Stream Framework for Activity Recognition with 2D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/43c49aaee9a83a41e6950add3dc32371f6ef1462\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":\"1804.10021\",\"authors\":[{\"authorId\":\"143688987\",\"name\":\"X. Yan\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"2404621\",\"name\":\"Hanlin Qin\"},{\"authorId\":\"3446916\",\"name\":\"Mingtao Feng\"},{\"authorId\":\"48570713\",\"name\":\"L. Zhang\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22e03419db32dd1a68394a545dcc400653df58f5\",\"title\":\"Deep Keyframe Detection in Human Action Videos\",\"url\":\"https://www.semanticscholar.org/paper/22e03419db32dd1a68394a545dcc400653df58f5\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.09403\",\"authors\":[{\"authorId\":\"41049768\",\"name\":\"Amlaan Bhoi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"title\":\"Spatio-temporal Action Recognition: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/76c67fb26e0c48efa4062bb9f288a1ceb8b332ee\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"1718355\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"title\":\"Two-Stream Oriented Video Super-Resolution for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/39e04aa60e7e7824f26988fc9df3b42143bc8222\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.02651\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.3390/app10186241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"title\":\"Learning Class Regularized Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c30d284bcba14754bbc020c7cf2688e2f831e97e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49694933\",\"name\":\"Ziheng Guo\"},{\"authorId\":\"145906066\",\"name\":\"Yang Chen\"},{\"authorId\":\"47504563\",\"name\":\"W. Huang\"},{\"authorId\":null,\"name\":\"Junhao Zhang\"}],\"doi\":\"10.1007/978-3-030-30508-6_26\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"title\":\"An Efficient 3D-NAS Method for Video-Based Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c615e11e6480390eeb7cb0bf6761971fddeffa36\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"27687205\",\"name\":\"N. Efthymiou\"},{\"authorId\":\"2539459\",\"name\":\"Petros Koutras\"},{\"authorId\":\"30192180\",\"name\":\"P. P. Filntisis\"},{\"authorId\":\"1688852\",\"name\":\"G. Potamianos\"},{\"authorId\":\"1750686\",\"name\":\"P. Maragos\"}],\"doi\":\"10.1109/ICIP.2018.8451146\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b56a568799a0dee06587d8ab54032f7bf7712008\",\"title\":\"Multi- View Fusion for Action Recognition in Child-Robot Interaction\",\"url\":\"https://www.semanticscholar.org/paper/b56a568799a0dee06587d8ab54032f7bf7712008\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2751577\",\"name\":\"Chenjie Ge\"},{\"authorId\":\"144515956\",\"name\":\"I. Gu\"},{\"authorId\":\"47440958\",\"name\":\"A. Jakola\"},{\"authorId\":\"1688428\",\"name\":\"Jie Yang\"}],\"doi\":\"10.1109/EMBC.2018.8513556\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7e668ed60bcd8caf3873cdff663f2ce69e60cd0\",\"title\":\"Deep Learning and Multi-Sensor Fusion for Glioma Classification Using Multistream 2D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/c7e668ed60bcd8caf3873cdff663f2ce69e60cd0\",\"venue\":\"2018 40th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1808.00022\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1016/j.cviu.2019.102799\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ef7b835c451793a6ea603fa3d5441901832c404e\",\"title\":\"Analyzing human-human interactions: A survey\",\"url\":\"https://www.semanticscholar.org/paper/ef7b835c451793a6ea603fa3d5441901832c404e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2008.04137\",\"authors\":[{\"authorId\":\"1410839772\",\"name\":\"Iker Ceballos\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"122043963\",\"name\":\"E. M\\u00fagica\"},{\"authorId\":\"40077386\",\"name\":\"Abhishek Singh\"},{\"authorId\":\"144258665\",\"name\":\"A. Rom\\u00e1n\"},{\"authorId\":\"2927870\",\"name\":\"Praneeth Vepakomma\"},{\"authorId\":\"1491799563\",\"name\":\"Ramesh Raskar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"195bad7b043542c9d0a7dccd93e04df3f4bdedcc\",\"title\":\"SplitNN-driven Vertical Partitioning\",\"url\":\"https://www.semanticscholar.org/paper/195bad7b043542c9d0a7dccd93e04df3f4bdedcc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3381029\",\"name\":\"J. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2019.102898\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"62af68e20481f9f98509bfed69ef1300a8e9485e\",\"title\":\"Cascade multi-head attention networks for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/62af68e20481f9f98509bfed69ef1300a8e9485e\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":\"1906.01004\",\"authors\":[{\"authorId\":null,\"name\":\"Yan Zhang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"152284539\",\"name\":\"Qianli Ma\"},{\"authorId\":\"143627576\",\"name\":\"Heiko Neumann\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"title\":\"Frontal Low-rank Random Tensors for Fine-grained Action Segmentation.\",\"url\":\"https://www.semanticscholar.org/paper/8d8bf28727f1b2bc1a47425f3b6ec59bb8381f5b\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.01939\",\"authors\":[{\"authorId\":\"48754312\",\"name\":\"Pengfei Zhang\"},{\"authorId\":\"3280033\",\"name\":\"J. Xue\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1109/TIP.2019.2937724\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1d0b8606483d6d9c1cdb5b8953bf61773bf633db\",\"title\":\"EleAtt-RNN: Adding Attentiveness to Neurons in Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/1d0b8606483d6d9c1cdb5b8953bf61773bf633db\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1802.04962\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2242116\",\"name\":\"Youngjin Yoon\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/WACV.2018.00189\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"title\":\"Disjoint Multi-task Learning Between Heterogeneous Human-Centric Tasks\",\"url\":\"https://www.semanticscholar.org/paper/a92b5234b8b73e06709dd48ec5f0ec357c1aabed\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47599321\",\"name\":\"Qian Wang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"title\":\"Zero-shot visual recognition via latent embedding learning\",\"url\":\"https://www.semanticscholar.org/paper/6ac568fa4e641c4a5b9f5ada98fb1eafe7b4d157\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36054719\",\"name\":\"A. Campilho\"},{\"authorId\":\"122498433\",\"name\":\"F. Karray\"},{\"authorId\":\"1491092225\",\"name\":\"Zhou Wang\"},{\"authorId\":\"1743774\",\"name\":\"E. Bertino\"}],\"doi\":\"10.1007/978-3-030-50347-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"title\":\"Image Analysis and Recognition: 17th International Conference, ICIAR 2020, P\\u00f3voa de Varzim, Portugal, June 24\\u201326, 2020, Proceedings, Part I\",\"url\":\"https://www.semanticscholar.org/paper/6ef4cc8126a312c5e4be1190e28238dc46f50aec\",\"venue\":\"ICIAR\",\"year\":2020},{\"arxivId\":\"1909.10236\",\"authors\":[{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"1591131960\",\"name\":\"Yiheng Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"0194898fea5464fe016d0ca202458a26485bf932\",\"title\":\"Scheduled Differentiable Architecture Search for Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0194898fea5464fe016d0ca202458a26485bf932\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"title\":\"MiCT : Mixed 3 D / 2 D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cb2917413c9b36c3bb9739bce6c03a1a6eb619b3\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1711.08200\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"title\":\"Temporal 3D ConvNets: New Architecture and Transfer Learning for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5ce640bbb9d6417fd0853ed88a9e7b93d72910d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-319-97909-0_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5549576809e8f9c3871c31285601f71d2d82ce5d\",\"title\":\"Residual Gating Fusion Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5549576809e8f9c3871c31285601f71d2d82ce5d\",\"venue\":\"CCBR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"},{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"}],\"doi\":\"10.1109/CVPR.2018.00814\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f11acabdc1aa9fb8917431268f85746b88d88c32\",\"title\":\"LAMV: Learning to Align and Match Videos with Kernelized Temporal Layers\",\"url\":\"https://www.semanticscholar.org/paper/f11acabdc1aa9fb8917431268f85746b88d88c32\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.13474\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":\"10.1109/ICMLA.2019.00036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"title\":\"Spatio-Temporal FAST 3D Convolutions for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/df3b3722df9f1c6a6b586a1c81a109c61ae7f9a9\",\"venue\":\"2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA)\",\"year\":2019},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30557120\",\"name\":\"Heeseung Kwon\"},{\"authorId\":\"2483916\",\"name\":\"Suha Kwak\"},{\"authorId\":\"72643925\",\"name\":\"Minsu Cho\"}],\"doi\":\"10.1145/3265987.3265991\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0a188802d96d6b045e57142f3c3bb3375d0f84ed\",\"title\":\"Video Understanding via Convolutional Temporal Pooling Network and Multimodal Feature Fusion\",\"url\":\"https://www.semanticscholar.org/paper/0a188802d96d6b045e57142f3c3bb3375d0f84ed\",\"venue\":\"CoVieW@MM\",\"year\":2018},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49455479\",\"name\":\"Y. Zhou\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"}],\"doi\":\"10.1109/CVPR.2018.00054\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b85b79d0535da7e994e419a75f65b2758bf90f21\",\"title\":\"MiCT: Mixed 3D/2D Convolutional Tube for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b85b79d0535da7e994e419a75f65b2758bf90f21\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"47067803\",\"name\":\"Hao Jiang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"title\":\"Action 4 D : Online Action Recognition in the Crowd and Clutter Quanzeng\",\"url\":\"https://www.semanticscholar.org/paper/53ff10d5c64f8b753e7ba04c8ab554901eb0e1b0\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3458261\",\"name\":\"Quanle Liu\"},{\"authorId\":\"1961065\",\"name\":\"Xiangjiu Che\"},{\"authorId\":\"3079649\",\"name\":\"Mei Bie\"}],\"doi\":\"10.1109/ACCESS.2019.2923651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"title\":\"R-STAN: Residual Spatial-Temporal Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/c93fea9dba471ad0b42ba7b217cbe5ee1bc74a26\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144739475\",\"name\":\"Jian Xiong\"},{\"authorId\":\"97295020\",\"name\":\"Liguo Lu\"},{\"authorId\":\"51464961\",\"name\":\"Hengbing Wang\"},{\"authorId\":null,\"name\":\"Jie Yang\"},{\"authorId\":\"152593447\",\"name\":\"Guan Gui\"}],\"doi\":\"10.1109/ACCESS.2019.2931471\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9339c00617b803c2426ad37dffaaff981ad9396\",\"title\":\"Object-Level Trajectories Based Fine-Grained Action Recognition in Visual IoT Applications\",\"url\":\"https://www.semanticscholar.org/paper/e9339c00617b803c2426ad37dffaaff981ad9396\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40351549\",\"name\":\"He Zhao\"},{\"authorId\":\"1516251189\",\"name\":\"Rick Wildes\"}],\"doi\":\"10.1109/ICCV.2019.00710\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"title\":\"Spatiotemporal Feature Residual Propagation for Action Prediction\",\"url\":\"https://www.semanticscholar.org/paper/93c6f04511240bcdcb6d51d8f457559dd63f4cf2\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47827957\",\"name\":\"Y. Zhao\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/CVPR.2018.00687\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d66e13a5e128a4ecad78e0c1c128893684292dec\",\"title\":\"Recognize Actions by Disentangling Components of Dynamics\",\"url\":\"https://www.semanticscholar.org/paper/d66e13a5e128a4ecad78e0c1c128893684292dec\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1709.03655\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"e19ebad4739d59f999d192bac7d596b20b887f78\",\"title\":\"Learning Gating ConvNet for Two-Stream based Methods in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e19ebad4739d59f999d192bac7d596b20b887f78\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1903.05577\",\"authors\":[{\"authorId\":\"50993183\",\"name\":\"Haochen Zhang\"},{\"authorId\":\"48928981\",\"name\":\"Dong Liu\"},{\"authorId\":\"2352456\",\"name\":\"Z. Xiong\"}],\"doi\":\"10.1109/ICCV.2019.00889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cb72cbdb5476118a207a51054787f6419d5ec055\",\"title\":\"Two-Stream Action Recognition-Oriented Video Super-Resolution\",\"url\":\"https://www.semanticscholar.org/paper/cb72cbdb5476118a207a51054787f6419d5ec055\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"title\":\"Image-set, Temporal and Spatiotemporal Representations of Videos for Recognizing, Localizing and Quantifying Actions\",\"url\":\"https://www.semanticscholar.org/paper/c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":\"10.1109/ICPR.2018.8545639\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"title\":\"Two-Stream Gated Fusion ConvNets for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1706.07911\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"50152762\",\"name\":\"Sen Liu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"title\":\"Large-Scale Human Activity Mapping using Geo-Tagged Videos\",\"url\":\"https://www.semanticscholar.org/paper/30b74e60ec11c0ebc4e640637d56d85872dd17ce\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1707.01408\",\"authors\":[{\"authorId\":\"2319973\",\"name\":\"Po-Yao Huang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"144811744\",\"name\":\"L. Jiang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60949b3f1c4da438f9955fe1015a1e569f8f123f\",\"title\":\"Video Representation Learning and Latent Concept Mining for Large-scale Multi-label Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/60949b3f1c4da438f9955fe1015a1e569f8f123f\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38298733\",\"name\":\"Muhaddisa Barat Ali\"},{\"authorId\":\"144515956\",\"name\":\"I. Gu\"},{\"authorId\":\"47440958\",\"name\":\"A. Jakola\"}],\"doi\":\"10.1007/978-3-030-29888-3_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"144c06f0b708e2bfd3e61b9150ccff24c57819ee\",\"title\":\"Multi-stream Convolutional Autoencoder and 2D Generative Adversarial Network for Glioma Classification\",\"url\":\"https://www.semanticscholar.org/paper/144c06f0b708e2bfd3e61b9150ccff24c57819ee\",\"venue\":\"CAIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a87ab836771164adb95d6744027e62e05f47fd96\",\"title\":\"Understanding human-human interactions: a survey\",\"url\":\"https://www.semanticscholar.org/paper/a87ab836771164adb95d6744027e62e05f47fd96\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Zheyuan Liu\"},{\"authorId\":\"9642011\",\"name\":\"Xiaoteng Zhang\"},{\"authorId\":\"33055674\",\"name\":\"L. Song\"},{\"authorId\":\"2261516\",\"name\":\"Zhengyan Ding\"},{\"authorId\":\"1730199\",\"name\":\"Huixian Duan\"}],\"doi\":\"10.1007/s10586-017-1309-2\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"title\":\"More efficient and effective tricks for deep action recognition\",\"url\":\"https://www.semanticscholar.org/paper/3a67e45b7bd7d5113e1f3fc4a02d8db9579e321a\",\"venue\":\"Cluster Computing\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"47748577\",\"name\":\"C. Ouyang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"title\":\"Nonlinear Channels Aggregation Networks for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b8e9c50f74ce6ca66a8ab61fb18ca31d26cf13f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"}],\"doi\":\"10.1109/TMM.2018.2887021\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"title\":\"Unsupervised Universal Attribute Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/46c7c0d5c54fbd3d26fd719ebc66e2188ea4fc07\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":\"1903.01000\",\"authors\":[{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"4241648\",\"name\":\"M. S. Sarfraz\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/FG.2019.8756609\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bae0a603d88f47b0ebdb1e325031c36f63dba738\",\"title\":\"Self-Supervised Learning of Face Representations for Video Face Clustering\",\"url\":\"https://www.semanticscholar.org/paper/bae0a603d88f47b0ebdb1e325031c36f63dba738\",\"venue\":\"2019 14th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2019)\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1904901470\",\"name\":\"Chengfeng Dou\"},{\"authorId\":\"151490870\",\"name\":\"Shikun Zhang\"},{\"authorId\":\"7643704\",\"name\":\"Hanping Wang\"},{\"authorId\":\"144622635\",\"name\":\"L. Sun\"},{\"authorId\":\"153268490\",\"name\":\"Yu-long Huang\"},{\"authorId\":\"35481850\",\"name\":\"W. Yue\"}],\"doi\":\"10.1016/j.sysarc.2020.101834\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59359e6f7d27b8b8afea1ba20d4762d677991558\",\"title\":\"ADHD fMRI short-time analysis method for edge computing based on multi-instance learning\",\"url\":\"https://www.semanticscholar.org/paper/59359e6f7d27b8b8afea1ba20d4762d677991558\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1803.08460\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"144537809\",\"name\":\"Yu Guan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1109/CVPR.2018.00983\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"30ca009c3988d96c4ef7671692f709e8100967f5\",\"title\":\"Towards Universal Representation for Unseen Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/30ca009c3988d96c4ef7671692f709e8100967f5\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2751577\",\"name\":\"Chenjie Ge\"},{\"authorId\":\"144515956\",\"name\":\"I. Gu\"},{\"authorId\":\"47440958\",\"name\":\"A. Jakola\"},{\"authorId\":\"144069365\",\"name\":\"J. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3526f4a0a516b1360a34722713c52b1fc2e6efba\",\"title\":\"USING SLICE-BASED DEEP LEARNING AND FUSION OF MULTI-MODAL MR IMAGES\",\"url\":\"https://www.semanticscholar.org/paper/3526f4a0a516b1360a34722713c52b1fc2e6efba\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.01549\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"31442858\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018401\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"title\":\"StNet: Local and Global Spatial-Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"88728572\",\"name\":\"Yalong Jia\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/ICME.2019.00103\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"title\":\"Channel-wise Temporal Attention Network for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe717940e455424c5fa25cc4343e7a42e0d005b6\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"title\":\"Multi-Modal Sensor Fusion: A Principled Approach to Optimality.\",\"url\":\"https://www.semanticscholar.org/paper/c22b67958821328c4dd831a7b61e64e534c2d9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1808.05085\",\"authors\":[{\"authorId\":\"40192003\",\"name\":\"Z. Zhang\"},{\"authorId\":\"1874900\",\"name\":\"Zhanghui Kuang\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":\"10.1145/3240508.3240534\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"title\":\"Temporal Sequence Distillation: Towards Few-Frame Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/9d4c467adc09fb50c5e799fc124f3e82da8c3c22\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"152245395\",\"name\":\"Zexin Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2933303\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"title\":\"Refined Spatial Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49419064\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"102868457\",\"name\":\"W. Li\"},{\"authorId\":\"46276098\",\"name\":\"Jianan Li\"},{\"authorId\":\"1735328\",\"name\":\"X. Xu\"},{\"authorId\":\"144410724\",\"name\":\"K. Jin\"}],\"doi\":\"10.1145/3234804.3234821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"title\":\"Local Feature Analysis for real-time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3dcdfdedc119bc3ae63dbe7f3ed6baa3218ed5f\",\"venue\":\"ICDLT '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"34358756\",\"name\":\"C. K. Mohan\"},{\"authorId\":\"144067348\",\"name\":\"K. R. Murty\"}],\"doi\":\"10.1109/ICIP.2018.8451226\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c6655ab00cf3fbcb412949e85204b608937c881\",\"title\":\"Action Recognition Based on Discriminative Embedding of Actions Using Siamese Networks\",\"url\":\"https://www.semanticscholar.org/paper/4c6655ab00cf3fbcb412949e85204b608937c881\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2283107\",\"name\":\"Debaditya Roy\"},{\"authorId\":\"70611576\",\"name\":\"C. Krishnamohan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"title\":\"REPRESENTATION LEARNING FOR ACTION RECOGNITION\",\"url\":\"https://www.semanticscholar.org/paper/62d8bbe48f623f130d243a38674cf77701fbbdb4\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1920920163\",\"name\":\"Haofei Wang\"},{\"authorId\":\"49298973\",\"name\":\"Junfeng Li\"}],\"doi\":\"10.1109/ACCESS.2020.3017076\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"title\":\"Human Action Recognition Algorithm Based on Multi-Feature Map Fusion\",\"url\":\"https://www.semanticscholar.org/paper/d2602fe505d3615889456eeb6fcdc71f8f855de7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66275285\",\"name\":\"Hemerson Tacon\"},{\"authorId\":\"145807601\",\"name\":\"A. Brito\"},{\"authorId\":\"67244903\",\"name\":\"H. Chaves\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":\"8125221\",\"name\":\"H. Maia\"},{\"authorId\":\"66088742\",\"name\":\"Darwin Ttito Concha\"},{\"authorId\":\"1398585275\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0008958003510358\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9213f65145533551043f36b542ee549b08089d3\",\"title\":\"Multi-stream Architecture with Symmetric Extended Visual Rhythms for Deep Learning Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e9213f65145533551043f36b542ee549b08089d3\",\"venue\":\"VISIGRAPP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4697712\",\"name\":\"Z. Zhu\"},{\"authorId\":\"1696842\",\"name\":\"Hongbing Ji\"},{\"authorId\":\"1786198\",\"name\":\"W. Zhang\"},{\"authorId\":\"1757932\",\"name\":\"Yiping Xu\"}],\"doi\":\"10.1016/j.neucom.2018.08.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"title\":\"Rank pooling dynamic network: Learning end-to-end dynamic characteristic for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/d92ff82c1b78cfbf2b9c8f65768ad9e4e3d1f47c\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"1801.03983\",\"authors\":[{\"authorId\":\"143847408\",\"name\":\"Mingze Xu\"},{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"46772058\",\"name\":\"X. Chen\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1109/WACV.2018.00178\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"title\":\"Fully-Coupled Two-Stream Spatiotemporal Networks for Extremely Low Resolution Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/58d496268f22d8cd35fbe7fa27919b80d84d9aa9\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1994889\",\"name\":\"A. S. Santos\"},{\"authorId\":\"1743455\",\"name\":\"H. Pedrini\"}],\"doi\":\"10.5220/0007409401140123\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"title\":\"Spatio-temporal Video Autoencoder for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2521944da3d8cba6b90ee0d069b2518efc8d2e40\",\"venue\":\"VISIGRAPP\",\"year\":2019},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20992076\",\"name\":\"Timothy Callemein\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"74922038\",\"name\":\"Floris De Feyter\"},{\"authorId\":\"73664580\",\"name\":\"Wim Boes\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2003472752\",\"name\":\"Tinne Tuytelaars\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1007/s11042-020-09616-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32921da55d7127169e901c4b3e5d6e2333185561\",\"title\":\"Show me where the action is!: Automatic capturing and timeline generation for reality TV.\",\"url\":\"https://www.semanticscholar.org/paper/32921da55d7127169e901c4b3e5d6e2333185561\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2011.03949\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"title\":\"Right on Time: Multi-Temporal Convolutions for Human Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7728ed8dd12e0ad64514ae9ec5d0bdf0576dadc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":\"1811.07059\",\"authors\":[{\"authorId\":\"3766266\",\"name\":\"Zexi Chen\"},{\"authorId\":\"145704184\",\"name\":\"B. Ramachandra\"},{\"authorId\":\"47353858\",\"name\":\"Tianfu Wu\"},{\"authorId\":\"3001600\",\"name\":\"Ranga Raju Vatsavai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7b0fe0bc433d894299e249d97ed894671c3748b1\",\"title\":\"Relational Long Short-Term Memory for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7b0fe0bc433d894299e249d97ed894671c3748b1\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"1604959773\",\"name\":\"Yichu Liu\"}],\"doi\":\"10.1007/s11063-019-10091-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"title\":\"Action Recognition with Multiple Relative Descriptors of Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/cace91ba53e05f6a5648f63b60bb657ec42764eb\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"1701.07368\",\"authors\":[{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145788702\",\"name\":\"Alexander G. Hauptmann\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1109/CVPRW.2017.161\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"title\":\"Deep Local Video Feature for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d20bb18da6b365ffcd7402d89172a3e934f89d38\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144960087\",\"name\":\"V. Sharma\"},{\"authorId\":\"4241648\",\"name\":\"M. S. Sarfraz\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9c513b0f304b1bb29de478a1227ddb201ed50217\",\"title\":\"A Simple and Effective Technique for Face Clustering in TV Series\",\"url\":\"https://www.semanticscholar.org/paper/9c513b0f304b1bb29de478a1227ddb201ed50217\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2007.12887\",\"authors\":[{\"authorId\":\"26415158\",\"name\":\"Xinqi Zhu\"},{\"authorId\":\"153250308\",\"name\":\"C. Xu\"},{\"authorId\":\"102853050\",\"name\":\"L. Hui\"},{\"authorId\":\"1830034\",\"name\":\"Cewu Lu\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/ICCV.2019.00359\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"title\":\"Approximated Bilinear Modules for Temporal Modeling\",\"url\":\"https://www.semanticscholar.org/paper/7303ce1fe8f54f45e4558eb81368bda9dfe2793f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yi Zhu\"},{\"authorId\":\"144325904\",\"name\":\"Yang Long\"},{\"authorId\":\"48953082\",\"name\":\"Y. Guan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"40799321\",\"name\":\"L. Shao\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b2cca16e8477f677b4a4c3f1ab572f7fc425ee99\",\"title\":\"ActivityNet Kernelised Representation Generalised Multiple Instance Learning Deep Features NMF with JSD Transfer Joint Matching Actions in Unknown Datasets Word 2 Vec New Concepts Deep Network Matching 1 2 3\",\"url\":\"https://www.semanticscholar.org/paper/b2cca16e8477f677b4a4c3f1ab572f7fc425ee99\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.027\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"439668462b3630ba6c43aec8a24a53ea8a316491\",\"title\":\"Domain learning joint with semantic adaptation for human action recognition\",\"url\":\"https://www.semanticscholar.org/paper/439668462b3630ba6c43aec8a24a53ea8a316491\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47482879\",\"name\":\"W. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"861ba11c0de8efc8bca4320f59364080886cfbdb\",\"title\":\"Deep learning for human fall classification with application to e-healthcare\",\"url\":\"https://www.semanticscholar.org/paper/861ba11c0de8efc8bca4320f59364080886cfbdb\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1812.01922\",\"authors\":[{\"authorId\":\"48379459\",\"name\":\"Y. Zhang\"},{\"authorId\":\"39578749\",\"name\":\"Siyu Tang\"},{\"authorId\":\"2276351\",\"name\":\"Krikamol Muandet\"},{\"authorId\":\"7595315\",\"name\":\"Christian Jarvers\"},{\"authorId\":\"144718494\",\"name\":\"H. Neumann\"}],\"doi\":\"10.1109/CVPR.2019.01228\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"428934f26e240aadeec86b40b23182455fb25c1a\",\"title\":\"Local Temporal Bilinear Pooling for Fine-Grained Action Parsing\",\"url\":\"https://www.semanticscholar.org/paper/428934f26e240aadeec86b40b23182455fb25c1a\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.09995\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2020.2985219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"title\":\"Temporal Reasoning Graph for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s00521-019-04578-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5295accd08f555354de16f2b860f2c09e6889b65\",\"title\":\"Hybrid and hierarchical fusion networks: a deep cross-modal learning architecture for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5295accd08f555354de16f2b860f2c09e6889b65\",\"venue\":\"Neural Computing and Applications\",\"year\":2019},{\"arxivId\":\"1802.08091\",\"authors\":[{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"35912331\",\"name\":\"G. Yang\"},{\"authorId\":\"40370556\",\"name\":\"Jin-Kun Lin\"},{\"authorId\":\"2947946\",\"name\":\"Ariel Shamir\"},{\"authorId\":\"7671691\",\"name\":\"Song-Hai Zhang\"},{\"authorId\":\"144918349\",\"name\":\"Shao-Ping Lu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa2d3996a0095eef90f8e0fcec7ab3b4ba63cd3f\",\"title\":\"Deep Online Video Stabilization\",\"url\":\"https://www.semanticscholar.org/paper/fa2d3996a0095eef90f8e0fcec7ab3b4ba63cd3f\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.12522\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"}],\"doi\":\"10.1007/978-3-030-20893-6_34\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"283181a2173b485726664edc6fe73f0465387629\",\"title\":\"Random Temporal Skipping for Multirate Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/283181a2173b485726664edc6fe73f0465387629\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48884977\",\"name\":\"K. Wang\"},{\"authorId\":\"143762036\",\"name\":\"B. Fang\"},{\"authorId\":\"2543829\",\"name\":\"Jiye Qian\"},{\"authorId\":\"4456978\",\"name\":\"S. Yang\"},{\"authorId\":\"47154938\",\"name\":\"X. Zhou\"},{\"authorId\":\"92104289\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/ACCESS.2019.2962572\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4f2058f1ccbe96efcac5fbb3db19f01bda76f50a\",\"title\":\"Perspective Transformation Data Augmentation for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/4f2058f1ccbe96efcac5fbb3db19f01bda76f50a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"1901.06792\",\"authors\":[{\"authorId\":\"10779576\",\"name\":\"Sunder Ali Khowaja\"},{\"authorId\":\"1685677\",\"name\":\"Seok-Lyong Lee\"}],\"doi\":\"10.1007/s11263-019-01248-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"title\":\"Semantic Image Networks for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b1f9a9bc031f47e972f2fb6cbd48a0474f7ca6c0\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1910.09616\",\"authors\":[{\"authorId\":\"51290120\",\"name\":\"Siddharth Roheda\"},{\"authorId\":\"145087510\",\"name\":\"H. Krim\"}],\"doi\":\"10.1609/aaai.v34i07.6870\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"title\":\"Conquering the CNN Over-Parameterization Dilemma: A Volterra Filtering Approach for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4b7273b117d61fe4330ed3c18e14b5ef40054d41\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9226060\",\"name\":\"Xu Gou\"},{\"authorId\":\"31332523\",\"name\":\"Linbo Qing\"},{\"authorId\":null,\"name\":\"Yi Wang\"},{\"authorId\":\"104499582\",\"name\":\"Mulin Xin\"},{\"authorId\":\"1524733684\",\"name\":\"Xianmin Wang\"}],\"doi\":\"10.1016/j.asoc.2020.106783\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f419321efb0b645601fe870d8b4dedf5ad5ecf41\",\"title\":\"Re-training and parameter sharing with the Hash trick for compressing convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/f419321efb0b645601fe870d8b4dedf5ad5ecf41\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48397283\",\"name\":\"Ruiqi Wang\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"}],\"doi\":\"10.1007/S11042-018-6509-0\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"title\":\"Combining multiple deep cues for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/c44ce50b8d369b6ee49c540ff1a74992b1358664\",\"venue\":\"Multim. Tools Appl.\",\"year\":2019},{\"arxivId\":\"2011.08652\",\"authors\":[{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"2025664854\",\"name\":\"Emad Bahrami Rad\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"2199924\",\"name\":\"M. Noroozi\"},{\"authorId\":\"46408185\",\"name\":\"E. Adeli\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"80ddd8e76480aa92aa071d33c624af7195b0b762\",\"title\":\"3D CNNs with Adaptive Temporal Feature Resolutions\",\"url\":\"https://www.semanticscholar.org/paper/80ddd8e76480aa92aa071d33c624af7195b0b762\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"16230100\",\"name\":\"Xuxu Wang\"},{\"authorId\":\"1560278711\",\"name\":\"Xiaotao Jiang\"},{\"authorId\":\"1563183976\",\"name\":\"Gloria Rumbidzai Regedzai\"},{\"authorId\":\"144728506\",\"name\":\"Haohao Meng\"},{\"authorId\":\"48243939\",\"name\":\"L. Sun\"}],\"doi\":\"10.1007/s11042-020-08792-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a0191cb91e21df8cd324e59861ec9ae91e3ae8\",\"title\":\"Gated neural network framework for interactive character control\",\"url\":\"https://www.semanticscholar.org/paper/66a0191cb91e21df8cd324e59861ec9ae91e3ae8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52022007\",\"name\":\"Vasileios Choutas\"},{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"3428663\",\"name\":\"J\\u00e9r\\u00f4me Revaud\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/CVPR.2018.00734\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6009bba115904bc3bf876224db90b232c4f0a48f\",\"title\":\"PoTion: Pose MoTion Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6009bba115904bc3bf876224db90b232c4f0a48f\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"31493847\",\"name\":\"A. H. Karami\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"92679c8cff92442f39de3405c21c8028162fe56a\",\"title\":\"Temporal 3D ConvNets Using Temporal Transition Layer\",\"url\":\"https://www.semanticscholar.org/paper/92679c8cff92442f39de3405c21c8028162fe56a\",\"venue\":\"CVPR Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2068393\",\"name\":\"Xiusheng Lu\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1761159\",\"name\":\"S. Zhang\"}],\"doi\":\"10.1007/s11042-017-5251-3\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"40d62396bb195d510bef5c0fd2bfa2bae6777754\",\"title\":\"Action recognition with multi-scale trajectory-pooled 3D convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/40d62396bb195d510bef5c0fd2bfa2bae6777754\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yingying Wang\"},{\"authorId\":\"50135244\",\"name\":\"Wenjia Li\"},{\"authorId\":\"143677598\",\"name\":\"R. Tao\"}],\"doi\":\"10.1109/LSP.2019.2940111\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9b40a95e4b2328cb681de4413ba918a978ecff\",\"title\":\"Multi-Branch Spatial-Temporal Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab9b40a95e4b2328cb681de4413ba918a978ecff\",\"venue\":\"IEEE Signal Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"DA COMPUTA\\u00c7\\u00c3O\"},{\"authorId\":\"3052490\",\"name\":\"M. Vieira\"},{\"authorId\":\"3387755\",\"name\":\"S. Villela\"},{\"authorId\":null,\"name\":\"Hemerson Aparecido da Costa\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"838871719b323c2b457c769cdf66d68f06df9523\",\"title\":\"Data Augmentation of Visual Rhythms using Symmetric Extension for Deep Learning Video Based Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/838871719b323c2b457c769cdf66d68f06df9523\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"4241648\",\"name\":\"M. S. Sarfraz\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/TBIOM.2019.2947264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"412f7b504244e0843226d0e626691d09f10b8ec6\",\"title\":\"Video Face Clustering With Self-Supervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/412f7b504244e0843226d0e626691d09f10b8ec6\",\"venue\":\"IEEE Transactions on Biometrics, Behavior, and Identity Science\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2944007\",\"name\":\"Guanghua Tan\"},{\"authorId\":\"1883252\",\"name\":\"Rui Miao\"},{\"authorId\":\"151471091\",\"name\":\"Y. Xiao\"}],\"doi\":\"10.1007/978-3-030-30508-6_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"title\":\"Action Recognition Based on Divide-and-Conquer\",\"url\":\"https://www.semanticscholar.org/paper/53c38e91f7315d0e79e61e644ef7dcbcd35678e0\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9742265\",\"name\":\"O. C. Kwon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/ICIP.2018.8451493\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"title\":\"Action Recognition: First-and Second-Order 3D Feature in Bi-Directional Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117185645\",\"name\":\"Sen-Zhe Xu\"},{\"authorId\":\"1745787\",\"name\":\"J. Hu\"},{\"authorId\":\"145631934\",\"name\":\"M. Wang\"},{\"authorId\":\"31471368\",\"name\":\"Tai-Jiang Mu\"},{\"authorId\":\"145140922\",\"name\":\"S. Hu\"}],\"doi\":\"10.1111/cgf.13566\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"title\":\"Deep Video Stabilization Using Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/d9de93805462d9a5b0676ce4049c7b56a55ed7c0\",\"venue\":\"Comput. Graph. Forum\",\"year\":2018}],\"corpusId\":6709077,\"doi\":\"10.1109/CVPR.2017.168\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":26,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"645de797f936cb19c1b8dba3b862543645510544\",\"references\":[{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1511.06062\",\"authors\":[{\"authorId\":\"145644823\",\"name\":\"Y. Gao\"},{\"authorId\":\"3258919\",\"name\":\"Oscar Beijbom\"},{\"authorId\":null,\"name\":\"Ning Zhang\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.41\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"title\":\"Compact Bilinear Pooling\",\"url\":\"https://www.semanticscholar.org/paper/327dc2fd203a7049f3409479ab68e5e2a83cd352\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"120896463\",\"name\":\"Chih-Wei Chen\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15552-9_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"994a7b903b937f8b177c035db86852091fd26aa7\",\"title\":\"Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/994a7b903b937f8b177c035db86852091fd26aa7\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144685146\",\"name\":\"Ninh Pham\"},{\"authorId\":\"1801719\",\"name\":\"R. Pagh\"}],\"doi\":\"10.1145/2487575.2487591\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ed4847b6ea369b7f4f1419d1a49504a534b2e3b4\",\"title\":\"Fast and scalable polynomial kernels via explicit feature maps\",\"url\":\"https://www.semanticscholar.org/paper/ed4847b6ea369b7f4f1419d1a49504a534b2e3b4\",\"venue\":\"KDD\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1713941\",\"name\":\"Christopher Zach\"},{\"authorId\":\"1730097\",\"name\":\"T. Pock\"},{\"authorId\":\"144746444\",\"name\":\"H. Bischof\"}],\"doi\":\"10.1007/978-3-540-74936-3_22\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"title\":\"A Duality Based Approach for Realtime TV-L1 Optical Flow\",\"url\":\"https://www.semanticscholar.org/paper/0f6bbe9afab5fd61f36de5461e9e6a30ca462c7c\",\"venue\":\"DAGM-Symposium\",\"year\":2007},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2013.65\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"title\":\"Temporal Localization of Actions with Actoms\",\"url\":\"https://www.semanticscholar.org/paper/404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":\"1610.02055\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"}],\"doi\":\"10.1167/17.10.296\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d8abf01fce0d44665949e7a73716fff7731fa6da\",\"title\":\"Places: An Image Database for Deep Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/d8abf01fce0d44665949e7a73716fff7731fa6da\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1608.00182\",\"authors\":[{\"authorId\":\"144963395\",\"name\":\"P. Tang\"},{\"authorId\":\"2443233\",\"name\":\"Xinggang Wang\"},{\"authorId\":\"2276155\",\"name\":\"Baoguang Shi\"},{\"authorId\":\"145905113\",\"name\":\"X. Bai\"},{\"authorId\":\"1743698\",\"name\":\"Wenyu Liu\"},{\"authorId\":\"144035504\",\"name\":\"Zhuowen Tu\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"659de7aa26bc129f4cea560076d5b593437f9229\",\"title\":\"Deep FisherNet for Object Classification\",\"url\":\"https://www.semanticscholar.org/paper/659de7aa26bc129f4cea560076d5b593437f9229\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1504.07889\",\"authors\":[{\"authorId\":\"2144284\",\"name\":\"Tsung-Yu Lin\"},{\"authorId\":\"2895705\",\"name\":\"Aruni RoyChowdhury\"},{\"authorId\":\"35208858\",\"name\":\"Subhransu Maji\"}],\"doi\":\"10.1109/ICCV.2015.170\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d3f789a56dca288b2c8e23ef047a2b342184950\",\"title\":\"Bilinear CNN Models for Fine-Grained Visual Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d3f789a56dca288b2c8e23ef047a2b342184950\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"3261451\",\"name\":\"Benjamin Rozenfeld\"}],\"doi\":\"10.1109/CVPR.2008.4587756\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f86767732f76f478d5845f2e59f99ba106e9265\",\"title\":\"Learning realistic human actions from movies\",\"url\":\"https://www.semanticscholar.org/paper/0f86767732f76f478d5845f2e59f99ba106e9265\",\"venue\":\"2008 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37335907\",\"name\":\"G. Willems\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-540-88688-4_48\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"title\":\"An Efficient Dense and Scale-Invariant Spatio-Temporal Interest Point Detector\",\"url\":\"https://www.semanticscholar.org/paper/117d576d72515e900e6fc5a4a0e7f1d0142a8924\",\"venue\":\"ECCV\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/ICCV.2003.1238663\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"642e328cae81c5adb30069b680cf60ba6b475153\",\"title\":\"Video Google: a text retrieval approach to object matching in videos\",\"url\":\"https://www.semanticscholar.org/paper/642e328cae81c5adb30069b680cf60ba6b475153\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1706007\",\"name\":\"Jianchao Yang\"},{\"authorId\":\"144782042\",\"name\":\"Kai Yu\"},{\"authorId\":\"144768792\",\"name\":\"Y. Gong\"},{\"authorId\":\"1739208\",\"name\":\"T. Huang\"}],\"doi\":\"10.1109/CVPRW.2009.5206757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c9633aedafe4ee8cf238fa06c40b84f47e17362\",\"title\":\"Linear spatial pyramid matching using sparse coding for image classification\",\"url\":\"https://www.semanticscholar.org/paper/0c9633aedafe4ee8cf238fa06c40b84f47e17362\",\"venue\":\"2009 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2009},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3048032\",\"name\":\"P. Scovanner\"},{\"authorId\":\"38245610\",\"name\":\"Saad Ali\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":\"10.1145/1291233.1291311\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"title\":\"A 3-dimensional sift descriptor and its application to action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe1b412ce7a4a36664734c4cad97b939b6ea6015\",\"venue\":\"ACM Multimedia\",\"year\":2007},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/978-3-319-10602-1_37\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"title\":\"Video Action Detection with Relational Dynamic-Poselets\",\"url\":\"https://www.semanticscholar.org/paper/d9c9b8194ac81f97bfedb7d15124e7b80c3c3d68\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1608.08851\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"3451338\",\"name\":\"A. Pazandeh\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"title\":\"Efficient Two-Stream Motion and Appearance 3D CNNs for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d309e414f0d6e56e7ba45736d28ee58ae2bad478\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1403.1840\",\"authors\":[{\"authorId\":\"5115386\",\"name\":\"Yunchao Gong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"37495246\",\"name\":\"R. Guo\"},{\"authorId\":\"1749609\",\"name\":\"S. Lazebnik\"}],\"doi\":\"10.1007/978-3-319-10584-0_26\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"a99add9d76d849a8d47b93532703e4ca0f683b92\",\"title\":\"Multi-scale Orderless Pooling of Deep Convolutional Activation Features\",\"url\":\"https://www.semanticscholar.org/paper/a99add9d76d849a8d47b93532703e4ca0f683b92\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2985266\",\"name\":\"Zhuowei Cai\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2014.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"title\":\"Multi-view Super Vector for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153302678\",\"name\":\"Jia Deng\"},{\"authorId\":\"47680287\",\"name\":\"W. Dong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"33642044\",\"name\":\"L. Li\"},{\"authorId\":\"94451829\",\"name\":\"K. Li\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2009.5206848\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b47265245e8db53a553049dcb27ed3e495fd625\",\"title\":\"ImageNet: A large-scale hierarchical image database\",\"url\":\"https://www.semanticscholar.org/paper/1b47265245e8db53a553049dcb27ed3e495fd625\",\"venue\":\"CVPR 2009\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"result\",\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"1768236\",\"name\":\"W. Freeman\"}],\"doi\":\"10.1162/089976600300015349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7e85f7d59e37972ec52cbabfef0512588d87f125\",\"title\":\"Separating Style and Content with Bilinear Models\",\"url\":\"https://www.semanticscholar.org/paper/7e85f7d59e37972ec52cbabfef0512588d87f125\",\"venue\":\"Neural Computation\",\"year\":2000},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"143995438\",\"name\":\"J. S\\u00e1nchez\"},{\"authorId\":\"1722052\",\"name\":\"Thomas Mensink\"}],\"doi\":\"10.1007/978-3-642-15561-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"title\":\"Improving the Fisher Kernel for Large-Scale Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/39f3b1804b8df5be645a1dcb4a876e128385d9be\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1408.5093\",\"authors\":[{\"authorId\":\"39978391\",\"name\":\"Y. Jia\"},{\"authorId\":\"1782282\",\"name\":\"Evan Shelhamer\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"3049736\",\"name\":\"S. Karayev\"},{\"authorId\":\"144361581\",\"name\":\"J. Long\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1145/2647868.2654889\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6bdb186ec4726e00a8051119636d4df3b94043b5\",\"title\":\"Caffe: Convolutional Architecture for Fast Feature Embedding\",\"url\":\"https://www.semanticscholar.org/paper/6bdb186ec4726e00a8051119636d4df3b94043b5\",\"venue\":\"ACM Multimedia\",\"year\":2014},{\"arxivId\":\"1502.04681\",\"authors\":[{\"authorId\":\"2897313\",\"name\":\"Nitish Srivastava\"},{\"authorId\":\"2711409\",\"name\":\"Elman Mansimov\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"title\":\"Unsupervised Learning of Video Representations using LSTMs\",\"url\":\"https://www.semanticscholar.org/paper/829510ad6f975c939d589eeb01a3cf6fc6c8ce4d\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"3502855\",\"name\":\"M. Marszalek\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.22.99\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"title\":\"A Spatio-Temporal Descriptor Based on 3D-Gradients\",\"url\":\"https://www.semanticscholar.org/paper/56e95f8efb7dbbc0b1820eaf365edc6f3b3f6719\",\"venue\":\"BMVC\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808423\",\"name\":\"G. Csurka\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b91180d8853d00e8f2df7ee3532e07d3d0cce2af\",\"title\":\"Visual categorization with bags of keypoints\",\"url\":\"https://www.semanticscholar.org/paper/b91180d8853d00e8f2df7ee3532e07d3d0cce2af\",\"venue\":\"eccv 2004\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"3413968\",\"name\":\"Petr Gron\\u00e1t\"},{\"authorId\":\"34395018\",\"name\":\"A. Torii\"},{\"authorId\":\"1758039\",\"name\":\"T. Pajdla\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2016.572\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bd53919b76f5eed0012429a8232eb1d5df300376\",\"title\":\"NetVLAD: CNN Architecture for Weakly Supervised Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bd53919b76f5eed0012429a8232eb1d5df300376\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018}],\"title\":\"Deep Temporal Linear Encoding Networks\",\"topics\":[{\"topic\":\"Convolutional neural network\",\"topicId\":\"29860\",\"url\":\"https://www.semanticscholar.org/topic/29860\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Embedded system\",\"topicId\":\"4423\",\"url\":\"https://www.semanticscholar.org/topic/4423\"},{\"topic\":\"Feature interaction problem\",\"topicId\":\"12720\",\"url\":\"https://www.semanticscholar.org/topic/12720\"},{\"topic\":\"Feature vector\",\"topicId\":\"4255\",\"url\":\"https://www.semanticscholar.org/topic/4255\"},{\"topic\":\"Algorithmic efficiency\",\"topicId\":\"19973\",\"url\":\"https://www.semanticscholar.org/topic/19973\"},{\"topic\":\"Interaction\",\"topicId\":\"72\",\"url\":\"https://www.semanticscholar.org/topic/72\"},{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"End-to-end encryption\",\"topicId\":\"854929\",\"url\":\"https://www.semanticscholar.org/topic/854929\"},{\"topic\":\"Aggregate data\",\"topicId\":\"54317\",\"url\":\"https://www.semanticscholar.org/topic/54317\"},{\"topic\":\"Emoticon\",\"topicId\":\"55238\",\"url\":\"https://www.semanticscholar.org/topic/55238\"},{\"topic\":\"ENCODE\",\"topicId\":\"365717\",\"url\":\"https://www.semanticscholar.org/topic/365717\"},{\"topic\":\"Graphics processing unit\",\"topicId\":\"8807\",\"url\":\"https://www.semanticscholar.org/topic/8807\"},{\"topic\":\"Machine learning\",\"topicId\":\"168\",\"url\":\"https://www.semanticscholar.org/topic/168\"}],\"url\":\"https://www.semanticscholar.org/paper/645de797f936cb19c1b8dba3b862543645510544\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"