"{\"abstract\":\"A Semantic Compositional Network (SCN) is developed for image captioning, in which semantic concepts (i.e., tags) are detected from the image, and the probability of each tag is used to compose the parameters in a long short-term memory (LSTM) network. The SCN extends each weight matrix of the LSTM to an ensemble of tag-dependent weight matrices. The degree to which each member of the ensemble is used to generate an image caption is tied to the image-dependent probability of the corresponding tag. In addition to captioning images, we also extend the SCN to generate captions for video clips. We qualitatively analyze semantic composition in SCNs, and quantitatively evaluate the algorithm on three benchmark datasets: COCO, Flickr30k, and Youtube2Text. Experimental results show that the proposed method significantly outperforms prior state-of-the-art approaches, across multiple evaluation metrics.\",\"arxivId\":\"1611.08002\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\",\"url\":\"https://www.semanticscholar.org/author/144702900\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\",\"url\":\"https://www.semanticscholar.org/author/144158271\"},{\"authorId\":\"144137069\",\"name\":\"X. He\",\"url\":\"https://www.semanticscholar.org/author/144137069\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\",\"url\":\"https://www.semanticscholar.org/author/2750075\"},{\"authorId\":\"143690259\",\"name\":\"K. Tran\",\"url\":\"https://www.semanticscholar.org/author/143690259\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\",\"url\":\"https://www.semanticscholar.org/author/1800422\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\",\"url\":\"https://www.semanticscholar.org/author/145006560\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\",\"url\":\"https://www.semanticscholar.org/author/144718788\"}],\"citationVelocity\":72,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1588044188\",\"name\":\"Trung-Hieu Tran\"},{\"authorId\":\"1588247218\",\"name\":\"Xuan-Hai Tran\"},{\"authorId\":\"34453615\",\"name\":\"V. Nguyen\"},{\"authorId\":\"1587990752\",\"name\":\"Khuong Nguyen-An\"}],\"doi\":\"10.1109/ACOMP.2019.00013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e621d4b962239ff10476000ee47343495b4a402\",\"title\":\"Building an Automatic Image Tagger with DenseNet and Transfer Learning\",\"url\":\"https://www.semanticscholar.org/paper/0e621d4b962239ff10476000ee47343495b4a402\",\"venue\":\"2019 International Conference on Advanced Computing and Applications (ACOMP)\",\"year\":2019},{\"arxivId\":\"1709.06548\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"39792258\",\"name\":\"Liqun Chen\"},{\"authorId\":\"7634810\",\"name\":\"Weiyao Wang\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"46935678\",\"name\":\"H. Liu\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6172eeb71a33d41dcbbe35cda56c0f041ee68bb8\",\"title\":\"Triangle Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/6172eeb71a33d41dcbbe35cda56c0f041ee68bb8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150213872\",\"name\":\"M. Hemalatha.\"},{\"authorId\":\"143783787\",\"name\":\"C. C. Sekhar\"}],\"doi\":\"10.1109/WACV45572.2020.9093344\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"509b25d45c6f5e3cafa48395c941611364e22efc\",\"title\":\"Domain-Specific Semantics Guided Approach to Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/509b25d45c6f5e3cafa48395c941611364e22efc\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":\"1912.10337\",\"authors\":[{\"authorId\":\"46296760\",\"name\":\"Dandan Guo\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"1450708782\",\"name\":\"Ruiying Lu\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e62219ff826633491b8ba8326dfb25f10a5ab75f\",\"title\":\"Recurrent Hierarchical Topic-Guided RNN for Language Generation\",\"url\":\"https://www.semanticscholar.org/paper/e62219ff826633491b8ba8326dfb25f10a5ab75f\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672151\",\"name\":\"Ning Xu\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"}],\"doi\":\"10.1007/s00530-018-0598-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f386d25bfbb0399fd6c8116add5faa66ffcfa467\",\"title\":\"Multi-guiding long short-term memory for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/f386d25bfbb0399fd6c8116add5faa66ffcfa467\",\"venue\":\"Multimedia Systems\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1430838755\",\"name\":\"Chien-Yao Wang\"},{\"authorId\":\"1490933657\",\"name\":\"Pei-Sin Liaw\"},{\"authorId\":\"2375118\",\"name\":\"Kai-Wen Liang\"},{\"authorId\":\"1519273435\",\"name\":\"Jai-Ching Wang\"},{\"authorId\":\"145456212\",\"name\":\"P. Chang\"}],\"doi\":\"10.1109/ICCE-Berlin47944.2019.8966173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a6578f9e1c222e2f7ff6ec0d50229f8e2391ec0c\",\"title\":\"Video Captioning Based on Joint Image\\u2013Audio Deep Learning Techniques\",\"url\":\"https://www.semanticscholar.org/paper/a6578f9e1c222e2f7ff6ec0d50229f8e2391ec0c\",\"venue\":\"2019 IEEE 9th International Conference on Consumer Electronics (ICCE-Berlin)\",\"year\":2019},{\"arxivId\":\"1811.00696\",\"authors\":[{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"2900282\",\"name\":\"W. Wang\"},{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"261783ef9c98986652ee11c4df20173edafae826\",\"title\":\"Sequence Generation with Guider Network\",\"url\":\"https://www.semanticscholar.org/paper/261783ef9c98986652ee11c4df20173edafae826\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"14618116\",\"name\":\"Chongyang Gao\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1016/J.PATREC.2018.07.024\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab27d39857f613af36eff3fa3796904f474f8cbd\",\"title\":\"Sequence in sequence for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/ab27d39857f613af36eff3fa3796904f474f8cbd\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"49723481\",\"name\":\"Huan Zhang\"},{\"authorId\":\"153191489\",\"name\":\"P. Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":\"10.18653/v1/P18-1241\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77685c77a1fa39890006fe13f43738aac49a2c51\",\"title\":\"Attacking Visual Language Grounding with Adversarial Examples: A Case Study on Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/77685c77a1fa39890006fe13f43738aac49a2c51\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":\"1906.12188\",\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"title\":\"A Deep Decoder Structure Based on WordEmbedding Regression for An Encoder-Decoder Based Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46702778\",\"name\":\"H. Zhang\"},{\"authorId\":\"2913523\",\"name\":\"Diedie Qiu\"},{\"authorId\":\"50477983\",\"name\":\"R. Wu\"},{\"authorId\":\"103624776\",\"name\":\"Dong-Hong Ji\"},{\"authorId\":\"49461429\",\"name\":\"Guangli Li\"},{\"authorId\":\"9201022\",\"name\":\"Zhenyu Niu\"},{\"authorId\":\"50289773\",\"name\":\"Tao Li\"}],\"doi\":\"10.1007/S00500-019-03973-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f7104056642c03263508957f20505a1dbba03ce\",\"title\":\"Novel model to integrate word embeddings and syntactic trees for automatic caption generation from images\",\"url\":\"https://www.semanticscholar.org/paper/7f7104056642c03263508957f20505a1dbba03ce\",\"venue\":\"Soft Comput.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1904.02628\",\"authors\":[{\"authorId\":\"65767906\",\"name\":\"Silvio Olivastri\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00185\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0c1ebaa635f68bb4a09fc59191642f30cfa894c9\",\"title\":\"End-to-End Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0c1ebaa635f68bb4a09fc59191642f30cfa894c9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1802.00176\",\"authors\":[{\"authorId\":\"2033687\",\"name\":\"Xuemei Xie\"},{\"authorId\":\"144310853\",\"name\":\"Jiang Du\"},{\"authorId\":\"35367337\",\"name\":\"Guangming Shi\"},{\"authorId\":\"145872985\",\"name\":\"Chenye Wang\"},{\"authorId\":\"153030385\",\"name\":\"X. Xu\"}],\"doi\":\"10.1007/978-3-030-03338-5_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a45885b29e4d2efaf75759131fb8bb524cffbd94\",\"title\":\"Perceptual Compressive Sensing\",\"url\":\"https://www.semanticscholar.org/paper/a45885b29e4d2efaf75759131fb8bb524cffbd94\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8275214\",\"name\":\"P. Tang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8194130\",\"name\":\"Qinyu Li\"}],\"doi\":\"10.1145/3303083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91aa0eb38446643cd622b060a76043b0ca2d7991\",\"title\":\"Rich Visual and Language Representation with Complementary Semantics for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/91aa0eb38446643cd622b060a76043b0ca2d7991\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"2006.14262\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"55c4cf3ed07f594a1826e604a875d7a2713a35e0\",\"title\":\"SACT: Self-Aware Multi-Space Feature Composition Transformer for Multinomial Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/55c4cf3ed07f594a1826e604a875d7a2713a35e0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.05316\",\"authors\":[{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"145215470\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"32556571\",\"name\":\"J. Liu\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"1700325\",\"name\":\"Graham Neubig\"}],\"doi\":\"10.1609/AAAI.V34I05.6305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"title\":\"What Makes A Good Story? Designing Composite Rewards for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/f416f27ba8ae0be32bb4c9a3a50995965a09c449\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1908.00120\",\"authors\":[{\"authorId\":\"2904100\",\"name\":\"Z. Han\"},{\"authorId\":\"102574232\",\"name\":\"C. Chen\"},{\"authorId\":\"46399275\",\"name\":\"Yu-Shen Liu\"},{\"authorId\":\"1796846\",\"name\":\"Matthias Zwicker\"}],\"doi\":\"10.1145/3394171.3413889\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66e87d0adf7df03fdd74e6dfea81f21aa03afab0\",\"title\":\"ShapeCaptioner: Generative Caption Network for 3D Shapes by Learning a Mapping from Parts Detected in Multiple Views to Sentences\",\"url\":\"https://www.semanticscholar.org/paper/66e87d0adf7df03fdd74e6dfea81f21aa03afab0\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1708.02478\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"8280077\",\"name\":\"Yuyu Guo\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1720243\",\"name\":\"X. Li\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TNNLS.2018.2851077\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d78c47093fbf3d85225fd502674aba4a29b3987\",\"title\":\"From Deterministic to Generative: Multimodal Stochastic RNNs for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d78c47093fbf3d85225fd502674aba4a29b3987\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37670557\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65885b53d54e52b8bbf31b1714be740eeb544c7f\",\"title\":\"Region Features ... ... Input Image Contextual Object Features ... ... ROI pooling C o n v Conv 5 _ 3 feature map Object Detection Region Proposal Network s Proposals Object Context Encoding\",\"url\":\"https://www.semanticscholar.org/paper/65885b53d54e52b8bbf31b1714be740eeb544c7f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1804.00100\",\"authors\":[{\"authorId\":null,\"name\":\"Jingwen Wang\"},{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"144391096\",\"name\":\"Yong Xu\"}],\"doi\":\"10.1109/CVPR.2018.00751\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"title\":\"Bidirectional Attentive Fusion with Context Gating for Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bb4e2d6a6e3e1067f21a4cad087fc91c671e495d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1007/978-981-10-5209-5_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"title\":\"Deep Learning in Natural Language Generation from Images\",\"url\":\"https://www.semanticscholar.org/paper/77991dca4fdc99b6622c55f86ca87429a5b8b308\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1709.09118\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d6a645ea49b0723c88286cbf416c7956b1e2ea7c\",\"title\":\"Tensor Product Generation Networks\",\"url\":\"https://www.semanticscholar.org/paper/d6a645ea49b0723c88286cbf416c7956b1e2ea7c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26554826\",\"name\":\"Yuzhao Mao\"},{\"authorId\":\"144161025\",\"name\":\"C. Zhou\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"},{\"authorId\":\"2462591\",\"name\":\"Ruifan Li\"}],\"doi\":\"10.24963/ijcai.2018/592\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"555e65623326de1b9c32bd22d482071920a6e4f1\",\"title\":\"Show and Tell More: Topic-Oriented Multi-Sentence Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/555e65623326de1b9c32bd22d482071920a6e4f1\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48116016\",\"name\":\"J. Ren\"},{\"authorId\":\"50550351\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1007/S11760-019-01449-W\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1581301ddb2b9b76c10b31eef101733ffebc46f8\",\"title\":\"CLOSE: Coupled content\\u2013semantic embedding\",\"url\":\"https://www.semanticscholar.org/paper/1581301ddb2b9b76c10b31eef101733ffebc46f8\",\"venue\":\"Signal Image Video Process.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"31399f850c03d7652869d2d57080c344acc41ecb\",\"title\":\"Attentive Tensor Product Learning for Language Generation and Grammar Parsing\",\"url\":\"https://www.semanticscholar.org/paper/31399f850c03d7652869d2d57080c344acc41ecb\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1911.03829\",\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"117849726\",\"name\":\"Yu Cheng\"},{\"authorId\":\"71776838\",\"name\":\"J. Liu\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60acc34101dc0395ae6d2ab6abf26cbedb00e961\",\"title\":\"Distilling the Knowledge of BERT for Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/60acc34101dc0395ae6d2ab6abf26cbedb00e961\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3169864\",\"name\":\"Phyu Phyu Khaing\"}],\"doi\":\"10.5815/IJIGSP.2019.06.01\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"10be5e50205809d7ad88d9687c9def7a94b90978\",\"title\":\"Attention-Based Deep Learning Model for Image Captioning: A Comparative Study\",\"url\":\"https://www.semanticscholar.org/paper/10be5e50205809d7ad88d9687c9def7a94b90978\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.03749\",\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1109/CVPR42600.2020.01090\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96485bda4f4118da249cc8a898230281ac8040a7\",\"title\":\"Better Captioning With Sequence-Level Exploration\",\"url\":\"https://www.semanticscholar.org/paper/96485bda4f4118da249cc8a898230281ac8040a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1807.09434\",\"authors\":[{\"authorId\":\"2183432\",\"name\":\"Boeun Kim\"},{\"authorId\":\"49380412\",\"name\":\"Y. Lee\"},{\"authorId\":\"3011724\",\"name\":\"Hyedong Jung\"},{\"authorId\":\"2529532\",\"name\":\"C. S. Cho\"}],\"doi\":\"10.1007/978-3-030-11018-5_12\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"239a38663967140e026385f6625a913a3e7b1cd7\",\"title\":\"Distinctive-attribute Extraction for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/239a38663967140e026385f6625a913a3e7b1cd7\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1938051940\",\"name\":\"Dylan Flaute\"},{\"authorId\":\"2405109\",\"name\":\"B. Narayanan\"}],\"doi\":\"10.1117/12.2568016\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"title\":\"Video captioning using weakly supervised convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/724776b0c788c6801e48b2ba6f0b8984d9ac7a67\",\"venue\":\"Optical Engineering + Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32324177\",\"name\":\"C. Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"144310030\",\"name\":\"F. Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.neucom.2018.07.029\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fc4a590d1859ba43c1303927c86c64b34e43287\",\"title\":\"Hierarchical attention-based multimodal fusion for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/4fc4a590d1859ba43c1303927c86c64b34e43287\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1908.10072\",\"authors\":[{\"authorId\":\"40892631\",\"name\":\"Bairui Wang\"},{\"authorId\":\"152309767\",\"name\":\"L. Ma\"},{\"authorId\":\"67074535\",\"name\":\"W. Zhang\"},{\"authorId\":\"119897463\",\"name\":\"Wenhao Jiang\"},{\"authorId\":\"46584062\",\"name\":\"Junling Wang\"},{\"authorId\":\"46641690\",\"name\":\"W. Liu\"}],\"doi\":\"10.1109/ICCV.2019.00273\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"title\":\"Controllable Video Captioning With POS Sequence Guidance Based on Gated Fusion Network\",\"url\":\"https://www.semanticscholar.org/paper/5e4742e510a26cd55b19d3ba191b688e7fb8f8cf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240677\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"title\":\"Spotting and Aggregating Salient Regions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"},{\"authorId\":\"143695423\",\"name\":\"Thang Nguyen\"},{\"authorId\":\"66622154\",\"name\":\"Ray Ptucha\"}],\"doi\":\"10.1007/s10044-018-00770-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"title\":\"Understanding temporal structure for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ddfe22a67bdd1cc2b8f1a2e6663044690226933\",\"venue\":\"Pattern Analysis and Applications\",\"year\":2019},{\"arxivId\":\"1911.00212\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.18653/v1/D19-1207\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55f546209c01530a7717d4170aa24947c6b92775\",\"title\":\"Low-Rank HOCA: Efficient High-Order Cross-Modal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/55f546209c01530a7717d4170aa24947c6b92775\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"46651452\",\"name\":\"Cong Li\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8803108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ff24050374748529fa2a1fee6941af08296449f8\",\"title\":\"Image Captioning with Attribute Refinement\",\"url\":\"https://www.semanticscholar.org/paper/ff24050374748529fa2a1fee6941af08296449f8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144669461\",\"name\":\"Kuncheng Fang\"},{\"authorId\":\"144913277\",\"name\":\"Lian Zhou\"},{\"authorId\":\"145020731\",\"name\":\"Cheng Jin\"},{\"authorId\":\"7550713\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"35632219\",\"name\":\"Kangnian Weng\"},{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1609/AAAI.V33I01.33018271\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"title\":\"Fully Convolutional Video Captioning with Coarse-to-Fine and Inherited Attention\",\"url\":\"https://www.semanticscholar.org/paper/506a3e330dbd2ecc17c6a6d4c239b1cce175b6b0\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1711.06354\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"28ee8af25582c9c3a04fa0f0809367d7ee936dca\",\"title\":\"Grounded Objects and Interactions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/28ee8af25582c9c3a04fa0f0809367d7ee936dca\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"46448210\",\"name\":\"Xiangnan Zhang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"}],\"doi\":\"10.1109/BigMM.2018.8499357\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"title\":\"Video Captioning with Semantic Guiding\",\"url\":\"https://www.semanticscholar.org/paper/ad8d0432bdc1fcefbd7ebc8badea8aceec16fbdf\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153804074\",\"name\":\"Heng Quan Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"}],\"doi\":\"10.1117/12.2524235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"title\":\"When visual object-context features meet generic and specific semantic priors in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"20332986\",\"name\":\"Q. Hu\"},{\"authorId\":\"144894837\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TCSVT.2019.2956593\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"230a8581672b3147238eaab2cf686c70fe4f672b\",\"title\":\"Convolutional Reconstruction-to-Sequence for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/230a8581672b3147238eaab2cf686c70fe4f672b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1909.02217\",\"authors\":[{\"authorId\":\"144889895\",\"name\":\"Ming Jiang\"},{\"authorId\":\"145919382\",\"name\":\"J. Hu\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"3207378\",\"name\":\"J. Diesner\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/D19-1156\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94c6e5ccd67be60a5ced11d0a5c59e0ab0f749d4\",\"title\":\"REO-Relevance, Extraness, Omission: A Fine-grained Evaluation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/94c6e5ccd67be60a5ced11d0a5c59e0ab0f749d4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"2001.06944\",\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"86724befacdd9fd8748607f5b025aa59fb7ef010\",\"title\":\"Nested-Wasserstein Self-Imitation Learning for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/86724befacdd9fd8748607f5b025aa59fb7ef010\",\"venue\":\"AISTATS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"9764377\",\"name\":\"Xuanhan Wang\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"}],\"doi\":\"10.1016/J.NEUCOM.2018.06.096\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"title\":\"Fused GRU with semantic-temporal attention for video captioning\",\"url\":\"https://www.semanticscholar.org/paper/31b28e96a337dfcf2dbfde104a1ec46f4e755844\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"143648909\",\"name\":\"C. Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/ICME.2019.00069\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"title\":\"Colloquial Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41030694\",\"name\":\"Huanyu Yu\"},{\"authorId\":\"3392007\",\"name\":\"Shuo Cheng\"},{\"authorId\":\"5796401\",\"name\":\"B. Ni\"},{\"authorId\":\"7272302\",\"name\":\"Minsi Wang\"},{\"authorId\":\"40430880\",\"name\":\"J. Zhang\"},{\"authorId\":\"50031361\",\"name\":\"X. Yang\"}],\"doi\":\"10.1109/CVPR.2018.00629\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f5876f67129a80a1ee753f715efcd2e2109bf432\",\"title\":\"Fine-Grained Video Captioning for Sports Narrative\",\"url\":\"https://www.semanticscholar.org/paper/f5876f67129a80a1ee753f715efcd2e2109bf432\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"1848462\",\"name\":\"Yarong Han\"},{\"authorId\":\"144530696\",\"name\":\"Li Wan\"},{\"authorId\":\"144025048\",\"name\":\"Xing Zhou\"},{\"authorId\":\"144975798\",\"name\":\"Min Deng\"}],\"doi\":\"10.1080/01431161.2019.1594439\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"title\":\"Geospatial relation captioning for high-spatial-resolution images by using an attention-based neural network\",\"url\":\"https://www.semanticscholar.org/paper/baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1813915\",\"name\":\"S. Liu\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1145/3240508.3240667\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"849642b4701ac11c035326069f707f23a51a6f1a\",\"title\":\"SibNet: Sibling Convolutional Encoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/849642b4701ac11c035326069f707f23a51a6f1a\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65767906\",\"name\":\"Silvio Olivastri\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"20f3d85b99b4b595b1c92f60a9b9a126f7384e15\",\"title\":\"An End-to-End Baseline for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/20f3d85b99b4b595b1c92f60a9b9a126f7384e15\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.03578\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3422575\",\"name\":\"\\u00d6zg\\u00fcn \\u00c7i\\u00e7ek\"},{\"authorId\":\"47495989\",\"name\":\"S. M. Ali\"},{\"authorId\":\"2454800\",\"name\":\"F. Mahdisoltani\"},{\"authorId\":\"48934984\",\"name\":\"C. Zhang\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0b26f0691b4fffa19c035e49ecc0eed97a826a26\",\"title\":\"Learning Representations for Predicting Future Activities\",\"url\":\"https://www.semanticscholar.org/paper/0b26f0691b4fffa19c035e49ecc0eed97a826a26\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1901.06283\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"Bai Li\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"717daba98eb57b898687fc013b705f763eb2916b\",\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/717daba98eb57b898687fc013b705f763eb2916b\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":\"1805.08191\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1709797\",\"name\":\"A. \\u00c7elikyilmaz\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"38504661\",\"name\":\"J. Wang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1609/aaai.v33i01.33018465\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c2b02822cfbc50d17ec5220a19556be9d601c132\",\"title\":\"Hierarchically Structured Reinforcement Learning for Topically Coherent Visual Story Generation\",\"url\":\"https://www.semanticscholar.org/paper/c2b02822cfbc50d17ec5220a19556be9d601c132\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"title\":\"Image Input OR Video Hierarchical LSTMs with Adaptive Attention ( hLSTMat ) Feature Extraction Generated Captions Losses\",\"url\":\"https://www.semanticscholar.org/paper/e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1909.07863\",\"authors\":[{\"authorId\":\"1387995349\",\"name\":\"Aditya Surikuchi\"},{\"authorId\":\"1708642\",\"name\":\"Jorma T. Laaksonen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b0a58dfb606811b69b7f6a1e6a5c8d3ec807ddb7\",\"title\":\"Character-Centric Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/b0a58dfb606811b69b7f6a1e6a5c8d3ec807ddb7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1912.13151\",\"authors\":[{\"authorId\":\"8010189\",\"name\":\"Xinjie Fan\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1471411319\",\"name\":\"Zhendong Wang\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"aa950171b25c05466d9d3cc58dff3b9ea9882e4a\",\"title\":\"Adaptive Correlated Monte Carlo for Contextual Categorical Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/aa950171b25c05466d9d3cc58dff3b9ea9882e4a\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"}],\"doi\":\"10.1109/CVPR.2018.00146\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2115fe369b3a6b859c6992ba023d5c11b1689801\",\"title\":\"GroupCap: Group-Based Image Captioning with Structured Relevance and Diversity Constraints\",\"url\":\"https://www.semanticscholar.org/paper/2115fe369b3a6b859c6992ba023d5c11b1689801\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1b47776ecc194616d5ae789357ac69b1298e47ae\",\"title\":\"Frames CNN Low-level Encoder ( Bi-LSTM ) High-level Encoder ( LSTM ) Worker Manager Internal Critic Environment segment signal goal state reward action HRL Agent context context\",\"url\":\"https://www.semanticscholar.org/paper/1b47776ecc194616d5ae789357ac69b1298e47ae\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2662002\",\"name\":\"Oliver Nina\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c43cd58f79a56538c8990693d900617b9bd940e5\",\"title\":\"A Multitask Learning Encoder-Decoders Framework for Generating Movie and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c43cd58f79a56538c8990693d900617b9bd940e5\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3424086\",\"name\":\"S. Sah\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"title\":\"Multi-Modal Deep Learning to Understand Vision and Language\",\"url\":\"https://www.semanticscholar.org/paper/950bb107027681a2a4b60b5c0439c3209c05a0ee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.11135\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"1706938\",\"name\":\"Y. Wang\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1109/CVPR.2018.00443\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74b284a66e75b65f5970d05bac000fe91243ee49\",\"title\":\"Video Captioning via Hierarchical Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/74b284a66e75b65f5970d05bac000fe91243ee49\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145471480\",\"name\":\"Yunmeng Feng\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46446912\",\"name\":\"X. Zhang\"},{\"authorId\":\"7521170\",\"name\":\"Chuanfu Xu\"},{\"authorId\":\"2243533\",\"name\":\"Zhenghua Wang\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1145/3302425.3302464\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"title\":\"AttResNet: Attention-based ResNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1806.00186\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1145/3355390\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"title\":\"Video Description\",\"url\":\"https://www.semanticscholar.org/paper/665a5673d33a90a1b71c0d5b1be127a76af43be7\",\"venue\":\"ACM Comput. Surv.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47767554\",\"name\":\"L. Wu\"},{\"authorId\":\"40444400\",\"name\":\"M. Xu\"},{\"authorId\":\"1783122\",\"name\":\"J. Wang\"},{\"authorId\":\"144242192\",\"name\":\"Stuart Perry\"}],\"doi\":\"10.1109/TMM.2019.2931815\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"title\":\"Recall What You See Continually Using GridLSTM in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5b8b83bbb8ea54873be904ff77b1764267b3bd33\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1906.01290\",\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"2125709\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"097981245eb3c66cc10a3164275d0bd52f5ae22a\",\"title\":\"Relational Reasoning using Prior Knowledge for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/097981245eb3c66cc10a3164275d0bd52f5ae22a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.10485\",\"authors\":[{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"48213346\",\"name\":\"Han Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1109/CVPR.2018.00143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"title\":\"AttnGAN: Fine-Grained Text to Image Generation with Attentional Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/8b35c00edfa4edfd7a99d816e671023d2c000d55\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"35528948\",\"name\":\"M. A. Khan\"}],\"doi\":\"10.1109/ACCESS.2019.2902507\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fe47bbcd536bb9ce80661b17dae92f41328e91f\",\"title\":\"ASoVS: Abstractive Summarization of Video Sequences\",\"url\":\"https://www.semanticscholar.org/paper/1fe47bbcd536bb9ce80661b17dae92f41328e91f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1801.04334\",\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1109/CVPR.2018.00943\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1b2402dcd85b81381fde40d0b971b510471ef23\",\"title\":\"TieNet: Text-Image Embedding Network for Common Thorax Disease Classification and Reporting in Chest X-Rays\",\"url\":\"https://www.semanticscholar.org/paper/b1b2402dcd85b81381fde40d0b971b510471ef23\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50997773\",\"name\":\"Xuguang Duan\"},{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1591133899\",\"name\":\"Yiwei Zhang\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"145583986\",\"name\":\"Wenwu Zhu\"}],\"doi\":\"10.1145/3343031.3351094\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0b12c784965baac88b6597890303fa834fa9eea\",\"title\":\"Watch, Reason and Code: Learning to Represent Videos Using Program\",\"url\":\"https://www.semanticscholar.org/paper/c0b12c784965baac88b6597890303fa834fa9eea\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12595577\",\"name\":\"S. Aravindkumar\"},{\"authorId\":\"48919600\",\"name\":\"P. Varalakshmi\"},{\"authorId\":\"145007956\",\"name\":\"M. Hemalatha\"}],\"doi\":\"10.1007/978-3-030-16657-1_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e23a5f3f6ccdd5b49ff2cc46ef2bdac8e1f08d4f\",\"title\":\"Generation of Image Caption Using CNN-LSTM Based Approach\",\"url\":\"https://www.semanticscholar.org/paper/e23a5f3f6ccdd5b49ff2cc46ef2bdac8e1f08d4f\",\"venue\":\"ISDA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3265845.3265851\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"title\":\"Sports Video Captioning by Attentive Motion Representation based Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"venue\":\"MMSports@MM\",\"year\":2018},{\"arxivId\":\"1910.01442\",\"authors\":[{\"authorId\":\"40879119\",\"name\":\"Kexin Yi\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"3422021\",\"name\":\"Yunzhu Li\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"143805212\",\"name\":\"A. Torralba\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f3ecbe546efed8ba42812f977354c16590bad77\",\"title\":\"CLEVRER: CoLlision Events for Video REpresentation and Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/7f3ecbe546efed8ba42812f977354c16590bad77\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1490776471\",\"name\":\"Anjie Tian\"},{\"authorId\":\"144798254\",\"name\":\"Lu Lu\"}],\"doi\":\"10.1109/ACCESS.2020.2964946\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"414773b7512a3c912e3ee2ba8897b3bbd1b72af3\",\"title\":\"Attentional Generative Adversarial Networks With Representativeness and Diversity for Generating Text to Realistic Image\",\"url\":\"https://www.semanticscholar.org/paper/414773b7512a3c912e3ee2ba8897b3bbd1b72af3\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1710.11475\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"96692a8fc740eee99e3ad5e48e73eae8de2578db\",\"title\":\"A Neural-Symbolic Approach to Design of CAPTCHA.\",\"url\":\"https://www.semanticscholar.org/paper/96692a8fc740eee99e3ad5e48e73eae8de2578db\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952857\",\"name\":\"K. Zheng\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"2478555\",\"name\":\"Shaopeng Lu\"},{\"authorId\":\"40457369\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-00776-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"title\":\"Multiple-Level Feature-Based Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1805970305\",\"name\":\"Georgios Barlas\"},{\"authorId\":\"1859319\",\"name\":\"Christos Veinidis\"},{\"authorId\":\"35575984\",\"name\":\"A. Arampatzis\"}],\"doi\":\"10.1007/s00371-020-01867-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a31c2b3a88719419cf679778846edbe3be9e81b3\",\"title\":\"What we see in a photograph: content selection for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a31c2b3a88719419cf679778846edbe3be9e81b3\",\"venue\":\"The Visual Computer\",\"year\":2020},{\"arxivId\":\"1901.06829\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"1749527\",\"name\":\"Xiang Zhao\"},{\"authorId\":\"2864855\",\"name\":\"Jizhou Huang\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018393\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"title\":\"Read, Watch, and Move: Reinforcement Learning for Temporally Grounding Natural Language Descriptions in Videos\",\"url\":\"https://www.semanticscholar.org/paper/6fd7e8aa1a031923e3580752e4ab9163e45fe41c\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144364295\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"title\":\"TVT: Two-View Transformer Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":null,\"name\":\"Rui Wang\"},{\"authorId\":\"144241178\",\"name\":\"B. Lyu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/BigMM.2018.8499066\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"title\":\"Image Captioning Based on Adaptive Balancing Loss\",\"url\":\"https://www.semanticscholar.org/paper/9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/TMM.2019.2896515\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5f79ee6c9b3e5951e4267d4624d2d7669a72cb3\",\"title\":\"Generating Video Descriptions With Latent Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/e5f79ee6c9b3e5951e4267d4624d2d7669a72cb3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"49469303\",\"name\":\"Xin-yuan Zhang\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a32535fb09e35a0f8e24e4d4e9bd33222a5258e1\",\"title\":\"Semantic Matching for Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/a32535fb09e35a0f8e24e4d4e9bd33222a5258e1\",\"venue\":\"EMNLP 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2388012\",\"name\":\"S. Dash\"},{\"authorId\":\"9528018\",\"name\":\"Shantanu Acharya\"},{\"authorId\":\"1882574\",\"name\":\"Partha Pakray\"},{\"authorId\":\"1455172724\",\"name\":\"Ranjita Das\"},{\"authorId\":\"1747784\",\"name\":\"Alexander Gelbukh\"}],\"doi\":\"10.1007/s13369-019-04262-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f8ee9c1907aeb58556b74471b876f9c19a76f86f\",\"title\":\"Topic-Based Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/f8ee9c1907aeb58556b74471b876f9c19a76f86f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"title\":\"Nested-Wasserstein Distance for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1809.07257\",\"authors\":[{\"authorId\":\"2662002\",\"name\":\"Oliver Nina\"},{\"authorId\":\"47238599\",\"name\":\"W. Garcia\"},{\"authorId\":\"47637016\",\"name\":\"Scott Clouse\"},{\"authorId\":\"1858702\",\"name\":\"A. Yilmaz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"81e31899aa9f0f54db069f0f4c2a29ed9587fe89\",\"title\":\"MTLE: A Multitask Learning Encoder of Visual Feature Representations for Video and Movie Description\",\"url\":\"https://www.semanticscholar.org/paper/81e31899aa9f0f54db069f0f4c2a29ed9587fe89\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66783923\",\"name\":\"Summra Saleem\"},{\"authorId\":\"40893753\",\"name\":\"A. Dilawari\"},{\"authorId\":\"2193802\",\"name\":\"M. U. Khan\"},{\"authorId\":\"1816309\",\"name\":\"Razi Iqbal\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"1858727\",\"name\":\"Tariq Umer\"}],\"doi\":\"10.1016/J.COMPELECENG.2019.07.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5a3cdb9ba6eb846fcb2b37df8557a8d10057d238\",\"title\":\"Stateful human-centered visual captioning system to aid video surveillance\",\"url\":\"https://www.semanticscholar.org/paper/5a3cdb9ba6eb846fcb2b37df8557a8d10057d238\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2019},{\"arxivId\":\"1903.09761\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"af4df89ad28580d98113fa6a816195137f7d1a1d\",\"title\":\"Scene Understanding for Autonomous Manipulation with Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/af4df89ad28580d98113fa6a816195137f7d1a1d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.00121\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"145468578\",\"name\":\"Ke Lin\"},{\"authorId\":\"1772128\",\"name\":\"A. Maye\"},{\"authorId\":\"47786863\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3389/frobt.2020.475767\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"304f94dbe2ed228309e86298766ad24d9b6c6747\",\"title\":\"A Semantics-Assisted Video Captioning Model Trained With Scheduled Sampling\",\"url\":\"https://www.semanticscholar.org/paper/304f94dbe2ed228309e86298766ad24d9b6c6747\",\"venue\":\"Frontiers in Robotics and AI\",\"year\":2020},{\"arxivId\":\"1708.09666\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"}],\"doi\":\"10.1145/3078971.3079000\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"title\":\"Generating Video Descriptions with Topic Guidance\",\"url\":\"https://www.semanticscholar.org/paper/d953d9767070bdb1f4f1af9e2a923dff047353cf\",\"venue\":\"ICMR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1904.01410\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"title\":\"Context and Attribute Grounded Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2008.10966\",\"authors\":[{\"authorId\":\"2548303\",\"name\":\"Lijie Fan\"},{\"authorId\":\"47268124\",\"name\":\"T. Li\"},{\"authorId\":\"46499812\",\"name\":\"Yuan Yuan\"},{\"authorId\":\"1785714\",\"name\":\"D. Katabi\"}],\"doi\":\"10.1007/978-3-030-58536-5_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"title\":\"In-Home Daily-Life Captioning Using Radio Signals\",\"url\":\"https://www.semanticscholar.org/paper/fadd6e5a8e877884dccb7ca5c8167f32f65ec5c4\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"145211780\",\"name\":\"Bin Fan\"},{\"authorId\":\"1380311632\",\"name\":\"Shinming Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.18653/v1/D19-1213\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"title\":\"Guiding the Flowing of Semantics: Interpretable Video Captioning via POS Tag\",\"url\":\"https://www.semanticscholar.org/paper/ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19268185\",\"name\":\"Niange Yu\"},{\"authorId\":\"145460915\",\"name\":\"Xiaolin Hu\"},{\"authorId\":\"38524079\",\"name\":\"Binheng Song\"},{\"authorId\":null,\"name\":\"Jian Yang\"},{\"authorId\":\"39665190\",\"name\":\"J. Zhang\"}],\"doi\":\"10.1109/TIP.2018.2889922\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"title\":\"Topic-Oriented Image Captioning Based on Order-Embedding\",\"url\":\"https://www.semanticscholar.org/paper/d4d77495c9d1e6ae4480f330c4fda80121452c63\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.06624\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"title\":\"Feature Fusion Effects of Tensor Product Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"1802.07089\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39772032\",\"name\":\"C. Liu\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"}],\"doi\":\"10.1609/AAAI.V33I01.33011344\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2105df749e0ece889bf98a671716dac923561062\",\"title\":\"Attentive Tensor Product Learning\",\"url\":\"https://www.semanticscholar.org/paper/2105df749e0ece889bf98a671716dac923561062\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ICIP.2019.8803785\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"title\":\"A Novel Attribute Selection Mechanism for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/da0cce8d791ca90b01696c6ef0de96c7904dd8cf\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"144478646\",\"name\":\"Z. Guo\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TMM.2017.2729019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"51b2c1e750b1d3b893072829d012f2352d6bd373\",\"title\":\"Video Captioning With Attention-Based LSTM and Semantic Consistency\",\"url\":\"https://www.semanticscholar.org/paper/51b2c1e750b1d3b893072829d012f2352d6bd373\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2019.2921655\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"title\":\"Sports Video Captioning via Attentive Motion Representation and Group Relationship Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122865911\",\"name\":\"Mie Mie Aung\"},{\"authorId\":\"145750914\",\"name\":\"Myint San\"},{\"authorId\":\"3169864\",\"name\":\"Phyu Phyu Khaing\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"45505889a0cf75a830545080d6b8b57cc2e2525f\",\"title\":\"Natural Language Description Generation for Image using Deep Learning Architecture\",\"url\":\"https://www.semanticscholar.org/paper/45505889a0cf75a830545080d6b8b57cc2e2525f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.10115\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"title\":\"TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.02765\",\"authors\":[{\"authorId\":\"48631993\",\"name\":\"Xin Eric Wang\"},{\"authorId\":\"46365930\",\"name\":\"Jiawei Wu\"},{\"authorId\":\"145979995\",\"name\":\"D. Zhang\"},{\"authorId\":\"1758652\",\"name\":\"Yu Su\"},{\"authorId\":\"1682479\",\"name\":\"William Yang Wang\"}],\"doi\":\"10.1609/aaai.v33i01.33018965\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"title\":\"Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aeb1fe15261f0ee10a27d1753fb301b7a044933a\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2741510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"title\":\"Deep Learning for Image-to-Text Generation: A Technical Overview\",\"url\":\"https://www.semanticscholar.org/paper/c5b803c2fee9bbf6d9132f633de70332b5e80a4d\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46296760\",\"name\":\"Dandan Guo\"},{\"authorId\":\"1409955695\",\"name\":\"B. Chen\"},{\"authorId\":\"1450708782\",\"name\":\"Ruiying Lu\"},{\"authorId\":\"38026572\",\"name\":\"M. Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bf5c373aa728f6708b365bc73be19b045ca8f604\",\"title\":\"Recurrent Hierarchical Topic-Guided Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/bf5c373aa728f6708b365bc73be19b045ca8f604\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49672730\",\"name\":\"Chunyuan Li\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e3c211c6e8dbea9849790a1c9491aed290a1e144\",\"title\":\"Towards Better Representations with Deep/Bayesian Learning\",\"url\":\"https://www.semanticscholar.org/paper/e3c211c6e8dbea9849790a1c9491aed290a1e144\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1905.02963\",\"authors\":[{\"authorId\":\"145114776\",\"name\":\"L. Sun\"},{\"authorId\":\"143721383\",\"name\":\"Bing Li\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":\"51260253\",\"name\":\"Z. Zha\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1109/ICME.2019.00226\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"title\":\"Multimodal Semantic Attention Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4ea5bcfce4ee889346c08efb2db3cb2e97250029\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"65827589\",\"name\":\"Nivetha Vijayaraju\"}],\"doi\":\"10.31979/etd.vm9n-39ed\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ede7e0721133697781fa3bb4b09e5a99373ab803\",\"title\":\"Image Retrieval Using Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ede7e0721133697781fa3bb4b09e5a99373ab803\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1708.04686\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"3131569\",\"name\":\"Haoxiang Li\"},{\"authorId\":\"144762505\",\"name\":\"C. Sun\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/ICCV.2017.201\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"title\":\"VQS: Linking Segmentations to Questions and Answers for Supervised Attention in VQA and Question-Focused Semantic Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/00f5bfc2fb760249ba4e9c72b72eea4574068339\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2007.11888\",\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"1796254\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.24963/ijcai.2020/88\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"884be34dd5d2ea78940da96d2813be7768933857\",\"title\":\"SBAT: Video Captioning with Sparse Boundary-Aware Transformer\",\"url\":\"https://www.semanticscholar.org/paper/884be34dd5d2ea78940da96d2813be7768933857\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":\"1712.02051\",\"authors\":[{\"authorId\":\"47666284\",\"name\":\"H. Chen\"},{\"authorId\":\"114464327\",\"name\":\"H. Zhang\"},{\"authorId\":\"49490596\",\"name\":\"Pin-Yu Chen\"},{\"authorId\":\"2882166\",\"name\":\"Jinfeng Yi\"},{\"authorId\":\"1793529\",\"name\":\"C. Hsieh\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58d190282ed59639b16e726a3237938b53976077\",\"title\":\"Show-and-Fool: Crafting Adversarial Examples for Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d190282ed59639b16e726a3237938b53976077\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2003.04865\",\"authors\":[{\"authorId\":\"3087214\",\"name\":\"Yutaro Shigeto\"},{\"authorId\":\"31678456\",\"name\":\"Y. Yoshikawa\"},{\"authorId\":\"2996464\",\"name\":\"Jiaqing Lin\"},{\"authorId\":\"39702069\",\"name\":\"A. Takeuchi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46cff2f107f0f9c84aa0d70c64a6d1acc5e766fe\",\"title\":\"Video Caption Dataset for Describing Human Actions in Japanese\",\"url\":\"https://www.semanticscholar.org/paper/46cff2f107f0f9c84aa0d70c64a6d1acc5e766fe\",\"venue\":\"LREC\",\"year\":2020},{\"arxivId\":\"1706.01231\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"153757316\",\"name\":\"Zhao Guo\"},{\"authorId\":\"144973314\",\"name\":\"Wu Liu\"},{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.24963/ijcai.2017/381\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"title\":\"Hierarchical LSTM with Adjusted Temporal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1803.07950\",\"authors\":[{\"authorId\":\"4322411\",\"name\":\"L. Li\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/WACV.2019.00042\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"title\":\"End-to-End Video Captioning With Multitask Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/abcf7dd1e35575eaac12332aa4bc7575ccdd6965\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51001584\",\"name\":\"Hyung-min Lee\"},{\"authorId\":\"153481384\",\"name\":\"Il-Koo Kim\"}],\"doi\":\"10.1109/IJCNN.2019.8851892\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"title\":\"Generating Natural Video Descriptions using Semantic Gate\",\"url\":\"https://www.semanticscholar.org/paper/b89d030332f7ff66ef270160dfc93e6b3122f34b\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40061480\",\"name\":\"Z. Dong\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"2000237078\",\"name\":\"Qi Cui\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/978-3-030-55187-2_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78a1094e0968cf4e2b61c83100d971031597ae4b\",\"title\":\"Adaptive Attention Mechanism Based Semantic Compositional Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/78a1094e0968cf4e2b61c83100d971031597ae4b\",\"venue\":\"IntelliSys\",\"year\":2020},{\"arxivId\":\"2001.05614\",\"authors\":[{\"authorId\":\"49178142\",\"name\":\"H. Chen\"},{\"authorId\":\"38376468\",\"name\":\"J. Li\"},{\"authorId\":\"145460910\",\"name\":\"Xiaolin Hu\"}],\"doi\":\"10.3233/FAIA200204\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f0c33980d7c011a8c657afb825220632e17b1568\",\"title\":\"Delving Deeper into the Decoder for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f0c33980d7c011a8c657afb825220632e17b1568\",\"venue\":\"ECAI\",\"year\":2020},{\"arxivId\":\"1904.03870\",\"authors\":[{\"authorId\":\"8511875\",\"name\":\"Jonghwan Mun\"},{\"authorId\":\"2889075\",\"name\":\"L. Yang\"},{\"authorId\":\"145888238\",\"name\":\"Zhou Ren\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2019.00675\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5a757427132fda0c66e18a0d059eca8e2472d13\",\"title\":\"Streamlined Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a757427132fda0c66e18a0d059eca8e2472d13\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"70435288\",\"name\":\"Xinxiao Wu\"},{\"authorId\":\"2674678\",\"name\":\"Xiaoxun Zhang\"},{\"authorId\":\"66547993\",\"name\":\"Yayun Qi\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6731\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4df184d6a74f1ffd84b644735c9afb5060552770\",\"title\":\"Joint Commonsense and Relation Reasoning for Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4df184d6a74f1ffd84b644735c9afb5060552770\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2006.03744\",\"authors\":[{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"},{\"authorId\":\"46429484\",\"name\":\"F. Wang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"461420c80d3bdc156e5db7af13264a955a6a2010\",\"title\":\"Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/461420c80d3bdc156e5db7af13264a955a6a2010\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49891089\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9610896\",\"name\":\"Y. Ding\"},{\"authorId\":\"144265847\",\"name\":\"Rui Wu\"},{\"authorId\":\"50822330\",\"name\":\"F. Xue\"}],\"doi\":\"10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00151\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a08403806ca61227b7a4780094fd8e652379362\",\"title\":\"A Denoising Framework for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/4a08403806ca61227b7a4780094fd8e652379362\",\"venue\":\"2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3123266.3127901\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3609c92bbcad4eaa6e239112fc2cadbf87bb3c33\",\"title\":\"Knowing Yourself: Improving Video Caption via In-depth Recap\",\"url\":\"https://www.semanticscholar.org/paper/3609c92bbcad4eaa6e239112fc2cadbf87bb3c33\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":\"1804.00819\",\"authors\":[{\"authorId\":\"2677364\",\"name\":\"Luowei Zhou\"},{\"authorId\":\"34872128\",\"name\":\"Yingbo Zhou\"},{\"authorId\":\"3587688\",\"name\":\"Jason J. Corso\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"}],\"doi\":\"10.1109/CVPR.2018.00911\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35ed258aede3df17ee20a6635364cb5fd2461049\",\"title\":\"End-to-End Dense Video Captioning with Masked Transformer\",\"url\":\"https://www.semanticscholar.org/paper/35ed258aede3df17ee20a6635364cb5fd2461049\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47824598\",\"name\":\"W. Wang\"},{\"authorId\":\"47814961\",\"name\":\"Y. Ding\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1109/ICASSP.2018.8461507\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"54969341ec539ddaaf7537b7353e3cea84790eac\",\"title\":\"A Novel Semantic Attribute-Based Feature for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/54969341ec539ddaaf7537b7353e3cea84790eac\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ba67de7e822a94091b9e57cc9be3069822a4f5c8\",\"title\":\"A Neural-Symbolic Approach to Natural Language Tasks\",\"url\":\"https://www.semanticscholar.org/paper/ba67de7e822a94091b9e57cc9be3069822a4f5c8\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2547721\",\"name\":\"M. Fourati\"},{\"authorId\":\"2245992\",\"name\":\"A. Jedidi\"},{\"authorId\":\"9395641\",\"name\":\"F. Gargouri\"}],\"doi\":\"10.1007/s11042-020-09589-9\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c1adfd46f461de181edc64bb783eedee45f55ed7\",\"title\":\"A survey on description and modeling of audiovisual documents\",\"url\":\"https://www.semanticscholar.org/paper/c1adfd46f461de181edc64bb783eedee45f55ed7\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1904.00766\",\"authors\":[{\"authorId\":\"90639891\",\"name\":\"Hassan Maleki Galandouz\"},{\"authorId\":\"2734293\",\"name\":\"Mohsen Ebrahimi Moghaddam\"},{\"authorId\":\"2567327\",\"name\":\"Mehrnoush Shamsfard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1717cd0899bda3166687281e6ed8b99ca285a311\",\"title\":\"A Weighted Multi-Criteria Decision Making Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1717cd0899bda3166687281e6ed8b99ca285a311\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3242155\",\"name\":\"Libin Jiao\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"4853966\",\"name\":\"H. Wang\"},{\"authorId\":\"145149132\",\"name\":\"R. Bie\"}],\"doi\":\"10.1109/ACCESS.2018.2882592\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f625ae421416c5c44df24ff89224562c0cdba3\",\"title\":\"Text Recovery via Deep CNN-BiLSTM Recognition and Bayesian Inference\",\"url\":\"https://www.semanticscholar.org/paper/e0f625ae421416c5c44df24ff89224562c0cdba3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1145/3239576.3239580\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"title\":\"Video Captioning using Hierarchical Multi-Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"venue\":\"ICAIP '18\",\"year\":2018},{\"arxivId\":\"1911.03829\",\"authors\":[{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1400216300\",\"name\":\"Yu Cheng\"},{\"authorId\":\"71776838\",\"name\":\"J. Liu\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.18653/v1/2020.acl-main.705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bc928c6c3effb7d585552ace624afd31b692149d\",\"title\":\"Distilling Knowledge Learned in BERT for Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/bc928c6c3effb7d585552ace624afd31b692149d\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"153173208\",\"name\":\"J. Xu\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1016/j.patrec.2019.11.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2eaffb8e5f6f8d11d0c5c012980b25829667f6d1\",\"title\":\"Exploring diverse and fine-grained caption for video by incorporating convolutional architecture into LSTM-based model\",\"url\":\"https://www.semanticscholar.org/paper/2eaffb8e5f6f8d11d0c5c012980b25829667f6d1\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2007.07614\",\"authors\":[{\"authorId\":\"50736086\",\"name\":\"Baoming Yan\"},{\"authorId\":\"50133570\",\"name\":\"Chen Zhou\"},{\"authorId\":\"144932914\",\"name\":\"B. Zhao\"},{\"authorId\":null,\"name\":\"Kan Guo\"},{\"authorId\":\"144825809\",\"name\":\"J. Yang\"},{\"authorId\":\"50080172\",\"name\":\"X. Li\"},{\"authorId\":\"144798383\",\"name\":\"Ming Zhang\"},{\"authorId\":null,\"name\":\"Yizhou Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"744df245f1387ac432d4a99dc6ec0067b4c01d61\",\"title\":\"Augmented Bi-path Network for Few-shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/744df245f1387ac432d4a99dc6ec0067b4c01d61\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50111883\",\"name\":\"S. Lee\"},{\"authorId\":\"1784897\",\"name\":\"Incheol Kim\"}],\"doi\":\"10.3745/JIPS.02.0098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fc1d373ca1b7abc470bf6a6a639436ea12461378\",\"title\":\"Video Captioning with Visual and Semantic Features\",\"url\":\"https://www.semanticscholar.org/paper/fc1d373ca1b7abc470bf6a6a639436ea12461378\",\"venue\":\"J. Inf. Process. Syst.\",\"year\":2018},{\"arxivId\":\"2005.01279\",\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"150116410\",\"name\":\"G. Wang\"},{\"authorId\":\"1500397567\",\"name\":\"Zheng Wen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.acl-main.227\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6675640a8ad5e180a3a68fb5e8b34386df28c68f\",\"title\":\"Improving Adversarial Text Generation by Modeling the Distant Future\",\"url\":\"https://www.semanticscholar.org/paper/6675640a8ad5e180a3a68fb5e8b34386df28c68f\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47286885\",\"name\":\"Jingyi Hou\"},{\"authorId\":\"47149737\",\"name\":\"X. Wu\"},{\"authorId\":\"29367810\",\"name\":\"Wentian Zhao\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"},{\"authorId\":\"7415267\",\"name\":\"Y. Jia\"}],\"doi\":\"10.1109/ICCV.2019.00901\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"title\":\"Joint Syntax Representation Learning and Visual Cue Translation for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ce40cd5214d556e9b8ca8ca401597321cb29b8d6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"119700639\",\"name\":\"Botian Shi\"},{\"authorId\":\"1791344388\",\"name\":\"Lei Ji\"},{\"authorId\":\"1783553\",\"name\":\"Zhen-dong Niu\"},{\"authorId\":\"46429989\",\"name\":\"N. Duan\"},{\"authorId\":\"143849609\",\"name\":\"M. Zhou\"},{\"authorId\":\"1710220\",\"name\":\"X. Chen\"}],\"doi\":\"10.1145/3394171.3413498\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"de4eabc5a672e5c3c1b3acbfa724cd8c85169c8c\",\"title\":\"Learning Semantic Concepts and Temporal Alignment for Narrated Video Procedural Captioning\",\"url\":\"https://www.semanticscholar.org/paper/de4eabc5a672e5c3c1b3acbfa724cd8c85169c8c\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1903.10869\",\"authors\":[{\"authorId\":\"145062693\",\"name\":\"Anh Nguyen\"},{\"authorId\":\"3354627\",\"name\":\"Thanh-Toan Do\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"1745158\",\"name\":\"D. Caldwell\"},{\"authorId\":\"145887349\",\"name\":\"N. Tsagarakis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"fda87f56010b1e8d05a52a166fdb2750b4dec39b\",\"title\":\"V2CNet: A Deep Learning Framework to Translate Videos to Commands for Robotic Manipulation\",\"url\":\"https://www.semanticscholar.org/paper/fda87f56010b1e8d05a52a166fdb2750b4dec39b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.00314\",\"authors\":[{\"authorId\":\"2635321\",\"name\":\"Josiah Wang\"},{\"authorId\":\"3238408\",\"name\":\"P. Madhyastha\"},{\"authorId\":\"1702974\",\"name\":\"Lucia Specia\"}],\"doi\":\"10.18653/v1/N18-1198\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"title\":\"Object Counts! Bringing Explicit Detections Back into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7d3dd33950f4a1be56eb88c0791263b3e3a6deee\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"1810.11536\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1007/978-3-030-20876-9_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"695420559bd694f0fe084b64556e8241c3d02868\",\"title\":\"Automatic Graphics Program Generation using Attention-Based Hierarchical Decoder\",\"url\":\"https://www.semanticscholar.org/paper/695420559bd694f0fe084b64556e8241c3d02868\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718794\",\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Yang Liu\"}],\"doi\":\"10.1007/978-981-10-5209-5_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"874cff125dc723eb86a9520247231d30f1432e17\",\"title\":\"A Joint Introduction to Natural Language Processing and to Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/874cff125dc723eb86a9520247231d30f1432e17\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"result\",\"background\"],\"isInfluential\":false,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/ISM.2018.00021\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"title\":\"Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2542427\",\"name\":\"H. Palangi\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0052b6a2c3533e30d5b521785345594c496f3683\",\"title\":\"Grammatically-Interpretable Learned Representations in Deep NLP Models\",\"url\":\"https://www.semanticscholar.org/paper/0052b6a2c3533e30d5b521785345594c496f3683\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"5477477\",\"name\":\"Martin Renqiang Min\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dd44ea9ef28bb2d08d273fa71cc9c27cda90a244\",\"title\":\"Recent work often develops a probabilistic model of the caption , conditioned on a video\",\"url\":\"https://www.semanticscholar.org/paper/dd44ea9ef28bb2d08d273fa71cc9c27cda90a244\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1611.08034\",\"authors\":[{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"2482836\",\"name\":\"Qinliang Su\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/P17-1030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f35f9a967fea696f2522d395ceae0988a53ddeae\",\"title\":\"Scalable Bayesian Learning of Recurrent Neural Networks for Language Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f35f9a967fea696f2522d395ceae0988a53ddeae\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Yunchen Pu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ce86da3e0a0ab5f6cf944cdfef7a607a61b16e2\",\"title\":\"Deep Generative Models for Image Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/9ce86da3e0a0ab5f6cf944cdfef7a607a61b16e2\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508437\",\"name\":\"J. Moon\"},{\"authorId\":\"1738142\",\"name\":\"D. Magazzeni\"},{\"authorId\":\"2804910\",\"name\":\"Michael Cashmore\"},{\"authorId\":\"65953844\",\"name\":\"Dorian Buksz\"},{\"authorId\":\"152840733\",\"name\":\"B. Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b946128d6b410514dafc734e21dc787fd903dec6\",\"title\":\"Towards Explanations of Plan Execution for Human-Robot Teaming\",\"url\":\"https://www.semanticscholar.org/paper/b946128d6b410514dafc734e21dc787fd903dec6\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144378325\",\"name\":\"R. Hern\\u00e1ndez\"},{\"authorId\":\"1491380573\",\"name\":\"Jes\\u00fas P\\u00e9rez-Mart\\u00edn\"},{\"authorId\":\"47315221\",\"name\":\"N. Bravo\"},{\"authorId\":\"1795669\",\"name\":\"J. M. Barrios\"},{\"authorId\":\"145899264\",\"name\":\"B. Bustos\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8e3288689b32e0f9af84b41574d0929ae1959b98\",\"title\":\"IMFD IMPRESEE at TRECVID 2019: Ad-Hoc Video Search and Video To Text\",\"url\":\"https://www.semanticscholar.org/paper/8e3288689b32e0f9af84b41574d0929ae1959b98\",\"venue\":\"TRECVID\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48028411\",\"name\":\"T. Jin\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"9338907\",\"name\":\"Z. Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.08.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"00b350e4211dd5ed4791744920e664880cd3fd3a\",\"title\":\"Recurrent convolutional video captioning with global and local attention\",\"url\":\"https://www.semanticscholar.org/paper/00b350e4211dd5ed4791744920e664880cd3fd3a\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1910.06954\",\"authors\":[{\"authorId\":\"35885339\",\"name\":\"M. C. Iordan\"},{\"authorId\":\"148197927\",\"name\":\"Tyler Giallanza\"},{\"authorId\":\"113057216\",\"name\":\"C. T. Ellis\"},{\"authorId\":\"20966285\",\"name\":\"Nicole M. Beckage\"},{\"authorId\":\"144872055\",\"name\":\"J. Cohen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e9111d689af577433af9f8078fb847c730ddd6d\",\"title\":\"Context Matters: Recovering Human Semantic Structure from Machine Learning Analysis of Large-Scale Text Corpora\",\"url\":\"https://www.semanticscholar.org/paper/7e9111d689af577433af9f8078fb847c730ddd6d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144654777\",\"name\":\"Ke Bai\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.1609/AAAI.V34I05.6249\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"826db2e5f340a90fc9672279f9e921b596aba4b7\",\"title\":\"Sequence Generation with Optimal-Transport-Enhanced Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/826db2e5f340a90fc9672279f9e921b596aba4b7\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2005.03804\",\"authors\":[{\"authorId\":\"3377097\",\"name\":\"A. Sharghi\"},{\"authorId\":\"1700665\",\"name\":\"N. Lobo\"},{\"authorId\":\"145103010\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d7cd871b42efb42f507444386e4317efd7dfc10c\",\"title\":\"Text Synopsis Generation for Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/d7cd871b42efb42f507444386e4317efd7dfc10c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"2699239\",\"name\":\"Yifan Peng\"},{\"authorId\":\"92790579\",\"name\":\"Le Lu\"},{\"authorId\":\"144202084\",\"name\":\"Zhiyong Lu\"},{\"authorId\":\"144838131\",\"name\":\"R. Summers\"}],\"doi\":\"10.1007/978-3-030-13969-8_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d50d8da795bd50ebd14c4635116c159354409c9c\",\"title\":\"Automatic Classification and Reporting of Multiple Common Thorax Diseases Using Chest Radiographs\",\"url\":\"https://www.semanticscholar.org/paper/d50d8da795bd50ebd14c4635116c159354409c9c\",\"venue\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"year\":2019},{\"arxivId\":\"1712.09783\",\"authors\":[{\"authorId\":\"2900282\",\"name\":\"Wenlin Wang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"47825534\",\"name\":\"W. Wang\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"34060310\",\"name\":\"Jiaji Huang\"},{\"authorId\":\"34337724\",\"name\":\"W. Ping\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"01eb299fec9b9f5f499d0ce9702d5aeb77848d88\",\"title\":\"Topic Compositional Neural Language Model\",\"url\":\"https://www.semanticscholar.org/paper/01eb299fec9b9f5f499d0ce9702d5aeb77848d88\",\"venue\":\"AISTATS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5c35e70954a05ec4b836f166882982f459eefa\",\"title\":\"Adaptive Feature Abstraction for Translating Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/4b5c35e70954a05ec4b836f166882982f459eefa\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"1708.09667\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"49252656\",\"name\":\"Jia Chen\"},{\"authorId\":\"1721329\",\"name\":\"Q. Jin\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1145/3123266.3123420\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6199348281e14a5a127b539f5cdb92fcddbac17\",\"title\":\"Video Captioning with Guidance of Multimodal Latent Topics\",\"url\":\"https://www.semanticscholar.org/paper/a6199348281e14a5a127b539f5cdb92fcddbac17\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"52196222\",\"name\":\"Y. Qiu\"},{\"authorId\":\"3026404\",\"name\":\"Yongkang Wong\"},{\"authorId\":\"153011269\",\"name\":\"Yuting Su\"},{\"authorId\":\"1744045\",\"name\":\"M. Kankanhalli\"}],\"doi\":\"10.1109/ACCESS.2018.2879642\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6b0247896a9d2eca0f4901032f5cfabd5b09dbe\",\"title\":\"A Fine-Grained Spatial-Temporal Attention Model for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e6b0247896a9d2eca0f4901032f5cfabd5b09dbe\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3255213\",\"name\":\"Z. Zhang\"},{\"authorId\":\"38188040\",\"name\":\"Dong Xu\"},{\"authorId\":\"47337540\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"2597292\",\"name\":\"Chuanqi Tan\"}],\"doi\":\"10.1109/TCSVT.2019.2936526\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"title\":\"Show, Tell and Summarize: Dense Video Captioning Using Visual Cue Aided Sentence Summarization\",\"url\":\"https://www.semanticscholar.org/paper/b1fed611b13bd5c463a340b375f382e48d45d1dc\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1909.02050\",\"authors\":[{\"authorId\":\"144889895\",\"name\":\"Ming Jiang\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"50141029\",\"name\":\"Xin Wang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"3207378\",\"name\":\"J. Diesner\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"}],\"doi\":\"10.18653/v1/D19-1220\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce01073130ff984eb43cbf43f6bdcbe4d5a09df9\",\"title\":\"TIGEr: Text-to-Image Grounding for Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/ce01073130ff984eb43cbf43f6bdcbe4d5a09df9\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s12559-019-09656-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"title\":\"Image Captioning with Memorized Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"venue\":\"Cognitive Computation\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1646765966\",\"name\":\"Daphne Demekas\"},{\"authorId\":\"47363526\",\"name\":\"T. Parr\"},{\"authorId\":\"144064129\",\"name\":\"K. Friston\"}],\"doi\":\"10.3389/fncom.2020.00030\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9b167315c4b539824dbfae03d62f7eb9e3fc66cb\",\"title\":\"An Investigation of the Free Energy Principle for Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9b167315c4b539824dbfae03d62f7eb9e3fc66cb\",\"venue\":\"Frontiers in Computational Neuroscience\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"39491387\",\"name\":\"J. Zhou\"},{\"authorId\":\"21576252\",\"name\":\"Jiangbo Ai\"},{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"1718099\",\"name\":\"A. Hanjalic\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"}],\"doi\":\"10.1109/TIP.2018.2855422\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd3d94fac6a282414406716040b10c1746634ecd\",\"title\":\"Video Captioning by Adversarial LSTM\",\"url\":\"https://www.semanticscholar.org/paper/fd3d94fac6a282414406716040b10c1746634ecd\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"2005.08271\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d87489d2facf197caafd24d0796523d55d47fb62\",\"title\":\"A Better Use of Audio-Visual Cues: Dense Video Captioning with Bi-modal Transformer\",\"url\":\"https://www.semanticscholar.org/paper/d87489d2facf197caafd24d0796523d55d47fb62\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2003.11618\",\"authors\":[{\"authorId\":\"48211835\",\"name\":\"J. Liu\"},{\"authorId\":\"2928777\",\"name\":\"Wenhu Chen\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"35729970\",\"name\":\"Yiming Yang\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":\"10.1109/cvpr42600.2020.01091\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"704ec27b8399df574a96da338c428a923509385e\",\"title\":\"Violin: A Large-Scale Dataset for Video-and-Language Inference\",\"url\":\"https://www.semanticscholar.org/paper/704ec27b8399df574a96da338c428a923509385e\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.07758\",\"authors\":[{\"authorId\":\"47698311\",\"name\":\"Vladimir Iashin\"},{\"authorId\":\"2827962\",\"name\":\"Esa Rahtu\"}],\"doi\":\"10.1109/CVPRW50498.2020.00487\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23e36087637e9d74815eba07990c38c02fecc966\",\"title\":\"Multi-modal Dense Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/23e36087637e9d74815eba07990c38c02fecc966\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2915033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"title\":\"Deep Hierarchical Encoder\\u2013Decoder Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1581863540\",\"name\":\"Aidean Sharghi Karganroodi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"550b08b659d3b8e7f45bdc09602af2184791d082\",\"title\":\"Visual-Textual Video Synopsis Generation\",\"url\":\"https://www.semanticscholar.org/paper/550b08b659d3b8e7f45bdc09602af2184791d082\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1804.00861\",\"authors\":[{\"authorId\":\"7379232\",\"name\":\"Dianqi Li\"},{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":\"144463557\",\"name\":\"M. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"title\":\"Generating Diverse and Accurate Visual Captions by Comparative Adversarial Learning\",\"url\":\"https://www.semanticscholar.org/paper/39144e468bde0424d38a3f20a6b62ddec4b459ae\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1007/978-3-030-14657-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a9bae357bc63540cfbd630f4aaab4088edf2e0\",\"title\":\"Video Captioning Using Hierarchical LSTM and Text-Based Sliding Window\",\"url\":\"https://www.semanticscholar.org/paper/08a9bae357bc63540cfbd630f4aaab4088edf2e0\",\"venue\":\"IoTaaS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"1809.06214\",\"authors\":[{\"authorId\":null,\"name\":\"Cheng Kuan Chen\"},{\"authorId\":\"1383271298\",\"name\":\"Zhufeng Pan\"},{\"authorId\":\"30885811\",\"name\":\"Min Sun\"},{\"authorId\":\"39793900\",\"name\":\"Ming-Yu Liu\"}],\"doi\":\"10.1609/AAAI.V33I01.33018151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e79138fd656ebea59eb008fcb97c97be7be8007\",\"title\":\"Unsupervised Stylish Image Description Generation via Domain Layer Norm\",\"url\":\"https://www.semanticscholar.org/paper/5e79138fd656ebea59eb008fcb97c97be7be8007\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":\"1911.09345\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"40366581\",\"name\":\"Wei Liu\"},{\"authorId\":\"1747500\",\"name\":\"A. Mian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"62fadf3cd3ba64cd148600f2582e2cfa6859fad7\",\"title\":\"Empirical Autopsy of Deep Video Captioning Frameworks\",\"url\":\"https://www.semanticscholar.org/paper/62fadf3cd3ba64cd148600f2582e2cfa6859fad7\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1807.03658\",\"authors\":[{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"}],\"doi\":\"10.1016/j.neucom.2020.08.035\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c5eda56ee3714e9cd0a8c0fb043341d1ddc1604d\",\"title\":\"Video Captioning with Boundary-aware Hierarchical Language Decoding and Joint Video Prediction\",\"url\":\"https://www.semanticscholar.org/paper/c5eda56ee3714e9cd0a8c0fb043341d1ddc1604d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1902.10322\",\"authors\":[{\"authorId\":\"50978260\",\"name\":\"Nayyer Aafaq\"},{\"authorId\":\"47398812\",\"name\":\"N. Akhtar\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"1746166\",\"name\":\"Syed Zulqarnain Gilani\"},{\"authorId\":\"46332747\",\"name\":\"A. Mian\"}],\"doi\":\"10.1109/CVPR.2019.01277\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"20888a7aebaf77a306c0886f165bd0d468db806d\",\"title\":\"Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/20888a7aebaf77a306c0886f165bd0d468db806d\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1709.05038\",\"authors\":[{\"authorId\":\"49693168\",\"name\":\"Yang Xian\"},{\"authorId\":\"35484757\",\"name\":\"Yingli Tian\"}],\"doi\":\"10.1109/TIP.2019.2917229\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"title\":\"Self-Guiding Multimodal LSTM\\u2014When We Do Not Have a Perfect Training Dataset for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/54f5c9df478dc510ea8f9c3b52917fb8356904e4\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2003.05162\",\"authors\":[{\"authorId\":\"1500408667\",\"name\":\"Zhiyuan Fang\"},{\"authorId\":\"120838645\",\"name\":\"Tejas Gokhale\"},{\"authorId\":\"120722271\",\"name\":\"Pratyay Banerjee\"},{\"authorId\":\"1760291\",\"name\":\"Chitta Baral\"},{\"authorId\":\"1784500\",\"name\":\"Yezhou Yang\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.61\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1794bc353c94e8d708476132eb326fe3af51c2e6\",\"title\":\"Video2Commonsense: Generating Commonsense Descriptions to Enrich Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1794bc353c94e8d708476132eb326fe3af51c2e6\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"1804.09066\",\"authors\":[{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"145264990\",\"name\":\"K. Singh\"},{\"authorId\":\"1710872\",\"name\":\"T. Brox\"}],\"doi\":\"10.1007/978-3-030-01216-8_43\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"aa63893b34f523973d0692dc74ff22512daac322\",\"title\":\"ECO: Efficient Convolutional Network for Online Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/aa63893b34f523973d0692dc74ff22512daac322\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"49865085\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-20876-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"title\":\"Multivariate Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50706692\",\"name\":\"Le Lu\"},{\"authorId\":\"2026596\",\"name\":\"Xiaosong Wang\"},{\"authorId\":\"50453737\",\"name\":\"Gustavo Carneiro\"},{\"authorId\":\"95057768\",\"name\":\"L. Yang\"}],\"doi\":\"10.1007/978-3-030-13969-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"title\":\"Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics\",\"url\":\"https://www.semanticscholar.org/paper/5c5f44c7c7ca139a5ff7a7c5f6456620834c29db\",\"venue\":\"Advances in Computer Vision and Pattern Recognition\",\"year\":2019},{\"arxivId\":\"1807.02257\",\"authors\":[{\"authorId\":\"1414497291\",\"name\":\"Edgar Margffoy-Tuay\"},{\"authorId\":\"152978592\",\"name\":\"Juan C. P\\u00e9rez\"},{\"authorId\":\"51049657\",\"name\":\"E. Botero\"},{\"authorId\":\"9739979\",\"name\":\"P. Arbel\\u00e1ez\"}],\"doi\":\"10.1007/978-3-030-01252-6_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"title\":\"Dynamic Multimodal Instance Segmentation guided by natural language queries\",\"url\":\"https://www.semanticscholar.org/paper/810eafc9e854ea9b1d7a9e9f755f8102310d5db6\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"},{\"authorId\":\"88265392\",\"name\":\"P. Liu\"},{\"authorId\":\"3343198\",\"name\":\"Yingjie Zhou\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"}],\"doi\":\"10.1109/BIGCOM.2019.00013\",\"intent\":[\"result\",\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a203fb561497774689ff4bb80cb18c9e00bf47b6\",\"title\":\"Semantic Tensor Product for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a203fb561497774689ff4bb80cb18c9e00bf47b6\",\"venue\":\"2019 5th International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92538707\",\"name\":\"Qi Zheng\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR42600.2020.01311\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"title\":\"Syntax-Aware Action Targeting for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":\"1811.10787\",\"authors\":[{\"authorId\":\"144599697\",\"name\":\"Y. Feng\"},{\"authorId\":\"145499468\",\"name\":\"L. Ma\"},{\"authorId\":\"40474876\",\"name\":\"Wei Liu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2019.00425\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"580fd9a601314ea32dc85ec98267b411dd3465cf\",\"title\":\"Unsupervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/580fd9a601314ea32dc85ec98267b411dd3465cf\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/MSP.2017.2762725\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b74d80faa4e4c95e44523d49f238dc40514d8b7c\",\"title\":\"Artificial Intelligence in the Rising Wave of Deep Learning: The Historical Path and Future Outlook [Perspectives]\",\"url\":\"https://www.semanticscholar.org/paper/b74d80faa4e4c95e44523d49f238dc40514d8b7c\",\"venue\":\"IEEE Signal Processing Magazine\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144718794\",\"name\":\"Li Deng\"},{\"authorId\":null,\"name\":\"Yang Liu\"}],\"doi\":\"10.1007/978-981-10-5209-5_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"59a3e156711d0d82799248e751c26396c7d24d8f\",\"title\":\"Epilogue: Frontiers of NLP in the Deep Learning Era\",\"url\":\"https://www.semanticscholar.org/paper/59a3e156711d0d82799248e751c26396c7d24d8f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2011.09928\",\"authors\":[{\"authorId\":\"79439415\",\"name\":\"Haoyu Dong\"},{\"authorId\":\"152764048\",\"name\":\"Zidong Wang\"},{\"authorId\":\"83277545\",\"name\":\"Qiang Qiu\"},{\"authorId\":\"1699339\",\"name\":\"G. Sapiro\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"88b5d42753d2f3a2194c886169038fd9ae7ade22\",\"title\":\"Using Text to Teach Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/88b5d42753d2f3a2194c886169038fd9ae7ade22\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2005.00200\",\"authors\":[{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"2378902\",\"name\":\"Yen-Chun Chen\"},{\"authorId\":\"1664725279\",\"name\":\"Yu Cheng\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"},{\"authorId\":\"1520007550\",\"name\":\"Jingjing Liu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.161\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"title\":\"HERO: Hierarchical Encoder for Video+Language Omni-representation Pre-training\",\"url\":\"https://www.semanticscholar.org/paper/6961065a16f6c3db4879cfad5875d11ce75e6b2f\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020}],\"corpusId\":11045175,\"doi\":\"10.1109/CVPR.2017.127\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":27,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"778ce81457383bd5e3fdb11b145ded202ebb4970\",\"references\":[{\"arxivId\":\"1510.07712\",\"authors\":[{\"authorId\":\"2910174\",\"name\":\"Haonan Yu\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"}],\"doi\":\"10.1109/CVPR.2016.496\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f678a0041f2c6f931168010e7418c500c3f14cdb\",\"title\":\"Video Paragraph Captioning Using Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/f678a0041f2c6f931168010e7418c500c3f14cdb\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1506.06272\",\"authors\":[{\"authorId\":\"2512850\",\"name\":\"Junqi Jin\"},{\"authorId\":\"2266415\",\"name\":\"K. Fu\"},{\"authorId\":\"2153397\",\"name\":\"Runpeng Cui\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"1700883\",\"name\":\"C. Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"56ffece2817a0363f551210733a611830ba1155d\",\"title\":\"Aligning where to see and what to tell: image caption with region-based attention and scene factorization\",\"url\":\"https://www.semanticscholar.org/paper/56ffece2817a0363f551210733a611830ba1155d\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1605.06715\",\"authors\":[{\"authorId\":\"51453887\",\"name\":\"Jiaming Song\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"03df3c827e6597f41bd31d64883686b33d792e9d\",\"title\":\"Factored Temporal Sigmoid Belief Networks for Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/03df3c827e6597f41bd31d64883686b33d792e9d\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1609.08976\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145153424\",\"name\":\"Ricardo Henao\"},{\"authorId\":\"50242822\",\"name\":\"X. Yuan\"},{\"authorId\":\"1978606\",\"name\":\"C. Li\"},{\"authorId\":\"9074631\",\"name\":\"A. Stevens\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"title\":\"Variational Autoencoder for Deep Learning of Images, Labels and Captions\",\"url\":\"https://www.semanticscholar.org/paper/f4c5d13a8e9e80edcd4f69f0eab0b4434364c6dd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1109/CVPR.2007.383036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2ac91e028cdc602695b46bd1f372c03b4d2776cf\",\"title\":\"Unsupervised Learning of Image Transformations\",\"url\":\"https://www.semanticscholar.org/paper/2ac91e028cdc602695b46bd1f372c03b4d2776cf\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":\"1412.4729\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"46485395\",\"name\":\"Huijuan Xu\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.3115/v1/N15-1173\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8cef41606f1e1324b683441e694f0e1c96387abf\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8cef41606f1e1324b683441e694f0e1c96387abf\",\"venue\":\"HLT-NAACL\",\"year\":2015},{\"arxivId\":\"1505.00487\",\"authors\":[{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"}],\"doi\":\"10.1109/ICCV.2015.515\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"title\":\"Sequence to Sequence -- Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/e58a110fa1e4ddf247d5c614d117d64bfbe135c4\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1505.01861\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"7179232\",\"name\":\"H. Li\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.497\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"title\":\"Jointly Modeling Embedding and Translation to Bridge Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/68478207cf3e4fc44bf1602abe82c7ac7f288872\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52014393\",\"name\":\"Ut Austin\"},{\"authorId\":\"123312980\",\"name\":\"Austin\"},{\"authorId\":\"102704114\",\"name\":\"UMass Lowell\"},{\"authorId\":\"102898595\",\"name\":\"Lowell\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"43795b7bac3d921c4e579964b54187bdbf6c6330\",\"title\":\"Translating Videos to Natural Language Using Deep Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/43795b7bac3d921c4e579964b54187bdbf6c6330\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1310.4546\",\"authors\":[{\"authorId\":null,\"name\":\"Tomas Mikolov\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"38644044\",\"name\":\"Kai Chen\"},{\"authorId\":\"32131713\",\"name\":\"G. S. Corrado\"},{\"authorId\":\"49959210\",\"name\":\"J. Dean\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"title\":\"Distributed Representations of Words and Phrases and their Compositionality\",\"url\":\"https://www.semanticscholar.org/paper/87f40e6f3022adbc1f1905e3e506abad05a9964f\",\"venue\":\"NIPS\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"D. Kingma\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"A method for stochastic optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1605.02688\",\"authors\":[{\"authorId\":\"1388360943\",\"name\":\"Rami Al-Rfou\"},{\"authorId\":\"1815021\",\"name\":\"G. Alain\"},{\"authorId\":\"2634674\",\"name\":\"Amjad Almahairi\"},{\"authorId\":\"48765757\",\"name\":\"Christof Angerm\\u00fcller\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"3227028\",\"name\":\"Fr\\u00e9d\\u00e9ric Bastien\"},{\"authorId\":\"145040409\",\"name\":\"J. Bayer\"},{\"authorId\":\"144336979\",\"name\":\"A. Belikov\"},{\"authorId\":\"7330729\",\"name\":\"A. Belopolsky\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"47944877\",\"name\":\"Arnaud Bergeron\"},{\"authorId\":\"32837403\",\"name\":\"J. Bergstra\"},{\"authorId\":\"115295647\",\"name\":\"Valentin Bisson\"},{\"authorId\":\"32308836\",\"name\":\"Josh Bleecher Snyder\"},{\"authorId\":\"14362225\",\"name\":\"Nicolas Bouchard\"},{\"authorId\":\"1395619597\",\"name\":\"Nicolas Boulanger-Lewandowski\"},{\"authorId\":\"2900675\",\"name\":\"Xavier Bouthillier\"},{\"authorId\":\"2346028\",\"name\":\"A. D. Br\\u00e9bisson\"},{\"authorId\":\"1967465\",\"name\":\"Olivier Breuleux\"},{\"authorId\":\"153921980\",\"name\":\"Pierre Luc Carrier\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"2292403\",\"name\":\"J. Chorowski\"},{\"authorId\":\"29848635\",\"name\":\"Paul F. Christiano\"},{\"authorId\":\"2348758\",\"name\":\"Tim Cooijmans\"},{\"authorId\":\"40638665\",\"name\":\"Marc-Alexandre C\\u00f4t\\u00e9\"},{\"authorId\":\"39977229\",\"name\":\"Myriam C\\u00f4t\\u00e9\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"2921469\",\"name\":\"Yann Dauphin\"},{\"authorId\":\"2460212\",\"name\":\"Olivier Delalleau\"},{\"authorId\":\"32604218\",\"name\":\"Julien Demouth\"},{\"authorId\":\"2755582\",\"name\":\"G. Desjardins\"},{\"authorId\":\"48373216\",\"name\":\"S. Dieleman\"},{\"authorId\":\"46573521\",\"name\":\"Laurent Dinh\"},{\"authorId\":\"2812151\",\"name\":\"Melanie Ducoffe\"},{\"authorId\":\"3074927\",\"name\":\"Vincent Dumoulin\"},{\"authorId\":\"3127597\",\"name\":\"S. Kahou\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"},{\"authorId\":\"40557013\",\"name\":\"Ziye Fan\"},{\"authorId\":\"2345617\",\"name\":\"Orhan Firat\"},{\"authorId\":\"39844381\",\"name\":\"M. Germain\"},{\"authorId\":\"3119801\",\"name\":\"Xavier Glorot\"},{\"authorId\":\"153440022\",\"name\":\"Ian J. Goodfellow\"},{\"authorId\":\"48196087\",\"name\":\"M. Graham\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"48080691\",\"name\":\"P. Hamel\"},{\"authorId\":\"1405640115\",\"name\":\"Iban Harlouchet\"},{\"authorId\":\"114956664\",\"name\":\"J. Heng\"},{\"authorId\":\"2507883\",\"name\":\"Bal\\u00e1zs Hidasi\"},{\"authorId\":\"25056820\",\"name\":\"S. Honari\"},{\"authorId\":\"36399635\",\"name\":\"Arjun Jain\"},{\"authorId\":\"152857609\",\"name\":\"S\\u00e9bastien Jean\"},{\"authorId\":\"49104216\",\"name\":\"Kai Jia\"},{\"authorId\":\"3025583\",\"name\":\"M. Korobov\"},{\"authorId\":\"144592382\",\"name\":\"Vivek Kulkarni\"},{\"authorId\":\"49071560\",\"name\":\"Alex Lamb\"},{\"authorId\":\"3087941\",\"name\":\"Pascal Lamblin\"},{\"authorId\":\"153109766\",\"name\":\"E. Larsen\"},{\"authorId\":\"40201308\",\"name\":\"C\\u00e9sar Laurent\"},{\"authorId\":\"72490641\",\"name\":\"Sueryun Lee\"},{\"authorId\":\"47682610\",\"name\":\"S. Lefran\\u00e7ois\"},{\"authorId\":\"2387233\",\"name\":\"S. Lemieux\"},{\"authorId\":\"144828689\",\"name\":\"N. L\\u00e9onard\"},{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"3245814\",\"name\":\"J. A. Livezey\"},{\"authorId\":\"40532172\",\"name\":\"C. Lorenz\"},{\"authorId\":\"102472217\",\"name\":\"J. Lowin\"},{\"authorId\":null,\"name\":\"Qianli Ma\"},{\"authorId\":\"1798462\",\"name\":\"Pierre-Antoine Manzagol\"},{\"authorId\":\"3422889\",\"name\":\"Olivier Mastropietro\"},{\"authorId\":\"1914552\",\"name\":\"Robert McGibbon\"},{\"authorId\":\"1710604\",\"name\":\"R. Memisevic\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1748421\",\"name\":\"Vincent Michalski\"},{\"authorId\":\"145687827\",\"name\":\"M. Mirza\"},{\"authorId\":\"40479190\",\"name\":\"Alberto Orlandi\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1996134\",\"name\":\"Razvan Pascanu\"},{\"authorId\":\"121252563\",\"name\":\"M. Pezeshki\"},{\"authorId\":\"2402716\",\"name\":\"Colin Raffel\"},{\"authorId\":\"49577546\",\"name\":\"Daniel Renshaw\"},{\"authorId\":\"3146111\",\"name\":\"M. Rocklin\"},{\"authorId\":\"114117487\",\"name\":\"Adriana Romero\"},{\"authorId\":\"48127262\",\"name\":\"M. Roth\"},{\"authorId\":\"47696458\",\"name\":\"Peter Sadowski\"},{\"authorId\":\"3373139\",\"name\":\"J. Salvatier\"},{\"authorId\":\"47918629\",\"name\":\"F. Savard\"},{\"authorId\":\"1382154289\",\"name\":\"Jan Schl\\u00fcter\"},{\"authorId\":\"47971768\",\"name\":\"John Schulman\"},{\"authorId\":\"40116153\",\"name\":\"Gabriel Schwartz\"},{\"authorId\":\"48190457\",\"name\":\"I. Serban\"},{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"3197429\",\"name\":\"Samira Shabanian\"},{\"authorId\":\"39442397\",\"name\":\"\\u00c9tienne Simon\"},{\"authorId\":\"11115628\",\"name\":\"Sigurd Spieckermann\"},{\"authorId\":\"120638144\",\"name\":\"S. Subramanyam\"},{\"authorId\":\"3407592\",\"name\":\"Jakub Sygnowski\"},{\"authorId\":\"66454233\",\"name\":\"J\\u00e9r\\u00e9mie Tanguay\"},{\"authorId\":\"3220768\",\"name\":\"G. V. Tulder\"},{\"authorId\":\"153160559\",\"name\":\"Joseph P. Turian\"},{\"authorId\":\"19555508\",\"name\":\"S. Urban\"},{\"authorId\":\"120247189\",\"name\":\"Pascal Vincent\"},{\"authorId\":\"2077146\",\"name\":\"Francesco Visin\"},{\"authorId\":\"153559313\",\"name\":\"H. D. Vries\"},{\"authorId\":\"1393680089\",\"name\":\"David Warde-Farley\"},{\"authorId\":\"27358391\",\"name\":\"D. J. Webb\"},{\"authorId\":\"39561601\",\"name\":\"M. Willson\"},{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"47936713\",\"name\":\"Lijun Xue\"},{\"authorId\":\"97709924\",\"name\":\"L. Yao\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"1774002\",\"name\":\"Y. Zhang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b570069f14c7588e066f7138e1f21af59d62e61\",\"title\":\"Theano: A Python framework for fast computation of mathematical expressions\",\"url\":\"https://www.semanticscholar.org/paper/6b570069f14c7588e066f7138e1f21af59d62e61\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":\"1605.00743\",\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"40381920\",\"name\":\"Tianbao Yang\"},{\"authorId\":\"40206014\",\"name\":\"Boqing Gong\"}],\"doi\":\"10.1109/CVPR.2016.17\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1e4f2c791f81a5fe95e693644e002fb652adb39\",\"title\":\"Learning Attributes Equals Multi-Source Domain Generalization\",\"url\":\"https://www.semanticscholar.org/paper/e1e4f2c791f81a5fe95e693644e002fb652adb39\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Z. Gan\"},{\"authorId\":null,\"name\":\"X. He\"},{\"authorId\":null,\"name\":\"J. Gao\"},{\"authorId\":null,\"name\":\"L. Deng\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Gener - ating attractive visual captions with styles\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1411.2539\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"title\":\"Unifying Visual-Semantic Embeddings with Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/2e36ea91a3c8fbff92be2989325531b4002e2afc\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1511.05284\",\"authors\":[{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/CVPR.2016.8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"title\":\"Deep Compositional Captioning: Describing Novel Object Categories without Paired Training Data\",\"url\":\"https://www.semanticscholar.org/paper/e516d22697bad6d0f7956b0e8bfa93d6eb0b2f17\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145971173\",\"name\":\"J. Xu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"145459057\",\"name\":\"Y. Rui\"}],\"doi\":\"10.1109/CVPR.2016.571\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"title\":\"MSR-VTT: A Large Video Description Dataset for Bridging Video and Language\",\"url\":\"https://www.semanticscholar.org/paper/b8e2e9f3ba008e28257195ec69a00e07f260131d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40240283\",\"name\":\"J. Dong\"},{\"authorId\":\"9931285\",\"name\":\"Xirong Li\"},{\"authorId\":\"2896042\",\"name\":\"Weiyu Lan\"},{\"authorId\":\"1890615\",\"name\":\"Y. Huo\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"}],\"doi\":\"10.1145/2964284.2984064\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f28cd3ad13fe0b3e94d7c49886648fb164601f20\",\"title\":\"Early Embedding and Late Reranking for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f28cd3ad13fe0b3e94d7c49886648fb164601f20\",\"venue\":\"ACM Multimedia\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144639556\",\"name\":\"Graham W. Taylor\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/1553374.1553505\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"346fbcffe4237aa60e8bcb3d4294a8b99436f1d0\",\"title\":\"Factored conditional restricted Boltzmann Machines for modeling motion style\",\"url\":\"https://www.semanticscholar.org/paper/346fbcffe4237aa60e8bcb3d4294a8b99436f1d0\",\"venue\":\"ICML '09\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1606.06630\",\"authors\":[{\"authorId\":\"3374063\",\"name\":\"Yuhuai Wu\"},{\"authorId\":\"35097114\",\"name\":\"Saizheng Zhang\"},{\"authorId\":\"48379623\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136cf66392f1d6bf42da4cc070888996dc472b91\",\"title\":\"On Multiplicative Integration with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/136cf66392f1d6bf42da4cc070888996dc472b91\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1409.2329\",\"authors\":[{\"authorId\":\"2563432\",\"name\":\"W. Zaremba\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97\",\"title\":\"Recurrent Neural Network Regularization\",\"url\":\"https://www.semanticscholar.org/paper/f264e8b33c0d49a692a6ce2c4bcb28588aeb7d97\",\"venue\":\"ArXiv\",\"year\":2014},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1504.00325\",\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"title\":\"Microsoft COCO Captions: Data Collection and Evaluation Server\",\"url\":\"https://www.semanticscholar.org/paper/696ca58d93f6404fea0fc75c62d1d7b378f47628\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/ICCV.2015.277\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3640aae13e344ad70a926510221dada626a44de\",\"title\":\"Guiding the Long-Short Term Memory Model for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/c3640aae13e344ad70a926510221dada626a44de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1509.04942\",\"authors\":[{\"authorId\":\"143904396\",\"name\":\"Xu Jia\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"title\":\"Guiding Long-Short Term Memory for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/175ee67fdfd0f93d6048e2217cfcc9ec873332b5\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.1109/CVPR.2017.108\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"title\":\"StyleNet: Generating Attractive Visual Captions with Styles\",\"url\":\"https://www.semanticscholar.org/paper/561ed7e47524fb3218e6a38f41cd877a9c33d3b9\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1611.07837\",\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d692d14b4277e6ad00b9030ad3b68141b3bbc21\",\"title\":\"Adaptive Feature Abstraction for Translating Video to Language\",\"url\":\"https://www.semanticscholar.org/paper/2d692d14b4277e6ad00b9030ad3b68141b3bbc21\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3308557\",\"name\":\"S. Hochreiter\"},{\"authorId\":\"145341374\",\"name\":\"J. Schmidhuber\"}],\"doi\":\"10.1162/neco.1997.9.8.1735\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"title\":\"Long Short-Term Memory\",\"url\":\"https://www.semanticscholar.org/paper/44d2abe2175df8153f465f6c39b68b76a0d40ab9\",\"venue\":\"Neural Computation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"61d2dda8d96a10a714636475c7589bd149bda053\",\"title\":\"Review Networks for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/61d2dda8d96a10a714636475c7589bd149bda053\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1505.01809\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"47413820\",\"name\":\"Hao Cheng\"},{\"authorId\":\"145204655\",\"name\":\"Hao Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"}],\"doi\":\"10.3115/v1/P15-2017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"title\":\"Language Models for Image Captioning: The Quirks and What Works\",\"url\":\"https://www.semanticscholar.org/paper/f142c849ffef66f7520aff4e0b40ac964ccb8cc1\",\"venue\":\"ACL\",\"year\":2015},{\"arxivId\":\"1406.2710\",\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ecdad98ac87f5b8a33095b61f4e4299deb18b26\",\"title\":\"A Multiplicative Model for Learning Distributed Text-Based Attribute Representations\",\"url\":\"https://www.semanticscholar.org/paper/2ecdad98ac87f5b8a33095b61f4e4299deb18b26\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1605.09553\",\"authors\":[{\"authorId\":\"50557601\",\"name\":\"Chenxi Liu\"},{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145757665\",\"name\":\"F. Sha\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"title\":\"Attention Correctness in Neural Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ae9850ce1ba187dc5f9e5ab0da381d8a551c1fc0\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"145704247\",\"name\":\"J. Martens\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"title\":\"Generating Text with Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e0e5dd8b206806372b3e20b9a2fbdbd0cf9ce1de\",\"venue\":\"ICML\",\"year\":2011},{\"arxivId\":\"1511.06432\",\"authors\":[{\"authorId\":\"2482072\",\"name\":\"Nicolas Ballas\"},{\"authorId\":\"145095579\",\"name\":\"L. Yao\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"title\":\"Delving Deeper into Convolutional Networks for Learning Video Representations\",\"url\":\"https://www.semanticscholar.org/paper/ed95c6bcdc16fb1f68b20d5bcd15c4aca4d0abde\",\"venue\":\"ICLR\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153642390\",\"name\":\"David L. Chen\"},{\"authorId\":\"83415753\",\"name\":\"W. Dolan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"title\":\"Collecting Highly Parallel Data for Paraphrase Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/554a31ce91189cf6022ac677413ef2f8b9b40ca7\",\"venue\":\"ACL 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2750075\",\"name\":\"Y. Pu\"},{\"authorId\":\"2984407\",\"name\":\"Martin Renqiang Min\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4b5c35e70954a05ec4b836f166882982f459eefa\",\"title\":\"Adaptive Feature Abstraction for Translating Video to Text\",\"url\":\"https://www.semanticscholar.org/paper/4b5c35e70954a05ec4b836f166882982f459eefa\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3141511\",\"name\":\"S. Banerjee\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"title\":\"METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments\",\"url\":\"https://www.semanticscholar.org/paper/0cd18e4400ff75b2f8b58d60ddb9b0bc12f489e7\",\"venue\":\"IEEvaluation@ACL\",\"year\":2005},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2884373\",\"name\":\"J. Elman\"}],\"doi\":\"10.1207/s15516709cog1402_1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"668087f0ae7ce1de6e0bd0965dbb480c08103260\",\"title\":\"Finding Structure in Time\",\"url\":\"https://www.semanticscholar.org/paper/668087f0ae7ce1de6e0bd0965dbb480c08103260\",\"venue\":\"Cogn. Sci.\",\"year\":1990},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Stevens\"},{\"authorId\":null,\"name\":\"J. Deng O. Russakovsky\"},{\"authorId\":null,\"name\":\"H. Su\"},{\"authorId\":null,\"name\":\"J. Krause\"},{\"authorId\":null,\"name\":\"S. Satheesh\"},{\"authorId\":null,\"name\":\"S. Ma\"},{\"authorId\":null,\"name\":\"Z. Huang\"},{\"authorId\":null,\"name\":\"A. Karpathy\"},{\"authorId\":null,\"name\":\"A. Khosla\"},{\"authorId\":null,\"name\":\"M. Bernstein\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"agenet large scale visual recognition challenge Factored temporal sigmoid belief networks for sequence learning Generating text with recurrent neural networks\",\"url\":\"\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1603.09016\",\"authors\":[{\"authorId\":\"143690259\",\"name\":\"K. Tran\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/CVPRW.2016.61\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"title\":\"Rich Image Captioning in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/18f1143c64e6557c933b206fb8b2a7bd1f389afd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2016}],\"title\":\"Semantic Compositional Networks for Visual Captioning\",\"topics\":[{\"topic\":\"Long short-term memory\",\"topicId\":\"117199\",\"url\":\"https://www.semanticscholar.org/topic/117199\"},{\"topic\":\"Microsoft Research\",\"topicId\":\"73897\",\"url\":\"https://www.semanticscholar.org/topic/73897\"},{\"topic\":\"Matrix multiplication\",\"topicId\":\"13371\",\"url\":\"https://www.semanticscholar.org/topic/13371\"},{\"topic\":\"Algorithm\",\"topicId\":\"305\",\"url\":\"https://www.semanticscholar.org/topic/305\"},{\"topic\":\"Video clip\",\"topicId\":\"30493\",\"url\":\"https://www.semanticscholar.org/topic/30493\"},{\"topic\":\"Benchmark (computing)\",\"topicId\":\"1374\",\"url\":\"https://www.semanticscholar.org/topic/1374\"},{\"topic\":\"Next-generation access\",\"topicId\":\"409349\",\"url\":\"https://www.semanticscholar.org/topic/409349\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Evaluation function\",\"topicId\":\"96169\",\"url\":\"https://www.semanticscholar.org/topic/96169\"}],\"url\":\"https://www.semanticscholar.org/paper/778ce81457383bd5e3fdb11b145ded202ebb4970\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"