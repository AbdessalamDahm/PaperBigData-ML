"{\"abstract\":\"Understanding the camera wearers activity is central to egocentric vision, yet one key facet of that activity is inherently invisible to the camera&#x2014;the wearers body pose. Prior work focuses on estimating the pose of hands and arms when they come into view, but this 1) gives an incomplete view of the full body posture, and 2) prevents any pose estimate at all in many frames, since the hands are only visible in a fraction of daily life activities. We propose to infer the invisible pose of a person behind the egocentric camera. Given a single video, our efficient learning-based approach returns the full body 3D joint positions for each frame. Our method exploits cues from the dynamic motion signatures of the surrounding scene&#x2014;which change predictably as a function of body pose&#x2014;as well as static scene structures that reveal the viewpoint (e.g., sitting vs. standing). We further introduce a novel energy minimization scheme to infer the pose sequence. It uses soft predictions of the poses per time instant together with a non-parametric model of human pose dynamics over longer windows. Our method outperforms an array of possible alternatives, including typical deep learning approaches for direct pose regression from images.\",\"arxivId\":\"1603.07763\",\"authors\":[{\"authorId\":\"143891657\",\"name\":\"H. Jiang\",\"url\":\"https://www.semanticscholar.org/author/143891657\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\",\"url\":\"https://www.semanticscholar.org/author/1794409\"}],\"citationVelocity\":10,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"93108271\",\"name\":\"Mohammad Almasi\"},{\"authorId\":\"5570375\",\"name\":\"H. Fathi\"},{\"authorId\":\"1581789684\",\"name\":\"Sayed Adel Ghaeinian\"},{\"authorId\":\"1580485424\",\"name\":\"S. Samiee\"},{\"authorId\":\"145625558\",\"name\":\"Chuankun Li\"},{\"authorId\":\"8120382\",\"name\":\"P. Wang\"},{\"authorId\":\"90862862\",\"name\":\"S. Wang\"},{\"authorId\":\"3292845\",\"name\":\"Y. Hou\"}],\"doi\":\"10.5120/ijca2019919703\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"b3b87a4b6e42b89d80e5a496c64f0ae7c16b064a\",\"title\":\"Human Action Recognition through the First-Person Point of view, Case Study Two Basic Task\",\"url\":\"https://www.semanticscholar.org/paper/b3b87a4b6e42b89d80e5a496c64f0ae7c16b064a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1808039\",\"name\":\"Emrah Basaran\"},{\"authorId\":\"10428247\",\"name\":\"Yonatan Tariku Tesfaye\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"title\":\"Person Re-identification in Videos Acquired by Mobile Devices with First-Person Point-of-View\",\"url\":\"https://www.semanticscholar.org/paper/1c838b9f37d1b4633e2addfbca2e51df0e24b0e3\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1701.00142\",\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"32776367\",\"name\":\"Mohammad Shafiei\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2980179.2980235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"title\":\"EgoCap: egocentric marker-less motion capture with two fisheye cameras\",\"url\":\"https://www.semanticscholar.org/paper/ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"}],\"doi\":\"10.1007/978-3-030-58520-4_24\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5e8a596261cfd846538811edf7db7d5f754b1159\",\"title\":\"Is Sharing of Egocentric Video Giving Away Your Biometric Signature?\",\"url\":\"https://www.semanticscholar.org/paper/5e8a596261cfd846538811edf7db7d5f754b1159\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3408086\",\"name\":\"M. Nouredanesh\"},{\"authorId\":\"29382256\",\"name\":\"Aaron W. Li\"},{\"authorId\":\"145113143\",\"name\":\"A. Godfrey\"},{\"authorId\":\"145803385\",\"name\":\"J. Hoey\"},{\"authorId\":\"145407517\",\"name\":\"J. Tung\"}],\"doi\":\"10.1007/978-3-030-11024-6_12\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"a472cc370eb59c347210ca5ba23dcef6af80ed1a\",\"title\":\"Chasing Feet in the Wild: A Proposed Egocentric Motion-Aware Gait Assessment Tool\",\"url\":\"https://www.semanticscholar.org/paper/a472cc370eb59c347210ca5ba23dcef6af80ed1a\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894435\",\"name\":\"M. Almasi\"},{\"authorId\":\"1742528579\",\"name\":\"Seyed Adel Ghaeinian\"},{\"authorId\":\"1580485424\",\"name\":\"S. Samiee\"},{\"authorId\":\"1742490137\",\"name\":\"Hamed Fathi\"}],\"doi\":\"10.1109/ICICT48043.2020.9112400\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"17d40e7de4e9aece88d187febc28b079f72d5b42\",\"title\":\"Investigating the Application of Human Motion Recognition for Athletics Talent Identification using the Head-Mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/17d40e7de4e9aece88d187febc28b079f72d5b42\",\"venue\":\"2020 International Conference on Inventive Computation Technologies (ICICT)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1827085\",\"name\":\"Young-Woon Cha\"},{\"authorId\":\"39310157\",\"name\":\"T. Price\"},{\"authorId\":\"48902263\",\"name\":\"Zhen Wei\"},{\"authorId\":\"47062695\",\"name\":\"Xinran Lu\"},{\"authorId\":\"10172108\",\"name\":\"Nicholas Rewkowski\"},{\"authorId\":\"3428200\",\"name\":\"Rohan Chabra\"},{\"authorId\":\"51274576\",\"name\":\"Zihe Qin\"},{\"authorId\":\"51270689\",\"name\":\"Hyounghun Kim\"},{\"authorId\":\"32361457\",\"name\":\"Zhaoqi Su\"},{\"authorId\":\"1680777\",\"name\":\"Yebin Liu\"},{\"authorId\":\"2044671\",\"name\":\"Adrian Ilie\"},{\"authorId\":\"144379239\",\"name\":\"A. State\"},{\"authorId\":\"145160032\",\"name\":\"Zhenlin Xu\"},{\"authorId\":\"40454588\",\"name\":\"J. Frahm\"},{\"authorId\":\"145472944\",\"name\":\"H. Fuchs\"}],\"doi\":\"10.1109/TVCG.2018.2868527\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"40577aa23c85870790b21b32b5580e86c44b2b48\",\"title\":\"Towards Fully Mobile 3D Face, Body, and Environment Capture Using Only Head-worn Cameras\",\"url\":\"https://www.semanticscholar.org/paper/40577aa23c85870790b21b32b5580e86c44b2b48\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2018},{\"arxivId\":\"2012.03680\",\"authors\":[{\"authorId\":\"52116137\",\"name\":\"Mathias Parger\"},{\"authorId\":\"34974549\",\"name\":\"Chengcheng Tang\"},{\"authorId\":\"2762640\",\"name\":\"Yuanlu Xu\"},{\"authorId\":\"1778560\",\"name\":\"C. Twigg\"},{\"authorId\":\"1873304039\",\"name\":\"Lingling Tao\"},{\"authorId\":\"1527091365\",\"name\":\"Yijing Li\"},{\"authorId\":\"1630623453\",\"name\":\"Robert Wang\"},{\"authorId\":\"1443779194\",\"name\":\"M. Steinberger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fd1a205b45e7bef69bb77a90555c13b6a18833d6\",\"title\":\"UNOC: Understanding Occlusion for Embodied Presence in Virtual Reality\",\"url\":\"https://www.semanticscholar.org/paper/fd1a205b45e7bef69bb77a90555c13b6a18833d6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1907.10045\",\"authors\":[{\"authorId\":\"3358340\",\"name\":\"Denis Tom\\u00e8\"},{\"authorId\":\"151353735\",\"name\":\"Patrick Peluse\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"},{\"authorId\":\"2863682\",\"name\":\"H. Badino\"}],\"doi\":\"10.1109/ICCV.2019.00782\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f54f2db3e1c8e79f073840a7fd4f320fb3d0589c\",\"title\":\"xR-EgoPose: Egocentric 3D Human Pose From an HMD Camera\",\"url\":\"https://www.semanticscholar.org/paper/f54f2db3e1c8e79f073840a7fd4f320fb3d0589c\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1610.02714\",\"authors\":[{\"authorId\":\"7233152\",\"name\":\"J. Finocchiaro\"},{\"authorId\":\"25263842\",\"name\":\"Aisha Urooj Khan\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"}],\"doi\":\"10.1109/WACV.2017.132\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"05441a4e03e15e6d307030daa68fcddc88bdbd8a\",\"title\":\"Egocentric Height Estimation\",\"url\":\"https://www.semanticscholar.org/paper/05441a4e03e15e6d307030daa68fcddc88bdbd8a\",\"venue\":\"2017 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2018952\",\"name\":\"Ruifeng Yuan\"},{\"authorId\":\"40498509\",\"name\":\"Mei Hui\"},{\"authorId\":\"39900815\",\"name\":\"M. Liu\"},{\"authorId\":\"144895662\",\"name\":\"Y. Zhao\"},{\"authorId\":\"32693617\",\"name\":\"Liquan Dong\"},{\"authorId\":\"16202870\",\"name\":\"Lingqin Kong\"},{\"authorId\":\"4429998\",\"name\":\"Ming Chang\"},{\"authorId\":\"144260877\",\"name\":\"Zhi Cai\"}],\"doi\":\"10.1117/12.2502880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"11f636e79df446e78c5463bd59b92c9ed9e49f12\",\"title\":\"Automatic segmentation of human depth map based on semantic segmentation of FCN and depth segmentation\",\"url\":\"https://www.semanticscholar.org/paper/11f636e79df446e78c5463bd59b92c9ed9e49f12\",\"venue\":\"International Conference on Digital Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"918b67624d6f579567b7a191d01375339dd9298f\",\"title\":\"You 2 Me : Inferring Body Pose in Egocentric Video via First and Second Person Interactions by Evonne\",\"url\":\"https://www.semanticscholar.org/paper/918b67624d6f579567b7a191d01375339dd9298f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2011.13341\",\"authors\":[{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"2812134\",\"name\":\"D. Yang\"},{\"authorId\":\"2655217\",\"name\":\"Y. Zhang\"},{\"authorId\":\"1813796\",\"name\":\"Zhaopeng Cui\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"},{\"authorId\":\"1831081930\",\"name\":\"Siyu Tang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"title\":\"4D Human Body Capture from Egocentric Video via 3D Scene Grounding\",\"url\":\"https://www.semanticscholar.org/paper/7d1bfeb5084e0a275602fc67fa0ac60269c1719e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.01519\",\"authors\":[{\"authorId\":\"3358340\",\"name\":\"Denis Tom\\u00e8\"},{\"authorId\":\"1914886\",\"name\":\"Thiemo Alldieck\"},{\"authorId\":\"151353735\",\"name\":\"Patrick Peluse\"},{\"authorId\":\"1403428213\",\"name\":\"Gerard Pons-Moll\"},{\"authorId\":\"3377447\",\"name\":\"L. Agapito\"},{\"authorId\":\"2863682\",\"name\":\"H. Badino\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"}],\"doi\":\"10.1109/TPAMI.2020.3029700\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d77d035a5cdccbd96e2779cdcf69c05808559d2\",\"title\":\"SelfPose: 3D Egocentric Pose Estimation from a Headset Mounted Camera\",\"url\":\"https://www.semanticscholar.org/paper/8d77d035a5cdccbd96e2779cdcf69c05808559d2\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403397\",\"name\":\"A. Ghosh\"},{\"authorId\":\"9215658\",\"name\":\"R. Chellappa\"}],\"doi\":\"10.1007/s42979-019-0025-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b80646f9b8d51090dfe383575680b00a268410a4\",\"title\":\"Single-Shot 3D Mesh Estimation via Adversarial Domain Adaptation - Learning Directly from Synthetic Data\",\"url\":\"https://www.semanticscholar.org/paper/b80646f9b8d51090dfe383575680b00a268410a4\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1904.09882\",\"authors\":[{\"authorId\":\"143874453\",\"name\":\"Evonne Ng\"},{\"authorId\":\"2480239\",\"name\":\"Donglai Xiang\"},{\"authorId\":\"7996087\",\"name\":\"Hanbyul Joo\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/cvpr42600.2020.00991\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"fe87da6f364417d87ecaf525e563851718ffdb07\",\"title\":\"You2Me: Inferring Body Pose in Egocentric Video via First and Second Person Interactions\",\"url\":\"https://www.semanticscholar.org/paper/fe87da6f364417d87ecaf525e563851718ffdb07\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1803.05959\",\"authors\":[{\"authorId\":\"2470018\",\"name\":\"WeiPeng Xu\"},{\"authorId\":\"49926328\",\"name\":\"A. Chatterjee\"},{\"authorId\":\"1699058\",\"name\":\"M. Zollh\\u00f6fer\"},{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"153918727\",\"name\":\"P. Fua\"},{\"authorId\":\"145361968\",\"name\":\"H. Seidel\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1109/TVCG.2019.2898650\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3b4f711f415d5559e0626543c5413e4f6ec71c6\",\"title\":\"Mo2Cap2: Real-time Mobile 3D Motion Capture with a Cap-mounted Fisheye Camera\",\"url\":\"https://www.semanticscholar.org/paper/c3b4f711f415d5559e0626543c5413e4f6ec71c6\",\"venue\":\"IEEE Transactions on Visualization and Computer Graphics\",\"year\":2019},{\"arxivId\":\"2006.00626\",\"authors\":[{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"},{\"authorId\":\"1720749879\",\"name\":\"Miao Liu\"},{\"authorId\":\"50779871\",\"name\":\"James M. Rehg\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"title\":\"In the Eye of the Beholder: Gaze and Actions in First Person Video\",\"url\":\"https://www.semanticscholar.org/paper/a48cde936f7dea115cbda99a08e12dbdf45d13fb\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152194498\",\"name\":\"Dong-Hyun Hwang\"},{\"authorId\":\"153816318\",\"name\":\"Kohei Aso\"},{\"authorId\":\"1684942\",\"name\":\"H. Koike\"}],\"doi\":\"10.1109/VR.2019.8798060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a82c70aa20679bb91b1a9a7a755e46769c1c4a62\",\"title\":\"Toward human motion capturing with an ultra-wide fisheye camera on the chest\",\"url\":\"https://www.semanticscholar.org/paper/a82c70aa20679bb91b1a9a7a755e46769c1c4a62\",\"venue\":\"2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3100027\",\"name\":\"Nikolaos Sarafianos\"},{\"authorId\":\"3175100\",\"name\":\"Bogdan Boteanu\"},{\"authorId\":\"1796198\",\"name\":\"B. Ionescu\"},{\"authorId\":\"1706204\",\"name\":\"I. Kakadiaris\"}],\"doi\":\"10.1016/j.cviu.2016.09.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"227ee3ac754c65852602379fa071cfc78d2e8e84\",\"title\":\"3D Human pose estimation: A review of the literature and analysis of covariates\",\"url\":\"https://www.semanticscholar.org/paper/227ee3ac754c65852602379fa071cfc78d2e8e84\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":\"2008.06046\",\"authors\":[{\"authorId\":\"72802941\",\"name\":\"C. Rockwell\"},{\"authorId\":\"1786435\",\"name\":\"David F. Fouhey\"}],\"doi\":\"10.1007/978-3-030-58520-4_31\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77cc755f4d2a953a9c630f6900a2cfd696408d2d\",\"title\":\"Full-Body Awareness from Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/77cc755f4d2a953a9c630f6900a2cfd696408d2d\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.08900\",\"authors\":[{\"authorId\":\"3727644\",\"name\":\"Satoshi Tsutsui\"},{\"authorId\":\"35782003\",\"name\":\"Yanwei Fu\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"90e9702ca01ebda8d131e1ec7c46506fc4959f2e\",\"title\":\"Whose hand is this? Person Identification from Egocentric Hand Gestures\",\"url\":\"https://www.semanticscholar.org/paper/90e9702ca01ebda8d131e1ec7c46506fc4959f2e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.10827\",\"authors\":[{\"authorId\":\"2883417\",\"name\":\"Kiana Ehsani\"},{\"authorId\":\"2456400\",\"name\":\"Hessam Bagherinezhad\"},{\"authorId\":\"40497777\",\"name\":\"Joseph Redmon\"},{\"authorId\":\"3012475\",\"name\":\"R. Mottaghi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2018.00426\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a63b8429ebeef316a65a94b021ef9a214c705f83\",\"title\":\"Who Let the Dogs Out? Modeling Dog Behavior from Visual Data\",\"url\":\"https://www.semanticscholar.org/paper/a63b8429ebeef316a65a94b021ef9a214c705f83\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.03173\",\"authors\":[{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"}],\"doi\":\"10.1109/ICCV.2019.01018\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bbfde97cb870408c4c78c9ec1c47c962b268b8d\",\"title\":\"Ego-Pose Estimation and Forecasting As Real-Time PD Control\",\"url\":\"https://www.semanticscholar.org/paper/7bbfde97cb870408c4c78c9ec1c47c962b268b8d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2779942\",\"name\":\"Kei Shimonishi\"},{\"authorId\":\"50525398\",\"name\":\"T. Fisher\"},{\"authorId\":\"144125614\",\"name\":\"H. Kawashima\"},{\"authorId\":\"1747395\",\"name\":\"Kotaro Funakoshi\"}],\"doi\":\"10.1007/978-3-030-41404-7_61\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18d093e74208fdfaafc5fc419a72ded01c3f37b4\",\"title\":\"Image2Height: Self-height Estimation from a Single-Shot Image\",\"url\":\"https://www.semanticscholar.org/paper/18d093e74208fdfaafc5fc419a72ded01c3f37b4\",\"venue\":\"ACPR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"}],\"doi\":\"10.22028/D291-26685\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"title\":\"From motion capture to interactive virtual worlds: towards unconstrained motion-capture algorithms for real-time performance-driven character animation\",\"url\":\"https://www.semanticscholar.org/paper/62c9590d6a37a24e6ce7805a4b1fe20c8e502c5e\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2894435\",\"name\":\"M. Almasi\"}],\"doi\":\"10.1109/icesc48915.2020.9155757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bf3d672e77b0b87f8dd79efd0cdf26752bb1bd5\",\"title\":\"Human Movement Analysis from the Egocentric Camera View\",\"url\":\"https://www.semanticscholar.org/paper/2bf3d672e77b0b87f8dd79efd0cdf26752bb1bd5\",\"venue\":\"2020 International Conference on Electronics and Sustainable Communication Systems (ICESC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1007/978-3-030-01270-0_45\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"bd9823202db4aa53f1a35f6a35f56843d0d0c71e\",\"title\":\"3D Ego-Pose Estimation via Imitation Learning\",\"url\":\"https://www.semanticscholar.org/paper/bd9823202db4aa53f1a35f6a35f56843d0d0c71e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2011.04837\",\"authors\":[{\"authorId\":\"2566332\",\"name\":\"Zhengyi Luo\"},{\"authorId\":\"10681518\",\"name\":\"Ryo Hachiuma\"},{\"authorId\":\"1477957320\",\"name\":\"Ye Yuan\"},{\"authorId\":\"87681606\",\"name\":\"S. Iwase\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"74a3710628de6cc3aff102566393bbf9025f12ca\",\"title\":\"Kinematics-Guided Reinforcement Learning for Object-Aware 3D Ego-Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/74a3710628de6cc3aff102566393bbf9025f12ca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152194498\",\"name\":\"Dong-Hyun Hwang\"},{\"authorId\":\"153816318\",\"name\":\"Kohei Aso\"},{\"authorId\":\"145412874\",\"name\":\"Ye Yuan\"},{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1684942\",\"name\":\"H. Koike\"}],\"doi\":\"10.1145/3379337.3415856\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"99714744c0285f356feb63901085da499eb7051c\",\"title\":\"MonoEye: Multimodal Human Motion Capture System Using A Single Ultra-Wide Fisheye Camera\",\"url\":\"https://www.semanticscholar.org/paper/99714744c0285f356feb63901085da499eb7051c\",\"venue\":\"UIST\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3403397\",\"name\":\"Arthita Ghosh\"}],\"doi\":\"10.13016/jcrn-mnj6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"37f347de55faca664a9c59ea957e5a85129dc2f5\",\"title\":\"Deep Inference on Multi-Sensor Data\",\"url\":\"https://www.semanticscholar.org/paper/37f347de55faca664a9c59ea957e5a85129dc2f5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39109324\",\"name\":\"R. Luo\"},{\"authorId\":\"3114252\",\"name\":\"O. Sener\"},{\"authorId\":\"1702137\",\"name\":\"S. Savarese\"}],\"doi\":\"10.1109/3DV.2017.00073\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58479c8c958584d501226712cba955dc98fc3f63\",\"title\":\"Scene Semantic Reconstruction from Egocentric RGB-D-Thermal Videos\",\"url\":\"https://www.semanticscholar.org/paper/58479c8c958584d501226712cba955dc98fc3f63\",\"venue\":\"2017 International Conference on 3D Vision (3DV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26324870\",\"name\":\"Daksh Thapar\"},{\"authorId\":\"34719987\",\"name\":\"A. Nigam\"},{\"authorId\":\"38772597\",\"name\":\"C. Arora\"}],\"doi\":\"10.1145/3394171.3413654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87fc465274a3ee292606e81ae1b9e232c0ff0c39\",\"title\":\"Recognizing Camera Wearer from Hand Gestures in Egocentric Videos: https://egocentricbiometric.github.io/\",\"url\":\"https://www.semanticscholar.org/paper/87fc465274a3ee292606e81ae1b9e232c0ff0c39\",\"venue\":\"ACM Multimedia\",\"year\":2020}],\"corpusId\":206595684,\"doi\":\"10.1109/CVPR.2017.373\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":3,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9e1f07016fb532800fcaccab03582cb16234b888\",\"references\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401653489\",\"name\":\"Daniel Guti\\u00e9rrez-G\\u00f3mez\"},{\"authorId\":\"1753581\",\"name\":\"J. J. Guerrero\"}],\"doi\":\"10.1145/2493988.2494351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00dadeeb6b6fbe3bc89075b2611e7cfbec245532\",\"title\":\"Scaled monocular SLAM for walking people\",\"url\":\"https://www.semanticscholar.org/paper/00dadeeb6b6fbe3bc89075b2611e7cfbec245532\",\"venue\":\"ISWC '13\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1702709\",\"name\":\"B. Kopp\"},{\"authorId\":\"50686700\",\"name\":\"A. Kunkel\"},{\"authorId\":\"2383633\",\"name\":\"H. Flor\"},{\"authorId\":\"2518601\",\"name\":\"T. Platz\"},{\"authorId\":\"4825570\",\"name\":\"U. Rose\"},{\"authorId\":\"5948776\",\"name\":\"K. H. Mauritz\"},{\"authorId\":\"47731439\",\"name\":\"K. Gresser\"},{\"authorId\":\"4796932\",\"name\":\"K. McCulloch\"},{\"authorId\":\"143669501\",\"name\":\"E. Taub\"}],\"doi\":\"10.1016/S0003-9993(97)90427-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"825f927d03db5c28ec429e4ece9343a89818f70a\",\"title\":\"The Arm Motor Ability Test: reliability, validity, and sensitivity to change of an instrument for assessing disabilities in activities of daily living.\",\"url\":\"https://www.semanticscholar.org/paper/825f927d03db5c28ec429e4ece9343a89818f70a\",\"venue\":\"Archives of physical medicine and rehabilitation\",\"year\":1997},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1401653489\",\"name\":\"Daniel Guti\\u00e9rrez-G\\u00f3mez\"},{\"authorId\":\"15793900\",\"name\":\"L. Puig\"},{\"authorId\":\"1753581\",\"name\":\"J. J. Guerrero\"}],\"doi\":\"10.1109/IROS.2012.6385607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"28b49a01380893abbcac04a3909b502c1beb3aa4\",\"title\":\"Full scaled 3D visual odometry from a single wearable omnidirectional camera\",\"url\":\"https://www.semanticscholar.org/paper/28b49a01380893abbcac04a3909b502c1beb3aa4\",\"venue\":\"2012 IEEE/RSJ International Conference on Intelligent Robots and Systems\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2776254\",\"name\":\"Yedid Hoshen\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2016.464\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dceca6bb3ac648c611f7097cf52a9b7f59be6f9\",\"title\":\"An Egocentric Look at Video Photographer Identity\",\"url\":\"https://www.semanticscholar.org/paper/0dceca6bb3ac648c611f7097cf52a9b7f59be6f9\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O. Arikan\"},{\"authorId\":null,\"name\":\"J.F.D.A. Forsyth\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"OBrien. Motion Synthesis from Annotations\",\"url\":\"\",\"venue\":\"Siggraph\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/CVPR.2013.458\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"5a90a0d0d4f349c2c330d9d137baf5076ee3f717\",\"title\":\"Pixel-Level Hand Detection in Ego-centric Videos\",\"url\":\"https://www.semanticscholar.org/paper/5a90a0d0d4f349c2c330d9d137baf5076ee3f717\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144040368\",\"name\":\"K. Kitani\"},{\"authorId\":\"1943600\",\"name\":\"T. Okabe\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"},{\"authorId\":\"143993575\",\"name\":\"A. Sugimoto\"}],\"doi\":\"10.1109/CVPR.2011.5995406\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8848d1abd31873594fc372e0022789f153112174\",\"title\":\"Fast unsupervised ego-action learning for first-person sports videos\",\"url\":\"https://www.semanticscholar.org/paper/8848d1abd31873594fc372e0022789f153112174\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L Kovar\"},{\"authorId\":null,\"name\":\"M Gleicher\"},{\"authorId\":null,\"name\":\"F Pighin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Motion Graphs. SIGGRAPH 2002\",\"url\":\"\",\"venue\":\"Motion Graphs. SIGGRAPH 2002\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2876810\",\"name\":\"Bilge Soran\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1809809\",\"name\":\"L. Shapiro\"}],\"doi\":\"10.1007/978-3-319-16814-2_12\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c2371629ad7bcde46e62859b2e812f6e5fc64cf\",\"title\":\"Action Recognition in the Presence of One Egocentric and Multiple Static Cameras\",\"url\":\"https://www.semanticscholar.org/paper/2c2371629ad7bcde46e62859b2e812f6e5fc64cf\",\"venue\":\"ACCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1750085\",\"name\":\"Zhao Liu\"},{\"authorId\":\"1704030\",\"name\":\"J. Zhu\"},{\"authorId\":\"145383433\",\"name\":\"J. Bu\"},{\"authorId\":\"2588203\",\"name\":\"Chun Chen\"}],\"doi\":\"10.1016/j.jvcir.2015.06.013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7bb1af55f2104a4d5dd7019d582cb047cfa7b529\",\"title\":\"A survey of human pose estimation: The body parts parsing based methods\",\"url\":\"https://www.semanticscholar.org/paper/7bb1af55f2104a4d5dd7019d582cb047cfa7b529\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3321919\",\"name\":\"Gr\\u00e9gory Rogez\"},{\"authorId\":\"3150023\",\"name\":\"J. Supancic\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2015.7299061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b639cf6a3b418544870b565d491f2c967d641ae2\",\"title\":\"First-person pose recognition using egocentric workspaces\",\"url\":\"https://www.semanticscholar.org/paper/b639cf6a3b418544870b565d491f2c967d641ae2\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1502.00956\",\"authors\":[{\"authorId\":\"1397877487\",\"name\":\"Raul Mur-Artal\"},{\"authorId\":\"145794862\",\"name\":\"J. M. M. Montiel\"},{\"authorId\":\"2642938\",\"name\":\"J. D. Tard\\u00f3s\"}],\"doi\":\"10.1109/TRO.2015.2463671\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6933c70c747e6a8103f68f1a1db80185401d537b\",\"title\":\"ORB-SLAM: A Versatile and Accurate Monocular SLAM System\",\"url\":\"https://www.semanticscholar.org/paper/6933c70c747e6a8103f68f1a1db80185401d537b\",\"venue\":\"IEEE Transactions on Robotics\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145984141\",\"name\":\"Ankur Agarwal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2004.5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3845d9e62540b8e2406343f801e026b562299ae0\",\"title\":\"3D human pose from silhouettes by relevance vector regression\",\"url\":\"https://www.semanticscholar.org/paper/3845d9e62540b8e2406343f801e026b562299ae0\",\"venue\":\"Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004.\",\"year\":2004},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2012.6248010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"title\":\"Detecting activities of daily living in first-person camera views\",\"url\":\"https://www.semanticscholar.org/paper/9e81caf9dd31b893ebbee3970c312619b7eac7bf\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2398457\",\"name\":\"Ekaterina H. Spriggs\"},{\"authorId\":\"143867160\",\"name\":\"F. Torre\"},{\"authorId\":\"145670946\",\"name\":\"M. Hebert\"}],\"doi\":\"10.1109/CVPRW.2009.5204354\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"title\":\"Temporal segmentation and activity classification from first-person sensing\",\"url\":\"https://www.semanticscholar.org/paper/1aaf8e1e8164e8968f693a100fee4343580b1d61\",\"venue\":\"2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46426476\",\"name\":\"X. Ren\"},{\"authorId\":\"39599498\",\"name\":\"C. Gu\"}],\"doi\":\"10.1109/CVPR.2010.5540074\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"title\":\"Figure-ground segmentation improves handled object recognition in egocentric video\",\"url\":\"https://www.semanticscholar.org/paper/04b16a1a19ee2128c663326b1e87a2d8ec368450\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2836466\",\"name\":\"L. Smith\"},{\"authorId\":\"144136729\",\"name\":\"Chen Yu\"},{\"authorId\":\"36452320\",\"name\":\"Alfredo F. Pereira\"}],\"doi\":\"10.1111/j.1467-7687.2009.00947.x\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5a2a97791fde78bdca1ba680c310282f644d55a5\",\"title\":\"Not your mother's view: the dynamics of toddler visual experience.\",\"url\":\"https://www.semanticscholar.org/paper/5a2a97791fde78bdca1ba680c310282f644d55a5\",\"venue\":\"Developmental science\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. J.\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Rehg . Delving into Egocentric Actions\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34977819\",\"name\":\"O. Arikan\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"},{\"authorId\":\"1394768078\",\"name\":\"J. O'Brien\"}],\"doi\":\"10.1145/1201775.882284\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3085fe3e65b7117c30f7516b96f9214d5af9b012\",\"title\":\"Motion synthesis from annotations\",\"url\":\"https://www.semanticscholar.org/paper/3085fe3e65b7117c30f7516b96f9214d5af9b012\",\"venue\":\"SIGGRAPH '03\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"T. Shiratori\"},{\"authorId\":null,\"name\":\"H. S. Park\"},{\"authorId\":null,\"name\":\"L. Sigal\"},{\"authorId\":null,\"name\":\"Y. Sheikh\"},{\"authorId\":null,\"name\":\"J. K. Hodgins\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"\",\"title\":\"Motion Capture from BodyMounted Cameras\",\"url\":\"\",\"venue\":\"ACM Transactions on Graphics,\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y Li\"},{\"authorId\":null,\"name\":\"Z Ye\"},{\"authorId\":null,\"name\":\"J Rehg\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Delving into Egocentric Actions. CVPR 2015\",\"url\":\"\",\"venue\":\"Delving into Egocentric Actions. CVPR 2015\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36274723\",\"name\":\"L. Kovar\"},{\"authorId\":\"1776507\",\"name\":\"M. Gleicher\"},{\"authorId\":\"1817134\",\"name\":\"F. Pighin\"}],\"doi\":\"10.1145/566570.566605\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9e24e178c608536db3fdcbd41984de33532b7c04\",\"title\":\"Motion graphs\",\"url\":\"https://www.semanticscholar.org/paper/9e24e178c608536db3fdcbd41984de33532b7c04\",\"venue\":\"SIGGRAPH '02\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40505733\",\"name\":\"Takaaki Shiratori\"},{\"authorId\":\"1806522\",\"name\":\"H. Park\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"},{\"authorId\":\"1788773\",\"name\":\"J. Hodgins\"}],\"doi\":\"10.1145/1964921.1964926\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"8bfe6b0c59350540955262fdebc9301a2c19c0ae\",\"title\":\"Motion capture from body-mounted cameras\",\"url\":\"https://www.semanticscholar.org/paper/8bfe6b0c59350540955262fdebc9301a2c19c0ae\",\"venue\":\"ACM Trans. Graph.\",\"year\":2011},{\"arxivId\":\"1701.00142\",\"authors\":[{\"authorId\":\"2933543\",\"name\":\"H. Rhodin\"},{\"authorId\":\"1819028\",\"name\":\"C. Richardt\"},{\"authorId\":\"1863006\",\"name\":\"D. Casas\"},{\"authorId\":\"3205238\",\"name\":\"Eldar Insafutdinov\"},{\"authorId\":\"32776367\",\"name\":\"Mohammad Shafiei\"},{\"authorId\":\"145156858\",\"name\":\"H. Seidel\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"1680185\",\"name\":\"C. Theobalt\"}],\"doi\":\"10.1145/2980179.2980235\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"title\":\"EgoCap: egocentric marker-less motion capture with two fisheye cameras\",\"url\":\"https://www.semanticscholar.org/paper/ec2d6d3bfa6a342c215c4f1ee1ae22a5c4ca82ae\",\"venue\":\"ACM Trans. Graph.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47683829\",\"name\":\"A. Fathi\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/ICCV.2011.6126269\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"title\":\"Understanding egocentric activities\",\"url\":\"https://www.semanticscholar.org/paper/bfc71c97f21b354ddfe69d17115e52db4fd4dce8\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2926663\",\"name\":\"Yair Poleg\"},{\"authorId\":\"145676235\",\"name\":\"C. Arora\"},{\"authorId\":\"144406261\",\"name\":\"Shmuel Peleg\"}],\"doi\":\"10.1109/CVPR.2014.325\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"title\":\"Temporal Segmentation of Egocentric Videos\",\"url\":\"https://www.semanticscholar.org/paper/579c88f5fd1b1e2e84c7659b6ed589aeee06035f\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"C. Li\"},{\"authorId\":null,\"name\":\"K. M. Kitani\"}],\"doi\":null,\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Pixel-level Hand Detection for Egocentric Videos\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Fathi\"},{\"authorId\":null,\"name\":\"A Farhadi\"},{\"authorId\":null,\"name\":\"Rehg J\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Understanding Egocentric Activities. ICCV 2011\",\"url\":\"\",\"venue\":\"Understanding Egocentric Activities. ICCV 2011\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1704879\",\"name\":\"H. Kjellstr\\u00f6m\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1007/3-540-47969-4_52\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7776d0a6bf3cdf9b3cd18b13d32c6babed84614b\",\"title\":\"Implicit Probabilistic Models of Human Motion for Synthesis and Tracking\",\"url\":\"https://www.semanticscholar.org/paper/7776d0a6bf3cdf9b3cd18b13d32c6babed84614b\",\"venue\":\"ECCV\",\"year\":2002},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Cheng Li\"},{\"authorId\":\"37991449\",\"name\":\"Kris M. Kitani\"}],\"doi\":\"10.1109/ICCV.2013.326\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":false,\"paperId\":\"3955eba240340ff793003dd17aedbbce9305c9bb\",\"title\":\"Model Recommendation with Virtual Probes for Egocentric Hand Detection\",\"url\":\"https://www.semanticscholar.org/paper/3955eba240340ff793003dd17aedbbce9305c9bb\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"O Arikan\"},{\"authorId\":null,\"name\":\"D A Forsyth\"},{\"authorId\":null,\"name\":\"J F Obrien\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Motion Synthesis from Annotations. Siggraph\",\"url\":\"\",\"venue\":\"Motion Synthesis from Annotations. Siggraph\",\"year\":2003},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2064160\",\"name\":\"A. Krizhevsky\"},{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":\"10.1145/3065386\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"title\":\"ImageNet classification with deep convolutional neural networks\",\"url\":\"https://www.semanticscholar.org/paper/abd1c342495432171beb7ca8fd9551ef13cbd0ff\",\"venue\":\"Commun. ACM\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738814\",\"name\":\"Y. Li\"},{\"authorId\":\"1843583\",\"name\":\"Zhefan Ye\"},{\"authorId\":\"144177248\",\"name\":\"James M. Rehg\"}],\"doi\":\"10.1109/CVPR.2015.7298625\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"title\":\"Delving into egocentric actions\",\"url\":\"https://www.semanticscholar.org/paper/08b1a3f8c6dc175b1e45818024def4ba311b21e6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1312.4659\",\"authors\":[{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":\"10.1109/CVPR.2014.214\",\"intent\":[\"methodology\",\"background\"],\"isInfluential\":true,\"paperId\":\"2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"title\":\"DeepPose: Human Pose Estimation via Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/2a002ce457f7ab3088fbd2691734f1ce79f750c4\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781120\",\"name\":\"C. Sminchisescu\"},{\"authorId\":\"3197309\",\"name\":\"A. Kanaujia\"},{\"authorId\":\"1711560\",\"name\":\"D. Metaxas\"}],\"doi\":\"10.1109/TPAMI.2007.1111\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f54057797f3a35e51d994db8d17863c574e0ffd7\",\"title\":\"BM\\u00b3E : Discriminative Density Propagation for Visual Tracking\",\"url\":\"https://www.semanticscholar.org/paper/f54057797f3a35e51d994db8d17863c574e0ffd7\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145089978\",\"name\":\"D. Damen\"},{\"authorId\":\"3067867\",\"name\":\"T. Leelasawassuk\"},{\"authorId\":\"2356868\",\"name\":\"Osian Haines\"},{\"authorId\":\"3336943\",\"name\":\"A. Calway\"},{\"authorId\":\"1398236231\",\"name\":\"W. Mayol-Cuevas\"}],\"doi\":\"10.5244/C.28.30\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d37a63088d0f296b3dc5f587944cd3c65d1e52e\",\"title\":\"You-Do, I-Learn: Discovering Task Relevant Objects and their Modes of Interaction from Multi-User Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/6d37a63088d0f296b3dc5f587944cd3c65d1e52e\",\"venue\":\"BMVC\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"},{\"authorId\":\"1731948\",\"name\":\"P. Viola\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/ICCV.2003.1238424\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3e1556aea42601df3f457ad43dfb059498931a33\",\"title\":\"Fast pose estimation with parameter-sensitive hashing\",\"url\":\"https://www.semanticscholar.org/paper/3e1556aea42601df3f457ad43dfb059498931a33\",\"venue\":\"Proceedings Ninth IEEE International Conference on Computer Vision\",\"year\":2003}],\"title\":\"Seeing Invisible Poses: Estimating 3D Body Pose from Egocentric Video\",\"topics\":[{\"topic\":\"Computer vision\",\"topicId\":\"5332\",\"url\":\"https://www.semanticscholar.org/topic/5332\"},{\"topic\":\"Global optimization\",\"topicId\":\"58624\",\"url\":\"https://www.semanticscholar.org/topic/58624\"},{\"topic\":\"Deep learning\",\"topicId\":\"2762\",\"url\":\"https://www.semanticscholar.org/topic/2762\"},{\"topic\":\"Video logging\",\"topicId\":\"146870\",\"url\":\"https://www.semanticscholar.org/topic/146870\"},{\"topic\":\"Information retrieval\",\"topicId\":\"2867\",\"url\":\"https://www.semanticscholar.org/topic/2867\"},{\"topic\":\"Parametric model\",\"topicId\":\"40004\",\"url\":\"https://www.semanticscholar.org/topic/40004\"},{\"topic\":\"Energy minimization\",\"topicId\":\"49183\",\"url\":\"https://www.semanticscholar.org/topic/49183\"},{\"topic\":\"Experiment\",\"topicId\":\"378\",\"url\":\"https://www.semanticscholar.org/topic/378\"},{\"topic\":\"Microsoft Windows\",\"topicId\":\"4539\",\"url\":\"https://www.semanticscholar.org/topic/4539\"},{\"topic\":\"Mathematical optimization\",\"topicId\":\"89\",\"url\":\"https://www.semanticscholar.org/topic/89\"},{\"topic\":\"Poor posture\",\"topicId\":\"1826649\",\"url\":\"https://www.semanticscholar.org/topic/1826649\"},{\"topic\":\"Type signature\",\"topicId\":\"173545\",\"url\":\"https://www.semanticscholar.org/topic/173545\"},{\"topic\":\"Coat of arms\",\"topicId\":\"65199\",\"url\":\"https://www.semanticscholar.org/topic/65199\"}],\"url\":\"https://www.semanticscholar.org/paper/9e1f07016fb532800fcaccab03582cb16234b888\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"