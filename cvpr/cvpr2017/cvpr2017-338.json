"{\"abstract\":\"Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning. Most methods force visual attention to be active for every generated word. However, the decoder likely requires little to no visual information from the image to predict non-visual words such as the and of. Other words that may seem visual can often be predicted reliably just from the language model e.g., sign after behind a red stop or phone following talking on a cell. In this paper, we propose a novel adaptive attention model with a visual sentinel. At each time step, our model decides whether to attend to the image (and if so, to which regions) or to the visual sentinel. The model decides whether to attend to the image and where, in order to extract meaningful information for sequential word generation. We test our method on the COCO image captioning 2015 challenge dataset and Flickr30K. Our approach sets the new state-of-the-art by a significant margin.\",\"arxivId\":\"1612.01887\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\",\"url\":\"https://www.semanticscholar.org/author/8553015\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\",\"url\":\"https://www.semanticscholar.org/author/2228109\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\",\"url\":\"https://www.semanticscholar.org/author/153432684\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\",\"url\":\"https://www.semanticscholar.org/author/2166511\"}],\"citationVelocity\":209,\"citations\":[{\"arxivId\":null,\"authors\":[{\"authorId\":\"3404403\",\"name\":\"Longteng Kong\"},{\"authorId\":\"145546921\",\"name\":\"J. Qin\"},{\"authorId\":\"40119164\",\"name\":\"D. Huang\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1109/ICASSP.2018.8461770\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"443e4bac111afe3dca81bac27d45f86ccafa65af\",\"title\":\"Hierarchical Attention and Context Modeling for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/443e4bac111afe3dca81bac27d45f86ccafa65af\",\"venue\":\"2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4291239\",\"name\":\"J. Zhang\"},{\"authorId\":\"145419855\",\"name\":\"J. Du\"},{\"authorId\":\"153634883\",\"name\":\"Li-Rong Dai\"}],\"doi\":\"10.1109/TMM.2018.2844689\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1591e0465e1fb8e7c533fbb2a612ddba3aa07f96\",\"title\":\"Track, Attend, and Parse (TAP): An End-to-End Framework for Online Handwritten Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1591e0465e1fb8e7c533fbb2a612ddba3aa07f96\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92187979\",\"name\":\"C. Xu\"},{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"16003095\",\"name\":\"Meng-long Zhang\"},{\"authorId\":\"49470161\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ICUSAI47366.2019.9124779\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"72364b3cd61221a99fb6be65e34a10c53db531cd\",\"title\":\"Attention-gated LSTM for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72364b3cd61221a99fb6be65e34a10c53db531cd\",\"venue\":\"2019 IEEE International Conference on Unmanned Systems and Artificial Intelligence (ICUSAI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46174228\",\"name\":\"Sidra Shabir\"},{\"authorId\":\"49854677\",\"name\":\"Syed Yasser Arafat\"}],\"doi\":\"10.1109/ICPESG.2018.8384519\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"title\":\"An image conveys a message: A brief survey on image description generation\",\"url\":\"https://www.semanticscholar.org/paper/4bc176200ff718ea0a0650145d3d263b0b7dfb39\",\"venue\":\"2018 1st International Conference on Power, Energy and Smart Grid (ICPESG)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"1808711\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"72028302\",\"name\":\"Zhiyao Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b9d765269867fb2e89df6cb2fa145b1b6117c99\",\"title\":\"Audio-Visual Event Localization in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/6b9d765269867fb2e89df6cb2fa145b1b6117c99\",\"venue\":\"CVPR Workshops\",\"year\":2019},{\"arxivId\":\"2012.05545\",\"authors\":[{\"authorId\":\"67333377\",\"name\":\"Zeliang Song\"},{\"authorId\":\"1727617\",\"name\":\"Xiaofei Zhou\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"2573626\",\"name\":\"Jianlong Tan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"title\":\"Image Captioning with Context-Aware Auxiliary Guidance\",\"url\":\"https://www.semanticscholar.org/paper/6f237f4ce10001a9b6cb47fae5333fa5ddb7e2d3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1810.10665\",\"authors\":[{\"authorId\":\"35752280\",\"name\":\"Kurt Shuster\"},{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":\"10.1109/CVPR.2019.01280\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c677000c9078fdff8622be15a37db7d4945f36c2\",\"title\":\"Engaging Image Captioning via Personality\",\"url\":\"https://www.semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2003.09168\",\"authors\":[{\"authorId\":\"49468484\",\"name\":\"Andres C. Rodriguez\"},{\"authorId\":\"1404069168\",\"name\":\"S. D\\u2019Aronco\"},{\"authorId\":\"144810819\",\"name\":\"K. Schindler\"},{\"authorId\":\"1753678\",\"name\":\"J. D. Wegner\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff487bb51c3c9287d93c02bec94c54638aac394a\",\"title\":\"Privileged Pooling: Supervised attention-based pooling for compensating dataset bias\",\"url\":\"https://www.semanticscholar.org/paper/ff487bb51c3c9287d93c02bec94c54638aac394a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"}],\"doi\":\"10.1007/978-3-030-37731-1_13\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"title\":\"Image Captioning Based on Visual and Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/d98f43eaf8678edbfabe50e4761c7aab550584b9\",\"venue\":\"MMM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"89766800\",\"name\":\"Zhenru Li\"},{\"authorId\":\"121704343\",\"name\":\"Yaoyi Li\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1007/978-3-030-36802-9_11\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"title\":\"Improve Image Captioning by Self-attention\",\"url\":\"https://www.semanticscholar.org/paper/c3a3cf7cbd5601d332de35a4c488da75b3a20047\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":\"1909.05506\",\"authors\":[{\"authorId\":\"1390879204\",\"name\":\"Zihao Wang\"},{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":\"1721677\",\"name\":\"J. Yan\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"145965208\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/ICCV.2019.00586\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19c630ad5a9de227f6357479fc95c62667be17f6\",\"title\":\"CAMP: Cross-Modal Adaptive Message Passing for Text-Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/19c630ad5a9de227f6357479fc95c62667be17f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1812.08658\",\"authors\":[{\"authorId\":\"37825612\",\"name\":\"Harsh Agrawal\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"46395829\",\"name\":\"Yufei Wang\"},{\"authorId\":\"1606041624\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"145461380\",\"name\":\"Rishabh Jain\"},{\"authorId\":\"1607624548\",\"name\":\"Mark Johnson\"},{\"authorId\":\"1606364265\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1606363958\",\"name\":\"Devi Parikh\"},{\"authorId\":\"1607486000\",\"name\":\"Stefan Lee\"},{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"}],\"doi\":\"10.1109/ICCV.2019.00904\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"title\":\"nocaps: novel object captioning at scale\",\"url\":\"https://www.semanticscholar.org/paper/8b55402ffee2734bfc7d5d7595500916e1ef04e8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.14752\",\"authors\":[{\"authorId\":\"47264639\",\"name\":\"Ashutosh Kumar Singh\"},{\"authorId\":\"2305086\",\"name\":\"Thoudam Doren Singh\"},{\"authorId\":\"1722399\",\"name\":\"Sivaji Bandyopadhyay\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"title\":\"A Comprehensive Review on Recent Methods and Challenges of Video Description\",\"url\":\"https://www.semanticscholar.org/paper/baf5478fbf0a2f0ca2af287a35f3f5469afcd936\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"103382547\",\"name\":\"Junzhong Ji\"},{\"authorId\":\"49770078\",\"name\":\"C. Xu\"},{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2692910\",\"name\":\"Boyue Wang\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"}],\"doi\":\"10.1109/TIP.2020.3004729\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63632ca4c1a6c16c9b6358624134880c3b23df90\",\"title\":\"Spatio-Temporal Memory Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/63632ca4c1a6c16c9b6358624134880c3b23df90\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":\"10.1109/ICCV.2017.71\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"title\":\"Towards Context-Aware Interaction Recognition for Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/222c0f085c3510eee3196fb9b3fdc52d3c488cd8\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1109/ACCESS.2019.2942000\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"801827592d18c4e6170d88f8345465de4a8db7ca\",\"title\":\"Video Captioning With Adaptive Attention and Mixed Loss Optimization\",\"url\":\"https://www.semanticscholar.org/paper/801827592d18c4e6170d88f8345465de4a8db7ca\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1470727651\",\"name\":\"Ariyo Oluwasanmi\"},{\"authorId\":\"4043033\",\"name\":\"E. Frimpong\"},{\"authorId\":\"32593111\",\"name\":\"Muhammad Umar Aftab\"},{\"authorId\":\"46352756\",\"name\":\"Edward Y. Baagyere\"},{\"authorId\":\"152179239\",\"name\":\"Zhiquang Qin\"},{\"authorId\":\"1470727785\",\"name\":\"Kifayat Ullah\"}],\"doi\":\"10.1109/ACCESS.2019.2957513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"78396f9e33eaada2a84dc12a59a3deceac05c526\",\"title\":\"Fully Convolutional CaptionNet: Siamese Difference Captioning Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/78396f9e33eaada2a84dc12a59a3deceac05c526\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390626344\",\"name\":\"Zhiyuan Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"title\":\"Cross-Modal Representation\",\"url\":\"https://www.semanticscholar.org/paper/7cd0c93b77bd2cf085c02c7a98118b6b43592110\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1679013\",\"name\":\"X. Zhang\"},{\"authorId\":\"144493052\",\"name\":\"Z. Zhao\"},{\"authorId\":\"145342793\",\"name\":\"J. Xu\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1016/j.knosys.2019.01.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"165e524750b9a3e5d47934e6fc72b9537128c116\",\"title\":\"Image-text sentiment analysis via deep multimodal attentive fusion\",\"url\":\"https://www.semanticscholar.org/paper/165e524750b9a3e5d47934e6fc72b9537128c116\",\"venue\":\"Knowl. Based Syst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50627194\",\"name\":\"Yue Qiu\"},{\"authorId\":\"1732705\",\"name\":\"Y. Satoh\"},{\"authorId\":\"143924106\",\"name\":\"R. Suzuki\"},{\"authorId\":\"35206224\",\"name\":\"K. Iwata\"},{\"authorId\":\"1730200\",\"name\":\"H. Kataoka\"}],\"doi\":\"10.3390/s20174761\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4f1217919ef803a0549822039f5328ea78f80ff\",\"title\":\"Indoor Scene Change Captioning Based on Multimodality Data\",\"url\":\"https://www.semanticscholar.org/paper/c4f1217919ef803a0549822039f5328ea78f80ff\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"},{\"authorId\":\"1796216614\",\"name\":\"Siyu Huang\"},{\"authorId\":\"40518823\",\"name\":\"Haoyi Xiong\"},{\"authorId\":\"7824051\",\"name\":\"Xingjian Li\"},{\"authorId\":\"1721158\",\"name\":\"D. Dou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"title\":\"Neighbours Matter: Image Captioning with Similar Images\",\"url\":\"https://www.semanticscholar.org/paper/652885a326e1b5b978f4abeeb88e5fe518733f7e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.08952\",\"authors\":[{\"authorId\":\"2638190\",\"name\":\"Maya Okawa\"},{\"authorId\":\"2664600\",\"name\":\"T. Iwata\"},{\"authorId\":\"12466305\",\"name\":\"Takeshi Kurashima\"},{\"authorId\":\"3293115\",\"name\":\"Yusuke Tanaka\"},{\"authorId\":\"49968508\",\"name\":\"H. Toda\"},{\"authorId\":\"1735221\",\"name\":\"N. Ueda\"}],\"doi\":\"10.1145/3292500.3330937\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6d272a9a28b4c79c8c2b8f5dfee27fb86c7156c\",\"title\":\"Deep Mixture Point Processes: Spatio-temporal Event Prediction with Rich Contextual Information\",\"url\":\"https://www.semanticscholar.org/paper/e6d272a9a28b4c79c8c2b8f5dfee27fb86c7156c\",\"venue\":\"KDD\",\"year\":2019},{\"arxivId\":\"1912.00863\",\"authors\":[{\"authorId\":\"2023862\",\"name\":\"V. Pham\"},{\"authorId\":\"2727595\",\"name\":\"Haihua Xu\"},{\"authorId\":\"2439648\",\"name\":\"Yerbolat Khassanov\"},{\"authorId\":\"46490704\",\"name\":\"Zhiping Zeng\"},{\"authorId\":\"1742722\",\"name\":\"Chng Eng Siong\"},{\"authorId\":\"7445609\",\"name\":\"Chongjia Ni\"},{\"authorId\":\"1742970\",\"name\":\"B. Ma\"},{\"authorId\":\"71200803\",\"name\":\"H. Li\"}],\"doi\":\"10.1109/ICASSP40776.2020.9054116\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c909ae761f6c382d8a8ca8d5f666ec4e47c4830\",\"title\":\"Independent Language Modeling Architecture for End-To-End ASR\",\"url\":\"https://www.semanticscholar.org/paper/3c909ae761f6c382d8a8ca8d5f666ec4e47c4830\",\"venue\":\"ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2020},{\"arxivId\":\"1810.12535\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1007/978-3-030-20870-7_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"74eda5e2a4a34b9d4a737da755b136455c947339\",\"title\":\"Gated Hierarchical Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/74eda5e2a4a34b9d4a737da755b136455c947339\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145704540\",\"name\":\"Li Ren\"},{\"authorId\":\"66719728\",\"name\":\"Kien A. Hua\"}],\"doi\":\"10.1109/ISM.2018.00021\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"title\":\"Improved Image Description Via Embedded Object Structure Graph and Semantic Feature Matching\",\"url\":\"https://www.semanticscholar.org/paper/95bba8c514f63c666e0a85bdf9c6e3b8113d1f8f\",\"venue\":\"2018 IEEE International Symposium on Multimedia (ISM)\",\"year\":2018},{\"arxivId\":\"1903.12020\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/CVPR.2019.00432\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"title\":\"Describing Like Humans: On Diversity in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"143648909\",\"name\":\"C. Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/ICME.2019.00069\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"title\":\"Colloquial Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6550b0f3c3c2e848827a0392126b55b1dbb5799b\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98419684\",\"name\":\"Phil Kinghorn\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9549e8e59f5ce436cc4d81ddb859b3295d131c5b\",\"title\":\"Deep learning-based regional image caption generation with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/9549e8e59f5ce436cc4d81ddb859b3295d131c5b\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150197175\",\"name\":\"L. Zhou\"},{\"authorId\":\"49890476\",\"name\":\"Yuejie Zhang\"},{\"authorId\":\"49296155\",\"name\":\"Y. Jiang\"},{\"authorId\":\"145326655\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145631869\",\"name\":\"W. Fan\"}],\"doi\":\"10.1109/TIP.2019.2928144\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95db18799c539c82379585d25af66fd968ff000c\",\"title\":\"Re-Caption: Saliency-Enhanced Image Captioning Through Two-Phase Learning\",\"url\":\"https://www.semanticscholar.org/paper/95db18799c539c82379585d25af66fd968ff000c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51907635\",\"name\":\"I. Khurram\"},{\"authorId\":\"1756409\",\"name\":\"M. M. Fraz\"},{\"authorId\":\"1380493605\",\"name\":\"M. Shahzad\"},{\"authorId\":\"2229652\",\"name\":\"N. Rajpoot\"}],\"doi\":\"10.1007/s12559-019-09697-1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e6b2728a7d0677e045a50203b574ea569a20cdf2\",\"title\":\"Dense-CaptionNet: a Sentence Generation Architecture for Fine-grained Description of Image Semantics\",\"url\":\"https://www.semanticscholar.org/paper/e6b2728a7d0677e045a50203b574ea569a20cdf2\",\"venue\":\"Cognitive Computation\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48195668\",\"name\":\"Jin Yuan\"},{\"authorId\":\"47059067\",\"name\":\"L. Zhang\"},{\"authorId\":\"2836997\",\"name\":\"Songrui Guo\"},{\"authorId\":\"1406190317\",\"name\":\"Y. Xiao\"},{\"authorId\":\"152985786\",\"name\":\"Z. Li\"}],\"doi\":\"10.1145/3394955\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"title\":\"Image Captioning with a Joint Attention Mechanism by Visual Concept Samples\",\"url\":\"https://www.semanticscholar.org/paper/2f977b1d34ad883483727a3c8c52e20b260ac0ad\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"1716595\",\"name\":\"Chengjun Zhan\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1117/1.JEI.28.2.023022\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3e21b716ee953230b0261d05db9664cf50e6f906\",\"title\":\"Long short-term memory network with external memories for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/3e21b716ee953230b0261d05db9664cf50e6f906\",\"venue\":\"J. Electronic Imaging\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":\"10.24963/ijcai.2018/110\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"title\":\"Image Cationing with Visual-Semantic LSTM\",\"url\":\"https://www.semanticscholar.org/paper/47921216d4758a16cf7b5bfc85cc7b9178bffe6a\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1805.08170\",\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"9325940\",\"name\":\"Pengchuan Zhang\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a484b7eda0e5389ae62ab1549f27594050a60f71\",\"title\":\"Turbo Learning for Captionbot and Drawingbot\",\"url\":\"https://www.semanticscholar.org/paper/a484b7eda0e5389ae62ab1549f27594050a60f71\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/978-3-030-00563-4_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"title\":\"Attend to Knowledge: Memory-Enhanced Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/18d99d29834ddd8c70878504998ca9f63f7b3ce1\",\"venue\":\"BICS\",\"year\":2018},{\"arxivId\":\"2003.03305\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"22d733f5d5a995469dc916102f1806253645ae60\",\"title\":\"Captioning Images with Novel Objects via Online Vocabulary Expansion\",\"url\":\"https://www.semanticscholar.org/paper/22d733f5d5a995469dc916102f1806253645ae60\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51934339\",\"name\":\"Nuzhat Naqvi\"},{\"authorId\":\"83256875\",\"name\":\"Z. Ye\"}],\"doi\":\"10.1007/s11042-020-09128-6\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"12b53d372b723e201a234786792c6de002244386\",\"title\":\"Image captions: global-local and joint signals attention model (GL-JSAM)\",\"url\":\"https://www.semanticscholar.org/paper/12b53d372b723e201a234786792c6de002244386\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jos\\u00e9 Miguel Cano Sant\\u00edn\"},{\"authorId\":null,\"name\":\"Simon Dobnik\"},{\"authorId\":null,\"name\":\"Mehdi Ghanimifard\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"769cf57f538cb50c4f5bdec6bb64470d19e372ff\",\"title\":\"Fast visual grounding in interaction: bringing few-shot learning with neural networks to an interactive robot\",\"url\":\"https://www.semanticscholar.org/paper/769cf57f538cb50c4f5bdec6bb64470d19e372ff\",\"venue\":\"PAM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"},{\"authorId\":\"2166203\",\"name\":\"O. Schulte\"}],\"doi\":\"10.1109/CVPRW.2018.00260\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2bd5fceb1f885f690f63a58c289607c85069be3d\",\"title\":\"Image Caption Generation with Hierarchical Contextual Visual Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bd5fceb1f885f690f63a58c289607c85069be3d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"108449655\",\"name\":\"Chetan Amritkar\"},{\"authorId\":\"9431671\",\"name\":\"Vaishali S. Jabade\"}],\"doi\":\"10.1109/ICCUBEA.2018.8697360\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01698c61fa4786c6c514fe252d5049b01cd010d\",\"title\":\"Image Caption Generation Using Deep Learning Technique\",\"url\":\"https://www.semanticscholar.org/paper/f01698c61fa4786c6c514fe252d5049b01cd010d\",\"venue\":\"2018 Fourth International Conference on Computing Communication Control and Automation (ICCUBEA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143753918\",\"name\":\"Y. Peng\"},{\"authorId\":\"3431037\",\"name\":\"J. Qi\"}],\"doi\":\"10.1109/TMM.2018.2877885\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7032cff8767425ab69c8f430a4869e5fd9a97eb5\",\"title\":\"Show and Tell in the Loop: Cross-Modal Circular Correlation Learning\",\"url\":\"https://www.semanticscholar.org/paper/7032cff8767425ab69c8f430a4869e5fd9a97eb5\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9095876\",\"name\":\"Jipeng Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"43965cdc9f84a32d3c7e89ee79a2e4d5dc8954ae\",\"title\":\"Word Embedding GRU ! \\\" # Image CNN Caption Generation Word Embedding Caption Embedding ! $ # Answer Prediction Question Phase\",\"url\":\"https://www.semanticscholar.org/paper/43965cdc9f84a32d3c7e89ee79a2e4d5dc8954ae\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052788\",\"name\":\"W. Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9dee5c6c65684f91bfe212f44b79383f69f4d84c\",\"title\":\"EasyChair Preprint No 1046 Image Caption Generation With Adaptive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/9dee5c6c65684f91bfe212f44b79383f69f4d84c\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1909.03169\",\"authors\":[{\"authorId\":\"32095408\",\"name\":\"Fawaz Sammani\"},{\"authorId\":\"67001969\",\"name\":\"Mahmoud Elsayed\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7af5c94fedc32f3104a08301a46c62f51b044a81\",\"title\":\"Look and Modify: Modification Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7af5c94fedc32f3104a08301a46c62f51b044a81\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7cc8e0430de6b9f1a2970e7f4f7596be0a0716e\",\"title\":\"CLARA: Dynamic Doctor Representation Learning for Clinical Trial Recruitment\",\"url\":\"https://www.semanticscholar.org/paper/e7cc8e0430de6b9f1a2970e7f4f7596be0a0716e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"35742440\",\"name\":\"X. Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2844789\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2609626519d8fa0ccc53bce49a3a21b928deeca6\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"92326466\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/cvpr42600.2020.01059\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"title\":\"Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3c5882ba83265093f2625fcebaf41bcdae4548a1\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520780\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38bbace118817cd18677f169a8c8e6c8b005df18\",\"title\":\"Auto-Encoding Graphical Inductive Bias for Descriptive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/38bbace118817cd18677f169a8c8e6c8b005df18\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153297544\",\"name\":\"X. Yang\"},{\"authorId\":\"118565563\",\"name\":\"Chong-Yang Gao\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1145/3394171.3413859\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"title\":\"Hierarchical Scene Graph Encoder-Decoder for Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/96389251e4f0f8494dfc8dc67c05992eed8e192b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9515493\",\"name\":\"Liangfu Cao\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"47158869\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1007/978-3-319-68155-9_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"title\":\"Jointly Learning Attentions with Semantic Cross-Modal Correlation for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/47d76f7c19c53a83704fa8c91d88add93c5654d1\",\"venue\":\"ADC\",\"year\":2017},{\"arxivId\":\"1810.06245\",\"authors\":[{\"authorId\":\"35935570\",\"name\":\"Jean-Benoit Delbrouck\"},{\"authorId\":\"144436412\",\"name\":\"S. Dupont\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"58d16e23e1192be4acaf6a29c1f5995817146554\",\"title\":\"Bringing back simplicity and lightliness into neural image captioning\",\"url\":\"https://www.semanticscholar.org/paper/58d16e23e1192be4acaf6a29c1f5995817146554\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1904.00767\",\"authors\":[{\"authorId\":\"1807405\",\"name\":\"S. Chen\"},{\"authorId\":\"49033321\",\"name\":\"Qi Zhao\"}],\"doi\":\"10.1007/978-3-030-01252-6_5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"title\":\"Boosted Attention: Leveraging Human Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5cab3ce511ec8345d16a28c00094a2800b3919ce\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49543226\",\"name\":\"Xiaoxiao Liu\"},{\"authorId\":\"40096492\",\"name\":\"Q. Xu\"},{\"authorId\":null,\"name\":\"Ning Wang\"}],\"doi\":\"10.1007/s00371-018-1566-y\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f79c03f977d1c9acb71d87301272682422b0b14f\",\"title\":\"A survey on deep neural network-based image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79c03f977d1c9acb71d87301272682422b0b14f\",\"venue\":\"The Visual Computer\",\"year\":2018},{\"arxivId\":\"1803.11544\",\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"145587210\",\"name\":\"Nassir Navab\"},{\"authorId\":\"1678633\",\"name\":\"Gregory Hager\"},{\"authorId\":\"2266326\",\"name\":\"Federico Tombari\"}],\"doi\":\"10.1109/CVPR.2018.00892\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a334442b493501bb60a53dc3e689fc569965ad81\",\"title\":\"Guide Me: Interacting with Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/a334442b493501bb60a53dc3e689fc569965ad81\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2004.00390\",\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"5332711\",\"name\":\"Meng Wang\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"}],\"doi\":\"10.1109/cvpr42600.2020.00483\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"title\":\"More Grounded Image Captioning by Distilling Image-Text Matching Model\",\"url\":\"https://www.semanticscholar.org/paper/c936e70cc1de52c5ad0ed5ec7a219bd25a46902c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1907.09358\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"151119369\",\"name\":\"M. Kalimuthu\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f8a48678094adbe421d61d0045361bfc635a2900\",\"title\":\"Trends in Integration of Vision and Language Research: A Survey of Tasks, Datasets, and Methods\",\"url\":\"https://www.semanticscholar.org/paper/f8a48678094adbe421d61d0045361bfc635a2900\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1905.10515\",\"authors\":[{\"authorId\":\"2153067\",\"name\":\"Baohua Sun\"},{\"authorId\":\"144890162\",\"name\":\"L. Yang\"},{\"authorId\":\"144485124\",\"name\":\"M. Lin\"},{\"authorId\":\"50674008\",\"name\":\"C. Young\"},{\"authorId\":\"46195424\",\"name\":\"P. Dong\"},{\"authorId\":\"47528094\",\"name\":\"Wenhan Zhang\"},{\"authorId\":\"35287113\",\"name\":\"Jason Dong\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70471f7d38c875e6e2912737729043e67272c326\",\"title\":\"SuperCaptioning: Image Captioning Using Two-dimensional Word Embedding\",\"url\":\"https://www.semanticscholar.org/paper/70471f7d38c875e6e2912737729043e67272c326\",\"venue\":\"BigMine@KDD\",\"year\":2019},{\"arxivId\":\"1904.02823\",\"authors\":[{\"authorId\":\"3306838\",\"name\":\"Ruizhou Ding\"},{\"authorId\":\"144774026\",\"name\":\"Ting-Wu Chin\"},{\"authorId\":\"2152269\",\"name\":\"Zeye Liu\"},{\"authorId\":\"1704073\",\"name\":\"Diana Marculescu\"}],\"doi\":\"10.1109/CVPR.2019.01167\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0cdef47d342cae516f67efd6e4991f4825043b70\",\"title\":\"Regularizing Activation Distribution for Training Binarized Deep Networks\",\"url\":\"https://www.semanticscholar.org/paper/0cdef47d342cae516f67efd6e4991f4825043b70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1703.10476\",\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.445\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c0a6854b793ca8ad281513c184318b73d4868c4\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/1c0a6854b793ca8ad281513c184318b73d4868c4\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"31126576\",\"name\":\"Zheng Xiong\"},{\"authorId\":\"2303260\",\"name\":\"Xianfang Sun\"},{\"authorId\":\"1734823\",\"name\":\"Paul L. Rosin\"},{\"authorId\":\"40534966\",\"name\":\"Longcun Jin\"},{\"authorId\":\"9245443\",\"name\":\"Xinyi Peng\"}],\"doi\":\"10.3390/app10010391\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"945ffeb90e538214e3063407db8e094469ec877a\",\"title\":\"Panoptic Segmentation-Based Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/945ffeb90e538214e3063407db8e094469ec877a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.08070\",\"authors\":[{\"authorId\":\"51163002\",\"name\":\"Alasdair Tran\"},{\"authorId\":\"46953477\",\"name\":\"A. Mathews\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"}],\"doi\":\"10.1109/CVPR42600.2020.01305\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"title\":\"Transform and Tell: Entity-Aware News Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c9f19acb4a9d56085a6d2f8f1acef7514777345\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"47655360\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1445303213\",\"name\":\"Jiaqi Zhao\"},{\"authorId\":\"49353948\",\"name\":\"Mingming Liu\"}],\"doi\":\"10.1016/j.knosys.2020.105920\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"title\":\"Remote sensing image captioning via Variational Autoencoder and Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/46fd9996cd945983f5acc9ed073dc244d6d2f32e\",\"venue\":\"Knowl. Based Syst.\",\"year\":2020},{\"arxivId\":\"2003.03749\",\"authors\":[{\"authorId\":\"92827207\",\"name\":\"J. Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1109/CVPR42600.2020.01090\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"96485bda4f4118da249cc8a898230281ac8040a7\",\"title\":\"Better Captioning With Sequence-Level Exploration\",\"url\":\"https://www.semanticscholar.org/paper/96485bda4f4118da249cc8a898230281ac8040a7\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144101175\",\"name\":\"Zhou Lei\"},{\"authorId\":\"1831825\",\"name\":\"Congcong Zhou\"},{\"authorId\":\"35155467\",\"name\":\"Shengbo Chen\"},{\"authorId\":\"1722738282\",\"name\":\"Yiyong Huang\"},{\"authorId\":\"1726027121\",\"name\":\"Xianrui Liu\"}],\"doi\":\"10.1109/ACCESS.2020.3024639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"title\":\"A Sparse Transformer-Based Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e85fdae1b5e297f1d8925c9bd5cd7e243a305116\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2007.08032\",\"authors\":[{\"authorId\":\"7232330\",\"name\":\"Spandan Madan\"},{\"authorId\":\"2717517\",\"name\":\"T. Henry\"},{\"authorId\":\"1573002290\",\"name\":\"Jamell Dozier\"},{\"authorId\":\"49374672\",\"name\":\"H. Ho\"},{\"authorId\":\"32016698\",\"name\":\"N. Bhandari\"},{\"authorId\":\"49587026\",\"name\":\"T. Sasaki\"},{\"authorId\":\"145403226\",\"name\":\"F. Durand\"},{\"authorId\":\"143758231\",\"name\":\"H. Pfister\"},{\"authorId\":\"2343486\",\"name\":\"X. Boix\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"5da610515325a2940481bffad14db9e2784ada5e\",\"title\":\"On the Capability of Neural Networks to Generalize to Unseen Category-Pose Combinations\",\"url\":\"https://www.semanticscholar.org/paper/5da610515325a2940481bffad14db9e2784ada5e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1510730409\",\"name\":\"Jia-Qi Yang\"},{\"authorId\":\"1721819\",\"name\":\"D. Zhan\"},{\"authorId\":\"50078941\",\"name\":\"Xin-Chun Li\"}],\"doi\":\"10.1007/978-3-030-47436-2_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb4b2b82b623e2dd52de1381903213e6a7c93073\",\"title\":\"Bottom-Up and Top-Down Graph Pooling\",\"url\":\"https://www.semanticscholar.org/paper/cb4b2b82b623e2dd52de1381903213e6a7c93073\",\"venue\":\"PAKDD\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":\"10.1109/ICCV.2019.00472\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5abe916562fad8306e3f4e571f83015047f0be1d\",\"title\":\"Robust Change Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5abe916562fad8306e3f4e571f83015047f0be1d\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"2894465\",\"name\":\"Benyou Wang\"},{\"authorId\":\"145581826\",\"name\":\"Jianbo Ye\"},{\"authorId\":\"144346838\",\"name\":\"Min Yang\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.24963/ijcai.2018/168\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbe4eac494fa7bc0bcd958d67393f097e0cb17db\",\"title\":\"A Multi-task Learning Approach for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbe4eac494fa7bc0bcd958d67393f097e0cb17db\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/WACV.2018.00208\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f18fe123e9017f3a9ac7cd140560a30b5a9b82c2\",\"title\":\"Improving Text-Based Person Search by Spatial Matching and Adaptive Threshold\",\"url\":\"https://www.semanticscholar.org/paper/f18fe123e9017f3a9ac7cd140560a30b5a9b82c2\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71787436\",\"name\":\"F. Xiao\"},{\"authorId\":\"144838968\",\"name\":\"Xue Gong\"},{\"authorId\":\"49890762\",\"name\":\"Yiming Zhang\"},{\"authorId\":\"2879323\",\"name\":\"Yanqing Shen\"},{\"authorId\":\"46276957\",\"name\":\"J. Li\"},{\"authorId\":\"1705421\",\"name\":\"Xieping Gao\"}],\"doi\":\"10.1016/J.NEUCOM.2019.06.085\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f5ec7bdce1acf0415e3c3370b4f634ca3d474cb\",\"title\":\"DAA: Dual LSTMs with adaptive attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f5ec7bdce1acf0415e3c3370b4f634ca3d474cb\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":\"1712.05558\",\"authors\":[{\"authorId\":\"2684967\",\"name\":\"J. Kim\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b68773df340498768e88487abe8f7fbac5fcb52d\",\"title\":\"CoDraw: Visual Dialog for Collaborative Drawing\",\"url\":\"https://www.semanticscholar.org/paper/b68773df340498768e88487abe8f7fbac5fcb52d\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40286455\",\"name\":\"Xuelong Li\"},{\"authorId\":\"46448616\",\"name\":\"Xueting Zhang\"},{\"authorId\":\"145909469\",\"name\":\"Wei Huang\"},{\"authorId\":\"50621207\",\"name\":\"Q. Wang\"}],\"doi\":\"10.1109/tgrs.2020.3010106\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f79bc9f9bf488f4580f1f4d9a360ac06a26e9e3e\",\"title\":\"Truncation Cross Entropy Loss for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f79bc9f9bf488f4580f1f4d9a360ac06a26e9e3e\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1722627\",\"name\":\"Xiaodong He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"46878216\",\"name\":\"M. Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a79b694bd4ef51207787da1948ed473903b751ef\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and VQA\",\"url\":\"https://www.semanticscholar.org/paper/a79b694bd4ef51207787da1948ed473903b751ef\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39541577\",\"name\":\"Sheng Li\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"104510214\",\"name\":\"K. Li\"},{\"authorId\":\"145692782\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/TETCI.2019.2892755\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"title\":\"Visual to Text: Survey of Image and Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/125b0bde4ac0b4cb9453b205bc0c5c184af3dec2\",\"venue\":\"IEEE Transactions on Emerging Topics in Computational Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144689876\",\"name\":\"D. Liang\"},{\"authorId\":\"12223602\",\"name\":\"F. Zhang\"},{\"authorId\":\"25109813\",\"name\":\"Weidong Zhang\"},{\"authorId\":\"49346854\",\"name\":\"Qi Zhang\"},{\"authorId\":\"41037252\",\"name\":\"Jinlan Fu\"},{\"authorId\":\"24859244\",\"name\":\"Minlong Peng\"},{\"authorId\":\"47388902\",\"name\":\"T. Gui\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.1145/3331184.3331228\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3af70e02cb62541d63392e2449e7337207ead434\",\"title\":\"Adaptive Multi-Attention Network Incorporating Answer Information for Duplicate Question Detection\",\"url\":\"https://www.semanticscholar.org/paper/3af70e02cb62541d63392e2449e7337207ead434\",\"venue\":\"SIGIR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Fan\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":\"10.1109/ICTAI.2018.00047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cdea9a5054f3b5f4dd4c3e75f9278e9548c2de7a\",\"title\":\"Long-Term Recurrent Merge Network Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cdea9a5054f3b5f4dd4c3e75f9278e9548c2de7a\",\"venue\":\"2018 IEEE 30th International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2018},{\"arxivId\":\"1912.06365\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"title\":\"Fast Image Caption Generation with Position Alignment\",\"url\":\"https://www.semanticscholar.org/paper/38e48d6b39ce94ddc2a0bf20320598739187bfef\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1903.05942\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"2398271\",\"name\":\"In-So Kweon\"}],\"doi\":\"10.1109/CVPR.2019.00643\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"title\":\"Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning\",\"url\":\"https://www.semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1706.01231\",\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"153757316\",\"name\":\"Zhao Guo\"},{\"authorId\":\"144973314\",\"name\":\"Wu Liu\"},{\"authorId\":\"2712862\",\"name\":\"D. Zhang\"},{\"authorId\":\"152555512\",\"name\":\"Heng Tao Shen\"}],\"doi\":\"10.24963/ijcai.2017/381\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"title\":\"Hierarchical LSTM with Adjusted Temporal Attention for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/616c2b2c8bb35b0da1feb9d869131edd5b53642a\",\"venue\":\"IJCAI\",\"year\":2017},{\"arxivId\":\"1904.10293\",\"authors\":[{\"authorId\":\"9372087\",\"name\":\"Q. Yan\"},{\"authorId\":\"145542268\",\"name\":\"Dong Gong\"},{\"authorId\":\"3177281\",\"name\":\"Qinfeng Shi\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"48379046\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/CVPR.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cc20befe4b33049d8a4eb21fb05572ecaf95acca\",\"title\":\"Attention-Guided Network for Ghost-Free High Dynamic Range Imaging\",\"url\":\"https://www.semanticscholar.org/paper/cc20befe4b33049d8a4eb21fb05572ecaf95acca\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3490541\",\"name\":\"Aaron Chan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"title\":\"A Survey of Image Captioning Methods\",\"url\":\"https://www.semanticscholar.org/paper/b775774edc1c2edcc9782f37eb2682cd01cfd94a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1911.00713\",\"authors\":[{\"authorId\":\"49780826\",\"name\":\"Hao Zhou\"},{\"authorId\":\"1750897\",\"name\":\"Chongyang Zhang\"},{\"authorId\":\"144541695\",\"name\":\"Chuanping Hu\"}],\"doi\":\"10.1145/3343031.3351024\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ad4333224c77079da0aee6b2b4a31c7f14cbd886\",\"title\":\"Visual Relationship Detection with Relative Location Mining\",\"url\":\"https://www.semanticscholar.org/paper/ad4333224c77079da0aee6b2b4a31c7f14cbd886\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08567-0\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"title\":\"GateCap: Gated spatial and semantic attention model for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/49280cc9fa8c9854a655afbfd213c1437c52f1e3\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145242717\",\"name\":\"H. Cheng\"},{\"authorId\":\"145310587\",\"name\":\"K. Wu\"},{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"145464144\",\"name\":\"J. Tian\"},{\"authorId\":\"143888056\",\"name\":\"R. Xu\"},{\"authorId\":\"2443214\",\"name\":\"Chao-Chen Gu\"},{\"authorId\":\"145394028\",\"name\":\"X. Guan\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206603\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"27e2197dbb2a4e3ec5eaaa9c94255c658e782b5e\",\"title\":\"Double Attention for Pathology Image Diagnosis Network with Visual Interpretability\",\"url\":\"https://www.semanticscholar.org/paper/27e2197dbb2a4e3ec5eaaa9c94255c658e782b5e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1998926555\",\"name\":\"Chenxi Yuan\"},{\"authorId\":\"2027167977\",\"name\":\"Yang Bai\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"68c11851ace525b233f05b985f8acf887d03d379\",\"title\":\"Bridge the Gap: High-level Semantic Planning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/68c11851ace525b233f05b985f8acf887d03d379\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384259000\",\"name\":\"Muchao Ye\"},{\"authorId\":\"47353599\",\"name\":\"M. Dai\"},{\"authorId\":\"50251617\",\"name\":\"Z. Zhou\"},{\"authorId\":\"19183333\",\"name\":\"Ruzheng Zhao\"}],\"doi\":\"10.23919/ChiCC.2019.8866119\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd194a673633fb0e68f8827e172edf62e1c03257\",\"title\":\"Local Statistical Active Contour Energy Functional based on Cauchy-Schwarz Divergence for Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/cd194a673633fb0e68f8827e172edf62e1c03257\",\"venue\":\"2019 Chinese Control Conference (CCC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11219408\",\"name\":\"Yuxuan Ding\"},{\"authorId\":\"46314444\",\"name\":\"W. Wang\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":\"48446599\",\"name\":\"H. Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"},{\"authorId\":\"145673165\",\"name\":\"Wei Wei\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"}],\"doi\":\"10.1007/978-3-030-31726-3_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"title\":\"Jointing Cross-Modality Retrieval to Reweight Attributes for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/6b1c6af412cc94e5cc5dcc11663b9828307aa21e\",\"venue\":\"PRCV\",\"year\":2019},{\"arxivId\":\"1904.13148\",\"authors\":[{\"authorId\":\"3110609\",\"name\":\"Zhennan Wang\"},{\"authorId\":\"2568383\",\"name\":\"Wenbin Zou\"},{\"authorId\":\"144282087\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICCV.2019.00611\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b7c074e0fce985164989f0163cef8e7bb59a3612\",\"title\":\"PR Product: A Substitute for Inner Product in Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b7c074e0fce985164989f0163cef8e7bb59a3612\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1904.02633\",\"authors\":[{\"authorId\":\"3026553\",\"name\":\"G. Liu\"},{\"authorId\":\"31375865\",\"name\":\"T. H. Hsu\"},{\"authorId\":\"41153596\",\"name\":\"Matthew B. A. McDermott\"},{\"authorId\":\"31809608\",\"name\":\"Willie Boag\"},{\"authorId\":\"2088565\",\"name\":\"Wei-Hung Weng\"},{\"authorId\":\"1679873\",\"name\":\"Peter Szolovits\"},{\"authorId\":\"145348788\",\"name\":\"M. Ghassemi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"435d5d96daff445bcc5f44a0e3cecdc46d4120d9\",\"title\":\"Clinically Accurate Chest X-Ray Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/435d5d96daff445bcc5f44a0e3cecdc46d4120d9\",\"venue\":\"MLHC\",\"year\":2019},{\"arxivId\":\"1706.00139\",\"authors\":[{\"authorId\":\"49701439\",\"name\":\"Van-Khanh Tran\"},{\"authorId\":\"145184546\",\"name\":\"L. Nguyen\"}],\"doi\":\"10.18653/v1/K17-1044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab65d7fa065ad8347bf9de1a4bfbf26a2f245594\",\"title\":\"Natural Language Generation for Spoken Dialogue System using RNN Encoder-Decoder Networks\",\"url\":\"https://www.semanticscholar.org/paper/ab65d7fa065ad8347bf9de1a4bfbf26a2f245594\",\"venue\":\"CoNLL\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46583706\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"},{\"authorId\":\"50857536\",\"name\":\"Z. Wang\"},{\"authorId\":\"145855523\",\"name\":\"D. Feng\"},{\"authorId\":\"145808910\",\"name\":\"Tieniu Tan\"}],\"doi\":\"10.1016/j.patcog.2019.107075\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"title\":\"Learning visual relationship and context-aware attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/70b03dfb947ca136e3476c9f49b8f6b044d0c1d9\",\"venue\":\"Pattern Recognit.\",\"year\":2020},{\"arxivId\":\"1912.08226\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"144255105\",\"name\":\"M. Stefanini\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"261570379fd841b426a4c51e8004f2cf9f1df771\",\"title\":\"M2: Meshed-Memory Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/261570379fd841b426a4c51e8004f2cf9f1df771\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2002.06701\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"title\":\"Gaussian Smoothen Semantic Features (GSSF) - Exploring the Linguistic Aspects of Visual Captioning in Indian Languages (Bengali) Using MSCOCO Framework\",\"url\":\"https://www.semanticscholar.org/paper/19b00a2bd1624a0931069a539a971e40b65bfb3a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.11251\",\"authors\":[{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"47636228\",\"name\":\"H. Chao\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/CVPR.2019.01278\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"title\":\"Pointing Novel Objects in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"66628761\",\"name\":\"Wenbo Nie\"},{\"authorId\":\"50079235\",\"name\":\"X. Li\"},{\"authorId\":\"1704871\",\"name\":\"Yao Yu\"}],\"doi\":\"10.1109/YAC.2019.8787715\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e46bfa93fb5874069b4bcdd6e887e96308babb2b\",\"title\":\"Image Caption Generation With Adaptive Transformer\",\"url\":\"https://www.semanticscholar.org/paper/e46bfa93fb5874069b4bcdd6e887e96308babb2b\",\"venue\":\"2019 34rd Youth Academic Annual Conference of Chinese Association of Automation (YAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"46651452\",\"name\":\"Cong Li\"},{\"authorId\":\"2641581\",\"name\":\"Tianpeng Li\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":\"10.1109/ICIP.2019.8803108\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ff24050374748529fa2a1fee6941af08296449f8\",\"title\":\"Image Captioning with Attribute Refinement\",\"url\":\"https://www.semanticscholar.org/paper/ff24050374748529fa2a1fee6941af08296449f8\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":\"2003.10925\",\"authors\":[{\"authorId\":\"47577022\",\"name\":\"Nannan Li\"},{\"authorId\":\"1724811\",\"name\":\"Z. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"title\":\"Learning Compact Reward for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/16025ed0f452e62514d4705b7da1e9f78067d9e7\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2001.06944\",\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"86724befacdd9fd8748607f5b025aa59fb7ef010\",\"title\":\"Nested-Wasserstein Self-Imitation Learning for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/86724befacdd9fd8748607f5b025aa59fb7ef010\",\"venue\":\"AISTATS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144137447\",\"name\":\"Tao Zhou\"},{\"authorId\":\"1391051492\",\"name\":\"Y. Quan\"}],\"doi\":\"10.1109/IJCNN.2019.8852118\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"title\":\"Image Captioning Based On Sentence-Level And Word-Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/f76cf186f93a0f5b3f57a8d0a1545e5b626e664e\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":\"1904.08364\",\"authors\":[{\"authorId\":\"2002678\",\"name\":\"Zecheng Xie\"},{\"authorId\":\"11833187\",\"name\":\"Yaoxiong Huang\"},{\"authorId\":\"49780704\",\"name\":\"Yuanzhi Zhu\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"9104738\",\"name\":\"Y. Liu\"},{\"authorId\":\"46330502\",\"name\":\"Lele Xie\"}],\"doi\":\"10.1109/CVPR.2019.00670\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c0af5f7cd34f7d1d27216525ddce378cbd72c70\",\"title\":\"Aggregation Cross-Entropy for Sequence Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c0af5f7cd34f7d1d27216525ddce378cbd72c70\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1911.04470\",\"authors\":[{\"authorId\":\"143879230\",\"name\":\"Jianjun Lei\"},{\"authorId\":\"49992877\",\"name\":\"Y. Song\"},{\"authorId\":\"144690387\",\"name\":\"B. Peng\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"40799321\",\"name\":\"Ling Shao\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"}],\"doi\":\"10.1109/TCSVT.2019.2936710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4e31dde236698ee4085147832f5fecbe028df9d\",\"title\":\"Semi-Heterogeneous Three-Way Joint Embedding Network for Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/b4e31dde236698ee4085147832f5fecbe028df9d\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1384783507\",\"name\":\"Anni Li\"},{\"authorId\":\"2601046\",\"name\":\"J. Qi\"},{\"authorId\":\"153176123\",\"name\":\"Huchuan Lu\"}],\"doi\":\"10.1016/j.neucom.2020.06.021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"title\":\"Multi-attention guided feature fusion network for salient object detection\",\"url\":\"https://www.semanticscholar.org/paper/7a551e9bce44d57c390dc34aa40d023cb9a889ee\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2009.12313\",\"authors\":[{\"authorId\":\"32556011\",\"name\":\"Victor Milewski\"},{\"authorId\":\"100781843\",\"name\":\"Marie-Francine Moens\"},{\"authorId\":\"2338197\",\"name\":\"Iacer Calixto\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b89e002625b0703f08b7590a1763ca7c8be66ad4\",\"title\":\"Are scene graphs good enough to improve Image Captioning?\",\"url\":\"https://www.semanticscholar.org/paper/b89e002625b0703f08b7590a1763ca7c8be66ad4\",\"venue\":\"AACL/IJCNLP\",\"year\":2020},{\"arxivId\":\"2012.13136\",\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"46641911\",\"name\":\"W. Liu\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"}],\"doi\":\"10.1007/s11263-019-01206-z\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"47286105575aacaed5ef74af9ae007e258abc60a\",\"title\":\"LCEval: Learned Composite Metric for Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/47286105575aacaed5ef74af9ae007e258abc60a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"2010.12852\",\"authors\":[{\"authorId\":\"34408936\",\"name\":\"R. Dua\"},{\"authorId\":\"2003624403\",\"name\":\"Sai Srinivas Kancheti\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"title\":\"Beyond VQA: Generating Multi-word Answer and Rationale to Visual Questions\",\"url\":\"https://www.semanticscholar.org/paper/fc80d27ca291823fc0be464a736cf72dbb4ac191\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1828728685\",\"name\":\"Moustapha Cheikh\"},{\"authorId\":\"1727395\",\"name\":\"M. Zrigui\"}],\"doi\":\"10.1007/978-3-030-53552-0_14\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"76a1a4aab4cf9eab7899d585481c6db59a4aa198\",\"title\":\"Active Learning Based Framework for Image Captioning Corpus Creation\",\"url\":\"https://www.semanticscholar.org/paper/76a1a4aab4cf9eab7899d585481c6db59a4aa198\",\"venue\":\"LION\",\"year\":2020},{\"arxivId\":\"1807.03871\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48805316\",\"name\":\"Z. Zhang\"},{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-01249-6_32\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"title\":\"\\\"Factual\\\" or \\\"Emotional\\\": Stylized Image Captioning with Adaptive Learning and Attention\",\"url\":\"https://www.semanticscholar.org/paper/abc7998326cc4fc3c9c0c3a9ede8ae2538439966\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1145/3240508.3241910\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"title\":\"Images2Poem: Generating Chinese Poetry from Image Streams\",\"url\":\"https://www.semanticscholar.org/paper/c064c00fb5aecfb181ef33d430dfc3053f1dc646\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1704.02798\",\"authors\":[{\"authorId\":\"39067762\",\"name\":\"Meire Fortunato\"},{\"authorId\":\"1723876\",\"name\":\"Charles Blundell\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5005998975f91eabd5cfefefe02eb58a71147599\",\"title\":\"Bayesian Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5005998975f91eabd5cfefefe02eb58a71147599\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1905.10521\",\"authors\":[{\"authorId\":\"2490092\",\"name\":\"Kyungwoo Song\"},{\"authorId\":\"91586945\",\"name\":\"Joonho Jang\"},{\"authorId\":\"120296402\",\"name\":\"Seung-Jae Shin\"},{\"authorId\":\"1729306\",\"name\":\"I. Moon\"}],\"doi\":\"10.1609/AAAI.V34I04.6039\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61bb0b9bf5aba11ab06e2a578ba32b21c4bd6611\",\"title\":\"Bivariate Beta LSTM\",\"url\":\"https://www.semanticscholar.org/paper/61bb0b9bf5aba11ab06e2a578ba32b21c4bd6611\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150338427\",\"name\":\"W. Li\"},{\"authorId\":\"120448891\",\"name\":\"K. Liu\"},{\"authorId\":\"3247548\",\"name\":\"Lizhe Zhang\"},{\"authorId\":\"145293271\",\"name\":\"F. Cheng\"}],\"doi\":\"10.1038/s41598-020-67529-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93a23cb12c011a1f414c53f151714a47fa85b6a7\",\"title\":\"Object detection based on an adaptive attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/93a23cb12c011a1f414c53f151714a47fa85b6a7\",\"venue\":\"Scientific Reports\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104470106\",\"name\":\"Lei Li\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"1842335\",\"name\":\"Q. Su\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"},{\"authorId\":\"38705735\",\"name\":\"C. Tai\"}],\"doi\":\"10.1109/TVCG.2020.2987626\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d5e396ba111f3b9c7f25d0d53ce8909995669b6b\",\"title\":\"Sketch-R2CNN: An RNN-Rasterization-CNN Architecture for Vector Sketch Recognition.\",\"url\":\"https://www.semanticscholar.org/paper/d5e396ba111f3b9c7f25d0d53ce8909995669b6b\",\"venue\":\"IEEE transactions on visualization and computer graphics\",\"year\":2020},{\"arxivId\":\"2009.12524\",\"authors\":[{\"authorId\":\"1972263989\",\"name\":\"Zanyar Zohourianshahzadi\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/HCCAI49649.2020.00009\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d3cf77a7eb87bf9c85c4631b196c4eb10ff5b51e\",\"title\":\"Neural Twins Talk\",\"url\":\"https://www.semanticscholar.org/paper/d3cf77a7eb87bf9c85c4631b196c4eb10ff5b51e\",\"venue\":\"2020 IEEE International Conference on Humanized Computing and Communication with Artificial Intelligence (HCCAI)\",\"year\":2020},{\"arxivId\":\"1905.12349\",\"authors\":[{\"authorId\":\"145361820\",\"name\":\"Y. Yao\"},{\"authorId\":\"145211313\",\"name\":\"X. Zhang\"},{\"authorId\":\"7576108\",\"name\":\"Baile Xu\"},{\"authorId\":\"1728090\",\"name\":\"S. Furao\"},{\"authorId\":\"46509484\",\"name\":\"Jian Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3bcbea55f35d6033daea81f8673e31fb23968f23\",\"title\":\"Super Interaction Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/3bcbea55f35d6033daea81f8673e31fb23968f23\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20630261\",\"name\":\"X. Xiao\"},{\"authorId\":\"40585252\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1016/J.PATCOG.2019.01.028\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"title\":\"Dense semantic embedding network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/18cb67e5970c4b1f0949a6f6db8f8cbaa68b2eb1\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72211602\",\"name\":\"Kai Rannenberg\"}],\"doi\":\"10.1007/978-3-030-46931-3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d37509fc390147f2ab8e3746c3abb208b3cfc36f\",\"title\":\"Intelligent Information Processing X: 11th IFIP TC 12 International Conference, IIP 2020, Hangzhou, China, July 3\\u20136, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/d37509fc390147f2ab8e3746c3abb208b3cfc36f\",\"venue\":\"Intelligent Information Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"7988538\",\"name\":\"Yadan Luo\"},{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"2416851\",\"name\":\"Hongzhi Yin\"}],\"doi\":\"10.1145/3240508.3240583\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"title\":\"Look Deeper See Richer: Depth-aware Image Paragraph Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f9853c76065b72a8a25d984f7aa4f2c65a2df623\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31275818\",\"name\":\"Yongzhe Xu\"},{\"authorId\":\"50778922\",\"name\":\"Jiangchuan Hu\"},{\"authorId\":\"40146211\",\"name\":\"K. Zeng\"},{\"authorId\":\"2311439\",\"name\":\"Yongyi Gong\"}],\"doi\":\"10.1109/ICDH.2018.00061\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"44dd332f81decef29c833a4de1b4899bd3aa94c3\",\"title\":\"Sketch-Based Shape Retrieval via Multi-view Attention and Generalized Similarity\",\"url\":\"https://www.semanticscholar.org/paper/44dd332f81decef29c833a4de1b4899bd3aa94c3\",\"venue\":\"2018 7th International Conference on Digital Home (ICDH)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2002678\",\"name\":\"Zecheng Xie\"},{\"authorId\":\"11833187\",\"name\":\"Yaoxiong Huang\"},{\"authorId\":\"49780704\",\"name\":\"Yuanzhi Zhu\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":\"9104738\",\"name\":\"Yuliang Liu\"},{\"authorId\":\"46330502\",\"name\":\"Lele Xie\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c67d692f0ca43b6c3b6cdba69f711ac33d26220\",\"title\":\"Aggregation 2 D-Prediction 1 D-Prediction Irregular Scene Text Recognition Counting Object In Everyday Scenes Regular Scene Text Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c67d692f0ca43b6c3b6cdba69f711ac33d26220\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1908.02632\",\"authors\":[{\"authorId\":\"151482698\",\"name\":\"Chen Shen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"Fuhai Chen\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"48569526\",\"name\":\"Xiangming Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"title\":\"Scene-based Factored Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c7f60b69ccafc9fb1aabc0aaac9942d68d9166cf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134654394\",\"name\":\"Ren C. Luo\"},{\"authorId\":\"34373093\",\"name\":\"Yu-Ting Hsu\"},{\"authorId\":\"151486060\",\"name\":\"Huan-Jun Ye\"}],\"doi\":\"10.1109/ISIE.2019.8781144\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"02695dca78cfe5c6c4fc7e4659b7ecac2b793bbc\",\"title\":\"Multi-Modal Human-Aware Image Caption System for Intelligent Service Robotics Applications\",\"url\":\"https://www.semanticscholar.org/paper/02695dca78cfe5c6c4fc7e4659b7ecac2b793bbc\",\"venue\":\"2019 IEEE 28th International Symposium on Industrial Electronics (ISIE)\",\"year\":2019},{\"arxivId\":\"1908.09317\",\"authors\":[{\"authorId\":\"3422200\",\"name\":\"I. Laina\"},{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"},{\"authorId\":\"145587209\",\"name\":\"N. Navab\"}],\"doi\":\"10.1109/ICCV.2019.00751\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"title\":\"Towards Unsupervised Image Captioning With Shared Multimodal Embeddings\",\"url\":\"https://www.semanticscholar.org/paper/a4ff2a0b65b7dfdecee8d2e4bc0c5f7e1fee03be\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jos\\u00e9 Miguel Cano Sant\\u00edn\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"48ef10651cf82fa01835fa78c71d082d61125b21\",\"title\":\"FAST VISUAL GROUNDING IN INTERACTION Bringing few-shot learning with neural networks to an interactive robot\",\"url\":\"https://www.semanticscholar.org/paper/48ef10651cf82fa01835fa78c71d082d61125b21\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1912.11872\",\"authors\":[{\"authorId\":\"153040576\",\"name\":\"T. Mei\"},{\"authorId\":\"101586660\",\"name\":\"W. Zhang\"},{\"authorId\":\"48577275\",\"name\":\"Ting Yao\"}],\"doi\":\"10.1017/ATSIP.2020.10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"title\":\"Vision and Language: from Visual Perception to Content Creation\",\"url\":\"https://www.semanticscholar.org/paper/3ba3e7970fac892ed3079d570ef019fa0940fec2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"121022911\",\"name\":\"Xiumei Chen\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2020.2972104\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3c7b9151021a8fa6781aa52b5bb78c9dd2511d3\",\"title\":\"A Joint Relationship Aware Neural Network for Single-Image 3D Human Pose Estimation\",\"url\":\"https://www.semanticscholar.org/paper/b3c7b9151021a8fa6781aa52b5bb78c9dd2511d3\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1906.12188\",\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"title\":\"A Deep Decoder Structure Based on WordEmbedding Regression for An Encoder-Decoder Based Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a7c6d0bccb43e886297c5bf41ba7bacbb4ac05ea\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144613170\",\"name\":\"S. Cao\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2383779\",\"name\":\"Qiu-Qi Ruan\"}],\"doi\":\"10.1016/j.neucom.2020.08.019\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f235982f603a740dcee9cff7c5de234878f80a3f\",\"title\":\"Interactions Guided Generative Adversarial Network for unsupervised image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f235982f603a740dcee9cff7c5de234878f80a3f\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1907.12905\",\"authors\":[{\"authorId\":\"8668622\",\"name\":\"Xiangxi Shi\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"},{\"authorId\":\"2708940\",\"name\":\"Shafiq R. Joty\"},{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"}],\"doi\":\"10.1145/3343031.3351060\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ea12e7ccefa226593a6918ae3100bfcd4b2d284\",\"title\":\"Watch It Twice: Video Captioning with a Refocused Video Encoder\",\"url\":\"https://www.semanticscholar.org/paper/5ea12e7ccefa226593a6918ae3100bfcd4b2d284\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"46867445\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9305704\",\"name\":\"Xiaosheng Yu\"}],\"doi\":\"10.1155/2020/3062706\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"title\":\"An Overview of Image Caption Generation Methods\",\"url\":\"https://www.semanticscholar.org/paper/4b652fa2b4ea242a25a62e2e67eddde867e7e189\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1783406\",\"name\":\"Yiqun Liu\"},{\"authorId\":\"50561553\",\"name\":\"Jun-qi Zhang\"},{\"authorId\":\"3340223\",\"name\":\"J. Mao\"},{\"authorId\":\"39767557\",\"name\":\"M. Zhang\"},{\"authorId\":\"8093158\",\"name\":\"S. Ma\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"},{\"authorId\":\"2663130\",\"name\":\"Yanxiong Lu\"},{\"authorId\":\"4950224\",\"name\":\"Leyu Lin\"}],\"doi\":\"10.1145/3329188\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0f40dad1bd4b0c075bb0af72096426b6b7384e93\",\"title\":\"Search Result Reranking with Visual and Structure Information Sources\",\"url\":\"https://www.semanticscholar.org/paper/0f40dad1bd4b0c075bb0af72096426b6b7384e93\",\"venue\":\"ACM Trans. Inf. Syst.\",\"year\":2019},{\"arxivId\":\"2010.09638\",\"authors\":[{\"authorId\":\"49353442\",\"name\":\"Jiawei Sheng\"},{\"authorId\":\"50530181\",\"name\":\"Shu Guo\"},{\"authorId\":\"48354053\",\"name\":\"Zhenyu Chen\"},{\"authorId\":\"1999184651\",\"name\":\"Juwei Yue\"},{\"authorId\":\"46659335\",\"name\":\"Lihong Wang\"},{\"authorId\":\"2079682\",\"name\":\"Tingwen Liu\"},{\"authorId\":\"46485352\",\"name\":\"Hongbo Xu\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.131\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b32f5c3d2b0717fd6436068052c33dba2f59fcf2\",\"title\":\"Adaptive Attentional Network for Few-Shot Knowledge Graph Completion\",\"url\":\"https://www.semanticscholar.org/paper/b32f5c3d2b0717fd6436068052c33dba2f59fcf2\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Ahmed Shehab Khan\"},{\"authorId\":null,\"name\":\"Zhiyuan Li\"},{\"authorId\":null,\"name\":\"Jie Cai\"},{\"authorId\":null,\"name\":\"Yan Tong\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"170f403ca462bf88513197f8e499e31dd7701d1a\",\"title\":\"Regional Attention Networks with Context-aware Fusion for Group Emotion Recognition\",\"url\":\"https://www.semanticscholar.org/paper/170f403ca462bf88513197f8e499e31dd7701d1a\",\"venue\":\"\",\"year\":null},{\"arxivId\":\"1811.09789\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"1795294\",\"name\":\"M. Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9347ee91bf90129582e7ed414d23ad3495180235\",\"title\":\"Senti-Attend: Image Captioning using Sentiment and Attention\",\"url\":\"https://www.semanticscholar.org/paper/9347ee91bf90129582e7ed414d23ad3495180235\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/s11063-019-09978-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9651480574afedb770e645871484b07fa6fc60c3\",\"title\":\"Deep Captioning with Attention-Based Visual Concept Transfer Mechanism for Enriching Description\",\"url\":\"https://www.semanticscholar.org/paper/9651480574afedb770e645871484b07fa6fc60c3\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.18653/v1/P18-3003\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"954a39752ca5ebc19eb7563c28a5773f70bff452\",\"title\":\"Learning-based Composite Metrics for Improved Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/954a39752ca5ebc19eb7563c28a5773f70bff452\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120383870\",\"name\":\"Yuhao Tang\"},{\"authorId\":\"3069077\",\"name\":\"Q. Mao\"},{\"authorId\":\"143698886\",\"name\":\"Hongjie Jia\"},{\"authorId\":\"3309006\",\"name\":\"Heping Song\"},{\"authorId\":\"144754529\",\"name\":\"Yongzhao Zhan\"}],\"doi\":\"10.1109/access.2019.2911714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d77867dace136e48ffadb912507e2518e867d673\",\"title\":\"An Emotion-Embedded Visual Attention Model for Dimensional Emotion Context Learning\",\"url\":\"https://www.semanticscholar.org/paper/d77867dace136e48ffadb912507e2518e867d673\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50591501\",\"name\":\"Wei Cui\"},{\"authorId\":\"29090447\",\"name\":\"D. Zhang\"},{\"authorId\":null,\"name\":\"Xin He\"},{\"authorId\":\"144817588\",\"name\":\"Meng Yao\"},{\"authorId\":\"47196880\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"80276778\",\"name\":\"Yuanjie Hao\"},{\"authorId\":\"47786973\",\"name\":\"J. Li\"},{\"authorId\":\"50225314\",\"name\":\"Weijie Wu\"},{\"authorId\":\"144351673\",\"name\":\"Wenqi Cui\"},{\"authorId\":\"1955707\",\"name\":\"Jiejun Huang\"}],\"doi\":\"10.3390/ijgi8090417\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0b2f0bccb5fb8b1b8acc30e4faa1bdbf667759eb\",\"title\":\"Multi-Scale Remote Sensing Semantic Analysis Based on a Global Perspective\",\"url\":\"https://www.semanticscholar.org/paper/0b2f0bccb5fb8b1b8acc30e4faa1bdbf667759eb\",\"venue\":\"ISPRS Int. J. Geo Inf.\",\"year\":2019},{\"arxivId\":\"1910.06475\",\"authors\":[{\"authorId\":\"152325076\",\"name\":\"H. Ge\"},{\"authorId\":\"79403975\",\"name\":\"Zehang Yan\"},{\"authorId\":\"96280392\",\"name\":\"K. Zhang\"},{\"authorId\":\"145327825\",\"name\":\"Mingde Zhao\"},{\"authorId\":\"46732983\",\"name\":\"Liang Sun\"}],\"doi\":\"10.1109/ICCV.2019.00184\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4b5231149f566fc8a78797b6fb448f9bca416380\",\"title\":\"Exploring Overall Contextual Information for Image Captioning in Human-Like Cognitive Style\",\"url\":\"https://www.semanticscholar.org/paper/4b5231149f566fc8a78797b6fb448f9bca416380\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38722063\",\"name\":\"Muyi Sun\"},{\"authorId\":\"147227838\",\"name\":\"Kaiyi Liang\"},{\"authorId\":\"1491104719\",\"name\":\"W. Zhang\"},{\"authorId\":\"49513859\",\"name\":\"Q. Chang\"},{\"authorId\":\"152482260\",\"name\":\"Xiaoguang Zhou\"}],\"doi\":\"10.1109/ACCESS.2020.2967350\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8a9ecd235480744dfa7603279467990727e3c8dd\",\"title\":\"Non-Local Attention and Densely-Connected Convolutional Neural Networks for Malignancy Suspiciousness Classification of Gastric Ulcer\",\"url\":\"https://www.semanticscholar.org/paper/8a9ecd235480744dfa7603279467990727e3c8dd\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1624658620\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"1429199889\",\"name\":\"Shaozu Yuan\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2981513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"711be95a04da16c93b6bc880169532b68cdca37a\",\"title\":\"Hierarchical Attention-Based Fusion for Image Caption With Multi-Grained Rewards\",\"url\":\"https://www.semanticscholar.org/paper/711be95a04da16c93b6bc880169532b68cdca37a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2685285\",\"name\":\"P. Palasek\"},{\"authorId\":\"48955389\",\"name\":\"Nilli Lavie\"},{\"authorId\":\"153242913\",\"name\":\"Luke Palmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd4c523e227fd326be5d9f37d8dbdd7c57ad6713\",\"title\":\"Attentional demand estimation with attentive driving models\",\"url\":\"https://www.semanticscholar.org/paper/cd4c523e227fd326be5d9f37d8dbdd7c57ad6713\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1885314583\",\"name\":\"Made Raharja Surya Mahadi\"},{\"authorId\":\"9347718\",\"name\":\"Anditya Arifianto\"},{\"authorId\":\"9308183\",\"name\":\"K. N. Ramadhani\"}],\"doi\":\"10.1109/ICoICT49345.2020.9166244\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"538b261dbdffc4745cb217128c001ef1e63dc6b6\",\"title\":\"Adaptive Attention Generation for Indonesian Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/538b261dbdffc4745cb217128c001ef1e63dc6b6\",\"venue\":\"2020 8th International Conference on Information and Communication Technology (ICoICT)\",\"year\":2020},{\"arxivId\":\"1904.12004\",\"authors\":[{\"authorId\":\"98243944\",\"name\":\"Chenglong Wang\"},{\"authorId\":\"3407947\",\"name\":\"R. Bunel\"},{\"authorId\":\"1729912\",\"name\":\"Krishnamurthy Dvijotham\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"1864353\",\"name\":\"Edward Grefenstette\"},{\"authorId\":\"143967473\",\"name\":\"P. Kohli\"}],\"doi\":\"10.1109/CVPR.2019.01254\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59b439bde73d80dccf367d414e209d08d312c059\",\"title\":\"Knowing When to Stop: Evaluation and Verification of Conformity to Output-Size Specifications\",\"url\":\"https://www.semanticscholar.org/paper/59b439bde73d80dccf367d414e209d08d312c059\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.07841\",\"authors\":[{\"authorId\":\"9919436\",\"name\":\"J. Yu\"},{\"authorId\":\"31115234\",\"name\":\"Jing Li\"},{\"authorId\":\"144007938\",\"name\":\"Zhou Yu\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"}],\"doi\":\"10.1109/TCSVT.2019.2947482\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"title\":\"Multimodal Transformer With Multi-View Visual Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/99b5153235b0ee583803bbd7cd6bd9da161d5348\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"1807.10854\",\"authors\":[{\"authorId\":\"51151229\",\"name\":\"Daniel W. Otter\"},{\"authorId\":\"51149804\",\"name\":\"J. R. Medina\"},{\"authorId\":\"34694214\",\"name\":\"J. Kalita\"}],\"doi\":\"10.1109/tnnls.2020.2979670\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"title\":\"A Survey of the Usages of Deep Learning in Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/e210f4b0a9b00b73f5f353ca38a60776fab443af\",\"venue\":\"IEEE transactions on neural networks and learning systems\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"49470127\",\"name\":\"X. Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"1406222945\",\"name\":\"Zhigang Luo\"}],\"doi\":\"10.1007/s11042-019-08209-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"title\":\"Object-aware semantics of attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/311ee1284e6bdf035f8c3a1a20d00c5841b2e341\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1810.03023\",\"authors\":[{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"40974715\",\"name\":\"Bhargav Kanuparthi\"},{\"authorId\":\"51922896\",\"name\":\"Giancarlo Kerg\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"3168518\",\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5f44f56c754cbd5e99e26d7fcad9d83d67d97cf1\",\"title\":\"h-detach: Modifying the LSTM Gradient Towards Better Optimization\",\"url\":\"https://www.semanticscholar.org/paper/5f44f56c754cbd5e99e26d7fcad9d83d67d97cf1\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152356310\",\"name\":\"Danyang Cao\"},{\"authorId\":\"152223852\",\"name\":\"Menggui Zhu\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"}],\"doi\":\"10.1007/s11042-019-08116-9\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3e19260676bbc8185830528773d54b83ba3f12a2\",\"title\":\"An image caption method based on object detection\",\"url\":\"https://www.semanticscholar.org/paper/3e19260676bbc8185830528773d54b83ba3f12a2\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2833820\",\"name\":\"Alakananda Vempala\"},{\"authorId\":\"1398830377\",\"name\":\"Daniel Preotiuc-Pietro\"}],\"doi\":\"10.18653/v1/P19-1272\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"54d92570201f72826e2a4bcc5b2a486e0b84049e\",\"title\":\"Categorizing and Inferring the Relationship between the Text and Image of Twitter Posts\",\"url\":\"https://www.semanticscholar.org/paper/54d92570201f72826e2a4bcc5b2a486e0b84049e\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1809.03702\",\"authors\":[{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"2361575\",\"name\":\"Olexa Bilaniuk\"},{\"authorId\":\"1737610\",\"name\":\"Jonathan Binas\"},{\"authorId\":\"144473519\",\"name\":\"M. Mozer\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa0beb3f4d7f6e7e49b153af7e8a7c30f2937b60\",\"title\":\"Sparse Attentive Backtracking: Temporal CreditAssignment Through Reminding\",\"url\":\"https://www.semanticscholar.org/paper/fa0beb3f4d7f6e7e49b153af7e8a7c30f2937b60\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":\"1908.02923\",\"authors\":[{\"authorId\":\"2455191\",\"name\":\"Omid Mohamad Nezami\"},{\"authorId\":\"143899054\",\"name\":\"Mark Dras\"},{\"authorId\":\"3093086\",\"name\":\"Stephen Wan\"},{\"authorId\":\"145212976\",\"name\":\"C\\u00e9cile Paris\"}],\"doi\":\"10.1613/jair.1.12025\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"title\":\"Image Captioning using Facial Expression and Attention\",\"url\":\"https://www.semanticscholar.org/paper/29f5da6a626c32506a1ef93300a16d1f2c812a11\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"81636696\",\"name\":\"T. Liang\"},{\"authorId\":\"47002621\",\"name\":\"Y. Li\"},{\"authorId\":\"9358854\",\"name\":\"Ruixuan Li\"},{\"authorId\":\"70387082\",\"name\":\"Xiwu Gu\"},{\"authorId\":\"1382828513\",\"name\":\"Olivier Habimana\"},{\"authorId\":\"152991588\",\"name\":\"Yi Hu\"}],\"doi\":\"10.1109/IJCNN.2019.8852185\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ded73aab50164efc02484de9c64d556d7ce3d7fe\",\"title\":\"Personalizing Session-based Recommendation with Dual Attentive Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/ded73aab50164efc02484de9c64d556d7ce3d7fe\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"112858943\",\"name\":\"Z. Liu\"},{\"authorId\":\"2427350\",\"name\":\"Yankai Lin\"},{\"authorId\":\"1753344\",\"name\":\"M. Sun\"}],\"doi\":\"10.1007/978-981-15-5573-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"title\":\"Representation Learning for Natural Language Processing\",\"url\":\"https://www.semanticscholar.org/paper/2f1107ea6b9b4147a808e9ae27757e214685e90a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3055959\",\"name\":\"Veena Thenkanidiyoor\"},{\"authorId\":\"47798961\",\"name\":\"R. Prasath\"},{\"authorId\":\"150255310\",\"name\":\"Odelu Vanga\"},{\"authorId\":\"145960032\",\"name\":\"R. Goebel\"},{\"authorId\":\"144865865\",\"name\":\"Y. Tanaka\"}],\"doi\":\"10.1007/978-3-030-66187-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b326e950ca86368056d2846444c25c61fedbc111\",\"title\":\"Mining Intelligence and Knowledge Exploration: 7th International Conference, MIKE 2019, Goa, India, December 19\\u201322, 2019, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/b326e950ca86368056d2846444c25c61fedbc111\",\"venue\":\"MIKE\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":null,\"name\":\"Yunhong Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/tcsvt.2019.2921655\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"title\":\"Sports Video Captioning via Attentive Motion Representation and Group Relationship Modeling\",\"url\":\"https://www.semanticscholar.org/paper/cd3beba63f991507ee1e8fb5298eb83c1890caa7\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":\"2008.12009\",\"authors\":[{\"authorId\":\"145338991\",\"name\":\"Ananya B. Sai\"},{\"authorId\":\"1389549528\",\"name\":\"Akash Kumar Mohankumar\"},{\"authorId\":\"2361078\",\"name\":\"Mitesh M. Khapra\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"de7f66cccc202dc563d9dcd0887fb37481d61b3d\",\"title\":\"A Survey of Evaluation Metrics Used for NLG Systems\",\"url\":\"https://www.semanticscholar.org/paper/de7f66cccc202dc563d9dcd0887fb37481d61b3d\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"72388323\",\"name\":\"Akash Abdu Jyothi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"517d923148ce9451777dd47e9cf368203428d6e0\",\"title\":\"Generating Natural Language Summaries for Image Sets by Akash Abdu Jyothi\",\"url\":\"https://www.semanticscholar.org/paper/517d923148ce9451777dd47e9cf368203428d6e0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Viktor Makoviichuk\"},{\"authorId\":\"6750120\",\"name\":\"Boris Kovalenko\"},{\"authorId\":\"7675774\",\"name\":\"C. Manning\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"874bcb52ffed680100aa13b729a9291b89b40250\",\"title\":\"Tell Me What I See\",\"url\":\"https://www.semanticscholar.org/paper/874bcb52ffed680100aa13b729a9291b89b40250\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48387339\",\"name\":\"Xinxin Zhu\"},{\"authorId\":\"1761970\",\"name\":\"L. Li\"},{\"authorId\":\"40478963\",\"name\":\"J. Liu\"},{\"authorId\":\"7475375\",\"name\":\"H. Peng\"},{\"authorId\":\"3712008\",\"name\":\"X. Niu\"}],\"doi\":\"10.3390/APP8050739\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"da958d2604e9f86f94a441d60488d0e93451c248\",\"title\":\"Captioning Transformer with Stacked Attention Modules\",\"url\":\"https://www.semanticscholar.org/paper/da958d2604e9f86f94a441d60488d0e93451c248\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.06861\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"1705047\",\"name\":\"S. Wang\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"10634370\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":\"10.1109/CVPR.2019.00646\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"title\":\"Self-Critical N-Step Training for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b6b3d6a37e7e77f5d5c763a4abeade256324268c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"122865911\",\"name\":\"Mie Mie Aung\"},{\"authorId\":\"145750914\",\"name\":\"Myint San\"},{\"authorId\":\"3169864\",\"name\":\"Phyu Phyu Khaing\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45505889a0cf75a830545080d6b8b57cc2e2525f\",\"title\":\"Natural Language Description Generation for Image using Deep Learning Architecture\",\"url\":\"https://www.semanticscholar.org/paper/45505889a0cf75a830545080d6b8b57cc2e2525f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47244778\",\"name\":\"R. Osswald\"},{\"authorId\":\"1834390\",\"name\":\"C. Retor\\u00e9\"},{\"authorId\":\"1818082\",\"name\":\"P. Sutton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"836d3a7d44fc36e3c6cb39ad6d83f9fb5bef00ec\",\"title\":\"CSTFRS 2019 IWCS 2019 Workshop on Computing Semantics with Types, Frames and Related Structures Proceedings of the Workshop\",\"url\":\"https://www.semanticscholar.org/paper/836d3a7d44fc36e3c6cb39ad6d83f9fb5bef00ec\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2589441\",\"name\":\"Shiqi Wu\"},{\"authorId\":\"152899497\",\"name\":\"Xiangrong Zhang\"},{\"authorId\":\"48632022\",\"name\":\"Xin Wang\"},{\"authorId\":\"1713590317\",\"name\":\"Chen Li\"},{\"authorId\":\"1734497\",\"name\":\"Licheng Jiao\"}],\"doi\":\"10.1109/IJCNN48605.2020.9207381\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8f497460633cf0a61c5749aa02f11bc95a599dc4\",\"title\":\"Scene Attention Mechanism for Remote Sensing Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/8f497460633cf0a61c5749aa02f11bc95a599dc4\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"41052836\",\"name\":\"Anya Belz\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1714982\",\"name\":\"Licheng Yu\"}],\"doi\":\"10.1017/S1351324918000086\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d740802aa22dbc187fe5df39108ba493b34d2839\",\"title\":\"From image to language and back again\",\"url\":\"https://www.semanticscholar.org/paper/d740802aa22dbc187fe5df39108ba493b34d2839\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":\"2003.03934\",\"authors\":[{\"authorId\":\"11064745\",\"name\":\"Raha Moraffah\"},{\"authorId\":\"145084368\",\"name\":\"Mansooreh Karami\"},{\"authorId\":\"2773849\",\"name\":\"Ruocheng Guo\"},{\"authorId\":\"19251475\",\"name\":\"A. Raglin\"},{\"authorId\":\"145896397\",\"name\":\"Huan Liu\"}],\"doi\":\"10.1145/3400051.3400058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"044fd644a3608178adc69820d9ff3b0e76ed3c74\",\"title\":\"Causal Interpretability for Machine Learning - Problems, Methods and Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/044fd644a3608178adc69820d9ff3b0e76ed3c74\",\"venue\":\"SIGKDD Explor.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151497541\",\"name\":\"X. Meng\"},{\"authorId\":\"151474857\",\"name\":\"Hao Kong\"},{\"authorId\":\"151486196\",\"name\":\"D. Tang\"},{\"authorId\":\"144720255\",\"name\":\"T. Lu\"}],\"doi\":\"10.1109/ICME.2019.00229\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95ddec4b0ab0024da1e80b66b0a29e0102c0b8fe\",\"title\":\"Multimodal Image Captioning Through Combining Reinforced Cross Entropy Loss and Stochastic Deprecation\",\"url\":\"https://www.semanticscholar.org/paper/95ddec4b0ab0024da1e80b66b0a29e0102c0b8fe\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38314306\",\"name\":\"Rakshith Shetty\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"1739548\",\"name\":\"M. Fritz\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1109/ICCV.2017.398\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"title\":\"Speaking the Same Language: Matching Machine to Human Captions by Adversarial Training\",\"url\":\"https://www.semanticscholar.org/paper/7fac20f3908c69bd336ea252e28c79f5abaa6dbe\",\"venue\":\"ICCV 2017\",\"year\":2017},{\"arxivId\":\"1805.09019\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"title\":\"CNN+CNN: Convolutional Decoders for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cbc3ebf2809edcaa04e252d25f4373c924f4136b\",\"venue\":\"CVPR 2018\",\"year\":2018},{\"arxivId\":\"1710.02534\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"83d66c1f808962536a68418587b691f30221c5a1\",\"title\":\"Contrastive Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/83d66c1f808962536a68418587b691f30221c5a1\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"1808.02373\",\"authors\":[{\"authorId\":\"48754192\",\"name\":\"Pingping Zhang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1cf836282b6e39e7c252a278a8d5397701230703\",\"title\":\"Troy: Give Attention to Saliency and for Saliency\",\"url\":\"https://www.semanticscholar.org/paper/1cf836282b6e39e7c252a278a8d5397701230703\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46407634\",\"name\":\"Jind\\u0159ich Helcl\"},{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"3452584\",\"name\":\"Tom Kocmi\"},{\"authorId\":\"1774026\",\"name\":\"Tom\\u00e1\\u0161 Musil\"},{\"authorId\":\"41022618\",\"name\":\"Ond\\u0159ej C\\u00edfka\"},{\"authorId\":\"3111948\",\"name\":\"Dusan Varis\"},{\"authorId\":\"143832874\",\"name\":\"Ondrej Bojar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"87941a5597b950d35e104fde4507ec1215c66366\",\"title\":\"Neural Monkey: The Current State and Beyond\",\"url\":\"https://www.semanticscholar.org/paper/87941a5597b950d35e104fde4507ec1215c66366\",\"venue\":\"AMTA\",\"year\":2018},{\"arxivId\":\"1809.06227\",\"authors\":[{\"authorId\":\"3441420\",\"name\":\"Tszhang Guo\"},{\"authorId\":\"3307026\",\"name\":\"S. Chang\"},{\"authorId\":\"2482533\",\"name\":\"Mo Yu\"},{\"authorId\":\"144654778\",\"name\":\"K. Bai\"}],\"doi\":\"10.18653/v1/D18-1083\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a78199a2cc678818489087454fe1150db4870196\",\"title\":\"Improving Reinforcement Learning Based Image Captioning with Natural Language Prior\",\"url\":\"https://www.semanticscholar.org/paper/a78199a2cc678818489087454fe1150db4870196\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"2006.03744\",\"authors\":[{\"authorId\":\"50651835\",\"name\":\"Mingjie Li\"},{\"authorId\":\"46429484\",\"name\":\"F. Wang\"},{\"authorId\":\"144950946\",\"name\":\"Xiaojun Chang\"},{\"authorId\":\"13246332\",\"name\":\"Xiaodan Liang\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"461420c80d3bdc156e5db7af13264a955a6a2010\",\"title\":\"Auxiliary Signal-Guided Knowledge Encoder-Decoder for Medical Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/461420c80d3bdc156e5db7af13264a955a6a2010\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391204924\",\"name\":\"Zongjian Zhang\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"50528721\",\"name\":\"Qiuyun Wu\"},{\"authorId\":\"94294263\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/IJCNN.2019.8851832\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"title\":\"Visual Relationship Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a273df2ac9fc4e796c532feb76f5e676a0773b1c\",\"venue\":\"2019 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121789307\",\"name\":\"W. Guo\"},{\"authorId\":\"143932869\",\"name\":\"Jian Liang\"},{\"authorId\":\"144496860\",\"name\":\"Xiangwei Kong\"},{\"authorId\":\"3051419\",\"name\":\"Lingxiao Song\"},{\"authorId\":\"143712929\",\"name\":\"R. He\"}],\"doi\":\"10.1007/978-3-030-20873-8_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"19cac7075675992baefe308300be4e69a9080d2e\",\"title\":\"X-GACMN: An X-Shaped Generative Adversarial Cross-Modal Network with Hypersphere Embedding\",\"url\":\"https://www.semanticscholar.org/paper/19cac7075675992baefe308300be4e69a9080d2e\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"32781973\",\"name\":\"Lizi Liao\"},{\"authorId\":\"51487414\",\"name\":\"Yunshan Ma\"},{\"authorId\":\"7792071\",\"name\":\"X. He\"},{\"authorId\":\"48043335\",\"name\":\"R. Hong\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1145/3240508.3240605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8384387a3739280b15d38f39429aadb7c9bd620f\",\"title\":\"Knowledge-aware Multimodal Dialogue Systems\",\"url\":\"https://www.semanticscholar.org/paper/8384387a3739280b15d38f39429aadb7c9bd620f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40564040\",\"name\":\"J. Wu\"},{\"authorId\":\"37403439\",\"name\":\"H. Hu\"},{\"authorId\":\"40468514\",\"name\":\"Liang Yang\"}],\"doi\":\"10.1145/3336495\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"715fe60a8615d283c70d12db13857d8948baebca\",\"title\":\"Pseudo-3D Attention Transfer Network with Content-aware Strategy for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/715fe60a8615d283c70d12db13857d8948baebca\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"Changyou Chen\"},{\"authorId\":\"49469303\",\"name\":\"Xin-yuan Zhang\"},{\"authorId\":\"1423652601\",\"name\":\"Ke Bai\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a32535fb09e35a0f8e24e4d4e9bd33222a5258e1\",\"title\":\"Semantic Matching for Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/a32535fb09e35a0f8e24e4d4e9bd33222a5258e1\",\"venue\":\"EMNLP 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46447188\",\"name\":\"X. Zhang\"},{\"authorId\":\"2548483\",\"name\":\"Shengfeng He\"},{\"authorId\":\"1688375\",\"name\":\"Xinhang Song\"},{\"authorId\":\"1726262\",\"name\":\"R. Lau\"},{\"authorId\":\"24350293\",\"name\":\"J. Jiao\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"}],\"doi\":\"10.1016/J.NEUCOM.2018.02.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"title\":\"Image captioning via semantic element embedding\",\"url\":\"https://www.semanticscholar.org/paper/f7a305d80eae6a9b9fecbeeb7ade0b25d412219d\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"2007.11690\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2562211\",\"name\":\"Xiaoyu Shen\"},{\"authorId\":\"2561225\",\"name\":\"D. Klakow\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"54a42098b34c2602305b03fe07b7db82b789f5db\",\"title\":\"Integrating Image Captioning with Rule-based Entity Masking\",\"url\":\"https://www.semanticscholar.org/paper/54a42098b34c2602305b03fe07b7db82b789f5db\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.05608\",\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"},{\"authorId\":\"143904954\",\"name\":\"Jean Oh\"}],\"doi\":\"10.24963/ijcai.2019/496\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"18403a06a67b7060645e137a36ad15122ee2c2f9\",\"title\":\"Image Captioning with Compositional Neural Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/18403a06a67b7060645e137a36ad15122ee2c2f9\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9610143\",\"name\":\"Zhihao Fan\"},{\"authorId\":\"2712533\",\"name\":\"Zhongyu Wei\"},{\"authorId\":\"50695111\",\"name\":\"Siyuan Wang\"},{\"authorId\":\"1790227\",\"name\":\"X. Huang\"}],\"doi\":\"10.18653/v1/P19-1652\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"title\":\"Bridging by Word: Image Grounded Vocabulary Construction for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aaf5e3afd61d0df6c483ca32faf8e7a9198b1557\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47751104\",\"name\":\"Dali Yang\"},{\"authorId\":\"144204924\",\"name\":\"C. Yuan\"}],\"doi\":\"10.1109/ICIP.2018.8451740\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"758d1c17569eea2a698cac31b2d9d2a772c84322\",\"title\":\"Hierarchical Context Encoding for Events Captioning in Videos\",\"url\":\"https://www.semanticscholar.org/paper/758d1c17569eea2a698cac31b2d9d2a772c84322\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"2002.04355\",\"authors\":[{\"authorId\":\"1471439125\",\"name\":\"\\u015eeymanur Akt\\u0131\"},{\"authorId\":\"1471431070\",\"name\":\"G\\u00f6zde Ay\\u015fe Tataro\\u011flu\"},{\"authorId\":\"32365318\",\"name\":\"H. K. Ekenel\"}],\"doi\":\"10.1109/IPTA.2019.8936070\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"41a8954131f313d8526b2f8fc0506405ec519819\",\"title\":\"Vision-based Fight Detection from Surveillance Cameras\",\"url\":\"https://www.semanticscholar.org/paper/41a8954131f313d8526b2f8fc0506405ec519819\",\"venue\":\"2019 Ninth International Conference on Image Processing Theory, Tools and Applications (IPTA)\",\"year\":2019},{\"arxivId\":\"1712.08697\",\"authors\":[{\"authorId\":\"3545259\",\"name\":\"A. Trott\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"title\":\"Interpretable Counting for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/0605a012aeeee9bef773812a533c4f3cb7fa5a5f\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"152343380\",\"name\":\"Fei Su\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"}],\"doi\":\"10.1016/j.image.2018.06.002\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f20d5a6f10c269582bd00fd4733bb0066faee302\",\"title\":\"Modeling visual and word-conditional semantic attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f20d5a6f10c269582bd00fd4733bb0066faee302\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1689115\",\"name\":\"Tao Zhang\"},{\"authorId\":\"145960537\",\"name\":\"W. Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"144281199\",\"name\":\"Q. Hu\"}],\"doi\":\"10.1007/978-981-10-7299-4_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"title\":\"Relevance and Coherence Based Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/dbcffedbf6c50c3759203b51710d0c43a6d7d81e\",\"venue\":\"CCCV\",\"year\":2017},{\"arxivId\":\"1903.00839\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"50218594\",\"name\":\"Z. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"}],\"doi\":\"10.1109/CVPR.2019.00205\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"title\":\"Improving Referring Expression Grounding With Cross-Modal Attention-Guided Erasing\",\"url\":\"https://www.semanticscholar.org/paper/cd961afa9d75e1e7a657a9e11d6f6d3b968282a0\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143780023\",\"name\":\"Zhong Ji\"},{\"authorId\":\"103571514\",\"name\":\"Erlu He\"},{\"authorId\":\"49528408\",\"name\":\"H. Wang\"},{\"authorId\":\"1700859\",\"name\":\"Aiping Yang\"}],\"doi\":\"10.1016/J.PATREC.2019.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be0b96235fc070f1c2847ba3a858c558f60e243a\",\"title\":\"Image-attribute reciprocally guided attention network for pedestrian attribute recognition\",\"url\":\"https://www.semanticscholar.org/paper/be0b96235fc070f1c2847ba3a858c558f60e243a\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"8799308\",\"name\":\"U. Nadeem\"},{\"authorId\":\"14752125\",\"name\":\"Syed Afaq Ali Shah\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"1980026040\",\"name\":\"Wei Liu\"}],\"doi\":\"10.1007/978-3-030-49724-8_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"title\":\"Vision to Language: Methods, Metrics and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/8885ae1cbdac1d27443167689ed872dfe46c9e3f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1710.03370\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/CVPR.2018.00898\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a565aa547e2bdf278ad3d1fce1f1da8e70c38a1\",\"title\":\"iVQA: Inverse Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/8a565aa547e2bdf278ad3d1fce1f1da8e70c38a1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.11807\",\"authors\":[{\"authorId\":\"144910087\",\"name\":\"Zhan Shi\"},{\"authorId\":\"152482200\",\"name\":\"X. Zhou\"},{\"authorId\":\"1767521\",\"name\":\"Xipeng Qiu\"},{\"authorId\":\"150345740\",\"name\":\"Xiao-Dan Zhu\"}],\"doi\":\"10.18653/v1/2020.acl-main.664\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7e0f91e51ee372939c96714c7919dde6dc756849\",\"title\":\"Improving Image Captioning with Better Use of Captions\",\"url\":\"https://www.semanticscholar.org/paper/7e0f91e51ee372939c96714c7919dde6dc756849\",\"venue\":\"ACL\",\"year\":2020},{\"arxivId\":\"1805.00063\",\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"240ed539e96b9a304de54c904b375a9870496bf7\",\"title\":\"Improved Image Captioning with Adversarial Semantic Alignment\",\"url\":\"https://www.semanticscholar.org/paper/240ed539e96b9a304de54c904b375a9870496bf7\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"title\":\"Mind Your Language: Learning Visually Grounded Dialog in a Multi-Agent Setting\",\"url\":\"https://www.semanticscholar.org/paper/bbf56398dba5593a2aed1c3857fa011442b3aed6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7416107\",\"name\":\"Darong Liu\"},{\"authorId\":\"2954959\",\"name\":\"W. Jiang\"},{\"authorId\":\"1455981444\",\"name\":\"Lin Mu\"},{\"authorId\":\"1390898970\",\"name\":\"Si Wang\"}],\"doi\":\"10.1109/ACCESS.2020.2993874\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"866d5768b17ab3b1f86c786243c1ed09baffd3b7\",\"title\":\"Streamflow Prediction Using Deep Learning Neural Network: Case Study of Yangtze River\",\"url\":\"https://www.semanticscholar.org/paper/866d5768b17ab3b1f86c786243c1ed09baffd3b7\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"153028537\",\"name\":\"X. Wu\"},{\"authorId\":\"36263371\",\"name\":\"Shen Ge\"},{\"authorId\":\"93249636\",\"name\":\"W. Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1609/AAAI.V34I07.6824\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"title\":\"Federated Learning for Vision-and-Language Grounding Problems\",\"url\":\"https://www.semanticscholar.org/paper/d40c5e2d42d19dd7fd85d45201c048e3768c740d\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143710447\",\"name\":\"F. Gustafsson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"430cfa330b32633f6022ffdea0102bbd58a2fa49\",\"title\":\"Neural Image Captioning for Intelligent Vehicle-to-Passenger Communication\",\"url\":\"https://www.semanticscholar.org/paper/430cfa330b32633f6022ffdea0102bbd58a2fa49\",\"venue\":\"\",\"year\":2017},{\"arxivId\":\"1805.05062\",\"authors\":[{\"authorId\":\"46183659\",\"name\":\"Maha Elbayad\"},{\"authorId\":\"143823463\",\"name\":\"L. Besacier\"},{\"authorId\":\"34602236\",\"name\":\"Jakob Verbeek\"}],\"doi\":\"10.18653/v1/P18-1195\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"db3340742a56a4bbb9d7ee8dba1958fb132a3c0a\",\"title\":\"Token-level and sequence-level loss smoothing for RNN language models\",\"url\":\"https://www.semanticscholar.org/paper/db3340742a56a4bbb9d7ee8dba1958fb132a3c0a\",\"venue\":\"ACL\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66511580\",\"name\":\"Mirza Muhammad Ali Baig\"},{\"authorId\":\"67307335\",\"name\":\"Mian Ihtisham Shah\"},{\"authorId\":\"9223428\",\"name\":\"Muhammad Abdullah Wajahat\"},{\"authorId\":\"2384836\",\"name\":\"Nauman Zafar\"},{\"authorId\":\"1744665\",\"name\":\"Omar Arif\"}],\"doi\":\"10.1109/DICTA.2018.8615810\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"title\":\"Image Caption Generator with Novel Object Injection\",\"url\":\"https://www.semanticscholar.org/paper/d3aef1e8acf2b1760d7685d73f08d614f95ef75d\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[],\"doi\":\"10.18653/v1/d19-64\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"55c9ec9ee9bcedafc502684623dfa799c6ce35e7\",\"title\":\"Beyond Vision and LANguage: inTEgrating Real-world kNowledge (LANTERN)\",\"url\":\"https://www.semanticscholar.org/paper/55c9ec9ee9bcedafc502684623dfa799c6ce35e7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.16056\",\"authors\":[{\"authorId\":\"46843171\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"1922182598\",\"name\":\"Yan Song\"},{\"authorId\":\"2678812\",\"name\":\"Tsung-Hui Chang\"},{\"authorId\":\"2005096276\",\"name\":\"Xiang Wan\"}],\"doi\":\"10.18653/v1/2020.emnlp-main.112\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebfc629ef2ed733e1c77df5e27c94f05eb012cab\",\"title\":\"Generating Radiology Reports via Memory-driven Transformer\",\"url\":\"https://www.semanticscholar.org/paper/ebfc629ef2ed733e1c77df5e27c94f05eb012cab\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"145558284\",\"name\":\"Kai Lei\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"title\":\"Aligning Visual Regions and Textual Concepts: Learning Fine-Grained Image Representations for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4eb0b7ced6c022eef4c6fb2ed3dcdbdccfc056dc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2921001\",\"name\":\"Spandana Gella\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"title\":\"Visual context for verb sense disambiguation and multilingual representation learning\",\"url\":\"https://www.semanticscholar.org/paper/49b9c506dea12a3cbdc78ddef4447742c91b2754\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144751998\",\"name\":\"C. He\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1145/3292058\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"title\":\"Image Captioning With Visual-Semantic Double Attention\",\"url\":\"https://www.semanticscholar.org/paper/1b0ef7ccad215c682a784d1aec4988b675d779b9\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1806.02934\",\"authors\":[{\"authorId\":\"51043791\",\"name\":\"A. Kalyan\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d2237f995d280edb8a47e27886261709ea3f654a\",\"title\":\"Learn from Your Neighbor: Learning Multi-modal Mappings from Sparse Annotations\",\"url\":\"https://www.semanticscholar.org/paper/d2237f995d280edb8a47e27886261709ea3f654a\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s13735-020-00198-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"title\":\"MRECN: mixed representation enhanced (de)compositional network for caption generation from visual features, modeling as pseudo tensor product representation\",\"url\":\"https://www.semanticscholar.org/paper/8c85757cdd7de5f99ab1717a6355a09bb717013c\",\"venue\":\"Int. J. Multim. Inf. Retr.\",\"year\":2020},{\"arxivId\":\"2004.14231\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"3157379\",\"name\":\"Wentong Liao\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"143672748\",\"name\":\"M. Yang\"},{\"authorId\":\"1779035\",\"name\":\"B. Rosenhahn\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"title\":\"Image Captioning through Image Transformer\",\"url\":\"https://www.semanticscholar.org/paper/657cce51f80e272373ab4fc0dabf5dc8b30c0070\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92538707\",\"name\":\"Qi Zheng\"},{\"authorId\":\"1409848027\",\"name\":\"Chaoyue Wang\"},{\"authorId\":\"143719918\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR42600.2020.01311\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"title\":\"Syntax-Aware Action Targeting for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/59cca2242fb20a6070369b5c1f172e5ee1d71785\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yiqi Yan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25102a9c3f6aab9d2b1c990f8a917872dabcaae9\",\"title\":\"Attention-based skin lesion recognition\",\"url\":\"https://www.semanticscholar.org/paper/25102a9c3f6aab9d2b1c990f8a917872dabcaae9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2881052\",\"name\":\"Amin Javari\"},{\"authorId\":\"51002202\",\"name\":\"Z. He\"},{\"authorId\":\"12318198\",\"name\":\"Zi-jie Huang\"},{\"authorId\":\"144175955\",\"name\":\"Jeetu Raj\"},{\"authorId\":\"143922493\",\"name\":\"K. Chang\"}],\"doi\":\"10.1145/3366423.3380182\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c675c2056d1e759f5dfca394c77d228d2d4478c\",\"title\":\"Weakly Supervised Attention for Hashtag Recommendation using Graph Data\",\"url\":\"https://www.semanticscholar.org/paper/8c675c2056d1e759f5dfca394c77d228d2d4478c\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1911.13181\",\"authors\":[{\"authorId\":\"10136905\",\"name\":\"Cheonbok Park\"},{\"authorId\":\"46244821\",\"name\":\"C. Lee\"},{\"authorId\":\"41019737\",\"name\":\"Hyojin Bahng\"},{\"authorId\":\"1999198856\",\"name\":\"Yunwon Tae\"},{\"authorId\":\"102503791\",\"name\":\"S. Jin\"},{\"authorId\":\"144733648\",\"name\":\"Keunjoo Kim\"},{\"authorId\":\"39324835\",\"name\":\"Sungahn Ko\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":\"10.1145/3340531.3411940\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b6cbb0cb3f6af078506b0295cff42e48895d3def\",\"title\":\"ST-GRAT: A Novel Spatio-temporal Graph Attention Networks for Accurately Forecasting Dynamically Changing Road Speed\",\"url\":\"https://www.semanticscholar.org/paper/b6cbb0cb3f6af078506b0295cff42e48895d3def\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yongzhuang Wang\"},{\"authorId\":\"49746133\",\"name\":\"Yangmei Shen\"},{\"authorId\":\"144045763\",\"name\":\"Hongkai Xiong\"},{\"authorId\":\"8131625\",\"name\":\"W. Lin\"}],\"doi\":\"10.1109/ICIP.2019.8803418\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"93368542c1774e2cbd12187a4ccc2c882c791d94\",\"title\":\"Adaptive Hard Example Mining for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93368542c1774e2cbd12187a4ccc2c882c791d94\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1492164677\",\"name\":\"Min Yang\"},{\"authorId\":\"2948588\",\"name\":\"Junhao Liu\"},{\"authorId\":\"143822675\",\"name\":\"Ying Shen\"},{\"authorId\":\"47122664\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"40265331\",\"name\":\"X. Chen\"},{\"authorId\":\"31060469\",\"name\":\"Qingyao Wu\"},{\"authorId\":\"48161719\",\"name\":\"C. Li\"}],\"doi\":\"10.1109/TIP.2020.3028651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f6a09cd467a2752e60a2766160a00c658667043e\",\"title\":\"An Ensemble of Generation- and Retrieval-Based Image Captioning With Dual Generator Generative Adversarial Network\",\"url\":\"https://www.semanticscholar.org/paper/f6a09cd467a2752e60a2766160a00c658667043e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8004535\",\"name\":\"Chaojun Han\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"46457827\",\"name\":\"Li Liu\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3240508.3240611\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f51d9d34635ad9f6310d767869710e78fc4174bf\",\"title\":\"Visual Spatial Attention Network for Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/f51d9d34635ad9f6310d767869710e78fc4174bf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1810.11939\",\"authors\":[{\"authorId\":\"11692951\",\"name\":\"Yu-Han Shen\"},{\"authorId\":\"67267602\",\"name\":\"K. He\"},{\"authorId\":\"1806930\",\"name\":\"W. Zhang\"}],\"doi\":\"10.21437/interspeech.2019-2045\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"411af2ef58b84a14805f3e99e505170695647a6e\",\"title\":\"Learning How to Listen: A Temporal-Frequential Attention Model for Sound Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/411af2ef58b84a14805f3e99e505170695647a6e\",\"venue\":\"INTERSPEECH\",\"year\":2019},{\"arxivId\":\"1812.02872\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"2149345\",\"name\":\"Chenxiao Guan\"},{\"authorId\":\"48616329\",\"name\":\"J. Goodman\"},{\"authorId\":\"50583301\",\"name\":\"Marc Moore\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5328a7024f820fafdab4165777807c2ecb855fe4\",\"title\":\"An Attempt towards Interpretable Audio-Visual Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/5328a7024f820fafdab4165777807c2ecb855fe4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145350881\",\"name\":\"Y. Tian\"},{\"authorId\":\"47120369\",\"name\":\"X. Wang\"},{\"authorId\":\"13013695\",\"name\":\"Jiachen Wu\"},{\"authorId\":\"49908315\",\"name\":\"Ruili Wang\"},{\"authorId\":\"7324474\",\"name\":\"Bailin Yang\"}],\"doi\":\"10.1613/jair.1.11338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfeda236987b04250a218b688e32b6b35c617ba4\",\"title\":\"Multi-scale Hierarchical Residual Network for Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/cfeda236987b04250a218b688e32b6b35c617ba4\",\"venue\":\"J. Artif. Intell. Res.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9073332\",\"name\":\"J. Li\"},{\"authorId\":\"1923156\",\"name\":\"P. Yao\"},{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"49039585\",\"name\":\"Wei-Cun Zhang\"}],\"doi\":\"10.3390/APP9163260\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"title\":\"Boosted Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/47716ca06a3ad4226a6d8706b6f02793b9892fe4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143946808\",\"name\":\"Bin Zhao\"},{\"authorId\":\"50080046\",\"name\":\"X. Li\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TIP.2019.2916757\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"title\":\"CAM-RNN: Co-Attention Model Based RNN for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/acc2cfe35343195a4f3d0df5d7841d47708208fb\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2692833\",\"name\":\"Wenbin Che\"},{\"authorId\":\"152213403\",\"name\":\"Xiaopeng Fan\"},{\"authorId\":\"145419122\",\"name\":\"R. Xiong\"},{\"authorId\":\"47783359\",\"name\":\"D. Zhao\"}],\"doi\":\"10.1109/TMM.2019.2954750\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4021baab5b3cda4347bab93a0426b0ab122764a7\",\"title\":\"Visual Relationship Embedding Network for Image Paragraph Generation\",\"url\":\"https://www.semanticscholar.org/paper/4021baab5b3cda4347bab93a0426b0ab122764a7\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"71063171\",\"name\":\"Long Chen\"},{\"authorId\":\"1390845848\",\"name\":\"Dezheng Zhang\"},{\"authorId\":\"145924255\",\"name\":\"P. Li\"},{\"authorId\":\"1876490291\",\"name\":\"Peng Lv\"}],\"doi\":\"10.1155/2020/6430627\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"42b88b58353d173bc318e01029996f0bb3989ddd\",\"title\":\"Change Detection of Remote Sensing Images Based on Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/42b88b58353d173bc318e01029996f0bb3989ddd\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"1709.03376\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"title\":\"Stack-Captioning: Coarse-to-Fine Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f14e73dade94b8b1f276dcd91257aa7de5f19d7\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":\"10.1145/3357384.3358000\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"title\":\"Adapting Visual Question Answering Models for Enhancing Multimodal Community Q&A Platforms\",\"url\":\"https://www.semanticscholar.org/paper/6fb13d374dc32a55ab454fe9b8dd05527b553af9\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s42979-020-00238-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3f732495721356944027051bb14100436a5dbdf5\",\"title\":\"AACR: Feature Fusion Effects of Algebraic Amalgamation Composed Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/3f732495721356944027051bb14100436a5dbdf5\",\"venue\":\"SN Comput. Sci.\",\"year\":2020},{\"arxivId\":\"1908.04919\",\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"58a77455b1c38afe1eab4bec664bd866eba1573d\",\"title\":\"Towards Diverse and Accurate Image Captions via Reinforcing Determinantal Point Process\",\"url\":\"https://www.semanticscholar.org/paper/58a77455b1c38afe1eab4bec664bd866eba1573d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1810.09630\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"345a222fef6f5c1415056319ae7e87a369940d3f\",\"title\":\"A Neural Compositional Paradigm for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/345a222fef6f5c1415056319ae7e87a369940d3f\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4421716\",\"name\":\"F. Wang\"},{\"authorId\":\"21776508\",\"name\":\"X. Gong\"},{\"authorId\":\"1754542\",\"name\":\"Linpeng Huang\"}],\"doi\":\"10.1109/ICPR.2018.8545355\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"title\":\"Time-Dependent Pre-attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1a1a77e953736ce25949395d5856fc1762bbf8c6\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143915557\",\"name\":\"K. Ma\"},{\"authorId\":\"145310587\",\"name\":\"K. Wu\"},{\"authorId\":\"145880684\",\"name\":\"Hao Cheng\"},{\"authorId\":\"5494837\",\"name\":\"C. Gu\"},{\"authorId\":\"40977498\",\"name\":\"Rui Xu\"},{\"authorId\":\"152936756\",\"name\":\"X. Guan\"}],\"doi\":\"10.1007/978-3-030-04224-0_24\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8642efc51d262547994c4c8600cb5d021de4952b\",\"title\":\"A Pathology Image Diagnosis Network with Visual Interpretability and Structured Diagnostic Report\",\"url\":\"https://www.semanticscholar.org/paper/8642efc51d262547994c4c8600cb5d021de4952b\",\"venue\":\"ICONIP\",\"year\":2018},{\"arxivId\":\"1811.02234\",\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"},{\"authorId\":\"1924996\",\"name\":\"S. Herbin\"},{\"authorId\":\"82117876\",\"name\":\"F. Jurie\"}],\"doi\":\"10.1007/978-3-030-20890-5_44\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"title\":\"Semantic bottleneck for computer vision tasks\",\"url\":\"https://www.semanticscholar.org/paper/ca4eb45862a7153e6264bc96a400508d94c9d7ef\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2012.01295\",\"authors\":[{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"2268783\",\"name\":\"Chenghua Lin\"},{\"authorId\":\"1510708415\",\"name\":\"Mian Zhou\"},{\"authorId\":\"49892954\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"13036580\",\"name\":\"Haoyu Lv\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"91c21f11bdcf89ae18b7fc805c114fa8f27f72ef\",\"title\":\"Generating Descriptions for Sequential Images with Local-Object Attention and Global Semantic Context Modelling\",\"url\":\"https://www.semanticscholar.org/paper/91c21f11bdcf89ae18b7fc805c114fa8f27f72ef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1902.09091\",\"authors\":[{\"authorId\":\"7324641\",\"name\":\"B. Yang\"},{\"authorId\":\"40975594\",\"name\":\"Tom Michael Mitchell\"}],\"doi\":\"10.18653/v1/P17-1132\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7bf34d65eec494a0b758f4ab3f58db8a89815e1f\",\"title\":\"Leveraging Knowledge Bases in LSTMs for Improving Machine Reading\",\"url\":\"https://www.semanticscholar.org/paper/7bf34d65eec494a0b758f4ab3f58db8a89815e1f\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"2011.00966\",\"authors\":[{\"authorId\":\"32370882\",\"name\":\"Shweta Mahajan\"},{\"authorId\":\"49863405\",\"name\":\"S. Roth\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7d805e35f17dab7382748130a2ca1bda629cdceb\",\"title\":\"Diverse Image Captioning with Context-Object Split Latent Spaces\",\"url\":\"https://www.semanticscholar.org/paper/7d805e35f17dab7382748130a2ca1bda629cdceb\",\"venue\":\"NeurIPS\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158899\",\"name\":\"Mariam Bouchakwa\"},{\"authorId\":\"2135034\",\"name\":\"Yassine Ayadi\"},{\"authorId\":\"1784204\",\"name\":\"I. Amous\"}],\"doi\":\"10.1007/s11042-020-08862-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"title\":\"A review on visual content-based and users\\u2019 tags-based image annotation: methods and techniques\",\"url\":\"https://www.semanticscholar.org/paper/445df9ebc8c43c39faeaa58518383f980fdd0da9\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145840350\",\"name\":\"P. Anderson\"}],\"doi\":\"10.25911/5D00D4EC451CC\",\"intent\":[\"background\",\"result\"],\"isInfluential\":true,\"paperId\":\"c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"title\":\"Vision and Language Learning: From Image Captioning and Visual Question Answering towards Embodied Agents\",\"url\":\"https://www.semanticscholar.org/paper/c2ce1912727a3e8c88b4af65c9ca088b3c8eb1a0\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"2600667\",\"name\":\"W. Diao\"},{\"authorId\":\"2987316\",\"name\":\"W. Zhang\"},{\"authorId\":\"1972876\",\"name\":\"Menglong Yan\"},{\"authorId\":\"97941663\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.3390/rs11202349\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4c9a104c7b9a76ba03b8f8cf14f7b6b9066d62f0\",\"title\":\"LAM: Remote Sensing Image Captioning with Label-Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/4c9a104c7b9a76ba03b8f8cf14f7b6b9066d62f0\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50621243\",\"name\":\"Qingzhong Wang\"},{\"authorId\":\"2751871\",\"name\":\"J. Wan\"},{\"authorId\":\"3651407\",\"name\":\"Antoni B. Chan\"}],\"doi\":\"10.1109/tpami.2020.3013834\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"title\":\"On Diversity in Image Captioning: Metrics and Methods.\",\"url\":\"https://www.semanticscholar.org/paper/ba341f992ceb10d9a7f032ac6027f18ef5e5f895\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39124346\",\"name\":\"J. Zhang\"},{\"authorId\":\"1783406\",\"name\":\"Yiqun Liu\"},{\"authorId\":\"8093158\",\"name\":\"S. Ma\"},{\"authorId\":\"144876834\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3269206.3271673\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b92f5734ffd7d9ff1dd0f3639e92ed18fda7824\",\"title\":\"Relevance Estimation with Multiple Information Sources on Search Engine Result Pages\",\"url\":\"https://www.semanticscholar.org/paper/0b92f5734ffd7d9ff1dd0f3639e92ed18fda7824\",\"venue\":\"CIKM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46314360\",\"name\":\"Weixuan Wang\"},{\"authorId\":\"49865085\",\"name\":\"Zhihong Chen\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"}],\"doi\":\"10.1007/978-3-030-20876-9_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"title\":\"Multivariate Attention Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bf3f2f2c1b88eb7b031d593c9d83641baea364e2\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34815079\",\"name\":\"Y. Atzmon\"},{\"authorId\":\"1750652\",\"name\":\"Jonathan Berant\"},{\"authorId\":\"1786843\",\"name\":\"A. Globerson\"},{\"authorId\":\"2626422\",\"name\":\"V. Kazemi\"},{\"authorId\":\"1732280\",\"name\":\"Gal Chechik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"title\":\"Generalization to new compositions of known entities in image understanding\",\"url\":\"https://www.semanticscholar.org/paper/c4934d9f9c41dbc46f4173aad2775432fe02e0e6\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46407634\",\"name\":\"Jind\\u0159ich Helcl\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5449aa3ca855cee1a80fe5f6bc97f7c0742e3e99\",\"title\":\"Improving Neural Machine Translation with External Information Thesis Proposal\",\"url\":\"https://www.semanticscholar.org/paper/5449aa3ca855cee1a80fe5f6bc97f7c0742e3e99\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"af258688503b48c1028680c67eb12cb351e9830a\",\"title\":\"Visual grounding of spatial relations in recurrent neural language models\",\"url\":\"https://www.semanticscholar.org/paper/af258688503b48c1028680c67eb12cb351e9830a\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5486222\",\"name\":\"Javedul Ferdous\"},{\"authorId\":\"144894381\",\"name\":\"A. S. Saif\"},{\"authorId\":\"152356279\",\"name\":\"D. Nandi\"},{\"authorId\":\"144593525\",\"name\":\"Mashiour Rahman\"}],\"doi\":\"10.5120/ijca2018918048\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ebbb0729c7c6459993296a307ca11d9f9ac80e94\",\"title\":\"An Efficient Hybrid Architecture for Visual Behavior Recognition using Convolutional Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/ebbb0729c7c6459993296a307ca11d9f9ac80e94\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.05548\",\"authors\":[{\"authorId\":\"49774254\",\"name\":\"Zilong Zheng\"},{\"authorId\":\"2693875\",\"name\":\"Wenguan Wang\"},{\"authorId\":\"3390244\",\"name\":\"Siyuan Qi\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/CVPR.2019.00683\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"title\":\"Reasoning Visual Dialogs With Structural and Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"39320489\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7b10801e1ef598ac50ee5317d2a3a482f000826\",\"title\":\"Improved Adversarial Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d7b10801e1ef598ac50ee5317d2a3a482f000826\",\"venue\":\"DGS@ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"144066903\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/TMM.2018.2888822\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"title\":\"High-Quality Image Captioning With Fine-Grained and Semantic-Guided Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2bc7959cf6bf0ae64f1a83f5fce1ac8cb2256ed3\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3482320\",\"name\":\"Hengcan Shi\"},{\"authorId\":\"1741866\",\"name\":\"H. Li\"},{\"authorId\":\"1706784\",\"name\":\"Fanman Meng\"},{\"authorId\":\"1702864\",\"name\":\"Q. Wu\"}],\"doi\":\"10.1007/978-3-030-01231-1_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"title\":\"Key-Word-Aware Network for Referring Expression Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/59e5a8e47e9408013f84cdf80b4ac49e9d82fa84\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2017491\",\"name\":\"J. Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"20570336\",\"name\":\"Z. Yang\"},{\"authorId\":\"104002286\",\"name\":\"Qing Wang\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/ICME.2019.00227\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4e3b2d5e0dfffc088e75da297a77f63820cd3a31\",\"title\":\"Concrete Image Captioning by Integrating Content Sensitive and Global Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/4e3b2d5e0dfffc088e75da297a77f63820cd3a31\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51058812\",\"name\":\"X. Liu\"},{\"authorId\":\"98355791\",\"name\":\"W. Liu\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"}],\"doi\":\"10.1109/ICEIEC.2019.8784585\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8ca688fbaaf93771d59ab59a92b62ecffd22013d\",\"title\":\"Image Captioning with Emotional Information via Multiple Model\",\"url\":\"https://www.semanticscholar.org/paper/8ca688fbaaf93771d59ab59a92b62ecffd22013d\",\"venue\":\"2019 IEEE 9th International Conference on Electronics Information and Emergency Communication (ICEIEC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1400258083\",\"name\":\"Chunpu Xu\"},{\"authorId\":\"47748857\",\"name\":\"Wei Zhao\"},{\"authorId\":\"31991405\",\"name\":\"Min Yang\"},{\"authorId\":\"2441161\",\"name\":\"Xiang Ao\"},{\"authorId\":\"1405918472\",\"name\":\"Wangrong Cheng\"},{\"authorId\":\"1936983\",\"name\":\"J. Tian\"}],\"doi\":\"10.1145/3357384.3358105\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e81c97c18cb4f4922e4442664350350536a71a13\",\"title\":\"A Unified Generation-Retrieval Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e81c97c18cb4f4922e4442664350350536a71a13\",\"venue\":\"CIKM\",\"year\":2019},{\"arxivId\":\"1911.03738\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"Marc Tanti\"},{\"authorId\":\"145464131\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"Kenneth P. Camilleri\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"title\":\"On Architectures for Including Visual Information in Neural Language Models for Image Description\",\"url\":\"https://www.semanticscholar.org/paper/a55f5de768a455ab01fbe0432962f2f6f1a0a7db\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"102735962\",\"name\":\"Hongyu Liu\"},{\"authorId\":\"49892954\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"98177768\",\"name\":\"Ya Li\"},{\"authorId\":\"90477013\",\"name\":\"Chuxin Zhang\"},{\"authorId\":\"104266220\",\"name\":\"Siyu Yi\"},{\"authorId\":null,\"name\":\"Tao Yuan\"}],\"doi\":\"10.1007/978-3-030-39431-8_34\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4e5d6e4575aeeabd8141831bc5cecc4dca4fc620\",\"title\":\"The Design Patent Images Classification Based on Image Caption Model\",\"url\":\"https://www.semanticscholar.org/paper/4e5d6e4575aeeabd8141831bc5cecc4dca4fc620\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1797144\",\"name\":\"G. Friedland\"},{\"authorId\":\"1772549\",\"name\":\"D. Borth\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"df9a08016fa553a169d893ce2d3fca375bab4781\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df9a08016fa553a169d893ce2d3fca375bab4781\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1909.02072\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"50218411\",\"name\":\"Z. Wang\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/ICCV.2019.00921\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"title\":\"Large-Scale Tag-Based Font Retrieval With Generative Feature Learning\",\"url\":\"https://www.semanticscholar.org/paper/22d07f5eb536877aafbad9d790b56c51bb1c4a42\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1810.11536\",\"authors\":[{\"authorId\":\"145293956\",\"name\":\"Zhihao Zhu\"},{\"authorId\":\"14598300\",\"name\":\"Zhan Xue\"},{\"authorId\":\"33762094\",\"name\":\"Zejian Yuan\"}],\"doi\":\"10.1007/978-3-030-20876-9_12\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"695420559bd694f0fe084b64556e8241c3d02868\",\"title\":\"Automatic Graphics Program Generation using Attention-Based Hierarchical Decoder\",\"url\":\"https://www.semanticscholar.org/paper/695420559bd694f0fe084b64556e8241c3d02868\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144792753\",\"name\":\"Y. Qin\"},{\"authorId\":\"151046769\",\"name\":\"Jiajun Du\"},{\"authorId\":\"48379418\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00856\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0c0ac3bb66203c32be81193fabeee44c3585582\",\"title\":\"Look Back and Predict Forward in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e0c0ac3bb66203c32be81193fabeee44c3585582\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49640335\",\"name\":\"Jinfei Zhou\"},{\"authorId\":\"145350969\",\"name\":\"Yaping Zhu\"},{\"authorId\":\"49349128\",\"name\":\"H. Pan\"}],\"doi\":\"10.1145/3317640.3317660\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c002b14a8bd3879858f2543102d5b8797297c801\",\"title\":\"Image caption based on Visual Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/c002b14a8bd3879858f2543102d5b8797297c801\",\"venue\":\"IVSP 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Jing Wang\"},{\"authorId\":\"49640379\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1109/DICTA.2018.8615876\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b59f9331ad08210260b1b156e4dadc2a42b38987\",\"title\":\"Band Weighting Network for Hyperspectral Image Classification\",\"url\":\"https://www.semanticscholar.org/paper/b59f9331ad08210260b1b156e4dadc2a42b38987\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Shuang Liu\"},{\"authorId\":\"144769215\",\"name\":\"L. Bai\"},{\"authorId\":\"1687503\",\"name\":\"Yanming Guo\"},{\"authorId\":\"3348635\",\"name\":\"Haoran Wang\"}],\"doi\":\"10.1109/BigMM.2018.8499098\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"eaf2eaf8ffd056799ae6bbe44f5939eb562fd8d9\",\"title\":\"Reference Based on Adaptive Attention Mechanism for Image Captioning*\",\"url\":\"https://www.semanticscholar.org/paper/eaf2eaf8ffd056799ae6bbe44f5939eb562fd8d9\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2786437\",\"name\":\"Linghui Li\"},{\"authorId\":\"144044848\",\"name\":\"Sheng Tang\"},{\"authorId\":\"2031845\",\"name\":\"Junbo Guo\"},{\"authorId\":null,\"name\":\"Rui Wang\"},{\"authorId\":\"144241178\",\"name\":\"B. Lyu\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/BigMM.2018.8499066\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"title\":\"Image Captioning Based on Adaptive Balancing Loss\",\"url\":\"https://www.semanticscholar.org/paper/9a830ef990527adef14fed8d05ef5df5b9c87d4c\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":\"1708.07281\",\"authors\":[{\"authorId\":\"2476328\",\"name\":\"Zizhao Zhang\"},{\"authorId\":\"2082604\",\"name\":\"F. Xing\"},{\"authorId\":\"143729223\",\"name\":\"H. Su\"},{\"authorId\":\"2766473\",\"name\":\"Xiaoshuang Shi\"},{\"authorId\":\"144890162\",\"name\":\"L. Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4a57f02af01ea260feaa6b2b4ede6c5e8e5ae78\",\"title\":\"Recent Advances in the Applications of Convolutional Neural Networks to Medical Image Contour Detection\",\"url\":\"https://www.semanticscholar.org/paper/b4a57f02af01ea260feaa6b2b4ede6c5e8e5ae78\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423621769\",\"name\":\"B. T. Nguyen\"},{\"authorId\":\"50259366\",\"name\":\"O. Prakash\"},{\"authorId\":\"1580282435\",\"name\":\"A. H. Vo\"}],\"doi\":\"10.1007/978-3-030-62324-1_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"21a742ee840b4a063deee66028409f9cf7f3829d\",\"title\":\"Attention Mechanism for Fashion Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/21a742ee840b4a063deee66028409f9cf7f3829d\",\"venue\":\"\",\"year\":2021},{\"arxivId\":\"2007.11731\",\"authors\":[{\"authorId\":\"1828787912\",\"name\":\"Yiwu Zhong\"},{\"authorId\":\"39060743\",\"name\":\"Liwei Wang\"},{\"authorId\":\"101777533\",\"name\":\"J. Chen\"},{\"authorId\":null,\"name\":\"Dong Yu\"},{\"authorId\":\"47002659\",\"name\":\"Yanchao Li\"}],\"doi\":\"10.1007/978-3-030-58568-6_13\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"title\":\"Comprehensive Image Captioning via Scene Graph Decomposition\",\"url\":\"https://www.semanticscholar.org/paper/66ed8795eb6de5d2a6b204baac9378d6d28136cc\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1939569\",\"name\":\"Feiran Huang\"},{\"authorId\":\"1863856\",\"name\":\"Kaimin Wei\"},{\"authorId\":\"1729395\",\"name\":\"J. Weng\"},{\"authorId\":\"1707275\",\"name\":\"Zhoujun Li\"}],\"doi\":\"10.1145/3388861\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1ddd604d33793517b171a28ccbd1e3ed40d543cc\",\"title\":\"Attention-Based Modality-Gated Networks for Image-Text Sentiment Analysis\",\"url\":\"https://www.semanticscholar.org/paper/1ddd604d33793517b171a28ccbd1e3ed40d543cc\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46336997\",\"name\":\"J. Su\"},{\"authorId\":\"2268783\",\"name\":\"Chenghua Lin\"},{\"authorId\":\"48993818\",\"name\":\"M. Zhou\"},{\"authorId\":\"2457312\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"13036580\",\"name\":\"Haoyu Lv\"}],\"doi\":\"10.18653/v1/W18-6702\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"fdb4e6aded4580d9109759240d51cb413e332102\",\"title\":\"Generating Description for Sequential Images with Local-Object Attention Conditioned on Global Semantic Context\",\"url\":\"https://www.semanticscholar.org/paper/fdb4e6aded4580d9109759240d51cb413e332102\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406233003\",\"name\":\"Yangyang Ye\"},{\"authorId\":\"2643087\",\"name\":\"Houjin Chen\"},{\"authorId\":null,\"name\":\"Chi Zhang\"},{\"authorId\":\"3023978\",\"name\":\"Xiaoli Hao\"},{\"authorId\":\"1711340\",\"name\":\"Zhaoxiang Zhang\"}],\"doi\":\"10.1016/j.neucom.2019.09.086\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"86c613cff08dccc6c69eb204b27390f1b7bf3797\",\"title\":\"SARPNET: Shape attention regional proposal network for liDAR-based 3D object detection\",\"url\":\"https://www.semanticscholar.org/paper/86c613cff08dccc6c69eb204b27390f1b7bf3797\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":\"10.1007/978-3-030-11018-5_14\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ae89d6027c6b45c7b2b95ebc01a1054966da133\",\"title\":\"Knowing When to Look for What and Where: Evaluating Generation of Spatial Descriptions with Adaptive Attention\",\"url\":\"https://www.semanticscholar.org/paper/8ae89d6027c6b45c7b2b95ebc01a1054966da133\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3272502\",\"name\":\"S. Sreela\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.1109/TENCONSPRING.2017.8070036\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"be370bdf8f02ee6bc6b322c78b5a8580087d12f9\",\"title\":\"Modified densely connected convolutional network for content generation in automatic image description generation system\",\"url\":\"https://www.semanticscholar.org/paper/be370bdf8f02ee6bc6b322c78b5a8580087d12f9\",\"venue\":\"2017 IEEE Region 10 Symposium (TENSYMP)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7816749\",\"name\":\"Santiago Pascual de la Puente\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb6d51a68cc8bd53a515d8f23893e9fd76005fbc\",\"title\":\"Efficient, end-to-end and self-supervised methods for speech processing and generation\",\"url\":\"https://www.semanticscholar.org/paper/fb6d51a68cc8bd53a515d8f23893e9fd76005fbc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47666606\",\"name\":\"Hui Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"34811036\",\"name\":\"Yuchen Guo\"},{\"authorId\":\"10795229\",\"name\":\"Caifeng Shan\"},{\"authorId\":\"144762952\",\"name\":\"J. Han\"}],\"doi\":\"10.1007/s12559-019-09656-w\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"title\":\"Image Captioning with Memorized Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/e99a3163815a0c40705ffd6347c6cdbf19fa5237\",\"venue\":\"Cognitive Computation\",\"year\":2019},{\"arxivId\":\"2002.08510\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1609/AAAI.V34I07.6631\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f1e3f995168b008637a049cbef6a5266986cb338\",\"title\":\"Expressing Objects just like Words: Recurrent Visual Embedding for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/f1e3f995168b008637a049cbef6a5266986cb338\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2010.03790\",\"authors\":[{\"authorId\":\"3377711\",\"name\":\"K. Murugesan\"},{\"authorId\":\"32946276\",\"name\":\"Mattia Atzeni\"},{\"authorId\":\"2223082\",\"name\":\"Pavan Kapanipathi\"},{\"authorId\":\"1748835883\",\"name\":\"Pushkar Shukla\"},{\"authorId\":\"47011667\",\"name\":\"S. Kumaravel\"},{\"authorId\":\"1699108\",\"name\":\"G. Tesauro\"},{\"authorId\":\"2940762\",\"name\":\"Kartik Talamadupula\"},{\"authorId\":\"2790926\",\"name\":\"Mrinmaya Sachan\"},{\"authorId\":\"153665855\",\"name\":\"M. Campbell\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c117a59fdad8ebf857d01082612093e9e6aa676e\",\"title\":\"Text-based RL Agents with Commonsense Knowledge: New Challenges, Environments and Baselines\",\"url\":\"https://www.semanticscholar.org/paper/c117a59fdad8ebf857d01082612093e9e6aa676e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.08608\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/ICCV.2019.00435\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"45f9856d418527d23dc7c89197627fa1f3b215f9\",\"title\":\"Learning to Collocate Neural Modules for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9856d418527d23dc7c89197627fa1f3b215f9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1576489018\",\"name\":\"Bang Hu Yin\"},{\"authorId\":\"98228895\",\"name\":\"Xiu Li\"}],\"doi\":\"10.1088/1757-899x/715/1/012082\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecfc3c33bbd319e7bf18f60ea2c66911d87044ca\",\"title\":\"Cross-modal retrieval by an end to end way\",\"url\":\"https://www.semanticscholar.org/paper/ecfc3c33bbd319e7bf18f60ea2c66911d87044ca\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1909.04743\",\"authors\":[{\"authorId\":\"15727192\",\"name\":\"Tete Xiao\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"},{\"authorId\":\"1891570\",\"name\":\"Dan Gutfreund\"},{\"authorId\":\"95743023\",\"name\":\"Mathew Monfort\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"}],\"doi\":\"10.1109/ICCV.2019.00402\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"title\":\"Reasoning About Human-Object Interactions Through Dual Attention Networks\",\"url\":\"https://www.semanticscholar.org/paper/98b6d3f69e37e6bf33ea270ac28773d86e778c34\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528566\",\"name\":\"Hui Wang\"},{\"authorId\":\"145863022\",\"name\":\"X. Zhang\"}],\"doi\":\"10.20944/PREPRINTS201804.0313.V1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"title\":\"Cross-Modal Multistep Fusion Network With Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2329335263b2911a05c36c8c3747d9ee96eb6fee\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3368782\",\"name\":\"Yuetan Lin\"},{\"authorId\":\"7372283\",\"name\":\"Zhangyang Pang\"},{\"authorId\":\"144199812\",\"name\":\"D. Wang\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.24963/ijcai.2018/586\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"title\":\"Feature Enhancement in Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f15ad07b9f6686bc72c45bf781c91f8eeb035899\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":\"1803.08314\",\"authors\":[{\"authorId\":\"46522599\",\"name\":\"Xihui Liu\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"},{\"authorId\":\"143982372\",\"name\":\"Dapeng Chen\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1007/978-3-030-01267-0_21\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"caab1c1d53718315f54bc4df42eb9a727fa18483\",\"title\":\"Show, Tell and Discriminate: Image Captioning by Self-retrieval with Partially Labeled Data\",\"url\":\"https://www.semanticscholar.org/paper/caab1c1d53718315f54bc4df42eb9a727fa18483\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50974488\",\"name\":\"Mingrui Lao\"},{\"authorId\":\"49813983\",\"name\":\"Yanming Guo\"},{\"authorId\":\"49528152\",\"name\":\"H. Wang\"},{\"authorId\":\"49468999\",\"name\":\"Xin Zhang\"}],\"doi\":\"10.1109/ACCESS.2018.2873570\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"title\":\"Multimodal Local Perception Bilinear Pooling for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/161876ad06d5a349ccde4b4db3d3759ef43268a8\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1906.00717\",\"authors\":[{\"authorId\":\"2903539\",\"name\":\"Junlong Gao\"},{\"authorId\":\"2802555\",\"name\":\"Xi Meng\"},{\"authorId\":null,\"name\":\"Shiqi Wang\"},{\"authorId\":\"50078954\",\"name\":\"Xia Li\"},{\"authorId\":\"1755176\",\"name\":\"Shanshe Wang\"},{\"authorId\":\"51130683\",\"name\":\"S. Ma\"},{\"authorId\":\"48385803\",\"name\":\"W. Gao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"36a3cfa6ed48988e23cf68b3abcbe097b29e594a\",\"title\":\"Masked Non-Autoregressive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/36a3cfa6ed48988e23cf68b3abcbe097b29e594a\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390533012\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"1752041\",\"name\":\"C. Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"145254492\",\"name\":\"Z. Wen\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"title\":\"Nested-Wasserstein Distance for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/0ed94607d6f1506f0cfb1bf0896a41300db52a1a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Marharyta Dekret\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ea607623a47bd5bc2589c223dfcbe98feb008a46\",\"title\":\"SpiralNet: Two-stage recursive-CNN for microscopy image segmentation\",\"url\":\"https://www.semanticscholar.org/paper/ea607623a47bd5bc2589c223dfcbe98feb008a46\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47740650\",\"name\":\"Jian Jhen Chen\"},{\"authorId\":\"145496509\",\"name\":\"Jie Shao\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"},{\"authorId\":\"2838253\",\"name\":\"C. He\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3132847.3132922\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"title\":\"Movie Fill in the Blank with Adaptive Temporal Attention and Description Update\",\"url\":\"https://www.semanticscholar.org/paper/3085671f6232aac4492ad861d09334b8f3a7e2a7\",\"venue\":\"CIKM\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34692779\",\"name\":\"K. Chang\"},{\"authorId\":\"10421443\",\"name\":\"Kung-Hung Lu\"},{\"authorId\":\"1720473\",\"name\":\"Chu-Song Chen\"}],\"doi\":\"10.1109/ICCV.2017.380\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"title\":\"Aesthetic Critiques Generation for Photos\",\"url\":\"https://www.semanticscholar.org/paper/c86716de32aaa0c9bce6f711b67c76c9fcecbb85\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1803.09845\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"94908120\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2018.00754\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"title\":\"Neural Baby Talk\",\"url\":\"https://www.semanticscholar.org/paper/3bf09b2e2639add154a9fe6ff98cc373d3e90e4e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2006.06316\",\"authors\":[{\"authorId\":\"116567136\",\"name\":\"Vasiliki Kougia\"},{\"authorId\":\"2332587\",\"name\":\"John Pavlopoulos\"},{\"authorId\":\"1471386897\",\"name\":\"P. Papapetrou\"},{\"authorId\":\"48314220\",\"name\":\"M. Gordon\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"46c681e64ad474245db423113bc9c64ccc904dca\",\"title\":\"RTEX: A novel methodology for Ranking, Tagging, and Explanatory diagnostic captioning of radiography exams\",\"url\":\"https://www.semanticscholar.org/paper/46c681e64ad474245db423113bc9c64ccc904dca\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1803.06936\",\"authors\":[{\"authorId\":\"144238414\",\"name\":\"Feng Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":\"10.1109/TPAMI.2018.2880185\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8927117cba0d82d59a35f099b47acb291c6567e3\",\"title\":\"Inverse Visual Question Answering: A New Benchmark and VQA Diagnosis Tool\",\"url\":\"https://www.semanticscholar.org/paper/8927117cba0d82d59a35f099b47acb291c6567e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1390788836\",\"name\":\"Guangxiang Zhao\"},{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"50317060\",\"name\":\"Zhiyuan Zhang\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"11774802\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4237bdd7df710c08b58d02bb48f8dcecd2521a80\",\"title\":\"Sparse Transformer: Concentrated Attention Through Explicit Selection\",\"url\":\"https://www.semanticscholar.org/paper/4237bdd7df710c08b58d02bb48f8dcecd2521a80\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145511765\",\"name\":\"Tong Wu\"},{\"authorId\":\"38338059\",\"name\":\"T. Ku\"},{\"authorId\":\"153504695\",\"name\":\"Hao Zhang\"}],\"doi\":\"10.1117/12.2552711\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b37b3cdcd6d839aaee661324c9d4a5411de20a11\",\"title\":\"Research for image caption based on global attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/b37b3cdcd6d839aaee661324c9d4a5411de20a11\",\"venue\":\"Target Recognition and Artificial Intelligence Summit Forum\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"},{\"authorId\":\"88265392\",\"name\":\"P. Liu\"},{\"authorId\":\"3343198\",\"name\":\"Yingjie Zhou\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"}],\"doi\":\"10.1109/BIGCOM.2019.00013\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a203fb561497774689ff4bb80cb18c9e00bf47b6\",\"title\":\"Semantic Tensor Product for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a203fb561497774689ff4bb80cb18c9e00bf47b6\",\"venue\":\"2019 5th International Conference on Big Data Computing and Communications (BIGCOM)\",\"year\":2019},{\"arxivId\":\"1708.06742\",\"authors\":[{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":true,\"paperId\":\"b44415a13f29ddc1af497b3876a2396673c3cfc0\",\"title\":\"Twin Networks: Using the Future as a Regularizer\",\"url\":\"https://www.semanticscholar.org/paper/b44415a13f29ddc1af497b3876a2396673c3cfc0\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"1911.09753\",\"authors\":[{\"authorId\":\"14454974\",\"name\":\"P. H. Seo\"},{\"authorId\":\"48267618\",\"name\":\"Piyush Sharma\"},{\"authorId\":\"2900341\",\"name\":\"Tomer Levinboim\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"},{\"authorId\":\"1737285\",\"name\":\"Radu Soricut\"}],\"doi\":\"10.1609/AAAI.V34I03.5655\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"b49c4285c6f744eaa5a653e7f7f0bc741ddbb8f5\",\"title\":\"Reinforcing an Image Caption Generator Using Off-Line Human Feedback\",\"url\":\"https://www.semanticscholar.org/paper/b49c4285c6f744eaa5a653e7f7f0bc741ddbb8f5\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48520182\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1145/3313873\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1a756ae8457454120ee2e067d4936d801f56ed62\",\"title\":\"Image Captioning by Asking Questions\",\"url\":\"https://www.semanticscholar.org/paper/1a756ae8457454120ee2e067d4936d801f56ed62\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1405686623\",\"name\":\"Nils Murrugarra-Llerena\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1109/CVPR.2019.00659\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"title\":\"Cross-Modality Personalization for Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"}],\"doi\":\"10.1109/ICASSP.2019.8682392\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4dee549ba6f09e59c6d6d13434a2b023d868467a\",\"title\":\"Image Captioning with Two Cascaded Agents\",\"url\":\"https://www.semanticscholar.org/paper/4dee549ba6f09e59c6d6d13434a2b023d868467a\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1705.00601\",\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"},{\"authorId\":\"39351028\",\"name\":\"Viraj Prabhu\"},{\"authorId\":\"2884573\",\"name\":\"Akrit Mohapatra\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"}],\"doi\":\"10.18653/v1/D17-1097\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"title\":\"The Promise of Premise: Harnessing Question Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/1d82e7736268917cc3d87a2ee0896b03e02a5ff6\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47956883\",\"name\":\"Xiangrong Zhang\"},{\"authorId\":null,\"name\":\"Xin Wang\"},{\"authorId\":\"144474380\",\"name\":\"X. Tang\"},{\"authorId\":\"46544755\",\"name\":\"Huiyu Zhou\"},{\"authorId\":\"33161908\",\"name\":\"C. Li\"}],\"doi\":\"10.3390/rs11060612\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"944e93e74379afedced307ca30fc6d31365dc96e\",\"title\":\"Description Generation for Remote Sensing Images Using Attribute Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/944e93e74379afedced307ca30fc6d31365dc96e\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52366010\",\"name\":\"Zhi-bin Guan\"},{\"authorId\":\"49600007\",\"name\":\"Kang Liu\"},{\"authorId\":\"47009350\",\"name\":\"Yan Ma\"},{\"authorId\":\"144222488\",\"name\":\"Xu Qian\"},{\"authorId\":\"35260608\",\"name\":\"Tongkai Ji\"}],\"doi\":\"10.3390/sym10110626\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"title\":\"Sequential Dual Attention: Coarse-to-Fine-Grained Hierarchical Generation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0d6b701c003c3aecfdbcf1700496cde74ea05642\",\"venue\":\"Symmetry\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"VGG\"},{\"authorId\":null,\"name\":\"RCNN\"},{\"authorId\":null,\"name\":\"LSTM\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"adf9243e6166df170fa1653dafe2d952ad1bfe9f\",\"title\":\"Dual Visual Attention Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/adf9243e6166df170fa1653dafe2d952ad1bfe9f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152281902\",\"name\":\"S. Wu\"},{\"authorId\":\"2087470\",\"name\":\"S. Fan\"},{\"authorId\":\"1700911\",\"name\":\"Zhiqi Shen\"},{\"authorId\":\"145977143\",\"name\":\"Mohan S. Kankanhalli\"},{\"authorId\":\"1699730\",\"name\":\"Anthony K. H. Tung\"}],\"doi\":\"10.1145/3394171.3413589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35ba6ed07ef68db187674498e684de7f3e160716\",\"title\":\"Who You Are Decides How You Tell\",\"url\":\"https://www.semanticscholar.org/paper/35ba6ed07ef68db187674498e684de7f3e160716\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1398104959\",\"name\":\"Justin R. Lovelace\"},{\"authorId\":\"144156074\",\"name\":\"Bobak Mortazavi\"}],\"doi\":\"10.18653/v1/2020.findings-emnlp.110\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"a554243e6806ac419ffdb19c354686f77ef2b848\",\"title\":\"Learning to Generate Clinically Coherent Chest X-Ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/a554243e6806ac419ffdb19c354686f77ef2b848\",\"venue\":\"EMNLP\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"32818833\",\"name\":\"Mingda Zhang\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"a9a074894a788afb0decb055574ea29b4190d636\",\"title\":\"Breaking Shortcuts by Masking for Robust Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a9a074894a788afb0decb055574ea29b4190d636\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1701.07274\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"9f1e9e56d80146766bc2316efbc54d8b770a23df\",\"title\":\"Deep Reinforcement Learning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/9f1e9e56d80146766bc2316efbc54d8b770a23df\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92916571\",\"name\":\"Han-Yu Peng\"},{\"authorId\":\"5440170\",\"name\":\"J. He\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yali Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.patrec.2019.08.032\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c54425fe683cc740c22447f0c6642b3d7cb01e0b\",\"title\":\"Dual-supervised attention network for deep cross-modal hashing\",\"url\":\"https://www.semanticscholar.org/paper/c54425fe683cc740c22447f0c6642b3d7cb01e0b\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-019-08021-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"title\":\"Survey of deep learning and architectures for visual captioning\\u2014transitioning between media and natural languages\",\"url\":\"https://www.semanticscholar.org/paper/1ba03c16bf25d33efc0d977ab51392e1d9b5a0fb\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1612.07086\",\"authors\":[{\"authorId\":\"2174964\",\"name\":\"Jiuxiang Gu\"},{\"authorId\":\"2096527\",\"name\":\"G. Wang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"},{\"authorId\":\"40894914\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/ICCV.2017.138\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"title\":\"An Empirical Study of Language CNN for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d85704f4814e9fa5ff0b68b1e5cad9e6527d0bbf\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"1905.06139\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"title\":\"Aligning Visual Regions and Textual Concepts for Semantic-Grounded Image Representations\",\"url\":\"https://www.semanticscholar.org/paper/cc663416cbbd577ea02e8b4ef0ea201f5a12d608\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"1764508\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2440041\",\"name\":\"X. Jiang\"},{\"authorId\":\"1724421\",\"name\":\"Deng Cai\"}],\"doi\":\"10.1109/TIP.2019.2902106\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"title\":\"Multi-Turn Video Question Answering via Hierarchical Attention Context Reinforced Networks\",\"url\":\"https://www.semanticscholar.org/paper/65bd828c05cac7eabe791e10d4d3c0f2da2b798c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1839363\",\"name\":\"Pierre L. Dognin\"},{\"authorId\":\"2576373\",\"name\":\"I. Melnyk\"},{\"authorId\":\"2211263\",\"name\":\"Youssef Mroueh\"},{\"authorId\":\"153598395\",\"name\":\"J. Ross\"},{\"authorId\":\"2500466\",\"name\":\"Tom Sercu\"}],\"doi\":\"10.1109/CVPR.2019.01071\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"title\":\"Adversarial Semantic Alignment for Improved Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/24fdb40c354599ee33a25530c3fa7b9ebc75e840\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9741677\",\"name\":\"Senmao Ye\"},{\"authorId\":\"7181955\",\"name\":\"J. Han\"},{\"authorId\":\"143905571\",\"name\":\"Nian Liu\"}],\"doi\":\"10.1109/TIP.2018.2855406\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"title\":\"Attentive Linear Transformation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4dea9cce0825c0cdb1a4a28c4ab8416d6e3e047c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Huan Yang\"},{\"authorId\":\"145144398\",\"name\":\"Dandan Song\"},{\"authorId\":\"3000498\",\"name\":\"Lejian Liao\"}],\"doi\":\"10.1007/978-3-319-97310-4_43\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c1473ca131d8a6030def18ca196b8d39e0665613\",\"title\":\"Image Captioning with Relational Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/c1473ca131d8a6030def18ca196b8d39e0665613\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"37310105\",\"name\":\"L. Zhao\"},{\"authorId\":\"47423527\",\"name\":\"Chunxia Zhang\"},{\"authorId\":null,\"name\":\"Xi Zhang\"},{\"authorId\":\"3034224\",\"name\":\"Yating Hu\"},{\"authorId\":\"8253080\",\"name\":\"Z. Niu\"}],\"doi\":\"10.1007/978-3-319-97304-3_67\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f472524ad1a5989aa1d66634a477041cd6ec9b64\",\"title\":\"A Deep Reinforced Training Method for Location-Based Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f472524ad1a5989aa1d66634a477041cd6ec9b64\",\"venue\":\"PRICAI\",\"year\":2018},{\"arxivId\":\"2003.00387\",\"authors\":[{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"},{\"authorId\":\"1490938689\",\"name\":\"Peng Wang\"},{\"authorId\":\"49018095\",\"name\":\"Qi Wu\"}],\"doi\":\"10.1109/cvpr42600.2020.00998\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"title\":\"Say As You Wish: Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/b4916e339caef2d2a98e633e1f0b2144e2b0c9e2\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2003.14080\",\"authors\":[{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"1490772804\",\"name\":\"Tao Mei\"}],\"doi\":\"10.1109/cvpr42600.2020.01098\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"title\":\"X-Linear Attention Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4adfa7b83342b77c830f2b0f6fc1b784c21e7ed0\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1519472504\",\"name\":\"Shaoxiong Feng\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"153141891\",\"name\":\"K. Li\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c56872681422c458010383c905c55726784a9292\",\"title\":\"Continue or SHIFT: Learning Conversational Patterns for Dialogue Generation\",\"url\":\"https://www.semanticscholar.org/paper/c56872681422c458010383c905c55726784a9292\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11007025\",\"name\":\"Junjiao Tian\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"df40d057b584de2cf74123a2ef4274de582d6b03\",\"title\":\"Detailed Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/df40d057b584de2cf74123a2ef4274de582d6b03\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150112916\",\"name\":\"Gabino Luis\"},{\"authorId\":\"47756806\",\"name\":\"D. Suarez\"},{\"authorId\":\"145940020\",\"name\":\"A. Mateos\"}],\"doi\":\"10.14201/ADCAIJ2018741726\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0dcf93dde3488d42e244999f6be62a1bb9732521\",\"title\":\"Multi-Agent Word Guessing Game\",\"url\":\"https://www.semanticscholar.org/paper/0dcf93dde3488d42e244999f6be62a1bb9732521\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TIP.2018.2855415\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"16a2a1bf612f9f9719a7945485f7e73324d18783\",\"title\":\"More is Better: Precise and Detailed Image Captioning Using Online Positive Recall and Missing Concepts Mining\",\"url\":\"https://www.semanticscholar.org/paper/16a2a1bf612f9f9719a7945485f7e73324d18783\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"3141085\",\"name\":\"V. K\\u0131l\\u0131\\u00e7\"}],\"doi\":\"10.23919/ELECO47770.2019.8990395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2c04709cafc945deaa13b6a92c092416188d8bf9\",\"title\":\"Smartphone-based Image Captioning for Visually and Hearing Impaired\",\"url\":\"https://www.semanticscholar.org/paper/2c04709cafc945deaa13b6a92c092416188d8bf9\",\"venue\":\"2019 11th International Conference on Electrical and Electronics Engineering (ELECO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"},{\"authorId\":\"150164718\",\"name\":\"Jialong Tang\"},{\"authorId\":null,\"name\":\"Ziyao Lu\"},{\"authorId\":\"3194601\",\"name\":\"Xianpei Han\"},{\"authorId\":\"2999092\",\"name\":\"H. Zhang\"}],\"doi\":\"10.1016/J.NEUCOM.2019.08.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"title\":\"A neural image captioning model with caption-to-images semantic constructor\",\"url\":\"https://www.semanticscholar.org/paper/2fb096118ebbe6615afe98c733c80f55bb40d2cf\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2706292\",\"name\":\"Xianhua Zeng\"},{\"authorId\":\"145117241\",\"name\":\"L. Wen\"},{\"authorId\":\"115986457\",\"name\":\"Yang Xu\"},{\"authorId\":\"1893927760\",\"name\":\"Conghui Ji\"}],\"doi\":\"10.1016/j.cmpb.2020.105700\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cbe08984fe9bb669e11e73b8fb14c9d43ab57017\",\"title\":\"Generating diagnostic report for medical image by high-middle-level visual information incorporation on double deep learning models\",\"url\":\"https://www.semanticscholar.org/paper/cbe08984fe9bb669e11e73b8fb14c9d43ab57017\",\"venue\":\"Comput. Methods Programs Biomed.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10798523\",\"name\":\"C. C. Park\"},{\"authorId\":\"3231991\",\"name\":\"Byeongchang Kim\"},{\"authorId\":\"1743920\",\"name\":\"Gunhee Kim\"}],\"doi\":\"10.1109/TPAMI.2018.2824816\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"title\":\"Towards Personalized Image Captioning via Multimodal Memory Networks\",\"url\":\"https://www.semanticscholar.org/paper/eb28671c43e6f3bfeee3b5bec8023887d8c07bc7\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":\"10.18653/v1/W19-8668\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7c6b67838d895f08a177634f553b5dfc669f44c5\",\"title\":\"What goes into a word: generating image descriptions with top-down spatial knowledge\",\"url\":\"https://www.semanticscholar.org/paper/7c6b67838d895f08a177634f553b5dfc669f44c5\",\"venue\":\"INLG\",\"year\":2019},{\"arxivId\":\"1809.00101\",\"authors\":[{\"authorId\":\"46457997\",\"name\":\"Lingbo Liu\"},{\"authorId\":\"2247393\",\"name\":\"Ruimao Zhang\"},{\"authorId\":\"35739338\",\"name\":\"Jiefeng Peng\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"2525530\",\"name\":\"B. Du\"},{\"authorId\":\"1737218\",\"name\":\"L. Lin\"}],\"doi\":\"10.1145/3240508.3240681\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4629b7caea78fc8255c3e8d795d5a98115aaf6a1\",\"title\":\"Attentive Crowd Flow Machines\",\"url\":\"https://www.semanticscholar.org/paper/4629b7caea78fc8255c3e8d795d5a98115aaf6a1\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2036790405\",\"name\":\"Kiyohiko Iwamura\"},{\"authorId\":\"34769384\",\"name\":\"Jun Younes Louhi Kasahara\"},{\"authorId\":\"24316406\",\"name\":\"A. Moro\"},{\"authorId\":\"152521159\",\"name\":\"A. Yamashita\"},{\"authorId\":\"50631807\",\"name\":\"H. Asama\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b6bea157580146a416540b467fa3002ccd044b7d\",\"title\":\"Potential of Incorporating Motion Estimation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b6bea157580146a416540b467fa3002ccd044b7d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3192572\",\"name\":\"Emiel van Miltenburg\"},{\"authorId\":\"2828538\",\"name\":\"\\u00c1kos K\\u00e1d\\u00e1r\"},{\"authorId\":\"2045556\",\"name\":\"R. Koolen\"},{\"authorId\":\"145210073\",\"name\":\"E. Krahmer\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14bfde3b760bc09d4c93f81dc029429fca734c48\",\"title\":\"DIDEC: The Dutch Image Description and Eye-tracking Corpus\",\"url\":\"https://www.semanticscholar.org/paper/14bfde3b760bc09d4c93f81dc029429fca734c48\",\"venue\":\"COLING\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2223252\",\"name\":\"Y. Zhou\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"46700604\",\"name\":\"J. Liu\"},{\"authorId\":\"1400120070\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1145/3394171.3414009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"title\":\"Attacking Image Captioning Towards Accuracy-Preserving Target Words Removal\",\"url\":\"https://www.semanticscholar.org/paper/0f480dadb895975a3921f5fcd03fdbf4085f8e9b\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.07583\",\"authors\":[{\"authorId\":\"1388780256\",\"name\":\"Yaser Alwatter\"},{\"authorId\":\"1798719\",\"name\":\"Yuhong Guo\"}],\"doi\":\"10.22215/etd/2019-13929\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"48795928eb87d1e8a038063b3aebee180e424d04\",\"title\":\"Inverse Visual Question Answering with Multi-Level Attentions\",\"url\":\"https://www.semanticscholar.org/paper/48795928eb87d1e8a038063b3aebee180e424d04\",\"venue\":\"ACML\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2552746\",\"name\":\"L. Zhang\"},{\"authorId\":\"144625807\",\"name\":\"V. Singh\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"1846624\",\"name\":\"T. Chen\"}],\"doi\":\"10.1109/WACV.2019.00017\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"941f459f674a5ebc05c9570a3cd97dc80d2ef203\",\"title\":\"Cascade Attention Machine for Occluded Landmark Detection in 2D X-Ray Angiography\",\"url\":\"https://www.semanticscholar.org/paper/941f459f674a5ebc05c9570a3cd97dc80d2ef203\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1109/ICIP.2018.8451558\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"title\":\"Image Captioning with Word Level Attention\",\"url\":\"https://www.semanticscholar.org/paper/c5f6ed9efc222fe2773135ffb4e5c567d98e64ea\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1808.04359\",\"authors\":[{\"authorId\":\"50714373\",\"name\":\"A. Agarwal\"},{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"},{\"authorId\":\"144582538\",\"name\":\"Vasu Sharma\"},{\"authorId\":\"35084211\",\"name\":\"M. Lewis\"},{\"authorId\":\"9076478\",\"name\":\"K. Sycara\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"title\":\"Community Regularization of Visually-Grounded Dialog\",\"url\":\"https://www.semanticscholar.org/paper/79414eab0f7283af26c2fa9dd3db738fabe52c88\",\"venue\":\"AAMAS\",\"year\":2019},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"2012.02128\",\"authors\":[{\"authorId\":\"1768759403\",\"name\":\"Jing Su\"},{\"authorId\":\"49892954\",\"name\":\"Qingyun Dai\"},{\"authorId\":\"8139616\",\"name\":\"F. Guerin\"},{\"authorId\":\"1510708415\",\"name\":\"Mian Zhou\"}],\"doi\":\"10.1016/j.csl.2020.101169\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c1a435ffd06c26f9f4273b11efed10bce2138d08\",\"title\":\"BERT-hLSTMs: BERT and Hierarchical LSTMs for Visual Storytelling\",\"url\":\"https://www.semanticscholar.org/paper/c1a435ffd06c26f9f4273b11efed10bce2138d08\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1909.02902\",\"authors\":[{\"authorId\":\"1391190009\",\"name\":\"Lingbo Liu\"},{\"authorId\":\"153206528\",\"name\":\"Jiajie Zhen\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"145736603\",\"name\":\"G. Zhan\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tits.2020.3002718\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5e1eaf7debe0b9b5b83627bf2d53c7ce636fafe5\",\"title\":\"Dynamic Spatial-Temporal Representation Learning for Traffic Flow Prediction\",\"url\":\"https://www.semanticscholar.org/paper/5e1eaf7debe0b9b5b83627bf2d53c7ce636fafe5\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"2010.08189\",\"authors\":[{\"authorId\":\"2283009\",\"name\":\"W. Chen\"},{\"authorId\":\"46315247\",\"name\":\"W. Wang\"},{\"authorId\":\"87109212\",\"name\":\"Li Liu\"},{\"authorId\":\"1731570\",\"name\":\"M. Lew\"}],\"doi\":\"10.1016/j.neucom.2020.10.042\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"title\":\"New Ideas and Trends in Deep Multimodal Content Understanding: A Review\",\"url\":\"https://www.semanticscholar.org/paper/61ba6969078b7358c61f7eb93b4150ab0e4f329b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.01148\",\"authors\":[{\"authorId\":\"2804902\",\"name\":\"M. M. Islam\"},{\"authorId\":\"32229358\",\"name\":\"Tariq Iqbal\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ab3f612125a13410373c33600abd3fccdf79ce31\",\"title\":\"HAMLET: A Hierarchical Multimodal Attention-based Human Activity Recognition Algorithm\",\"url\":\"https://www.semanticscholar.org/paper/ab3f612125a13410373c33600abd3fccdf79ce31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48515249\",\"name\":\"Y. Li\"},{\"authorId\":\"1390462650\",\"name\":\"Juan Yang\"}],\"doi\":\"10.1145/3366750.3366756\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"c8462d4c88767ca26b70bcaa88da811d5f8303d1\",\"title\":\"Hydrological Time Series Prediction Model Based on Attention-LSTM Neural Network\",\"url\":\"https://www.semanticscholar.org/paper/c8462d4c88767ca26b70bcaa88da811d5f8303d1\",\"venue\":\"ICML 2019\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1818920\",\"name\":\"Zijia Lin\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":\"10.24963/ijcai.2018/84\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b4ae889c38444939ae4312ab38bf7036f6df739f\",\"title\":\"Show, Observe and Tell: Attribute-driven Attention Model for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b4ae889c38444939ae4312ab38bf7036f6df739f\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1431726865\",\"name\":\"R. SreelaS.\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.3390/info10110354\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"title\":\"Dense Model for Automatic Image Description Generation with Game Theoretic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/f3b1964968f2dd1a065a43c4cafae6a6de6dac1c\",\"venue\":\"Inf.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"49969428\",\"name\":\"Z. Li\"},{\"authorId\":\"1856671082\",\"name\":\"Shengjia Chen\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1145/3340531.3411948\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3428bac9141f6db961fc4665db1cbc9a196152da\",\"title\":\"Image Captioning with Internal and External Knowledge\",\"url\":\"https://www.semanticscholar.org/paper/3428bac9141f6db961fc4665db1cbc9a196152da\",\"venue\":\"CIKM\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2126416\",\"name\":\"Q. Wang\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1109/ICME.2019.00270\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"title\":\"Visual Dialog with Targeted Objects\",\"url\":\"https://www.semanticscholar.org/paper/16e5c968baa7a2cec88e2d5a03fb7d8bb0911a96\",\"venue\":\"2019 IEEE International Conference on Multimedia and Expo (ICME)\",\"year\":2019},{\"arxivId\":\"1912.11637\",\"authors\":[{\"authorId\":\"1390788836\",\"name\":\"Guangxiang Zhao\"},{\"authorId\":\"35996608\",\"name\":\"Junyang Lin\"},{\"authorId\":\"50317060\",\"name\":\"Zhiyuan Zhang\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"143725038\",\"name\":\"Qi Su\"},{\"authorId\":\"11774802\",\"name\":\"X. Sun\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b03cf6324ecf7a295a4aeae5970c88d1a1c3f336\",\"title\":\"Explicit Sparse Transformer: Concentrated Attention Through Explicit Selection\",\"url\":\"https://www.semanticscholar.org/paper/b03cf6324ecf7a295a4aeae5970c88d1a1c3f336\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"1752427\",\"name\":\"Jiansheng Chen\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"47718901\",\"name\":\"Weitao Wan\"},{\"authorId\":\"153447481\",\"name\":\"Youze Xue\"}],\"doi\":\"10.1109/TIP.2020.2969330\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"title\":\"Image Captioning With End-to-End Attribute Detection and Subsequent Attributes Prediction\",\"url\":\"https://www.semanticscholar.org/paper/ff5a1ec81f327b711a5433e4cd40467215a13f39\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"116740128\",\"name\":\"Hongchen Tan\"},{\"authorId\":\"48033092\",\"name\":\"X. Liu\"},{\"authorId\":\"3223020\",\"name\":\"Xin Li\"},{\"authorId\":\"48379553\",\"name\":\"Y. Zhang\"},{\"authorId\":\"2207938\",\"name\":\"B. Yin\"}],\"doi\":\"10.1109/ICCV.2019.01060\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"129e2359e072ba20029e48545f4acefa618d748a\",\"title\":\"Semantics-Enhanced Adversarial Nets for Text-to-Image Synthesis\",\"url\":\"https://www.semanticscholar.org/paper/129e2359e072ba20029e48545f4acefa618d748a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1902.03751\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1774780\",\"name\":\"Yilin Shen\"},{\"authorId\":\"1705713\",\"name\":\"Hongxia Jin\"},{\"authorId\":\"145054147\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/ICCV.2019.00268\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"title\":\"Taking a HINT: Leveraging Explanations to Make Vision and Language Models More Grounded\",\"url\":\"https://www.semanticscholar.org/paper/ab9ac4bea4ee49fd879337ac477dc09de4914fbf\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1912.08830\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"}],\"doi\":\"10.1007/978-3-030-58565-5_13\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"82b6033697e2a2a6018577bc3dac239b40a0a242\",\"title\":\"ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language\",\"url\":\"https://www.semanticscholar.org/paper/82b6033697e2a2a6018577bc3dac239b40a0a242\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1808.05864\",\"authors\":[{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":null,\"name\":\"Feng Wu\"}],\"doi\":\"10.1145/3240508.3240632\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"title\":\"Context-Aware Visual Policy Network for Sequence-Level Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0574dc64c8275b09ed587dc3977f4d3c990bd4df\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1903.02507\",\"authors\":[{\"authorId\":\"3259825\",\"name\":\"Jiayun Li\"},{\"authorId\":\"39367903\",\"name\":\"Mohammad K. Ebrahimpour\"},{\"authorId\":\"33129821\",\"name\":\"Azadeh Moghtaderi\"},{\"authorId\":\"1915432\",\"name\":\"Yen-Yun Yu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ea752a837e24686a5774e6cbe6f787a76cd014d\",\"title\":\"Image captioning with weakly-supervised attention penalty\",\"url\":\"https://www.semanticscholar.org/paper/2ea752a837e24686a5774e6cbe6f787a76cd014d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47775786\",\"name\":\"J. Xu\"},{\"authorId\":null,\"name\":\"Wei Liu\"},{\"authorId\":\"70587110\",\"name\":\"Chao Liu\"},{\"authorId\":null,\"name\":\"Yu Wang\"},{\"authorId\":\"50256071\",\"name\":\"Ying Chi\"},{\"authorId\":\"65863521\",\"name\":\"Xuansong Xie\"},{\"authorId\":\"143863244\",\"name\":\"Xian-Sheng Hua\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cb308fcb3d36f5afec8b57355749ffbe4c99b28c\",\"title\":\"Concept Detection based on Multi-label Classification and Image Captioning Approach - DAMO at ImageCLEF 2019\",\"url\":\"https://www.semanticscholar.org/paper/cb308fcb3d36f5afec8b57355749ffbe4c99b28c\",\"venue\":\"CLEF\",\"year\":2019},{\"arxivId\":\"1909.03918\",\"authors\":[{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2019.00271\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"05106b86ec45914d1136719d311078182d437872\",\"title\":\"Hierarchy Parsing for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/05106b86ec45914d1136719d311078182d437872\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97636424\",\"name\":\"G. Li\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144303230\",\"name\":\"Ping Liu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1109/ICCV.2019.00902\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"title\":\"Entangled Transformer for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7c4530882cfcef1d2b4aa2996f494dfac626b5d9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1954481\",\"name\":\"D. Huynh\"},{\"authorId\":\"47126776\",\"name\":\"E. Elhamifar\"}],\"doi\":\"10.1109/cvpr42600.2020.00880\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7541e6e97c5d94184922f7db5b7fe185063941ef\",\"title\":\"A Shared Multi-Attention Framework for Multi-Label Zero-Shot Learning\",\"url\":\"https://www.semanticscholar.org/paper/7541e6e97c5d94184922f7db5b7fe185063941ef\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48707795\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"}],\"doi\":\"10.24963/ijcai.2020/92\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"506e7acfb05c851a7b3ccb256f4fed6d5a7dc15c\",\"title\":\"Human Consensus-Oriented Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/506e7acfb05c851a7b3ccb256f4fed6d5a7dc15c\",\"venue\":\"IJCAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1389373080\",\"name\":\"Ruoyu Chen\"},{\"authorId\":\"2607225\",\"name\":\"Zhongnian Li\"},{\"authorId\":\"1772283\",\"name\":\"D. Zhang\"}],\"doi\":\"10.1007/978-981-15-1398-5_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bab70faa1e36b525766f85b5ff87bff4566d0294\",\"title\":\"Adaptive Joint Attention with Reinforcement Training for Convolutional Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/bab70faa1e36b525766f85b5ff87bff4566d0294\",\"venue\":\"HBAI@IJCAI\",\"year\":2019},{\"arxivId\":\"1810.06339\",\"authors\":[{\"authorId\":\"2276894\",\"name\":\"Yuxi Li\"}],\"doi\":\"10.1201/9781351006620-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"title\":\"Deep Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/f2ac2a3fd7b341f2b1be752b4dd46ed9abcf0751\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292635\",\"name\":\"Zongtao Liu\"},{\"authorId\":\"144757965\",\"name\":\"Y. Yang\"},{\"authorId\":\"49015988\",\"name\":\"W. Huang\"},{\"authorId\":\"41216247\",\"name\":\"Zhongyi Tang\"},{\"authorId\":\"145644795\",\"name\":\"Ning Li\"},{\"authorId\":\"39918420\",\"name\":\"F. Wu\"}],\"doi\":\"10.1145/3308558.3313714\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b3f6b215de019c72ae31362d11ab29f56948f605\",\"title\":\"How Do Your Neighbors Disclose Your Information: Social-Aware Time Series Imputation\",\"url\":\"https://www.semanticscholar.org/paper/b3f6b215de019c72ae31362d11ab29f56948f605\",\"venue\":\"WWW\",\"year\":2019},{\"arxivId\":\"1904.02628\",\"authors\":[{\"authorId\":\"65767906\",\"name\":\"Silvio Olivastri\"},{\"authorId\":\"1931660\",\"name\":\"Gurkirt Singh\"},{\"authorId\":\"1754181\",\"name\":\"Fabio Cuzzolin\"}],\"doi\":\"10.1109/ICCVW.2019.00185\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"0c1ebaa635f68bb4a09fc59191642f30cfa894c9\",\"title\":\"End-to-End Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0c1ebaa635f68bb4a09fc59191642f30cfa894c9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"1711.06370\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"144663765\",\"name\":\"Qi Wu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2018.00447\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7299465d70181e423480fdb252aa2e28c18aa012\",\"title\":\"Parallel Attention: A Unified Framework for Visual Object Discovery Through Dialogs and Queries\",\"url\":\"https://www.semanticscholar.org/paper/7299465d70181e423480fdb252aa2e28c18aa012\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1810.04020\",\"authors\":[{\"authorId\":\"47412302\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"2470423\",\"name\":\"Ferdous Sohel\"},{\"authorId\":\"2222847\",\"name\":\"M. F. Shiratuddin\"},{\"authorId\":\"47028380\",\"name\":\"Hamid Laga\"}],\"doi\":\"10.1145/3295748\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"title\":\"A Comprehensive Survey of Deep Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7e27d44e3fac723ccb703e0a83b22711bd42efe8\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1726159226\",\"name\":\"Xiangqing Shen\"},{\"authorId\":\"49167055\",\"name\":\"B. Liu\"},{\"authorId\":\"1697439\",\"name\":\"Yong Zhou\"},{\"authorId\":\"1491078664\",\"name\":\"Jiaqi Zhao\"}],\"doi\":\"10.1007/s11042-020-09294-7\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"title\":\"Remote sensing image caption generation via transformer and reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/20d2de48968f3ed1dc00be6ded0e2271d0f1a1a4\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2011.07680\",\"authors\":[{\"authorId\":\"1477956290\",\"name\":\"Wenting Xu\"},{\"authorId\":\"2023765018\",\"name\":\"C. Qi\"},{\"authorId\":\"50070382\",\"name\":\"Zhenghua Xu\"},{\"authorId\":\"1690572\",\"name\":\"Thomas Lukasiewicz\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"504e7bba81083ebbc4e114e48938ebaffb5ba03c\",\"title\":\"Reinforced Medical Report Generation with X-Linear Attention and Repetition Penalty\",\"url\":\"https://www.semanticscholar.org/paper/504e7bba81083ebbc4e114e48938ebaffb5ba03c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.00222\",\"authors\":[{\"authorId\":\"67318326\",\"name\":\"Y. Koizumi\"},{\"authorId\":\"1423768681\",\"name\":\"Ryo Masumura\"},{\"authorId\":\"2963420\",\"name\":\"Kyosuke Nishida\"},{\"authorId\":\"50131290\",\"name\":\"M. Yasuda\"},{\"authorId\":\"2880610\",\"name\":\"S. Saito\"}],\"doi\":\"10.21437/interspeech.2020-2087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cd1b307eff4e0a72e8c975e90bea6ec6be286718\",\"title\":\"A Transformer-based Audio Captioning Model with Keyword Estimation\",\"url\":\"https://www.semanticscholar.org/paper/cd1b307eff4e0a72e8c975e90bea6ec6be286718\",\"venue\":\"INTERSPEECH\",\"year\":2020},{\"arxivId\":\"1911.10132\",\"authors\":[{\"authorId\":\"151430668\",\"name\":\"Chiranjib Sur\"}],\"doi\":\"10.1007/s11042-020-09865-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"title\":\"CRUR: Coupled-Recurrent Unit for Unification, Conceptualization and Context Capture for Language Representation - A Generalization of Bi Directional LSTM\",\"url\":\"https://www.semanticscholar.org/paper/c8f8ea39c64cf08792cd49c6ad04e85e3b90c88f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145824699\",\"name\":\"Zheng Lian\"},{\"authorId\":\"49403723\",\"name\":\"H. Li\"},{\"authorId\":\"102696161\",\"name\":\"Rui Wang\"},{\"authorId\":\"38865491\",\"name\":\"Xiaohui Hu\"}],\"doi\":\"10.1109/ICTAI50040.2020.00119\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"45f9791def36fd6e2e701b0d5d5c44063a9da473\",\"title\":\"Enhanced soft attention mechanism with an inception-like module for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/45f9791def36fd6e2e701b0d5d5c44063a9da473\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Mehrdad Hosseinzadeh\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"da8a8a0ce5a15d072c85e1bace61e28701547c12\",\"title\":\"Video Captioning of Future Frames\",\"url\":\"https://www.semanticscholar.org/paper/da8a8a0ce5a15d072c85e1bace61e28701547c12\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"8408809\",\"name\":\"M. Chen\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"47666390\",\"name\":\"H. Chen\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"47362455\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1007/s12559-018-9581-x\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"title\":\"Neural Image Caption Generation with Weighted Training and Reference\",\"url\":\"https://www.semanticscholar.org/paper/848602d3de1b1ab9a06146e8b8f3f836cacbce91\",\"venue\":\"Cognitive Computation\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/WACV.2018.00190\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"title\":\"Fine-Grained and Semantic-Guided Visual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6107d5107e7e0d94a3f0f43b642c4cfd1cba3b79\",\"venue\":\"2018 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2018},{\"arxivId\":\"1810.04101\",\"authors\":[{\"authorId\":\"1809420\",\"name\":\"Loris Bazzani\"},{\"authorId\":\"2120874\",\"name\":\"Tobias Domhan\"},{\"authorId\":\"2521764\",\"name\":\"F. Hieber\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"title\":\"Image Captioning as Neural Machine Translation Task in SOCKEYE\",\"url\":\"https://www.semanticscholar.org/paper/d76c73ab62d960f5417dfa8aff9e63d357c5fd5d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5482750\",\"name\":\"J. Wang\"},{\"authorId\":\"145200778\",\"name\":\"Wei Wang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1145/3240508.3240538\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"72f9116a04e584081635500e9f0789fa26e4d15f\",\"title\":\"Hierarchical Memory Modelling for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/72f9116a04e584081635500e9f0789fa26e4d15f\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1911.10115\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"title\":\"TPsgtR: Neural-Symbolic Tensor Product Scene-Graph-Triplet Representation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/50c6889b547cc08a203842d5cf5bcb4c58e052b5\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.06666\",\"authors\":[{\"authorId\":\"9085797\",\"name\":\"Keren Ye\"},{\"authorId\":\"1770205\",\"name\":\"Adriana Kovashka\"}],\"doi\":\"10.1007/978-3-030-01267-0_51\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1be2c16060974f66e5366872ebbee21325075e8\",\"title\":\"ADVISE: Symbolism and External Knowledge for Decoding Advertisements\",\"url\":\"https://www.semanticscholar.org/paper/e1be2c16060974f66e5366872ebbee21325075e8\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48569838\",\"name\":\"Xiangyang Li\"},{\"authorId\":\"1696610\",\"name\":\"S. Jiang\"}],\"doi\":\"10.1109/TMM.2019.2896516\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"title\":\"Know More Say Less: Image Captioning Based on Scene Graphs\",\"url\":\"https://www.semanticscholar.org/paper/bc73f0f7d895a089416bc8f6090f3f8707c6a12f\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50125796\",\"name\":\"Yajun Xu\"},{\"authorId\":\"1855978\",\"name\":\"Zhendong Mao\"},{\"authorId\":\"8157255\",\"name\":\"Zhineng Chen\"},{\"authorId\":null,\"name\":\"Xin Wen\"},{\"authorId\":\"40282454\",\"name\":\"Y. Li\"}],\"doi\":\"10.1007/s11042-020-08787-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8fc1c9858799792d20159894a7271286a5a1a516\",\"title\":\"Context propagation embedding network for weakly supervised semantic segmentation\",\"url\":\"https://www.semanticscholar.org/paper/8fc1c9858799792d20159894a7271286a5a1a516\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"46700004\",\"name\":\"J. Liu\"},{\"authorId\":\"116829059\",\"name\":\"Shi-chen Lu\"},{\"authorId\":\"1699900\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/TMM.2019.2951226\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"837a513a43c7bcce903edbacbfc507cba6451e21\",\"title\":\"Show, Tell, and Polish: Ruminant Decoding for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/837a513a43c7bcce903edbacbfc507cba6451e21\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1803.04376\",\"authors\":[{\"authorId\":\"3212867\",\"name\":\"R. Luo\"},{\"authorId\":\"31844147\",\"name\":\"Brian L. Price\"},{\"authorId\":\"145823372\",\"name\":\"S. Cohen\"},{\"authorId\":\"2490189\",\"name\":\"Gregory Shakhnarovich\"}],\"doi\":\"10.1109/CVPR.2018.00728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"title\":\"Discriminability Objective for Training Descriptive Captions\",\"url\":\"https://www.semanticscholar.org/paper/7c1802d8d43dfe783650a03f03d41609fa5ae91e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1811.03403\",\"authors\":[{\"authorId\":\"8407377\",\"name\":\"Jarryd Son\"},{\"authorId\":\"144204985\",\"name\":\"A. Mishra\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c9c2576998c1236f8a5ae11f822ec155c2e7de56\",\"title\":\"ExGate: Externally Controlled Gating for Feature-based Attention in Artificial Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/c9c2576998c1236f8a5ae11f822ec155c2e7de56\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144774112\",\"name\":\"F. Liu\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"},{\"authorId\":\"2345507\",\"name\":\"Wankou Yang\"},{\"authorId\":\"145928755\",\"name\":\"C. Sun\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"57417c4a523d93801c8901d6f3c3740eaa65c9ae\",\"title\":\"Inverse Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/57417c4a523d93801c8901d6f3c3740eaa65c9ae\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1392406002\",\"name\":\"Arturs Polis\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4bfeae734bced5b2613af9f7d8271354b614e08e\",\"title\":\"Paragraph-length image captioning using hierarchical recurrent neural networks\",\"url\":\"https://www.semanticscholar.org/paper/4bfeae734bced5b2613af9f7d8271354b614e08e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1703.06246\",\"authors\":[{\"authorId\":\"3194022\",\"name\":\"Bohan Zhuang\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"1780381\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"145950884\",\"name\":\"I. Reid\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"title\":\"Towards Context-aware Interaction Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f95f45b8e4d99175f8c68bb539231d82846d5f0b\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48394426\",\"name\":\"Naeha Sharif\"},{\"authorId\":\"39689790\",\"name\":\"L. White\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"},{\"authorId\":\"2210661\",\"name\":\"S. Shah\"}],\"doi\":\"10.1007/978-3-030-01237-3_3\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"title\":\"NNEval: Neural Network Based Evaluation Metric for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/fa9189749a4c95c45ec7d98db49e5f736c51760e\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1812.06624\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"title\":\"Feature Fusion Effects of Tensor Product Representation on (De)Compositional Network for Caption Generation for Images\",\"url\":\"https://www.semanticscholar.org/paper/5f3c111425a1e2f6316f01b9b0f3d09fa146b134\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79893149\",\"name\":\"A. L. Peirson\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e0509ab96c57189720bd5dad4eca655888f70071\",\"title\":\"C L ] 8 J un 2 01 8 Dank Learning : Generating Memes Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/e0509ab96c57189720bd5dad4eca655888f70071\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4942547\",\"name\":\"Zongjian Zhang\"},{\"authorId\":\"145698633\",\"name\":\"Q. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"145093625\",\"name\":\"F. Chen\"}],\"doi\":\"10.1109/DICTA.2018.8615788\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"title\":\"Size-Invariant Attention Accuracy Metric for Image Captioning with High-Resolution Residual Attention\",\"url\":\"https://www.semanticscholar.org/paper/2ce9fd151c7e67581dfa85b662f5034aca1896e6\",\"venue\":\"2018 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"title\":\"Image Input OR Video Hierarchical LSTMs with Adaptive Attention ( hLSTMat ) Feature Extraction Generated Captions Losses\",\"url\":\"https://www.semanticscholar.org/paper/e060c24c57930007d9496edc6847ed78ef1b0ddd\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40974715\",\"name\":\"Bhargav Kanuparthi\"},{\"authorId\":\"2309967\",\"name\":\"D. Arpit\"},{\"authorId\":\"51922896\",\"name\":\"Giancarlo Kerg\"},{\"authorId\":\"145604319\",\"name\":\"Nan Rosemary Ke\"},{\"authorId\":null,\"name\":\"Ioannis Mitliagkas\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1d17baa369d635c817875dbe32b5e5264926a15f\",\"title\":\"WARDS BETTER OPTIMIZATION\",\"url\":\"https://www.semanticscholar.org/paper/1d17baa369d635c817875dbe32b5e5264926a15f\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144560801\",\"name\":\"Wenzhong Guo\"},{\"authorId\":\"120465682\",\"name\":\"J. Wang\"},{\"authorId\":\"49183986\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/ACCESS.2019.2916887\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff\",\"title\":\"Deep Multimodal Representation Learning: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/c192c7d1d94e7a64de7e18e2f2fdffbf2909fcff\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Wei Zhang\"},{\"authorId\":\"48325104\",\"name\":\"Z. Bai\"},{\"authorId\":\"46758870\",\"name\":\"Y. Zhu\"}],\"doi\":\"10.1145/3330393.3330410\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cd0b66c3fdee9aebdb56d5998e955fd7cd5cd6a6\",\"title\":\"An Improved Approach Based on CNN-RNNs for Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cd0b66c3fdee9aebdb56d5998e955fd7cd5cd6a6\",\"venue\":\"ICMSSP 2019\",\"year\":2019},{\"arxivId\":\"1809.07041\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1007/978-3-030-01264-9_42\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"title\":\"Exploring Visual Relationship for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0000fcfd467a19cf0e59169c2f07d730a0f3a8b9\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"},{\"authorId\":\"2947553\",\"name\":\"S. Lo\\u00e1iciga\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"676eb5b297e644393defda035fff8cfe01e99de4\",\"title\":\"On Visual Coreference Chains Resolution\",\"url\":\"https://www.semanticscholar.org/paper/676eb5b297e644393defda035fff8cfe01e99de4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10773088\",\"name\":\"Somjit Nath\"},{\"authorId\":\"144237796\",\"name\":\"V. Liu\"},{\"authorId\":\"145483914\",\"name\":\"A. Chan\"},{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"145240145\",\"name\":\"Adam White\"},{\"authorId\":\"114860989\",\"name\":\"M. White\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0503c6822ca5a5706de16a112783bd8bddd95cc9\",\"title\":\"Training Recurrent Neural Networks Online by Learning Explicit State Variables\",\"url\":\"https://www.semanticscholar.org/paper/0503c6822ca5a5706de16a112783bd8bddd95cc9\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"title\":\"VisualNews : A Large Multi-source News Image Dataset\",\"url\":\"https://www.semanticscholar.org/paper/7e5bcdd0366c3ddd1579159595d1990f515cf93b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1805.08389\",\"authors\":[{\"authorId\":\"35585536\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"91956c41190231eefd2186f21b79d1ca1495a68e\",\"title\":\"Joint Image Captioning and Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/91956c41190231eefd2186f21b79d1ca1495a68e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145443283\",\"name\":\"A. Asadi\"},{\"authorId\":\"1682051\",\"name\":\"R. Safabakhsh\"}],\"doi\":\"10.1007/978-3-030-31756-0_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"title\":\"The Encoder-Decoder Framework and Its Applications\",\"url\":\"https://www.semanticscholar.org/paper/0e299ff8156d4c935f55edae12a1aa884de27e8a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48033092\",\"name\":\"X. Liu\"},{\"authorId\":\"116740128\",\"name\":\"Hongchen Tan\"},{\"authorId\":\"49144260\",\"name\":\"Xin Tong\"},{\"authorId\":\"1839803\",\"name\":\"J. Cao\"},{\"authorId\":\"13297323\",\"name\":\"Jun Zhou\"}],\"doi\":\"10.1016/J.NEUCOM.2019.07.063\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cfe9065ce9f22822607e82234551e0c5262ae394\",\"title\":\"Feature preserving GAN and multi-scale feature enhancement for domain adaption person Re-identification\",\"url\":\"https://www.semanticscholar.org/paper/cfe9065ce9f22822607e82234551e0c5262ae394\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/CVPR.2019.00427\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"title\":\"Cross-Modal Relationship Inference for Grounding Referring Expressions\",\"url\":\"https://www.semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145471480\",\"name\":\"Yunmeng Feng\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46446912\",\"name\":\"X. Zhang\"},{\"authorId\":\"7521170\",\"name\":\"Chuanfu Xu\"},{\"authorId\":\"2243533\",\"name\":\"Zhenghua Wang\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1145/3302425.3302464\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"title\":\"AttResNet: Attention-based ResNet for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/11a8cc3fa18ab4f7158447cc1fc8800489e82f9c\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35351918\",\"name\":\"Vien Gia An\"},{\"authorId\":\"115252570\",\"name\":\"Hyunkook Park\"},{\"authorId\":\"1699113\",\"name\":\"C. Lee\"}],\"doi\":\"10.1109/CVPRW50498.2020.00243\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"341a7d06756f9a2586cff28f3178fc0260412ef6\",\"title\":\"Dual-domain Deep Convolutional Neural Networks for Image Demoireing\",\"url\":\"https://www.semanticscholar.org/paper/341a7d06756f9a2586cff28f3178fc0260412ef6\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49418270\",\"name\":\"Yong Wang\"},{\"authorId\":\"1485232293\",\"name\":\"Wenkai Zhang\"},{\"authorId\":\"47362549\",\"name\":\"Qing Liu\"},{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"11732382\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1145/3394171.3413877\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"title\":\"Improving Intra- and Inter-Modality Visual Relation for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a05a96d5d9bac88d7c8b34be2e57f58f17a6e53d\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1902.07864\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1606411716\",\"name\":\"Karan Desai\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cef77310f326bd30b172459dbecaedf228fc7b23\",\"title\":\"Probabilistic Neural-symbolic Models for Interpretable Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/cef77310f326bd30b172459dbecaedf228fc7b23\",\"venue\":\"ICML\",\"year\":2019},{\"arxivId\":\"1909.03409\",\"authors\":[{\"authorId\":\"145066132\",\"name\":\"Bin Guo\"},{\"authorId\":null,\"name\":\"Hao Wang\"},{\"authorId\":\"151260226\",\"name\":\"Y. Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Y. Sun\"},{\"authorId\":\"2256618\",\"name\":\"Z. Yu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"title\":\"c-TextGen: Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/4cd7ce0d1ad83b2afbc2468d5d43ff8de0d9ae28\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.04464\",\"authors\":[{\"authorId\":\"3144952\",\"name\":\"Sibei Yang\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"66616425\",\"name\":\"Yizhou Yu\"}],\"doi\":\"10.1109/tpami.2020.2973983\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14204fd579ad2802490a8f4a781392ca7ba19c80\",\"title\":\"Relationship-Embedded Representation Learning for Grounding Referring Expressions.\",\"url\":\"https://www.semanticscholar.org/paper/14204fd579ad2802490a8f4a781392ca7ba19c80\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":\"1812.06164\",\"authors\":[{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"3325894\",\"name\":\"M. Drozdzal\"},{\"authorId\":\"1398090762\",\"name\":\"Xavier Gir\\u00f3-i-Nieto\"},{\"authorId\":\"144290131\",\"name\":\"A. Romero\"}],\"doi\":\"10.1109/CVPR.2019.01070\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"7ab155f8f532a238bc29e054b498a6945c157ace\",\"title\":\"Inverse Cooking: Recipe Generation From Food Images\",\"url\":\"https://www.semanticscholar.org/paper/7ab155f8f532a238bc29e054b498a6945c157ace\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1406233003\",\"name\":\"Yangyang Ye\"},{\"authorId\":\"145409873\",\"name\":\"C. Zhang\"},{\"authorId\":\"50017797\",\"name\":\"X. Hao\"}],\"doi\":\"10.1007/s11432-019-2636-x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cdf16f77a1bf028ed35e687e8997918c3086d233\",\"title\":\"ARPNET: attention region proposal network for 3D object detection\",\"url\":\"https://www.semanticscholar.org/paper/cdf16f77a1bf028ed35e687e8997918c3086d233\",\"venue\":\"Science China Information Sciences\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144364295\",\"name\":\"M. Chen\"},{\"authorId\":\"2367491\",\"name\":\"Y. Li\"},{\"authorId\":\"1720488\",\"name\":\"Zhongfei Zhang\"},{\"authorId\":\"48669017\",\"name\":\"Siyu Huang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"title\":\"TVT: Two-View Transformer Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2c3c72fffcbbf66cbb649b64aa51199722140ad1\",\"venue\":\"ACML\",\"year\":2018},{\"arxivId\":\"2007.02517\",\"authors\":[{\"authorId\":\"32583496\",\"name\":\"Y. Fu\"},{\"authorId\":\"46999477\",\"name\":\"Tingting Liu\"},{\"authorId\":\"31933517\",\"name\":\"M. Gao\"},{\"authorId\":\"145031578\",\"name\":\"Aoying Zhou\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2395f4b80e54d4b93bf425e207aa6d2236dd5f0b\",\"title\":\"EDSL: An Encoder-Decoder Architecture with Symbol-Level Features for Printed Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2395f4b80e54d4b93bf425e207aa6d2236dd5f0b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145959949\",\"name\":\"J. Serrano\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"title\":\"Boosting image captioning with an attentional mechanism = Boosting image captioning using diverse beam search\",\"url\":\"https://www.semanticscholar.org/paper/e07f8a6b7d805b3622a584ec97a269d54a405e1d\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49770170\",\"name\":\"C. Xu\"},{\"authorId\":\"33538504\",\"name\":\"Gengming Zhu\"},{\"authorId\":\"40367854\",\"name\":\"Lixin Wang\"}],\"doi\":\"10.1145/3318299.3318375\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"798f1e5ca775fd0186c82786865859cebba52d84\",\"title\":\"Image Captioning Based on Automatic Constraint Loss\",\"url\":\"https://www.semanticscholar.org/paper/798f1e5ca775fd0186c82786865859cebba52d84\",\"venue\":\"ICMLC '19\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98482977\",\"name\":\"\\u0411\\u043e\\u0440\\u0438\\u0441\\u043e\\u0432 \\u0413\\u0435\\u043e\\u0440\\u0433\\u0438\\u0439 \\u0410\\u043b\\u0435\\u043a\\u0441\\u0430\\u043d\\u0434\\u0440\\u043e\\u0432\\u0438\\u0447\"},{\"authorId\":\"97625681\",\"name\":\"\\u0422\\u0438\\u0445\\u043e\\u043c\\u0438\\u0440\\u043e\\u0432\\u0430 \\u0422\\u0430\\u043c\\u0430\\u0440\\u0430 \\u041f\\u0435\\u0442\\u0440\\u043e\\u0432\\u043d\\u0430\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0de0cec214cf34d089a9fce9015256b63534cd08\",\"title\":\"\\u0417\\u0430\\u0434\\u0430\\u0447\\u0438 \\u0438 \\u043c\\u0435\\u0442\\u043e\\u0434\\u044b \\u0440\\u0435\\u0441\\u0443\\u0440\\u0441\\u043e\\u0441\\u0431\\u0435\\u0440\\u0435\\u0433\\u0430\\u044e\\u0449\\u0435\\u0439 \\u043e\\u043f\\u0442\\u0438\\u043c\\u0438\\u0437\\u0430\\u0446\\u0438\\u0438 \\u0432 \\u044d\\u043b\\u0435\\u043a\\u0442\\u0440\\u043e\\u044d\\u043d\\u0435\\u0440\\u0433\\u0435\\u0442\\u0438\\u0447\\u0435\\u0441\\u043a\\u043e\\u0439 \\u0441\\u0438\\u0441\\u0442\\u0435\\u043c\\u0435\",\"url\":\"https://www.semanticscholar.org/paper/0de0cec214cf34d089a9fce9015256b63534cd08\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49292427\",\"name\":\"B. Wang\"},{\"authorId\":\"3429418\",\"name\":\"Cun-gang Wang\"},{\"authorId\":\"47834797\",\"name\":\"Qian Zhang\"},{\"authorId\":\"1749725513\",\"name\":\"Ying Su\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"48615794\",\"name\":\"Yanyan Xu\"}],\"doi\":\"10.1109/ACCESS.2020.2999568\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"title\":\"Cross-Lingual Image Caption Generation Based on Visual Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/1fac7ac22af5db06edde0fbda2bc61a97c7c9625\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9708577\",\"name\":\"Zhengyuan Zhang\"},{\"authorId\":\"2987316\",\"name\":\"W. Zhang\"},{\"authorId\":\"2600667\",\"name\":\"W. Diao\"},{\"authorId\":\"1972876\",\"name\":\"Menglong Yan\"},{\"authorId\":\"143703146\",\"name\":\"X. Gao\"},{\"authorId\":\"9758599\",\"name\":\"Xi-an Sun\"}],\"doi\":\"10.1109/ACCESS.2019.2942154\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"9d706abc18828390fa0b809a2eb62e1e7688f159\",\"title\":\"VAA: Visual Aligning Attention Model for Remote Sensing Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9d706abc18828390fa0b809a2eb62e1e7688f159\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145318418\",\"name\":\"X. Ma\"},{\"authorId\":\"8180253\",\"name\":\"Bing-Kun Bao\"},{\"authorId\":\"8012449\",\"name\":\"Lingling Yao\"},{\"authorId\":\"48258806\",\"name\":\"C. Xu\"}],\"doi\":\"10.1109/ICIP.2019.8803561\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"83813c661c18dbca63ed8d8b1838f883fa6c4751\",\"title\":\"Multimodal Latent Factor Model with Language Constraint for Predicate Detection\",\"url\":\"https://www.semanticscholar.org/paper/83813c661c18dbca63ed8d8b1838f883fa6c4751\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1804472\",\"name\":\"H. Chen\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"}],\"doi\":null,\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"60af58a2435fe758fe9a172f2009efbb89584f58\",\"title\":\"Temporal-Difference Learning With Sampling Baseline for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/60af58a2435fe758fe9a172f2009efbb89584f58\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3226409\",\"name\":\"Y. Cao\"},{\"authorId\":\"3040905\",\"name\":\"Q. Wang\"},{\"authorId\":\"5380819\",\"name\":\"K. Huang\"},{\"authorId\":\"80083020\",\"name\":\"Rui Zhang\"}],\"doi\":\"10.1007/978-3-030-39431-8_1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ab374c50e061b84b7076181522b3684d2273337\",\"title\":\"Improving Image Caption Performance with Linguistic Context\",\"url\":\"https://www.semanticscholar.org/paper/3ab374c50e061b84b7076181522b3684d2273337\",\"venue\":\"BICS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"113519586\",\"name\":\"T. X. Dang\"},{\"authorId\":\"31704596\",\"name\":\"A. Oh\"},{\"authorId\":\"9483271\",\"name\":\"In-Seop Na\"},{\"authorId\":\"2183069\",\"name\":\"S. Kim\"}],\"doi\":\"10.1145/3310986.3311002\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"title\":\"The Role of Attention Mechanism and Multi-Feature in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eeb782dcf29651caca5a2bcb6019b54c3ddee1a0\",\"venue\":\"ICMLSC 2019\",\"year\":2019},{\"arxivId\":\"2008.07935\",\"authors\":[{\"authorId\":\"48269537\",\"name\":\"Ye Zhu\"},{\"authorId\":\"50118837\",\"name\":\"Y. Wu\"},{\"authorId\":\"91893932\",\"name\":\"Y. Yang\"},{\"authorId\":\"96519714\",\"name\":\"Yan Yan\"}],\"doi\":\"10.1007/978-3-030-58592-1_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"title\":\"Describing Unseen Videos via Multi-Modal Cooperative Dialog Agents\",\"url\":\"https://www.semanticscholar.org/paper/29ef96b859c2ec55b67fca6f2e59ac27a6bc2cb1\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2007.03877\",\"authors\":[{\"authorId\":\"1826472\",\"name\":\"Dooseop Choi\"},{\"authorId\":\"2197109\",\"name\":\"Seung-Jun Han\"},{\"authorId\":\"97999178\",\"name\":\"K. Min\"},{\"authorId\":\"51428464\",\"name\":\"Jeongdan Choi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10ad369ae7920f7305417bf26ba33b1b4490f462\",\"title\":\"PathGAN: Local Path Planning with Generative Adversarial Networks\",\"url\":\"https://www.semanticscholar.org/paper/10ad369ae7920f7305417bf26ba33b1b4490f462\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.10549\",\"authors\":[{\"authorId\":\"47336925\",\"name\":\"Ran Gu\"},{\"authorId\":\"2138754\",\"name\":\"G. Wang\"},{\"authorId\":\"145147423\",\"name\":\"Tao Song\"},{\"authorId\":\"1870003762\",\"name\":\"Rui Huang\"},{\"authorId\":\"2487903\",\"name\":\"M. Aertsen\"},{\"authorId\":\"1470694146\",\"name\":\"J. Deprest\"},{\"authorId\":\"50975019\",\"name\":\"S\\u00e9bastien Ourselin\"},{\"authorId\":\"12975639\",\"name\":\"T. Vercauteren\"},{\"authorId\":\"48692127\",\"name\":\"Shaoting Zhang\"}],\"doi\":\"10.1109/TMI.2020.3035253\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6b78b2cde7015539ecb0e4be4ee14ed021210753\",\"title\":\"CA-Net: Comprehensive Attention Convolutional Neural Networks for Explainable Medical Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/6b78b2cde7015539ecb0e4be4ee14ed021210753\",\"venue\":\"IEEE transactions on medical imaging\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"3374688\",\"name\":\"M. Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"},{\"authorId\":null,\"name\":\"Heng Liu\"},{\"authorId\":\"30631999\",\"name\":\"Donghu Deng\"}],\"doi\":\"10.1016/J.PATREC.2019.07.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"749f376d0addb83569fcc7536e46308abbb232d4\",\"title\":\"How much do cross-modal related semantics benefit image captioning by weighting attributes and re-ranking sentences?\",\"url\":\"https://www.semanticscholar.org/paper/749f376d0addb83569fcc7536e46308abbb232d4\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":\"1804.06786\",\"authors\":[{\"authorId\":\"2689239\",\"name\":\"Jack Hessel\"},{\"authorId\":\"1705700\",\"name\":\"David Mimno\"},{\"authorId\":\"145810617\",\"name\":\"Lillian Lee\"}],\"doi\":\"10.18653/v1/N18-1199\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d02bf4082850a667bf0b7b6205df1cf9c1899233\",\"title\":\"Quantifying the visual concreteness of words and topics in multimodal datasets\",\"url\":\"https://www.semanticscholar.org/paper/d02bf4082850a667bf0b7b6205df1cf9c1899233\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"2007.10662\",\"authors\":[{\"authorId\":\"69544685\",\"name\":\"Jie Wu\"},{\"authorId\":\"1765674\",\"name\":\"Tianshui Chen\"},{\"authorId\":\"1721715\",\"name\":\"Hefeng Wu\"},{\"authorId\":\"10665619\",\"name\":\"Z. Yang\"},{\"authorId\":\"1773818\",\"name\":\"Guangchun Luo\"},{\"authorId\":\"49478124\",\"name\":\"L. Lin\"}],\"doi\":\"10.1109/tmm.2020.3011317\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"title\":\"Fine-Grained Image Captioning with Global-Local Discriminative Objective\",\"url\":\"https://www.semanticscholar.org/paper/f0edc8eb2d2b53482faf34906dacf996bc4127f6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"},{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"}],\"doi\":\"10.1007/978-3-030-57983-8_17\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d8cbeae59ec7d54eabe34b2c143541d1fd7e7fe\",\"title\":\"Spatial Descriptions on a Functional-Geometric Spectrum: the Location of Objects\",\"url\":\"https://www.semanticscholar.org/paper/7d8cbeae59ec7d54eabe34b2c143541d1fd7e7fe\",\"venue\":\"Spatial Cognition\",\"year\":2020},{\"arxivId\":\"2012.07119\",\"authors\":[{\"authorId\":\"1500647323\",\"name\":\"Giang Dao\"},{\"authorId\":\"65756109\",\"name\":\"Minwoo Lee\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2f11a33dce7aea8bad599560ab20b88501eb206a\",\"title\":\"Demysifying Deep Neural Networks Through Interpretation: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/2f11a33dce7aea8bad599560ab20b88501eb206a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.01881\",\"authors\":[{\"authorId\":\"1443435125\",\"name\":\"Zhengcong Fei\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"03158341c61b8bfedc9ccd503610ab150678a7c1\",\"title\":\"Better Understanding Hierarchical Visual Relationship for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/03158341c61b8bfedc9ccd503610ab150678a7c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1805.07112\",\"authors\":[{\"authorId\":\"1828568\",\"name\":\"Chen Chen\"},{\"authorId\":\"39108991\",\"name\":\"Shuai Mu\"},{\"authorId\":\"1410650653\",\"name\":\"Wanpeng Xiao\"},{\"authorId\":\"1410066883\",\"name\":\"Zexiong Ye\"},{\"authorId\":\"1410052649\",\"name\":\"Liesi Wu\"},{\"authorId\":\"102396462\",\"name\":\"Fuming Ma\"},{\"authorId\":\"34974680\",\"name\":\"Q. Ju\"}],\"doi\":\"10.1609/aaai.v33i01.33018142\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"title\":\"Improving Image Captioning with Conditional Generative Adversarial Nets\",\"url\":\"https://www.semanticscholar.org/paper/0daa3a4118e00b9f63b2d014a16ff1bc3ca9ff7e\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153188145\",\"name\":\"J. Kim\"},{\"authorId\":\"143808231\",\"name\":\"Nikita Kitaev\"},{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1692756\",\"name\":\"B. Zhang\"},{\"authorId\":\"39402399\",\"name\":\"Yuandong Tian\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"144179578\",\"name\":\"D. Parikh\"}],\"doi\":\"10.18653/v1/P19-1651\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"title\":\"CoDraw: Collaborative Drawing as a Testbed for Grounded Goal-driven Communication\",\"url\":\"https://www.semanticscholar.org/paper/58641a3a4b4653b5d63e57dc6dfe3935b866d78f\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47591102\",\"name\":\"F. Chen\"},{\"authorId\":\"152566316\",\"name\":\"Songxian Xie\"},{\"authorId\":\"48570095\",\"name\":\"Xinyi Li\"},{\"authorId\":\"98482203\",\"name\":\"S. Li\"},{\"authorId\":\"1762106\",\"name\":\"Jintao Tang\"},{\"authorId\":\"1749687\",\"name\":\"Ting Wang\"}],\"doi\":\"10.1109/ICMEW.2019.00083\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"beaee074a9548022527c2a5a45a64861df7784ea\",\"title\":\"What Topics Do Images Say: A Neural Image Captioning Model with Topic Representation\",\"url\":\"https://www.semanticscholar.org/paper/beaee074a9548022527c2a5a45a64861df7784ea\",\"venue\":\"2019 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736468\",\"name\":\"L. Lefakis\"},{\"authorId\":\"2403712\",\"name\":\"A. Akbik\"},{\"authorId\":\"2742129\",\"name\":\"Roland Vollgraf\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d05a1c25c456489911bb3f0877082798269d0069\",\"title\":\"FEIDEGGER: A Multi-modal Corpus of Fashion Images and Descriptions in German\",\"url\":\"https://www.semanticscholar.org/paper/d05a1c25c456489911bb3f0877082798269d0069\",\"venue\":\"LREC\",\"year\":2018},{\"arxivId\":\"2008.04015\",\"authors\":[{\"authorId\":\"116740128\",\"name\":\"Hongchen Tan\"},{\"authorId\":\"48033092\",\"name\":\"X. Liu\"},{\"authorId\":\"120675386\",\"name\":\"Shengjing Tian\"},{\"authorId\":\"2207938\",\"name\":\"B. Yin\"},{\"authorId\":\"1503438566\",\"name\":\"Xin Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e1afb6a7f1e3be34a8fbc5b060f34c3946c678ad\",\"title\":\"MHSA-Net: Multi-Head Self-Attention Network for Occluded Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/e1afb6a7f1e3be34a8fbc5b060f34c3946c678ad\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.11004\",\"authors\":[{\"authorId\":\"2671321\",\"name\":\"L. Gao\"},{\"authorId\":\"1770664\",\"name\":\"X. Li\"},{\"authorId\":\"2346105\",\"name\":\"Jingkuan Song\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TPAMI.2019.2894139\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"title\":\"Hierarchical LSTMs with Adaptive Attention for Visual Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c0343f9cc5f16166bda83815812c4c71ab3258e3\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"50025928\",\"name\":\"Yuqian Li\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"49285626\",\"name\":\"An-An Liu\"}],\"doi\":\"10.1007/s11063-019-09997-5\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"title\":\"Hierarchical Deep Neural Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/65471c0f2a8ee941363ee009e81d450a1b0bbbf9\",\"venue\":\"Neural Processing Letters\",\"year\":2019},{\"arxivId\":\"2007.10055\",\"authors\":[{\"authorId\":\"9649426\",\"name\":\"F. Santos\"},{\"authorId\":\"144180187\",\"name\":\"H. Macedo\"},{\"authorId\":\"151228742\",\"name\":\"T. Bispo\"},{\"authorId\":\"2948325\",\"name\":\"C. Zanchettin\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"579cb4a90442e0370543c22d0aba92dd639899c0\",\"title\":\"Morphological Skip-Gram: Using morphological knowledge to improve word representation\",\"url\":\"https://www.semanticscholar.org/paper/579cb4a90442e0370543c22d0aba92dd639899c0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.01475\",\"authors\":[{\"authorId\":\"35570245\",\"name\":\"Ali Furkan Biten\"},{\"authorId\":\"51231577\",\"name\":\"Llu\\u00eds G\\u00f3mez\"},{\"authorId\":\"143823474\",\"name\":\"M. Rusi\\u00f1ol\"},{\"authorId\":\"1694974\",\"name\":\"Dimosthenis Karatzas\"}],\"doi\":\"10.1109/CVPR.2019.01275\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"908c6b1577a1f5309ae183daf2e24363039f22a8\",\"title\":\"Good News, Everyone! Context Driven Entity-Aware Captioning for News Images\",\"url\":\"https://www.semanticscholar.org/paper/908c6b1577a1f5309ae183daf2e24363039f22a8\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391190009\",\"name\":\"Lingbo Liu\"},{\"authorId\":\"153206528\",\"name\":\"Jiajie Zhen\"},{\"authorId\":\"144958813\",\"name\":\"Guanbin Li\"},{\"authorId\":\"145736603\",\"name\":\"G. Zhan\"},{\"authorId\":\"46456313\",\"name\":\"Liang Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e0149858cb78d0dd3a4db4db39636f5f5ba21dbe\",\"title\":\"ACFM: A Dynamic Spatial-Temporal Network for Traffic Prediction\",\"url\":\"https://www.semanticscholar.org/paper/e0149858cb78d0dd3a4db4db39636f5f5ba21dbe\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1808.08114\",\"authors\":[{\"authorId\":\"9952952\",\"name\":\"Jo Schlemper\"},{\"authorId\":\"2941969\",\"name\":\"O. Oktay\"},{\"authorId\":\"144932484\",\"name\":\"M. Schaap\"},{\"authorId\":\"1825371\",\"name\":\"M. Heinrich\"},{\"authorId\":\"2015193\",\"name\":\"Bernhard Kainz\"},{\"authorId\":\"1709824\",\"name\":\"Ben Glocker\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"}],\"doi\":\"10.1016/j.media.2019.01.012\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2a2bdf5cf0d73bc333423a8fd246593f4bf65322\",\"title\":\"Attention gated networks: Learning to leverage salient regions in medical images\",\"url\":\"https://www.semanticscholar.org/paper/2a2bdf5cf0d73bc333423a8fd246593f4bf65322\",\"venue\":\"Medical Image Anal.\",\"year\":2019},{\"arxivId\":\"1708.01336\",\"authors\":[{\"authorId\":\"144811744\",\"name\":\"L. Jiang\"},{\"authorId\":\"1915796\",\"name\":\"Junwei Liang\"},{\"authorId\":\"48749954\",\"name\":\"L. Cao\"},{\"authorId\":\"1944225\",\"name\":\"Yannis Kalantidis\"},{\"authorId\":\"3256430\",\"name\":\"Sachin Farfade\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ceac30061d8f7985987448f4712c49eeb98efad2\",\"title\":\"MemexQA: Visual Memex Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/ceac30061d8f7985987448f4712c49eeb98efad2\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66520980\",\"name\":\"Yasufumi Moriya\"},{\"authorId\":\"143723939\",\"name\":\"G. Jones\"}],\"doi\":\"10.1109/SLT.2018.8639551\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"628bbe92a4003b0ddf0d3df3aeee405603ddd128\",\"title\":\"LSTM Language Model Adaptation with Images and Titles for Multimedia Automatic Speech Recognition\",\"url\":\"https://www.semanticscholar.org/paper/628bbe92a4003b0ddf0d3df3aeee405603ddd128\",\"venue\":\"2018 IEEE Spoken Language Technology Workshop (SLT)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7843061\",\"name\":\"Gamaleldin F. Elsayed\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f302ce6172125f55b8efc5cdef2be2b36ddf9ba4\",\"title\":\"Soft attention is popular in models used for natural language tasks\",\"url\":\"https://www.semanticscholar.org/paper/f302ce6172125f55b8efc5cdef2be2b36ddf9ba4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"29461008\",\"name\":\"Lecheng Wang\"},{\"authorId\":\"51478887\",\"name\":\"Shizheng Qin\"},{\"authorId\":\"14565924\",\"name\":\"Meng-long Xu\"},{\"authorId\":\"97937527\",\"name\":\"Rui Zhang\"},{\"authorId\":\"1410674575\",\"name\":\"Lizhe Qi\"},{\"authorId\":\"50550297\",\"name\":\"W. Zhang\"}],\"doi\":\"10.1109/ROBIO49542.2019.8961449\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a70981ab7b4011b8f4e656e383685d8c3cd58c79\",\"title\":\"From Quick-draw To Story: A Story Generation System for Kids\\u2019 Robot\",\"url\":\"https://www.semanticscholar.org/paper/a70981ab7b4011b8f4e656e383685d8c3cd58c79\",\"venue\":\"2019 IEEE International Conference on Robotics and Biomimetics (ROBIO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"120897486\",\"name\":\"Anwen Hu\"},{\"authorId\":\"3009919\",\"name\":\"Shizhe Chen\"},{\"authorId\":\"143715671\",\"name\":\"Qin Jin\"}],\"doi\":\"10.1145/3394171.3413576\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"title\":\"ICECAP: Information Concentrated Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6c0abdf9a9c47e8ec2606b06a5324ec7d2e7ebe7\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1909.02489\",\"authors\":[{\"authorId\":\"47748186\",\"name\":\"Wei Wei\"},{\"authorId\":\"144996789\",\"name\":\"L. Cheng\"},{\"authorId\":\"2089102\",\"name\":\"X. Mao\"},{\"authorId\":\"143652253\",\"name\":\"G. Zhou\"},{\"authorId\":\"143663410\",\"name\":\"F. Zhu\"}],\"doi\":\"10.1109/ACCESS.2020.3018752\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"title\":\"Stack-VS: Stacked Visual-Semantic Attention for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/b1e8e509a62c424055ffc050dc7cb41329674ea9\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144469308\",\"name\":\"Jian Wang\"},{\"authorId\":\"145534714\",\"name\":\"Jie Feng\"}],\"doi\":\"10.1109/ACCESS.2020.3018546\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"123361e4769f2f8a17742197aa52cc676a4caa9a\",\"title\":\"Hybrid Attention Distribution and Factorized Embedding Matrix in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/123361e4769f2f8a17742197aa52cc676a4caa9a\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3158336\",\"name\":\"Aroma Mahendru\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"title\":\"Role of Premises in Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e973243bf6d4b8bd56f210ba490a26e7946c5b1f\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1921534\",\"name\":\"Philip Kinghorn\"},{\"authorId\":\"41204462\",\"name\":\"L. Zhang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"}],\"doi\":\"10.1016/j.neucom.2017.07.014\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"title\":\"A region-based image caption generator with refined descriptions\",\"url\":\"https://www.semanticscholar.org/paper/6acb911d57720367d1ae7b9bce8ab9f9dcd9aadb\",\"venue\":\"Neurocomputing\",\"year\":2018},{\"arxivId\":\"1709.08693\",\"authors\":[{\"authorId\":\"48670486\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":\"28969396\",\"name\":\"C. Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"title\":\"Can you fool AI with adversarial examples on a visual Turing test?\",\"url\":\"https://www.semanticscholar.org/paper/dda1822872942f658b89e7e1c1ffe08c35e7b290\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"49933533\",\"name\":\"Jing Yun\"},{\"authorId\":\"48559698\",\"name\":\"Zhiwei Xu\"},{\"authorId\":\"1807620\",\"name\":\"Guanglai Gao\"}],\"doi\":\"10.1155/2020/9562587\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8a20a9b1345d8919b692f7f7fe919937bf823358\",\"title\":\"Gated Object-Attribute Matching Network for Detailed Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/8a20a9b1345d8919b692f7f7fe919937bf823358\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47859297\",\"name\":\"D. Wang\"},{\"authorId\":\"143984297\",\"name\":\"Daniel Beck\"},{\"authorId\":\"143620680\",\"name\":\"Trevor Cohn\"}],\"doi\":\"10.18653/v1/D19-6405\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"93447c939657029b6305053599f51e78ba8a4c3d\",\"title\":\"On the Role of Scene Graphs in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/93447c939657029b6305053599f51e78ba8a4c3d\",\"venue\":\"LANTERN@EMNLP-IJCNLP\",\"year\":2019},{\"arxivId\":\"1812.03283\",\"authors\":[{\"authorId\":\"4760298\",\"name\":\"J. Du\"},{\"authorId\":\"144485517\",\"name\":\"Yu Qin\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b75163ef32d63ba076e94d9321442ca8223fcd4\",\"title\":\"Attend More Times for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0b75163ef32d63ba076e94d9321442ca8223fcd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145441561\",\"name\":\"W. Cui\"},{\"authorId\":\"49451360\",\"name\":\"Fei Wang\"},{\"authorId\":\"144258396\",\"name\":\"X. He\"},{\"authorId\":\"29090447\",\"name\":\"D. Zhang\"},{\"authorId\":\"122135929\",\"name\":\"Xuxiang Xu\"},{\"authorId\":\"144817588\",\"name\":\"Meng Yao\"},{\"authorId\":\"72682876\",\"name\":\"Z. Wang\"},{\"authorId\":\"1955707\",\"name\":\"Jiejun Huang\"}],\"doi\":\"10.3390/RS11091044\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"75b0a1264b5ba0202ee3e81b89d7e9f0042c3744\",\"title\":\"Multi-Scale Semantic Segmentation and Spatial Relationship Recognition of Remote Sensing Images Based on an Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/75b0a1264b5ba0202ee3e81b89d7e9f0042c3744\",\"venue\":\"Remote. Sens.\",\"year\":2019},{\"arxivId\":\"2001.06127\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"46585209\",\"name\":\"J. Wang\"},{\"authorId\":\"1765212\",\"name\":\"C. Hori\"},{\"authorId\":\"34749896\",\"name\":\"T. Marks\"}],\"doi\":\"10.1109/WACV45572.2020.9093291\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e73fa178f729097428059af13b916275c7e92331\",\"title\":\"Spatio-Temporal Ranked-Attention Networks for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e73fa178f729097428059af13b916275c7e92331\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152673712\",\"name\":\"Youming Gao\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"47362529\",\"name\":\"T. Xu\"},{\"authorId\":\"1965723\",\"name\":\"Y. Xu\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-30508-6_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"title\":\"Referring Expression Comprehension via Co-attention and Visual Context\",\"url\":\"https://www.semanticscholar.org/paper/accdbb3b851357e4bc412442ddaf43945a60eb4b\",\"venue\":\"ICANN\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2933400\",\"name\":\"Jurgis Skilters\"},{\"authorId\":\"1798058\",\"name\":\"N. Newcombe\"},{\"authorId\":\"70514916\",\"name\":\"David Uttal\"}],\"doi\":\"10.1007/978-3-030-57983-8\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"267c6cf5e0e2952ac74b5df4ad58266392fd9e1e\",\"title\":\"Spatial Cognition XII: 12th International Conference, Spatial Cognition 2020, Riga, Latvia, August 26\\u201328, 2020, Proceedings\",\"url\":\"https://www.semanticscholar.org/paper/267c6cf5e0e2952ac74b5df4ad58266392fd9e1e\",\"venue\":\"Spatial Cognition\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36251013\",\"name\":\"Wei Li\"},{\"authorId\":\"20412557\",\"name\":\"Dashan Guo\"},{\"authorId\":\"1706164\",\"name\":\"X. Fang\"}],\"doi\":\"10.1016/j.patrec.2017.10.012\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ba881ec9ed2b435468ba6bbdc1821bde7778417\",\"title\":\"Multimodal architecture for video captioning with memory networks and an attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/0ba881ec9ed2b435468ba6bbdc1821bde7778417\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2018},{\"arxivId\":\"1803.08842\",\"authors\":[{\"authorId\":\"34777509\",\"name\":\"Yapeng Tian\"},{\"authorId\":\"145458657\",\"name\":\"Jing Shi\"},{\"authorId\":\"2868721\",\"name\":\"Bochen Li\"},{\"authorId\":\"3270912\",\"name\":\"Z. Duan\"},{\"authorId\":\"2026123\",\"name\":\"Chenliang Xu\"}],\"doi\":\"10.1007/978-3-030-01216-8_16\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"title\":\"Audio-Visual Event Localization in Unconstrained Videos\",\"url\":\"https://www.semanticscholar.org/paper/a5e58ef7c11515847967019fbe01fa033d9bdd88\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1805.07526\",\"authors\":[{\"authorId\":\"3418794\",\"name\":\"Kuan Han\"},{\"authorId\":\"4431043\",\"name\":\"Haiguang Wen\"},{\"authorId\":\"3334748\",\"name\":\"Y. Zhang\"},{\"authorId\":\"40360280\",\"name\":\"Di Fu\"},{\"authorId\":\"2889774\",\"name\":\"E. Culurciello\"},{\"authorId\":\"1799110\",\"name\":\"Z. Liu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a3d8122c8c470b2f7b81d97145b75330d8949cfb\",\"title\":\"Deep Predictive Coding Network with Local Recurrent Processing for Object Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a3d8122c8c470b2f7b81d97145b75330d8949cfb\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"11833187\",\"name\":\"Yaoxiong Huang\"},{\"authorId\":\"49109969\",\"name\":\"Mengchao He\"},{\"authorId\":\"144838978\",\"name\":\"Lianwen Jin\"},{\"authorId\":null,\"name\":\"Yongpan Wang\"}],\"doi\":\"10.1007/978-3-030-58539-6_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dcd546b3a8475b9e7e4e67376fb196a23ed923a9\",\"title\":\"RD-GAN: Few/Zero-Shot Chinese Character Style Transfer via Radical Decomposition and Rendering\",\"url\":\"https://www.semanticscholar.org/paper/dcd546b3a8475b9e7e4e67376fb196a23ed923a9\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51907635\",\"name\":\"I. Khurram\"},{\"authorId\":\"1756409\",\"name\":\"M. M. Fraz\"},{\"authorId\":\"144398177\",\"name\":\"M. Shahzad\"}],\"doi\":\"10.1007/978-3-030-03801-4_37\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"96bbc92a5fe2794bc6741dbe1467cc2c7872de29\",\"title\":\"Detailed Sentence Generation Architecture for Image Semantics Description\",\"url\":\"https://www.semanticscholar.org/paper/96bbc92a5fe2794bc6741dbe1467cc2c7872de29\",\"venue\":\"ISVC\",\"year\":2018},{\"arxivId\":\"1801.10300\",\"authors\":[{\"authorId\":\"48149965\",\"name\":\"W. Lin\"},{\"authorId\":\"143672077\",\"name\":\"K. Chen\"},{\"authorId\":\"29837150\",\"name\":\"HungYueh Chiang\"},{\"authorId\":\"31871157\",\"name\":\"Winston Hsu\"}],\"doi\":\"10.1145/3184558.3186354\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9e1b3cf334aead8d2c29747f6ee7d1291dd83708\",\"title\":\"Netizen-Style Commenting on Fashion Photos: Dataset and Diversity Measures\",\"url\":\"https://www.semanticscholar.org/paper/9e1b3cf334aead8d2c29747f6ee7d1291dd83708\",\"venue\":\"WWW\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1620218253\",\"name\":\"Sruthy Manmadhan\"},{\"authorId\":\"30588803\",\"name\":\"Binsu C. Kovoor\"}],\"doi\":\"10.1007/s10462-020-09832-7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"667b88984df0c5c11ac07899ffb5509185abdf57\",\"title\":\"Visual question answering: a state-of-the-art review\",\"url\":\"https://www.semanticscholar.org/paper/667b88984df0c5c11ac07899ffb5509185abdf57\",\"venue\":\"Artificial Intelligence Review\",\"year\":2020},{\"arxivId\":\"1808.08732\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"1781885\",\"name\":\"Houfeng Wang\"},{\"authorId\":\"2511091\",\"name\":\"X. Sun\"}],\"doi\":\"10.18653/v1/D18-1013\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8968072ad12bcb96c513ae1c01abf6abdae810df\",\"title\":\"simNet: Stepwise Image-Topic Merging Network for Generating Detailed and Comprehensive Image Captions\",\"url\":\"https://www.semanticscholar.org/paper/8968072ad12bcb96c513ae1c01abf6abdae810df\",\"venue\":\"EMNLP\",\"year\":2018},{\"arxivId\":\"1706.01554\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145721096\",\"name\":\"A. Kannan\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"title\":\"Best of Both Worlds: Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model\",\"url\":\"https://www.semanticscholar.org/paper/8cdd241b474bf7b0632162403ac2a3c4799252ad\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2003.11743\",\"authors\":[{\"authorId\":\"1491233100\",\"name\":\"Pranav Agarwal\"},{\"authorId\":\"145086911\",\"name\":\"A. Betancourt\"},{\"authorId\":\"1594025086\",\"name\":\"V. Panagiotou\"},{\"authorId\":\"2251072\",\"name\":\"N. Rodr\\u00edguez\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b430a5384c82beb6102106fbea0a134425a08c23\",\"title\":\"Egoshots, an ego-vision life-logging dataset and semantic fidelity metric to evaluate diversity in image captioning models\",\"url\":\"https://www.semanticscholar.org/paper/b430a5384c82beb6102106fbea0a134425a08c23\",\"venue\":\"ICLR 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46307991\",\"name\":\"Liyan Chen\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"title\":\"Learning Latent Graph Representations for Relational VQA\",\"url\":\"https://www.semanticscholar.org/paper/6af347d516b1975bafa59abb34a0bfb2bb09b364\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1711.05345\",\"authors\":[{\"authorId\":\"2815804\",\"name\":\"Yu-An Chung\"},{\"authorId\":\"1706104\",\"name\":\"Hung-yi Lee\"},{\"authorId\":\"145898106\",\"name\":\"James R. Glass\"}],\"doi\":\"10.18653/v1/N18-1143\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bb567cf793a6c4df1a652489c5ce866fe044f0e5\",\"title\":\"Supervised and Unsupervised Transfer Learning for Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/bb567cf793a6c4df1a652489c5ce866fe044f0e5\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"117548227\",\"name\":\"Saloni Kalra\"},{\"authorId\":\"88872765\",\"name\":\"Alka Leekha\"}],\"doi\":\"10.1080/02522667.2020.1715602\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"title\":\"Survey of convolutional neural networks for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/117333afd2ce2d80dd195dc5c5087f1b2b6bebdc\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592290\",\"name\":\"R. Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"34739384\",\"name\":\"Jinsong Su\"}],\"doi\":\"10.1109/CVPR.2018.00146\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2115fe369b3a6b859c6992ba023d5c11b1689801\",\"title\":\"GroupCap: Group-Based Image Captioning with Structured Relevance and Diversity Constraints\",\"url\":\"https://www.semanticscholar.org/paper/2115fe369b3a6b859c6992ba023d5c11b1689801\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30978802\",\"name\":\"Brandon Cui\"},{\"authorId\":null,\"name\":\"Calvin Qi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"08a3043e30ff342f9a92b438646e05d3eeeef6f4\",\"title\":\"Survey Analysis of Machine Learning Methods for Natural Language Processing for MBTI Personality Type Prediction\",\"url\":\"https://www.semanticscholar.org/paper/08a3043e30ff342f9a92b438646e05d3eeeef6f4\",\"venue\":\"\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"97cf2d8581eb7ec0fcd2ead5410473d8440eb3a6\",\"title\":\"Supplementary Material for CVPR 2018 paper # 330\",\"url\":\"https://www.semanticscholar.org/paper/97cf2d8581eb7ec0fcd2ead5410473d8440eb3a6\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.05106\",\"authors\":[{\"authorId\":\"48310271\",\"name\":\"Sungmin Kang\"},{\"authorId\":\"145966306\",\"name\":\"David Keetae Park\"},{\"authorId\":\"14071669\",\"name\":\"Jaehyuk Chang\"},{\"authorId\":\"1795455\",\"name\":\"Jaegul Choo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"852be63894ca7fb948e14fdef8c086adb237da2d\",\"title\":\"Interpreting Models by Allowing to Ask\",\"url\":\"https://www.semanticscholar.org/paper/852be63894ca7fb948e14fdef8c086adb237da2d\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1811.12104\",\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"143973868\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"title\":\"Towards Human-Friendly Referring Expression Generation\",\"url\":\"https://www.semanticscholar.org/paper/3c5907ba6b921841a49e77632c14db64e4db4fd4\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134654394\",\"name\":\"Ren C. Luo\"},{\"authorId\":\"34373093\",\"name\":\"Yu-Ting Hsu\"},{\"authorId\":\"123191934\",\"name\":\"Yu-Cheng Wen\"},{\"authorId\":\"151486060\",\"name\":\"Huan-Jun Ye\"}],\"doi\":\"10.1109/ICPHYS.2019.8780171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f10ee8e986c7e1a3f85c28b3e34eb8d5ffcb14ae\",\"title\":\"Visual Image Caption Generation for Service Robotics and Industrial Applications\",\"url\":\"https://www.semanticscholar.org/paper/f10ee8e986c7e1a3f85c28b3e34eb8d5ffcb14ae\",\"venue\":\"2019 IEEE International Conference on Industrial Cyber Physical Systems (ICPS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145066124\",\"name\":\"Bin Guo\"},{\"authorId\":\"46506266\",\"name\":\"Haiying Wang\"},{\"authorId\":\"151260226\",\"name\":\"Yasan Ding\"},{\"authorId\":\"117889029\",\"name\":\"Shaoyang Hao\"},{\"authorId\":\"79953570\",\"name\":\"Yueqi Sun\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"title\":\"1 c-TextGen : Conditional Text Generation for Harmonious Human-Machine Interaction\",\"url\":\"https://www.semanticscholar.org/paper/891082eb8ec9796d9e6041a93c2dfcf1654daf76\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144081629\",\"name\":\"Mario G\\u00f3mez Mart\\u00ednez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"faa8314259e9de1af8e841c265b0251531b32e04\",\"title\":\"Deep learning for image captioning: an encoder-decoder architecture with soft attention\",\"url\":\"https://www.semanticscholar.org/paper/faa8314259e9de1af8e841c265b0251531b32e04\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":\"50006507\",\"name\":\"Yanli Ji\"},{\"authorId\":\"145833207\",\"name\":\"Ning Xie\"},{\"authorId\":\"144618699\",\"name\":\"F. Shen\"}],\"doi\":\"10.1016/j.sigpro.2017.12.008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"title\":\"Recurrent attention network using spatial-temporal relations for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2ae9f14872520bb2926cfef2b670a5e9bc3870a5\",\"venue\":\"Signal Process.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3225210\",\"name\":\"Shaohan Hu\"},{\"authorId\":\"15634170\",\"name\":\"S. Huang\"},{\"authorId\":\"50248791\",\"name\":\"G. Wang\"},{\"authorId\":\"49969968\",\"name\":\"Zhipeng Li\"},{\"authorId\":\"145458349\",\"name\":\"Z. Qin\"}],\"doi\":\"10.1007/978-3-030-36802-9_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"797089139d87aeda56bee0b0374bee71521ae169\",\"title\":\"Delving into Precise Attention in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/797089139d87aeda56bee0b0374bee71521ae169\",\"venue\":\"ICONIP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"52150251\",\"name\":\"A. Goel\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"103192742\",\"name\":\"T. Nguyen\"},{\"authorId\":\"2518212\",\"name\":\"Hakan Bilen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"title\":\"Learning to Caption Images with Two-Stream Attention and Sentence Auto-Encoder\",\"url\":\"https://www.semanticscholar.org/paper/3d807fed82f61bc48aea76f191d2e19e2fc38f5d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48064309\",\"name\":\"L. Yang\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"150311018\",\"name\":\"Songlong Xing\"},{\"authorId\":\"150344317\",\"name\":\"Xinlong Lu\"}],\"doi\":\"10.1145/3386725\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1546133a67bfab09c64a9e2875266b1286ccab55\",\"title\":\"Constrained LSTM and Residual Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1546133a67bfab09c64a9e2875266b1286ccab55\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1993656298\",\"name\":\"Jingwen Hou\"},{\"authorId\":\"144545118\",\"name\":\"Sheng Yang\"},{\"authorId\":\"144968899\",\"name\":\"W. Lin\"}],\"doi\":\"10.1145/3394171.3413695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3be8cfb1299582b8ac6eca28350537c8b6f3777f\",\"title\":\"Object-level Attention for Aesthetic Rating Distribution Prediction\",\"url\":\"https://www.semanticscholar.org/paper/3be8cfb1299582b8ac6eca28350537c8b6f3777f\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4247049\",\"name\":\"Jingyu Liu\"},{\"authorId\":\"39685680\",\"name\":\"Wei Wang\"},{\"authorId\":\"144143335\",\"name\":\"L. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1109/TIP.2020.2979010\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"title\":\"Attribute-Guided Attention for Referring Expression Generation and Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/2d8e70022d5ee5cfd5a51f8d8bdba876ff6bda5f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"2009.03949\",\"authors\":[{\"authorId\":\"1699605396\",\"name\":\"Zeyu Wang\"},{\"authorId\":\"114200472\",\"name\":\"Berthy Feng\"},{\"authorId\":\"144958935\",\"name\":\"Karthik Narasimhan\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"}],\"doi\":\"10.1007/978-3-030-58571-6_37\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81be56a5783552d5b32463b392ff0499dd86a5ab\",\"title\":\"Towards Unique and Informative Captioning of Images\",\"url\":\"https://www.semanticscholar.org/paper/81be56a5783552d5b32463b392ff0499dd86a5ab\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145522783\",\"name\":\"Z. Sun\"},{\"authorId\":\"144361839\",\"name\":\"X. Lin\"},{\"authorId\":\"50218964\",\"name\":\"Zhaohui Wang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00767-6_19\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8b600d520f95b811857052d864ee54567064dd9\",\"title\":\"Multi-decoder Based Co-attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b8b600d520f95b811857052d864ee54567064dd9\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"2002.06436\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"title\":\"MRRC: Multiple Role Representation Crossover Interpretation for Image Captioning With R-CNN Feature Distribution Composition (FDC)\",\"url\":\"https://www.semanticscholar.org/paper/4ad005019f7069a3aaff959fbaa657f2ef2143fc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51933789\",\"name\":\"N. Ilinykh\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"title\":\"When an Image Tells a Story: The Role of Visual and Semantic Information for Generating Paragraph Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/4a8a490f8d3a7414444289b8802052eae3ebbe0c\",\"venue\":\"INLG\",\"year\":2020},{\"arxivId\":\"2010.03855\",\"authors\":[{\"authorId\":\"40622539\",\"name\":\"Dong-Jin Kim\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"49331178\",\"name\":\"Jinsoo Choi\"},{\"authorId\":\"145017149\",\"name\":\"In So Kweon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"title\":\"Dense Relational Image Captioning via Multi-task Triple-Stream Networks\",\"url\":\"https://www.semanticscholar.org/paper/0bda89ebb8cbec54afb013349c97a8264b36fee0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.11479\",\"authors\":[{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5388388db25f0d40ef6612333a0279373f8dddcf\",\"title\":\"TSP: Temporally-Sensitive Pretraining of Video Encoders for Localization Tasks\",\"url\":\"https://www.semanticscholar.org/paper/5388388db25f0d40ef6612333a0279373f8dddcf\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1908.03067\",\"authors\":[{\"authorId\":\"8093340\",\"name\":\"Shuming Ma\"},{\"authorId\":\"46709826\",\"name\":\"Pengcheng Yang\"},{\"authorId\":\"1701889\",\"name\":\"Tianyu Liu\"},{\"authorId\":\"144326610\",\"name\":\"Peng Li\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.18653/v1/P19-1197\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"924ea1528b555ddfbfe6167f8fd18fd0e8b36479\",\"title\":\"Key Fact as Pivot: A Two-Stage Model for Low Resource Table-to-Text Generation\",\"url\":\"https://www.semanticscholar.org/paper/924ea1528b555ddfbfe6167f8fd18fd0e8b36479\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1812.02378\",\"authors\":[{\"authorId\":\"47008946\",\"name\":\"X. Yang\"},{\"authorId\":\"10817432\",\"name\":\"Kaihua Tang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1688642\",\"name\":\"J. Cai\"}],\"doi\":\"10.1109/CVPR.2019.01094\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"title\":\"Auto-Encoding Scene Graphs for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1807.09986\",\"authors\":[{\"authorId\":\"2093119\",\"name\":\"W. Jiang\"},{\"authorId\":\"145698310\",\"name\":\"Lin Ma\"},{\"authorId\":\"1717861\",\"name\":\"Yu-Gang Jiang\"},{\"authorId\":\"46641573\",\"name\":\"W. Liu\"},{\"authorId\":\"38144094\",\"name\":\"T. Zhang\"}],\"doi\":\"10.1007/978-3-030-01216-8_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"title\":\"Recurrent Fusion Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/04cd9168dcf1a0d2cf01db95a1af53d0900bc346\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2002.11701\",\"authors\":[{\"authorId\":\"3233864\",\"name\":\"S. Biswal\"},{\"authorId\":\"47343720\",\"name\":\"Cao Xiao\"},{\"authorId\":\"28331874\",\"name\":\"Lucas Glass\"},{\"authorId\":\"144293787\",\"name\":\"M. Westover\"},{\"authorId\":\"1738536\",\"name\":\"Jimeng Sun\"}],\"doi\":\"10.1145/3366423.3380137\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a842fe8c25348627764462a57f0cd43d8cef103b\",\"title\":\"CLARA: Clinical Report Auto-completion\",\"url\":\"https://www.semanticscholar.org/paper/a842fe8c25348627764462a57f0cd43d8cef103b\",\"venue\":\"WWW\",\"year\":2020},{\"arxivId\":\"1911.03977\",\"authors\":[{\"authorId\":\"145282222\",\"name\":\"C. Zhang\"},{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718783\",\"name\":\"Li Deng\"}],\"doi\":\"10.1109/JSTSP.2020.2987728\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"title\":\"Multimodal Intelligence: Representation Learning, Information Fusion, and Applications\",\"url\":\"https://www.semanticscholar.org/paper/415efb7b4d9d1e5b64dbaf3fe4229ad462acce71\",\"venue\":\"IEEE Journal of Selected Topics in Signal Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696589727\",\"name\":\"Dongming Zhou\"},{\"authorId\":\"7924036\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"48708659\",\"name\":\"Zhiwen Wang\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206932\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"title\":\"Multi-level Visual Fusion Networks for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/a32ac0995afcbc748fa6533b941e9834ec7bfc2e\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47672526\",\"name\":\"Shiwei Wang\"},{\"authorId\":\"2410125\",\"name\":\"Long Lan\"},{\"authorId\":\"46447554\",\"name\":\"Xiaodong Zhang\"},{\"authorId\":\"48593034\",\"name\":\"Guohua Dong\"},{\"authorId\":\"145254061\",\"name\":\"Z. Luo\"}],\"doi\":\"10.1109/ACCESS.2019.2917979\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"title\":\"Cascade Semantic Fusion for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/c5a759bbf042fe8852f23567cf14daf3d9f180bc\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144654777\",\"name\":\"Ke Bai\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1700522\",\"name\":\"Guoyin Wang\"},{\"authorId\":\"49337256\",\"name\":\"W. Wang\"},{\"authorId\":\"51030446\",\"name\":\"R. Henao\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":\"10.1609/AAAI.V34I05.6249\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"826db2e5f340a90fc9672279f9e921b596aba4b7\",\"title\":\"Sequence Generation with Optimal-Transport-Enhanced Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/826db2e5f340a90fc9672279f9e921b596aba4b7\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47084642\",\"name\":\"Heng Song\"},{\"authorId\":\"1756644\",\"name\":\"Junwu Zhu\"},{\"authorId\":\"1591599792\",\"name\":\"Y. Jiang\"}],\"doi\":\"10.1016/j.compeleceng.2020.106630\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"title\":\"avtmNet: Adaptive Visual-Text Merging Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9835f38f6d3a8b964d53e78fa01e4490169b9169\",\"venue\":\"Comput. Electr. Eng.\",\"year\":2020},{\"arxivId\":\"1903.02499\",\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f9f1de36707a7c4885006554be09d16cf3fd6b4\",\"title\":\"A Synchronized Multi-Modal Attention-Caption Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3f9f1de36707a7c4885006554be09d16cf3fd6b4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1705.11160\",\"authors\":[{\"authorId\":\"143695288\",\"name\":\"J. Li\"},{\"authorId\":\"145490067\",\"name\":\"Muhua Zhu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1ada06eb9d7d8f757ccdd3ae6056492c88b62fa9\",\"title\":\"Learning When to Attend for Neural Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/1ada06eb9d7d8f757ccdd3ae6056492c88b62fa9\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2105743\",\"name\":\"Y. Bin\"},{\"authorId\":\"6897666\",\"name\":\"Yang Yang\"},{\"authorId\":null,\"name\":\"Jie Zhou\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1145/3123266.3123391\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"39836fbbcd2a664edb31119e88870c38b83df352\",\"title\":\"Adaptively Attending to Visual Attributes and Linguistic Knowledge for Captioning\",\"url\":\"https://www.semanticscholar.org/paper/39836fbbcd2a664edb31119e88870c38b83df352\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51288875\",\"name\":\"Y. Zhou\"},{\"authorId\":\"49941674\",\"name\":\"Zhenzhen Hu\"},{\"authorId\":\"3076466\",\"name\":\"X. Liu\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1007/978-3-030-00776-8_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee34a697bc114a5284025648fb9b49f9cdf5e343\",\"title\":\"Video Captioning Based on the Spatial-Temporal Saliency Tracing\",\"url\":\"https://www.semanticscholar.org/paper/ee34a697bc114a5284025648fb9b49f9cdf5e343\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":\"1704.06567\",\"authors\":[{\"authorId\":\"3448602\",\"name\":\"Jind\\u0159ich Libovick\\u00fd\"},{\"authorId\":\"46407634\",\"name\":\"Jind\\u0159ich Helcl\"}],\"doi\":\"10.18653/v1/P17-2031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e7dc0d6669d411849010a32ee75b49cf4c853f55\",\"title\":\"Attention Strategies for Multi-Source Sequence-to-Sequence Learning\",\"url\":\"https://www.semanticscholar.org/paper/e7dc0d6669d411849010a32ee75b49cf4c853f55\",\"venue\":\"ACL\",\"year\":2017},{\"arxivId\":\"1909.08611\",\"authors\":[{\"authorId\":\"26936326\",\"name\":\"Alexandros Stergiou\"},{\"authorId\":\"51463388\",\"name\":\"G. Kapidis\"},{\"authorId\":\"2358813\",\"name\":\"Grigorios Kalliatakis\"},{\"authorId\":\"49018286\",\"name\":\"C. Chrysoulas\"},{\"authorId\":\"1754666\",\"name\":\"R. Poppe\"},{\"authorId\":\"1739867\",\"name\":\"R. Veltkamp\"}],\"doi\":\"10.1109/ICCVW.2019.00524\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"title\":\"Class Feature Pyramids for Video Explanation\",\"url\":\"https://www.semanticscholar.org/paper/aaf75022b71fb0346b476ba1b8ad7ec9633d2f58\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7808048\",\"name\":\"M. Bucher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d423f37185a2210d5e47f24d4792e68d0088cd52\",\"title\":\"Apprentissage et exploitation de repr\\u00e9sentations s\\u00e9mantiques pour la classification et la recherche d'images. (Learning and exploiting semantic representations for image classification and retrieval)\",\"url\":\"https://www.semanticscholar.org/paper/d423f37185a2210d5e47f24d4792e68d0088cd52\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"134881509\",\"name\":\"Xiucong Shi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7e75b28c77c83b3281541b6b9a0222de615ab78b\",\"title\":\"Image Description Generation in Chinese Based on Keywords Guidance\",\"url\":\"https://www.semanticscholar.org/paper/7e75b28c77c83b3281541b6b9a0222de615ab78b\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1812.05252\",\"authors\":[{\"authorId\":\"144579865\",\"name\":\"P. Gao\"},{\"authorId\":\"47893312\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"30156979\",\"name\":\"Haoxuan You\"},{\"authorId\":\"50676465\",\"name\":\"Zhengkai Jiang\"},{\"authorId\":\"2887562\",\"name\":\"Pan Lu\"},{\"authorId\":\"49212307\",\"name\":\"Steven C. H. Hoi\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00680\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e9b13731027418ed38103d1dfc8a70f6881bc684\",\"title\":\"Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40235164\",\"name\":\"J. Wu\"},{\"authorId\":\"145030935\",\"name\":\"H. Hu\"},{\"authorId\":\"144084568\",\"name\":\"Yi Wu\"}],\"doi\":\"10.1145/3271485\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"744d79cfe0b38b2e674c7425dea67492d4f14807\",\"title\":\"Image Captioning via Semantic Guidance Attention and Consensus Selection Strategy\",\"url\":\"https://www.semanticscholar.org/paper/744d79cfe0b38b2e674c7425dea67492d4f14807\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2018},{\"arxivId\":\"1807.09958\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"50816334\",\"name\":\"D. Ye\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1007/978-3-030-01228-1_18\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"title\":\"Rethinking the Form of Latent States in Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/94e3b75a6732b5918c4c2b87d127a9216ff07efc\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"1901.02527\",\"authors\":[{\"authorId\":\"3422202\",\"name\":\"Dong Huk Park\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"17420047ab3c64ebbb63dcf21931d26fa77955d6\",\"title\":\"Viewpoint Invariant Change Captioning\",\"url\":\"https://www.semanticscholar.org/paper/17420047ab3c64ebbb63dcf21931d26fa77955d6\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2097029\",\"name\":\"J. Zhang\"},{\"authorId\":\"122700784\",\"name\":\"Zhaohui Tang\"},{\"authorId\":\"49291167\",\"name\":\"Yongfang Xie\"},{\"authorId\":\"46247410\",\"name\":\"M. Ai\"},{\"authorId\":\"145202887\",\"name\":\"W. Gui\"}],\"doi\":\"10.1016/j.mineng.2020.106332\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c40be90ac3125d7fcd8594bae9e3d8150c71d417\",\"title\":\"Convolutional memory network-based flotation performance monitoring\",\"url\":\"https://www.semanticscholar.org/paper/c40be90ac3125d7fcd8594bae9e3d8150c71d417\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3306838\",\"name\":\"Ruizhou Ding\"}],\"doi\":\"10.1184/R1/11933406.V1\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cb86d6febbd90ebc8aa52add7483e4e66452360f\",\"title\":\"Improving Efficiency and Accuracy for Training and Inference of Hardware-aware Machine Learning Systems\",\"url\":\"https://www.semanticscholar.org/paper/cb86d6febbd90ebc8aa52add7483e4e66452360f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1703.09137\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.1017/S1351324918000098\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"title\":\"Where to put the Image in an Image Caption Generator\",\"url\":\"https://www.semanticscholar.org/paper/6cc46899b415ebef4a70068b2cbd8a50e955aeb6\",\"venue\":\"Nat. Lang. Eng.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1862138\",\"name\":\"Dmitriy Serdyuk\"},{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6402703b62325865d00da1f58dbbcaf9a2bc417d\",\"title\":\"Twin Networks: Matching the Future for Sequence Generation\",\"url\":\"https://www.semanticscholar.org/paper/6402703b62325865d00da1f58dbbcaf9a2bc417d\",\"venue\":\"ICLR\",\"year\":2018},{\"arxivId\":\"1706.09789\",\"authors\":[{\"authorId\":\"145798491\",\"name\":\"D. Golub\"},{\"authorId\":\"2421691\",\"name\":\"Po-Sen Huang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"}],\"doi\":\"10.18653/v1/D17-1087\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be60cdc4f3202f44afdfb90bff005e3005dacf9a\",\"title\":\"Two-Stage Synthesis Networks for Transfer Learning in Machine Comprehension\",\"url\":\"https://www.semanticscholar.org/paper/be60cdc4f3202f44afdfb90bff005e3005dacf9a\",\"venue\":\"EMNLP\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2692833\",\"name\":\"Wenbin Che\"},{\"authorId\":\"1800904\",\"name\":\"X. Fan\"},{\"authorId\":\"145419122\",\"name\":\"R. Xiong\"},{\"authorId\":\"1725937\",\"name\":\"D. Zhao\"}],\"doi\":\"10.1145/3240508.3240695\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0931be61bde7706ad4c10c556495b72effaef820\",\"title\":\"Paragraph Generation Network with Visual Relationship Detection\",\"url\":\"https://www.semanticscholar.org/paper/0931be61bde7706ad4c10c556495b72effaef820\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":\"1910.03291\",\"authors\":[{\"authorId\":\"1387993874\",\"name\":\"Alireza Mohammadshahi\"},{\"authorId\":\"2875254\",\"name\":\"R\\u00e9mi Lebret\"},{\"authorId\":\"1751802\",\"name\":\"K. Aberer\"}],\"doi\":\"10.18653/v1/D19-6605\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2d880af464e477421e5cddc794e971c6db193b8c\",\"title\":\"Aligning Multilingual Word Embeddings for Cross-Modal Retrieval Task\",\"url\":\"https://www.semanticscholar.org/paper/2d880af464e477421e5cddc794e971c6db193b8c\",\"venue\":\"IJCNLP 2019\",\"year\":2019},{\"arxivId\":\"1908.07644\",\"authors\":[{\"authorId\":\"7843061\",\"name\":\"Gamaleldin F. Elsayed\"},{\"authorId\":\"40464924\",\"name\":\"Simon Kornblith\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ceddc94e4539763185003b924b6178dd8beef73\",\"title\":\"Saccader: Improving Accuracy of Hard Attention Models for Vision\",\"url\":\"https://www.semanticscholar.org/paper/7ceddc94e4539763185003b924b6178dd8beef73\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143602033\",\"name\":\"Anan Liu\"},{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"144536249\",\"name\":\"W. Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.24963/ijcai.2018/114\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"title\":\"Multi-Level Policy and Reward Reinforcement Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2b5a95ec7882bf329c4203513e606aa91d4174c5\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2932516\",\"name\":\"J. Zhang\"},{\"authorId\":\"1853471\",\"name\":\"K. Mei\"},{\"authorId\":\"1626610869\",\"name\":\"Yu Zheng\"},{\"authorId\":\"1692580\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1109/TMM.2020.2976552\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"title\":\"Integrating Part of Speech Guidance for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/27d838ae5a89cd54ef1cb6599484c794bd544ad9\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143905586\",\"name\":\"Cuirong Long\"},{\"authorId\":\"2059713\",\"name\":\"Xiaoshan Yang\"},{\"authorId\":\"145194969\",\"name\":\"C. Xu\"}],\"doi\":\"10.1007/s11042-019-7441-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f147a64982b25ea28a2b0737c68b0f65fdb46bd8\",\"title\":\"Cross-domain personalized image captioning\",\"url\":\"https://www.semanticscholar.org/paper/f147a64982b25ea28a2b0737c68b0f65fdb46bd8\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2019},{\"arxivId\":\"1911.10354\",\"authors\":[{\"authorId\":\"51215319\",\"name\":\"Kohei Uehara\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.18653/v1/2020.nlpbt-1.6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fc4598d636b599c4752a376cc074541c5a0ec97a\",\"title\":\"Unsupervised Keyword Extraction for Full-sentence VQA\",\"url\":\"https://www.semanticscholar.org/paper/fc4598d636b599c4752a376cc074541c5a0ec97a\",\"venue\":\"NLPBT\",\"year\":2020},{\"arxivId\":\"2007.09815\",\"authors\":[{\"authorId\":\"48096354\",\"name\":\"L. Zhao\"}],\"doi\":\"10.36227/techrxiv.12733049.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3ca50610e34cc8273bc946514afcfc99a0752a1c\",\"title\":\"Event Prediction in Big Data Era: A Systematic Survey\",\"url\":\"https://www.semanticscholar.org/paper/3ca50610e34cc8273bc946514afcfc99a0752a1c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.15454\",\"authors\":[{\"authorId\":null,\"name\":\"Wei-Ning Hsu\"},{\"authorId\":null,\"name\":\"David Harwath\"},{\"authorId\":null,\"name\":\"Christopher Song\"},{\"authorId\":\"152450847\",\"name\":\"J. Glass\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"title\":\"Text-Free Image-to-Speech Synthesis Using Learned Segmental Units\",\"url\":\"https://www.semanticscholar.org/paper/5df12460d9a742b08f82e8b79cb102a8be5dd9b4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5759455\",\"name\":\"Yabei Li\"},{\"authorId\":\"48805574\",\"name\":\"Zhang Zhang\"},{\"authorId\":\"49096898\",\"name\":\"Yanhua Cheng\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"},{\"authorId\":\"143874948\",\"name\":\"T. Tan\"}],\"doi\":\"10.1016/J.PATCOG.2019.02.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"663acb9d6cab09fdb3a6310cc00a2fc2b2d7721a\",\"title\":\"MAPNet: Multi-modal attentive pooling network for RGB-D indoor scene classification\",\"url\":\"https://www.semanticscholar.org/paper/663acb9d6cab09fdb3a6310cc00a2fc2b2d7721a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49896351\",\"name\":\"Wenjing Gao\"},{\"authorId\":\"1761546\",\"name\":\"Y. Zhu\"},{\"authorId\":\"39093337\",\"name\":\"Wenjun Zhang\"},{\"authorId\":\"46459368\",\"name\":\"Ke Zhang\"},{\"authorId\":\"7181355\",\"name\":\"Honghao Gao\"}],\"doi\":\"10.1111/coin.12202\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"39ad3d759bad5b3495f830c4102e17ecce62d033\",\"title\":\"A hierarchical recurrent approach to predict scene graphs from a visual\\u2010attention\\u2010oriented perspective\",\"url\":\"https://www.semanticscholar.org/paper/39ad3d759bad5b3495f830c4102e17ecce62d033\",\"venue\":\"Comput. Intell.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2795882\",\"name\":\"Samuel Humeau\"},{\"authorId\":null,\"name\":\"Hexiang Hu\"},{\"authorId\":\"1713934\",\"name\":\"Antoine Bordes\"},{\"authorId\":\"145183709\",\"name\":\"J. Weston\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"title\":\"ENGAGING IMAGE CAPTIONING\",\"url\":\"https://www.semanticscholar.org/paper/5c8ad080ccb3f5e3c999c2948029f0bd005d5635\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1811.08170\",\"authors\":[{\"authorId\":\"143900009\",\"name\":\"Lei Li\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":\"3049304\",\"name\":\"Youyi Zheng\"},{\"authorId\":\"1842335\",\"name\":\"Q. Su\"},{\"authorId\":\"3169698\",\"name\":\"Hongbo Fu\"},{\"authorId\":\"38705735\",\"name\":\"C. Tai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5619152331d49bde96ae9f51fffac931ca37a500\",\"title\":\"Sketch-R2CNN: An Attentive Network for Vector Sketch Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5619152331d49bde96ae9f51fffac931ca37a500\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1707.07998\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"31790073\",\"name\":\"C. Buehler\"},{\"authorId\":\"2406263\",\"name\":\"Damien Teney\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"39089563\",\"name\":\"Lei Zhang\"}],\"doi\":\"10.1109/CVPR.2018.00636\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"title\":\"Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/a82c1d1ccaa3a3d1d6ee6677de0eed2e93ddb6e8\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.02365\",\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48929163\",\"name\":\"Daqing Liu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"},{\"authorId\":\"144864336\",\"name\":\"F. Wu\"}],\"doi\":\"10.1109/TPAMI.2019.2909864\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"title\":\"Context-Aware Visual Policy Network for Fine-Grained Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/d0134f63879cedf3cdfe795bd2fd7c48d9554e4a\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":\"1906.06632\",\"authors\":[{\"authorId\":\"145859178\",\"name\":\"Jian Zheng\"},{\"authorId\":\"33770363\",\"name\":\"Sudha Krishnamurthy\"},{\"authorId\":\"3090152\",\"name\":\"Ruxin Chen\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"11004494\",\"name\":\"Zhenhao Ge\"},{\"authorId\":\"47056922\",\"name\":\"X. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"854a20d09da5e412dbaf41513d97dca2f67b647b\",\"title\":\"Image Captioning with Integrated Bottom-Up and Multi-level Residual Top-Down Attention for Game Scene Understanding\",\"url\":\"https://www.semanticscholar.org/paper/854a20d09da5e412dbaf41513d97dca2f67b647b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"53eaf8b796a6b658a450be6149f87220ac255988\",\"title\":\"Appendix : Probabilistic Neural-symbolic models for Interpretable Visual Question\",\"url\":\"https://www.semanticscholar.org/paper/53eaf8b796a6b658a450be6149f87220ac255988\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"145523338\",\"name\":\"Peng Yao\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1109/CVPR.2019.00433\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"title\":\"MSCap: Multi-Style Image Captioning With Unpaired Stylized Text\",\"url\":\"https://www.semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Xin Huang\"},{\"authorId\":\"51231229\",\"name\":\"Fengqi Yan\"},{\"authorId\":\"40515617\",\"name\":\"W. Xu\"},{\"authorId\":\"1716059\",\"name\":\"M. Li\"}],\"doi\":\"10.1109/ACCESS.2019.2947134\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"12e9fb63e5b46b241fed3ab2e9d95219db80e056\",\"title\":\"Multi-Attention and Incorporating Background Information Model for Chest X-Ray Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/12e9fb63e5b46b241fed3ab2e9d95219db80e056\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145857599\",\"name\":\"N. Xu\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"153152064\",\"name\":\"A. Liu\"},{\"authorId\":\"153576783\",\"name\":\"Weizhi Nie\"},{\"authorId\":\"2788104\",\"name\":\"Yuting Su\"},{\"authorId\":\"48693981\",\"name\":\"J. Nie\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1109/TMM.2019.2941820\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"aff890f20d28a13b9fb89d192fad35d92381c410\",\"title\":\"Multi-Level Policy and Reward-Based Deep Reinforcement Learning Framework for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/aff890f20d28a13b9fb89d192fad35d92381c410\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1901.06283\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"3272356\",\"name\":\"Yizhe Zhang\"},{\"authorId\":\"1940556\",\"name\":\"Ruiyi Zhang\"},{\"authorId\":\"46387857\",\"name\":\"Chenyang Tao\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"46701859\",\"name\":\"H. Zhang\"},{\"authorId\":null,\"name\":\"Bai Li\"},{\"authorId\":\"19178763\",\"name\":\"Dinghan Shen\"},{\"authorId\":\"2624978\",\"name\":\"C. Chen\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"717daba98eb57b898687fc013b705f763eb2916b\",\"title\":\"Improving Sequence-to-Sequence Learning via Optimal Transport\",\"url\":\"https://www.semanticscholar.org/paper/717daba98eb57b898687fc013b705f763eb2916b\",\"venue\":\"ICLR\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3242155\",\"name\":\"Libin Jiao\"},{\"authorId\":\"46477167\",\"name\":\"H. Wu\"},{\"authorId\":\"4853966\",\"name\":\"H. Wang\"},{\"authorId\":\"145149132\",\"name\":\"R. Bie\"}],\"doi\":\"10.1109/ACCESS.2018.2882592\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"e0f625ae421416c5c44df24ff89224562c0cdba3\",\"title\":\"Text Recovery via Deep CNN-BiLSTM Recognition and Bayesian Inference\",\"url\":\"https://www.semanticscholar.org/paper/e0f625ae421416c5c44df24ff89224562c0cdba3\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1736464\",\"name\":\"M. Khademi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"title\":\"Graph neural networks for multimodal learning and representation\",\"url\":\"https://www.semanticscholar.org/paper/4819ce65a0322a748c6d606d0678e8a0f78dafcc\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"101624195\",\"name\":\"David Betancourt\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"355e8f8228c648add36d165bc9f65fd9c320444e\",\"title\":\"Interval field for spatially and temporally dependent uncertainty\\u2013machine learning approach\",\"url\":\"https://www.semanticscholar.org/paper/355e8f8228c648add36d165bc9f65fd9c320444e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"121789307\",\"name\":\"W. Guo\"},{\"authorId\":\"32885778\",\"name\":\"Huaibo Huang\"},{\"authorId\":\"144496860\",\"name\":\"Xiangwei Kong\"},{\"authorId\":\"144282794\",\"name\":\"R. He\"}],\"doi\":\"10.1145/3343031.3351053\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"title\":\"Learning Disentangled Representation for Cross-Modal Retrieval with Deep Mutual Information Estimation\",\"url\":\"https://www.semanticscholar.org/paper/52dab186eabb9b4c0634dbccce515c7d73cbc5de\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1909.05693\",\"authors\":[{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"101377061\",\"name\":\"Zizhou Jia\"},{\"authorId\":\"144600412\",\"name\":\"H. Chen\"},{\"authorId\":\"2091623\",\"name\":\"L. Li\"},{\"authorId\":\"38329336\",\"name\":\"G. Ding\"},{\"authorId\":\"1732330\",\"name\":\"K. Keutzer\"}],\"doi\":\"10.1145/3343031.3351062\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12c258108ab59ef0189a6deb47222a99269da212\",\"title\":\"PDANet: Polarity-consistent Deep Attention Network for Fine-grained Visual Emotion Regression\",\"url\":\"https://www.semanticscholar.org/paper/12c258108ab59ef0189a6deb47222a99269da212\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1809.04835\",\"authors\":[{\"authorId\":\"3404500\",\"name\":\"Haichao Shi\"},{\"authorId\":\"144326612\",\"name\":\"P. Li\"},{\"authorId\":\"49292319\",\"name\":\"Bo Wang\"},{\"authorId\":\"2960930\",\"name\":\"Z. Wang\"}],\"doi\":\"10.1145/3240876.3240900\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dec04588b73efb1192d1778b2b818842ccd242e7\",\"title\":\"Image captioning based on deep reinforcement learning\",\"url\":\"https://www.semanticscholar.org/paper/dec04588b73efb1192d1778b2b818842ccd242e7\",\"venue\":\"ICIMCS '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3440249\",\"name\":\"Ruozi Huang\"},{\"authorId\":\"46353980\",\"name\":\"Huang Hu\"},{\"authorId\":\"145717875\",\"name\":\"Wei Wu\"},{\"authorId\":\"2505139\",\"name\":\"K. Sawada\"},{\"authorId\":\"144315664\",\"name\":\"Mi Zhang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b210d4594f19342ff625cf50d8d4bccfdc0d2ae5\",\"title\":\"Dance Revolution: Long Sequence Dance Generation with Music via Curriculum Learning\",\"url\":\"https://www.semanticscholar.org/paper/b210d4594f19342ff625cf50d8d4bccfdc0d2ae5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2009.14405\",\"authors\":[{\"authorId\":\"2458059\",\"name\":\"Y. Huang\"},{\"authorId\":\"47739902\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"title\":\"Teacher-Critical Training Strategies for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/6caaf71d18f093aebd0cffdcf246b86400092ab5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"98727476\",\"name\":\"Tsan-Hwei Huang\"},{\"authorId\":\"2024357948\",\"name\":\"Hunter Hsieh\"},{\"authorId\":\"2025282857\",\"name\":\"Jiaqi Qin\"},{\"authorId\":\"2024727250\",\"name\":\"Hsien-Fung Liu\"},{\"authorId\":\"2377003\",\"name\":\"M. Eirinaki\"}],\"doi\":\"10.1109/TransAI49837.2020.00008\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"title\":\"Play it again IMuCo! Music Composition to Match your Mood\",\"url\":\"https://www.semanticscholar.org/paper/30855a62d640c70429a81eec1b22bcc2a63c9c30\",\"venue\":\"2020 Second International Conference on Transdisciplinary AI (TransAI)\",\"year\":2020},{\"arxivId\":\"2012.07333\",\"authors\":[{\"authorId\":\"1733071048\",\"name\":\"Chao Zeng\"},{\"authorId\":\"1687386\",\"name\":\"S. Kwong\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d7212df671c50beb567e3d3d608b0c14405c40e3\",\"title\":\"Intrinsic Image Captioning Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/d7212df671c50beb567e3d3d608b0c14405c40e3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39054424\",\"name\":\"Min Gao\"},{\"authorId\":\"121685794\",\"name\":\"Xian-Hua Han\"},{\"authorId\":\"36190812\",\"name\":\"Jing Li\"},{\"authorId\":\"144562060\",\"name\":\"Hui Ji\"},{\"authorId\":\"2856513\",\"name\":\"Huaxiang Zhang\"},{\"authorId\":\"51299154\",\"name\":\"Jiande Sun\"}],\"doi\":\"10.1007/s11042-018-6751-5\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b737a81ff05e64e29596415c65dbc156e3481f95\",\"title\":\"Image super-resolution based on two-level residual learning CNN\",\"url\":\"https://www.semanticscholar.org/paper/b737a81ff05e64e29596415c65dbc156e3481f95\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1807.09434\",\"authors\":[{\"authorId\":\"2183432\",\"name\":\"Boeun Kim\"},{\"authorId\":\"49380412\",\"name\":\"Y. Lee\"},{\"authorId\":\"3011724\",\"name\":\"Hyedong Jung\"},{\"authorId\":\"2529532\",\"name\":\"C. S. Cho\"}],\"doi\":\"10.1007/978-3-030-11018-5_12\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"239a38663967140e026385f6625a913a3e7b1cd7\",\"title\":\"Distinctive-attribute Extraction for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/239a38663967140e026385f6625a913a3e7b1cd7\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40362315\",\"name\":\"J. Wang\"},{\"authorId\":\"1866977\",\"name\":\"Yiping Duan\"},{\"authorId\":\"144978572\",\"name\":\"X. Tao\"},{\"authorId\":\"47789939\",\"name\":\"J. Lu\"}],\"doi\":\"10.1109/ICC40277.2020.9149264\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3a5a6c759925570ab178c45340d34174fc8760f3\",\"title\":\"Local-to-Global Semantic Supervised Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3a5a6c759925570ab178c45340d34174fc8760f3\",\"venue\":\"ICC 2020 - 2020 IEEE International Conference on Communications (ICC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"50172036\",\"name\":\"X. Wu\"},{\"authorId\":\"1993634137\",\"name\":\"Shen Ge\"},{\"authorId\":\"47958349\",\"name\":\"X. Zhang\"},{\"authorId\":\"144934703\",\"name\":\"Wei Fan\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1145/3394171.3414004\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"title\":\"Bridging the Gap between Vision and Language Domains for Improved Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0f24a830cdacb07415f335784cd0a7e81eb42f3a\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1703.06029\",\"authors\":[{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"37895334\",\"name\":\"S. Fidler\"},{\"authorId\":\"2422559\",\"name\":\"R. Urtasun\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/ICCV.2017.323\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"title\":\"Towards Diverse and Natural Image Descriptions via a Conditional GAN\",\"url\":\"https://www.semanticscholar.org/paper/24dc571a49d3431e8cb1f1008f86d5dd5b7a1613\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2011.00927\",\"authors\":[{\"authorId\":\"2000125058\",\"name\":\"Feicheng Huang\"},{\"authorId\":\"144111674\",\"name\":\"Zhixin Li\"},{\"authorId\":\"92057141\",\"name\":\"H. Wei\"},{\"authorId\":\"104269832\",\"name\":\"Canlong Zhang\"},{\"authorId\":\"1998838209\",\"name\":\"Huifang Ma\"}],\"doi\":\"10.1007/s10994-020-05919-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"899b365ce70207f1fd456e982583841d9e4701bf\",\"title\":\"Boost Image Captioning with Knowledge Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/899b365ce70207f1fd456e982583841d9e4701bf\",\"venue\":\"Mach. Learn.\",\"year\":2020},{\"arxivId\":\"1908.02127\",\"authors\":[{\"authorId\":\"26982950\",\"name\":\"Longteng Guo\"},{\"authorId\":\"1749850\",\"name\":\"J. Liu\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"},{\"authorId\":\"49298906\",\"name\":\"Jiangwei Li\"},{\"authorId\":\"145851264\",\"name\":\"Wei Luo\"},{\"authorId\":\"46386029\",\"name\":\"H. Lu\"}],\"doi\":\"10.1145/3343031.3350943\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"133921bb5e559de464c0078f5fa67409aca27917\",\"title\":\"Aligning Linguistic Words and Visual Semantic Units for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/133921bb5e559de464c0078f5fa67409aca27917\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38889850\",\"name\":\"Pengfei Xia\"},{\"authorId\":\"50774917\",\"name\":\"Jingsong He\"},{\"authorId\":\"153781930\",\"name\":\"Jin Yin\"}],\"doi\":\"10.1007/s11042-020-09110-2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"title\":\"Boosting image caption generation with feature fusion module\",\"url\":\"https://www.semanticscholar.org/paper/17cefd99f2d04fc01663ba261d6afee54e8408d5\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2020},{\"arxivId\":\"2004.03708\",\"authors\":[{\"authorId\":\"80389349\",\"name\":\"Zhuowan Li\"},{\"authorId\":\"2536742\",\"name\":\"Quan Hung Tran\"},{\"authorId\":\"2712573\",\"name\":\"Long Mai\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":\"10.1109/CVPR42600.2020.00350\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"title\":\"Context-Aware Group Captioning via Self-Attention and Contrastive Features\",\"url\":\"https://www.semanticscholar.org/paper/477b70ed4753745e2700dd2791c3a5fb966f8b64\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"2004.12274\",\"authors\":[{\"authorId\":\"29860450\",\"name\":\"Baoyu Jing\"},{\"authorId\":\"1905077\",\"name\":\"Zeya Wang\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.18653/v1/P19-1657\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"title\":\"Show, Describe and Conclude: On Exploiting the Structure Information of Chest X-ray Reports\",\"url\":\"https://www.semanticscholar.org/paper/f08b8d6f2df54675c9b83fb115e63df763ea32fb\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":\"1708.00107\",\"authors\":[{\"authorId\":\"143775536\",\"name\":\"B. McCann\"},{\"authorId\":\"40518045\",\"name\":\"James Bradbury\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bc8fa64625d9189f5801837e7b133e7fe3c581f7\",\"title\":\"Learned in Translation: Contextualized Word Vectors\",\"url\":\"https://www.semanticscholar.org/paper/bc8fa64625d9189f5801837e7b133e7fe3c581f7\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48352212\",\"name\":\"Aming Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"7607499\",\"name\":\"Yezhou Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a7501eb6d58b1f347140402171df7b3291496ab2\",\"title\":\"Connective Cognition Network for Directional Visual Commonsense Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/a7501eb6d58b1f347140402171df7b3291496ab2\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1805.08298\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"e2a2818ec251d947acd9c74c2040337e656946bc\",\"title\":\"Hybrid Retrieval-Generation Reinforced Agent for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/e2a2818ec251d947acd9c74c2040337e656946bc\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1500399153\",\"name\":\"Burak Makav\"},{\"authorId\":\"3141085\",\"name\":\"V. K\\u0131l\\u0131\\u00e7\"}],\"doi\":\"10.23919/ELECO47770.2019.8990630\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94b442f133b1c11ccb6fb22affb797818745c4b7\",\"title\":\"A New Image Captioning Approach for Visually Impaired People\",\"url\":\"https://www.semanticscholar.org/paper/94b442f133b1c11ccb6fb22affb797818745c4b7\",\"venue\":\"2019 11th International Conference on Electrical and Electronics Engineering (ELECO)\",\"year\":2019},{\"arxivId\":\"1711.02326\",\"authors\":[{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"1996705\",\"name\":\"Anirudh Goyal\"},{\"authorId\":\"2361575\",\"name\":\"Olexa Bilaniuk\"},{\"authorId\":\"1737610\",\"name\":\"Jonathan Binas\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1e34c955e5a412c71c07c5d9ef03680fd4d5add\",\"title\":\"Sparse Attentive Backtracking: Long-Range Credit Assignment in Recurrent Networks\",\"url\":\"https://www.semanticscholar.org/paper/a1e34c955e5a412c71c07c5d9ef03680fd4d5add\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2001.11561\",\"authors\":[{\"authorId\":\"2373631\",\"name\":\"L. Ye\"},{\"authorId\":\"143962644\",\"name\":\"Zhi Liu\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1109/TMM.2020.2971171\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"28bd4e070c12b421db0f7b32438142038b82af53\",\"title\":\"Dual Convolutional LSTM Network for Referring Image Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/28bd4e070c12b421db0f7b32438142038b82af53\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":\"1906.05190\",\"authors\":[{\"authorId\":null,\"name\":\"Xin Li\"},{\"authorId\":\"145690873\",\"name\":\"R. Cao\"},{\"authorId\":\"39895985\",\"name\":\"D. Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f37eccaba2a370d60e32cc4daf179383265b6904\",\"title\":\"Vispi: Automatic Visual Perception and Interpretation of Chest X-rays\",\"url\":\"https://www.semanticscholar.org/paper/f37eccaba2a370d60e32cc4daf179383265b6904\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1806.04510\",\"authors\":[{\"authorId\":\"1411254465\",\"name\":\"V. AbelL.Peirson\"},{\"authorId\":\"9934480\",\"name\":\"E. Tolunay\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47ec091ba9d916e391c2f4e8ec36edcb59d104d6\",\"title\":\"Dank Learning: Generating Memes Using Deep Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/47ec091ba9d916e391c2f4e8ec36edcb59d104d6\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"940c90eb474cb2670559e03965b97a67eabd7a73\",\"title\":\"CODRAW: COLLABORATIVE DRAWING\",\"url\":\"https://www.semanticscholar.org/paper/940c90eb474cb2670559e03965b97a67eabd7a73\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.05709\",\"authors\":[{\"authorId\":\"2479987\",\"name\":\"L. Pineda\"},{\"authorId\":\"31571033\",\"name\":\"A. Salvador\"},{\"authorId\":\"3325894\",\"name\":\"M. Drozdzal\"},{\"authorId\":\"144290131\",\"name\":\"A. Romero\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a572d976738579dd2d05c44555f726fc7fb1330e\",\"title\":\"Elucidating image-to-set prediction: An analysis of models, losses and datasets\",\"url\":\"https://www.semanticscholar.org/paper/a572d976738579dd2d05c44555f726fc7fb1330e\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145361820\",\"name\":\"Y. Yao\"},{\"authorId\":\"49469052\",\"name\":\"X. Zhang\"},{\"authorId\":\"7576108\",\"name\":\"Baile Xu\"},{\"authorId\":\"71883949\",\"name\":\"Furao Shen\"},{\"authorId\":\"46509484\",\"name\":\"Jian Zhao\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0a10c5066ccf123528fb5eb7d129729b13fe5726\",\"title\":\"Super Interaction Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/0a10c5066ccf123528fb5eb7d129729b13fe5726\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471428747\",\"name\":\"Yang Zhen-yu\"},{\"authorId\":\"1471428729\",\"name\":\"Zhang Jiao\"}],\"doi\":\"10.1109/ICAIT.2019.8935913\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfa80ccf8530de52fe9ae4f617cdb57fa81f8f4c\",\"title\":\"Image Caption Method Combining Multi-angle with Multi-modality\",\"url\":\"https://www.semanticscholar.org/paper/bfa80ccf8530de52fe9ae4f617cdb57fa81f8f4c\",\"venue\":\"2019 IEEE 11th International Conference on Advanced Infocomm Technology (ICAIT)\",\"year\":2019},{\"arxivId\":\"1806.06004\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ceabd7ff28ce2d501511da998252aeb938adc98b\",\"title\":\"Partially-Supervised Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/ceabd7ff28ce2d501511da998252aeb938adc98b\",\"venue\":\"NeurIPS\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9455885\",\"name\":\"Ankit Rathi\"}],\"doi\":\"10.1109/ICCECE48148.2020.9223087\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a93629ec132628e86ff7ab6cd21099f5968d58bf\",\"title\":\"Deep learning apporach for image captioning in Hindi language\",\"url\":\"https://www.semanticscholar.org/paper/a93629ec132628e86ff7ab6cd21099f5968d58bf\",\"venue\":\"2020 International Conference on Computer, Electrical & Communication Engineering (ICCECE)\",\"year\":2020},{\"arxivId\":\"1804.05338\",\"authors\":[{\"authorId\":\"9952952\",\"name\":\"Jo Schlemper\"},{\"authorId\":\"2941969\",\"name\":\"O. Oktay\"},{\"authorId\":\"46308087\",\"name\":\"Liang Chen\"},{\"authorId\":\"33938383\",\"name\":\"J. Matthew\"},{\"authorId\":\"50693459\",\"name\":\"C. Knight\"},{\"authorId\":\"2015193\",\"name\":\"Bernhard Kainz\"},{\"authorId\":\"1709824\",\"name\":\"Ben Glocker\"},{\"authorId\":\"1717710\",\"name\":\"D. Rueckert\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f55cc2602a70d178ae8499c19d5bee80fa40133\",\"title\":\"Attention-Gated Networks for Improving Ultrasound Scan Plane Detection\",\"url\":\"https://www.semanticscholar.org/paper/2f55cc2602a70d178ae8499c19d5bee80fa40133\",\"venue\":\"MICCAI 2018\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145082091\",\"name\":\"Jianbo Zheng\"},{\"authorId\":\"1747615\",\"name\":\"Teng-Yok Lee\"},{\"authorId\":\"48931599\",\"name\":\"Chen Feng\"},{\"authorId\":\"113778242\",\"name\":\"Xiaohua Lit\"},{\"authorId\":\"7969330\",\"name\":\"Ziming Zhang\"}],\"doi\":\"10.1109/ICPR.2018.8545607\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d399b86d4c67472fd65e9466359a43ef2f914f97\",\"title\":\"Robust Attentional Pooling via Feature Selection\",\"url\":\"https://www.semanticscholar.org/paper/d399b86d4c67472fd65e9466359a43ef2f914f97\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2203994\",\"name\":\"Tengfei Xing\"},{\"authorId\":\"50218964\",\"name\":\"Zhaohui Wang\"},{\"authorId\":\"7788280\",\"name\":\"J. Yang\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"}],\"doi\":\"10.1007/978-3-030-00764-5_68\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2147e0ef8507e1a4880a916e46c27e15c11d65f4\",\"title\":\"Text to Region: Visual-Word Guided Saliency Detection\",\"url\":\"https://www.semanticscholar.org/paper/2147e0ef8507e1a4880a916e46c27e15c11d65f4\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49359942\",\"name\":\"C. Rupprecht\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9f931f3c70487e86c475fe18cfe16caf4f65d4e\",\"title\":\"Learning under Ambiguity through Multiple Predictions\",\"url\":\"https://www.semanticscholar.org/paper/d9f931f3c70487e86c475fe18cfe16caf4f65d4e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48902313\",\"name\":\"Wei Zhang\"},{\"authorId\":\"2053452\",\"name\":\"Ting Yao\"},{\"authorId\":\"2066429\",\"name\":\"Shiai Zhu\"},{\"authorId\":\"30889568\",\"name\":\"Abdulmotaleb El Saddik\"}],\"doi\":\"10.1145/3279952\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"title\":\"Deep Learning\\u2013Based Multimedia Analytics\",\"url\":\"https://www.semanticscholar.org/paper/bb9e418469d018be7f5ac2c4b2435ccac50088a3\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":\"1909.00692\",\"authors\":[{\"authorId\":\"35345881\",\"name\":\"S. N. Chowdhury\"},{\"authorId\":\"2499758\",\"name\":\"Simon Razniewski\"},{\"authorId\":\"1751591\",\"name\":\"G. Weikum\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"971bf8654232421843ba35e632c9602a5acdf341\",\"title\":\"Story-oriented Image Selection and Placement\",\"url\":\"https://www.semanticscholar.org/paper/971bf8654232421843ba35e632c9602a5acdf341\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1811.07662\",\"authors\":[{\"authorId\":\"47833739\",\"name\":\"Y. Zheng\"},{\"authorId\":\"2112160\",\"name\":\"Y. Li\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"}],\"doi\":\"10.1109/CVPR.2019.00859\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"23e943809c131c50dc90c1d308373febc60b9029\",\"title\":\"Intention Oriented Image Captions With Guiding Objects\",\"url\":\"https://www.semanticscholar.org/paper/23e943809c131c50dc90c1d308373febc60b9029\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1811.10652\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/CVPR.2019.00850\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8e59cf8c3becbedced0089028a1cddac8b19b251\",\"title\":\"Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions\",\"url\":\"https://www.semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1906.06619\",\"authors\":[{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"46397904\",\"name\":\"L. Fritz\"},{\"authorId\":\"36004650\",\"name\":\"Gabi Shalev\"},{\"authorId\":\"40135367\",\"name\":\"E. Oks\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7b4708bce76d496e0a1083d057cad6e1562a302d\",\"title\":\"Generating Diverse and Informative Natural Language Fashion Feedback\",\"url\":\"https://www.semanticscholar.org/paper/7b4708bce76d496e0a1083d057cad6e1562a302d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1908.01323\",\"authors\":[{\"authorId\":\"143707205\",\"name\":\"B. Ding\"},{\"authorId\":\"48015811\",\"name\":\"Chengjiang Long\"},{\"authorId\":\"13800342\",\"name\":\"L. Zhang\"},{\"authorId\":\"2420700\",\"name\":\"Chunxia Xiao\"}],\"doi\":\"10.1109/ICCV.2019.01031\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a1e9452b05457233e7761d36642dc8ca8a04dd8e\",\"title\":\"ARGAN: Attentive Recurrent Generative Adversarial Network for Shadow Detection and Removal\",\"url\":\"https://www.semanticscholar.org/paper/a1e9452b05457233e7761d36642dc8ca8a04dd8e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50987563\",\"name\":\"Sangmin Park\"},{\"authorId\":\"97243906\",\"name\":\"Young-gab Kim\"}],\"doi\":\"10.1016/j.inffus.2020.10.009\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"65dc69953ef141871f1701d68196aa278566fc16\",\"title\":\"Survey and challenges of story generation models - A multimodal perspective with five steps: Data embedding, topic modeling, storyline generation, draft story generation, and story evaluation\",\"url\":\"https://www.semanticscholar.org/paper/65dc69953ef141871f1701d68196aa278566fc16\",\"venue\":\"\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"92716077\",\"name\":\"Shaokang Yang\"},{\"authorId\":\"122218340\",\"name\":\"J. Niu\"},{\"authorId\":\"1809483\",\"name\":\"Jiyan Wu\"},{\"authorId\":\"37305311\",\"name\":\"X. Liu\"}],\"doi\":\"10.1007/978-3-030-60248-2_48\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"title\":\"Automatic Medical Image Report Generation with Multi-view and Multi-modal Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/c0e3f376cd8e08119a2f24821c667b7b9d6ec410\",\"venue\":\"ICA3PP\",\"year\":2020},{\"arxivId\":\"2007.00145\",\"authors\":[{\"authorId\":\"3381900\",\"name\":\"E. Dodds\"},{\"authorId\":\"31922487\",\"name\":\"J. Culpepper\"},{\"authorId\":\"80236158\",\"name\":\"Simao Herdade\"},{\"authorId\":\"29969244\",\"name\":\"Y. Zhang\"},{\"authorId\":\"145908678\",\"name\":\"K. Boakye\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e09df55b9aaf6e81b210815106d5ea075e3aaad0\",\"title\":\"Modality-Agnostic Attention Fusion for visual search with text feedback\",\"url\":\"https://www.semanticscholar.org/paper/e09df55b9aaf6e81b210815106d5ea075e3aaad0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.14744\",\"authors\":[{\"authorId\":\"50811121\",\"name\":\"Liqun Chen\"},{\"authorId\":\"144702900\",\"name\":\"Zhe Gan\"},{\"authorId\":\"5524736\",\"name\":\"Y. Cheng\"},{\"authorId\":\"50703697\",\"name\":\"Linjie Li\"},{\"authorId\":\"145006560\",\"name\":\"L. Carin\"},{\"authorId\":\"46700348\",\"name\":\"Jing-jing Liu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"title\":\"Graph Optimal Transport for Cross-Domain Alignment\",\"url\":\"https://www.semanticscholar.org/paper/2a8e5670a5ffdb72344f626ca06bb98a4a0209af\",\"venue\":\"ICML\",\"year\":2020},{\"arxivId\":\"2001.01037\",\"authors\":[{\"authorId\":\"46969089\",\"name\":\"J. Sun\"},{\"authorId\":\"3633358\",\"name\":\"S. Lapuschkin\"},{\"authorId\":\"1699054\",\"name\":\"W. Samek\"},{\"authorId\":\"49345823\",\"name\":\"Alexander Binder\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"82e836be97e706dca7029ce6a0553b4890726593\",\"title\":\"Understanding Image Captioning Models beyond Visualizing Attention\",\"url\":\"https://www.semanticscholar.org/paper/82e836be97e706dca7029ce6a0553b4890726593\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.01410\",\"authors\":[{\"authorId\":\"4332039\",\"name\":\"Guojun Yin\"},{\"authorId\":\"37145669\",\"name\":\"Lu Sheng\"},{\"authorId\":null,\"name\":\"Bin Liu\"},{\"authorId\":\"1708598\",\"name\":\"N. Yu\"},{\"authorId\":\"48631549\",\"name\":\"X. Wang\"},{\"authorId\":\"144478188\",\"name\":\"J. Shao\"}],\"doi\":\"10.1109/CVPR.2019.00640\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"title\":\"Context and Attribute Grounded Dense Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.08110\",\"authors\":[{\"authorId\":\"47904580\",\"name\":\"Yiyu Wang\"},{\"authorId\":\"2073589\",\"name\":\"Jungang Xu\"},{\"authorId\":\"46676156\",\"name\":\"Yingfei Sun\"},{\"authorId\":\"40368776\",\"name\":\"Ben He\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"title\":\"Image Captioning based on Deep Learning Methods: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/8ef4a09eb86e150b08a80d59c2c092d1a56be780\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2010.03743\",\"authors\":[{\"authorId\":\"13941532\",\"name\":\"Fuxiao Liu\"},{\"authorId\":null,\"name\":\"Yinghan Wang\"},{\"authorId\":\"1785372925\",\"name\":\"Tianlu Wang\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"title\":\"VisualNews : Benchmark and Challenges in Entity-aware Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/51f2eb8b16d132d3c403ed76d3ac816a8f58f25c\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9305072\",\"name\":\"Jifei Song\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1705408\",\"name\":\"Yi-Zhe Song\"},{\"authorId\":\"145406421\",\"name\":\"T. Xiang\"},{\"authorId\":\"1697755\",\"name\":\"Timothy M. Hospedales\"}],\"doi\":\"10.1109/ICCV.2017.592\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f1c808ed24684b734f137f8bb76524ddc5ed1b36\",\"title\":\"Deep Spatial-Semantic Attention for Fine-Grained Sketch-Based Image Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/f1c808ed24684b734f137f8bb76524ddc5ed1b36\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49386928\",\"name\":\"Y. Xue\"},{\"authorId\":\"39866461\",\"name\":\"T. Xu\"},{\"authorId\":\"145707661\",\"name\":\"L. Long\"},{\"authorId\":\"1726787\",\"name\":\"Zhiyun Xue\"},{\"authorId\":\"1721328\",\"name\":\"S. Antani\"},{\"authorId\":\"145116486\",\"name\":\"G. Thoma\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"}],\"doi\":\"10.1007/978-3-030-00928-1_52\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5173728c5e7f5f9c3d36a93232147a3fa19e54e\",\"title\":\"Multimodal Recurrent Model with Attention for Automated Radiology Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/a5173728c5e7f5f9c3d36a93232147a3fa19e54e\",\"venue\":\"MICCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"15862607\",\"name\":\"Xiaoliang Chu\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2037988\",\"name\":\"Weichen Sun\"},{\"authorId\":\"32324177\",\"name\":\"C. Wu\"}],\"doi\":\"10.3390/s18020646\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"title\":\"Social Image Captioning: Exploring Visual Attention and User Attention\",\"url\":\"https://www.semanticscholar.org/paper/e4b9c14951cea6259dd9d522586ba2c5bb1fbcce\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"1908.06954\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"46315174\",\"name\":\"Wenmin Wang\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"},{\"authorId\":\"144539992\",\"name\":\"Xiao-Yong Wei\"}],\"doi\":\"10.1109/ICCV.2019.00473\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c163d4942117179d3e97182e1b280027d7d60a9\",\"title\":\"Attention on Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/4c163d4942117179d3e97182e1b280027d7d60a9\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66353591\",\"name\":\"Amaia Salvador Aguilera\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"title\":\"Computer vision beyond the visible : image understanding through language\",\"url\":\"https://www.semanticscholar.org/paper/4cb1819c27e207a2afeccfe450b931cc317de1e1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8353931\",\"name\":\"Jiahe Shi\"},{\"authorId\":\"5550675\",\"name\":\"Y. Li\"},{\"authorId\":\"103307901\",\"name\":\"Shengjin Wang\"}],\"doi\":\"10.1109/ICIP.2019.8803149\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8c054cda5375018e902daab0b0875773a854d035\",\"title\":\"Cascade Attention: Multiple Feature Based Learning for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/8c054cda5375018e902daab0b0875773a854d035\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3071906\",\"name\":\"Anna Fariha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"001dc49f7f3348841b4086f966bfe4e9dfadf03e\",\"title\":\"Automatic image captioning using multi-task learning\",\"url\":\"https://www.semanticscholar.org/paper/001dc49f7f3348841b4086f966bfe4e9dfadf03e\",\"venue\":\"\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48283024\",\"name\":\"Xinghan Chen\"},{\"authorId\":\"145179162\",\"name\":\"Mingxing Zhang\"},{\"authorId\":\"48708844\",\"name\":\"Zheng Wang\"},{\"authorId\":\"144898145\",\"name\":\"Lin Zuo\"},{\"authorId\":\"92160187\",\"name\":\"Bo Li\"},{\"authorId\":\"46173234\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1016/J.PATREC.2018.12.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a74042d5da6eecf8929008f95c3becf4218a3cce\",\"title\":\"Leveraging unpaired out-of-domain data for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/a74042d5da6eecf8929008f95c3becf4218a3cce\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9119184\",\"name\":\"Huazhong Jin\"},{\"authorId\":\"48608098\",\"name\":\"Yuxia Wu\"},{\"authorId\":\"1510781142\",\"name\":\"Fang Wan\"},{\"authorId\":\"1510781771\",\"name\":\"M. Hu\"},{\"authorId\":\"40201664\",\"name\":\"Q. Li\"}],\"doi\":\"10.1117/12.2539338\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"cf4a051a57b7bd22ab0f416f162fc72d5640d17b\",\"title\":\"Image caption generation method based on adaptive attention mechanism\",\"url\":\"https://www.semanticscholar.org/paper/cf4a051a57b7bd22ab0f416f162fc72d5640d17b\",\"venue\":\"International Symposium on Multispectral Image Processing and Pattern Recognition\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"2598444\",\"name\":\"Chengjun Zhang\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1145/3319921.3319934\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1da9da475a471eacdb47a7f71d81cc3517188054\",\"title\":\"Reconstructing Attention with Dynamic Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1da9da475a471eacdb47a7f71d81cc3517188054\",\"venue\":\"ICIAI 2019\",\"year\":2019},{\"arxivId\":\"2005.11475\",\"authors\":[{\"authorId\":\"1713961937\",\"name\":\"Junxu Cao\"},{\"authorId\":\"1819450790\",\"name\":\"Qi Chen\"},{\"authorId\":\"145505204\",\"name\":\"J. Guo\"},{\"authorId\":\"1899368\",\"name\":\"Ruichao Shi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"bee737b3ab65b750dc5b00f6c8aa6d79c01079a2\",\"title\":\"Attention-guided Context Feature Pyramid Network for Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/bee737b3ab65b750dc5b00f6c8aa6d79c01079a2\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2005279478\",\"name\":\"Sreela Sreekumaran Pillai Remadevi Amma\"},{\"authorId\":\"1984257\",\"name\":\"S. M. Idicula\"}],\"doi\":\"10.25046/aj050447\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1226eeb9787b7555e810ee289c4593cb2da04775\",\"title\":\"Keyword Driven Image Description Generation System\",\"url\":\"https://www.semanticscholar.org/paper/1226eeb9787b7555e810ee289c4593cb2da04775\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1903.10122\",\"authors\":[{\"authorId\":\"46194597\",\"name\":\"C. Y. Li\"},{\"authorId\":\"40250403\",\"name\":\"Xiaodan Liang\"},{\"authorId\":\"2749311\",\"name\":\"Zhiting Hu\"},{\"authorId\":\"143977260\",\"name\":\"E. Xing\"}],\"doi\":\"10.1609/AAAI.V33I01.33016666\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"adc998ac4fa71bdab19537c50e3d84bf982974c1\",\"title\":\"Knowledge-driven Encode, Retrieve, Paraphrase for Medical Image Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/adc998ac4fa71bdab19537c50e3d84bf982974c1\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40912088\",\"name\":\"M. Tanaka\"},{\"authorId\":\"51491153\",\"name\":\"Takayuki Itamochi\"},{\"authorId\":\"3193466\",\"name\":\"K. Narioka\"},{\"authorId\":\"152599661\",\"name\":\"Ikuro Sato\"},{\"authorId\":\"3250559\",\"name\":\"Y. Ushiku\"},{\"authorId\":\"1790553\",\"name\":\"T. Harada\"}],\"doi\":\"10.1109/ICCV.2019.00589\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"949959250e487617faa3035b05b52aa03a8e9895\",\"title\":\"Generating Easy-to-Understand Referring Expressions for Target Identifications\",\"url\":\"https://www.semanticscholar.org/paper/949959250e487617faa3035b05b52aa03a8e9895\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48669970\",\"name\":\"X. Xu\"},{\"authorId\":\"2727656\",\"name\":\"X. Chen\"},{\"authorId\":null,\"name\":\"Chang Liu\"},{\"authorId\":\"34721166\",\"name\":\"Anna Rohrbach\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"},{\"authorId\":\"143711382\",\"name\":\"D. Song\"}],\"doi\":\"10.1109/CVPR.2018.00520\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"title\":\"Fooling Vision and Language Models Despite Localization and Attention Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/2fa9b32ebc329d57fa2e3fabb9e12382f019f47a\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1443736039\",\"name\":\"Yuki Mori\"},{\"authorId\":\"46362679\",\"name\":\"Hiroshi Fukui\"},{\"authorId\":\"134790239\",\"name\":\"Tsubasa Hirakawa\"},{\"authorId\":\"1443785402\",\"name\":\"Jo Nishiyama\"},{\"authorId\":\"1687819\",\"name\":\"T. Yamashita\"},{\"authorId\":\"1687968\",\"name\":\"H. Fujiyoshi\"}],\"doi\":\"10.1109/ITSC.2019.8917187\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b8fe7a6857906af4adb5b1e92d90279257811965\",\"title\":\"Attention Neural Baby Talk: Captioning of Risk Factors while Driving\",\"url\":\"https://www.semanticscholar.org/paper/b8fe7a6857906af4adb5b1e92d90279257811965\",\"venue\":\"2019 IEEE Intelligent Transportation Systems Conference (ITSC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144063214\",\"name\":\"M. Z. Hossain\"},{\"authorId\":\"19324907\",\"name\":\"F. Sohel\"},{\"authorId\":\"96363850\",\"name\":\"Mohd Fairuz Shiratuddin\"},{\"authorId\":\"48540238\",\"name\":\"Hamid Laga\"},{\"authorId\":\"1698675\",\"name\":\"M. Bennamoun\"}],\"doi\":\"10.1109/DICTA47822.2019.8946003\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"098833985221f9f30d547dadf24ae7b0f1433ef5\",\"title\":\"Bi-SAN-CAP: Bi-Directional Self-Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/098833985221f9f30d547dadf24ae7b0f1433ef5\",\"venue\":\"2019 Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2019},{\"arxivId\":\"1910.02974\",\"authors\":[{\"authorId\":\"3468983\",\"name\":\"M. Cornia\"},{\"authorId\":\"1843795\",\"name\":\"L. Baraldi\"},{\"authorId\":\"1741922\",\"name\":\"R. Cucchiara\"}],\"doi\":\"10.1109/ICRA40945.2020.9196653\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fe6f2a08cb8911d52533a413b071638d0463f10a\",\"title\":\"SMArT: Training Shallow Memory-aware Transformers for Robotic Explainability\",\"url\":\"https://www.semanticscholar.org/paper/fe6f2a08cb8911d52533a413b071638d0463f10a\",\"venue\":\"2020 IEEE International Conference on Robotics and Automation (ICRA)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9358850\",\"name\":\"Ruifan Li\"},{\"authorId\":\"4189987\",\"name\":\"Haoyu Liang\"},{\"authorId\":\"46571714\",\"name\":\"Yihui Shi\"},{\"authorId\":\"39825530\",\"name\":\"Fangxiang Feng\"},{\"authorId\":\"39527132\",\"name\":\"Xiaojie Wang\"}],\"doi\":\"10.1016/j.neucom.2020.02.041\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f85b7e09e60315d725b316ffc813d20535b21b2\",\"title\":\"Dual-CNN: A Convolutional language decoder for paragraph image captioning\",\"url\":\"https://www.semanticscholar.org/paper/7f85b7e09e60315d725b316ffc813d20535b21b2\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143696833\",\"name\":\"Wenjie Cai\"},{\"authorId\":\"47362438\",\"name\":\"Q. Liu\"}],\"doi\":\"10.1016/j.neucom.2020.06.112\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"title\":\"Image captioning with semantic-enhanced features and extremely hard negative examples\",\"url\":\"https://www.semanticscholar.org/paper/c218331cf31c32c46eb660c1b2ce3e506c99b3b0\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1801.10121\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"title\":\"Image Captioning at Will: A Versatile Scheme for Effectively Injecting Sentiments into Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/a5d8c57c53d896275d6fa2d1137cd152a2cd7624\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51349878\",\"name\":\"Y. C. Yoon\"},{\"authorId\":\"49591454\",\"name\":\"SoYoung Park\"},{\"authorId\":\"14966100\",\"name\":\"Soo Park\"},{\"authorId\":\"153803012\",\"name\":\"H. Lim\"}],\"doi\":\"10.4218/ETRIJ.2018-0621\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"title\":\"Image classification and captioning model considering a CAM\\u2010based disagreement loss\",\"url\":\"https://www.semanticscholar.org/paper/ef2c1911a95122d62d2886b70ab91a7595954bd4\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1805.02459\",\"authors\":[{\"authorId\":\"48986542\",\"name\":\"L. Jin\"},{\"authorId\":\"2287686\",\"name\":\"Xiangbo Shu\"},{\"authorId\":\"49243317\",\"name\":\"K. Li\"},{\"authorId\":\"3233021\",\"name\":\"Zechao Li\"},{\"authorId\":\"2272096\",\"name\":\"Guo-Jun Qi\"},{\"authorId\":\"8053308\",\"name\":\"J. Tang\"}],\"doi\":\"10.1109/TIP.2018.2883522\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e59e88ec6c3ad81feecee7645a6cfd80c04b2688\",\"title\":\"Deep Ordinal Hashing With Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/e59e88ec6c3ad81feecee7645a6cfd80c04b2688\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40663500\",\"name\":\"J. Chen\"},{\"authorId\":\"1848462\",\"name\":\"Yarong Han\"},{\"authorId\":\"144530696\",\"name\":\"Li Wan\"},{\"authorId\":\"144025048\",\"name\":\"Xing Zhou\"},{\"authorId\":\"144975798\",\"name\":\"Min Deng\"}],\"doi\":\"10.1080/01431161.2019.1594439\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"title\":\"Geospatial relation captioning for high-spatial-resolution images by using an attention-based neural network\",\"url\":\"https://www.semanticscholar.org/paper/baf0c489e3f307187d5f20f10b4e24db37cd1cd1\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1907.03950\",\"authors\":[{\"authorId\":\"152951058\",\"name\":\"Drew A. Hudson\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"title\":\"Learning by Abstraction: The Neural State Machine\",\"url\":\"https://www.semanticscholar.org/paper/136c05cb8dd359fb8e0dc7947172a9ecb74ccbec\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"2003.03669\",\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":\"48550129\",\"name\":\"Jiajun Deng\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1007/978-3-030-58601-0_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"title\":\"Adaptive Offline Quintuplet Loss for Image-Text Matching\",\"url\":\"https://www.semanticscholar.org/paper/638a9e0ee63031d13193bf2f67483ffbaf44e674\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"134473682\",\"name\":\"Mingwen Shao\"},{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"}],\"doi\":\"10.1016/j.neucom.2019.12.073\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"50260b547a481a95a2346759da8dba9366e89348\",\"title\":\"Multi-Attention Generative Adversarial Network for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/50260b547a481a95a2346759da8dba9366e89348\",\"venue\":\"Neurocomputing\",\"year\":2020},{\"arxivId\":\"1903.03414\",\"authors\":[{\"authorId\":\"19171514\",\"name\":\"J. Yang\"},{\"authorId\":\"49846744\",\"name\":\"Bo Zhang\"}],\"doi\":\"10.3390/APP9102078\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bfc870926e1583f79be747ea1d8c6436b84d7396\",\"title\":\"Artificial Intelligence in Intelligent Tutoring Robots: A Systematic Review and Design Guidelines\",\"url\":\"https://www.semanticscholar.org/paper/bfc870926e1583f79be747ea1d8c6436b84d7396\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47196880\",\"name\":\"Ziwei Wang\"},{\"authorId\":\"145622169\",\"name\":\"Zi Huang\"},{\"authorId\":\"150350159\",\"name\":\"Yadan Luo\"}],\"doi\":\"10.1007/978-3-030-39469-1_2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7fb87759fff098cbb487d74404ce8ca1098253a1\",\"title\":\"PAIC: Parallelised Attentive Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/7fb87759fff098cbb487d74404ce8ca1098253a1\",\"venue\":\"ADC\",\"year\":2020},{\"arxivId\":\"1912.08360\",\"authors\":[{\"authorId\":\"49102717\",\"name\":\"Feilong Chen\"},{\"authorId\":\"33427918\",\"name\":\"Fandong Meng\"},{\"authorId\":\"46372563\",\"name\":\"Jiaming Xu\"},{\"authorId\":\"144326610\",\"name\":\"Peng Li\"},{\"authorId\":\"153260119\",\"name\":\"Bo Xu\"},{\"authorId\":\"144535460\",\"name\":\"J. Zhou\"}],\"doi\":\"10.1609/AAAI.V34I05.6248\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"title\":\"DMRM: A Dual-channel Multi-hop Reasoning Model for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/7ae9c15c90b7d3e3c90c7f6d83743d4a0e07416b\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"2001.09545\",\"authors\":[{\"authorId\":\"2973730\",\"name\":\"Chiranjib Sur\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"title\":\"aiTPR: Attribute Interaction-Tensor Product Representation for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/66a2eb540af6f47db177599bc793ab0c6a6aa47e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2012.02206\",\"authors\":[{\"authorId\":\"73286206\",\"name\":\"Dave Zhenyu Chen\"},{\"authorId\":\"47621053\",\"name\":\"A. Gholami\"},{\"authorId\":\"2209612\",\"name\":\"M. Nie\\u00dfner\"},{\"authorId\":\"3317599\",\"name\":\"A. X. Chang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"title\":\"Scan2Cap: Context-aware Dense Captioning in RGB-D Scans\",\"url\":\"https://www.semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1808.09648\",\"authors\":[{\"authorId\":\"25309225\",\"name\":\"Avikalp Srivastava\"},{\"authorId\":\"153803927\",\"name\":\"H. Liu\"},{\"authorId\":\"33208854\",\"name\":\"S. Fujita\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"title\":\"From VQA to Multimodal CQA: Adapting Visual QA Models for Community QA Tasks\",\"url\":\"https://www.semanticscholar.org/paper/216c6d29a6f57c37ef8f26f88b6ec9be5b855a66\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"},{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"1380224383\",\"name\":\"Xuri Ge\"},{\"authorId\":\"153017460\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"1835006\",\"name\":\"Feiyue Huang\"},{\"authorId\":null,\"name\":\"Yan Wang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"title\":\"Variational Structured Semantic Inference for Diverse Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/2eca0afa23ee2b9b0999c445b8dba44ad3039bd1\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1710.06303\",\"authors\":[{\"authorId\":\"3219864\",\"name\":\"Aditya Mogadala\"},{\"authorId\":\"2168767\",\"name\":\"Umanga Bista\"},{\"authorId\":\"33650938\",\"name\":\"Lexing Xie\"},{\"authorId\":\"1748257\",\"name\":\"Achim Rettinger\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"631a1571d1a073369ec7c98e196de07e263ae130\",\"title\":\"Describing Natural Images Containing Novel Objects with Knowledge Guided Assitance\",\"url\":\"https://www.semanticscholar.org/paper/631a1571d1a073369ec7c98e196de07e263ae130\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1860938\",\"name\":\"M. Ghanimifard\"},{\"authorId\":\"2995275\",\"name\":\"Simon Dobnik\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d56fda7043eb683ecfcdd62277e82480e75b9f14\",\"title\":\"Learning to Compose Spatial Relations with Grounded Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/d56fda7043eb683ecfcdd62277e82480e75b9f14\",\"venue\":\"IWCS\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49386928\",\"name\":\"Y. Xue\"},{\"authorId\":\"143713756\",\"name\":\"Xiaolei Huang\"}],\"doi\":\"10.1007/978-3-030-20351-1_10\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7f364afcbc3ae1cd6ea6546205aaa90c13cfd553\",\"title\":\"Improved Disease Classification in Chest X-Rays with Transferred Features from Report Generation\",\"url\":\"https://www.semanticscholar.org/paper/7f364afcbc3ae1cd6ea6546205aaa90c13cfd553\",\"venue\":\"IPMI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151034836\",\"name\":\"I. Hrga\"},{\"authorId\":\"1382503013\",\"name\":\"Marina Ivasic-Kos\"}],\"doi\":\"10.23919/MIPRO.2019.8756821\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"title\":\"Deep Image Captioning: An Overview\",\"url\":\"https://www.semanticscholar.org/paper/2c602c5ac9c6de0108b8bd7d4075f5f2da2e790c\",\"venue\":\"2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153804074\",\"name\":\"Heng Quan Liu\"},{\"authorId\":\"2094026\",\"name\":\"Chunna Tian\"},{\"authorId\":\"151118825\",\"name\":\"Mengmeng Jiang\"}],\"doi\":\"10.1117/12.2524235\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"title\":\"When visual object-context features meet generic and specific semantic priors in image captioning\",\"url\":\"https://www.semanticscholar.org/paper/67f717df98ebaa35ac1995f31bc7b678fb8536e0\",\"venue\":\"International Conference on Graphic and Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143962510\",\"name\":\"Z. Zha\"},{\"authorId\":\"48210950\",\"name\":\"Jiawei Liu\"},{\"authorId\":\"49876189\",\"name\":\"T. Yang\"},{\"authorId\":\"1699819\",\"name\":\"Yongdong Zhang\"}],\"doi\":\"10.1145/3320061\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"86ce76f54a7bfc6047f83877408f789449f28df4\",\"title\":\"Spatiotemporal-Textual Co-Attention Network for Video Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/86ce76f54a7bfc6047f83877408f789449f28df4\",\"venue\":\"ACM Trans. Multim. Comput. Commun. Appl.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49891089\",\"name\":\"Y. Zhang\"},{\"authorId\":\"9610896\",\"name\":\"Y. Ding\"},{\"authorId\":\"144265847\",\"name\":\"Rui Wu\"},{\"authorId\":\"50822330\",\"name\":\"F. Xue\"}],\"doi\":\"10.1109/DASC/PiCom/CBDCom/CyberSciTech.2019.00151\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"4a08403806ca61227b7a4780094fd8e652379362\",\"title\":\"A Denoising Framework for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/4a08403806ca61227b7a4780094fd8e652379362\",\"venue\":\"2019 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"33969294\",\"name\":\"K. Ding\"},{\"authorId\":\"1683738\",\"name\":\"S. Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.1109/TMM.2019.2915033\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"title\":\"Deep Hierarchical Encoder\\u2013Decoder Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/bbb9f5378eac3eb8245cbd0f998a95cef2954508\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2059218\",\"name\":\"Ankit Khare\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01fe0c5f0d033141a29f4958f15520798022bbe7\",\"title\":\"ULTRA-CONTEXT: MAXIMIZING THE CONTEXT FOR BETTER IMAGE CAPTION GENERATION\",\"url\":\"https://www.semanticscholar.org/paper/01fe0c5f0d033141a29f4958f15520798022bbe7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36960501\",\"name\":\"Swaminathan Gurumurthy\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"title\":\"Removing the i\\u2019s from i.i.d : Testing generalization on hard datasets\",\"url\":\"https://www.semanticscholar.org/paper/41121dd73ce28ebe31ebf9c9a402cf575665ea32\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471428747\",\"name\":\"Yang Zhen-yu\"},{\"authorId\":\"1471428729\",\"name\":\"Zhang Jiao\"}],\"doi\":\"10.1109/ICCSNT47585.2019.8962488\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"46f87af5af877b2d83b8fdbb9b97c72d0aa14ff9\",\"title\":\"Fine-grained Image Caption based on Multi-level Attention\",\"url\":\"https://www.semanticscholar.org/paper/46f87af5af877b2d83b8fdbb9b97c72d0aa14ff9\",\"venue\":\"2019 IEEE 7th International Conference on Computer Science and Network Technology (ICCSNT)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1952857\",\"name\":\"K. Zheng\"},{\"authorId\":\"144469723\",\"name\":\"C. Zhu\"},{\"authorId\":\"2478555\",\"name\":\"Shaopeng Lu\"},{\"authorId\":\"40457369\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-00776-8_9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"title\":\"Multiple-Level Feature-Based Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/9808d89c32f661d9fd797a97cc7c3ff2ed2cd260\",\"venue\":\"PCM\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49528055\",\"name\":\"Hanzhang Wang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"3187665\",\"name\":\"Kaisheng Xu\"}],\"doi\":\"10.1109/CVPR.2018.00521\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"title\":\"Categorizing Concepts with Basic Level for Vision-to-Language\",\"url\":\"https://www.semanticscholar.org/paper/7fdac774e51e0aa8f9921e857067801d73a8d2d0\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1906.02634\",\"authors\":[{\"authorId\":\"3319373\",\"name\":\"Dirk Weissenborn\"},{\"authorId\":\"2556289\",\"name\":\"Oscar T\\u00e4ckstr\\u00f6m\"},{\"authorId\":\"39328010\",\"name\":\"Jakob Uszkoreit\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e763fdc9ae56826ff799163ea035b29bffd8ea6f\",\"title\":\"Scaling Autoregressive Video Models\",\"url\":\"https://www.semanticscholar.org/paper/e763fdc9ae56826ff799163ea035b29bffd8ea6f\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"1909.09060\",\"authors\":[{\"authorId\":\"48544896\",\"name\":\"Lun Huang\"},{\"authorId\":\"1788029\",\"name\":\"W. Wang\"},{\"authorId\":\"49289638\",\"name\":\"Y. Xia\"},{\"authorId\":\"40445654\",\"name\":\"J. Chen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"312799645adfafb886f156708a7a36f2db459c62\",\"title\":\"Adaptively Aligned Image Captioning via Adaptive Attention Time\",\"url\":\"https://www.semanticscholar.org/paper/312799645adfafb886f156708a7a36f2db459c62\",\"venue\":\"NeurIPS\",\"year\":2019},{\"arxivId\":\"1908.11824\",\"authors\":[{\"authorId\":\"2265229\",\"name\":\"Lei Ke\"},{\"authorId\":\"1678473\",\"name\":\"W. Pei\"},{\"authorId\":\"47731271\",\"name\":\"Ruiyu Li\"},{\"authorId\":\"2029246\",\"name\":\"Xiaoyong Shen\"},{\"authorId\":\"5068280\",\"name\":\"Yu-Wing Tai\"}],\"doi\":\"10.1109/ICCV.2019.00898\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"0db903dd28a3be3e57f40033c16cce574231f78e\",\"title\":\"Reflective Decoding Network for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0db903dd28a3be3e57f40033c16cce574231f78e\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934161\",\"name\":\"T. Chen\"},{\"authorId\":null,\"name\":\"Yuxiao Chen\"},{\"authorId\":null,\"name\":\"Han Guo\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/BigData.2018.8622513\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d77731d2b2e0c8be5bf2d247974029f769064529\",\"title\":\"You Type a Few Words and We Do the Rest: Image Recommendation for Social Multimedia Posts\",\"url\":\"https://www.semanticscholar.org/paper/d77731d2b2e0c8be5bf2d247974029f769064529\",\"venue\":\"2018 IEEE International Conference on Big Data (Big Data)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66916694\",\"name\":\"X. Xiao\"},{\"authorId\":\"46660013\",\"name\":\"L. Wang\"},{\"authorId\":\"145211780\",\"name\":\"Bin Fan\"},{\"authorId\":\"1380311632\",\"name\":\"Shinming Xiang\"},{\"authorId\":\"144809241\",\"name\":\"C. Pan\"}],\"doi\":\"10.18653/v1/D19-1213\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"title\":\"Guiding the Flowing of Semantics: Interpretable Video Captioning via POS Tag\",\"url\":\"https://www.semanticscholar.org/paper/ed8cf8a585e3506778ba0584cdff1ac7d9db75b4\",\"venue\":\"EMNLP/IJCNLP\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"7934466\",\"name\":\"Junwei Zhou\"},{\"authorId\":\"47119743\",\"name\":\"X. Wang\"},{\"authorId\":\"2710247\",\"name\":\"Jizhong Han\"},{\"authorId\":\"144553025\",\"name\":\"S. Hu\"},{\"authorId\":\"2755326\",\"name\":\"Hongchao Gao\"}],\"doi\":\"10.1109/BigMM.2018.8499060\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"title\":\"Spatial- Temporal Attention for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/0486c77b8f251e8ae52f5ab6304288c1a8bcc48a\",\"venue\":\"2018 IEEE Fourth International Conference on Multimedia Big Data (BigMM)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"97713340\",\"name\":\"X. Liu\"},{\"authorId\":\"1943870\",\"name\":\"Weibin Liu\"},{\"authorId\":\"145767616\",\"name\":\"Weiwei Xing\"}],\"doi\":\"10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00152\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f55a588eef043cbb72ee548714d623b573c21e9b\",\"title\":\"Image Caption Generation with Local Semantic Information and Global Information\",\"url\":\"https://www.semanticscholar.org/paper/f55a588eef043cbb72ee548714d623b573c21e9b\",\"venue\":\"2019 IEEE SmartWorld, Ubiquitous Intelligence & Computing, Advanced & Trusted Computing, Scalable Computing & Communications, Cloud & Big Data Computing, Internet of People and Smart City Innovation (SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49478695\",\"name\":\"Teng Jiang\"},{\"authorId\":\"144513168\",\"name\":\"L. Gong\"},{\"authorId\":\"7607492\",\"name\":\"Y. Yang\"}],\"doi\":\"10.1142/s146902682050011x\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"81b1a0d8ca4ab3b9807164866de7e5dca73651dd\",\"title\":\"Spatial Relational Attention Using Fully Convolutional Networks for Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/81b1a0d8ca4ab3b9807164866de7e5dca73651dd\",\"venue\":\"Int. J. Comput. Intell. Appl.\",\"year\":2020},{\"arxivId\":\"2012.07061\",\"authors\":[{\"authorId\":\"9665187\",\"name\":\"Jiayi Ji\"},{\"authorId\":\"46491945\",\"name\":\"Yunpeng Luo\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"2642638\",\"name\":\"F. Chen\"},{\"authorId\":\"1993645531\",\"name\":\"Gen Luo\"},{\"authorId\":\"47096329\",\"name\":\"Yongjian Wu\"},{\"authorId\":\"40366236\",\"name\":\"Yue Gao\"},{\"authorId\":\"1572139630\",\"name\":\"Rongrong Ji\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"title\":\"Improving Image Captioning by Leveraging Intra- and Inter-layer Global Representation in Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/7217b5d8d0fb753532026cc36b0aaa056960c6f8\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1705.08759\",\"authors\":[{\"authorId\":\"144207643\",\"name\":\"Q. Sun\"},{\"authorId\":\"2297229\",\"name\":\"Stefan Lee\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1109/CVPR.2017.763\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1cee733ee31e245dac4655a870fd9226163a52b5\",\"title\":\"Bidirectional Beam Search: Forward-Backward Inference in Neural Sequence Models for Fill-in-the-Blank Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/1cee733ee31e245dac4655a870fd9226163a52b5\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017},{\"arxivId\":\"1902.09774\",\"authors\":[{\"authorId\":\"145422343\",\"name\":\"Dalu Guo\"},{\"authorId\":\"48258751\",\"name\":\"Chang Xu\"},{\"authorId\":\"143719920\",\"name\":\"D. Tao\"}],\"doi\":\"10.1109/CVPR.2019.01068\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"title\":\"Image-Question-Answer Synergistic Network for Visual Dialog\",\"url\":\"https://www.semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1905.06512\",\"authors\":[{\"authorId\":\"2250995\",\"name\":\"Liner Yang\"},{\"authorId\":\"32679122\",\"name\":\"Cunliang Kong\"},{\"authorId\":\"47558643\",\"name\":\"Yun Chen\"},{\"authorId\":\"46399266\",\"name\":\"Yang Liu\"},{\"authorId\":\"122729767\",\"name\":\"Qinan Fan\"},{\"authorId\":\"1851775\",\"name\":\"E. Yang\"}],\"doi\":\"10.1109/TASLP.2020.2987754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ef635fbc62075af027e6fae1e982635f997500ad\",\"title\":\"Incorporating Sememes into Chinese Definition Modeling\",\"url\":\"https://www.semanticscholar.org/paper/ef635fbc62075af027e6fae1e982635f997500ad\",\"venue\":\"IEEE/ACM Transactions on Audio, Speech, and Language Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2042704741\",\"name\":\"Xiaohan Zou\"},{\"authorId\":\"144289788\",\"name\":\"C. Lin\"},{\"authorId\":\"2042741172\",\"name\":\"Yinjia Zhang\"},{\"authorId\":\"1729695\",\"name\":\"Qinpei Zhao\"}],\"doi\":\"10.1109/ICTAI50040.2020.00124\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"f8465dc22e66853636edce1cd537317120ecfcbb\",\"title\":\"To be an Artist: Automatic Generation on Food Image Aesthetic Captioning\",\"url\":\"https://www.semanticscholar.org/paper/f8465dc22e66853636edce1cd537317120ecfcbb\",\"venue\":\"2020 IEEE 32nd International Conference on Tools with Artificial Intelligence (ICTAI)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"104150443\",\"name\":\"Zeqin Huang\"},{\"authorId\":\"9118491\",\"name\":\"Zhongzhi Shi\"}],\"doi\":\"10.1007/978-3-030-46931-3_29\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f08ac1aa8bfc804414b1e5a2bb98203337368807\",\"title\":\"Image Caption Combined with GAN Training Method\",\"url\":\"https://www.semanticscholar.org/paper/f08ac1aa8bfc804414b1e5a2bb98203337368807\",\"venue\":\"Intelligent Information Processing\",\"year\":2020},{\"arxivId\":\"2003.03923\",\"authors\":[{\"authorId\":\"1410097225\",\"name\":\"X. Yang\"},{\"authorId\":\"5462268\",\"name\":\"Hanwang Zhang\"},{\"authorId\":\"50490213\",\"name\":\"Jianfei Cai\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1e420efcd3fbace6f219c812a78d33cb64e25445\",\"title\":\"Deconfounded Image Captioning: A Causal Retrospect\",\"url\":\"https://www.semanticscholar.org/paper/1e420efcd3fbace6f219c812a78d33cb64e25445\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48462171\",\"name\":\"Lu Zhang\"},{\"authorId\":\"1519062024\",\"name\":\"Jianming Zhang\"},{\"authorId\":\"145527698\",\"name\":\"Zhe Lin\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"},{\"authorId\":\"49990648\",\"name\":\"Y. He\"}],\"doi\":\"10.1109/CVPR.2019.00618\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"791fa4797683469f91b27940253c7725c9717f24\",\"title\":\"CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection\",\"url\":\"https://www.semanticscholar.org/paper/791fa4797683469f91b27940253c7725c9717f24\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"2002.12585\",\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"19169659\",\"name\":\"Xuancheng Ren\"},{\"authorId\":\"7896029\",\"name\":\"Yuanxin Liu\"},{\"authorId\":\"145558281\",\"name\":\"Kai Lei\"},{\"authorId\":\"48305273\",\"name\":\"Xu Sun\"}],\"doi\":\"10.24963/ijcai.2019/708\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"title\":\"Exploring and Distilling Cross-Modal Information for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b23622ba3eef8a82036710271c6c35bd8a49ce8f\",\"venue\":\"IJCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47968201\",\"name\":\"Lixin Liu\"},{\"authorId\":\"46741143\",\"name\":\"Jiajun Tang\"},{\"authorId\":\"145078589\",\"name\":\"Xiaojun Wan\"},{\"authorId\":\"35310979\",\"name\":\"Zongming Guo\"}],\"doi\":\"10.1109/ICCV.2019.00434\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"title\":\"Generating Diverse and Descriptive Image Captions Using Visual Paraphrases\",\"url\":\"https://www.semanticscholar.org/paper/b774d6cd89cb27e62f03f183b89b7cacc412e131\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"15281603\",\"name\":\"Zerui Chen\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"144143336\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/ICIP.2019.8802975\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"title\":\"Augmented Visual-Semantic Embeddings for Image and Sentence Matching\",\"url\":\"https://www.semanticscholar.org/paper/66ec6ec4ced51e24e4a3b26246237dfe3ee689a5\",\"venue\":\"2019 IEEE International Conference on Image Processing (ICIP)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508437\",\"name\":\"Jiyoun Moon\"},{\"authorId\":\"97166798\",\"name\":\"Beom-Hee Lee\"}],\"doi\":\"10.3390/app9183789\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"bf299851d033ce8245b1c433949dd52219d82742\",\"title\":\"PDDL Planning with Natural Language-Based Scene Understanding for UAV-UGV Cooperation\",\"url\":\"https://www.semanticscholar.org/paper/bf299851d033ce8245b1c433949dd52219d82742\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471428747\",\"name\":\"Yang Zhen-yu\"},{\"authorId\":\"1471428729\",\"name\":\"Zhang Jiao\"}],\"doi\":\"10.1109/IAEAC47372.2019.8998010\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f57e68cfdc1a7fdde23f69ec9e8a0b39d624ad5c\",\"title\":\"Research on Image Caption Method Based on Mixed Image Features\",\"url\":\"https://www.semanticscholar.org/paper/f57e68cfdc1a7fdde23f69ec9e8a0b39d624ad5c\",\"venue\":\"2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"eccfd6174709c285d62b11fb3da9b68d485ca883\",\"title\":\"Integrating Rule-based Entity Masking into Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/eccfd6174709c285d62b11fb3da9b68d485ca883\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152747612\",\"name\":\"Zhenyu Yang\"},{\"authorId\":\"153874396\",\"name\":\"Qiao Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2980578\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"059093bc3bb44949e9754fb4366f0be7cea34bac\",\"title\":\"ATT-BM-SOM: A Framework of Effectively Choosing Image Information and Optimizing Syntax for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/059093bc3bb44949e9754fb4366f0be7cea34bac\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40061480\",\"name\":\"Z. Dong\"},{\"authorId\":\"46812609\",\"name\":\"Xian Zhong\"},{\"authorId\":\"50358603\",\"name\":\"S. Chen\"},{\"authorId\":\"1432791325\",\"name\":\"Wenxuan Liu\"},{\"authorId\":\"2000237078\",\"name\":\"Qi Cui\"},{\"authorId\":\"152283661\",\"name\":\"L. Zhong\"}],\"doi\":\"10.1007/978-3-030-55187-2_5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"78a1094e0968cf4e2b61c83100d971031597ae4b\",\"title\":\"Adaptive Attention Mechanism Based Semantic Compositional Network for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/78a1094e0968cf4e2b61c83100d971031597ae4b\",\"venue\":\"IntelliSys\",\"year\":2020},{\"arxivId\":\"1811.03760\",\"authors\":[{\"authorId\":\"83172211\",\"name\":\"Youru Li\"},{\"authorId\":\"1749780\",\"name\":\"Zhenfeng Zhu\"},{\"authorId\":\"144322656\",\"name\":\"D. Kong\"},{\"authorId\":\"144288060\",\"name\":\"H. Han\"},{\"authorId\":\"38161033\",\"name\":\"Y. Zhao\"}],\"doi\":\"10.1016/J.KNOSYS.2019.05.028\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f601f077a43056ee66d52e2a78063c81b321e3bc\",\"title\":\"EA-LSTM: Evolutionary Attention-based LSTM for Time Series Prediction\",\"url\":\"https://www.semanticscholar.org/paper/f601f077a43056ee66d52e2a78063c81b321e3bc\",\"venue\":\"Knowl. Based Syst.\",\"year\":2019},{\"arxivId\":\"1906.00513\",\"authors\":[{\"authorId\":\"46365808\",\"name\":\"Jialin Wu\"},{\"authorId\":\"32193161\",\"name\":\"Zeyuan Hu\"},{\"authorId\":\"1797655\",\"name\":\"R. Mooney\"}],\"doi\":\"10.18653/v1/P19-1348\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b16da6786f799de7d31786fbbf5dafa1979a2c64\",\"title\":\"Generating Question Relevant Captions to Aid Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/b16da6786f799de7d31786fbbf5dafa1979a2c64\",\"venue\":\"ACL\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10136905\",\"name\":\"Cheonbok Park\"},{\"authorId\":\"73258428\",\"name\":\"Chunggi Lee\"},{\"authorId\":\"41019737\",\"name\":\"Hyojin Bahng\"},{\"authorId\":\"1438303832\",\"name\":\"Taeyun won\"},{\"authorId\":\"3736059\",\"name\":\"Kihwan Kim\"},{\"authorId\":\"102503791\",\"name\":\"S. Jin\"},{\"authorId\":\"39324835\",\"name\":\"Sungahn Ko\"},{\"authorId\":\"1795455\",\"name\":\"J. Choo\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"459bf3d1e2e602f9bf193a90990ccea4572bab4b\",\"title\":\"STGRAT: A Spatio-Temporal Graph Attention Network for Traffic Forecasting\",\"url\":\"https://www.semanticscholar.org/paper/459bf3d1e2e602f9bf193a90990ccea4572bab4b\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9728275\",\"name\":\"Huanhou Xiao\"},{\"authorId\":\"34875762\",\"name\":\"J. Shi\"}],\"doi\":\"10.1145/3239576.3239580\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"title\":\"Video Captioning using Hierarchical Multi-Attention Model\",\"url\":\"https://www.semanticscholar.org/paper/0f47d9d2d64c45246ae7882d81398e6274f7c8e6\",\"venue\":\"ICAIP '18\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yue Wang\"},{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"1680068\",\"name\":\"X. Wang\"}],\"doi\":\"10.1145/3126686.3126714\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"title\":\"Image Caption with Synchronous Cross-Attention\",\"url\":\"https://www.semanticscholar.org/paper/b5bfe824fc49fe78b538ac15f21c4cd6a9d44347\",\"venue\":\"ACM Multimedia\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1738607561\",\"name\":\"S. Nikiforova\"},{\"authorId\":\"2398266\",\"name\":\"Tejaswini Deoskar\"},{\"authorId\":\"2129425\",\"name\":\"D. Paperno\"},{\"authorId\":\"2021738\",\"name\":\"Y. Winter\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"569459a9b1ca74bbf4b74908c30dc583d78b59ab\",\"title\":\"Geo-Aware Image Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/569459a9b1ca74bbf4b74908c30dc583d78b59ab\",\"venue\":\"COLING\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1927674\",\"name\":\"Fenglin Liu\"},{\"authorId\":\"1491236221\",\"name\":\"Meng Gao\"},{\"authorId\":\"1747773\",\"name\":\"T. Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"}],\"doi\":\"10.1109/ICDM.2019.00054\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"8f04013efcdf606d65145859f4f9eb6c48908869\",\"title\":\"Exploring Semantic Relationships for Image Captioning without Parallel Data\",\"url\":\"https://www.semanticscholar.org/paper/8f04013efcdf606d65145859f4f9eb6c48908869\",\"venue\":\"2019 IEEE International Conference on Data Mining (ICDM)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1978802390\",\"name\":\"Haolei Pei\"},{\"authorId\":\"8559954\",\"name\":\"Q. Chen\"},{\"authorId\":\"13257164\",\"name\":\"J. Wang\"},{\"authorId\":\"123555217\",\"name\":\"Q. Sun\"},{\"authorId\":\"1680030\",\"name\":\"Yubo Jia\"}],\"doi\":\"10.1109/IJCNN48605.2020.9206815\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"title\":\"Visual Relational Reasoning for Image Caption\",\"url\":\"https://www.semanticscholar.org/paper/129f71acdcec4b171a4f11beec4f10463d5ffa38\",\"venue\":\"2020 International Joint Conference on Neural Networks (IJCNN)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2047692\",\"name\":\"Chenyou Fan\"},{\"authorId\":\"47295036\",\"name\":\"Zehua Zhang\"},{\"authorId\":\"2821130\",\"name\":\"David J. Crandall\"}],\"doi\":\"10.1016/j.jvcir.2018.05.008\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"title\":\"Deepdiary: Lifelogging image captioning and summarization\",\"url\":\"https://www.semanticscholar.org/paper/26eff1aa014ed0f19fbda0ac6b554f8ba9881f25\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"36595248\",\"name\":\"Fang Fang\"},{\"authorId\":\"2774427\",\"name\":\"Hanli Wang\"},{\"authorId\":\"50581334\",\"name\":\"Y. Chen\"},{\"authorId\":\"8275214\",\"name\":\"P. Tang\"}],\"doi\":\"10.1007/s11042-018-6228-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"title\":\"Looking deeper and transferring attention for image captioning\",\"url\":\"https://www.semanticscholar.org/paper/c580b0a8dc655a8831ddbb7954bb929b1f236ebc\",\"venue\":\"Multimedia Tools and Applications\",\"year\":2018},{\"arxivId\":\"1806.04342\",\"authors\":[{\"authorId\":\"145604319\",\"name\":\"N. Ke\"},{\"authorId\":\"7912420\",\"name\":\"Konrad Zolna\"},{\"authorId\":\"2041695\",\"name\":\"Alessandro Sordoni\"},{\"authorId\":\"3146592\",\"name\":\"Zhouhan Lin\"},{\"authorId\":\"3382568\",\"name\":\"Adam Trischler\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"},{\"authorId\":\"145134886\",\"name\":\"Joelle Pineau\"},{\"authorId\":\"1778839\",\"name\":\"Laurent Charlin\"},{\"authorId\":\"1972076\",\"name\":\"C. Pal\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d9b48c0c50e06ccfef722ea6ac88c5000615534\",\"title\":\"Focused Hierarchical RNNs for Conditional Sequence Processing\",\"url\":\"https://www.semanticscholar.org/paper/8d9b48c0c50e06ccfef722ea6ac88c5000615534\",\"venue\":\"ICML\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145607944\",\"name\":\"Xin Guo\"},{\"authorId\":\"49532658\",\"name\":\"B. Zhu\"},{\"authorId\":\"2454625\",\"name\":\"L. Polan\\u00eda\"},{\"authorId\":\"35020996\",\"name\":\"Charles Boncelet\"},{\"authorId\":\"1800783\",\"name\":\"K. Barner\"}],\"doi\":\"10.1145/3242969.3264990\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cf4e5206722ba16061982b885f8c7c86beacd27c\",\"title\":\"Group-Level Emotion Recognition Using Hybrid Deep Models Based on Faces, Scenes, Skeletons and Visual Attentions\",\"url\":\"https://www.semanticscholar.org/paper/cf4e5206722ba16061982b885f8c7c86beacd27c\",\"venue\":\"ICMI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2626358\",\"name\":\"B. Chen\"},{\"authorId\":\"35391826\",\"name\":\"Peixia Li\"},{\"authorId\":\"49321717\",\"name\":\"Chong Sun\"},{\"authorId\":\"40562844\",\"name\":\"D. Wang\"},{\"authorId\":\"145789906\",\"name\":\"G. Yang\"},{\"authorId\":\"1790976\",\"name\":\"H. Lu\"}],\"doi\":\"10.1016/j.patcog.2018.10.005\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9c92cec207554ce1f9608d5994eaaa2814933f2c\",\"title\":\"Multi attention module for visual tracking\",\"url\":\"https://www.semanticscholar.org/paper/9c92cec207554ce1f9608d5994eaaa2814933f2c\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47287647\",\"name\":\"Sen He\"},{\"authorId\":\"2319672\",\"name\":\"H. Tavakoli\"},{\"authorId\":\"3177797\",\"name\":\"A. Borji\"},{\"authorId\":\"3251678\",\"name\":\"N. Pugeault\"}],\"doi\":\"10.1109/ICCV.2019.00862\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"title\":\"Human Attention in Image Captioning: Dataset and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/e4a91b8c1259e7744784d922f250dd77ea951e9f\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1806.00523\",\"authors\":[{\"authorId\":\"31352445\",\"name\":\"Kashyap Chitta\"}],\"doi\":\"10.1007/978-3-030-11018-5_34\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"title\":\"Targeted Kernel Networks: Faster Convolutions with Attentive Regularization\",\"url\":\"https://www.semanticscholar.org/paper/1d2c89e4ccef7de458d79e092cd7fada66c3e345\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2011.01385\",\"authors\":[{\"authorId\":\"3280656\",\"name\":\"Litao Yu\"},{\"authorId\":\"123275544\",\"name\":\"Jian Zhang\"},{\"authorId\":\"47506551\",\"name\":\"Qiang Wu\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"title\":\"Dual Attention on Pyramid Feature Maps for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b0aa35ac0caf5230cdd1c5022b246e2381f87aac\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2007.03338\",\"authors\":[{\"authorId\":\"40651988\",\"name\":\"Marzieh Heidari\"},{\"authorId\":\"2862462\",\"name\":\"Mehdi Ghatee\"},{\"authorId\":\"1780566\",\"name\":\"A. Nickabadi\"},{\"authorId\":\"1796299590\",\"name\":\"Arash Pourhasan Nezhad\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"title\":\"Diverse and Styled Image Captioning Using SVD-Based Mixture of Recurrent Experts\",\"url\":\"https://www.semanticscholar.org/paper/20b332af8399233b5fc33a7e7f98538bd4a82ab0\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1906.09610\",\"authors\":[{\"authorId\":\"50086111\",\"name\":\"K. Niu\"},{\"authorId\":\"48356084\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2020.2984883\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"title\":\"Improving Description-Based Person Re-Identification by Multi-Granularity Image-Text Alignments\",\"url\":\"https://www.semanticscholar.org/paper/7f2512bea65bcc298e8258f8aaccb13dbf59f2d9\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8433849\",\"name\":\"Mengshi Qi\"},{\"authorId\":\"40013375\",\"name\":\"Y. Wang\"},{\"authorId\":\"3079475\",\"name\":\"Annan Li\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1145/3265845.3265851\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"title\":\"Sports Video Captioning by Attentive Motion Representation based Hierarchical Recurrent Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/b1f62af29f1d13133b543e0b65ccf1a42ded7f25\",\"venue\":\"MMSports@MM\",\"year\":2018},{\"arxivId\":\"2001.05876\",\"authors\":[{\"authorId\":\"46659203\",\"name\":\"L. Wang\"},{\"authorId\":\"1486057423\",\"name\":\"Zechen Bai\"},{\"authorId\":\"48378975\",\"name\":\"Yonghua Zhang\"},{\"authorId\":\"37514286\",\"name\":\"H. Lu\"}],\"doi\":\"10.1609/aaai.v34i07.6898\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"85079d64d6fdd0ba5318fda119d152f2d2946391\",\"title\":\"Show, Recall, and Tell: Image Captioning with Recall Mechanism\",\"url\":\"https://www.semanticscholar.org/paper/85079d64d6fdd0ba5318fda119d152f2d2946391\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":\"1708.02043\",\"authors\":[{\"authorId\":\"32227979\",\"name\":\"M. Tanti\"},{\"authorId\":\"1700894\",\"name\":\"Albert Gatt\"},{\"authorId\":\"2370774\",\"name\":\"K. Camilleri\"}],\"doi\":\"10.18653/v1/W17-3506\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"title\":\"What is the Role of Recurrent Neural Networks (RNNs) in an Image Caption Generator?\",\"url\":\"https://www.semanticscholar.org/paper/3d22f972448a2336677ae6ff2877fae010c7dfa2\",\"venue\":\"INLG\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1788124\",\"name\":\"Qiuyuan Huang\"},{\"authorId\":\"1748557\",\"name\":\"P. Smolensky\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"144953174\",\"name\":\"Dapeng Wu\"}],\"doi\":\"10.18653/v1/N18-1114\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f2df65bc38690ec56c4fe24380f9993ba2904e9c\",\"title\":\"Tensor Product Generation Networks for Deep NLP Modeling\",\"url\":\"https://www.semanticscholar.org/paper/f2df65bc38690ec56c4fe24380f9993ba2904e9c\",\"venue\":\"NAACL-HLT\",\"year\":2018},{\"arxivId\":\"2012.11587\",\"authors\":[{\"authorId\":\"120157233\",\"name\":\"J. Yang\"},{\"authorId\":\"13589371\",\"name\":\"Jiayuan Mao\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"2042941\",\"name\":\"D. Cox\"},{\"authorId\":\"1763295\",\"name\":\"J. Tenenbaum\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"title\":\"Object-Centric Diagnosis of Visual Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/617b8d0715469dfdb9e44e0f0031ac99a0f333d9\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.02033\",\"authors\":[{\"authorId\":\"152332057\",\"name\":\"Baohua Sun\"},{\"authorId\":\"1999579263\",\"name\":\"Michael Lin\"},{\"authorId\":\"1505825326\",\"name\":\"Hao Sha\"},{\"authorId\":\"1986616718\",\"name\":\"Lin Yang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"title\":\"SuperOCR: A Conversion from Optical Character Recognition to Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/b366c17a5a0daf851ec4a5d94b29accb4c643b73\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.08315\",\"authors\":[{\"authorId\":\"151195783\",\"name\":\"Ruixiang Tang\"},{\"authorId\":\"3432460\",\"name\":\"Mengnan Du\"},{\"authorId\":\"48513905\",\"name\":\"Yuening Li\"},{\"authorId\":\"47781070\",\"name\":\"Zirui Liu\"},{\"authorId\":\"1490483806\",\"name\":\"X. Hu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b239fe63de5de0a1e0c08af97a30f79b5a2bdbc\",\"title\":\"Mitigating Gender Bias in Captioning Systems\",\"url\":\"https://www.semanticscholar.org/paper/0b239fe63de5de0a1e0c08af97a30f79b5a2bdbc\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2002.08670\",\"authors\":[{\"authorId\":\"31469067\",\"name\":\"Jia-Ming Wang\"},{\"authorId\":\"153140559\",\"name\":\"Jun Du\"},{\"authorId\":\"47539230\",\"name\":\"Jian-Shu Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"533b40bdeed5539703163ef77faddc1a96639d91\",\"title\":\"Stroke Constrained Attention Network for Online Handwritten Mathematical Expression Recognition\",\"url\":\"https://www.semanticscholar.org/paper/533b40bdeed5539703163ef77faddc1a96639d91\",\"venue\":\"ArXiv\",\"year\":2020}],\"corpusId\":18347865,\"doi\":\"10.1109/CVPR.2017.345\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":98,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"references\":[{\"arxivId\":\"1605.07912\",\"authors\":[{\"authorId\":\"47087291\",\"name\":\"Z. Yang\"},{\"authorId\":\"30556331\",\"name\":\"Y. Yuan\"},{\"authorId\":\"9287688\",\"name\":\"Yuexin Wu\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"50056360\",\"name\":\"William W. Cohen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"title\":\"Encode, Review, and Decode: Reviewer Module for Caption Generation\",\"url\":\"https://www.semanticscholar.org/paper/90fbeb4c871d3916c2b428645a1e1482f05826e1\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"7d76a09aa363685bc0f04a502ed853dc09a574e2\",\"title\":\"Grad-CAM: Why did you say that? Visual Explanations from Deep Networks via Gradient-based Localization\",\"url\":\"https://www.semanticscholar.org/paper/7d76a09aa363685bc0f04a502ed853dc09a574e2\",\"venue\":\"\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3323275\",\"name\":\"Kishore Papineni\"},{\"authorId\":\"1781292\",\"name\":\"S. Roukos\"},{\"authorId\":\"144582029\",\"name\":\"T. Ward\"},{\"authorId\":\"2587983\",\"name\":\"Wei-Jing Zhu\"}],\"doi\":\"10.3115/1073083.1073135\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"d7da009f457917aa381619facfa5ffae9329a6e9\",\"title\":\"Bleu: a Method for Automatic Evaluation of Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/d7da009f457917aa381619facfa5ffae9329a6e9\",\"venue\":\"ACL\",\"year\":2002},{\"arxivId\":\"1603.01417\",\"authors\":[{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"title\":\"Dynamic Memory Networks for Visual and Textual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/f96898d15a1bf1fa8925b1280d0e07a7a8e72194\",\"venue\":\"ICML\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fad611e35b3731740b4d8b754241e77add5a70b9\",\"title\":\"Multimodal Neural Language Models\",\"url\":\"https://www.semanticscholar.org/paper/fad611e35b3731740b4d8b754241e77add5a70b9\",\"venue\":\"ICML\",\"year\":2014},{\"arxivId\":\"1405.0312\",\"authors\":[{\"authorId\":\"33493200\",\"name\":\"Tsung-Yi Lin\"},{\"authorId\":\"145854440\",\"name\":\"M. Maire\"},{\"authorId\":\"50172592\",\"name\":\"Serge J. Belongie\"},{\"authorId\":\"48966748\",\"name\":\"James Hays\"},{\"authorId\":\"1690922\",\"name\":\"P. Perona\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1007/978-3-319-10602-1_48\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"71b7178df5d2b112d07e45038cb5637208659ff7\",\"title\":\"Microsoft COCO: Common Objects in Context\",\"url\":\"https://www.semanticscholar.org/paper/71b7178df5d2b112d07e45038cb5637208659ff7\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2166511\",\"name\":\"R. Socher\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"},{\"authorId\":\"144783904\",\"name\":\"Christopher D. Manning\"},{\"authorId\":\"34699434\",\"name\":\"A. Ng\"}],\"doi\":\"10.1162/tacl_a_00177\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"title\":\"Grounded Compositional Semantics for Finding and Describing Images with Sentences\",\"url\":\"https://www.semanticscholar.org/paper/0ca7d208ff8d81377e0eaa9723820aeae7a7322d\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1512.00567\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"103590098\",\"name\":\"Jon Shlens\"},{\"authorId\":\"3282833\",\"name\":\"Z. Wojna\"}],\"doi\":\"10.1109/CVPR.2016.308\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"title\":\"Rethinking the Inception Architecture for Computer Vision\",\"url\":\"https://www.semanticscholar.org/paper/23ffaa0fe06eae05817f527a47ac3291077f9e58\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/TPAMI.2012.162\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cb6700d94c6118ee13f4f4fecac99f111189812\",\"title\":\"BabyTalk: Understanding and Generating Simple Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/5cb6700d94c6118ee13f4f4fecac99f111189812\",\"venue\":\"IEEE Trans. Pattern Anal. Mach. Intell.\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145592791\",\"name\":\"P. Kuznetsova\"},{\"authorId\":\"2004053\",\"name\":\"Vicente Ordonez\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"title\":\"Collective Generation of Natural Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/2a0d0f6c5a69b264710df0230696f47c5918e2f2\",\"venue\":\"ACL\",\"year\":2012},{\"arxivId\":\"1607.08822\",\"authors\":[{\"authorId\":\"6965856\",\"name\":\"Peter Anderson\"},{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"145177220\",\"name\":\"Mark Johnson\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/978-3-319-46454-1_24\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"title\":\"SPICE: Semantic Propositional Image Caption Evaluation\",\"url\":\"https://www.semanticscholar.org/paper/1c54acd7d9ed8017acdc5674c9b7faac738fd651\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1781574\",\"name\":\"Chin-Yew Lin\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"60b05f32c32519a809f21642ef1eb3eaf3848008\",\"title\":\"ROUGE: A Package for Automatic Evaluation of Summaries\",\"url\":\"https://www.semanticscholar.org/paper/60b05f32c32519a809f21642ef1eb3eaf3848008\",\"venue\":\"ACL 2004\",\"year\":2004},{\"arxivId\":\"1611.01646\",\"authors\":[{\"authorId\":\"145690248\",\"name\":\"Ting Yao\"},{\"authorId\":\"3202968\",\"name\":\"Yingwei Pan\"},{\"authorId\":\"3431141\",\"name\":\"Yehao Li\"},{\"authorId\":\"3430743\",\"name\":\"Zhaofan Qiu\"},{\"authorId\":\"144025741\",\"name\":\"T. Mei\"}],\"doi\":\"10.1109/ICCV.2017.524\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"title\":\"Boosting Image Captioning with Attributes\",\"url\":\"https://www.semanticscholar.org/paper/5785466bc14529e94e54baa4ed051f7037f3b1d3\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"145297531\",\"name\":\"A. Lai\"},{\"authorId\":\"2170746\",\"name\":\"M. Hodosh\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"}],\"doi\":\"10.1162/tacl_a_00166\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"44040913380206991b1991daf1192942e038fe31\",\"title\":\"From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions\",\"url\":\"https://www.semanticscholar.org/paper/44040913380206991b1991daf1192942e038fe31\",\"venue\":\"Transactions of the Association for Computational Linguistics\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"34176020\",\"name\":\"Jesse Dodge\"},{\"authorId\":\"46479604\",\"name\":\"Amit Goyal\"},{\"authorId\":\"1721910\",\"name\":\"Kota Yamaguchi\"},{\"authorId\":\"1714215\",\"name\":\"K. Stratos\"},{\"authorId\":\"1682965\",\"name\":\"Xufeng Han\"},{\"authorId\":\"40614240\",\"name\":\"A. Mensch\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"},{\"authorId\":\"1722360\",\"name\":\"Hal Daum\\u00e9\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"355de7460120ddc1150d9ce3756f9848983f7ff4\",\"title\":\"Midge: Generating Image Descriptions From Computer Vision Detections\",\"url\":\"https://www.semanticscholar.org/paper/355de7460120ddc1150d9ce3756f9848983f7ff4\",\"venue\":\"EACL\",\"year\":2012},{\"arxivId\":\"1411.4555\",\"authors\":[{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"1726415\",\"name\":\"A. Toshev\"},{\"authorId\":\"1751569\",\"name\":\"S. Bengio\"},{\"authorId\":\"1761978\",\"name\":\"D. Erhan\"}],\"doi\":\"10.1109/CVPR.2015.7298935\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"title\":\"Show and tell: A neural image caption generator\",\"url\":\"https://www.semanticscholar.org/paper/d4dc1012d780e8e2547237eb5a6dc7b1bf47d2f0\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1505.04467\",\"authors\":[{\"authorId\":\"39172707\",\"name\":\"J. Devlin\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"2983898\",\"name\":\"Ross B. Girshick\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3ca194773fe583661b988fbdf33f7680764438b3\",\"title\":\"Exploring Nearest Neighbor Approaches for Image Captioning\",\"url\":\"https://www.semanticscholar.org/paper/3ca194773fe583661b988fbdf33f7680764438b3\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2015.7298932\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"title\":\"Deep visual-semantic alignments for generating image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/ebd1f6822d1dbb13bb813ff83a3490e0439fc9e4\",\"venue\":\"CVPR\",\"year\":2015},{\"arxivId\":\"1511.02274\",\"authors\":[{\"authorId\":\"8387085\",\"name\":\"Zichao Yang\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"}],\"doi\":\"10.1109/CVPR.2016.10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"title\":\"Stacked Attention Networks for Image Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/2c1890864c1c2b750f48316dc8b650ba4772adc5\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1609.07843\",\"authors\":[{\"authorId\":\"3375440\",\"name\":\"Stephen Merity\"},{\"authorId\":\"2228109\",\"name\":\"Caiming Xiong\"},{\"authorId\":\"40518045\",\"name\":\"James Bradbury\"},{\"authorId\":\"2166511\",\"name\":\"R. Socher\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"efbd381493bb9636f489b965a2034d529cd56bcd\",\"title\":\"Pointer Sentinel Mixture Models\",\"url\":\"https://www.semanticscholar.org/paper/efbd381493bb9636f489b965a2034d529cd56bcd\",\"venue\":\"ICLR\",\"year\":2017},{\"arxivId\":\"1502.03044\",\"authors\":[{\"authorId\":\"36303818\",\"name\":\"Kelvin Xu\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"},{\"authorId\":\"3450996\",\"name\":\"Ryan Kiros\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1760871\",\"name\":\"Aaron C. Courville\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"1804104\",\"name\":\"R. Zemel\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"title\":\"Show, Attend and Tell: Neural Image Caption Generation with Visual Attention\",\"url\":\"https://www.semanticscholar.org/paper/4d8f2d14af5991d4f0d050d22216825cac3157bd\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1606.00061\",\"authors\":[{\"authorId\":\"8553015\",\"name\":\"Jiasen Lu\"},{\"authorId\":\"145743311\",\"name\":\"Jianwei Yang\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"title\":\"Hierarchical Question-Image Co-Attention for Visual Question Answering\",\"url\":\"https://www.semanticscholar.org/paper/fb9d253258d6b3beceb9d6cd7bba6e0a29ab875b\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":\"1411.4952\",\"authors\":[{\"authorId\":\"47395669\",\"name\":\"H. Fang\"},{\"authorId\":\"144157872\",\"name\":\"Saurabh Gupta\"},{\"authorId\":\"3346186\",\"name\":\"Forrest N. Iandola\"},{\"authorId\":\"2100612\",\"name\":\"R. Srivastava\"},{\"authorId\":\"144718788\",\"name\":\"L. Deng\"},{\"authorId\":\"3127283\",\"name\":\"Piotr Doll\\u00e1r\"},{\"authorId\":\"1800422\",\"name\":\"Jianfeng Gao\"},{\"authorId\":\"144137069\",\"name\":\"X. He\"},{\"authorId\":\"49501003\",\"name\":\"Margaret Mitchell\"},{\"authorId\":\"144189092\",\"name\":\"John C. Platt\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"1681543\",\"name\":\"G. Zweig\"}],\"doi\":\"10.1109/CVPR.2015.7298754\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"title\":\"From captions to visual concepts and back\",\"url\":\"https://www.semanticscholar.org/paper/15f102c3c9f4d4fe6ba105e221df48c6e8902b3b\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1506.01144\",\"authors\":[{\"authorId\":\"34902783\",\"name\":\"Qi Wu\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"},{\"authorId\":\"2161037\",\"name\":\"L. Liu\"},{\"authorId\":\"2699095\",\"name\":\"A. Dick\"},{\"authorId\":\"5546141\",\"name\":\"A. V. D. Hengel\"}],\"doi\":\"10.1109/CVPR.2016.29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"title\":\"What Value Do Explicit High Level Concepts Have in Vision to Language Problems?\",\"url\":\"https://www.semanticscholar.org/paper/00fe3d95d0fd5f1433d81405bee772c4fe9af9c6\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.04150\",\"authors\":[{\"authorId\":\"145291669\",\"name\":\"B. Zhou\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"2677488\",\"name\":\"\\u00c0gata Lapedriza\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"143805211\",\"name\":\"A. Torralba\"}],\"doi\":\"10.1109/CVPR.2016.319\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"title\":\"Learning Deep Features for Discriminative Localization\",\"url\":\"https://www.semanticscholar.org/paper/31f9eb39d840821979e5df9f34a6e92dd9c879f2\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1409.0473\",\"authors\":[{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"title\":\"Neural Machine Translation by Jointly Learning to Align and Translate\",\"url\":\"https://www.semanticscholar.org/paper/fa72afa9b2cbc8f0d7b05d52548906610ffbb9c5\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1406.1078\",\"authors\":[{\"authorId\":\"1979489\",\"name\":\"Kyunghyun Cho\"},{\"authorId\":\"3158246\",\"name\":\"B. V. Merrienboer\"},{\"authorId\":\"1854385\",\"name\":\"\\u00c7aglar G\\u00fcl\\u00e7ehre\"},{\"authorId\":\"3335364\",\"name\":\"Dzmitry Bahdanau\"},{\"authorId\":\"2076086\",\"name\":\"Fethi Bougares\"},{\"authorId\":\"144518416\",\"name\":\"Holger Schwenk\"},{\"authorId\":\"1751762\",\"name\":\"Yoshua Bengio\"}],\"doi\":\"10.3115/v1/D14-1179\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b544dfe355a5070b60986319a3f51fb45d1348e\",\"title\":\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\",\"url\":\"https://www.semanticscholar.org/paper/0b544dfe355a5070b60986319a3f51fb45d1348e\",\"venue\":\"EMNLP\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145564333\",\"name\":\"G. Kulkarni\"},{\"authorId\":\"3128210\",\"name\":\"Visruth Premraj\"},{\"authorId\":\"2985883\",\"name\":\"Sagnik Dhar\"},{\"authorId\":\"50341924\",\"name\":\"Siming Li\"},{\"authorId\":\"1699545\",\"name\":\"Yejin Choi\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"1685538\",\"name\":\"T. Berg\"}],\"doi\":\"10.1109/CVPR.2011.5995466\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"169b847e69c35cfd475eb4dcc561a24de11762ca\",\"title\":\"Baby talk: Understanding and generating simple image descriptions\",\"url\":\"https://www.semanticscholar.org/paper/169b847e69c35cfd475eb4dcc561a24de11762ca\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1412.6632\",\"authors\":[{\"authorId\":\"36010601\",\"name\":\"Junhua Mao\"},{\"authorId\":\"145738410\",\"name\":\"W. Xu\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"40579682\",\"name\":\"J. Wang\"},{\"authorId\":\"145081362\",\"name\":\"A. Yuille\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"title\":\"Deep Captioning with Multimodal Recurrent Neural Networks (m-RNN)\",\"url\":\"https://www.semanticscholar.org/paper/54b2b6f35f1b5704dddfaa3a137a2f4ad3dfe745\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1610.02391\",\"authors\":[{\"authorId\":\"35100058\",\"name\":\"R. R. Selvaraju\"},{\"authorId\":\"2313517\",\"name\":\"Abhishek Das\"},{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"144354133\",\"name\":\"Michael Cogswell\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"},{\"authorId\":\"1746610\",\"name\":\"Dhruv Batra\"}],\"doi\":\"10.1007/s11263-019-01228-7\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"title\":\"Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization\",\"url\":\"https://www.semanticscholar.org/paper/e7eef2ac4136ec93bd306d2c9c353a13729a4553\",\"venue\":\"International Journal of Computer Vision\",\"year\":2019},{\"arxivId\":\"1409.3215\",\"authors\":[{\"authorId\":\"1701686\",\"name\":\"Ilya Sutskever\"},{\"authorId\":\"1689108\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"2827616\",\"name\":\"Quoc V. Le\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cea967b59209c6be22829699f05b8b1ac4dc092d\",\"title\":\"Sequence to Sequence Learning with Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/cea967b59209c6be22829699f05b8b1ac4dc092d\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":\"1411.5726\",\"authors\":[{\"authorId\":\"8137017\",\"name\":\"Ramakrishna Vedantam\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"},{\"authorId\":\"153432684\",\"name\":\"D. Parikh\"}],\"doi\":\"10.1109/CVPR.2015.7299087\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"258986132bf17755fe8263e42429fe73218c1534\",\"title\":\"CIDEr: Consensus-based image description evaluation\",\"url\":\"https://www.semanticscholar.org/paper/258986132bf17755fe8263e42429fe73218c1534\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2157958\",\"name\":\"Michael J. Denkowski\"},{\"authorId\":\"1784914\",\"name\":\"A. Lavie\"}],\"doi\":\"10.3115/v1/W14-3348\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"26adb749fc5d80502a6d889966e50b31391560d3\",\"title\":\"Meteor Universal: Language Specific Translation Evaluation for Any Target Language\",\"url\":\"https://www.semanticscholar.org/paper/26adb749fc5d80502a6d889966e50b31391560d3\",\"venue\":\"WMT@ACL\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1888731\",\"name\":\"M. Hejrati\"},{\"authorId\":\"21160985\",\"name\":\"M. Sadeghi\"},{\"authorId\":\"145539241\",\"name\":\"P. Young\"},{\"authorId\":\"3125805\",\"name\":\"Cyrus Rashtchian\"},{\"authorId\":\"3118681\",\"name\":\"J. Hockenmaier\"},{\"authorId\":\"144016256\",\"name\":\"D. Forsyth\"}],\"doi\":\"10.1007/978-3-642-15561-1_2\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"title\":\"Every Picture Tells a Story: Generating Sentences from Images\",\"url\":\"https://www.semanticscholar.org/paper/eaaed23a2d94feb2f1c3ff22a25777c7a78f3141\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":\"1603.03925\",\"authors\":[{\"authorId\":\"36610242\",\"name\":\"Quanzeng You\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"8056043\",\"name\":\"Zhaowen Wang\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"33642939\",\"name\":\"Jiebo Luo\"}],\"doi\":\"10.1109/CVPR.2016.503\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"title\":\"Image Captioning with Semantic Attention\",\"url\":\"https://www.semanticscholar.org/paper/bf55591e09b58ea9ce8d66110d6d3000ee804bdd\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"39717886\",\"name\":\"Xinlei Chen\"},{\"authorId\":\"1699161\",\"name\":\"C. L. Zitnick\"}],\"doi\":\"10.1109/CVPR.2015.7298856\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a72b8bbd039989db39769da836cdb287737deb92\",\"title\":\"Mind's eye: A recurrent visual representation for image caption generation\",\"url\":\"https://www.semanticscholar.org/paper/a72b8bbd039989db39769da836cdb287737deb92\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1412.2306\",\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/TPAMI.2016.2598339\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"title\":\"Deep Visual-Semantic Alignments for Generating Image Descriptions\",\"url\":\"https://www.semanticscholar.org/paper/55e022fb7581bb9e1fce678d21fb25ffbb3fbb88\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2017}],\"title\":\"Knowing When to Look: Adaptive Attention via a Visual Sentinel for Image Captioning\",\"topics\":[{\"topic\":\"Language model\",\"topicId\":\"26812\",\"url\":\"https://www.semanticscholar.org/topic/26812\"},{\"topic\":\"Encoder\",\"topicId\":\"16744\",\"url\":\"https://www.semanticscholar.org/topic/16744\"}],\"url\":\"https://www.semanticscholar.org/paper/9f4d7d622d1f7319cc511bfef661cd973e881a4c\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"