"{\"abstract\":\"In this work, we introduce a new video representation for action classification that aggregates local convolutional features across the entire spatio-temporal extent of the video. We do so by integrating state-of-the-art two-stream networks [42] with learnable spatio-temporal feature aggregation [6]. The resulting architecture is end-to-end trainable for whole-video classification. We investigate different strategies for pooling across space and time and combining signals from the different streams. We find that: (i) it is important to pool jointly across space and time, but (ii) appearance and motion streams are best aggregated into their own separate representations. Finally, we show that our representation outperforms the two-stream base architecture by a large margin (13% relative) as well as outperforms other baselines with comparable base architectures on HMDB51, UCF101, and Charades video classification benchmarks.\",\"arxivId\":\"1704.02895\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\",\"url\":\"https://www.semanticscholar.org/author/3102850\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\",\"url\":\"https://www.semanticscholar.org/author/1770537\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\",\"url\":\"https://www.semanticscholar.org/author/1737809\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\",\"url\":\"https://www.semanticscholar.org/author/1782755\"},{\"authorId\":\"145160921\",\"name\":\"Bryan C. Russell\",\"url\":\"https://www.semanticscholar.org/author/145160921\"}],\"citationVelocity\":83,\"citations\":[{\"arxivId\":\"1901.09244\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/ICCV.2019.00094\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"title\":\"DistInit: Learning Video Representations Without a Single Labeled Video\",\"url\":\"https://www.semanticscholar.org/paper/8c05c3ec1cf5ca7865cd0e73dd688e94537d5f1a\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"1910.04744\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"479c6913b92335d77e81af95f559508f0e2753e5\",\"title\":\"CATER: A diagnostic dataset for Compositional Actions and TEmporal Reasoning\",\"url\":\"https://www.semanticscholar.org/paper/479c6913b92335d77e81af95f559508f0e2753e5\",\"venue\":\"ICLR\",\"year\":2020},{\"arxivId\":\"2011.04258\",\"authors\":[{\"authorId\":\"1397311046\",\"name\":\"Bastien Vanderplaetse\"},{\"authorId\":\"153352427\",\"name\":\"S. Dupont\"}],\"doi\":\"10.1109/CVPRW50498.2020.00456\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"98b4c122b866c366fea3e6fccbabef10164c3a8c\",\"title\":\"Improved Soccer Action Spotting using both Audio and Video Streams\",\"url\":\"https://www.semanticscholar.org/paper/98b4c122b866c366fea3e6fccbabef10164c3a8c\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":\"2005.02591\",\"authors\":[{\"authorId\":\"9734988\",\"name\":\"Yuecong Xu\"},{\"authorId\":\"2562263\",\"name\":\"Jianfei Yang\"},{\"authorId\":\"120974533\",\"name\":\"Kezhi Mao\"},{\"authorId\":\"2037059\",\"name\":\"Jian-Xiong Yin\"},{\"authorId\":\"144308998\",\"name\":\"S. See\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"title\":\"Exploiting Inter-Frame Regional Correlation for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fa2d451e839f4108aaa5fdeaa5a5722f3b232d52\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1810.03964\",\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"},{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"}],\"doi\":\"10.1109/ICIP.2018.8451666\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification with Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5c5c710f4ad73c4e015afefe6a2a5f131ccfd82d\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46740305\",\"name\":\"Chunlei Wu\"},{\"authorId\":\"51172982\",\"name\":\"Haiwen Cao\"},{\"authorId\":\"1954076\",\"name\":\"W. Zhang\"},{\"authorId\":\"2250564\",\"name\":\"Leiquan Wang\"},{\"authorId\":\"19261873\",\"name\":\"Yiwei Wei\"},{\"authorId\":\"152245395\",\"name\":\"Zexin Peng\"}],\"doi\":\"10.1109/ACCESS.2019.2933303\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"title\":\"Refined Spatial Network for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f4d85123227c7b78b80f2d2076a8fe3ac627010b\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"47892850\",\"name\":\"H. Li\"},{\"authorId\":\"2581829\",\"name\":\"Dejun Zhang\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/TIP.2018.2890749\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"de58df0ceb2741e33e996322a8422aa06442d150\",\"title\":\"Action-Stage Emphasized Spatiotemporal VLAD for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de58df0ceb2741e33e996322a8422aa06442d150\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":\"2001.04583\",\"authors\":[{\"authorId\":\"38661780\",\"name\":\"Tushar Nagarajan\"},{\"authorId\":\"48513679\",\"name\":\"Yanghao Li\"},{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR42600.2020.00024\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"title\":\"Ego-Topo: Environment Affordances From Egocentric Video\",\"url\":\"https://www.semanticscholar.org/paper/7d8f6dd70e8c15105e52b5ac4666db7085689939\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145589539\",\"name\":\"Y. Peng\"},{\"authorId\":\"145222823\",\"name\":\"H. Ye\"},{\"authorId\":\"11320042\",\"name\":\"Yining Lin\"},{\"authorId\":\"3393850\",\"name\":\"Yixin Bao\"},{\"authorId\":\"50144563\",\"name\":\"Zhijian Zhao\"},{\"authorId\":\"31567595\",\"name\":\"Haonan Qiu\"},{\"authorId\":\"46215480\",\"name\":\"Y. Lu\"},{\"authorId\":\"36547117\",\"name\":\"L. Wang\"},{\"authorId\":\"3015119\",\"name\":\"Y. Zheng\"}],\"doi\":\"10.1145/3134263.3134264\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"title\":\"Large-Scale Video Classification with Elastic Streaming Sequential Data Processing System\",\"url\":\"https://www.semanticscholar.org/paper/cec8936d97dea2fcf04f175d3facaaeb65e574bf\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1641886189\",\"name\":\"Vali Ollah Maraghi\"},{\"authorId\":\"1692435\",\"name\":\"K. Faez\"}],\"doi\":\"10.1109/ICSPIS48872.2019.9066160\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3d1b7d73baf3482275532604607d6756275be73\",\"title\":\"Zero-Shot Learning on Human-Object Interaction Recognition in Video\",\"url\":\"https://www.semanticscholar.org/paper/f3d1b7d73baf3482275532604607d6756275be73\",\"venue\":\"2019 5th Iranian Conference on Signal Processing and Intelligent Systems (ICSPIS)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"48515099\",\"name\":\"Y. Li\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"title\":\"Multimodal Keyless Attention Fusion for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/686970efdcef5d11a4d2b1f5d77d5515d766f53a\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1804.04527\",\"authors\":[{\"authorId\":\"22314218\",\"name\":\"Silvio Giancola\"},{\"authorId\":\"41022271\",\"name\":\"Mohieddine Amine\"},{\"authorId\":\"41015552\",\"name\":\"Tarek Dghaily\"},{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"}],\"doi\":\"10.1109/CVPRW.2018.00223\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"982f2025925062aeafac07ae015c9ed273e4d3d6\",\"title\":\"SoccerNet: A Scalable Dataset for Action Spotting in Soccer Videos\",\"url\":\"https://www.semanticscholar.org/paper/982f2025925062aeafac07ae015c9ed273e4d3d6\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50854337\",\"name\":\"D. Xu\"},{\"authorId\":\"145974111\",\"name\":\"Jun Xiao\"},{\"authorId\":\"47122432\",\"name\":\"Zhou Zhao\"},{\"authorId\":\"144899815\",\"name\":\"J. Shao\"},{\"authorId\":\"145982709\",\"name\":\"Di Xie\"},{\"authorId\":\"143749205\",\"name\":\"Y. Zhuang\"}],\"doi\":\"10.1109/CVPR.2019.01058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"title\":\"Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction\",\"url\":\"https://www.semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPRW.2019.00351\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"title\":\"Leveraging the Present to Anticipate the Future in Videos\",\"url\":\"https://www.semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1811.01549\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"47230289\",\"name\":\"Zhichao Zhou\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"31442858\",\"name\":\"F. Li\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"47001910\",\"name\":\"Y. Li\"},{\"authorId\":\"48170161\",\"name\":\"L. Wang\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1609/aaai.v33i01.33018401\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"title\":\"StNet: Local and Global Spatial-Temporal Modeling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/94d67304c6c0d23c7dfcf008cbf799b54b8d20b9\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2900228\",\"name\":\"A. Masys\"},{\"authorId\":\"1388869398\",\"name\":\"Mamoun Alazab\"},{\"authorId\":\"50627760\",\"name\":\"Mingjian Tang\"}],\"doi\":\"10.1007/978-3-030-13057-2\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0267a77049e4dd02d61d032d061f29bd0e81b486\",\"title\":\"Deep Learning Applications for Cyber Security\",\"url\":\"https://www.semanticscholar.org/paper/0267a77049e4dd02d61d032d061f29bd0e81b486\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1709.03655\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e19ebad4739d59f999d192bac7d596b20b887f78\",\"title\":\"Learning Gating ConvNet for Two-Stream based Methods in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e19ebad4739d59f999d192bac7d596b20b887f78\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153552006\",\"name\":\"A. Franco\"},{\"authorId\":\"31649620\",\"name\":\"A. Magnani\"},{\"authorId\":\"1747625\",\"name\":\"D. Maio\"}],\"doi\":\"10.1016/j.patrec.2020.01.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2bebb0afdcc3e4c5a95e4b0b659569c096f2894c\",\"title\":\"A multimodal approach for human activity recognition based on skeleton and RGB data\",\"url\":\"https://www.semanticscholar.org/paper/2bebb0afdcc3e4c5a95e4b0b659569c096f2894c\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"46809347\",\"name\":\"Xuhuan Duan\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"1786361\",\"name\":\"Zhenxing Niu\"},{\"authorId\":\"144988571\",\"name\":\"Gang Hua\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.3390/s18051657\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"title\":\"Segment-Tube: Spatio-Temporal Action Localization in Untrimmed Videos with Per-Frame Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/f02a6bccdaee14ab55ad94263539f4f33f1b15bb\",\"venue\":\"Sensors\",\"year\":2018},{\"arxivId\":\"2006.09675\",\"authors\":[{\"authorId\":\"46578437\",\"name\":\"K. Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"}],\"doi\":\"10.1109/tcsvt.2020.2984569\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"046f98d55c557d574ef84631cae8d65d709585ed\",\"title\":\"A Real-time Action Representation with Temporal Encoding and Deep Compression\",\"url\":\"https://www.semanticscholar.org/paper/046f98d55c557d574ef84631cae8d65d709585ed\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1910.00628\",\"authors\":[{\"authorId\":\"51036510\",\"name\":\"A. Narayanan\"},{\"authorId\":\"71124982\",\"name\":\"Avinash Siravuru\"},{\"authorId\":\"2086607\",\"name\":\"B. Dariush\"}],\"doi\":\"10.1109/LRA.2020.2967738\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"997a31a9a32a1769adccbf4a5f77d69ac29fe229\",\"title\":\"Gated Recurrent Fusion to Learn Driving Behavior from Temporal Multimodal Data\",\"url\":\"https://www.semanticscholar.org/paper/997a31a9a32a1769adccbf4a5f77d69ac29fe229\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"1809.03669\",\"authors\":[{\"authorId\":\"3865974\",\"name\":\"Xiaolin Song\"},{\"authorId\":\"40093162\",\"name\":\"Cuiling Lan\"},{\"authorId\":\"144864745\",\"name\":\"Wenjun Zeng\"},{\"authorId\":\"1757173\",\"name\":\"Junliang Xing\"},{\"authorId\":\"6485172\",\"name\":\"Xiaoyan Sun\"},{\"authorId\":\"40354745\",\"name\":\"J. Yang\"}],\"doi\":\"10.1109/TCSVT.2019.2896029\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"title\":\"Temporal\\u2013Spatial Mapping for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/96f0da034d090a3ecadd0fb92333bb681f23ab14\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1832019\",\"name\":\"Fuhua Shang\"},{\"authorId\":\"145421603\",\"name\":\"Tao Han\"},{\"authorId\":\"152236895\",\"name\":\"Feng Tian\"},{\"authorId\":\"1884170385\",\"name\":\"Jun Tao\"},{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"}],\"doi\":\"10.1109/ACCESS.2020.3014691\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"title\":\"A Multimodal Pairwise Discrimination Network for Cross-Domain Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1c93dfb167a90c2a5a7b802c629327224d4ee806\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":\"2002.03342\",\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":null,\"name\":\"Yi Yang\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPRW50498.2020.00346\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"de79226c40767073dea787327637c8415b1bc60a\",\"title\":\"Dynamic Inference: A New Approach Toward Efficient Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de79226c40767073dea787327637c8415b1bc60a\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"38b217f438697476c3fbffd3f1595c17fd05ee89\",\"title\":\"Adapting computer vision models to limitations on input dimensionality and model complexity\",\"url\":\"https://www.semanticscholar.org/paper/38b217f438697476c3fbffd3f1595c17fd05ee89\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2004.01808\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"143798882\",\"name\":\"Mihir Jain\"},{\"authorId\":\"2954103\",\"name\":\"B. E. Bejnordi\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"title\":\"TimeGate: Conditional Gating of Segments in Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/24fd7077532323fffec0aab2bea3d1db4159ffc1\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.03462\",\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"143930563\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"60840dce8073545641198c297796902fa390c719\",\"title\":\"PAN: Towards Fast Action Recognition via Learning Persistence of Appearance\",\"url\":\"https://www.semanticscholar.org/paper/60840dce8073545641198c297796902fa390c719\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23604671\",\"name\":\"H. Wang\"},{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"}],\"doi\":\"10.1145/3240508.3240677\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"title\":\"Spotting and Aggregating Salient Regions for Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/e5abe63d687f927a0ac61e9ad62f88b355d89caf\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2087534\",\"name\":\"Y. Zhu\"},{\"authorId\":\"1990768\",\"name\":\"Guangcan Liu\"}],\"doi\":\"10.1007/s00371-019-01770-y\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"084655e3d230385103d080544d900aa4aa91cf10\",\"title\":\"Fine-grained action recognition using multi-view attentions\",\"url\":\"https://www.semanticscholar.org/paper/084655e3d230385103d080544d900aa4aa91cf10\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":\"1707.04143\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1732242\",\"name\":\"Y. Liu\"},{\"authorId\":null,\"name\":\"Yi Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c0ff3fbca31be3c9ed2460df6c6edecec19fc3c\",\"title\":\"UTS submission to Google YouTube-8M Challenge 2017\",\"url\":\"https://www.semanticscholar.org/paper/7c0ff3fbca31be3c9ed2460df6c6edecec19fc3c\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":\"2008.07819\",\"authors\":[{\"authorId\":\"72831997\",\"name\":\"T. Ma\"},{\"authorId\":\"101160956\",\"name\":\"L. Zhang\"},{\"authorId\":\"87641774\",\"name\":\"X. Diao\"},{\"authorId\":\"1411075691\",\"name\":\"O. Ma\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"title\":\"ConvGRU in Fine-grained Pitching Action Recognition for Action Outcome Prediction\",\"url\":\"https://www.semanticscholar.org/paper/1c6a82bcb60db6f0b131e270e4ffb8b84bc01c6e\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46433230\",\"name\":\"Y. Zhou\"},{\"authorId\":\"9846740\",\"name\":\"Jiamin Ren\"},{\"authorId\":\"46275945\",\"name\":\"Jingyu Li\"},{\"authorId\":\"1739512\",\"name\":\"Litong Feng\"},{\"authorId\":\"1725421\",\"name\":\"Shi Qiu\"},{\"authorId\":\"144389951\",\"name\":\"P. Luo\"}],\"doi\":\"10.1145/3134263.3134265\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"title\":\"Video Classification via Relational Feature Encoding Networks\",\"url\":\"https://www.semanticscholar.org/paper/be068ce0d5284dbd2c4c8ba4a31a41da2f794193\",\"venue\":\"LSVC '17\",\"year\":2017},{\"arxivId\":\"2012.11552\",\"authors\":[{\"authorId\":\"2475428\",\"name\":\"Spyros Gidaris\"},{\"authorId\":\"3056236\",\"name\":\"Andrei Bursuc\"},{\"authorId\":\"145037972\",\"name\":\"Gilles Puy\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0026d112cf8f3b98e45455d967de9ca3c33d22f6\",\"title\":\"Online Bag-of-Visual-Words Generation for Unsupervised Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/0026d112cf8f3b98e45455d967de9ca3c33d22f6\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47637491\",\"name\":\"M. Lakhal\"},{\"authorId\":\"7840884\",\"name\":\"A. Clap\\u00e9s\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"},{\"authorId\":\"145440152\",\"name\":\"A. Cavallaro\"}],\"doi\":\"10.1007/978-3-030-11012-3_40\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"title\":\"Residual Stacked RNNs for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d1a8e7c833318d30d30e3eeb0cef139f86a02bcc\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151474893\",\"name\":\"Maryam Koohzadi\"},{\"authorId\":\"48315995\",\"name\":\"Nasrollah Moghadam Charkari\"}],\"doi\":\"10.1007/s11063-020-10248-1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"397d3252caa29d233ab97cf7213f398c17c28409\",\"title\":\"A Context Based Deep Temporal Embedding Network in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/397d3252caa29d233ab97cf7213f398c17c28409\",\"venue\":\"Neural Processing Letters\",\"year\":2020},{\"arxivId\":\"1808.03766\",\"authors\":[{\"authorId\":\"2931652\",\"name\":\"Bernard Ghanem\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"145404204\",\"name\":\"Cees G. M. Snoek\"},{\"authorId\":\"3175258\",\"name\":\"Fabian Caba Heilbron\"},{\"authorId\":\"19198894\",\"name\":\"Humam Alwassel\"},{\"authorId\":\"144201025\",\"name\":\"Victor Escorcia\"},{\"authorId\":\"145237361\",\"name\":\"R. Krishna\"},{\"authorId\":\"8983218\",\"name\":\"S. Buch\"},{\"authorId\":\"3409955\",\"name\":\"C. D. Dao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5468c96e3846da23c26b59c28c313506bffbf7ce\",\"title\":\"The ActivityNet Large-Scale Activity Recognition Challenge 2018 Summary\",\"url\":\"https://www.semanticscholar.org/paper/5468c96e3846da23c26b59c28c313506bffbf7ce\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145749153\",\"name\":\"R. Leyva\"},{\"authorId\":\"145395437\",\"name\":\"F. Doctor\"},{\"authorId\":\"2031669\",\"name\":\"A. Herrera\"},{\"authorId\":\"1959195375\",\"name\":\"Sohail Sahab\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a50e6b64d5351cd3d4780c232fc3f7512a72aec4\",\"title\":\"Multimodal Deep Features Fusion for Video Memorability Prediction\",\"url\":\"https://www.semanticscholar.org/paper/a50e6b64d5351cd3d4780c232fc3f7512a72aec4\",\"venue\":\"MediaEval\",\"year\":2019},{\"arxivId\":\"1908.10136\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f0446862cbdf61974e039a85d349d7f7864f42c1\",\"title\":\"Cooperative Cross-Stream Network for Discriminative Action Representation\",\"url\":\"https://www.semanticscholar.org/paper/f0446862cbdf61974e039a85d349d7f7864f42c1\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51208565\",\"name\":\"S. Cheng\"},{\"authorId\":\"92194342\",\"name\":\"Guoyi Qin\"},{\"authorId\":\"47320067\",\"name\":\"S. Li\"},{\"authorId\":\"144917416\",\"name\":\"M. Xie\"},{\"authorId\":\"1730232\",\"name\":\"Zheng Ma\"}],\"doi\":\"10.1109/ICCWAMTIP47768.2019.9067588\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"04538c624c44c9735f519a411c95732cc638e469\",\"title\":\"VLAD-SSTA: VLAD with Soft Spatio-Temporal Assignment for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/04538c624c44c9735f519a411c95732cc638e469\",\"venue\":\"2019 16th International Computer Conference on Wavelet Active Media Technology and Information Processing\",\"year\":2019},{\"arxivId\":\"2011.12619\",\"authors\":[{\"authorId\":\"147084112\",\"name\":\"Jack Humphreys\"},{\"authorId\":\"48354826\",\"name\":\"Z. Chen\"},{\"authorId\":\"145047838\",\"name\":\"Dacheng Tao\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"e88bff50c417703239e0a832fddb267196ab5a99\",\"title\":\"Recent Progress in Appearance-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e88bff50c417703239e0a832fddb267196ab5a99\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1901.02229\",\"authors\":[{\"authorId\":\"36727640\",\"name\":\"Krishna Kanth Nakka\"},{\"authorId\":\"2862871\",\"name\":\"Mathieu Salzmann\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"cda787954a62630e097a1edd4b0334b4072124a0\",\"title\":\"Interpretable BoW Networks for Adversarial Example Detection\",\"url\":\"https://www.semanticscholar.org/paper/cda787954a62630e097a1edd4b0334b4072124a0\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840277\",\"name\":\"Song Han\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"title\":\"Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/5925a25dfe107c49c636eccb8f9fd1aeef7b438c\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1812.02817\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"2252963\",\"name\":\"Xinyu Li\"},{\"authorId\":\"3302978\",\"name\":\"Kaixiang Huang\"},{\"authorId\":\"7707929\",\"name\":\"Yehan Wang\"},{\"authorId\":\"51231992\",\"name\":\"Shuhong Chen\"},{\"authorId\":\"144555425\",\"name\":\"Ivan Marsic\"}],\"doi\":null,\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"556ca2389246b0a848b578dc824b930e1337a4bc\",\"title\":\"Tri-axial Self-Attention for Concurrent Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/556ca2389246b0a848b578dc824b930e1337a4bc\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1907.09665\",\"authors\":[{\"authorId\":\"48535072\",\"name\":\"Xiangyu He\"},{\"authorId\":\"145105838\",\"name\":\"Ke Cheng\"},{\"authorId\":\"91583500\",\"name\":\"Q. Chen\"},{\"authorId\":\"2571792\",\"name\":\"Q. Hu\"},{\"authorId\":\"3493834\",\"name\":\"Peisong Wang\"},{\"authorId\":\"143949499\",\"name\":\"J. Cheng\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a474c69b29ad7dc7009003f531a2d06ca2682cc2\",\"title\":\"Compact Global Descriptor for Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/a474c69b29ad7dc7009003f531a2d06ca2682cc2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.06822\",\"authors\":[{\"authorId\":\"2173531\",\"name\":\"Sangwoo Cho\"},{\"authorId\":\"1691260\",\"name\":\"H. Foroosh\"}],\"doi\":\"10.1007/978-3-030-20887-5_22\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"title\":\"Spatio-Temporal Fusion Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fd4303b2f54a2a87c4ee33b33359b85258d4a726\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"1904.07846\",\"authors\":[{\"authorId\":\"2420123\",\"name\":\"D. Dwibedi\"},{\"authorId\":\"3152281\",\"name\":\"Y. Aytar\"},{\"authorId\":\"2704494\",\"name\":\"J. Tompson\"},{\"authorId\":\"3142556\",\"name\":\"Pierre Sermanet\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00190\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"75662c7ab05db37c52a2d750af2a8b712bbf3d53\",\"title\":\"Temporal Cycle-Consistency Learning\",\"url\":\"https://www.semanticscholar.org/paper/75662c7ab05db37c52a2d750af2a8b712bbf3d53\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"153168978\",\"name\":\"Wen Zhou\"}],\"doi\":\"10.1016/j.jvcir.2019.102650\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"title\":\"Deep spectral feature pyramid in the frequency domain for long-term action recognition\",\"url\":\"https://www.semanticscholar.org/paper/a22e41d8ac3c56072d5fe1136567d1b82d9bb46e\",\"venue\":\"J. Vis. Commun. Image Represent.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1471424585\",\"name\":\"Deepika Roselind Johnson\"},{\"authorId\":\"69493918\",\"name\":\"V. R. Uthariaraj\"}],\"doi\":\"10.1155/2020/8852404\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"title\":\"A Novel Parameter Initialization Technique Using RBM-NN for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eded9af5fc3c7462b6e6e355e0a2f1bbe8d66141\",\"venue\":\"Comput. Intell. Neurosci.\",\"year\":2020},{\"arxivId\":\"2009.07420\",\"authors\":[{\"authorId\":\"3671120\",\"name\":\"Yanyi Zhang\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"144555425\",\"name\":\"I. Marsic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"title\":\"Multi-Label Activity Recognition using Activity-specific Features\",\"url\":\"https://www.semanticscholar.org/paper/d951f225ab2d64af36e9c44a658ac79c2afde7f3\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51036510\",\"name\":\"Athma Narayanan\"},{\"authorId\":\"145608726\",\"name\":\"Avinash Siravuru\"},{\"authorId\":\"2086607\",\"name\":\"Behzad Dariush\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"6f3e3703491e8e193dbe24b0dd832767c0a9fada\",\"title\":\"Temporal Multimodal Fusion for Driver Behavior Prediction Tasks using Gated Recurrent Fusion Units\",\"url\":\"https://www.semanticscholar.org/paper/6f3e3703491e8e193dbe24b0dd832767c0a9fada\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50322696\",\"name\":\"Haoliang Tan\"},{\"authorId\":\"48169980\",\"name\":\"L. Wang\"},{\"authorId\":\"46324995\",\"name\":\"Q. Zhang\"},{\"authorId\":\"2687716\",\"name\":\"Zhanning Gao\"},{\"authorId\":\"1715389\",\"name\":\"Nanning Zheng\"},{\"authorId\":\"144988570\",\"name\":\"Gang Hua\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8715474732e8d024078d482b8d0f7cae88a31bcc\",\"title\":\"Object Affordances Graph Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8715474732e8d024078d482b8d0f7cae88a31bcc\",\"venue\":\"BMVC\",\"year\":2019},{\"arxivId\":\"1812.09533\",\"authors\":[{\"authorId\":\"27069030\",\"name\":\"Zixi Cai\"},{\"authorId\":\"40494138\",\"name\":\"H. Neher\"},{\"authorId\":\"52564092\",\"name\":\"Kanav Vats\"},{\"authorId\":\"1720258\",\"name\":\"David A Clausi\"},{\"authorId\":\"1702003\",\"name\":\"J. Zelek\"}],\"doi\":\"10.1109/CVPRW.2019.00310\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"title\":\"Temporal Hockey Action Recognition via Pose and Optical Flows\",\"url\":\"https://www.semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)\",\"year\":2019},{\"arxivId\":\"1905.05143\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"title\":\"VideoGraph: Recognizing Minutes-Long Human Activities in Videos\",\"url\":\"https://www.semanticscholar.org/paper/3d17bc4c3ffcf9e2ecebcae0f5f24f9ee8cc0dcf\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1711.11248\",\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"1688882\",\"name\":\"Y. LeCun\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/CVPR.2018.00675\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"title\":\"A Closer Look at Spatiotemporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89c3050522a0bb9820c32dc7444e003ef0d3e2e4\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1909.09602\",\"authors\":[{\"authorId\":\"1388016741\",\"name\":\"Chris Careaga\"},{\"authorId\":\"144156036\",\"name\":\"Brian Hutchinson\"},{\"authorId\":\"47312946\",\"name\":\"Nathan Hodas\"},{\"authorId\":\"21785345\",\"name\":\"L. Phillips\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"title\":\"Metric-Based Few-Shot Learning for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/de3c3e7f2a9d6b48e01f02ec452458e9f37bb6bc\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152519410\",\"name\":\"Xufeng Qian\"},{\"authorId\":\"2125211\",\"name\":\"Yueting Zhuang\"},{\"authorId\":\"1527113445\",\"name\":\"Yi-Meng Li\"},{\"authorId\":\"51237531\",\"name\":\"Shaoning Xiao\"},{\"authorId\":\"3290437\",\"name\":\"S. Pu\"},{\"authorId\":\"1384523745\",\"name\":\"Jun Xiao\"}],\"doi\":\"10.1145/3343031.3351058\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"434825e75b5152670d10d9b18e1fce0d6954464f\",\"title\":\"Video Relation Detection with Spatio-Temporal Graph\",\"url\":\"https://www.semanticscholar.org/paper/434825e75b5152670d10d9b18e1fce0d6954464f\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"2010.06647\",\"authors\":[{\"authorId\":\"153634296\",\"name\":\"Matthew Hutchinson\"},{\"authorId\":\"74882299\",\"name\":\"Vijay Gadepally\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"65955a106905afb90a2a2fa74e48c6d6d597892f\",\"title\":\"Video Action Understanding: A Tutorial\",\"url\":\"https://www.semanticscholar.org/paper/65955a106905afb90a2a2fa74e48c6d6d597892f\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1527097122\",\"name\":\"Y. Li\"},{\"authorId\":\"6681872\",\"name\":\"Chunping Liu\"},{\"authorId\":\"144602988\",\"name\":\"Yi Ji\"},{\"authorId\":\"9359893\",\"name\":\"Shengrong Gong\"}],\"doi\":\"10.1145/3378026\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"083e075864cdf19117f6b5f78db877347e2bca4f\",\"title\":\"Spatio-temporal Deep Residual Network with Hierarchical Attentions for Video Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/083e075864cdf19117f6b5f78db877347e2bca4f\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1906.04226\",\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"143907244\",\"name\":\"Yi Yang\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"title\":\"FASTER Recurrent Networks for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/8a71b7cf982cf1b54cda4f0746d4ba7c7ea3f4e4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48599063\",\"name\":\"Ziqi Yang\"},{\"authorId\":\"46810102\",\"name\":\"X. Gong\"},{\"authorId\":\"46791330\",\"name\":\"Ying Guo\"},{\"authorId\":\"49663403\",\"name\":\"Wenbin Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2990683\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"title\":\"A Temporal Sequence Dual-Branch Network for Classifying Hybrid Ultrasound Data of Breast Cancer\",\"url\":\"https://www.semanticscholar.org/paper/52b6cb41e3603efadcacac33ee0ce0e92dc344bc\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"01aecbebc76d494853f6f525f4d285564e697fa7\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/01aecbebc76d494853f6f525f4d285564e697fa7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2006.06028\",\"authors\":[{\"authorId\":\"36727640\",\"name\":\"Krishna Kanth Nakka\"},{\"authorId\":\"2862871\",\"name\":\"M. Salzmann\"}],\"doi\":null,\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"e42b6dbf2e050b78890022d6b834c26567eb2fd5\",\"title\":\"Towards Robust Fine-grained Recognition by Maximal Separation of Discriminative Features\",\"url\":\"https://www.semanticscholar.org/paper/e42b6dbf2e050b78890022d6b834c26567eb2fd5\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2004.10141\",\"authors\":[{\"authorId\":\"1397958297\",\"name\":\"R. Ben-Ari\"},{\"authorId\":\"1645272447\",\"name\":\"Mor Shpigel\"},{\"authorId\":\"1408268488\",\"name\":\"Ophir Azulai\"},{\"authorId\":\"46189009\",\"name\":\"U. Barzelay\"},{\"authorId\":\"143679933\",\"name\":\"Daniel Rotman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b7637b757133c1aa88403754bdc42e25ad3ab31\",\"title\":\"TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b7637b757133c1aa88403754bdc42e25ad3ab31\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145905489\",\"name\":\"Y. Huang\"},{\"authorId\":\"1696527\",\"name\":\"S. Lai\"},{\"authorId\":\"35392319\",\"name\":\"Shao-Heng Tai\"}],\"doi\":\"10.1007/978-3-030-11012-3_33\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"8639c08322b30a456662e439b5bb7edd2e2551e6\",\"title\":\"Human Action Recognition Based on Temporal Pose CNN and Multi-dimensional Fusion\",\"url\":\"https://www.semanticscholar.org/paper/8639c08322b30a456662e439b5bb7edd2e2551e6\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1811.09974\",\"authors\":[{\"authorId\":\"3128506\",\"name\":\"Yanghao Li\"},{\"authorId\":\"3384254\",\"name\":\"Sijie Song\"},{\"authorId\":\"50023941\",\"name\":\"Y. Li\"},{\"authorId\":\"41127426\",\"name\":\"Jiaying Liu\"}],\"doi\":\"10.1609/aaai.v33i01.33018674\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6ae72dc774f62b190036fb094be4558d827e53d2\",\"title\":\"Temporal Bilinear Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6ae72dc774f62b190036fb094be4558d827e53d2\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Yang Li\"},{\"authorId\":\"144957598\",\"name\":\"K. Li\"},{\"authorId\":\"47120598\",\"name\":\"X. Wang\"}],\"doi\":\"10.24963/ijcai.2018/112\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ac1c192f920fa501175d1edc187db1d31dc97c03\",\"title\":\"Deeply-Supervised CNN Model for Action Recognition with Trainable Feature Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/ac1c192f920fa501175d1edc187db1d31dc97c03\",\"venue\":\"IJCAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26986716\",\"name\":\"Clemens Pohlt\"},{\"authorId\":\"2016549\",\"name\":\"T. Schlegl\"},{\"authorId\":\"1724954\",\"name\":\"S. Wachsmuth\"}],\"doi\":\"10.1109/SMC.2019.8913873\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eb4ee1232012908a0b40fa927be4bbcb0e646edf\",\"title\":\"Human Work Activity Recognition for Working Cells in Industrial Production Contexts\",\"url\":\"https://www.semanticscholar.org/paper/eb4ee1232012908a0b40fa927be4bbcb0e646edf\",\"venue\":\"2019 IEEE International Conference on Systems, Man and Cybernetics (SMC)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1409338179\",\"name\":\"Ruibing Jin\"},{\"authorId\":\"100739830\",\"name\":\"Jianliang Wang\"}],\"doi\":\"10.1109/ICCA.2019.8899924\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f13b70821c42a4b04a26dd887426cb2ab6205924\",\"title\":\"Two-stream network for online quadrotor detection without dedicated annotations\",\"url\":\"https://www.semanticscholar.org/paper/f13b70821c42a4b04a26dd887426cb2ab6205924\",\"venue\":\"2019 IEEE 15th International Conference on Control and Automation (ICCA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144990601\",\"name\":\"Hao Sun\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"2263014\",\"name\":\"Xiangtao Zheng\"},{\"authorId\":\"7828998\",\"name\":\"Xiaoqiang Lu\"}],\"doi\":\"10.1109/TGRS.2019.2931801\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dd6df50588d6c65c4dd9b95d85cba62d766a29f5\",\"title\":\"Remote Sensing Scene Classification by Gated Bidirectional Network\",\"url\":\"https://www.semanticscholar.org/paper/dd6df50588d6c65c4dd9b95d85cba62d766a29f5\",\"venue\":\"IEEE Transactions on Geoscience and Remote Sensing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3193566\",\"name\":\"Yongbo Bo\"},{\"authorId\":\"19244094\",\"name\":\"Yangdi Lu\"},{\"authorId\":\"145850224\",\"name\":\"Wenbo He\"}],\"doi\":\"10.1109/WACV45572.2020.9093481\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5ced7f13f2c616f770c126eba68626a4830205de\",\"title\":\"Few-Shot Learning of Video Action Recognition Only Based on Video Contents\",\"url\":\"https://www.semanticscholar.org/paper/5ced7f13f2c616f770c126eba68626a4830205de\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"46285992\",\"name\":\"Y. Yang\"},{\"authorId\":\"11445222\",\"name\":\"H. Wang\"}],\"doi\":\"10.1609/AAAI.V34I07.7012\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"title\":\"FASTER Recurrent Networks for Efficient Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d718baf9187fa5851a9389e5e250d47ba1210e0e\",\"venue\":\"AAAI\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6435837116d2d08d4f873e2b556c29a4d20812d\",\"title\":\"Holistic Large Scale Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e6435837116d2d08d4f873e2b556c29a4d20812d\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1708.07335\",\"authors\":[{\"authorId\":\"1778374\",\"name\":\"Savas \\u00d6zkan\"},{\"authorId\":\"1929001\",\"name\":\"G. Akar\"}],\"doi\":\"10.1109/ICCVW.2017.366\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"9addd3eb94e8ef7b826f2ec38b84d28a1f0c5cad\",\"title\":\"Relaxed Spatio-Temporal Deep Feature Aggregation for Real-Fake Expression Prediction\",\"url\":\"https://www.semanticscholar.org/paper/9addd3eb94e8ef7b826f2ec38b84d28a1f0c5cad\",\"venue\":\"2017 IEEE International Conference on Computer Vision Workshops (ICCVW)\",\"year\":2017},{\"arxivId\":\"1908.08498\",\"authors\":[{\"authorId\":\"48842721\",\"name\":\"Evangelos Kazakos\"},{\"authorId\":\"19263506\",\"name\":\"Arsha Nagrani\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCV.2019.00559\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"title\":\"EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7c9de67cc76aeecddcd07e8898acea3ef4eba738\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2012.08510\",\"authors\":[{\"authorId\":\"144234446\",\"name\":\"Bo He\"},{\"authorId\":\"50031265\",\"name\":\"Xitong Yang\"},{\"authorId\":\"3099139\",\"name\":\"Zuxuan Wu\"},{\"authorId\":\"48444479\",\"name\":\"Hao Chen\"},{\"authorId\":\"38760573\",\"name\":\"Ser-Nam Lim\"},{\"authorId\":\"51453757\",\"name\":\"Abhinav Shrivastava\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b77967866434f46c41f25baf7149d9b027b600b3\",\"title\":\"GTA: Global Temporal Attention for Video Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/b77967866434f46c41f25baf7149d9b027b600b3\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2012.10283\",\"authors\":[{\"authorId\":\"3330863\",\"name\":\"F. Hu\"},{\"authorId\":\"2890278\",\"name\":\"Eva Mohedano\"},{\"authorId\":\"98536322\",\"name\":\"N. O'Connor\"},{\"authorId\":\"123746715\",\"name\":\"K. McGuinness\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"title\":\"Temporal Bilinear Encoding Network of Audio-Visual Features at Low Sampling Rates\",\"url\":\"https://www.semanticscholar.org/paper/eeb3393f1b01fb523b6aa990c5778e824ccc439d\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2008.10850\",\"authors\":[{\"authorId\":\"40951853\",\"name\":\"Manyuan Zhang\"},{\"authorId\":\"12920342\",\"name\":\"Guanglu Song\"},{\"authorId\":\"145798292\",\"name\":\"Hang Zhou\"},{\"authorId\":\"30752055\",\"name\":\"Y. Liu\"}],\"doi\":\"10.1007/978-3-030-58607-2_1\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"title\":\"Discriminability Distillation in Group Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/a1027f7c27273c8c0aac30bbd31da87a0fa342db\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51231094\",\"name\":\"P. Nikolov\"},{\"authorId\":\"1734848\",\"name\":\"O. Boumbarov\"},{\"authorId\":\"1750280\",\"name\":\"A. Manolova\"},{\"authorId\":\"1710302\",\"name\":\"K. Tonchev\"},{\"authorId\":\"1703073\",\"name\":\"Vladimir Poulkov\"}],\"doi\":\"10.1109/TSP.2018.8441171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d4d7a134872ab438086c36ef58749fe66a633be5\",\"title\":\"Skeleton-Based Human Activity Recognition by Spatio-Temporal Representation and Convolutional Neural Networks with application to Cyber Physical Systems with Human in the Loop\",\"url\":\"https://www.semanticscholar.org/paper/d4d7a134872ab438086c36ef58749fe66a633be5\",\"venue\":\"2018 41st International Conference on Telecommunications and Signal Processing (TSP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"5808321\",\"name\":\"Meng-Chieh Wu\"},{\"authorId\":\"145888908\",\"name\":\"Ching-Te Chiu\"}],\"doi\":\"10.1016/j.sysarc.2019.101695\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"title\":\"Multi-teacher knowledge distillation for compressed video action recognition based on deep learning\",\"url\":\"https://www.semanticscholar.org/paper/25da842e3efcdd96b98e1276a59e6073d9c0b970\",\"venue\":\"J. Syst. Archit.\",\"year\":2020},{\"arxivId\":\"1811.08383\",\"authors\":[{\"authorId\":\"46698300\",\"name\":\"Ji Lin\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"143840275\",\"name\":\"Song Han\"}],\"doi\":\"10.1109/ICCV.2019.00718\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bbfd46721c145852e443ae4aad35148b814bf91\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/4bbfd46721c145852e443ae4aad35148b814bf91\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2648498\",\"name\":\"Wenlong Xie\"},{\"authorId\":\"1720100\",\"name\":\"H. Yao\"},{\"authorId\":\"1759841\",\"name\":\"Xiaoshuai Sun\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"1755487\",\"name\":\"S. Zhao\"},{\"authorId\":\"144078686\",\"name\":\"Tat-Seng Chua\"}],\"doi\":\"10.1109/TMM.2018.2879749\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c1d06998c57d06a792df88a48f4e52b59f730ff\",\"title\":\"Discovering Latent Discriminative Patterns for Multi-Mode Event Representation\",\"url\":\"https://www.semanticscholar.org/paper/2c1d06998c57d06a792df88a48f4e52b59f730ff\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"145251501\",\"name\":\"W. Zou\"},{\"authorId\":\"144168342\",\"name\":\"Zheng Zhu\"}],\"doi\":\"10.1109/ICPR.2018.8545639\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"title\":\"Two-Stream Gated Fusion ConvNets for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/fe6edc8c6e4cff6a2c115648a2135ffd47b04a08\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"2006.00830\",\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"1803321310\",\"name\":\"Angela Yao\"}],\"doi\":\"10.1007/978-3-030-58517-4_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"title\":\"Temporal Aggregate Representations for Long-Range Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/6c8f191fa7b5c51af0810b0996a0ef25b4db4d9a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"6018169\",\"name\":\"Zhiqiang Tao\"},{\"authorId\":\"13048116\",\"name\":\"Y. Liu\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":\"10.1109/ICCV.2019.00631\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"ae79d06b12cef96868a6aaee3c8a8115cc957f80\",\"title\":\"Generative Multi-View Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ae79d06b12cef96868a6aaee3c8a8115cc957f80\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145061360\",\"name\":\"S. Ravi\"},{\"authorId\":\"30430452\",\"name\":\"M. Suman\"},{\"authorId\":\"144186025\",\"name\":\"P. Kishore\"},{\"authorId\":\"79324299\",\"name\":\"Kiran Kumar Eepuri\"},{\"authorId\":\"48387925\",\"name\":\"Maddala Teja Kiran Kumar\"},{\"authorId\":\"41212177\",\"name\":\"D. Kumar\"}],\"doi\":\"10.1016/J.COLA.2019.04.002\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fed9af888038dcffd51d648c9e81e8a53c7efcd2\",\"title\":\"Multi modal spatio temporal co-trained CNNs with single modal testing on RGB-D based sign language gesture recognition\",\"url\":\"https://www.semanticscholar.org/paper/fed9af888038dcffd51d648c9e81e8a53c7efcd2\",\"venue\":\"J. Comput. Lang.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1423699581\",\"name\":\"A. F. D. Marsiano\"},{\"authorId\":\"9149246\",\"name\":\"I. Soesanti\"},{\"authorId\":\"2969172\",\"name\":\"Igi Ardiyanto\"}],\"doi\":\"10.1109/ICAICTA.2019.8904395\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"title\":\"Deep learning-based Anomaly Detection on Surveillance Videos: Recent Advances\",\"url\":\"https://www.semanticscholar.org/paper/8bbd6a362fd9afe63c8780d9ec199eeb257c5eef\",\"venue\":\"2019 International Conference of Advanced Informatics: Concepts, Theory and Applications (ICAICTA)\",\"year\":2019},{\"arxivId\":\"2004.01398\",\"authors\":[{\"authorId\":\"48513712\",\"name\":\"Y. Li\"},{\"authorId\":\"102880425\",\"name\":\"Bin Ji\"},{\"authorId\":\"48203223\",\"name\":\"Xintian Shi\"},{\"authorId\":\"98697812\",\"name\":\"J. Zhang\"},{\"authorId\":\"48418655\",\"name\":\"Bin Kang\"},{\"authorId\":\"48170350\",\"name\":\"Limin Wang\"}],\"doi\":\"10.1109/cvpr42600.2020.00099\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"title\":\"TEA: Temporal Excitation and Aggregation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1ebeb84e2b8e1182a2b4821c906200ecc49ae187\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51508179\",\"name\":\"Z. Gao\"},{\"authorId\":\"114320931\",\"name\":\"Hai-Zhen Xuan\"},{\"authorId\":\"41189853\",\"name\":\"H. Zhang\"},{\"authorId\":\"31197849\",\"name\":\"Shaohua Wan\"},{\"authorId\":\"2840539\",\"name\":\"Kim-Kwang Raymond Choo\"}],\"doi\":\"10.1109/JIOT.2019.2911669\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"title\":\"Adaptive Fusion and Category-Level Dictionary Learning Model for Multiview Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/95ab737cc9d496fa2ac544169465c10b962d4cd4\",\"venue\":\"IEEE Internet of Things Journal\",\"year\":2019},{\"arxivId\":\"2012.06567\",\"authors\":[{\"authorId\":\"1805946041\",\"name\":\"Yi Zhu\"},{\"authorId\":\"21657733\",\"name\":\"X. Li\"},{\"authorId\":\"49046944\",\"name\":\"C. Liu\"},{\"authorId\":\"2890820\",\"name\":\"Mohammadreza Zolfaghari\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"22539483\",\"name\":\"Chongruo Wu\"},{\"authorId\":\"152781163\",\"name\":\"Z. Zhang\"},{\"authorId\":\"2397422\",\"name\":\"Joseph Tighe\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"49140510\",\"name\":\"M. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"title\":\"A Comprehensive Study of Deep Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ee12f02830a5e1f7cadd3623dfed495cf099bc82\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"2010.11757\",\"authors\":[{\"authorId\":\"48239920\",\"name\":\"Chun-Fu Chen\"},{\"authorId\":\"1819152\",\"name\":\"R. Panda\"},{\"authorId\":\"40544169\",\"name\":\"K. Ramakrishnan\"},{\"authorId\":\"1723233\",\"name\":\"R. Feris\"},{\"authorId\":\"38060482\",\"name\":\"J. M. Cohn\"},{\"authorId\":\"143868587\",\"name\":\"A. Oliva\"},{\"authorId\":\"33421444\",\"name\":\"Quanfu Fan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"title\":\"Deep Analysis of CNN-based Spatio-temporal Representations for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f5c2623a44660ad9fe6cd46710fec6e812a3375a\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2006.02826\",\"authors\":[{\"authorId\":\"144881168\",\"name\":\"Tobias Fischer\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"}],\"doi\":\"10.1109/LRA.2020.3025505\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"81a3995e9724eaf8eb70319f87a37233fbf7e9cf\",\"title\":\"Event-Based Visual Place Recognition With Ensembles of Temporal Windows\",\"url\":\"https://www.semanticscholar.org/paper/81a3995e9724eaf8eb70319f87a37233fbf7e9cf\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1413105978\",\"name\":\"Mounir Bendali-Braham\"},{\"authorId\":\"152947675\",\"name\":\"Jonathan Weber\"},{\"authorId\":\"2318564\",\"name\":\"G. Forestier\"},{\"authorId\":\"3482237\",\"name\":\"L. Idoumghar\"},{\"authorId\":\"145344693\",\"name\":\"Pierre-Alain Muller\"}],\"doi\":\"10.1109/ISPA.2019.8868704\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"846273f4e526022fd611dce55af1393ca1c84554\",\"title\":\"Transfer learning for the classification of video-recorded crowd movements\",\"url\":\"https://www.semanticscholar.org/paper/846273f4e526022fd611dce55af1393ca1c84554\",\"venue\":\"2019 11th International Symposium on Image and Signal Processing and Analysis (ISPA)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"},{\"authorId\":\"40566477\",\"name\":\"H. Yang\"},{\"authorId\":\"2937291\",\"name\":\"Zhikang Fu\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"title\":\"Hierarchical Nonlinear Orthogonal Adaptive-Subspace Self-Organizing Map Based Feature Extraction for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/290b8a2fb39043d98cad6bb97595f7d79e394ba4\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":\"1811.05014\",\"authors\":[{\"authorId\":\"47244850\",\"name\":\"Rongcheng Lin\"},{\"authorId\":\"144033366\",\"name\":\"J. Xiao\"},{\"authorId\":\"144147221\",\"name\":\"Jianping Fan\"}],\"doi\":\"10.1007/978-3-030-11018-5_19\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"919548553251d5cf92a2cb50e87d29b862613bb5\",\"title\":\"NeXtVLAD: An Efficient Neural Network to Aggregate Frame-level Features for Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/919548553251d5cf92a2cb50e87d29b862613bb5\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2004.02205\",\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"e908719ae2a09e3726300df65bcd31dfddea5a86\",\"title\":\"Deep Multimodal Feature Encoding for Video Ordering\",\"url\":\"https://www.semanticscholar.org/paper/e908719ae2a09e3726300df65bcd31dfddea5a86\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1812.06203\",\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"},{\"authorId\":\"50702063\",\"name\":\"B. Singh\"},{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"1693428\",\"name\":\"L. Davis\"}],\"doi\":\"10.1109/WACV.2019.00022\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"title\":\"TAN: Temporal Aggregation Network for Dense Multi-Label Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/6fc28617ad940d214cbc6a9a0805d3f0047e08f7\",\"venue\":\"2019 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26409184\",\"name\":\"M. Z. Khan\"},{\"authorId\":\"66783923\",\"name\":\"Summra Saleem\"},{\"authorId\":\"40589170\",\"name\":\"M. A. Hassan\"},{\"authorId\":\"65752088\",\"name\":\"Muhammad Usman Ghanni Khan\"}],\"doi\":\"10.1109/ICET.2018.8603644\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2de0eec253589e7569810abb22deaa074b634908\",\"title\":\"Learning Deep C3D Features For Soccer Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/2de0eec253589e7569810abb22deaa074b634908\",\"venue\":\"2018 14th International Conference on Emerging Technologies (ICET)\",\"year\":2018},{\"arxivId\":\"1808.09892\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1007/978-3-030-03840-3_28\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"title\":\"Top-down Attention Recurrent VLAD Encoding for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/b1d2001e877bb36c8ccc97bee62d9824a3b8874d\",\"venue\":\"AI*IA\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"51432978\",\"name\":\"Zhongke Liao\"},{\"authorId\":\"46354059\",\"name\":\"Haifeng Hu\"},{\"authorId\":\"49050918\",\"name\":\"J. Zhang\"},{\"authorId\":\"7650248\",\"name\":\"C. Yin\"}],\"doi\":\"10.1016/j.cviu.2019.102821\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"fedf56f95e5e80464254573ce2d9648606899ccb\",\"title\":\"Residual attention unit for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/fedf56f95e5e80464254573ce2d9648606899ccb\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"80174387\",\"name\":\"Bas van Boven\"},{\"authorId\":\"1722117\",\"name\":\"P. V. D. Putten\"},{\"authorId\":\"29903504\",\"name\":\"A. \\u00c5str\\u00f6m\"},{\"authorId\":\"81709369\",\"name\":\"H. Khalafi\"},{\"authorId\":\"2562595\",\"name\":\"A. Plaat\"}],\"doi\":\"10.1007/978-3-030-01768-2_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6aeddb71c6bcea5f206b8a731bb408b592def08e\",\"title\":\"Real-Time Excavation Detection at Construction Sites using Deep Learning\",\"url\":\"https://www.semanticscholar.org/paper/6aeddb71c6bcea5f206b8a731bb408b592def08e\",\"venue\":\"IDA\",\"year\":2018},{\"arxivId\":\"1906.09383\",\"authors\":[{\"authorId\":\"144652817\",\"name\":\"Xiaohan Wang\"},{\"authorId\":\"48607331\",\"name\":\"Yu Wu\"},{\"authorId\":\"2948393\",\"name\":\"Linchao Zhu\"},{\"authorId\":\"143699996\",\"name\":\"Y. Yang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"title\":\"Baidu-UTS Submission to the EPIC-Kitchens Action Recognition Challenge 2019\",\"url\":\"https://www.semanticscholar.org/paper/0f8762553f4a8674249e60eb1cac9289ef0547f4\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144997028\",\"name\":\"L. Li\"},{\"authorId\":\"145274329\",\"name\":\"Zhaoxiang Zhang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"49681016\",\"name\":\"L. Wang\"}],\"doi\":\"10.1109/ICPR.2018.8546263\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"title\":\"Deep Temporal Feature Encoding for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ecbe158c795b2bdbad9a16ac40a12a09c6bf11f1\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":\"1810.11731\",\"authors\":[{\"authorId\":\"1412518183\",\"name\":\"Marian K. Y. Boktor\"},{\"authorId\":\"1410429737\",\"name\":\"A. Al-Kabbany\"},{\"authorId\":\"46318863\",\"name\":\"Radwa Khalil\"},{\"authorId\":\"1398644693\",\"name\":\"S. El-Khamy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"6044b30751c19b3231782fb0475c9ca438940690\",\"title\":\"Real-time Action Recognition with Dissimilarity-based Training of Specialized Module Networks\",\"url\":\"https://www.semanticscholar.org/paper/6044b30751c19b3231782fb0475c9ca438940690\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35723063\",\"name\":\"Md. Jamil-Ur Rahman\"},{\"authorId\":\"2035718\",\"name\":\"R. Lagani\\u00e8re\"}],\"doi\":\"10.1109/CRV50864.2020.00035\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"title\":\"Single-Stage End-to-End Temporal Activity Detection in Untrimmed Videos\",\"url\":\"https://www.semanticscholar.org/paper/29507fe58ff6ef84c7c1c33d6d095fd80b3cf577\",\"venue\":\"2020 17th Conference on Computer and Robot Vision (CRV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"19236987\",\"name\":\"Wenwan You\"},{\"authorId\":\"2299070\",\"name\":\"Junqi Guo\"},{\"authorId\":\"40439918\",\"name\":\"Ke Shan\"},{\"authorId\":\"46239625\",\"name\":\"Y. Dai\"}],\"doi\":\"10.1016/j.procs.2019.01.213\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"80cb437ae935486b061767d6eb342dbf37f64fa3\",\"title\":\"A Novel Trajectory-VLAD Based Action Recognition Algorithm for Video Analysis\",\"url\":\"https://www.semanticscholar.org/paper/80cb437ae935486b061767d6eb342dbf37f64fa3\",\"venue\":\"IIKI\",\"year\":2018},{\"arxivId\":\"2003.08275\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2975022cb314045d1471c407454bcdf8b7cb5fef\",\"title\":\"PIC: Permutation Invariant Convolution for Recognizing Long-range Activities\",\"url\":\"https://www.semanticscholar.org/paper/2975022cb314045d1471c407454bcdf8b7cb5fef\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1704.06925\",\"authors\":[{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1007/s11263-018-1111-5\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"title\":\"Second-order Temporal Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9297a216ee4613d2c86b2ba9aff2b29089d98120\",\"venue\":\"International Journal of Computer Vision\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2129212\",\"name\":\"M. Leong\"},{\"authorId\":\"145052848\",\"name\":\"D. Prasad\"},{\"authorId\":\"2277707\",\"name\":\"Y. T. Lee\"},{\"authorId\":\"72659791\",\"name\":\"F. Lin\"}],\"doi\":\"10.20944/preprints201912.0086.v1\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"title\":\"Semi-CNN Architecture for Effective Spatio- Temporal Learning in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/29248ee8f8c7032e6d122390f02973a3e76ac6e4\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143627655\",\"name\":\"Guan Luo\"},{\"authorId\":\"1387518609\",\"name\":\"Jiutong Wei\"},{\"authorId\":\"48594951\",\"name\":\"Weiming Hu\"},{\"authorId\":\"144555237\",\"name\":\"S. Maybank\"}],\"doi\":\"10.1109/TIP.2019.2955561\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"be8d5cc013082e9ac8b5588c04177953a2d5047e\",\"title\":\"Tangent Fisher Vector on Matrix Manifolds for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/be8d5cc013082e9ac8b5588c04177953a2d5047e\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":\"1908.09995\",\"authors\":[{\"authorId\":\"2659862\",\"name\":\"J. Zhang\"},{\"authorId\":\"38083193\",\"name\":\"F. Shen\"},{\"authorId\":\"1390532590\",\"name\":\"Xing Xu\"},{\"authorId\":\"1724393\",\"name\":\"H. Shen\"}],\"doi\":\"10.1109/TIP.2020.2985219\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"title\":\"Temporal Reasoning Graph for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/f3b9458522b828c39b1a7d7a9ffa15eae0789bfc\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49970148\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"49678929\",\"name\":\"Y. Sato\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"59e777069a4a24b47dfb27712bb3e5dcf3392f62\",\"title\":\"F \\\" , $ F % , $ conv Conv Fusion conv ReLU concat X $ Spatial Attention Submodule \\u03b1 $ \\u03a3 RNNtask Feature Encoding Attention Pooling Temporal Aggregation\",\"url\":\"https://www.semanticscholar.org/paper/59e777069a4a24b47dfb27712bb3e5dcf3392f62\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1712.09184\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"2082991\",\"name\":\"Georgia Gkioxari\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"}],\"doi\":\"10.1109/CVPR.2018.00044\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"title\":\"Detect-and-Track: Efficient Pose Estimation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/5084ca7e4db3168e674414ae55cb6f4e682214e1\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1804.02516\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3448af861bf5d44ce7ab6b25002504815212252e\",\"title\":\"Learning a Text-Video Embedding from Incomplete and Heterogeneous Data\",\"url\":\"https://www.semanticscholar.org/paper/3448af861bf5d44ce7ab6b25002504815212252e\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":\"1810.00530\",\"authors\":[{\"authorId\":\"31818146\",\"name\":\"Sebastian Kmiec\"},{\"authorId\":\"2028949\",\"name\":\"Juhan Bae\"},{\"authorId\":\"38230393\",\"name\":\"R. An\"}],\"doi\":\"10.1007/978-3-030-11018-5_21\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2d30f6757086ef60731f4016c3c22e6c818558b5\",\"title\":\"Learnable Pooling Methods for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/2d30f6757086ef60731f4016c3c22e6c818558b5\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"1903.06879\",\"authors\":[{\"authorId\":\"49279229\",\"name\":\"Lifang Wu\"},{\"authorId\":\"144037701\",\"name\":\"Z. Yang\"},{\"authorId\":\"2842106\",\"name\":\"Jiaoyu He\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"3471034\",\"name\":\"Y. Xu\"},{\"authorId\":\"144983032\",\"name\":\"D. Xu\"},{\"authorId\":\"1735257\",\"name\":\"C. Chen\"}],\"doi\":\"10.1109/TCSVT.2019.2912529\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"30e4e817459b0d032d11ae6759e717bc4213836b\",\"title\":\"Ontology-Based Global and Collective Motion Patterns for Event Classification in Basketball Videos\",\"url\":\"https://www.semanticscholar.org/paper/30e4e817459b0d032d11ae6759e717bc4213836b\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153234114\",\"name\":\"Yunlei Sun\"},{\"authorId\":\"2679444\",\"name\":\"Dalin Zhang\"}],\"doi\":\"10.17559/tv-20190506101459\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9478073c3ec0a111e1d3d78508a40f985ecd216d\",\"title\":\"ATSN: Attention-Based Temporal Segment Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9478073c3ec0a111e1d3d78508a40f985ecd216d\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1909.03309\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"39440469\",\"name\":\"Sudhakar Kumawat\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":\"10.1007/978-981-15-8697-2_10\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"title\":\"Exploring Temporal Differences in 3D Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/5ea90b8a0ff9fe3c9f1f0bee8e1fe137e112dd4f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145594181\",\"name\":\"B. Zhu\"}],\"doi\":\"10.1007/978-3-030-03338-5_27\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"title\":\"Feature Aggregation Tree: Capture Temporal Motion Information for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/c9a6de2cc6a4a9f689553e92876cff646eaebae6\",\"venue\":\"PRCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3443768\",\"name\":\"M. A. Rahman\"},{\"authorId\":null,\"name\":\"Robert Lagani\\u00e8re\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a70b46841bdf48f8a15508f1f48b51937d082efa\",\"title\":\"Mid-level Fusion for End-to-End Temporal Activity Detection in Untrimmed Video\",\"url\":\"https://www.semanticscholar.org/paper/a70b46841bdf48f8a15508f1f48b51937d082efa\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.00381\",\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"7855312\",\"name\":\"S. Escalera\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.1109/cvpr42600.2020.00118\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57cee868188127305f966a178ca22025b397d911\",\"title\":\"Gate-Shift Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/57cee868188127305f966a178ca22025b397d911\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.11230\",\"authors\":[{\"authorId\":\"145873652\",\"name\":\"Y. Kong\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"title\":\"Human Action Recognition and Prediction: A Survey\",\"url\":\"https://www.semanticscholar.org/paper/025a44bf059aef8b9ee2e6ca598bebefc59a4a61\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"93318099\",\"name\":\"J. Lin\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"title\":\"TSM: Temporal Shift Module for Efficient Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1dc7454bacae9a949db38b8306bd7c4df855fa1c\",\"venue\":\"\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145586191\",\"name\":\"Can Zhang\"},{\"authorId\":\"26981150\",\"name\":\"Yue-Xian Zou\"},{\"authorId\":\"115151196\",\"name\":\"G. Chen\"},{\"authorId\":\"48204311\",\"name\":\"L. Gan\"}],\"doi\":\"10.1145/3343031.3350876\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"title\":\"PAN: Persistent Appearance Network with an Efficient Motion Cue for Fast Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ab7f7501d889607d6a9aa3f5ea465a8b1c44f7ff\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":\"1808.01106\",\"authors\":[{\"authorId\":\"144708945\",\"name\":\"Yang Du\"},{\"authorId\":null,\"name\":\"Chunfeng Yuan\"},{\"authorId\":null,\"name\":\"Bing Li\"},{\"authorId\":\"48096213\",\"name\":\"L. Zhao\"},{\"authorId\":\"2082374\",\"name\":\"Yangxi Li\"},{\"authorId\":\"40506509\",\"name\":\"W. Hu\"}],\"doi\":\"10.1007/978-3-030-01270-0_23\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"title\":\"Interaction-aware Spatio-temporal Pyramid Attention Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/7feb72b2d475b0e82444247c0b979cc1112ddaed\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2003.13158\",\"authors\":[{\"authorId\":\"146108424\",\"name\":\"A. Kukleva\"},{\"authorId\":\"2103464\",\"name\":\"Makarand Tapaswi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"}],\"doi\":\"10.1109/cvpr42600.2020.00987\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d57d0c8071378c26967fa428bf339193713b91a5\",\"title\":\"Learning Interactions and Relationships Between Movie Characters\",\"url\":\"https://www.semanticscholar.org/paper/d57d0c8071378c26967fa428bf339193713b91a5\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2138686\",\"name\":\"Saiyed Umer\"},{\"authorId\":\"2244865\",\"name\":\"Mrinmoy Ghorai\"},{\"authorId\":\"2579872\",\"name\":\"P. P. Mohanta\"}],\"doi\":\"10.1109/ICAPR.2017.8592958\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77ce767da4574d882d9552e91956d3012a5c500f\",\"title\":\"Event Recognition in Unconstrained Video using Multi-Scale Deep Spatial Features\",\"url\":\"https://www.semanticscholar.org/paper/77ce767da4574d882d9552e91956d3012a5c500f\",\"venue\":\"2017 Ninth International Conference on Advances in Pattern Recognition (ICAPR)\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693655\",\"name\":\"Jakub Loko\\u010d\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"725c076637a1e61676d7e84856036247cd971e53\",\"title\":\"Methods for Content-based Interactive Retrieval\",\"url\":\"https://www.semanticscholar.org/paper/725c076637a1e61676d7e84856036247cd971e53\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1911.12249\",\"authors\":[{\"authorId\":\"1432232515\",\"name\":\"Asket Kaur\"},{\"authorId\":\"37256593\",\"name\":\"N. Rao\"},{\"authorId\":\"1432231501\",\"name\":\"Tanya Joon\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e6020c184b7c3c4f41475510008dfbebe50930df\",\"title\":\"Literature Review of Action Recognition in the Wild\",\"url\":\"https://www.semanticscholar.org/paper/e6020c184b7c3c4f41475510008dfbebe50930df\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1906.04833\",\"authors\":[{\"authorId\":\"1693461\",\"name\":\"Ping Hu\"},{\"authorId\":\"46793780\",\"name\":\"Ximeng Sun\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1749590\",\"name\":\"S. Sclaroff\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"63449a4a176fc1a323d0e78fcbe0691beec0d188\",\"title\":\"Weakly-supervised Compositional FeatureAggregation for Few-shot Recognition\",\"url\":\"https://www.semanticscholar.org/paper/63449a4a176fc1a323d0e78fcbe0691beec0d188\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"2006.05700\",\"authors\":[{\"authorId\":\"1735947\",\"name\":\"Sourav Garg\"},{\"authorId\":\"38777725\",\"name\":\"Ben Harwood\"},{\"authorId\":\"33195661\",\"name\":\"G. Anand\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"}],\"doi\":\"10.1109/LRA.2020.3005627\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"f25396b7152c2c4c4c59b601fcff0a3902664f70\",\"title\":\"Delta Descriptors: Change-Based Place Representation for Robust Visual Localization\",\"url\":\"https://www.semanticscholar.org/paper/f25396b7152c2c4c4c59b601fcff0a3902664f70\",\"venue\":\"IEEE Robotics and Automation Letters\",\"year\":2020},{\"arxivId\":\"1710.05112\",\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2017.2786999\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"title\":\"Video Classification With CNNs: Using the Codec as a Spatio-Temporal Activity Sensor\",\"url\":\"https://www.semanticscholar.org/paper/ea9e5fcdac51328a99e88f14b194abb933bd81b3\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143678524\",\"name\":\"A. Khan\"},{\"authorId\":\"2383966\",\"name\":\"Loris Bozzato\"},{\"authorId\":\"144077615\",\"name\":\"L. Serafini\"},{\"authorId\":\"1680609\",\"name\":\"B. Lazzerini\"}],\"doi\":\"10.29007/pjd4\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"599e779ad7c795aa1a210c5f07622184eecea121\",\"title\":\"Visual Reasoning on Complex Events in Soccer Videos Using Answer Set Programming\",\"url\":\"https://www.semanticscholar.org/paper/599e779ad7c795aa1a210c5f07622184eecea121\",\"venue\":\"GCAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"66039652\",\"name\":\"Abel D\\u00edaz Berenguer\"},{\"authorId\":\"30988779\",\"name\":\"Meshia C\\u00e9dric Oveneke\"},{\"authorId\":\"153055277\",\"name\":\"Habib-Ur-Rehman Khalid\"},{\"authorId\":\"1402930818\",\"name\":\"Mitchel Alioscha-P\\u00e9rez\"},{\"authorId\":\"66423728\",\"name\":\"A. Bourdoux\"},{\"authorId\":\"48077408\",\"name\":\"H. Sahli\"}],\"doi\":\"10.1109/ACCESS.2019.2942305\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4bc9f2f4c34ccacd90248aedf10899c8c4e1596f\",\"title\":\"GestureVLAD: Combining Unsupervised Features Representation and Spatio-Temporal Aggregation for Doppler-Radar Gesture Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4bc9f2f4c34ccacd90248aedf10899c8c4e1596f\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":\"10.1109/CVPR.2018.00769\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"title\":\"What Makes a Video a Video: Analyzing Temporal Information in Video Understanding Models and Datasets\",\"url\":\"https://www.semanticscholar.org/paper/c3e94bffaa786b099a37d58e64e8dc870c7526b9\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"150213872\",\"name\":\"M. Hemalatha.\"},{\"authorId\":\"143783787\",\"name\":\"C. C. Sekhar\"}],\"doi\":\"10.1109/WACV45572.2020.9093344\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"509b25d45c6f5e3cafa48395c941611364e22efc\",\"title\":\"Domain-Specific Semantics Guided Approach to Video Captioning\",\"url\":\"https://www.semanticscholar.org/paper/509b25d45c6f5e3cafa48395c941611364e22efc\",\"venue\":\"2020 IEEE Winter Conference on Applications of Computer Vision (WACV)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144388361\",\"name\":\"C. Li\"},{\"authorId\":\"1740430\",\"name\":\"B. Zhang\"},{\"authorId\":\"40262099\",\"name\":\"C. Chen\"},{\"authorId\":\"1694936\",\"name\":\"Q. Ye\"},{\"authorId\":\"1783847\",\"name\":\"J. Han\"},{\"authorId\":\"1822413\",\"name\":\"Guodong Guo\"},{\"authorId\":\"145592288\",\"name\":\"Rongrong Ji\"}],\"doi\":\"10.1109/TIP.2019.2912357\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"cc68848151657035ffbd945d99106e8c52e15c20\",\"title\":\"Deep Manifold Structure Transfer for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/cc68848151657035ffbd945d99106e8c52e15c20\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153626248\",\"name\":\"D. Liu\"},{\"authorId\":\"40349048\",\"name\":\"Y. Wang\"},{\"authorId\":\"1718829\",\"name\":\"J. Kato\"}],\"doi\":\"10.1109/DICTA.2017.8227428\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"0b8b33481e92189044fd595ed9d177812017e0f3\",\"title\":\"Evaluation of Triple-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/0b8b33481e92189044fd595ed9d177812017e0f3\",\"venue\":\"2017 International Conference on Digital Image Computing: Techniques and Applications (DICTA)\",\"year\":2017},{\"arxivId\":\"2011.12957\",\"authors\":[{\"authorId\":\"31817157\",\"name\":\"Ahmed Mohammed\"},{\"authorId\":\"2957937\",\"name\":\"I. Farup\"},{\"authorId\":\"1389934093\",\"name\":\"M. Pedersen\"},{\"authorId\":\"2939019\",\"name\":\"Sule YAYILGAN YILDIRIM\"},{\"authorId\":\"4005476\",\"name\":\"\\u00d8. Hovde\"}],\"doi\":\"10.1016/j.cviu.2020.103062\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"75b588a39ba57590816944321c559e1ca0dbd389\",\"title\":\"PS-DeVCEM: Pathology-sensitive deep learning model for video capsule endoscopy based on weakly labeled data\",\"url\":\"https://www.semanticscholar.org/paper/75b588a39ba57590816944321c559e1ca0dbd389\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"2511001\",\"name\":\"Yin Bi\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"2747620\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/ICASSP.2019.8683606\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"750c885ee644cb19d89f52ab31639f56254273a2\",\"title\":\"Neuromorphic Vision Sensing for CNN-based Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/750c885ee644cb19d89f52ab31639f56254273a2\",\"venue\":\"ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)\",\"year\":2019},{\"arxivId\":\"1912.01540\",\"authors\":[{\"authorId\":\"3451474\",\"name\":\"Himalaya Jain\"},{\"authorId\":\"2475428\",\"name\":\"Spyros Gidaris\"},{\"authorId\":\"2505902\",\"name\":\"Nikos Komodakis\"},{\"authorId\":\"1398301486\",\"name\":\"P. P\\u00e9rez\"},{\"authorId\":\"51021910\",\"name\":\"M. Cord\"}],\"doi\":\"10.1007/978-3-030-58589-1_11\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"7c1400a8998b28d0ff1220f2fdcf4c2380244b83\",\"title\":\"QUEST: Quantized embedding space for transferring knowledge\",\"url\":\"https://www.semanticscholar.org/paper/7c1400a8998b28d0ff1220f2fdcf4c2380244b83\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2614755\",\"name\":\"Yashar Deldjoo\"}],\"doi\":\"10.1007/978-3-030-32094-2_6\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"509344a100522709b5d01a9d781c4a3f5bc2284a\",\"title\":\"Enhancing Video Recommendation Using Multimedia Content\",\"url\":\"https://www.semanticscholar.org/paper/509344a100522709b5d01a9d781c4a3f5bc2284a\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1712.00636\",\"authors\":[{\"authorId\":\"2978413\",\"name\":\"Chao-Yuan Wu\"},{\"authorId\":\"1771307\",\"name\":\"M. Zaheer\"},{\"authorId\":\"2804000\",\"name\":\"Hexiang Hu\"},{\"authorId\":\"1758550\",\"name\":\"R. Manmatha\"},{\"authorId\":\"46234526\",\"name\":\"Alex Smola\"},{\"authorId\":\"2562966\",\"name\":\"Philipp Kr\\u00e4henb\\u00fchl\"}],\"doi\":\"10.1109/CVPR.2018.00631\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"9d98a956aadaff727e495b14b7c532d40ea49e16\",\"title\":\"Compressed Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d98a956aadaff727e495b14b7c532d40ea49e16\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1908.09442\",\"authors\":[{\"authorId\":\"47057388\",\"name\":\"X. Li\"},{\"authorId\":\"6873935\",\"name\":\"T. Lin\"},{\"authorId\":\"153201747\",\"name\":\"Xiao Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"1724520\",\"name\":\"W. Zuo\"},{\"authorId\":\"46651287\",\"name\":\"C. Li\"},{\"authorId\":\"46550771\",\"name\":\"X. Long\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"32379958\",\"name\":\"Fu Li\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1145/3394171.3413860\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"317e0392d2a830df88dd093df01ef4d2943e5c96\",\"title\":\"Deep Concept-wise Temporal Convolutional Networks for Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/317e0392d2a830df88dd093df01ef4d2943e5c96\",\"venue\":\"ACM Multimedia\",\"year\":2020},{\"arxivId\":\"1907.12919\",\"authors\":[{\"authorId\":\"143937396\",\"name\":\"Jo\\u00e3o Antunes\"},{\"authorId\":\"152477216\",\"name\":\"P. Abreu\"},{\"authorId\":\"145036494\",\"name\":\"A. Bernardino\"},{\"authorId\":\"1772588\",\"name\":\"A. Smailagic\"},{\"authorId\":\"1742634\",\"name\":\"D. Siewiorek\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"102c5f96b879de46921cfc1f589dbc364310cf54\",\"title\":\"Attention Filtering for Multi-person Spatiotemporal Action Detection on Deep Two-Stream CNN Architectures\",\"url\":\"https://www.semanticscholar.org/paper/102c5f96b879de46921cfc1f589dbc364310cf54\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145731841\",\"name\":\"P. Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":\"10.1109/CVPR.2018.00705\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"title\":\"Temporal Deformable Residual Networks for Action Segmentation in Videos\",\"url\":\"https://www.semanticscholar.org/paper/4bfcedc30c05b68ba109b9ae71db42f1f1985770\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9742265\",\"name\":\"O. C. Kwon\"},{\"authorId\":\"2447631\",\"name\":\"Junyeong Kim\"},{\"authorId\":\"145954697\",\"name\":\"C. Yoo\"}],\"doi\":\"10.1109/ICIP.2018.8451493\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"title\":\"Action Recognition: First-and Second-Order 3D Feature in Bi-Directional Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/ac9ee00414034f340b1c612ef23bbc9ed6d653e0\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9016631\",\"name\":\"Tso-Hsin Yeh\"},{\"authorId\":\"144805693\",\"name\":\"C. Kuo\"},{\"authorId\":\"1805559\",\"name\":\"A. Liu\"},{\"authorId\":\"103483753\",\"name\":\"Yu-Hung Liu\"},{\"authorId\":\"9006204\",\"name\":\"Yu-Huan Yang\"},{\"authorId\":\"1491078400\",\"name\":\"Zijun Li\"},{\"authorId\":\"121418048\",\"name\":\"J. Shen\"},{\"authorId\":\"1743408\",\"name\":\"L. Fu\"}],\"doi\":\"10.1109/IROS40897.2019.8968533\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"f98c4ae113621fdddaf5321b6f2f22310698f994\",\"title\":\"ResFlow: Multi-tasking of Sequentially Pooling Spatiotemporal Features for Action Recognition and Optical Flow Estimation\",\"url\":\"https://www.semanticscholar.org/paper/f98c4ae113621fdddaf5321b6f2f22310698f994\",\"venue\":\"2019 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)\",\"year\":2019},{\"arxivId\":\"2004.06704\",\"authors\":[{\"authorId\":\"27575517\",\"name\":\"Dian Shao\"},{\"authorId\":\"145454812\",\"name\":\"Yue Zhao\"},{\"authorId\":\"144445937\",\"name\":\"Bo Dai\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"}],\"doi\":\"10.1109/cvpr42600.2020.00269\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"title\":\"FineGym: A Hierarchical Video Dataset for Fine-Grained Action Understanding\",\"url\":\"https://www.semanticscholar.org/paper/f5c35edc9cf622c7dd7e19ce6fbd5d563557de5b\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1905.10654\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"title\":\"Exploring Temporal Information for Improved Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/20718203ce3b9c7ed5f56f13c08c988bfdf154ca\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1898524487\",\"name\":\"Yunyu Liu\"},{\"authorId\":\"1491247995\",\"name\":\"Lichen Wang\"},{\"authorId\":\"153802755\",\"name\":\"Y. Bai\"},{\"authorId\":\"12282768\",\"name\":\"Can Qin\"},{\"authorId\":\"2788685\",\"name\":\"Z. Ding\"},{\"authorId\":\"144015161\",\"name\":\"Y. Fu\"}],\"doi\":\"10.1007/978-3-030-58568-6_19\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"808337c8f90d14f503870a91bc143cdef39db6c7\",\"title\":\"Generative View-Correlation Adaptation for Semi-supervised Multi-view Learning\",\"url\":\"https://www.semanticscholar.org/paper/808337c8f90d14f503870a91bc143cdef39db6c7\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"2011.13202\",\"authors\":[{\"authorId\":\"2029244883\",\"name\":\"Soroosh Poorgholi\"},{\"authorId\":\"50311569\",\"name\":\"O. Kayhan\"},{\"authorId\":\"1738975\",\"name\":\"J. C. V. Gemert\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"title\":\"t-EVA: Time-Efficient t-SNE Video Annotation\",\"url\":\"https://www.semanticscholar.org/paper/5960bbc43b3fddde32a9f57f8821f7f978343de4\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2008.08072\",\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"8797855\",\"name\":\"A. Piergiovanni\"},{\"authorId\":\"3462309\",\"name\":\"Juhana Kangaspunta\"},{\"authorId\":\"2148510\",\"name\":\"A. Angelova\"}],\"doi\":\"10.1007/978-3-030-58565-5_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a156594c076a8f0e073e5656ae8e3311212d2422\",\"title\":\"AssembleNet++: Assembling Modality Representations via Attention Connections\",\"url\":\"https://www.semanticscholar.org/paper/a156594c076a8f0e073e5656ae8e3311212d2422\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1404304087\",\"name\":\"Salah Al-Obaidi\"},{\"authorId\":\"2034275779\",\"name\":\"Hiba Al-Khafaji\"},{\"authorId\":\"74338570\",\"name\":\"Charith Abhayaratne\"}],\"doi\":\"10.1109/ACCESS.2020.3039740\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"title\":\"Modeling Temporal Visual Salience for Human Action Recognition Enabled Visual Anonymity Preservation\",\"url\":\"https://www.semanticscholar.org/paper/9edf2c2a48a07a077e54f719eb2d0820dbda76ab\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79755154\",\"name\":\"Hongje Seong\"},{\"authorId\":\"2246939\",\"name\":\"Junhyuk Hyun\"},{\"authorId\":\"70400973\",\"name\":\"Euntai Kim\"}],\"doi\":\"10.1109/ICCVW.2019.00194\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"title\":\"Video Multitask Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/0be0313db9a4fd54a2e3a4f427772498a1419db8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"26329506\",\"name\":\"Jingchun Cheng\"},{\"authorId\":\"40807467\",\"name\":\"Han-Kai Hsu\"},{\"authorId\":\"144823841\",\"name\":\"Chen Fang\"},{\"authorId\":\"41151701\",\"name\":\"H. Jin\"},{\"authorId\":\"1678689\",\"name\":\"S. Wang\"},{\"authorId\":\"37144787\",\"name\":\"Ming-Hsuan Yang\"}],\"doi\":\"10.1007/978-3-030-20870-7_14\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"304d4b20092eecfdf2bb84ab961d5be23d2bf7a0\",\"title\":\"Learning from PhotoShop Operation Videos: The PSOV Dataset\",\"url\":\"https://www.semanticscholar.org/paper/304d4b20092eecfdf2bb84ab961d5be23d2bf7a0\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":\"2012.11866\",\"authors\":[{\"authorId\":\"2595189\",\"name\":\"Zehua Sun\"},{\"authorId\":\"120809631\",\"name\":\"Jiwang Liu\"},{\"authorId\":\"143969578\",\"name\":\"Qiuhong Ke\"},{\"authorId\":\"1877377\",\"name\":\"H. Rahmani\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"816236bf3219363bfe4b847363e137b1fe6712e7\",\"title\":\"Human Action Recognition from Various Data Modalities: A Review\",\"url\":\"https://www.semanticscholar.org/paper/816236bf3219363bfe4b847363e137b1fe6712e7\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144422820\",\"name\":\"Xiang Xiang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"title\":\"Image-set, Temporal and Spatiotemporal Representations of Videos for Recognizing, Localizing and Quantifying Actions\",\"url\":\"https://www.semanticscholar.org/paper/c6cdf39c70aabf973a56db1ea009ab275f3f6ee8\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1904.11451\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"1576263143\",\"name\":\"Jurgen Gall\"},{\"authorId\":\"49157259\",\"name\":\"R. Stiefelhagen\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-58558-7_35\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"title\":\"Large Scale Holistic Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/1c2fe9e87e31e6fdb2b7bae5f9cc3c2d2612d13a\",\"venue\":\"ECCV\",\"year\":2020},{\"arxivId\":\"1812.02707\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"35681810\",\"name\":\"J. Carreira\"},{\"authorId\":\"2786693\",\"name\":\"C. Doersch\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2019.00033\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"94bbc4ea271c918705876b60d98d227a0ab55a43\",\"title\":\"Video Action Transformer Network\",\"url\":\"https://www.semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391190989\",\"name\":\"L. Liu\"},{\"authorId\":\"1679704\",\"name\":\"Y. Liu\"},{\"authorId\":\"73329364\",\"name\":\"Jiangning Zhang\"}],\"doi\":\"10.1109/TIE.2018.2884206\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"58ff25ce1332b5fdc9ac430222d03e550b4e29e9\",\"title\":\"Learning-Based Hand Motion Capture and Understanding in Assembly Process\",\"url\":\"https://www.semanticscholar.org/paper/58ff25ce1332b5fdc9ac430222d03e550b4e29e9\",\"venue\":\"IEEE Transactions on Industrial Electronics\",\"year\":2019},{\"arxivId\":\"1904.11407\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1742325\",\"name\":\"R. Stiefelhagen\"}],\"doi\":\"10.1109/ICCV.2019.00629\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"title\":\"DynamoNet: Dynamic Action and Motion Network\",\"url\":\"https://www.semanticscholar.org/paper/296bce85d5a844caa63ab41a96898fd8559e4bb0\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"88999446\",\"name\":\"Lovish Chum\"},{\"authorId\":\"37390198\",\"name\":\"A. Subramanian\"},{\"authorId\":\"1699429\",\"name\":\"V. Balasubramanian\"},{\"authorId\":\"1694502\",\"name\":\"C. Jawahar\"}],\"doi\":\"10.1007/s41745-019-0099-3\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"title\":\"Beyond Supervised Learning: A Computer Vision Perspective\",\"url\":\"https://www.semanticscholar.org/paper/d6de0d33e48d6dc73afbd81a57130e0e826cbeb9\",\"venue\":\"Journal of the Indian Institute of Science\",\"year\":2019},{\"arxivId\":\"1904.04289\",\"authors\":[{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/ICCV.2019.00633\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2aed352cdd78010f72eaf618d52a4793fab32cea\",\"title\":\"SCSampler: Sampling Salient Clips From Video for Efficient Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2aed352cdd78010f72eaf618d52a4793fab32cea\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8092281\",\"name\":\"Hai-Hong Phan\"},{\"authorId\":\"9923528\",\"name\":\"Chi Trung Ha\"},{\"authorId\":\"47523551\",\"name\":\"T. T. Nguy\\u1ec5n\"}],\"doi\":\"10.1109/MAPR49794.2020.9237772\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"title\":\"Improving the efficiency of human action recognition using deep compression\",\"url\":\"https://www.semanticscholar.org/paper/14b22559f288a9ef8e1bac5f85855b00e3e28df1\",\"venue\":\"2020 International Conference on Multimedia Analysis and Pattern Recognition (MAPR)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4439383\",\"name\":\"Jamie Ray\"},{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"35259685\",\"name\":\"Y. Wang\"},{\"authorId\":\"3429328\",\"name\":\"Matt Feiszli\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1007/978-3-030-01264-9_39\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"71167cf519940a7373adc221401c396198763ab0\",\"title\":\"Scenes-Objects-Actions: A Multi-task, Multi-label Video Dataset\",\"url\":\"https://www.semanticscholar.org/paper/71167cf519940a7373adc221401c396198763ab0\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2012.11673\",\"authors\":[{\"authorId\":\"1900466056\",\"name\":\"Sirjan Kafle\"},{\"authorId\":\"1633418058\",\"name\":\"Aman Gupta\"},{\"authorId\":\"1410725735\",\"name\":\"Xue Xia\"},{\"authorId\":\"145630384\",\"name\":\"A. Sankar\"},{\"authorId\":\"46772427\",\"name\":\"X. Chen\"},{\"authorId\":\"144006576\",\"name\":\"D. Wen\"},{\"authorId\":\"2121454\",\"name\":\"Libao Zhang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"18d91abf683d10837f384c1b4c9a3f9f90cf3e87\",\"title\":\"Smoothed Gaussian Mixture Models for Video Classification and Recommendation\",\"url\":\"https://www.semanticscholar.org/paper/18d91abf683d10837f384c1b4c9a3f9f90cf3e87\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1391201846\",\"name\":\"Jianyu Chen\"},{\"authorId\":\"144749222\",\"name\":\"J. Kong\"},{\"authorId\":\"1801474\",\"name\":\"Hui Sun\"},{\"authorId\":\"49507094\",\"name\":\"H. Xu\"},{\"authorId\":\"4058024\",\"name\":\"X. Liu\"},{\"authorId\":\"1774877\",\"name\":\"Ying-hua Lu\"},{\"authorId\":\"5858971\",\"name\":\"Caixia Zheng\"}],\"doi\":\"10.3390/s20113126\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12afacc80852a3cffa18722ef43c0d82746ff66c\",\"title\":\"Spatiotemporal Interaction Residual Networks with Pseudo3D for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/12afacc80852a3cffa18722ef43c0d82746ff66c\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1909.02856\",\"authors\":[{\"authorId\":\"48094430\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"}],\"doi\":\"10.1109/TPAMI.2019.2937292\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"title\":\"Discriminative Video Representation Learning Using Support Vector Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/0d3420c51d930983b62c69713c2004bf3a6fb89d\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"12373810\",\"name\":\"S. Li\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"d9c99179fb0ee3ec5e0466a531d22bb1e800c40f\",\"title\":\"Development of Recurrent Neural Networks and Its Applications to Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d9c99179fb0ee3ec5e0466a531d22bb1e800c40f\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1711.09550\",\"authors\":[{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"144608002\",\"name\":\"Gerard de Melo\"},{\"authorId\":\"3045089\",\"name\":\"Jiajun Wu\"},{\"authorId\":\"48033101\",\"name\":\"Xiao Liu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/CVPR.2018.00817\",\"intent\":[\"result\"],\"isInfluential\":false,\"paperId\":\"5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"title\":\"Attention Clusters: Purely Attention Based Local Feature Integration for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/5406fd98aa22bc2a0c1a8bc2a58ca3eb7a91155d\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3386593\",\"name\":\"X. Dai\"}],\"doi\":\"10.13016/IFOP-IT5W\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"title\":\"Modeling Deep Context in Spatial and Temporal Domain\",\"url\":\"https://www.semanticscholar.org/paper/0b77a9dd4cd19af8f7822993ed463debccf894ed\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1706.06905\",\"authors\":[{\"authorId\":\"19200186\",\"name\":\"Antoine Miech\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"title\":\"Learnable pooling with Context Gating for video classification\",\"url\":\"https://www.semanticscholar.org/paper/1238d0c296c1263afa958ccc1bff3d65e6430be3\",\"venue\":\"ArXiv\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"49831019\",\"name\":\"Pengcheng Wang\"},{\"authorId\":\"50341413\",\"name\":\"S. Li\"}],\"doi\":\"10.1117/12.2513868\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e6f8e35dfcbd99269a38915f1b268452c9b5dab0\",\"title\":\"Structural-attentioned LSTM for action recognition based on skeleton\",\"url\":\"https://www.semanticscholar.org/paper/e6f8e35dfcbd99269a38915f1b268452c9b5dab0\",\"venue\":\"Other Conferences\",\"year\":2018},{\"arxivId\":\"1712.05080\",\"authors\":[{\"authorId\":\"143671632\",\"name\":\"P. Nguyen\"},{\"authorId\":\"40282288\",\"name\":\"Ting Liu\"},{\"authorId\":\"145686558\",\"name\":\"Gautam Prasad\"},{\"authorId\":\"40030651\",\"name\":\"B. Han\"}],\"doi\":\"10.1109/CVPR.2018.00706\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c661d1940518445f350aa5e49ed16f815d90bec2\",\"title\":\"Weakly Supervised Action Localization by Sparse Temporal Pooling Network\",\"url\":\"https://www.semanticscholar.org/paper/c661d1940518445f350aa5e49ed16f815d90bec2\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1808.07272\",\"authors\":[{\"authorId\":\"2527741\",\"name\":\"Sibo Song\"},{\"authorId\":\"143770929\",\"name\":\"N. Cheung\"},{\"authorId\":\"1802086\",\"name\":\"V. Chandrasekhar\"},{\"authorId\":\"1709001\",\"name\":\"B. Mandal\"}],\"doi\":\"10.1145/3240508.3240713\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"title\":\"Deep Adaptive Temporal Pooling for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d09d663055b3b6d588bf4de2f386bb144d09aea8\",\"venue\":\"ACM Multimedia\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46382329\",\"name\":\"Hongyang Li\"},{\"authorId\":\"38373223\",\"name\":\"J. Chen\"},{\"authorId\":\"144328091\",\"name\":\"R. Hu\"},{\"authorId\":\"145684947\",\"name\":\"M. Yu\"},{\"authorId\":\"2983562\",\"name\":\"Huafeng Chen\"},{\"authorId\":\"2646978\",\"name\":\"Zengmin Xu\"}],\"doi\":\"10.1007/978-3-030-05716-9_30\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"title\":\"Action Recognition Using Visual Attention with Reinforcement Learning\",\"url\":\"https://www.semanticscholar.org/paper/eed979bab2cb22ff105ba59ce674ac5f327f8ddc\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":\"1910.09920\",\"authors\":[{\"authorId\":\"10007321\",\"name\":\"Farnoosh Heidarivincheh\"},{\"authorId\":\"1728108\",\"name\":\"M. Mirmehdi\"},{\"authorId\":\"145089978\",\"name\":\"D. Damen\"}],\"doi\":\"10.1109/ICCVW.2019.00150\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"85accdf27ef03155d41f9740fed6044afb5dd5f6\",\"title\":\"Weakly-Supervised Completion Moment Detection using Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/85accdf27ef03155d41f9740fed6044afb5dd5f6\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":\"2006.02826\",\"authors\":[{\"authorId\":\"144881168\",\"name\":\"Tobias Fischer\"},{\"authorId\":\"1809144\",\"name\":\"Michael Milford\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3270f9d8ef79799baf8b3f757a3b2923c25c2b78\",\"title\":\"Event-based visual place recognition with ensembles of spatio-temporal windows\",\"url\":\"https://www.semanticscholar.org/paper/3270f9d8ef79799baf8b3f757a3b2923c25c2b78\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1904.12602\",\"authors\":[{\"authorId\":\"49681152\",\"name\":\"L. Wang\"},{\"authorId\":\"145125621\",\"name\":\"B. Sun\"},{\"authorId\":\"4056993\",\"name\":\"J. P. Robinson\"},{\"authorId\":\"113933538\",\"name\":\"Taotao Jing\"},{\"authorId\":\"46956675\",\"name\":\"Yun Fu\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"15f0fb321619915a20b29452f19697dbfa2cf6d2\",\"title\":\"EV-Action: Electromyography-Vision Multi-Modal Action Dataset\",\"url\":\"https://www.semanticscholar.org/paper/15f0fb321619915a20b29452f19697dbfa2cf6d2\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":\"1911.11319\",\"authors\":[{\"authorId\":\"1384480816\",\"name\":\"Pingchuan Ma\"},{\"authorId\":\"120026268\",\"name\":\"Yao Zhou\"},{\"authorId\":null,\"name\":\"Yu Lu\"},{\"authorId\":\"1726357\",\"name\":\"Wayne Zhang\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"title\":\"Learning Efficient Video Representation with Video Shuffle Networks\",\"url\":\"https://www.semanticscholar.org/paper/3b5829a65c4eb19ec8922a1575c6900d5f94046f\",\"venue\":\"ArXiv\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"70249755\",\"name\":\"Zachary Wharton\"},{\"authorId\":\"1931096\",\"name\":\"A. Behera\"},{\"authorId\":\"152891407\",\"name\":\"Y. Liu\"},{\"authorId\":\"2004428132\",\"name\":\"Nikolaos Bessis\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"1b3e3b52ac85512fb87be2df7ad4f0e67c99a8b1\",\"title\":\"Coarse Temporal Attention Network (CTA-Net) for Driver\\u2019s Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/1b3e3b52ac85512fb87be2df7ad4f0e67c99a8b1\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144158271\",\"name\":\"Chuang Gan\"},{\"authorId\":\"2823637\",\"name\":\"Mingkui Tan\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"title\":\"T-C3D: Temporal Convolutional 3D Network for Real-Time Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/3d708e4ecabc50d3f3e387a21a73f6ae2b52ddfc\",\"venue\":\"AAAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"31176543\",\"name\":\"Juan Buhagiar\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"43b4b13f1a928834b4f5eed725305a60d9ba6641\",\"title\":\"Temporal localization of actions in untrimmed videos\",\"url\":\"https://www.semanticscholar.org/paper/43b4b13f1a928834b4f5eed725305a60d9ba6641\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1904.07911\",\"authors\":[{\"authorId\":\"47001807\",\"name\":\"Y. Li\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/CVPR.2019.00980\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e91dca6e99f2d392953524986f2125be2008d9fc\",\"title\":\"REPAIR: Removing Representation Bias by Dataset Resampling\",\"url\":\"https://www.semanticscholar.org/paper/e91dca6e99f2d392953524986f2125be2008d9fc\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1812.10222\",\"authors\":[{\"authorId\":\"16340457\",\"name\":\"L. Wu\"},{\"authorId\":null,\"name\":\"Yang Wang\"},{\"authorId\":\"144082425\",\"name\":\"L. Shao\"},{\"authorId\":\"39872583\",\"name\":\"M. Wang\"}],\"doi\":\"10.1109/TNNLS.2019.2891244\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"19992d925606520af56ea1b5d2ee7c3ff33e4dde\",\"title\":\"3-D PersonVLAD: Learning Deep Global Representations for Video-Based Person Reidentification\",\"url\":\"https://www.semanticscholar.org/paper/19992d925606520af56ea1b5d2ee7c3ff33e4dde\",\"venue\":\"IEEE Transactions on Neural Networks and Learning Systems\",\"year\":2019},{\"arxivId\":\"1703.10667\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"50133145\",\"name\":\"Min-Hung Chen\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"}],\"doi\":\"10.1016/j.image.2018.09.003\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"title\":\"TS-LSTM and Temporal-Inception: Exploiting Spatiotemporal Dynamics for Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/aac934f2eed758d4a27562dae4e9c5415ff4cdb7\",\"venue\":\"Signal Process. Image Commun.\",\"year\":2019},{\"arxivId\":\"1711.06330\",\"authors\":[{\"authorId\":\"7437104\",\"name\":\"Chih-Yao Ma\"},{\"authorId\":\"2293919\",\"name\":\"Asim Kadav\"},{\"authorId\":\"50162780\",\"name\":\"I. Melvin\"},{\"authorId\":\"145276578\",\"name\":\"Z. Kira\"},{\"authorId\":\"9202076\",\"name\":\"G. Al-Regib\"},{\"authorId\":\"1775043\",\"name\":\"H. Graf\"}],\"doi\":\"10.1109/CVPR.2018.00710\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"66aebb3af16aaa78579344784212ae10f60ec27e\",\"title\":\"Attend and Interact: Higher-Order Object Interactions for Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/66aebb3af16aaa78579344784212ae10f60ec27e\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145412333\",\"name\":\"L. Lu\"},{\"authorId\":\"48831152\",\"name\":\"Siyuan Li\"},{\"authorId\":\"153708390\",\"name\":\"Niannian Chen\"},{\"authorId\":\"2019262779\",\"name\":\"Lin Gao\"},{\"authorId\":\"2020711614\",\"name\":\"Yong Fan\"},{\"authorId\":\"50262192\",\"name\":\"Yong Jiang\"},{\"authorId\":\"50790156\",\"name\":\"L. Wu\"}],\"doi\":\"10.1007/978-3-030-63820-7_28\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"title\":\"Learning and Distillating the Internal Relationship of Motion Features in Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b64e377a75b9820dbcb08b3ffeea72d4331c1a1e\",\"venue\":\"ICONIP\",\"year\":2020},{\"arxivId\":\"1712.04109\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"144752314\",\"name\":\"Bo Xiong\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"}],\"doi\":\"10.1109/CVPR.2018.00622\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"89498817a49d9c349ec9f67375023ead0411b865\",\"title\":\"Im2Flow: Motion Hallucination from Static Images for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/89498817a49d9c349ec9f67375023ead0411b865\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":\"1708.02696\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/ICCV.2017.235\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"45f858f9e8d7713f60f52618e54089ba68dfcd6d\",\"title\":\"What Actions are Needed for Understanding Human Actions in Videos?\",\"url\":\"https://www.semanticscholar.org/paper/45f858f9e8d7713f60f52618e54089ba68dfcd6d\",\"venue\":\"2017 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2017},{\"arxivId\":\"2011.00786\",\"authors\":[{\"authorId\":\"152905588\",\"name\":\"Jianhua Yang\"},{\"authorId\":\"144368930\",\"name\":\"Yan Huang\"},{\"authorId\":\"2004516791\",\"name\":\"Kai Niu\"},{\"authorId\":\"46953683\",\"name\":\"Zhanyu Ma\"},{\"authorId\":\"123865558\",\"name\":\"Liang Wang\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"title\":\"Actor and Action Modular Network for Text-based Video Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/57177ff1c7cac4bd05597fc19e683c92ed751e9b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"1711.04161\",\"authors\":[{\"authorId\":\"1696573\",\"name\":\"Jiagang Zhu\"},{\"authorId\":\"9276071\",\"name\":\"Wei Zou\"},{\"authorId\":\"40031201\",\"name\":\"Z. Zhu\"},{\"authorId\":\"12791587\",\"name\":\"Lin Li\"}],\"doi\":\"10.1109/ICPR.2018.8545710\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8c501a89092252a9f62f76a6f439916efe626251\",\"title\":\"End-to-end Video-level Representation Learning for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8c501a89092252a9f62f76a6f439916efe626251\",\"venue\":\"2018 24th International Conference on Pattern Recognition (ICPR)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143815125\",\"name\":\"M. Jubran\"},{\"authorId\":\"2822935\",\"name\":\"Alhabib Abbas\"},{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"},{\"authorId\":\"134883142\",\"name\":\"Y. Andreopoulos\"}],\"doi\":\"10.1109/TCSVT.2018.2887408\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"title\":\"Rate-Accuracy Trade-Off in Video Classification With Deep Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/dc16d4cb81d03d8c78b69f1935f7c7ea44d7fc59\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1693655\",\"name\":\"Jakub Loko\\u010d\"},{\"authorId\":\"28111091\",\"name\":\"Gregor Kovalc\\u00edk\"},{\"authorId\":\"40037607\",\"name\":\"T. Soucek\"},{\"authorId\":\"2317400\",\"name\":\"Jaroslav Moravec\"},{\"authorId\":\"30714105\",\"name\":\"Premysl Cech\"}],\"doi\":\"10.1145/3343031.3351046\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a07c6af8c24266387b20c91a74fe42e74ec42e73\",\"title\":\"A Framework for Effective Known-item Search in Video\",\"url\":\"https://www.semanticscholar.org/paper/a07c6af8c24266387b20c91a74fe42e74ec42e73\",\"venue\":\"ACM Multimedia\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3414842\",\"name\":\"Hongsong Wang\"},{\"authorId\":\"1693997\",\"name\":\"Liang Wang\"}],\"doi\":\"10.1109/TIP.2018.2837386\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"c7deb1abdfdbb9fee0912b409bdb32335948b56f\",\"title\":\"Beyond Joints: Learning Representations From Primitive Geometries for Skeleton-Based Action Recognition and Detection\",\"url\":\"https://www.semanticscholar.org/paper/c7deb1abdfdbb9fee0912b409bdb32335948b56f\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":\"1903.10547\",\"authors\":[{\"authorId\":\"145639633\",\"name\":\"Yao-Hung Hubert Tsai\"},{\"authorId\":\"2038685\",\"name\":\"S. Divvala\"},{\"authorId\":\"49933077\",\"name\":\"Louis-Philippe Morency\"},{\"authorId\":\"145124475\",\"name\":\"R. Salakhutdinov\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"}],\"doi\":\"10.1109/CVPR.2019.01067\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ce079b5a18054eb9434bf7032bcdffb599fd4f6e\",\"title\":\"Video Relationship Reasoning Using Gated Spatio-Temporal Energy Graph\",\"url\":\"https://www.semanticscholar.org/paper/ce079b5a18054eb9434bf7032bcdffb599fd4f6e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"30177384\",\"name\":\"Md Azher Uddin\"},{\"authorId\":\"1750915\",\"name\":\"Y. Lee\"}],\"doi\":\"10.3390/s19071599\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"02830b56dde8695982251369b0c8a9f096b86e5b\",\"title\":\"Feature Fusion of Deep Spatial Features and Handcrafted Spatiotemporal Features for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/02830b56dde8695982251369b0c8a9f096b86e5b\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"10025937\",\"name\":\"Z. Xu\"},{\"authorId\":\"145235479\",\"name\":\"L. Su\"},{\"authorId\":\"47672591\",\"name\":\"Shuhui Wang\"},{\"authorId\":\"1689702\",\"name\":\"Q. Huang\"},{\"authorId\":\"46868155\",\"name\":\"Y. Zhang\"}],\"doi\":\"10.1109/ICMEW.2018.8551529\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"title\":\"S2L: Single-Streamline For Complex Video Event Detection\",\"url\":\"https://www.semanticscholar.org/paper/142b46642dd46566f7be8c6263dfc6bf13a8b0dd\",\"venue\":\"2018 IEEE International Conference on Multimedia & Expo Workshops (ICMEW)\",\"year\":2018},{\"arxivId\":\"1808.05174\",\"authors\":[{\"authorId\":\"3294630\",\"name\":\"Aayush Bansal\"},{\"authorId\":\"2863531\",\"name\":\"Shugao Ma\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"},{\"authorId\":\"1774867\",\"name\":\"Yaser Sheikh\"}],\"doi\":\"10.1007/978-3-030-01228-1_8\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8ad3c383a79e85159098112127300dfd08c21319\",\"title\":\"Recycle-GAN: Unsupervised Video Retargeting\",\"url\":\"https://www.semanticscholar.org/paper/8ad3c383a79e85159098112127300dfd08c21319\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47203405\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"Dongliang He\"},{\"authorId\":\"145681030\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"5cea56f516de4e239467d2c4b77488725765e4e3\",\"title\":\"Agent 1 Agent 2 Agent 3 Predicted as Hopscotch Action Observation Observation Observation Action Action Step by step Untrimmed video All agents stop\",\"url\":\"https://www.semanticscholar.org/paper/5cea56f516de4e239467d2c4b77488725765e4e3\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1906.01028\",\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"32774629\",\"name\":\"A. Richard\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"}],\"doi\":\"10.1109/TPAMI.2018.2884469\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25edae7a44dc4f26adc04693199595a12a3b1eec\",\"title\":\"A Hybrid RNN-HMM Approach for Weakly Supervised Temporal Action Segmentation\",\"url\":\"https://www.semanticscholar.org/paper/25edae7a44dc4f26adc04693199595a12a3b1eec\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2020},{\"arxivId\":\"1912.11236\",\"authors\":[{\"authorId\":\"50081274\",\"name\":\"L. Zhang\"},{\"authorId\":\"3480262\",\"name\":\"Zenglin Shi\"},{\"authorId\":\"10638646\",\"name\":\"Joey Tianyi Zhou\"},{\"authorId\":\"37535930\",\"name\":\"Ming-Ming Cheng\"},{\"authorId\":\"71222785\",\"name\":\"Yun Liu\"},{\"authorId\":\"3459992\",\"name\":\"Jiawang Bian\"},{\"authorId\":\"3111797\",\"name\":\"Z. Zeng\"},{\"authorId\":\"12459603\",\"name\":\"Chunhua Shen\"}],\"doi\":\"10.1109/tpami.2020.2976969\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"07335131c3f8b032ad2ddca317ccbac0997ec6f7\",\"title\":\"Ordered or Orderless: A Revisit for Video based Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/07335131c3f8b032ad2ddca317ccbac0997ec6f7\",\"venue\":\"IEEE transactions on pattern analysis and machine intelligence\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47423370\",\"name\":\"Can Zhang\"},{\"authorId\":\"35325151\",\"name\":\"Yuexian Zou\"},{\"authorId\":\"145082678\",\"name\":\"G. Chen\"}],\"doi\":\"10.1007/978-3-030-05710-7_39\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"title\":\"Hierarchical Temporal Pooling for Efficient Online Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8feb4af3daf7d1c71d0ee69a3995d17fb21275a2\",\"venue\":\"MMM\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2408106\",\"name\":\"Mokhtar B. Abdullah\"},{\"authorId\":\"34911220\",\"name\":\"Mobeen Ahmad\"},{\"authorId\":\"52271749\",\"name\":\"D. Han\"}],\"doi\":\"10.1109/ICEIC49074.2020.9051332\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f9e74c827a29e5fb8bca1fd4451ec23aaa6713bc\",\"title\":\"Facial Expression Recognition in Videos: An CNN-LSTM based Model for Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f9e74c827a29e5fb8bca1fd4451ec23aaa6713bc\",\"venue\":\"2020 International Conference on Electronics, Information, and Communication (ICEIC)\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34678431\",\"name\":\"F. Sener\"},{\"authorId\":\"1734802895\",\"name\":\"Dipika Singhania\"},{\"authorId\":\"144031869\",\"name\":\"A. Yao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"e77735f1131cdb42db5a03093e4d15ebce34d473\",\"title\":\"Temporal Aggregate Representations for Long Term Video Understanding\",\"url\":\"https://www.semanticscholar.org/paper/e77735f1131cdb42db5a03093e4d15ebce34d473\",\"venue\":\"ECCV 2020\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46838180\",\"name\":\"M. Soltanian\"},{\"authorId\":\"145268563\",\"name\":\"S. Amini\"},{\"authorId\":\"145988166\",\"name\":\"S. Ghaemmaghami\"}],\"doi\":\"10.1109/TMM.2019.2959426\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"title\":\"Spatio-Temporal VLAD Encoding of Visual Events Using Temporal Ordering of the Mid-Level Deep Semantics\",\"url\":\"https://www.semanticscholar.org/paper/fea7210dd49ba69b805ef66cfe499e1d84fdf6aa\",\"venue\":\"IEEE Transactions on Multimedia\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2303172\",\"name\":\"Peng Lei\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"title\":\"AN ABSTRACT OF THE DISSERTATION OF\",\"url\":\"https://www.semanticscholar.org/paper/b9306e90facafc2001e6f01f209ddbb0694d61fb\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"2005.14260\",\"authors\":[{\"authorId\":\"3163251\",\"name\":\"E. Holm\"},{\"authorId\":\"114655960\",\"name\":\"Ryan Cohn\"},{\"authorId\":\"1576487679\",\"name\":\"Nan Gao\"},{\"authorId\":\"31382172\",\"name\":\"Andrew R. Kitahara\"},{\"authorId\":\"1388292752\",\"name\":\"Thomas P. Matson\"},{\"authorId\":\"144747847\",\"name\":\"Bo Lei\"},{\"authorId\":\"1729514557\",\"name\":\"Srujana Rao Yarasi\"}],\"doi\":\"10.1007/s11661-020-06008-4\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3297aafcbf4af1d1a011eb893a80a0632c628c31\",\"title\":\"Overview: Computer Vision and Machine Learning for Microstructural Characterization and Analysis\",\"url\":\"https://www.semanticscholar.org/paper/3297aafcbf4af1d1a011eb893a80a0632c628c31\",\"venue\":\"Metallurgical and Materials Transactions A\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1756362\",\"name\":\"Swathikiran Sudhakaran\"},{\"authorId\":\"1717522\",\"name\":\"O. Lanz\"}],\"doi\":\"10.3233/IA-190021\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"title\":\"Top-down attention recurrent VLAD encoding for action recognition in videos\",\"url\":\"https://www.semanticscholar.org/paper/6faa95812c73f297eb7f1a8b191b72a8ba0ae763\",\"venue\":\"Intelligenza Artificiale\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"143611428\",\"name\":\"Z. Tu\"},{\"authorId\":\"144561905\",\"name\":\"W. Xie\"},{\"authorId\":\"1681843\",\"name\":\"J. Dauwels\"},{\"authorId\":\"2913552\",\"name\":\"Baoxin Li\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1109/tcsvt.2018.2830102\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"title\":\"Semantic Cues Enhanced Multimodality Multistream CNN for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/e1d5a04b0ff209aed0f254f39401e235ef56bd09\",\"venue\":\"IEEE Transactions on Circuits and Systems for Video Technology\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47527828\",\"name\":\"W. Zhang\"},{\"authorId\":\"2634975\",\"name\":\"J. Wang\"},{\"authorId\":\"2029678802\",\"name\":\"Fangping Lan\"}],\"doi\":\"10.1109/JAS.2020.1003465\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"a78ad2f90ee6b3c1350f068f4d9e4e039248b189\",\"title\":\"Dynamic hand gesture recognition based on short-term sampling neural networks\",\"url\":\"https://www.semanticscholar.org/paper/a78ad2f90ee6b3c1350f068f4d9e4e039248b189\",\"venue\":\"IEEE/CAA Journal of Automatica Sinica\",\"year\":2021},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9071789\",\"name\":\"Z. Liu\"},{\"authorId\":\"9173291\",\"name\":\"L. Wang\"},{\"authorId\":\"145608731\",\"name\":\"N. Zheng\"}],\"doi\":\"10.1007/978-3-319-92007-8_10\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"title\":\"Content-Aware Attention Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/d401b48dd13c2a6855c0f2c5f65c7f087f3d5373\",\"venue\":\"AIAI\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"8567510\",\"name\":\"B. Chen\"},{\"authorId\":\"47786973\",\"name\":\"J. Li\"},{\"authorId\":\"144268511\",\"name\":\"Gang Wei\"},{\"authorId\":\"2945421\",\"name\":\"Biyun Ma\"}],\"doi\":\"10.3390/e20050341\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"f926d0a0c6362f337879cc66375a789c67605709\",\"title\":\"M-SAC-VLADNet: A Multi-Path Deep Feature Coding Model for Visual Classification\",\"url\":\"https://www.semanticscholar.org/paper/f926d0a0c6362f337879cc66375a789c67605709\",\"venue\":\"Entropy\",\"year\":2018},{\"arxivId\":\"1811.11875\",\"authors\":[{\"authorId\":\"52121635\",\"name\":\"Nathan Inkawhich\"},{\"authorId\":\"52117082\",\"name\":\"Matthew Inkawhich\"},{\"authorId\":\"50579965\",\"name\":\"Yiran Chen\"},{\"authorId\":\"47892815\",\"name\":\"H. Li\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"title\":\"Adversarial Attacks for Optical Flow-Based Action Recognition Classifiers\",\"url\":\"https://www.semanticscholar.org/paper/12cde6fe2816a465210d6b6a0e6166f73a686bbf\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33998511\",\"name\":\"Aaron Chadha\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"title\":\"From pixels to spikes : efficient multimodal learning in the presence of domain shift\",\"url\":\"https://www.semanticscholar.org/paper/02bd4c1b8adcd3478441f83972dceb2757ef409e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48841342\",\"name\":\"Qing Lei\"},{\"authorId\":\"1701928\",\"name\":\"Jixiang Du\"},{\"authorId\":\"49173384\",\"name\":\"Hongbo Zhang\"},{\"authorId\":\"47416429\",\"name\":\"Shuang Ye\"},{\"authorId\":\"123204699\",\"name\":\"Duan-Sheng Chen\"}],\"doi\":\"10.3390/s19194129\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"title\":\"A Survey of Vision-Based Human Action Evaluation Methods\",\"url\":\"https://www.semanticscholar.org/paper/fdcd429a8d6ae1928d71dd2c89e67b31138c13e1\",\"venue\":\"Sensors\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3385719\",\"name\":\"Fiza Murtaza\"},{\"authorId\":\"1697680\",\"name\":\"M. Yousaf\"},{\"authorId\":\"1697856\",\"name\":\"S. Velastin\"}],\"doi\":\"10.1109/ICIP.2018.8451255\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"ad58b92ebc45e71e40ce68d4375441267549b054\",\"title\":\"DA-VLAD: Discriminative Action Vector of Locally Aggregated Descriptors for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ad58b92ebc45e71e40ce68d4375441267549b054\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":\"1812.01289\",\"authors\":[{\"authorId\":\"13142264\",\"name\":\"Noureldien Hussein\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"144638781\",\"name\":\"A. Smeulders\"}],\"doi\":\"10.1109/CVPR.2019.00034\",\"intent\":[\"background\",\"result\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"title\":\"Timeception for Complex Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e\",\"venue\":\"2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2019},{\"arxivId\":\"1809.05848\",\"authors\":[{\"authorId\":\"46700331\",\"name\":\"J. Liu\"},{\"authorId\":\"51305314\",\"name\":\"Zehuan Yuan\"},{\"authorId\":\"1697065\",\"name\":\"C. Wang\"}],\"doi\":\"10.1007/978-3-030-11018-5_26\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"title\":\"Towards Good Practices for Multi-modal Fusion in Large-scale Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/1dc373458adf54678b6b981ce458ccdbe3f9d112\",\"venue\":\"ECCV Workshops\",\"year\":2018},{\"arxivId\":\"2010.11649\",\"authors\":[{\"authorId\":\"2502363\",\"name\":\"Gagan Kanojia\"},{\"authorId\":\"145853779\",\"name\":\"S. Raman\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"ed9915ad5ce1b469861503be803e6adab2eea985\",\"title\":\"Learning to Sort Image Sequences via Accumulated Temporal Differences\",\"url\":\"https://www.semanticscholar.org/paper/ed9915ad5ce1b469861503be803e6adab2eea985\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"69458617\",\"name\":\"Albert Clap\\u00e9s i Sintes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"9a00c447f626be388bb402faeac3653d8555785e\",\"title\":\"Learning to recognize human actions: from hand-crafted to deep-learning based visual representations\",\"url\":\"https://www.semanticscholar.org/paper/9a00c447f626be388bb402faeac3653d8555785e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"23278631\",\"name\":\"Guangle Yao\"},{\"authorId\":\"144673774\",\"name\":\"T. Lei\"},{\"authorId\":\"23227806\",\"name\":\"Jiandan Zhong\"}],\"doi\":\"10.1016/j.patrec.2018.05.018\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"title\":\"A review of Convolutional-Neural-Network-based action recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c12495bfb2f47881191ce0cb672f0372c6a31e2\",\"venue\":\"Pattern Recognit. Lett.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"152441499\",\"name\":\"Jiang Bian\"},{\"authorId\":\"40380492\",\"name\":\"Dayong Tian\"},{\"authorId\":\"2289713\",\"name\":\"Yuanyan Tang\"},{\"authorId\":\"143719919\",\"name\":\"D. Tao\"}],\"doi\":\"10.1145/3330138\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2bd6470e300018390cb7ba21c826760aa994bfd3\",\"title\":\"Trajectory Data Classification\",\"url\":\"https://www.semanticscholar.org/paper/2bd6470e300018390cb7ba21c826760aa994bfd3\",\"venue\":\"ACM Trans. Intell. Syst. Technol.\",\"year\":2019},{\"arxivId\":\"1710.07455\",\"authors\":[{\"authorId\":\"144119773\",\"name\":\"Kun Liu\"},{\"authorId\":\"1686917\",\"name\":\"Wu Liu\"},{\"authorId\":\"144258295\",\"name\":\"Huadong Ma\"},{\"authorId\":\"123175679\",\"name\":\"W. Huang\"},{\"authorId\":\"27619673\",\"name\":\"Xiongxiong Dong\"}],\"doi\":\"10.1007/s11280-018-0642-6\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"title\":\"Generalized zero-shot learning for action recognition with web-scale video data\",\"url\":\"https://www.semanticscholar.org/paper/c9f0cad35ad2a974dbf371bb6347d44232b1169f\",\"venue\":\"World Wide Web\",\"year\":2018},{\"arxivId\":\"1704.00389\",\"authors\":[{\"authorId\":\"46759150\",\"name\":\"Yi Zhu\"},{\"authorId\":\"2362534\",\"name\":\"Zhenzhong Lan\"},{\"authorId\":\"145211099\",\"name\":\"S. Newsam\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1007/978-3-030-20893-6_23\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"47195627755d88121af2513646ac41eec8645fb7\",\"title\":\"Hidden Two-Stream Convolutional Networks for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47195627755d88121af2513646ac41eec8645fb7\",\"venue\":\"ACCV\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1642174039\",\"name\":\"Dezhong Xu\"},{\"authorId\":\"1642213055\",\"name\":\"Heng Fu\"},{\"authorId\":\"8531710\",\"name\":\"L. Wu\"},{\"authorId\":\"2980051\",\"name\":\"Meng Jian\"},{\"authorId\":\"113144757\",\"name\":\"D. Wang\"},{\"authorId\":\"39267996\",\"name\":\"X. Liu\"}],\"doi\":\"10.1109/ACCESS.2020.2979742\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"35b91aa0115a4189ece2a365b59d42f21c186de8\",\"title\":\"Group Activity Recognition by Using Effective Multiple Modality Relation Representation With Temporal-Spatial Attention\",\"url\":\"https://www.semanticscholar.org/paper/35b91aa0115a4189ece2a365b59d42f21c186de8\",\"venue\":\"IEEE Access\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2571594\",\"name\":\"Q. Han\"},{\"authorId\":\"1879492445\",\"name\":\"Haofeng Wang\"},{\"authorId\":\"1986616718\",\"name\":\"Lin Yang\"},{\"authorId\":\"123804803\",\"name\":\"M. Wu\"},{\"authorId\":\"1879461270\",\"name\":\"Jinqiao Kou\"},{\"authorId\":\"1933131\",\"name\":\"Q. Du\"},{\"authorId\":\"50599290\",\"name\":\"N. Li\"}],\"doi\":\"10.1007/s11554-020-01029-z\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"dc64f5416cca1aec1faa7ec655266970846ff2b4\",\"title\":\"Real-time adversarial GAN-based abnormal crowd behavior detection\",\"url\":\"https://www.semanticscholar.org/paper/dc64f5416cca1aec1faa7ec655266970846ff2b4\",\"venue\":\"J. Real Time Image Process.\",\"year\":2020},{\"arxivId\":\"1711.01467\",\"authors\":[{\"authorId\":\"3102850\",\"name\":\"Rohit Girdhar\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"title\":\"Attentional Pooling for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/90bb40d96fcd16129eb85ce5dc4ee3b2380d74c8\",\"venue\":\"NIPS\",\"year\":2017},{\"arxivId\":\"2007.04755\",\"authors\":[{\"authorId\":\"3370667\",\"name\":\"Yongqin Xian\"},{\"authorId\":\"3443095\",\"name\":\"Bruno Korbar\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"},{\"authorId\":\"2893664\",\"name\":\"Zeynep Akata\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"title\":\"Generalized Many-Way Few-Shot Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/f5f35c39f9e5979a97cd5d4affe40b7cd3f6dd45\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1730228\",\"name\":\"M. Liu\"},{\"authorId\":\"47781541\",\"name\":\"Z. Liu\"}],\"doi\":\"10.1145/3347450.3357654\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d062058cdef85163512c3984f0f1ba78f625582e\",\"title\":\"Deep Reinforcement Learning Visual-Text Attention for Multimodal Video Classification\",\"url\":\"https://www.semanticscholar.org/paper/d062058cdef85163512c3984f0f1ba78f625582e\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1811.05042\",\"authors\":[{\"authorId\":\"145508587\",\"name\":\"J. Wen\"},{\"authorId\":\"34469457\",\"name\":\"R. Liu\"},{\"authorId\":\"39436559\",\"name\":\"Nenggan Zheng\"},{\"authorId\":\"104171063\",\"name\":\"Q. Zheng\"},{\"authorId\":\"40384324\",\"name\":\"Z. Gong\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"}],\"doi\":\"10.1609/aaai.v33i01.33015401\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d68b2b83709b70b25925defcd7f9e73967af6bd\",\"title\":\"Exploiting Local Feature Patterns for Unsupervised Domain Adaptation\",\"url\":\"https://www.semanticscholar.org/paper/2d68b2b83709b70b25925defcd7f9e73967af6bd\",\"venue\":\"AAAI\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"35031371\",\"name\":\"Wenbin Du\"},{\"authorId\":\"2799162\",\"name\":\"Y. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/TIP.2017.2778563\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"57eeaceb14a01a2560d0b90d38205e512dcca691\",\"title\":\"Recurrent Spatial-Temporal Attention Network for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/57eeaceb14a01a2560d0b90d38205e512dcca691\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"20992076\",\"name\":\"Timothy Callemein\"},{\"authorId\":\"34855451\",\"name\":\"T. Roussel\"},{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"74922038\",\"name\":\"Floris De Feyter\"},{\"authorId\":\"73664580\",\"name\":\"Wim Boes\"},{\"authorId\":\"1768441\",\"name\":\"L. V. Eycken\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"},{\"authorId\":\"1727198\",\"name\":\"H. V. hamme\"},{\"authorId\":\"2003472752\",\"name\":\"Tinne Tuytelaars\"},{\"authorId\":\"1752649\",\"name\":\"T. Goedem\\u00e9\"}],\"doi\":\"10.1007/s11042-020-09616-9\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"32921da55d7127169e901c4b3e5d6e2333185561\",\"title\":\"Show me where the action is!: Automatic capturing and timeline generation for reality TV.\",\"url\":\"https://www.semanticscholar.org/paper/32921da55d7127169e901c4b3e5d6e2333185561\",\"venue\":\"\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2199479\",\"name\":\"Jongmin Yu\"},{\"authorId\":\"145423641\",\"name\":\"D. Y. Kim\"},{\"authorId\":\"8770612\",\"name\":\"Yongsang Yoon\"},{\"authorId\":\"145745152\",\"name\":\"M. Jeon\"}],\"doi\":\"10.1007/s00371-019-01751-1\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"title\":\"Action matching network: open-set action recognition using spatio-temporal representation matching\",\"url\":\"https://www.semanticscholar.org/paper/eb7a000f5c196dbb09f939674140ebcd1f20899e\",\"venue\":\"The Visual Computer\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3429960\",\"name\":\"Youjiang Xu\"},{\"authorId\":\"144622313\",\"name\":\"Yahong Han\"},{\"authorId\":\"2248826\",\"name\":\"R. Hong\"},{\"authorId\":\"144876831\",\"name\":\"Q. Tian\"}],\"doi\":\"10.1109/TIP.2018.2846664\",\"intent\":[\"result\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"title\":\"Sequential Video VLAD: Training the Aggregation Locally and Temporally\",\"url\":\"https://www.semanticscholar.org/paper/7fe2ab9f54242ef8609ef9bf988f008c7d42407c\",\"venue\":\"IEEE Transactions on Image Processing\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1435354211\",\"name\":\"Shubin Dai\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"b2dec8a3f3ee662d1297d2a31cef77eb9212a2f7\",\"title\":\"A segment-level classification solution to the 3 rd YouTube-8 M Video Understanding Challenge\",\"url\":\"https://www.semanticscholar.org/paper/b2dec8a3f3ee662d1297d2a31cef77eb9212a2f7\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"38485317\",\"name\":\"De-An Huang\"},{\"authorId\":\"34066479\",\"name\":\"Vignesh Ramanathan\"},{\"authorId\":\"144542135\",\"name\":\"D. Mahajan\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"},{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afd90a0675936e2f747171a1063d8171d987656\",\"title\":\"l 1 l 2 l 3 l 4 l 5 ( a ) Class-Agnostic Temporal\",\"url\":\"https://www.semanticscholar.org/paper/3afd90a0675936e2f747171a1063d8171d987656\",\"venue\":\"\",\"year\":2018},{\"arxivId\":\"1806.07754\",\"authors\":[{\"authorId\":\"3310120\",\"name\":\"Ali Diba\"},{\"authorId\":\"143794218\",\"name\":\"M. Fayyaz\"},{\"authorId\":\"50633800\",\"name\":\"V. Sharma\"},{\"authorId\":\"2713759\",\"name\":\"M. M. Arzani\"},{\"authorId\":\"9456273\",\"name\":\"Rahman Yousefzadeh\"},{\"authorId\":\"145689714\",\"name\":\"Juergen Gall\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-030-01225-0_18\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"title\":\"Spatio-Temporal Channel Correlation Networks for Action Classification\",\"url\":\"https://www.semanticscholar.org/paper/85fb0d6cc991cf49ebc4f506b5edd44214979f65\",\"venue\":\"ECCV\",\"year\":2018},{\"arxivId\":\"2008.01232\",\"authors\":[{\"authorId\":\"1395788009\",\"name\":\"M. E. Kalfaoglu\"},{\"authorId\":\"1699609\",\"name\":\"Sinan Kalkan\"},{\"authorId\":\"1751998\",\"name\":\"Aydin Alatan\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"title\":\"Late Temporal Modeling in 3D CNN Architectures with BERT for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dce965db955113b3710c9977dc5f68f3bfd85c4b\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"153562818\",\"name\":\"Linjiang Huang\"},{\"authorId\":\"49867037\",\"name\":\"Y. Huang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":null,\"name\":\"Liang Wang\"}],\"doi\":\"10.1016/J.PATCOG.2019.03.010\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"title\":\"Part-aligned pose-guided recurrent network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/01c2dc6910d4552ddd86cf75dc17f3afeed9c57a\",\"venue\":\"Pattern Recognit.\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"151492109\",\"name\":\"Wensong Chan\"},{\"authorId\":\"71506962\",\"name\":\"Zhiqiang Tian\"},{\"authorId\":\"51381728\",\"name\":\"S. Liu\"},{\"authorId\":\"145160620\",\"name\":\"J. Ren\"},{\"authorId\":\"2498428\",\"name\":\"X. Lan\"}],\"doi\":\"10.1007/978-3-030-27535-8_41\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"title\":\"Select and Focus: Action Recognition with Spatial-Temporal Attention\",\"url\":\"https://www.semanticscholar.org/paper/d08e6292cf641d5865e2c4fa15624267e225cc9b\",\"venue\":\"ICIRA\",\"year\":2019},{\"arxivId\":\"1803.10628\",\"authors\":[{\"authorId\":\"48094509\",\"name\":\"J. Wang\"},{\"authorId\":\"2691929\",\"name\":\"A. Cherian\"},{\"authorId\":\"29905643\",\"name\":\"F. Porikli\"},{\"authorId\":\"145273587\",\"name\":\"Stephen Gould\"}],\"doi\":\"10.1109/CVPR.2018.00126\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"7f36848ec69413253c2e76fa389424e9bf2d7054\",\"title\":\"Video Representation Learning Using Discriminative Pooling\",\"url\":\"https://www.semanticscholar.org/paper/7f36848ec69413253c2e76fa389424e9bf2d7054\",\"venue\":\"2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145878079\",\"name\":\"Vivek Sharma\"}],\"doi\":\"10.5445/IR/1000119819\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"title\":\"Self-supervised Face Representation Learning\",\"url\":\"https://www.semanticscholar.org/paper/3605e0e6ea610576fa85fcf8737b9f20ddd87180\",\"venue\":\"\",\"year\":2020},{\"arxivId\":\"1912.04487\",\"authors\":[{\"authorId\":\"3387849\",\"name\":\"Ruohan Gao\"},{\"authorId\":\"66808667\",\"name\":\"Tae-Hyun Oh\"},{\"authorId\":\"1794409\",\"name\":\"K. Grauman\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"}],\"doi\":\"10.1109/cvpr42600.2020.01047\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"title\":\"Listen to Look: Action Recognition by Previewing Audio\",\"url\":\"https://www.semanticscholar.org/paper/c4128ba8deeb67e731cf52fb98addcfddd487e55\",\"venue\":\"2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2020},{\"arxivId\":\"1806.10319\",\"authors\":[{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"50984378\",\"name\":\"F. Li\"},{\"authorId\":\"2273005\",\"name\":\"Qijie Zhao\"},{\"authorId\":\"144858226\",\"name\":\"Xiang Long\"},{\"authorId\":\"145413801\",\"name\":\"Y. Fu\"},{\"authorId\":\"35247507\",\"name\":\"Shilei Wen\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"10370545ea747c6adec26142dbfc499681876570\",\"title\":\"Exploiting Spatial-Temporal Modelling and Multi-Modal Fusion for Human Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/10370545ea747c6adec26142dbfc499681876570\",\"venue\":\"ArXiv\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1491175421\",\"name\":\"Nima Taherifard\"},{\"authorId\":\"48778270\",\"name\":\"M. Simsek\"},{\"authorId\":\"1978739614\",\"name\":\"Charles Lascelles\"},{\"authorId\":\"2497479\",\"name\":\"B. Kantarci\"}],\"doi\":\"10.1109/OJVT.2020.3024755\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"27e53dac5562e6a59a5adbf78e5b8aca478ef8a7\",\"title\":\"Attention-Based Event Characterization for Scarce Vehicular Sensing Data\",\"url\":\"https://www.semanticscholar.org/paper/27e53dac5562e6a59a5adbf78e5b8aca478ef8a7\",\"venue\":\"IEEE Open Journal of Vehicular Technology\",\"year\":2020},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2563751\",\"name\":\"Y. Zhu\"},{\"authorId\":\"145015817\",\"name\":\"Gang Yu\"},{\"authorId\":\"34316743\",\"name\":\"Junsong Yuan\"},{\"authorId\":\"10212005\",\"name\":\"K. Ma\"}],\"doi\":\"10.1109/ICIP.2018.8451430\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"title\":\"Selecting Informative Frames for Action Recognition with Partial Observations\",\"url\":\"https://www.semanticscholar.org/paper/a6badaa9bbd8e222a2f06389261e27c5a599df68\",\"venue\":\"2018 25th IEEE International Conference on Image Processing (ICIP)\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40078088\",\"name\":\"X. Tang\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"99a6492fbea30d57ed7e7edf316a96f93008a17a\",\"title\":\"Video Sequence Classification Using Spatio-temporal Features\",\"url\":\"https://www.semanticscholar.org/paper/99a6492fbea30d57ed7e7edf316a96f93008a17a\",\"venue\":\"\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48093158\",\"name\":\"Jinpeng Wang\"},{\"authorId\":\"145517136\",\"name\":\"A. Ma\"}],\"doi\":\"10.1007/978-3-030-34120-6_7\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"title\":\"Spatial-Temporal Bottom-Up Top-Down Attention Model for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9ad5dce0e3d9663a5d0c4044c927776e4bcef2e2\",\"venue\":\"ICIG\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3150525\",\"name\":\"E. Chen\"},{\"authorId\":\"144981720\",\"name\":\"Xue Bai\"},{\"authorId\":\"145735014\",\"name\":\"L. Gao\"},{\"authorId\":\"74806144\",\"name\":\"H. Tinega\"},{\"authorId\":\"1761058\",\"name\":\"Y. Ding\"}],\"doi\":\"10.1109/ACCESS.2019.2910604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"title\":\"A Spatiotemporal Heterogeneous Two-Stream Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/41bfc72e40cb5878e1f6e54f450abb69345f8a99\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4464686\",\"name\":\"ZhenXing Zheng\"},{\"authorId\":\"2896701\",\"name\":\"G. An\"},{\"authorId\":\"144953181\",\"name\":\"D. Wu\"},{\"authorId\":\"144695333\",\"name\":\"Q. Ruan\"}],\"doi\":\"10.1016/J.NEUCOM.2019.05.058\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"67d3ec7b1070405575974e449cfdc495b43f7b21\",\"title\":\"Spatial-temporal pyramid based Convolutional Neural Network for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/67d3ec7b1070405575974e449cfdc495b43f7b21\",\"venue\":\"Neurocomputing\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"47825539\",\"name\":\"Wei Wang\"},{\"authorId\":\"152299675\",\"name\":\"Siyuan Hao\"},{\"authorId\":\"49020088\",\"name\":\"Yunchao Wei\"},{\"authorId\":\"3124720\",\"name\":\"Shengtao Xiao\"},{\"authorId\":\"33221685\",\"name\":\"Jiashi Feng\"},{\"authorId\":\"1703601\",\"name\":\"N. Sebe\"}],\"doi\":\"10.1109/ACCESS.2019.2936604\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"74195742093c489401ef8dc3d7f8639fd12c20e8\",\"title\":\"Temporal Spiking Recurrent Neural Network for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/74195742093c489401ef8dc3d7f8639fd12c20e8\",\"venue\":\"IEEE Access\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145298075\",\"name\":\"Danilo Avola\"},{\"authorId\":\"1729018\",\"name\":\"L. Cinque\"},{\"authorId\":\"1962368873\",\"name\":\"Alessio Fagioli\"},{\"authorId\":\"144706031\",\"name\":\"G. Foresti\"},{\"authorId\":\"3433822\",\"name\":\"Daniele Pannone\"},{\"authorId\":\"1709627\",\"name\":\"C. Piciarelli\"}],\"doi\":\"10.3390/s20185365\",\"intent\":[\"methodology\"],\"isInfluential\":true,\"paperId\":\"f5f1908ea49173304f95f52a3abdc6e138c305dc\",\"title\":\"Bodyprint\\u2014A Meta-Feature Based LSTM Hashing Model for Person Re-Identification\",\"url\":\"https://www.semanticscholar.org/paper/f5f1908ea49173304f95f52a3abdc6e138c305dc\",\"venue\":\"Sensors\",\"year\":2020},{\"arxivId\":\"1901.02579\",\"authors\":[{\"authorId\":\"46947776\",\"name\":\"Zhenqiang Li\"},{\"authorId\":\"48355461\",\"name\":\"Yifei Huang\"},{\"authorId\":\"3172280\",\"name\":\"Minjie Cai\"},{\"authorId\":\"9467266\",\"name\":\"Y. Sato\"}],\"doi\":\"10.1109/ICCVW.2019.00539\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"70681bc4d3facb1839c3459ee1c68b048d46bca8\",\"title\":\"Manipulation-Skill Assessment from Videos with Spatial Attention Network\",\"url\":\"https://www.semanticscholar.org/paper/70681bc4d3facb1839c3459ee1c68b048d46bca8\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision Workshop (ICCVW)\",\"year\":2019},{\"arxivId\":null,\"authors\":[{\"authorId\":\"50884736\",\"name\":\"L. Wu\"},{\"authorId\":\"144367279\",\"name\":\"B. Lovell\"},{\"authorId\":null,\"name\":\"Yang Wang\"}],\"doi\":\"10.1007/978-3-030-13057-2_3\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5293e0a0cdc76688e7961c315e5d11b7667b9377\",\"title\":\"Deep Learning in Person Re-identification for Cyber-Physical Surveillance Systems\",\"url\":\"https://www.semanticscholar.org/paper/5293e0a0cdc76688e7961c315e5d11b7667b9377\",\"venue\":\"\",\"year\":2019},{\"arxivId\":\"1712.08416\",\"authors\":[{\"authorId\":\"1403581832\",\"name\":\"Laura Sevilla-Lara\"},{\"authorId\":\"2699340\",\"name\":\"Yiyi Liao\"},{\"authorId\":\"3349249\",\"name\":\"Fatma G\\u00fcney\"},{\"authorId\":\"2745026\",\"name\":\"V. Jampani\"},{\"authorId\":\"150013821\",\"name\":\"A. Geiger\"},{\"authorId\":\"2105795\",\"name\":\"Michael J. Black\"}],\"doi\":\"10.1007/978-3-030-12939-2_20\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"title\":\"On the Integration of Optical Flow and Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/b4990d5eff926fb9dadceef5bb79fa1932904eeb\",\"venue\":\"GCPR\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"40465774\",\"name\":\"Z. Gao\"},{\"authorId\":\"9162163\",\"name\":\"T. Han\"},{\"authorId\":\"145081305\",\"name\":\"L. Zhu\"},{\"authorId\":\"38079143\",\"name\":\"H. Zhang\"},{\"authorId\":\"38930487\",\"name\":\"Yinglong Wang\"}],\"doi\":\"10.1109/ACCESS.2018.2878313\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"title\":\"Exploring the Cross-Domain Action Recognition Problem by Deep Feature Learning and Cross-Domain Learning\",\"url\":\"https://www.semanticscholar.org/paper/5c45c46b9b35685497d5fcdf2d4d748f3d27449a\",\"venue\":\"IEEE Access\",\"year\":2018},{\"arxivId\":\"1907.13369\",\"authors\":[{\"authorId\":\"50224945\",\"name\":\"Wenhao Wu\"},{\"authorId\":\"2192303\",\"name\":\"D. He\"},{\"authorId\":\"145681032\",\"name\":\"Xiao Tan\"},{\"authorId\":\"2869725\",\"name\":\"Shifeng Chen\"},{\"authorId\":\"2671368\",\"name\":\"Shilei Wen\"}],\"doi\":\"10.1109/ICCV.2019.00632\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"2d8d533980774f7fa28f480b743c1998343fa3dd\",\"title\":\"Multi-Agent Reinforcement Learning Based Frame Sampling for Effective Untrimmed Video Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2d8d533980774f7fa28f480b743c1998343fa3dd\",\"venue\":\"2019 IEEE/CVF International Conference on Computer Vision (ICCV)\",\"year\":2019},{\"arxivId\":\"2011.10190\",\"authors\":[{\"authorId\":\"102811267\",\"name\":\"Reza Ghoddoosian\"},{\"authorId\":\"34282786\",\"name\":\"Saif Sayed\"},{\"authorId\":\"1720747\",\"name\":\"V. Athitsos\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"041f428cf81939985843402b72521289ea48b2e6\",\"title\":\"Action Duration Prediction for Segment-Level Alignment of Weakly-Labeled Videos\",\"url\":\"https://www.semanticscholar.org/paper/041f428cf81939985843402b72521289ea48b2e6\",\"venue\":\"ArXiv\",\"year\":2020},{\"arxivId\":\"2011.07807\",\"authors\":[{\"authorId\":\"1782000465\",\"name\":\"Aftab Alam\"},{\"authorId\":\"51453868\",\"name\":\"Irfan Ullah\"},{\"authorId\":\"2806926\",\"name\":\"Young-Koo Lee\"}],\"doi\":\"10.1109/ACCESS.2020.3017135\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"title\":\"Video Big Data Analytics in the Cloud: A Reference Architecture, Survey, Opportunities, and Open Research Issues\",\"url\":\"https://www.semanticscholar.org/paper/9faf9029981a0b92abdb983a60f2af96eca3aea2\",\"venue\":\"IEEE Access\",\"year\":2020}],\"corpusId\":16091693,\"doi\":\"10.1109/CVPR.2017.337\",\"fieldsOfStudy\":[\"Computer Science\"],\"influentialCitationCount\":34,\"is_open_access\":true,\"is_publisher_licensed\":true,\"paperId\":\"63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"references\":[{\"arxivId\":\"1507.05738\",\"authors\":[{\"authorId\":\"34149749\",\"name\":\"Serena Yeung\"},{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"47243342\",\"name\":\"N. Jin\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-017-1013-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"title\":\"Every Moment Counts: Dense Detailed Labeling of Actions in Complex Videos\",\"url\":\"https://www.semanticscholar.org/paper/aa2d1dac4e27aebfb759d6e0b41b8a8ab1b01406\",\"venue\":\"International Journal of Computer Vision\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"152821938\",\"name\":\"Sanketh Shetty\"},{\"authorId\":\"120906511\",\"name\":\"T. Leung\"},{\"authorId\":\"1694199\",\"name\":\"R. Sukthankar\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1109/CVPR.2014.223\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"title\":\"Large-Scale Video Classification with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/6d4c9c923e9f145d1c01a2de2afc38ec23c44253\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"1689269\",\"name\":\"C. Liu\"}],\"doi\":\"10.1109/CVPR.2011.5995407\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"title\":\"Action recognition by dense trajectories\",\"url\":\"https://www.semanticscholar.org/paper/3afbb0e64fcb70496b44b30b76fac9456cc51e34\",\"venue\":\"CVPR 2011\",\"year\":2011},{\"arxivId\":\"1409.0575\",\"authors\":[{\"authorId\":\"2192178\",\"name\":\"Olga Russakovsky\"},{\"authorId\":\"48550120\",\"name\":\"J. Deng\"},{\"authorId\":\"71309570\",\"name\":\"H. Su\"},{\"authorId\":\"2285165\",\"name\":\"J. Krause\"},{\"authorId\":\"145031342\",\"name\":\"S. Satheesh\"},{\"authorId\":\"145423516\",\"name\":\"S. Ma\"},{\"authorId\":\"3109481\",\"name\":\"Zhiheng Huang\"},{\"authorId\":\"2354728\",\"name\":\"A. Karpathy\"},{\"authorId\":\"2556428\",\"name\":\"A. Khosla\"},{\"authorId\":\"145879842\",\"name\":\"Michael S. Bernstein\"},{\"authorId\":\"39668247\",\"name\":\"A. Berg\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/s11263-015-0816-y\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"title\":\"ImageNet Large Scale Visual Recognition Challenge\",\"url\":\"https://www.semanticscholar.org/paper/e74f9b7f8eec6ba4704c206b93bc8079af3da4bd\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3216212\",\"name\":\"Vladyslav Sydorov\"},{\"authorId\":\"3090214\",\"name\":\"Mayu Sakurada\"},{\"authorId\":\"1787591\",\"name\":\"Christoph H. Lampert\"}],\"doi\":\"10.1109/CVPR.2014.182\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"3f6d73d16b1dc9daef6f67fc80110520b16b5799\",\"title\":\"Deep Fisher Kernels -- End to End Learning of the Fisher Kernel GMM Parameters\",\"url\":\"https://www.semanticscholar.org/paper/3f6d73d16b1dc9daef6f67fc80110520b16b5799\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Gorban\"},{\"authorId\":null,\"name\":\"H Idrees\"},{\"authorId\":null,\"name\":\"Y.-G Jiang\"},{\"authorId\":null,\"name\":\"A R Zamir\"},{\"authorId\":null,\"name\":\"I Laptev\"},{\"authorId\":null,\"name\":\"M Shah\"},{\"authorId\":null,\"name\":\"R Sukthankar\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"THUMOS challenge: Action recognition with a large number of classes\",\"year\":2015},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Supplementary material (appendix) for the pa- per. https://rohitgirdhar.github.io/ ActionVLAD/arxiv\",\"url\":\"\",\"venue\":\"Supplementary material (appendix) for the pa- per. https://rohitgirdhar.github.io/ ActionVLAD/arxiv\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1803520\",\"name\":\"L. V. D. Maaten\"},{\"authorId\":\"1695689\",\"name\":\"Geoffrey E. Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1c46943103bd7b7a2c7be86859995a4144d1938b\",\"title\":\"Visualizing Data using t-SNE\",\"url\":\"https://www.semanticscholar.org/paper/1c46943103bd7b7a2c7be86859995a4144d1938b\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1723883\",\"name\":\"F. Perronnin\"},{\"authorId\":\"3344005\",\"name\":\"C. Dance\"}],\"doi\":\"10.1109/CVPR.2007.383266\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"23694b6d61668e62bb11f17c1d75dde3b4951948\",\"title\":\"Fisher Kernels on Visual Vocabularies for Image Categorization\",\"url\":\"https://www.semanticscholar.org/paper/23694b6d61668e62bb11f17c1d75dde3b4951948\",\"venue\":\"2007 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2007},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"2876552\",\"name\":\"Changqing Zou\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"143740449\",\"name\":\"Q. Peng\"}],\"doi\":\"10.1007/978-3-319-10602-1_38\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"title\":\"Action Recognition with Stacked Fisher Vectors\",\"url\":\"https://www.semanticscholar.org/paper/34f2f2dbaca68eb05426b51620673e71b69e1b37\",\"venue\":\"ECCV\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1688071\",\"name\":\"Basura Fernando\"},{\"authorId\":\"2304222\",\"name\":\"E. Gavves\"},{\"authorId\":\"2111981\",\"name\":\"Jos\\u00e9 Oramas\"},{\"authorId\":\"3060081\",\"name\":\"A. Ghodrati\"},{\"authorId\":\"1704728\",\"name\":\"T. Tuytelaars\"}],\"doi\":\"10.1109/CVPR.2015.7299176\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"5443a1b18fed3173dc426735ff9f486194185172\",\"title\":\"Modeling video evolution for action recognition\",\"url\":\"https://www.semanticscholar.org/paper/5443a1b18fed3173dc426735ff9f486194185172\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A. Gorban\"},{\"authorId\":null,\"name\":\"H. Idrees\"},{\"authorId\":null,\"name\":\"Y.-G. Jiang\"},{\"authorId\":null,\"name\":\"A. R. Zamir\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and R\",\"url\":\"\",\"venue\":\"Sukthankar. THUMOS challenge: Action recognition with a large number of classes\",\"year\":2015},{\"arxivId\":\"1512.03958\",\"authors\":[{\"authorId\":\"3004979\",\"name\":\"G. Lev\"},{\"authorId\":\"2251827\",\"name\":\"Gil Sadeh\"},{\"authorId\":\"145969200\",\"name\":\"B. Klein\"},{\"authorId\":\"145128145\",\"name\":\"Lior Wolf\"}],\"doi\":\"10.1007/978-3-319-46466-4_50\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"title\":\"RNN Fisher Vectors for Action Recognition and Image Annotation\",\"url\":\"https://www.semanticscholar.org/paper/04b8a1d2498a7c8bd90a5465a02b2e8e178177c5\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1411.4389\",\"authors\":[{\"authorId\":\"7408951\",\"name\":\"J. Donahue\"},{\"authorId\":\"2234342\",\"name\":\"Lisa Anne Hendricks\"},{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"1811430\",\"name\":\"Subhashini Venugopalan\"},{\"authorId\":\"1687120\",\"name\":\"S. Guadarrama\"},{\"authorId\":\"2903226\",\"name\":\"Kate Saenko\"},{\"authorId\":\"1753210\",\"name\":\"Trevor Darrell\"}],\"doi\":\"10.1109/TPAMI.2016.2599174\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"f01fc808592ea7c473a69a6e7484040a435f36d9\",\"title\":\"Long-term recurrent convolutional networks for visual recognition and description\",\"url\":\"https://www.semanticscholar.org/paper/f01fc808592ea7c473a69a6e7484040a435f36d9\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"}],\"doi\":\"10.1109/CVPR.2005.177\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"title\":\"Histograms of oriented gradients for human detection\",\"url\":\"https://www.semanticscholar.org/paper/cec734d7097ab6b1e60d95228ffd64248eb89d66\",\"venue\":\"2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05)\",\"year\":2005},{\"arxivId\":\"1503.08909\",\"authors\":[{\"authorId\":\"2340579\",\"name\":\"J. Ng\"},{\"authorId\":\"3308897\",\"name\":\"Matthew J. Hausknecht\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"},{\"authorId\":\"49519592\",\"name\":\"Oriol Vinyals\"},{\"authorId\":\"3089272\",\"name\":\"Rajat Monga\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"}],\"doi\":\"10.1109/CVPR.2015.7299101\",\"intent\":[],\"isInfluential\":true,\"paperId\":\"5418b2a482720e013d487a385c26fae0f017c6a6\",\"title\":\"Beyond short snippets: Deep networks for video classification\",\"url\":\"https://www.semanticscholar.org/paper/5418b2a482720e013d487a385c26fae0f017c6a6\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1409.1556\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"eb42cf88027de515750f230b23b1a057dc782108\",\"title\":\"Very Deep Convolutional Networks for Large-Scale Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/eb42cf88027de515750f230b23b1a057dc782108\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"G. Awad\"},{\"authorId\":null,\"name\":\"J. Fiscus\"},{\"authorId\":null,\"name\":\"M. Michel\"},{\"authorId\":null,\"name\":\"D. Joy\"},{\"authorId\":null,\"name\":\"W. Kraaij\"},{\"authorId\":null,\"name\":\"A. F. Smeaton\"},{\"authorId\":null,\"name\":\"G. Qunot\"},{\"authorId\":null,\"name\":\"M. Eskevich\"},{\"authorId\":null,\"name\":\"R. Aly\"},{\"authorId\":null,\"name\":\"G.J.F. Jones\"},{\"authorId\":null,\"name\":\"R. Ordelman\"},{\"authorId\":null,\"name\":\"B. Huet\"},{\"authorId\":null,\"name\":\"M. Larson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Trecvid 2016: Evaluating video search\",\"url\":\"\",\"venue\":\"video event detection, localization, and hyperlinking. In TRECVID\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Jhuang\"},{\"authorId\":null,\"name\":\"E. Garrote\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\": A method for stochastic optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L Van Der Maaten\"},{\"authorId\":null,\"name\":\"G E Hinton\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing highdimensional data using t-sne\",\"url\":\"\",\"venue\":\"Visualizing highdimensional data using t-sne\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"48950628\",\"name\":\"N. Dalal\"},{\"authorId\":\"1756114\",\"name\":\"B. Triggs\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1007/11744047_33\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"title\":\"Human Detection Using Oriented Histograms of Flow and Appearance\",\"url\":\"https://www.semanticscholar.org/paper/44f3ac3277c2eb6e5599739eb875888c46e21d4c\",\"venue\":\"ECCV\",\"year\":2006},{\"arxivId\":\"1510.00562\",\"authors\":[{\"authorId\":\"41191188\",\"name\":\"Lin Sun\"},{\"authorId\":\"2370507\",\"name\":\"K. Jia\"},{\"authorId\":\"1739816\",\"name\":\"D. Yeung\"},{\"authorId\":\"2131088\",\"name\":\"B. Shi\"}],\"doi\":\"10.1109/ICCV.2015.522\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"title\":\"Human Action Recognition Using Factorized Spatio-Temporal Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/95561aec9f00cdf5346e627574e1a022eda3e4f5\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1406.2199\",\"authors\":[{\"authorId\":\"34838386\",\"name\":\"K. Simonyan\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"title\":\"Two-Stream Convolutional Networks for Action Recognition in Videos\",\"url\":\"https://www.semanticscholar.org/paper/67dccc9a856b60bdc4d058d83657a089b8ad4486\",\"venue\":\"NIPS\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1681054\",\"name\":\"H. J\\u00e9gou\"},{\"authorId\":\"3271933\",\"name\":\"M. Douze\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"},{\"authorId\":\"144565371\",\"name\":\"P. P\\u00e9rez\"}],\"doi\":\"10.1109/CVPR.2010.5540039\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"400e09ceca374f0621335f84a4daf2049d5902be\",\"title\":\"Aggregating local descriptors into a compact image representation\",\"url\":\"https://www.semanticscholar.org/paper/400e09ceca374f0621335f84a4daf2049d5902be\",\"venue\":\"2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1007/s11263-015-0859-0\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"16eaa26a84468b27e559215db01c53286808ec2a\",\"title\":\"MoFAP: A Multi-level Representation for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/16eaa26a84468b27e559215db01c53286808ec2a\",\"venue\":\"International Journal of Computer Vision\",\"year\":2015},{\"arxivId\":\"1608.07138\",\"authors\":[{\"authorId\":\"37868227\",\"name\":\"C. D. Souza\"},{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"2286630\",\"name\":\"E. Vig\"},{\"authorId\":\"3940956\",\"name\":\"A. Pe\\u00f1a\"}],\"doi\":\"10.1007/978-3-319-46478-7_43\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"title\":\"Sympathy for the Details: Dense Trajectories and Hybrid Classification Architectures for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4191d91b6f8c6e48ba6aed3451384b6122ab4a15\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79430136\",\"name\":\"Axel M. Gressner\"},{\"authorId\":\"34943373\",\"name\":\"Torsten Arndt\"}],\"doi\":\"10.1515/9783111548050-035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"896384a7206ab682d5bf585b47eac93e23e60529\",\"title\":\"Z\",\"url\":\"https://www.semanticscholar.org/paper/896384a7206ab682d5bf585b47eac93e23e60529\",\"venue\":\"Lexikon der Medizinischen Laboratoriumsdiagnostik\",\"year\":2012},{\"arxivId\":\"1506.01929\",\"authors\":[{\"authorId\":\"2492127\",\"name\":\"Philippe Weinzaepfel\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2015.362\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"title\":\"Learning to Track for Spatio-Temporal Action Localization\",\"url\":\"https://www.semanticscholar.org/paper/2f488a8139630e3b2499ea2d3ff192e33387f7de\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":\"1512.00795\",\"authors\":[{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1109/CVPR.2016.291\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"title\":\"Actions ~ Transformations\",\"url\":\"https://www.semanticscholar.org/paper/8d093efcfadda3ac7de7b0e1ca7d9aa2005c2ec3\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"35033378\",\"name\":\"M. M. Ullah\"},{\"authorId\":\"2909350\",\"name\":\"Alexander Kl\\u00e4ser\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.5244/C.23.124\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"title\":\"Evaluation of Local Spatio-temporal Features for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/a39e6968580762ac5ae3cd064e86e1849f3efb7f\",\"venue\":\"BMVC\",\"year\":2009},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"L. van der Maaten\"},{\"authorId\":null,\"name\":\"G. E. Hinton\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Visualizing highdimensional data using t-sne\",\"url\":\"\",\"venue\":\"\",\"year\":2008},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34346779\",\"name\":\"Weixin Li\"},{\"authorId\":null,\"name\":\"Qian Yu\"},{\"authorId\":\"1696401\",\"name\":\"Ajay Divakaran\"},{\"authorId\":\"1699559\",\"name\":\"N. Vasconcelos\"}],\"doi\":\"10.1109/ICCV.2013.339\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"70a97b4191e31bd5c6d2aef82ff6086dfb1282db\",\"title\":\"Dynamic Pooling for Complex Event Recognition\",\"url\":\"https://www.semanticscholar.org/paper/70a97b4191e31bd5c6d2aef82ff6086dfb1282db\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1611.02155\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1709096\",\"name\":\"R. Wildes\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"title\":\"Spatiotemporal Residual Networks for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/5f4d2f6ad967f7c9369c04e75cda08f12cb8afbd\",\"venue\":\"NIPS\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3063676\",\"name\":\"Michalis Raptis\"},{\"authorId\":\"144398147\",\"name\":\"L. Sigal\"}],\"doi\":\"10.1109/CVPR.2013.342\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9bc95b2fa949b0de6ef028fde359e2a60fceee04\",\"title\":\"Poselet Key-Framing: A Model for Human Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9bc95b2fa949b0de6ef028fde359e2a60fceee04\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2013.207\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"25d0fa49ca846370ff4796a6ac6688a42cf50f77\",\"title\":\"All About VLAD\",\"url\":\"https://www.semanticscholar.org/paper/25d0fa49ca846370ff4796a6ac6688a42cf50f77\",\"venue\":\"2013 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2013},{\"arxivId\":\"1608.00859\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"1807606\",\"name\":\"D. Lin\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"},{\"authorId\":\"1681236\",\"name\":\"L. Gool\"}],\"doi\":\"10.1007/978-3-319-46484-8_2\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"title\":\"Temporal Segment Networks: Towards Good Practices for Deep Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/ea3d7de6c0880e14455b9acb28f1bc1234321456\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1412.6980\",\"authors\":[{\"authorId\":\"1726807\",\"name\":\"Diederik P. Kingma\"},{\"authorId\":\"2503659\",\"name\":\"Jimmy Ba\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"title\":\"Adam: A Method for Stochastic Optimization\",\"url\":\"https://www.semanticscholar.org/paper/a6cb366736791bcccc5c8639de5a8f9636bf87e8\",\"venue\":\"ICLR\",\"year\":2015},{\"arxivId\":\"1604.04053\",\"authors\":[{\"authorId\":\"144813536\",\"name\":\"Kai Kang\"},{\"authorId\":\"3001348\",\"name\":\"Wanli Ouyang\"},{\"authorId\":\"49404547\",\"name\":\"Hongsheng Li\"},{\"authorId\":\"31843833\",\"name\":\"X. Wang\"}],\"doi\":\"10.1109/CVPR.2016.95\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"title\":\"Object Detection from Video Tubelets with Convolutional Neural Networks\",\"url\":\"https://www.semanticscholar.org/paper/8da14c0c524d0cb832afadd0f879d162a4a8c991\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"79430136\",\"name\":\"Axel M. Gressner\"},{\"authorId\":\"34943373\",\"name\":\"T. Arndt\"}],\"doi\":\"10.1515/9783111548050-035\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d8a00b35dba8eec07dc59bbe980a87d297b85bfc\",\"title\":\"Z\",\"url\":\"https://www.semanticscholar.org/paper/d8a00b35dba8eec07dc59bbe980a87d297b85bfc\",\"venue\":\"Lexikon der Medizinischen Laboratoriumsdiagnostik\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2367683\",\"name\":\"H. Pirsiavash\"},{\"authorId\":\"1770537\",\"name\":\"D. Ramanan\"}],\"doi\":\"10.1109/CVPR.2014.85\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7c0f1b49fd8a5b2ca8116e613a5da10babe5e564\",\"title\":\"Parsing Videos of Actions with Segmental Grammars\",\"url\":\"https://www.semanticscholar.org/paper/7c0f1b49fd8a5b2ca8116e613a5da10babe5e564\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":null,\"authors\":[{\"authorId\":\"145876242\",\"name\":\"G. Awad\"},{\"authorId\":\"3241934\",\"name\":\"J. Fiscus\"},{\"authorId\":\"4770950\",\"name\":\"D. Joy\"},{\"authorId\":\"33765735\",\"name\":\"M. Michel\"},{\"authorId\":\"1680223\",\"name\":\"A. Smeaton\"},{\"authorId\":\"1740640\",\"name\":\"Wessel Kraaij\"},{\"authorId\":\"1406426956\",\"name\":\"Georges Qu\\u00e9not\"},{\"authorId\":\"2203861\",\"name\":\"Maria Eskevich\"},{\"authorId\":\"144597794\",\"name\":\"R. Aly\"},{\"authorId\":\"32488932\",\"name\":\"Roeland Ordelman\"},{\"authorId\":\"51091173\",\"name\":\"M. Ritter\"},{\"authorId\":\"143723939\",\"name\":\"G. Jones\"},{\"authorId\":\"145880168\",\"name\":\"B. Huet\"},{\"authorId\":\"104810482\",\"name\":\"M. Larson\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"c10c5d3fd3575570ec55ddbe838fb2a52cf97bc9\",\"title\":\"TRECVID 2016: Evaluating Video Search, Video Event Detection, Localization, and Hyperlinking\",\"url\":\"https://www.semanticscholar.org/paper/c10c5d3fd3575570ec55ddbe838fb2a52cf97bc9\",\"venue\":\"TRECVID\",\"year\":2016},{\"arxivId\":null,\"authors\":[],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Project webpage (code/models). http:// rohitgirdhar.github.io/ActionVLAD\",\"url\":\"\",\"venue\":\"Project webpage (code/models). http:// rohitgirdhar.github.io/ActionVLAD\",\"year\":null},{\"arxivId\":null,\"authors\":[{\"authorId\":\"3355264\",\"name\":\"Kevin D. Tang\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"},{\"authorId\":\"50678963\",\"name\":\"D. Koller\"}],\"doi\":\"10.1109/CVPR.2012.6247808\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"6acdddc36ea57ec84581e9e196665f246e8157ab\",\"title\":\"Learning latent temporal structure for complex event detection\",\"url\":\"https://www.semanticscholar.org/paper/6acdddc36ea57ec84581e9e196665f246e8157ab\",\"venue\":\"2012 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1687325\",\"name\":\"Du Tran\"},{\"authorId\":\"1769383\",\"name\":\"Lubomir D. Bourdev\"},{\"authorId\":\"2276554\",\"name\":\"R. Fergus\"},{\"authorId\":\"1732879\",\"name\":\"L. Torresani\"},{\"authorId\":\"2210374\",\"name\":\"Manohar Paluri\"}],\"doi\":\"10.1109/ICCV.2015.510\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"title\":\"Learning Spatiotemporal Features with 3D Convolutional Networks\",\"url\":\"https://www.semanticscholar.org/paper/d25c65d261ea0e6a458be4c50c40ffe5bc508f77\",\"venue\":\"2015 IEEE International Conference on Computer Vision (ICCV)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"34849128\",\"name\":\"Marcus Rohrbach\"},{\"authorId\":\"2485529\",\"name\":\"Michaela Regneri\"},{\"authorId\":\"1906895\",\"name\":\"M. Andriluka\"},{\"authorId\":\"40404576\",\"name\":\"S. Amin\"},{\"authorId\":\"1717560\",\"name\":\"Manfred Pinkal\"},{\"authorId\":\"48920094\",\"name\":\"B. Schiele\"}],\"doi\":\"10.1007/978-3-642-33718-5_11\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"title\":\"Script Data for Attribute-Based Recognition of Composite Activities\",\"url\":\"https://www.semanticscholar.org/paper/8623fe8b087cedcaac276e313f8fed6f0dfccc33\",\"venue\":\"ECCV\",\"year\":2012},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2299479\",\"name\":\"R. Arandjelovi\\u0107\"},{\"authorId\":\"3413968\",\"name\":\"Petr Gron\\u00e1t\"},{\"authorId\":\"34395018\",\"name\":\"A. Torii\"},{\"authorId\":\"1758039\",\"name\":\"T. Pajdla\"},{\"authorId\":\"1782755\",\"name\":\"Josef Sivic\"}],\"doi\":\"10.1109/CVPR.2016.572\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"bd53919b76f5eed0012429a8232eb1d5df300376\",\"title\":\"NetVLAD: CNN Architecture for Weakly Supervised Place Recognition\",\"url\":\"https://www.semanticscholar.org/paper/bd53919b76f5eed0012429a8232eb1d5df300376\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":\"1505.04868\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"},{\"authorId\":\"50295995\",\"name\":\"X. Tang\"}],\"doi\":\"10.1109/CVPR.2015.7299059\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"df658828fb4146877f1031ec9d07052f7eb31186\",\"title\":\"Action recognition with trajectory-pooled deep-convolutional descriptors\",\"url\":\"https://www.semanticscholar.org/paper/df658828fb4146877f1031ec9d07052f7eb31186\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":\"1212.0402\",\"authors\":[{\"authorId\":\"1799979\",\"name\":\"K. Soomro\"},{\"authorId\":\"40029556\",\"name\":\"A. Zamir\"},{\"authorId\":\"145103012\",\"name\":\"M. Shah\"}],\"doi\":null,\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"title\":\"UCF101: A Dataset of 101 Human Actions Classes From Videos in The Wild\",\"url\":\"https://www.semanticscholar.org/paper/da9e411fcf740569b6b356f330a1d0fc077c8d7c\",\"venue\":\"ArXiv\",\"year\":2012},{\"arxivId\":\"1405.4506\",\"authors\":[{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"39527134\",\"name\":\"X. Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1016/j.cviu.2016.03.013\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"facbedfe90956c720f70aab14767b5e25dcc6478\",\"title\":\"Bag of visual words and fusion methods for action recognition: Comprehensive study and good practice\",\"url\":\"https://www.semanticscholar.org/paper/facbedfe90956c720f70aab14767b5e25dcc6478\",\"venue\":\"Comput. Vis. Image Underst.\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"123446103\",\"name\":\"Hilde Kuehne\"},{\"authorId\":\"119268487\",\"name\":\"Hueihan Jhuang\"},{\"authorId\":\"1930964\",\"name\":\"E. Garrote\"},{\"authorId\":\"145031878\",\"name\":\"T. Poggio\"},{\"authorId\":\"1981539\",\"name\":\"Thomas Serre\"}],\"doi\":\"10.1109/ICCV.2011.6126543\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"8b3b8848a311c501e704c45c6d50430ab7068956\",\"title\":\"HMDB: A large video database for human motion recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b3b8848a311c501e704c45c6d50430ab7068956\",\"venue\":\"2011 International Conference on Computer Vision\",\"year\":2011},{\"arxivId\":null,\"authors\":[{\"authorId\":\"46506697\",\"name\":\"Heng Wang\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/ICCV.2013.441\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"d721f4d64b8e722222c876f0a0f226ed49476347\",\"title\":\"Action Recognition with Improved Trajectories\",\"url\":\"https://www.semanticscholar.org/paper/d721f4d64b8e722222c876f0a0f226ed49476347\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M. Abadi\"},{\"authorId\":null,\"name\":\"A. Agarwal\"},{\"authorId\":null,\"name\":\"P. Barham\"},{\"authorId\":null,\"name\":\"E. Brevdo\"},{\"authorId\":null,\"name\":\"Z. Chen\"},{\"authorId\":null,\"name\":\"C. Citro\"},{\"authorId\":null,\"name\":\"G. S. Corrado\"},{\"authorId\":null,\"name\":\"A. Davis\"},{\"authorId\":null,\"name\":\"J. Dean\"},{\"authorId\":null,\"name\":\"M. Devin\"},{\"authorId\":null,\"name\":\"S. Ghemawat\"},{\"authorId\":null,\"name\":\"I. Goodfellow\"},{\"authorId\":null,\"name\":\"A. Harp\"},{\"authorId\":null,\"name\":\"G. Irving\"},{\"authorId\":null,\"name\":\"M. Isard\"},{\"authorId\":null,\"name\":\"Y. Jia\"},{\"authorId\":null,\"name\":\"R. Jozefowicz\"},{\"authorId\":null,\"name\":\"L. Kaiser\"},{\"authorId\":null,\"name\":\"M. Kudlur\"},{\"authorId\":null,\"name\":\"J. Levenberg\"},{\"authorId\":null,\"name\":\"D. Man\\u00e9\"},{\"authorId\":null,\"name\":\"R. Monga\"},{\"authorId\":null,\"name\":\"S. Moore\"},{\"authorId\":null,\"name\":\"D. Murray\"},{\"authorId\":null,\"name\":\"C. Olah\"},{\"authorId\":null,\"name\":\"M. Schuster\"},{\"authorId\":null,\"name\":\"J. Shlens\"},{\"authorId\":null,\"name\":\"B. Steiner\"},{\"authorId\":null,\"name\":\"I. Sutskever\"},{\"authorId\":null,\"name\":\"K. Talwar\"},{\"authorId\":null,\"name\":\"P. Tucker\"},{\"authorId\":null,\"name\":\"V. Vanhoucke\"},{\"authorId\":null,\"name\":\"V. Vasudevan\"},{\"authorId\":null,\"name\":\"F. Vi\\u00e9gas\"},{\"authorId\":null,\"name\":\"O. Vinyals\"},{\"authorId\":null,\"name\":\"P. Warden\"},{\"authorId\":null,\"name\":\"M. Wattenberg\"},{\"authorId\":null,\"name\":\"M. Wicke\"},{\"authorId\":null,\"name\":\"Y. Yu\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"and X\",\"url\":\"\",\"venue\":\"Zheng. Tensor- Flow: Large-scale machine learning on heterogeneous systems\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"H. Jhuang H. Kuehne\"},{\"authorId\":null,\"name\":\"E. Garrote\"},{\"authorId\":null,\"name\":\"T. Poggio\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\": A method for stochastic optimization\",\"url\":\"\",\"venue\":\"\",\"year\":2015},{\"arxivId\":\"1604.06573\",\"authors\":[{\"authorId\":\"2322150\",\"name\":\"Christoph Feichtenhofer\"},{\"authorId\":\"1718587\",\"name\":\"A. Pinz\"},{\"authorId\":\"1688869\",\"name\":\"Andrew Zisserman\"}],\"doi\":\"10.1109/CVPR.2016.213\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"9d9aced120e530484609164c836da64548693484\",\"title\":\"Convolutional Two-Stream Network Fusion for Video Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/9d9aced120e530484609164c836da64548693484\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"A Wang\"},{\"authorId\":null,\"name\":\"A Farhadi\"},{\"authorId\":null,\"name\":\"Gupta\"},{\"authorId\":null,\"name\":\"Actionsactions\\u02dcactions\\u02dctransformations\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"CVPR\",\"url\":\"\",\"venue\":\"CVPR\",\"year\":2016},{\"arxivId\":\"1602.07261\",\"authors\":[{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"},{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2657155\",\"name\":\"V. Vanhoucke\"},{\"authorId\":\"122113652\",\"name\":\"Alexander Amir Alemi\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"title\":\"Inception-v4, Inception-ResNet and the Impact of Residual Connections on Learning\",\"url\":\"https://www.semanticscholar.org/paper/b5c26ab8767d046cb6e32d959fdf726aee89bb62\",\"venue\":\"AAAI\",\"year\":2017},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2121584\",\"name\":\"Wangjiang Zhu\"},{\"authorId\":\"145815850\",\"name\":\"Jie Hu\"},{\"authorId\":\"143847421\",\"name\":\"Gang Sun\"},{\"authorId\":\"47300766\",\"name\":\"X. Cao\"},{\"authorId\":\"143970608\",\"name\":\"Y. Qiao\"}],\"doi\":\"10.1109/CVPR.2016.219\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"title\":\"A Key Volume Mining Deep Framework for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/4c822785c29ceaf67a0de9c699716c94fefbd37d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"9200530\",\"name\":\"Juan Carlos Niebles\"},{\"authorId\":\"120896463\",\"name\":\"Chih-Wei Chen\"},{\"authorId\":\"48004138\",\"name\":\"Li Fei-Fei\"}],\"doi\":\"10.1007/978-3-642-15552-9_29\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"994a7b903b937f8b177c035db86852091fd26aa7\",\"title\":\"Modeling Temporal Structure of Decomposable Motion Segments for Activity Classification\",\"url\":\"https://www.semanticscholar.org/paper/994a7b903b937f8b177c035db86852091fd26aa7\",\"venue\":\"ECCV\",\"year\":2010},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"Y. Jiang\"},{\"authorId\":null,\"name\":\"J. Liu\"},{\"authorId\":null,\"name\":\"A. Roshan Zamir\"},{\"authorId\":null,\"name\":\"I. Laptev\"},{\"authorId\":null,\"name\":\"M. Piccardi\"},{\"authorId\":null,\"name\":\"M. Shah\"},{\"authorId\":null,\"name\":\"R. Sukthankar\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"THUMOS challenge: Action recognition with a large number of classes\",\"url\":\"\",\"venue\":\"http://www. thumos.info/\",\"year\":2013},{\"arxivId\":\"1603.05027\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1007/978-3-319-46493-0_38\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"title\":\"Identity Mappings in Deep Residual Networks\",\"url\":\"https://www.semanticscholar.org/paper/77f0a39b8e02686fd85b01971f8feb7f60971f80\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1609.08675\",\"authors\":[{\"authorId\":\"1389570466\",\"name\":\"Sami Abu-El-Haija\"},{\"authorId\":\"144317839\",\"name\":\"Nisarg Kothari\"},{\"authorId\":\"2119006\",\"name\":\"Joonseok Lee\"},{\"authorId\":\"1820908\",\"name\":\"A. Natsev\"},{\"authorId\":\"1805076\",\"name\":\"G. Toderici\"},{\"authorId\":\"2758088\",\"name\":\"B. Varadarajan\"},{\"authorId\":\"2259154\",\"name\":\"Sudheendra Vijayanarasimhan\"}],\"doi\":null,\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"title\":\"YouTube-8M: A Large-Scale Video Classification Benchmark\",\"url\":\"https://www.semanticscholar.org/paper/c9a1e8e1ba2913ef0bdf1c5eaaa1ac0a79be3716\",\"venue\":\"ArXiv\",\"year\":2016},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1766489\",\"name\":\"M. Ryoo\"},{\"authorId\":\"1705627\",\"name\":\"J. Aggarwal\"}],\"doi\":\"10.1109/CVPR.2006.242\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"a6e1a68340951785c7aa3d3ba7a99d64a997a2ef\",\"title\":\"Recognition of Composite Human Activities through Context-Free Grammar Based Representation\",\"url\":\"https://www.semanticscholar.org/paper/a6e1a68340951785c7aa3d3ba7a99d64a997a2ef\",\"venue\":\"2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06)\",\"year\":2006},{\"arxivId\":\"1411.4006\",\"authors\":[{\"authorId\":\"2351434\",\"name\":\"Zhongwen Xu\"},{\"authorId\":\"39033919\",\"name\":\"Y. Yang\"},{\"authorId\":\"7661726\",\"name\":\"A. Hauptmann\"}],\"doi\":\"10.1109/CVPR.2015.7298789\",\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"title\":\"A discriminative CNN video representation for event detection\",\"url\":\"https://www.semanticscholar.org/paper/10232b9557b39b4a5a90cdc1b3bd9d25824a2b8f\",\"venue\":\"2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"4599641\",\"name\":\"M. Amer\"},{\"authorId\":\"143856428\",\"name\":\"S. Todorovic\"},{\"authorId\":\"145841336\",\"name\":\"A. Fern\"},{\"authorId\":\"145380991\",\"name\":\"S. Zhu\"}],\"doi\":\"10.1109/ICCV.2013.171\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"dad1256c23f9e22126cc8f982eb45bed69df587f\",\"title\":\"Monte Carlo Tree Search for Scheduling Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/dad1256c23f9e22126cc8f982eb45bed69df587f\",\"venue\":\"2013 IEEE International Conference on Computer Vision\",\"year\":2013},{\"arxivId\":\"1507.02159\",\"authors\":[{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"3331521\",\"name\":\"Yuanjun Xiong\"},{\"authorId\":\"1915826\",\"name\":\"Zhe Wang\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"1f05473c587e2a3b587f51eb808695a1c10bc153\",\"title\":\"Towards Good Practices for Very Deep Two-Stream ConvNets\",\"url\":\"https://www.semanticscholar.org/paper/1f05473c587e2a3b587f51eb808695a1c10bc153\",\"venue\":\"ArXiv\",\"year\":2015},{\"arxivId\":null,\"authors\":[{\"authorId\":\"2985266\",\"name\":\"Zhuowei Cai\"},{\"authorId\":\"33345248\",\"name\":\"L. Wang\"},{\"authorId\":\"1766837\",\"name\":\"Xiaojiang Peng\"},{\"authorId\":null,\"name\":\"Yu Qiao\"}],\"doi\":\"10.1109/CVPR.2014.83\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"title\":\"Multi-view Super Vector for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/8b5ff695d2bafa45f6bc50927b3142cc93601c59\",\"venue\":\"2014 IEEE Conference on Computer Vision and Pattern Recognition\",\"year\":2014},{\"arxivId\":\"1604.01753\",\"authors\":[{\"authorId\":\"34280810\",\"name\":\"Gunnar A. Sigurdsson\"},{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"39849136\",\"name\":\"X. Wang\"},{\"authorId\":\"143787583\",\"name\":\"Ali Farhadi\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"1737809\",\"name\":\"A. Gupta\"}],\"doi\":\"10.1007/978-3-319-46448-0_31\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":false,\"paperId\":\"21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"title\":\"Hollywood in Homes: Crowdsourcing Data Collection for Activity Understanding\",\"url\":\"https://www.semanticscholar.org/paper/21334d1aac5422da88780f8e24e181bfa15ef0e1\",\"venue\":\"ECCV\",\"year\":2016},{\"arxivId\":\"1511.06040\",\"authors\":[{\"authorId\":\"31515231\",\"name\":\"M. S. Ibrahim\"},{\"authorId\":\"2716937\",\"name\":\"S. Muralidharan\"},{\"authorId\":\"49152600\",\"name\":\"Zhiwei Deng\"},{\"authorId\":\"3214848\",\"name\":\"Arash Vahdat\"},{\"authorId\":\"10771328\",\"name\":\"G. Mori\"}],\"doi\":\"10.1109/CVPR.2016.217\",\"intent\":[\"background\"],\"isInfluential\":false,\"paperId\":\"7ee9ba11982ec072d4ced752970cb8910e469f28\",\"title\":\"A Hierarchical Deep Temporal Model for Group Activity Recognition\",\"url\":\"https://www.semanticscholar.org/paper/7ee9ba11982ec072d4ced752970cb8910e469f28\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1502.03167\",\"authors\":[{\"authorId\":\"144147316\",\"name\":\"S. Ioffe\"},{\"authorId\":\"2574060\",\"name\":\"Christian Szegedy\"}],\"doi\":null,\"intent\":[\"methodology\"],\"isInfluential\":false,\"paperId\":\"4d376d6978dad0374edfa6709c9556b42d3594d3\",\"title\":\"Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\",\"url\":\"https://www.semanticscholar.org/paper/4d376d6978dad0374edfa6709c9556b42d3594d3\",\"venue\":\"ICML\",\"year\":2015},{\"arxivId\":\"1512.03385\",\"authors\":[{\"authorId\":\"39353098\",\"name\":\"Kaiming He\"},{\"authorId\":\"1771551\",\"name\":\"X. Zhang\"},{\"authorId\":\"3080683\",\"name\":\"Shaoqing Ren\"},{\"authorId\":null,\"name\":\"Jian Sun\"}],\"doi\":\"10.1109/cvpr.2016.90\",\"intent\":[\"background\",\"methodology\"],\"isInfluential\":true,\"paperId\":\"2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"title\":\"Deep Residual Learning for Image Recognition\",\"url\":\"https://www.semanticscholar.org/paper/2c03df8b48bf3fa39054345bafabfeff15bfd11d\",\"venue\":\"2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2016},{\"arxivId\":\"1604.04494\",\"authors\":[{\"authorId\":\"2668759\",\"name\":\"G. Varol\"},{\"authorId\":\"143991676\",\"name\":\"I. Laptev\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2017.2712608\",\"intent\":[\"background\"],\"isInfluential\":true,\"paperId\":\"47e3ef70f2539386bcef604097fa9235246c6d53\",\"title\":\"Long-Term Temporal Convolutions for Action Recognition\",\"url\":\"https://www.semanticscholar.org/paper/47e3ef70f2539386bcef604097fa9235246c6d53\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2018},{\"arxivId\":null,\"authors\":[{\"authorId\":\"1799820\",\"name\":\"Adrien Gaidon\"},{\"authorId\":\"1753355\",\"name\":\"Z. Harchaoui\"},{\"authorId\":\"2462253\",\"name\":\"C. Schmid\"}],\"doi\":\"10.1109/TPAMI.2013.65\",\"intent\":[],\"isInfluential\":false,\"paperId\":\"404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"title\":\"Temporal Localization of Actions with Actoms\",\"url\":\"https://www.semanticscholar.org/paper/404352f5c18d4aca97f0cb660a31bf5d0df3fe0c\",\"venue\":\"IEEE Transactions on Pattern Analysis and Machine Intelligence\",\"year\":2013},{\"arxivId\":null,\"authors\":[{\"authorId\":null,\"name\":\"M Abadi\"},{\"authorId\":null,\"name\":\"A Agarwal\"},{\"authorId\":null,\"name\":\"P Barham\"},{\"authorId\":null,\"name\":\"E Brevdo\"},{\"authorId\":null,\"name\":\"Z Chen\"},{\"authorId\":null,\"name\":\"C Citro\"},{\"authorId\":null,\"name\":\"G S Corrado\"},{\"authorId\":null,\"name\":\"A Davis\"},{\"authorId\":null,\"name\":\"J Dean\"},{\"authorId\":null,\"name\":\"M Devin\"},{\"authorId\":null,\"name\":\"S Ghemawat\"},{\"authorId\":null,\"name\":\"I Goodfellow\"},{\"authorId\":null,\"name\":\"A Harp\"},{\"authorId\":null,\"name\":\"G Irving\"},{\"authorId\":null,\"name\":\"M Isard\"},{\"authorId\":null,\"name\":\"Y Jia\"},{\"authorId\":null,\"name\":\"R Jozefowicz\"},{\"authorId\":null,\"name\":\"L Kaiser\"},{\"authorId\":null,\"name\":\"M Kudlur\"},{\"authorId\":null,\"name\":\"J Levenberg\"},{\"authorId\":null,\"name\":\"D Man\\u00e9\"},{\"authorId\":null,\"name\":\"R Monga\"},{\"authorId\":null,\"name\":\"S Moore\"},{\"authorId\":null,\"name\":\"D Murray\"},{\"authorId\":null,\"name\":\"C Olah\"},{\"authorId\":null,\"name\":\"M Schuster\"},{\"authorId\":null,\"name\":\"J Shlens\"},{\"authorId\":null,\"name\":\"B Steiner\"},{\"authorId\":null,\"name\":\"I Sutskever\"},{\"authorId\":null,\"name\":\"K Talwar\"},{\"authorId\":null,\"name\":\"P Tucker\"},{\"authorId\":null,\"name\":\"V Vanhoucke\"},{\"authorId\":null,\"name\":\"V Vasudevan\"},{\"authorId\":null,\"name\":\"F Vi\\u00e9gas\"},{\"authorId\":null,\"name\":\"O Vinyals\"}],\"doi\":null,\"intent\":[],\"isInfluential\":false,\"paperId\":\"\",\"title\":\"Wicke, Y. Yu, and X. Zheng. Tensor- Flow: Large-scale machine learning on heterogeneous systems\",\"url\":\"\",\"venue\":\"Wicke, Y. Yu, and X. Zheng. Tensor- Flow: Large-scale machine learning on heterogeneous systems\",\"year\":2015}],\"title\":\"ActionVLAD: Learning Spatio-Temporal Aggregation for Action Classification\",\"topics\":[{\"topic\":\"End-to-end principle\",\"topicId\":\"299633\",\"url\":\"https://www.semanticscholar.org/topic/299633\"},{\"topic\":\"End-to-end encryption\",\"topicId\":\"854929\",\"url\":\"https://www.semanticscholar.org/topic/854929\"},{\"topic\":\"Motion compensation\",\"topicId\":\"100764\",\"url\":\"https://www.semanticscholar.org/topic/100764\"},{\"topic\":\"IBM Notes\",\"topicId\":\"82564\",\"url\":\"https://www.semanticscholar.org/topic/82564\"},{\"topic\":\"Veritas Cluster Server\",\"topicId\":\"7172148\",\"url\":\"https://www.semanticscholar.org/topic/7172148\"}],\"url\":\"https://www.semanticscholar.org/paper/63213d080a43660ac59ea12e3c35e6953f6d7ce8\",\"venue\":\"2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)\",\"year\":2017}\n"